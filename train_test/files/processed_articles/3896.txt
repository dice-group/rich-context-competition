{
    "abstract": "Abstract\nIn the few years since the advent of `Big Data' research, social media analytics has begun to accumulate studies drawing on\nsocial media as a resource and tool for research work. Yet, there has been relatively little attention paid to the devel-\nopment of methodologies for handling this kind of data. The few works that exist in this area often reflect upon the\nimplications of `grand' social science methodological concepts for new social media research (i.e. they focus on general\nissues such as sampling, data validity, ethics, etc.). By contrast, we advance an abductively oriented methodological suite\ndesigned to explore the construction of phenomena played out through social media. To do this, we use a software tool \u00ad\nChorus \u00ad to illustrate a visual analytic approach to data. Informed by visual analytic principles, we posit a two-by-two\nmethodological model of social media analytics, combining two data collection strategies with two analytic modes. We go\non to demonstrate each of these four approaches `in action', to help clarify how and why they might be used to address\nvarious research questions.\n",
    "reduced_content": "Original Research Article\nDoing social media analytics\nPhillip Brooker1, Julie Barnett1 and Timothy Cribbin2\n Keywords\nSocial media, Twitter, analytics, digital social science, data visualisation, methods\nThe ever-expanding usage of social media throughout\neveryday life offers a critical data resource to social\nscientists. Though this is increasingly recognised, such\ndata brings with it new methodological challenges in\nterms of finding ways to analyse what it tells us about\nsocial life. Social media provides a form of user-gener-\nated data which may be unsolicited and unscripted, and\nwhich is often expressed multi-modally (i.e. through\ncombinations of text, hyperlinks, images, videos,\nmusic, etc.). Hence, it is important to consider the chal-\nlenges that this data holds for researchers in terms of\nrendering them amenable to analysis, and in identifying\nthe sort of research questions that such data might\nappropriately address. As Raghavan (2014) notes,\nresearchers no longer lack computational tools or the-\nories to help make sense of social media data, yet there\nremains a paucity of methodologies to make transpar-\nent the move from tools to explanations.\nWe address this challenge by demonstrating the\nvalue of a `visual analytic' approach to capturing and\nexploring the qualitative and subjective facets of\nTwitter data as a socio-technical research `assemblage'\nuncovered by research are acknowledged as essentially\nintertwined with the technical aspects of data collection\nand visualisation (amongst other aspects of the research\nprocess more generally). We choose Twitter as a foun-\ndation due to its role as `a ``model organism'' of big\nsufficiently simple in its broadcast mechanics such\nthat its exploration `is conducive to progress in basic\nquestions underlying the entire field' (Tufekci, 2014:\ncontent, tweets are accompanied by various metadata,\nincluding: timestamps; tweeters' usernames and\nuserIDs; `follower' and `following' counts; geo-location\ncoordinates; hashtags; @mentions (i.e. communica-\ntions between users); retweets (where users re-post\nothers' tweets) and hyperlinks. Coupling the lexical\n1University of Bath, UK\n2Brunel University, UK\nCorresponding author:\nPhillip Brooker, University of Bath, 3rd Floor, 10 West, University of Bath,\nClaverton Down, BA2 7AY, UK.\nEmail: p.d.brooker@bath.ac.uk\nBig Data & Society\nbds.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License (http://\nwww.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-\nat-sage).\ncontent of tweets with these metadata provides a rich\ncontext in which to base an analysis.\nThe paper is organised as follows. We first discuss\nexisting methodological literature in social media\nanalytics, highlighting the shortage of methodological\nstrategies for handling social media data. We go on to\nposit a (visual analytic) framework that seeks to\naddress this, grounded in an abductive ontological per-\nspective. We outline the general ideas behind two\nmodes of data collection and two analytic approaches,\nexploring their four combinatory permutations. We\ndemonstrate the four analytic lenses with empirical\nexamples: the role of media in talk around the UK\n2011 e coli food scare, user experiences of adrenaline\nauto-injectors (`epipens'), bovine tuberculosis (bTB)\nand UK badger activism, and symptom-reporting\namongst cystic fibrosis sufferers.\nExisting social science approaches to\nTwitter\nMany studies of Twitter focus on theoretical/concep-\ntual issues (e.g., boyd & Crawford, 2012; Kitchin,\nfacet of this triumvirate, is only just beginning to\nreceive the same attention.\nMany important methodological contributions\n(e.g., Bru\ndological concerns long standing in the social sciences\nsuch as sampling and demographics, and the representa-\ntiveness and quality of social media data. For instance,\nMahrt and Scharkow (2013) contend that `it is currently\nimpossible to collect a sample in a way that adheres to\nthe conventions of sample quality established in the\nTo view the web as data set for social and cultural\nresearch is to be confronted with a variety of issues\nabout messy data. . . Here the general reputation pro-\nblem about quality online is transformed, initially,\ninto the question of how to clean up the data, since\nthere is a lack of uniformity in how users fill in\nforms, fields, boxes and other text entry spaces.\nHere, Mahrt and Scharkow and Rogers question the\ncapacity of social media data to capitulate to an inter-\nrogation via methods we already have at our disposal.\nThis application of existing methodological thinking to\nsocial media analytics gives us pause \u00ad to what extent\nare these concepts relevant to social media analytics,\ngiven that its difference from more traditional forms\nof enquiry is often considered a defining characteristic?\nWe build on previous work (Anderson, 2011; boyd,\nexplore methodologies which are more attuned to the\nnewness inherent in social media analytics.\nAs such, we align our work less with authors dealing\nwith the trends and patterns available in aggregate\noverviews of large-scale data, and more with Marshall\n(2012), who provocatively destabilises the processes\nthrough which tweets come to be construed as data,\nadvocating a more qualitative-flavoured approach\nbased on closer readings of tweets. In this regard, our\napproach downplays the relevancy of concepts such as\ndata validity and sampling as yardsticks for measuring\nthe `goodness' of social media data. Instead, we explore\nwhat is possible with the `noisy' and `unclean' data we\nhave to hand, providing an alternative means to `drill\ndown' into the substantive content of tweets.\nThe proposed methodological toolkit is supportive\nof abductive modes of enquiry (Blaikie, 2000; Locke,\n2010), which work through a research process induc-\ntively, towards increasingly plausible explanations of\nphenomena. Ontologically, abductive reasoning oper-\nates with an understanding of research phenomena as\nco-constructed products of social interactions, includ-\ning those which contribute towards the undertaking of\nresearch by researchers. Such phenomena do not exist\noutside of the `assemblage' of social, technical, material\nand other factors which converge to generate, shape\nand make them available to social research. The idea\nof assemblages is implicated in the work of boyd (2010),\nthe interactions of a digital public \u00ad a `community' of\npeople brought together in and by a digital domain \u00ad\nare shaped by the affordances of the platforms they use\n(i.e. a social media service). This shaping works both\nways: as a crude example, Twitter's conventions help\nstructure how people communicate and what they use\nthe platform to say, and people's tweeting practices\nserve to reorganise the possibilities of Twitter (e.g.,\nthe oft-remarked-upon `folk' origins of the hashtag).\nIn practice, investigating assemblages necessitates the\nincorporation of a wider, more inter-connected array\nof elements, including: users, platforms, communicative\npractices, cultural events and issues (about which\npeople communicate), the algorithms that structure\ntheir interactions, the research process itself (as the\nmechanism by which a researcher develops insights),\nand so on.\nIf our subjects are the messy products of such inter-\nweaving factors then, as Hughes and Sharrock (1997)\nnote, epistemologically we must (unapologetically) con-\ncede that our descriptions of the reality at hand\n2 Big Data & Society\ninevitably describe only the assemblage we have built to\ninvoke that reality's construction. Accordingly, we\ndirect our methodological toolkit towards supporting\nthe task of making transparent how these assembled\nfactors produce research findings. Under this schema,\nwe begin to see and interrogate the processes through\nwhich users, algorithms, offline `real-world' occurrences\nand other social factors collectively emerge as tools of\npublic knowledge and discourse (Anderson, 2011). To\nthis end, we advance a `visual analytic' approach to\nfacilitate the unpicking of Twitter and the investigative\nprocess itself as a socio-technical assemblage (Langlois,\nA visual analytic framework for\nunderstanding Twitter data\nVisual analytics (Thomas and Cook, 2005) integrates\ntechniques from two fields \u00ad information visualisation\n(Card et al., 1999) and computational modelling \u00ad and\nhas already made notable contributions to social media\nanalytics (Diakopoulos et al., 2010; Hassan et al.,\n2014). The key principle of visual analytics is the use\nof interactive visualisation as part of a process of ana-\nlytical reasoning (rather than as static outputs display-\ning the outcomes of an analysis) (Thomas and Cook,\n2005). Central to the approach is that visualisations do\nnot replace the skills of the researcher but rather\namplify their inherent capabilities by capitalising on\nthe high-bandwidth processing of visual perception\n(Card et al., 1999). The analytic process begins with\noverviews (high-level abstractions) that guide research-\ners towards potentially interesting aspects of the data.\nThe researcher can then either transform the view (e.g.,\nby zooming or filtering) or create new visualisations\nthat enable them to `drill down' and engage in finer\nqualitative analysis of their data.\nThis visual analytic approach to social media data is\na natural extension of abductive interpretivist reason-\ning, in that it promotes a thoroughly exploratory orien-\ntation to data and analysis. Reflecting the ontological\nand epistemological ideas outlined above, as new\ninsights are derived they are fed back into the assem-\nblage and the research process becomes an endlessly\nexploratory endeavour \u00ad such exploratory work is not\nmerely prior to `a proper analysis'; it is the analysis.\nWith data collection and analysis as one seamless pro-\ncess, exploration of an initial dataset may lead to new\nquestions which may in turn feed back into new rounds\nof data collection, with findings emerging throughout\nthe ongoing iterations. Hence, visual analytics facili-\ntates a mind-set wherein researchers can probe their\nown assumptions and perspectives to help capture phe-\nnomena as they unfold and encourages questioning\naround the relevance of long-held social science\nconcepts to evaluate their applicability to new digital\ndata (as we have attempted to do above).\nThe framework and examples we present here apply\nvisual analytics to social research questions. We have\nundertaken our empirical work using the Chorus data\ncollection and visualisation suite,3 which provides a set\nof affordances to researchers via two types of visualisa-\ntion: the timeline and cluster map views outlined in the\nexamples below. Our usage of Chorus' visualisations is\nnot undertaken with the aim of concretising a singular\nreading of the data \u00ad we reiterate that the visualisations\ndo not demonstrate singular readings, and to read them\nas if they were is to downplay the analytic impact of the\nvarious processes through which they come to be.\nIn this regard, the analytic strategies we outline below\ndemonstrate ways of using visualisations to navigate\naround social media data and work towards qualitative\ninsights grounded in original tweet content.\nCommensurate with our adopted abductive ontol-\nogy and the notion of the research process as an assem-\nblage, we acknowledge that our methodological talk is\ninextricably bound to the affordances Chorus provides.\nThis need not disrupt the sense in which the present\npaper can speak to the methodological exigencies of\nsocial media analytics research, since we are not posit-\ning a set of abstract techniques for handling social\nmedia data. No such taxonomy of techniques is possi-\nble, and every new research project will demand differ-\nent techniques specifically tailored to the data\nassemblage at hand. We instead aim to demonstrate\nand facilitate a methodological mind-set of `thinking\nin assemblages', which will help researchers generate\ntechniques of their own to suit their work.\n`Thinking in assemblages' (via a visual analytic\napproach) offers researchers a way to be reflexively\nattuned to their phenomena and to the role of research\nas a subjective enterprise. This is vital for qualitative\nresearch in that it ensures researchers are better able to\naccount for their phenomena by demonstrating the pro-\ncesses through which findings are derived. This endea-\nvour is tied to the application of the visual analytic\nprinciple of folding visualisations into the research pro-\ncess (as opposed to treating them as results), and in the\nunderstanding of research as iterative. It is on these two\npoints where we hope to extend our approach to\nresearch conducted with other tools (and also to social\nmedia platforms other than Twitter).With this aim in\nmind, we posit a framework which outlines a set of\nchoices for researchers to make in terms of how to collect\nand analyse their data. This framework codifies several\ncomplementary research approaches to Twitter\nresearch; rather than pitch these as `novel', our aim is\nto give methodological shape to social media analytics\nby situating various existing approaches in relation to\none another. As part of this framework, we outline two\nBrooker et al. 3\ndata collection strategies (semantically driven and user\ndriven) and two analytic modes (temporal analysis and\ncorpus analysis), as different ways of organising Twitter\ndata. We provide empirical examples for the four result-\ning permutations, indicating the sorts of research ques-\ntions they might be used to address and the kinds of\ninsights they might uncover.\nData collection\nTwitter's APIs (Application Programming Interfaces;\nthe technologies through which users access Twitter\ndata) allow users to retrieve a range of data entities\nand associated values. We outline two approaches to\ncollecting this data. First, the familiar query keyword\nsearch, which utilises linguistic entities (i.e. words,\nhashtags, URLs) as criteria for compiling datasets.\nSecond, we discuss data consisting of extended time-\nlines of groups of users \u00ad a user-following strategy.4\nCapturing semantically driven data (query\nkeyword searches)\nThis type of data capture takes the semantic content of\nusers' tweets as its starting point. The research process\nmight therefore begin by identifying keywords that are\nlikely to typify tweets around a topic of interest, using\nlogical operators to define the scope. The resulting data\nhas an inherent semantic orientation around a topic,\nwhilst retaining a degree of flexibility as to how exclu-\nsive the query is (i.e. it can include a selection of alter-\nnative terms to account for variations in the ways\npeople tweet around the topic).\nCapturing user-driven data (user following)\nUser-driven data is organised around the Twitter activ-\nity of selected groups of users. This involves identifying\nusers whose tweets are pertinent to a research question,\npulling their Twitter timelines and sifting for research-\nrelevant themes. This approach is useful for projects\nwhere a keyword query is not easily defined (i.e.\nwhere tweeters use implicit, informal, colloquial or gen-\neral references to the area of interest) or where there is\nvalue in understanding the role of a particular issue\nwithin a broader set of preoccupations. Whilst allowing\nresearchers to find out what a group of people are tweet-\ning about without narrowing the scope with keywords,\nthis strategy nonetheless provides an analytic challenge\nin terms of the diversity of topics captured.\nData analysis\nComplementary to these data collection strategies, we\noutline two analytic orientations to Twitter data:\ntemporal and corpus analysis. There has been a recent\ntrend in the application of visual analytics towards\nrepresenting how topical structure evolves over time \u00ad\nthere is value in decomposing temporal and semantic\nstructures into distinct but coordinated views of the\nsame data. On the conceptual level a time-dependent\nevent-based view of data and a non-time-dependent\ntopic-based view of data can be conceived as two\nsides of the same coin that is topic evolution. We do\nthis because there are interesting social science research\nquestions about topics which may not require an\ninsight into how a topic has evolved \u00ad see for instance\nour examples on user experiences of epi-pen devices and\nsymptom reporting by cystic fibrosis sufferers. This, we\nargue, allows researchers to more straightforwardly see\nthe possibilities of each analytic type before considering\nhow best to combine them. Moreover, our distinguish-\ning between these two approaches does not preclude\nresearchers from exploring topic evolution in the\nmove from one methodological strategy to another \u00ad\nin fact, we encourage this as part of the iterative nature\nof visual analytics as a social science methodology.\nGiven our concern to display how software tools\nbecome embedded within the assemblages we con-\nstruct to render social phenomena visible, it is\nworth noting several technical differences between\nChorus and other (aforementioned) tools and\napproaches. First, in contrast to more general text\nanalytic tools such as Textflow (Cui et al., 2011),\nChorus is specifically designed to be sensitive to the\ntechnical and contextual exigencies of Twitter, afford-\ning a deeper exploration of Twitter's role in the\nassemblages we build around it. Second, Chorus\nuses Twitter's Search API rather than its Streaming\nAPI (as is the case with TwitInfo (Marcus et al.,\n2011)) allowing for more comprehensive recall of\ndata around specific topics. Third, the exploration\nof tweets and user timelines with Chorus' particular\nspatial-semantic (cluster) views facilitate unique ana-\nlytic possibilities not provided by other Twitter ana-\nlytic tools. These features (and more) situate Chorus\nas a useful alternative to existing tools, the possibili-\nties of which are demonstrated in the example cases\nbelow.\nTemporal analysis (event based)\nTwitter data can be viewed as a temporally unfolding\nnarrative. Researchers may draw insights from such\nthings as: variation in tweet volume around loci, evol-\nving positive or negative sentiment over the course of a\nconversation, shifts in the vocabulary characterising a\ndiscussion, changes in the likelihood of URLs being\n4 Big Data & Society\nreferenced within tweets, and so on. In this way, a\nchronological viewing lends itself to the exploration\nof `events' as they unfold within Twitter.\nCorpus analysis (topic based)\nBy contrast, a corpus analysis relies on a conception\nof whole datasets as an `information space' in which\nsemantic features (words, hashtags, etc.) intersect in\npotentially interesting ways, irrespective of the time\nthey are expressed. Researchers may draw\ninsights from the exploration of topical structures\nemerging from the entire body of data, investigating\nthe ways in which keywords are used together to\nform broader themes. In this way, a corpus analysis\nviewing of the Twitter data lends itself to the explora-\ntion of `topics'.\nFour empirical examples\nBased on the four quadrants of our framework\n(Table 1) we demonstrate how each can be used to\naddress distinct types of social research questions.\nThese examples should not be considered comprehen-\nsive treatments of the data \u00ad indeed, a comprehensive\ntreatment is impossible if the social media analytics\nresearch process is understood as ever-exploratory\nand essentially iterative. Rather, our aim is to point\nthe way towards a fuller analysis by demonstrating\nhow to collect data that may speak to a particular\nresearch question and techniques for analytically hand-\nling that data with Chorus' visual models.\nAcross each of our examples, we outline our data\ncollection strategy, the keywords used or the user time-\nlines selected. Chorus' queries tend towards inclusivity\n(e.g. a query keyword of `epipen' would also capture\ntweets containing the terms `epipens' and `#epipen').\nQueries return all tweets with unique TweetIDs\n(including retweets), removing duplicate entries where\nthey satisfy more than one query criteria. For the exam-\nples below, retweets were not removed.\nWe also outline our usage of Chorus' visualisations\nto find our way around the data, and it is helpful here\nto briefly describe how Chorus builds those visualisa-\ntions since this is a formative factor in the data assem-\nblages they help create. Chorus first builds a `word'\nindex containing counts of all significant corpus\nwords within each tweet in the dataset. Less significant\nwords such as stop words (`a', `the', `and', and so on),\nparticularly rare or common terms are pruned from the\nindex prior to analysis. By default, words that occur in\nmore than 50% of all tweets or fewer than 0.1% or two\ntweets (whichever is greater) are removed. This index-\ning results in a matrix of word-tweet counts from which\nmeasures of both tweet and term similarity are com-\nputed (using cosine or the normalised dot product\nmetric). Chorus also derives a word-interval matrix,\nan aggregated version of the term-tweet matrix which\ncontains the standardised (0\u00ad1) frequencies for each\nterm in each specified time interval (seconds, minutes,\netc.). This is used to compute various temporal statistics\ndescribed below.\nThe timeline graphs (Figures 1 and 5) display var-\nious statistics including: tweet volume, ratio of tweets\ncontaining a URL, positive sentiment, negative senti-\nment, novelty of terms and homogeneity of terms (see\nbelow for further detail). The cluster map visualisations\n(Figures 2, 3, 4 and 6) use the word index to compute a\nmap in which the distance between words is inversely\nproportional to their contextual similarity, i.e. words\nthat tend to commonly occur together in tweets are\npositioned closer together. In this way, groups of\nrelated words cohere into `clusters', providing a the-\nmatic overview and a basis for navigation around the\ndataset.\nTemporal analysis of semantically driven data\nA temporal (or event-based) view of semantically driven\nTwitter data draws on the chronology available both in\nabsolute terms of the time of posting (CreatedAt field)\nand as a result of relative tweet order (TweetID field).\nTable 1. Combinations of different strategies for data collection and analysis.\nData analysis\nTemporal analysis (event based) Corpus analysis (topic based)\nData capture Semantically driven\n(query keyword)\nHow does a narrative about a semantic\nentity (i.e. word, hashtags, etc.)\nunfold over time?\nHow is talk around a semantic entity\norganised topically (and sub-\ntopically)?\nUser driven (User\nfollowing)\nHow do users' language and tweeting\npractices change (or not) over time?\nWhat topics are a specific group of\nusers tweeting about (and how are\nthey doing it)?\nBrooker et al. 5\nThe semantically driven nature of the data centres the\nanalysis on specified unifying aspects of conversation \u00ad\na hashtag, mentions to a particular user account, etc. \u00ad\nand associated attributes such as tweet volume, the\nratio of tweets to tweets with links, sentiment analytics,\nsemantic homogeneity or novelty, and so on.5 The\nfocus here is on how information within various data\nfields fluctuates or maintains across time, providing\ninsight into how people use Twitter across a Twitter-\nreported event.\nExample: The role of media in talk around the UK 2011 e coli\nfood scare. We explored public perceptions of E. coli\nduring the 2011 EHEC/E. coli bacteria outbreak in\nEurope. Our search terms were `e coli' and related\nterms (`e. coli', `#ecoli'), capturing 19,998 tweets span-\nning an approximately three-month period (mid-May\nto mid-August 2011). Each interval in Figure 1 repre-\nsents a day of tweets. Our interest was in exploring the\ndifferent periods constituting the Twitter e coli scare\n`event', characterised by different styles of tweeting\nwithin those periods (e.g. `fact-sharing', `rumour pro-\npagation', `raising awareness'). This time-dependent\nFigure 1. Timeline view of `e coli' data.\nFigure 3. Origin nodes of the `devices and user-experience'\nbranch (labelled a). Note the terms `legbuddy!waistpal' at the\nroot, and `carrier!sufferers' (indicating the relevant user-group\n(labelled b)).\nFigure 2. `Devices and user-experience' branch (origin nodes\nlabelled a, physical device user opinions sub-branch labelled b).\n6 Big Data & Society\nview lends itself to research questions concerning\nchange in opinions and meanings: it is event based, in\nthat the characteristic narratives of an `event' are\nrevealed through an unfolding chronological order of\nkey moments.\nWe identify several stages to the conversation.6 First,\nprecursor to the main event; it contains few mentions\nof `e coli': unrelated jokes, small-scale local news stories\nand so on. This incoherence is visible in the high level of\nnovelty \u00ad the red measure \u00ad which indicates that this\nperiod contains few terms persisting in an ongoing con-\nversation.7 A second phase is identifiable at 24 May\n2011, with a marked decrease in the semantic novelty\nof tweets. This is the beginning of a six-day period,\ninformation propagation and the sharing of news head-\nlines and URLs to news websites. At this point,\nretweets from news media stories enter into the conver-\nsation \u00ad links to articles citing the origin of the out-\nbreak in Germany form a significant portion of the\ntotal volume of tweets, with between 76 and 90% of\ntweets featuring a URL. The next period, from 30 May\nof tweets, whilst the ratio of tweets to tweets with URLs\ndrops considerably and we find people using a different\nset of terms to talk about e coli (exemplified by the\nrising novelty metric and the falling homogeneity\nmetric). Tweets here are emotive in content rather\nthan factual, and it is at this point that e coli begins\nto become a concern for a significantly larger Twitter\npopulation who express their anxieties, ask for advice,\nshow sympathy for sufferers and fatalities, and so on.\nWith this analysis, we have begun to characterise a\nTwitter event by breaking it down into time-dependent\nperiods with distinct characteristics. Relying on the\nchronology of the data, we can situate tweets within\nan unfolding conversation which tells us dually about\nthe events at hand as well as variations in tweeting\npractices.\nCorpus analysis of semantically driven data\nA corpus (or topic-based) view of semantically driven\nTwitter data aims to uncover the semantic makeup of\na whole dataset. This is achieved in Chorus using the\nterm co-occurrence visualisation model (Cluster\nExplorer). This mode of analysis affords the discovery\nof sub-topics and themes around an original topic set\nby keyword criteria.\nIn order to explore these topical clusters further, we\nmake use of `cluster maps' (Figures 2, 3, 4 and 6), which\nplace terms occurring together frequently within tweets\nFigure 5. Timeline view of 15 key badger activists' timelines.\nFigure 4. Sub-branch showing user opinions on physical\naspects of epipens (labelled b in Figure 2).\nBrooker et al. 7\ncloser together in space. Using this distance-similarity\nmetaphor causes topics to emerge as structures (clus-\nters, hubs, branches, etc.) within the information space\nof the map. Whereas a temporal view is event based\n(due to the choice to view data in discrete intervals) a\ncorpus view is topic based, allowing researchers to delve\ndeeper into the subjective content of tweets.\nExample: User experiences of epinephrine auto-injectors\n(`epipens'). Our example for this analytic mode is\naround the topic of epipens (query keyword:\n`epipen'): a popular brand of hand-held medical\ndevice for administering epinephrine in the event of\nan allergic reaction. Although the data collection\nmethod is the same (keyword searching) this dataset\nis most appropriately treated in a different way to the\ne coli example presented above. In this instance we were\nnot aware, a priori, of any important chronological\naspects of interest \u00ad rather, we wanted to explore every-\nday epipen user-experience issues. It is a relatively low-\nconvergence on a single sub-topic.\nZooming in on one section of the term-level map (see\nFigure 2) reveals a branch oriented around discussion\nof user experiences of epipen devices, diverging from a\nlarger central node (top left of Figure 2).\nInspection of these branches indicates a discussion\nabout accessories for carrying epipens. Tracing the dis-\ncussion back to the `root term' at which the topic\ndiverges from other threads, we see the terms `leg-\nbuddy' and `waistpal' (referring to products for\nmaking carrying an epipen convenient and subtle) are\nkey to the formulation of a distinct `devices and user-\nexperience' branch (Figure 3).\nFigure 4 shows tweeters associating terms pertaining\nto physical aspects of epipens with the term `cases'.\nHere we see that the user experience of epipen cases is\nlargely negative and relates to their size and visibility\n(and accordingly, the sizes of devices), e.g.:\nNot fucking pleased with this new epipen, its\nMASSIVE, needs an even bigger case. . .how am I\nmeant to sit down???\nI am allergic to nuts carry an epipen AT ALL TIMES\nbut am a certified swim coach and wear a one piece. . .\nmy life sucks8\nThis mode of analysis allowed us to explore a broad\ntopic of interest \u00ad epipens \u00ad without relying on simple\nterm frequency to point us in any particular direction.\nNavigating around the cluster map in this way, analysts\ncan sift their data for `needles in haystacks' \u00ad here, this\nprovided insight into user experiences with epipens\nunlikely to be uncovered with more formal search\nterms (i.e. `weight' and `size').\nTemporal analysis of user-driven data\nA temporal (or event-based) view of user-driven data\ncaptures a diverse array of interests in the selected\nuser group, with analyses relying on the chronology\nof the data to elicit a narrative of how various features\n\u00ad e.g. term frequencies, usage of URL links, sentiment,\nnovelty and homogeneity of conversation, etc. \u00ad fluc-\ntuate over time. The people whose timelines we capture\nmay display interests in areas other than those we\nselected to be users to exemplify; these too become\navailable to us. The data thus represents a proliferation\nof themes within which the topic of interest is\nembedded. The analytic focus is primarily in the peri-\nods where the user group converges on or diverges from\nsome issue or event. In this way, a temporal view of\nuser-driven data pieces together a story describing a set\nof evolving issues expressed by a user group and digs\ninto that data beyond linguistically oriented accounts\nof frequencies of key terms.\nExample: bTB and badger activism in the UK. The example\nwe present here concerns a period of activist activity\naround UK proposals to cull badgers in countryside\nareas to prevent the spread of bTB. Our search strategy\ncaptured the Twitter timelines of 15 most frequent users\nof a selection of hashtags9 through which badger cul-\nling activism was expressed, yielding 46,494 tweets from\nthe entire Twitter output of these users over this period,\nwhether tweets pertained to badger culling or other-\nwise. Our objective was to explore the practices through\nwhich activists mobilise Twitter in their activism.\nFigure 6. Clustering around the term `organ', taken from\nDataset 1.\n8 Big Data & Society\nThe time period captured includes a key moment:\nbadger culling programme. The most voluminous inter-\nitself, during which the novelty metric is at its lowest \u00ad\nfor the few days leading up to the Defra press release\ntweets became highly convergent around the cull\nannouncement. Furthermore, not every tweet contains\noriginal content \u00ad often, the activists tweet ideas and\nlinks multiple times. This is reflected in the significant\nwhich saw a convergence on certain terms to propagate\ntheir message \u00ad in addition to obvious terms like\n`badger' and `cull', terms like `make', `save' and\n`iTunes' were used to engage non-activists in the\ndebate (i.e. with encouragement to `save' badgers\nthrough signing an e-petition, and to purchase Brian\nMay's new anti-cull charity single via `iTunes' in an\nattempt to `make' it chart).\nDespite their concern with supporting badger acti-\nvism, the 15 selected users do tweet about different\ntopics. Visually, these are seen as the red novelty\nmetric rises in the timeline, as well as `crossovers'\nwhere the typically overriding negative (blue) senti-\nment dips and the typically lower positive (green)\nsentiment rises. In periods of spiking novelty, we\nfind tweeters turning to new topics, e.g. reports of\noccur in conjunction with novelty spikes, these peri-\nods denote a change in the net positivity and nega-\ntivity of words used to express newly introduced\nwhen activists celebrate the birthday of Freddie\nMercury \u00ad with Brian May as the celebrity figurehead\nof the movement, his ex-Queen bandmate Freddie\nMercury's birthday is celebrated as a way of showing\nsupport for May.\nOverall, our 15 activists express different interests\nthat are not wholly disconnected from the badger\nculling debate, yet neither do they constitute a part\nof it; we begin to get a sense of their broader inter-\nests as `activists' within multiple environmental issues.\nIt is clear that badger culling activism dominates their\ntalk, but using user-driven data we can do more to\nunderstand the broader personas of those people\nwhose practices constitute this conversation.\nCorpus analysis of user-driven data\nA corpus approach to user-driven data collection side-\nsteps any lack of a priori knowledge as to how\npeople tweet about a given topic on Twitter. There\nare research tasks for which effective query keyword\ncriteria cannot be ascertained beforehand. Hence,\nthe purpose of adopting this mode of analysis is to\nexplore the overall topical makeup of the dataset to\nfind out what kinds of things a user group tweet\nabout, using a cluster map showing connected terms\nof interest.\nExample: Symptom reporting of cystic fibrosis sufferers (and\nfamilies of sufferers). Here, we used Chorus' data collec-\ntion tool to capture user-driven data from a selection of\nfollowers of a cystic fibrosis (CF) news account.\nThe number of followers at the time of collection\ntweets over an approximately six-month period\nanalysis more tractable, we filtered the dataset by\nselecting tweets from the lower end of the tweets-per-\nhere focuses on the first 1797 users, who tweet between\nload associated with processing the visualisations. Our\ninterest here was in locating and understanding suf-\nferers' reports of the everyday experiences of CF, to\nidentify issues of importance which may go unreported\nin formal medical interactions.\nThis approach allowed us to discover topics of inter-\nest to our user group of candidate CF sufferers that fell\noutside of our expectations. Exploring the cluster map\nrevealed a varied array of topics, reflecting the everyday\nnature of the users' conversations captured. However,\nnoticeable clustering occurred around a key topic per-\ntaining to the term `organ' and the connected terms\n`double', `lung' and `transplant'.\nThis clustering conveys a picture of transplant talk\nas having a significant relation to lungs \u00ad this much\nmight be expected amongst candidate CF sufferers.\nHaving identified this cluster we were then able to\ndrill further down and found a distinct set of tweeting\npractices around the topic. Here, tweeters routinely\ninvolved themselves in personal communications\nexpressing and receiving concern for CF sufferers\nknown to be awaiting or undergoing double lung trans-\nplant surgery and recovery, e.g.:\n@ConcernedTweeter thankyou :) Yeah I'm needing a\ntransplant badly now, still fighting everyday though!\n#organdonation #CysticFibrosis\nRT: will every cfer please keep @CFSufferer in ur\nprayers, she's in theatre right now getting a double\nlung transplant!\n@CFSufferer I hope you are doing unreal since the\ntransplant! Was so delighted to hear the news\n#wooohoo\nBrooker et al. 9\nThese same tweeters also utilised transplant surgery\nepisodes to topicalise important related issues\n(such as post-operation aftercare and the organ donor\nregister), e.g.:\n@CFCharity it's my sis's 30th bday today. She has CF\n& had a double lung transplant 1 yr ago which saved\nher \u00ad need more awareness!!!\nRT: @CFSufferer Its transplant week next week. I'm\nalive because of an Organ Donor. Please sign the organ\ndonor register! #RT\nAside from their interpersonal communication, these\ntweeters make active use of the publicly visible nature\nof Twitter to help encourage others to recognise the\nemotive nature of transplants for CF sufferers and to\ncampaign for positive action (i.e. registering as an\norgan donor). Our topic-based approach unveiled a\ncluster of key issues which would be difficult to locate\nwith keywords, given the term `transplant' is likely used\nmore widely on Twitter than we would find relevant to\ncandidate CF sufferers specifically. We were then able\nto investigate what this topic consists of for the selected\nuser group and explore how the topic is structured and\nachieved through those users' tweeting practices.\nSelecting a strategy\nGiven the different characteristics of the two modes of\ndata capture outlined above, it is useful to review the\nreasons for choosing one over the other. Semantically\ndriven data collection is suited to conversations where\nsome unifying (set of) term(s) is known already and\nreflects people's usage of terms (rather than artificially\ncreating a topic by filtering data with keywords). Given\nthe focussed nature of this data, it is well placed to\nprovide insight into broader trends \u00ad e.g. in predicting\nelection results (Tumasjan et al., 2010). In contrast,\nuser-driven data is more sensitive to the variety of dif-\nferent topics that specified groups of users tweet about.\nUser-driven data is less focussed than its semantically\ndriven counterpart, but enables researchers to induc-\ntively derive relevant keywords and topics. The decision\nabout which strategy to adopt should be a data-driven\nprocess dependent on the research question. This\nrequires experimentation with different data collection\nand analytic methods \u00ad having had a `hands-on'\napproach to collecting data, researchers will find them-\nselves equipped with better understandings of how to\ntreat that data analytically.\nSimilarly, analytic work should start with a period of\nexploration to ascertain whether the data lend them-\nselves to an event- or topic-based analysis. Initial visua-\nlisations and summaries of the data are revealing \u00ad are\nthere distinct events, and what interesting things might\nbe said about them? Or does the dataset show a corpus\nof topics for which chronological ordering does not\nproduce insightful findings?\nThis process of exploration may keep iterating\nacross any or all of the four cells outlined in Table 1,\nthe end result being that researchers will find themselves\nwith a set of research questions, a dataset which reason-\nably contains answers to those questions, and an ana-\nlytic approach for drawing out those answers.\nThis iterative process is the essence of visual analytics.\nWe have demonstrated the value in applying visual\nanalytics to social media research projects by positing\nfour empirical examples as initial steps upon which\ndeeper iterations might be built. An example of how\nwe envisage this working: our corpus analytic user-\ndriven study of cystic fibrosis sufferer experiences\nuncovered a keyword \u00ad `pwcf', or `Person/People\nWith Cystic Fibrosis' \u00ad which we might feasibly go on\nto use as the basis for a query keyword search to see\nhow topics around the term `pwcf' change over time\n(i.e. a temporal view of semantically driven data).\nUnfortunately, for present purposes we have had to\nrefrain from the iterative work of `switching cells' in\nour examples, instead posing one example per cell so\nas to clearly demarcate each approach. Nonetheless, we\nhope readers will appreciate the value in iterating across\nthe space of the framework.\nConclusion\nWe present a set of complementary methodologies for\nundertaking analyses of Twitter data as a socio-techni-\ncal assemblage, with the emphasis on navigating\naround and unpicking the factors that construct and\nconstrain the data. This notion of the research process\nas engaged in the production of assemblages informs\nthis paper from top to bottom. To achieve this, we have\ntaken a visual analytic approach (Thomas and Cook,\n2005) wherein visualisations are utilised as tools for\nforming and pursuing hypotheses rather than results\nin themselves. Given our abductive grounding, this\nexploratory focus is highly appropriate, in that it is\nconducive to developing and defending interpretive\naccounts of social media in data-led ways.\nInasmuch as methods and methodologies are only as\nvaluable as the empirical results they may yield, we can\nexpect different social media projects to require new\nmethodologies to support different modes of data col-\nlection and analysis. Given that our approach to build-\ning the visual analytic methodology is partly shaped by\nChorus \u00ad a text-based Twitter analytics suite \u00ad as an\nelement of our own research assemblage, the scope of\nour work is bound by the specific affordances Chorus\nprovides. Thus, it is misleading for us to profess to have\ninsight into how visual analytics might apply to projects\n10 Big Data & Society\nChorus cannot currently support (i.e. on non-\n`microblog' platforms or with non-textual facets of\nTwitter data). However, we hope to have demonstrated\nthat the general idea of using visualisations as tools for\nexploring data assemblages stands as a provocative\nalternative way for researchers to use existing tools to\nwork with their data differently. We have focussed on\nthe utility of visual analytics for text-based Twitter data\nin the hope that others may take up the reins and\nmodify those principles to fit other platforms and\ndata. We anticipate that our delineations of semanti-\ncally and user-driven data and temporal and corpus\nanalyses might be useful in this regard, as a demonstra-\ntion of a framework for helping researchers think about\nand organise their research, and to create a foundation\nfor further thinking around possible applications of\nvisual analytics throughout digital social science\ngenerally.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with\nrespect to the research, authorship, and/or publication of this\narticle.\nFunding\nThe author(s) received no financial support for the research,\nauthorship, and/or publication of this article.\nNotes\n1. Current estimates indicate that Twitter's output exceeds\n(http://en.wikipedia.org/wiki/Twitter, accessed on 06/05/\n2. Tufekci (2014) does express reservations about how far a\nsingular focus on Twitter might take the field, in terms of\nsuch things as unrepresentativeness and skewing the direc-\ntion of research. Nonetheless, Tufekci acknowledges the\nvalue in a paradigm which encourages a community\nresearch effort around shared datasets, tools and\nproblems.\n3. www.chorusanalytics.co.uk.\n4. Specifically, Chorus' data collection routines draw on the\nfollowing methods within Twitter's REST API. Query key-\nword searches use GET/search/tweets. User timeline retrie-\nvals use GET/statuses/user_timeline to provide tweets,\nwith GET/friends/list and GET/followers/list methods to\nbuild lists of users to follow (though Chorus also allows\nfor users to provide their own lists of tweeters to follow).\n5. It is worth noting here that although they are associated,\nthe metrics in these pairs \u00ad positive and negative sentiment,\nand novelty and homogeneity \u00ad do not necessarily nega-\ntively correlate as might be expected. Positive and negative\nsentiment utilise the SentiStrength algorithm (Thelwall\net al., 2010), ascribing sentiment values to terms within\ntweets, and tweets may feasibly contain strong positive\nand negative terms simultaneously (e.g., `I love tea but\nhate coffee'). Similarly, novelty and homogeneity are not\nnecessarily inversely related \u00ad novelty detects shifts in word\nusage between an interval and intervals immediately pre-\nceding it, whereas homogeneity reflects the extent to which\ntweets within an interval tend to use the same terms. In this\nway, an interval may show both a high novelty and homo-\ngeneity value, i.e. tweeters may be using a relatively small\nvocabulary within an interval (high homogeneity), though\ntheir talk in that interval may be markedly different than\nthe talk in previous intervals (high novelty).\n6. For brevity, our analysis terminates at interval 31.\n7. We recognise that this may be an artefact of the data, in\nthat a relatively low volume of tweets amplifies differences\nbetween intervals in terms of novelty/homogeneity \u00ad we\nmake the point for demonstrative purposes.\n8. Usernames have been anonymised and tweet content para-\nphrased to protect the anonymity of tweeters.\n9. The hashtags and the usernames derived from them are\nnot reproduced here since this could compromise these\nusers' anonymity.\nReferences\nAnderson CW (2011) Deliberative, agonistic, and algorithmic\naudiences: Journalism's vision of its public in an age of\naudience. International Journal of Communication 5:\nBlaikie N (2000) Designing Social Research: The Logic of\nAnticipation. Cambridge: Polity Press.\nboyd d (2010) Social network sites as networked publics:\nAffordances, dynamics, and implications.\nIn: Pappachrissi Z (ed.) A Networked Self: Identity,\nCommunity, and Culture on Social Network Sites.\nboyd d and Crawford K (2012) Critical questions for big data.\nboyd d, Golder S and Lotan G (2010) Tweet, tweet, retweet:\nConversational aspects of retweeting on Twitter. In:\nProceedings of the 43rd Hawaii International Conference\npp.1\u00ad10. IEEE Computer Society.\nBru\n\u00a8 gger N and Finnemann NO (2013) The web and digital\nhumanities: Theoretical and methodological concerns.\nBruns A and Burgess JE (2011) The use of Twitter hashtags in\nthe formation of ad hoc publics. In: Proceedings of the 6th\nEuropean Consortium for Political Research (ECPR)\nGeneral Conference, Reykjavik, Iceland, 24\u00ad27 August\nBurnap P, Williams ML, Sloan L, et al. (2014) Tweeting the\nterror: Modelling the social media reaction to the\nWoolwich terrorist attack. Social Network Analysis and\nCard S, Mackinlay J and Shneiderman B (1999) Readings in\nInformation Visualization: Using Vision to Think. New\nYork: Morgan Kaufmann.\nCui W, Lin S, Tan L, et al. (2011) TextFlow: Towards\nbetter understanding of evolving topics in text.\nIEEE Transactions on Visualization and Computer\nDiakopoulos N, Naaman M and Kivran-Swaine F Diamonds\nin the rough: Social media visual analytics for journalistic\nenquiry. In: IEEE Symposium on Visual Analytics Science\nand Technology, Salt Lake City, UT, USA, 25\u00ad26 October\nGillespie T (2014) The relevance of algorithms. In: Gillespie\nT, Boczkowski PJ and Foot KA (eds) Media Technologies:\nEssays on Communication, Materiality, and Society.\nHassan S, Sanger J and Pernul G (2014) SoDA: Dynamic\nvisual analytics of big social data. In: 2014 International\nConference on Big Data and Smart Computing\nHeverin T and Zach L (2011) Use of microblogging for col-\nlective sense-making during violent crises: A study of three\ncampus shootings. Journal of the American Society for\nHughes J and Sharrock W (1997) The Philosophy of Social\nResearch. Harlow, UK: Pearson Longman.\nKitchin R (2014) Big data, new epistemologies and paradigm\nLanglois G (2011) Meaning, semiotechnologies and participa-\nLocke K (2010) Abduction. In: Mills AJ, Eurepos J and\nWiebe E (eds) Encyclopedia of Case Study Research.\nLondon: Sage Publications, pp. 1\u00ad3.\nLuo D, Yang J, Krstajic M, et al. (2012) EventRiver: Visually\nexploring text collections with temporal references. IEEE\nTransactions on Visualization and Computer Graphics\nMahrt M and Scharkow M (2013) The value of big data in\ndigital media research. Journal of Broadcasting and\nMarcus A, Bernstein MS, Badar O, et al. (2011) TwitInfo:\nAggregating and visualizing microblogs for event explor-\nation. In: CHI `11 Proceedings of the SIGCHI Conference\non Human Factors in Computing Systems, Vancouver,\nMarshall C (2012) Big Data, the crowd and me. Information\nMatthews N and Sunderland N (2013) Digital life-story nar-\nratives as data for policy makers and practitioners:\nThinking through methodologies for large-scale multi-\nmedia qualitative datasets. Journal of Broadcasting and\nMurthy D (2012) Towards a sociological understanding of\nMurthy D (2013) Twitter: Social Communication in the\nTwitter Age. Cambridge: Polity Press.\nRaghavan P (2014) It's time to scale the science in the social\nsciences. Big Data and Society 1(1): 1\u00ad4.\nRogers R (2013) Digital Methods. London: The MIT Press.\nRose S, Butner S, Cowley W, et al. (2009) Describing story\nevolution from dynamic information streams. In: IEEE\nsymposium on visual analytics science and technology,\nSharma S (2013) Black Twitter? Racial hashtags, networks\nThelwall M, Buckley K, Paltoglou G, et al. (2010) Sentiment\nstrength detection in short informal text. Journal of the\nAmerican Society for Information Science and Technology\nThomas J and Cook K (2005) Illuminating the Path: The\nResearch and Development Agenda for Visual Analytics.\nRichland, WA, USA: Pacific Northwest National\nLaboratory.\nTufekci Z (2014) Big questions for social media big data:\nRepresentativeness, validity and other methodological pit-\nfalls. In: Proceedings of the Eighth International AAAI\nConference on Weblogs and Social Media, Ann Arbor,\nCA: The AAAI Press.\nTumasjan A, Sprenger TO, Sandner PG, et al. (2010)\nPredicting elections with Twitter: What 140 characters\nreveals about political sentiment. In: Proceedings of the\n4th International AAAI Conference on Weblogs and\n12 Big Data & Society"
}