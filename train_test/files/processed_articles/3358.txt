{
    "abstract": "Abstract. Mantis shrimp and primates both possess good color vision, but the neural implementation\nin the two species is very different, a reflection of the largely unrelated evolutionary lineages of these\ncreatures. Mantis shrimp have scanning compound eyes with 12 classes of photoreceptors, and have\nevolved a system to decode color information at the front-end of the sensory stream. Primates have\nimage-focusing eyes with three classes of cones, and decode color further along the visual-processing\nhierarchy. Despite these differences, we report a fascinating parallel between the computational\nstrategies at the color-decoding stage in the brains of stomatopods and primates. Both species appear\nto use narrowly tuned cells that support interval decoding color identification.\n",
    "reduced_content": "a Pion publication\nQasim Zaidi\nGraduate Center for Vision Research, State University of New York, New York; e-mail: qz@sunyopt.edu\nJustin Marshall\nQueensland Brain Institute, The University of Queensland, Brisbane, Queensland 4072,Australia; e-mail: h.thoen@uq.edu.au\nHanne Thoen\nQueensland Brain Institute, The University of Queensland, Brisbane, Queensland 4072, Australia;\ne-mail: justin.marshall@uq.edu.au\nBevil R. Conway\nNeuroscience Program, Wellesley College, Wellesley, Massachusetts; e-mail: bconway@wellesley.edu\n Keywords: mantis shrimp, primate color vision, color decoding, tuning curves, winner-take-all, photoreceptors,\nIT cortex.\nIn the second half of the 19th century, James Clerk Maxwell showed that people make color matches\nby equating light absorbed in each of three photoreceptor classes. Maxwell's results supported the\nidea that color is represented in the human brain by a linear three-dimensional (3-D) space in which\ndistinct points correspond to different colors, while each point (color) within this space corresponds to\nan almost infinite number of physically distinct lights (metamers). For example, the single-wavelength\nyellow of the rainbow is indistinguishable from an appropriate mixture of wavelengths that sepa-\nrately appear red and green--both stimuli cause the same relative activation of the three cone types.\n\nMaxwell's discovery pointed to the critical role that neural comparison of photoreceptor outputs plays\nin determining what colors we see.\nWhen Cronin and Marshall (1989) reported that mantis shrimp, a predatory stomatopod crustacean,\nhas 12 classes of narrowly tuned photoreceptors (Figure 1A), three in the ultra-violet range and nine\ncovering the 400\u00ad700-nm spectrum, the scientific imagination ran wild: do they have a 12-dimensional\n(12-D) color space, so that they distinguish colors we confuse, and see colors we cannot even imagine?\nSuch conjectures were restrained by the concern that their small brains could be overloaded by color\ncomputations in a 12-D space. Behavioral experiments by Thoen, How, Chiou, and Marshall (2014)\nhave since shown that mantis shrimp are in fact poor at discriminating colors that humans see as dis-\ntinct. The results suggested that the 12 classes of photoreceptors function independently, and their out-\nputs are not compared by later neurons. So it has been concluded that mantis shrimp have a color system\nunlike humans, or possibly any other creature. The requirements of rapid hunting decisions and a small\nbrain, could have led mantis shrimp to evolve 12 narrow-tuned color receptors at the front end of the\nvisual system: presumably the photoreceptors feed a fast, hard-wired, interval-decoding computation,\nwhere perceived color corresponds to the peak sensitivity of the most responsive photoreceptor. Such\nhard-wiring is typical of many invertebrate sensory systems where behavioral tasks are \"matched\" to\nthe environmental parameters that drive the task.\nEvolution of neural computations: Mantis shrimp and human\ncolor decoding\n493 Zaidi Q, Marshall J, Thoen H, Conway BR\nThe eyes and photoreceptors of mantis shrimp and humans are clearly different, but are the neural\nstrategies used to compute color that different? On the basis of physiological and anatomical research\nin macaque monkeys, a trichromat with color vision very similar to humans (Stoughton, Lafer-Sousa,\nGagin, & Conway, 2012), we have reason to believe that the computations carried out by the color-\nvision systems in humans and mantis shrimp are more similar than they first appear. Although color\nin trichromatic primates is encoded using three (not 12) classes of broadly tuned photoreceptors, pri-\nmates have much larger brains than shrimp: neural circuits compare cone responses within the retina\n(Sun, Smithson, Zaidi, & Lee 2006), and the neural circuits responsible for color perception are linked\nacross several different cortical regions (Conway, 2014). In inferior temporal cortex (IT), several steps\ndownstream of the cones, the cells are remarkably color specific (Komatsu, Ideura, Kaji, & Yamane,\n1992), as shown for a sample of IT neurons in Figure 1B (Conway, Moeller, & Tsao, 2007). Some\ncells respond only to red, others to reddish blue, bluish red, violet, and so on. In their specificity, the\ncolor preferences of these cells are strikingly similar to the color specificity of the mantis shrimp pho-\ntoreceptors, suggesting that the 400 million year old color processing system in stomatopods and the\n40 million year old primate system could ultimately use a similar strategy at the decoding stage.\nTo test this idea, we used simulations to determine the extent to which primates could use nar-\nrowly tuned IT cells for an interval-color-decoding strategy similar to the one that is postulated to\noperate in the mantis shrimp. The strategy hypothesizes that the decoded color of a stimulus corre-\nsponds to the color preference of the IT neuron that produced the highest firing to the stimulus. In for-\nmal terms, this approach couples interval coding with a winner-take-all decision rule. For each of 279\nposterior IT \"glob\" cells, based on responses to brief presentations of 45 colors measured with single-\nunit recording (Conway et al., 2007), we simulated a model cell with the same color-tuning. Firing\nrates for each stimulus color were generated by a Poisson distribution with mean and variance equal\nto the mean firing rate of the measured cell. So in every trial, the simulated response varied around the\ncolor-tuning by an amount chosen at random from the Poisson distribution. Each frame of the movie\nin Figure 2 (left--movie can be found at http://i-perception.perceptionweb.com/journal/I/volume/5/\narticle/i0662sas) shows the simulated responses of the whole population to each color stimulus. The\ncells have been sorted along the x-axis according to their color preferences: cells tuned to red are on\nthe left, followed rightwards by cells tuned to orange, yellow and so on around the color circle. The\nstimulus is depicted by the red symbol, and the decoded color is simply the color preference of the\ncell with the maximum firing rate. For the first trial, the cell with the maximum firing is tuned to the\nstimulus color, showing that the simple decoding strategy worked. As the simulated stimulus changes\nfrom 1 to 45, even with this meager number of cells and stimuli, the population supports fairly accu-\nrate interval decoding of color. Since each cortical neuron receives thousands of synapses, and color\ncells are organized into local columns of similarly color-tuned cells, it may be unrealistic to restrict the\ndecision to a single neuron's response. So we used the average of the responses of all cells with the\nsame preferred color, and found that the decoding accuracy improved markedly (Figure 2--right). The\nsuccess of interval decoding presents a physiologically realistic and computationally efficient alterna-\ntive to color theories based on unique hues (De Valois & De Valois, 1993) that have no physiological\nsupport. Interval decoding is also compatible with the results of the only color micro-stimulation\nexperiment done on humans (Murphey, Yoshor, & Beauchamp, 2008).\nFigure 1. Color tuning of (A) mantis shrimp photoreceptors, and (B) of a few neurons in macaque inferior\ntemporal cortex.\nEvolution of neural computations 494\nIt is intriguing to consider whether winner-take-all with IT cells represents a hard-wired approxi-\nmation of optimal Bayesian decoding of the population of responses. If the neurons in the population\nhave independent variability, then the population response probability will be the product of the\nPoisson probability of all the neurons. Applying Bayes'rule to get the probability of decoding a stimu-\nlus color given a pattern of population responses, leads to an expression for decoding that contains\na term that represents multiplication of tuning curves raised by the number of spikes, and is the only\nterm that depends on the pattern of responses on a trial. A cell that only fires if it gets spikes from two\ncells within a short time interval, will only fire for stimuli for which the tuning curves of the earlier\ncells overlap, i.e. the output tuning curve will look like a multiplication of the input tuning curves.\nSimilarly, a cell that only fires if it receives a defined number of input spikes in a short interval, will\nhave a tuning curve that looks like the input tuning curve raised to the power of the number of spikes\n(Sanger, 1998). These operations will approximate the response-dependent term in Bayesian decod-\ning, and performed on broadly tuned outputs from antecedent stages of processing will generate nar-\nrower tuning, consistent with empirical observations in IT. Interval decoding would therefore provide\nrapid color identification because no further computations would be required on the outputs of IT\nneurons. Since IT cortex has millions of color-tuned cells, they can sample the spectrum much more\nfinely than the 12 mantis shrimp photoreceptors, so interval decoding could simultaneously provide\nmuch better color identification and discrimination compared to mantis shrimp, resolving the paradox\nthat mantis shrimp have poorer color vision than humans despite having more photoreceptor classes.\nIn mantis shrimp, the cost of early functional specialization in the compound eye, and the sub-\ndivision of tasks to different eye areas (Cronin & Marshall, 1989), requires that the animal scan the\nscene to generate a representation of its visual world (Land, Marshall, Brownless, & Cronin, 1990).\nThe primate eye is fundamentally different from the shrimp, like a digital camera it possesses a sin-\ngle focusing apparatus for a dense array of photoreceptors. Using just three classes of broadly tuned\ncone photoreceptors, the primate visual system is able to distinguish the spectra of natural lights and\nobjects sufficiently (Barlow, 1982), while maintaining good spatial resolution, and providing the\nmeans to identify objects by their colors despite variations in ambient lights and surrounding scenes\n(Zaidi, 1998, 2001). More classes of photoreceptors would improve the sampling of natural spectra\n(Nascimento, Foster, & Amano, 2005), but would seriously compromise spatial resolution. Generating\nnarrow color tuning in functionally specialized cortical regions affords rapid interval decoding without\nlosing these features.\nDespite tremendous differences in human versus mantis shrimp eye structure and brain circuitry,\nthe striking similarity between the color sensitivities of primate IT neurons and stomatopod photore-\nceptors provides evidence of a common computational strategy across largely unrelated species. Inter-\nval decoding of color is an interesting example of independent evolutionary histories converging on\nFigure 2. Stills of movies that can be found at http://i-perception.perceptionweb.com/journal/I/volume/5/article/\ni0662sas. (Left) In the movie each frame shows Poisson responses of 279 IT neurons (black stars) elicited by a\nstimulus color (red circle) on one trial, plotted versus the mode of the tuning curve of each cell. The stimulus color\nprogresses on each frame representing an independent trial. At the end of the 45-color cycle, blue circles plot the\ndecoded color (the preferred color of the cell that fired maximally on that trial) against the stimulus color. The\nsimulations are repeated five times to demonstrate the variability in probabilistic decoding. (Right) In the movie\nthe black stars now give the average response of all the cells preferentially tuned to the color on the x-axis. The\ndecoding is considerably more accurate.\n495 Zaidi Q, Marshall J, Thoen H, Conway BR\nthe same robust computational principle, and may thus be worth emulating by machine vision systems\ndesigned to function in the real word.\n"
}