{
    "abstract": "Sharad Goela,1 and Matthew J. Salganikb,1 aMicroeconomics and Social Systems, Yahoo! Research, 111 West 40th Street, New York, NY, 10018; and bDepartment of Sociology and Office of",
    "reduced_content": "Sharad Goela,1 and Matthew J. Salganikb,1\naMicroeconomics and Social Systems, Yahoo! Research, 111 West 40th Street, New York, NY, 10018; and bDepartment of Sociology and Office of\nPopulation Research, Princeton University, Wallace Hall, Princeton, NJ 08544\nEdited* by Adrian Raftery, University of Washington, Seattle, WA, and approved March 3, 2010 (received for review January 8, 2010)\nRespondent-driven sampling (RDS) is a network-based technique\nfor estimating traits in hard-to-reach populations, for example,\nthe prevalence of HIV among drug injectors. In recent years RDS\nhas been used in more than 120 studies in more than 20 countries\nand by leading public health organizations, including the Centers\nfor Disease Control and Prevention in the United States. Despite\nthe widespread use and growing popularity of RDS, there has been\nlittle empirical validation of the methodology. Here we investigate\nthe performance of RDS by simulating sampling from 85 known,\nnetwork populations. Across a variety of traits we find that RDS\nis substantially less accurate than generally acknowledged and\nthat reported RDS confidence intervals are misleadingly narrow.\nMoreover, because we model a best-case scenario in which the\ntheoreticalRDSsamplingassumptionshold exactly, itis unlikelythat\nRDS performsany betterin practicethan in our simulations. Notably,\nthepoorperformanceofRDSisdrivennotbythebiasbutbythehigh\nvariance of estimates, a possibility that had been largely overlooked\nin the RDS literature. Given the consistency of our results across\nnetworks and our generous sampling conditions, we conclude that\nRDS as currently practiced may not be suitable for key aspects of\npublic health surveillance where it is now extensively applied.\ndisease surveillance  snowball sampling  social networks\nThe development and evaluation of public health policies often\nrequire detailed information about so-called hard-to-reach or\nhidden populations. For example, HIV researchers are especially\ninterested in monitoring risk behavior and disease prevalence\namong injection drug users, men who have sex with men, and\ncommercial sex workers--the groups at highest risk for HIV in\nmost countries. Unfortunately, however, these high-risk groups\nare not easily studied with standard sampling methods, including\ninstitutional sampling, targeted sampling, and time-location\nsampling (1).\nRespondent-driven sampling (RDS) (2\u00ad4) facilitates examina-\ntion of such hidden populations via a chain-referral procedure in\nwhich participants recruit one another, akin to snowball sam-\npling. RDS is now widely used in the public health community\nand has been recently applied in more than 120 studies in more\npants (5). In particular, in helping to track the HIV epidemic,\nRDS is used by the Centers for Disease Control and Prevention\n(CDC) (6, 7) and by the United States President's Emergency\nPlan for AIDS Relief.\nRDS is a method both for data collection and for statistical\ninference. To generate an RDS sample, one begins by selecting\na small number of initial participants (\"seeds\") from the target\npopulation who are asked--and typically provided financial\nincentive--to recruit their contacts in the population (2). The\nsampling proceeds with current sample members recruiting\nthe next wave of sample members, continuing until the desired\nsample size is reached. Participants are usually allowed to recruit\nup to three other contacts in order to ensure sampling continues\neven if some sample members do not recruit.\nWith the RDS sampling design, individuals with more contacts\nin the target population are more likely to be recruited (4). To\nadjust for this selection bias, respondents are weighted inversely\nproportional to their network degree or number of contacts.\nSpecifically, for any individual trait f (e.g., age), the RDS estimate\n^\nf\nof the population mean of f is defined to be\n^\nf\n\u00bc\n\nn\n1degree\u00f0Xi\n\u00de \nn\nf\u00f0Xi\n\u00de\ndegree\u00f0Xi\n\u00de\n; ...; Xn\nare the n participants in the study. Typically, f is\n0\u00ad1, for example, indicating infectivity of a specific disease, in\nwhich case ^\nf\nestimates prevalence of the trait in the target\nThe accuracy of RDS estimates is affected by the structure of\nthe underlying social network, the distribution of traits within\nthe network, and the recruitment dynamics. In particular,\nRDS can perform poorly when traits cluster in cohesive subpo-\npulations (10)--a phenomenon that may be especially acute in\nthe case of infectious diseases (11). Gauging the combined effect\nof these factors has proven difficult, and previous attempts to\nassess the performance of RDS have been largely inconclusive.\nThe earliest evaluations of RDS come from simulation studies\non synthetic networks (4, 8, 12). These studies, however, likely\noverestimated the accuracy of RDS by neglecting to design syn-\nthetic networks that adequately mimic the community structure\nof real social networks (10). Recently, Gile and Handcock (13)\nhave evaluated the bias of RDS estimates on more realistic syn-\nthetic networks. Beyond simulation studies, there have been\nthree approaches for assessing the quality of RDS. First, RDS\nhas been carried out on a population with known characteristics:\nundergraduates at a large residential university (9, 14). Because\nonly a single RDS sample was taken, however, it is difficult to\nascertain sample-to-sample variability of estimates. Second,\nRDS estimates have been compared to estimates derived from\nalternative sampling methods (15\u00ad21) (Table S1). These compar-\nisons have not yielded consistent patterns and are hindered by the\nfact that true population values remain unknown.\u00a7 Finally, the\nAuthor contributions: S.G. and M.J.S. designed research, performed research, analyzed\ndata, and wrote the paper.\nThe authors declare no conflict of interest.\n*This Direct Submission article had a prearranged editor.\nFreely available online through the PNAS open access option.\nAn earlier RDS estimator (4) was based on a slightly different statistical correction and is\nstill in widespread use. Consistent with past analytic (8) and empirical (9) results, we find\nthe two estimators perform comparably (Fig. S1).\nFor the 13 traits studied (e.g., college major), RDS estimates of the population proportions\nwere generally within five percentage points of the true values. Although often cited as\nevidence in support of RDS, we note that the majority of these traits had true population\nproportions less than 10%; thus an absolute error of five percentage points is\nrelatively large.\n\u00a7In some cases, RDS has produced results generally in line with other methods [e.g., a study\nof drug users in New York City (18)], whereas in other cases, estimates from RDS differed\nsignificantly. For example, in studies of injection drug users (IDU) in Seattle (17), estimates\nfrom RDS indicated an older, more downtown-based IDU population than two previous\nstudies, prompting researchers to suspect problems with RDS; and in studies of MSM in\nForteliza, Brazil (19), RDS estimates of the proportion of lower-class MSM were much\nhigher than past estimates from time-location sampling--in this case, RDS estimates were\nbelieved to better characterize the target population. Additional discussion of these\ncomparative studies is available in ref. 17.\n1To whom correspondence may be addressed. E-mail: goel@yahoo-inc.com or mjs3@\nprinceton.edu.\nThis article contains supporting information online at www.pnas.org/cgi/content/full/\nSTATISTICS\nstability of repeated cross-sectional RDS estimates has been\nexamined, again yielding ambiguous results. For example, in stu-\ndies of men who have sex with men (MSM) in Beijing, China in\nand employment status were stable, whereas estimates of educa-\ntion and sexual orientation were suspiciously volatile.\u00b6\nIn contrast to previous approaches, we evaluate the perfor-\nmance of RDS by simulating the sampling and estimation process\non 85 real populations mapped in two previous studies. In all\ncases, both the network structure of the population and demo-\ngraphic traits for each individual are available. We are thus able\nto directly compare empirical RDS estimates to true population\nvalues and, in particular, to measure the variability of estimates.\nData and Methods\nOur first source of data, Project 90, was a large, multiyear study\nthat began in 1987 as a prospective examination of the influence\nof network structure on the propagation of infectious disease\n(23). As such, researchers attempted to construct a network\ncensus of high-risk heterosexuals in Colorado Springs, focusing\nparticularly on sex workers and drug injectors and their sexual\nand drug partners (23\u00ad26). We restrict attention to the giant\ncomponent of the network, comprising 4,430 individuals and\n18,407 edges, representing social, sexual, and drug affiliation.\nOur second data source, the National Longitudinal Study of Ado-\nlescent Health (Add Health), mapped the friendship networks of\n84 middle and high schools in the United States (27\u00ad29). The\ngiant components for these school networks range in size from\nRather than attempting to model the complex social dynamics\nthat play out during the RDS recruitment process, in our simula-\ntions we assume the same, idealized sampling conditions consid-\nered in the theoretical RDS literature (4, 8, 10, 30). Specifically,\n(i) initial sample members are chosen independently and propor-\ntional to network degree; (ii) relationships within the population\nare symmetric (i.e., if A is a contact of B, then B is also a contact\nof A); (iii) participants recruit uniformly at random from their\ncontacts; (iv) those who are recruited always participate in the\nstudy; (v) individuals can be recruited into the sample more than\nonce; (vi) the number of recruits per participant does not depend\non individual traits; and (vii) respondents accurately report their\nsocial network degree. The remaining parameters of our simula-\ntions are modeled after common RDS study features (5). Starting\nfrom ten initial seeds, each participant recruits between 0 and 3\nother individuals. The exact recruitment distribution mimics an\nRDS study of drug injectors in Tijuana and Ciudad Juarez,\nMexico (31), in which 13 of participants recruited no one,\n16 recruited one other participant, 16 recruited two other\nparticipants, and 13 recruited three other participants, the max-\nimum allowed. The simulated recruitment procedure continues\nuntil a sample size of 500 is reached. The entire sampling process\nwas repeated 10,000 times on each network to generate replicate\nestimates.\nResults\nFrom each simulated sample, the RDS estimator (Eq. 1) was used\nto infer the population proportion of a given trait--for example,\nthe proportion of drug dealers in the Project 90 network or the\nproportion of students on the soccer team in a particular Add\nHealth school. Consistent with theoretical results (8, 10), we find\nRDS generates approximately unbiased estimates: Across all\nnetworks and traits, both the mean and median bias are less than\nThe variability of RDS estimates, however, is significantly\nlarger than generally acknowledged. We quantify this variability\nin terms of design effect (32), which benchmarks the performance\nof RDS against that of simple random sampling (SRS). Specifi-\ncally, the design effect d is Var\u00f0^\n\u00deVar\u00f0^\n\u00de, where ^\nis\nthe RDS estimate and ^\nis the estimate obtained from SRS.\nIt follows that an RDS estimate with sample size n and design\neffect d has the same variance as a simple random sample of\nsize nd. A design effect of 10, for example, effectively reduces\nan RDS sample of nominal size 500 to an SRS sample of\nConsistently large design effects are seen in both Project 90\nand Add Health (Fig. 1). The 13 binary traits in Project 90 have\ndesign effects that range from 5.7 to 58.3, with a median design\neffect of 11.0. As a consequence, estimating the 17% unemploy-\nment rate in Project 90, which has a design effect of 10, with\nreasonable precision (\u00c65%, 95% confidence) requires an RDS\nsample of approximately 2,300 people--a sample size 5 times\nlarger than in nearly all previous RDS studies (5). We observe\na similar phenomenon for each of the 46 binary traits in Add\nHealth. The median design effect for traits ranges from 4.2 to\n14.4, where for each trait the median is taken across the 84\nAdd Health schools. The overall median design effect for all traits\nin all schools is 5.9.\nAll traits in the Project 90 and the Add Health networks\nyield design effects larger than what is commonly assumed in\nthe planning stages of RDS studies. A review of 91 studies found\nthat more than half assumed a design effect less than 1.5, and all\nassumed a design effect less than 2.5 (5). Furthermore, a rule-\nof-thumb design effect of 2 had been suggested by Salganik\n(12). Given that we find typical design effects greater than 5, even\nPIMP\nHOMELESS\nRETIRED\nUNEMPLOYED\nHOUSEWIFE\nTHIEF\nFEMALE\nDISABLED\nNONWHITE\nA\nDesign effect\nBRACE\nHEAL\nADOPTED\nBOOK\nCHEERLEADING\nSGA\nHISTORY\nWRESTLING\nDEBA\nTE\nTENNIS\nORCHESTRA\nGERMAN\nFFA\nFRENCH\nTWIN\nSWIMMING\nSP\nANISH\nLA\nTIN\nCOMPUTER\nMA\nTH\nNEWSP\nAPER\nVOLLEYBALL\nYEARBOOK\nDRAMA\nNA\nTIVE\nSOCCER\nTRACK\nSCIENCE\nFOOTBALL\nCHORUS\nHONOR\nFEMALE\nBAND\nBASKETBALL\nDRINK\nNONWHITE\nB\nFig. 1. Design effects for the 13 binary traits in Project 90 (A) and the 46\nbinary traits in Add Health (B); in Add Health, each circle indicates the design\neffect of a trait in one of 84 schools.\n\u00b6Year-to-year estimates for the proportion of the population with less than a high school\neducation went from 33% to 70% to 66%, and estimates for the proportion bisexual\nunder optimistic sampling conditions, it is likely that many RDS\nstudies do not have sufficiently large sample sizes to meet their\nstated study objectives. In particular, the CDC, in its assessment\nof RDS for use in the National HIV Behavioral Surveillance\nSystem, concludes that a sample of size 500 is adequate to esti-\nmate traits with 5% precision (95% confidence) (33), implicitly\nassuming a design effect of 1. Though valid if subjects are chosen\nby SRS, our results suggest an RDS sample of 500 may lead to\nerrors of 10% or more.\nCompounding these large design effects, the standard RDS\nconfidence intervals developed by Salganik (12, 34) are often mis-\nleadingly narrow, masking the effects of inadequate sample sizes\n(Fig. 2). In Project 90, the coverage probability of nominal 95%\nconfidence intervals ranges across traits from 42% to 65%, with\nmedian coverage of 52%. In other words, though 95% of such\nintervals should contain the true population proportion, in our\nsimulations only about half of the intervals in fact do. We find\nsimilar results for the Add Health networks, where nominal\n95% intervals have coverage probability across traits ranging\nlikely that, in a substantial fraction of field studies, true popula-\ntion values fall outside the reported ranges.\nTo put our results in context, we compare the RDS estimator\n(Eq. 1)--which weights sample members inversely proportional\nto their network degree--to the unweighted mean of the RDS\nsample, an estimation method that mimics traditional snowball\nsampling and that is widely considered problematic for public\nhealth surveillance (35, 36). As shown in Fig. 3, though the\nsample mean generally has larger bias than the RDS estimator,\nthe two estimators are comparable in terms of their standard\nerror and their overall performance, as quantified by root-\nmean-squared error (RMSE). Specifically, in Add Health the\nmedian absolute bias, standard error, and RMSE of the sample\nand in Project 90 the analogous values for the sample mean\nHelping to explain why RDS and the sample mean perform\nsimilarly, we note that weighted and unweighted means differ\nto the extent that weights and traits are correlated, a fact that\nis well-documented in the survey sampling literature (37). Thus\nthe advantages of RDS are manifest primarily when network\ndegree correlates with, for example, drug use, sexual behavior,\nor other traits of interest. At least in the datasets we examine,\nhowever, we see mostly weak correlations and thus generally find\nweighting to have minimal impact. In Add Health, where traits\nand degree have median absolute correlation of 0.05, RDS\nand the sample mean perform almost identically: The median\ndifference in RMSE (RMSE of the sample mean minus RMSE\nof the RDS estimator) is -0.001 across all school-trait pairs. Ten\nof the thirteen traits in Project 90 are likewise weakly correlated\nwith degree--median absolute correlation among these ten is\n0.06--and RDS and the sample mean are correspondingly simi-\nlar, with a median difference in RMSE of 0.005. The remaining\ntraits--indicating, respectively, whether an individual is a drug\ndealer, a sex worker, or unemployed--are more highly correlated\n0.13. Though, even in these three cases where RDS substantially\nNONWHITE\nPIMP\nTHIEF\nHOMELESS\nHOUSEWIFE\nDISABLED\nUNEMPLOYED\nRETIRED\nFEMALE\nA\nCoverage rate\nLA\nTIN\nGERMAN\nBOOK\nHISTORY\nFFA\nORCHESTRA\nDRINK\nFRENCH\nNONWHITE\nSCIENCE\nHONOR\nDEBA\nTE\nBASKETBALL\nCOMPUTER\nTWIN\nBAND\nMA\nTH\nNEWSP\nAPER\nSP\nANISH\nTENNIS\nTRACK\nCHORUS\nYEARBOOK\nSOCCER\nSGA\nWRESTLING\nVOLLEYBALL\nFOOTBALL\nSWIMMING\nDRAMA\nCHEERLEADING\nNA\nTIVE\nFEMALE\nADOPTED\nHEAL\nFig. 2. Coverage rates of nominal 95% RDS confidence intervals in Project\n90 (A) and Add Health (B). For each trait in Add Health, the mean coverage\nover all 84 schools is shown.\nBias of sample mean\nBias of RDS estimate\nA\nStd. error of sample mean\nStd. error of RDS estimate\nB\nRMSE of sample mean\nRMSE of RDS estimate\nC\nBias of sample mean\nBias of RDS estimate\nD\nStd. error of sample mean\nStd. error of RDS estimate\nE\nRMSE of sample mean\nRMSE of RDS estimate\nF\nFig. 3. Comparison of bias, standard error, and RMSE between the RDS\nestimator and the unweighted mean of the RDS sample in Project 90\n(A\u00adC) and Add Health (D\u00adF). Each point corresponds to a given trait in a given\nnetwork population.\nSTATISTICS\noutperforms the sample mean, RDS is still far from ideal, with\ndesign effects greater than 10 for all three traits.\nIn the above analysis, we considered the performance of RDS\nfor 85 previously mapped real social networks. To check the\nrobustness of our results, we simulate RDS on several variants\nof these network populations. We find that large design effects\npersist, suggesting that our results extend beyond the particular\npopulations we study and hold more generally. First, a significant\nstructural anomaly with the Project 90 network is the large num-\nber of so-called leaf nodes (i.e., individuals connected to exactly\none other node), which comprise 18% of the giant component.\nThese leaves often correspond to individuals who were identified\nin the study by another participant but who themselves were not\ndirectly interviewed. Repeating our analysis on the Project 90\nsubnetwork that excludes these leaves, we find no appreciable\nchange in the performance of RDS, with a median design effect\nond, of the 84 Add Health networks, 44 represent joint middle\nand high schools whereas the remaining 40 are exclusively high\nschools. In the joint middle and high schools there is substantial\nsegregation between these two constituent subpopulations\n(29, 38, 39), and as such, one may worry that our results are driven\nby this single, atypical, network feature. We find, however, that\nthe distribution of design effects in the joint schools is approxi-\nmately the same as in those that are strictly high schools, with\nmedian design effects of 5.9 and 6.0, respectively (Fig. S3). Third,\nstudents in the Add Health study were asked to name up to five\nmale and five female friends, and in our primary analysis we\ninferred a symmetric edge between students A and B if either in-\ndividual named the other. Alternatively, one could consider only\nreciprocal nominations--inferring a symmetric tie between A and\nB only if A and B both nominate one another--that potentially\ncorrespond to stronger friendships (29). We find that the perfor-\nmance of RDS on these reciprocal-nomination networks is in fact\nconsiderably worse, with a median design effect of 18.9, com-\npared to 5.9 for the one-sided-nomination networks (Fig. S4).\nFor a final robustness check, we confirm that large design effects\nare not driven by obvious structural or demographic properties of\nthe target populations. Specifically, across the 84 Add Health\nschools, we find that design effect is weakly correlated with both\nschool size (0.07) and the true population proportion of the trait\nDiscussion\nPast work has emphasized that RDS in theory generates approxi-\nmately unbiased estimates (4, 8, 30)--and we indeed find this to\nbe the case in our simulations. However, by neglecting to consider\nthe variance, this result has been widely interpreted as indicating\nthat RDS has low error. Explicitly examining the variance of\nRDS, we find that estimates are much less precise than previously\nbelieved. In particular, RDS as currently practiced may be poorly\nsuited for important aspects of public health surveillance where it\nis now extensively applied. For example, to reliably detect a\ndecline in unsafe injection practice from 40% to 30% with\nSRS requires approximately 350 people at each of the two time\npoints. With a design effect of 5--a typical finding in our simu-\nlations--the required sample size jumps to 1750, substantially\nlarger than nearly all RDS studies (5). Consequently, it seems\nthat many existing studies do not have sufficient power to identify\neven quite large changes in behavior and almost certainly could\nnot identify with statistical confidence small changes in disease\nprevalence.\nOur findings are subject to two potential objections. First, the\nProject 90 and the Add Health networks are not perfect repre-\nsentations of hidden populations. In particular, networks of high\nschool students are unlikely to be representative of networks of\npopulations at high risk for HIV, and the Project 90 network,\nalthough it maps such a hidden population, probably suffers from\nsignificant missing data. We attempted to mitigate this short\ncoming by analyzing two distinct datasets, each with different\nlimitations, and by analyzing several thousand network-trait pairs\n(46 traits \u00d7 84 school networks from Add Health, and 13 traits\nin the Project 90 network), thus decreasing the chance that our\nfindings are driven by anomalous features of any one trait or\nnetwork. Furthermore, we considered several modified versions\nof these networks to check for robustness to structural perturba-\ntions. The qualitative consistency of our results suggests that the\nobserved high variance of RDS estimates is the norm rather than\nthe exception.\nSecond, in order to simulate recruitment, we followed the\nsame idealized sampling design assumed in the theoretical\nRDS literature; it is thus possible that RDS could perform better\nunder real-world sampling conditions than it does in our simu-\nlated environment. It seems much more likely, however, that\nactual RDS sampling dynamics only exacerbate the problems\nindicated by our results (13). Specifically, initial participants\nare generally a convenience sample and are almost certainly\nnot chosen in the judicious, independent manner of our simula-\ntions (40). There is also evidence of nonrandom recruitment of\npeers and of differential participation and recruitment rates\n(40\u00ad44). In a study of MSM in Brazil (45), for example, partici-\npants were more likely to recruit those who they thought engaged\nin riskier behavior and who would therefore most benefit from\nHIV testing; this same study found that some individuals refused\nto participate for fear of disclosing their sexual orientation.\nEvidence of differential recruitment rates was seen in a study\nof jazz musicians in New York, with women on average recruiting\nmore than 60% more participants than men (30). Furthermore, in\npractice, and in contrast to our simulations, participants are\nprohibited from entering an RDS study multiple times, a policy\nintended to deter fraudulent recruitment tactics, but one that also\ngenerally increases the bias of estimates (13). Finally, ascertain-\ning an individual's network degree is a challenging problem\n(46\u00ad48)--particularly in the context of RDS (40)--and so self-\nreported network size represents a possibly significant source\nof nonsampling error absent from our simulations.\nConclusion\nSimulating sampling across 85 real social networks, we find the\nvariance of RDS is typically 5\u00ad10 times greater than that of\nSRS and, moreover, that standard RDS confidence intervals\nare misleadingly narrow. In light of our generous sampling\nassumptions, and the robustness of our results to network pertur-\nbations, it is likely that RDS will perform no better--and may\nperhaps perform considerably worse--in field studies. In particu-\nlar, our results highlight the considerable obstacles facing RDS in\napplications such as disease surveillance. By clarifying the limita-\ntions of RDS, we hope to encourage its further development,\nsystematic evaluation, and cautious application.\n"
}