{
    "abstract": "Engineering companies (ECs), operating mainly through projects, have acquired considerable importance in the Moroccan economy for they serve as a one-stop consultancy offering for all the services necessary for definition, production, and project management (PM). They play an important role in supporting government and investors' decision as well as in knowledge transfer to local businesses.",
    "reduced_content": "Sector\nincludes research articles\nthat focus on the analysis and\nresolution of managerial and\nacademic issues based on\nanalytical and empirical or\ncase research\nEngineering companies (ECs), operating mainly through projects, have acquired\nconsiderable importance in the Moroccan economy for they serve as a one-stop\nconsultancy offering for all the services necessary for definition, production, and\nproject management (PM). They play an important role in supporting government\nand investors' decision as well as in knowledge transfer to local businesses.\nEngineering projects are managed in an environment often characterized by turbu-\nlence, complexity, and crucial need for flexibility and high quality information. The\nsuccess or failure of these projects depends on decisions made during their life cycle.\nThe burden of a bad decision in general and in the engineering sector, in particular,\nwhere business is generally run through projects, is becoming very overwhelming\nand these companies are urged to change the way they make decisions. They have\nto base their decisions more and more on high quality information, effective knowl-\nedge management (KM), and competitive intelligence (CI), tools. More importantly,\nthey have to use an effective decision analysis process to avoid mental bias that is\nthe most important reason behind bad decisions. Furthermore, such a project deci-\nsion analysis process should reinforce the strategic alignment of the organization\nin order to achieve the desired decision strategic impact. However, the conjunction\nand harmonization of all these processes and systems require smooth and careful\nimplementation, allowing for effective change management and high levels of\nmaturity in project decision-making capabilities and competencies. Accordingly,\nthe ECs need to climb suitable maturity levels, leading to both agility and flexi-\nbility. While agility relies on strong and adaptive processes covering the three main\ncomponents of enterprise intelligence, namely business intelligence, CI and KM,\nflexibility for a project-based organization means a combination in a proper dosage\nof effective organizational PM processes, on the one hand, and balanced project\ndecision processes, on the other.\nIn this backdrop, this article reviews literature, analyses different processes and\nmodels proposed in the last 10 years and develops an intelligent PM maturity model\nfor the Moroccan ECs. The proposed model, grounded on strong theoretical foun-\ndations and participatory design approach, is a hybrid between staged and system-\nbased models. It balances between rigidity and stability ensured by staged models\nand flexibility provided by the system-based models.\nVIKALPA\nThe Journal for Decision Makers\nManagement, Ahmedabad\nSAGE Publications\nsagepub.in/home.nav\nhttp://vik.sagepub.com\nExecutive\nSummary\nProject-based organizations (PBOs) adopt a busi-\nness model that combines intelligent systems\nwith a set of project management (PM) processes.\nBesides, they have to harmonize these efforts with\neffective project decision analysis processes (PDAPs)\nIntelligent systems ensure agility and project knowl-\nedge capitalization and PM processes guarantee a\nconsistent and methodical approach when framing\nand implementing project decisions (Virine & Trumper,\n2008). According to the statistics published by FMCI\n(2011), the Moroccan engineering market counts more\nthan 600 engineering companies (ECs) and employs\nover. More than 70 per cent of these companies are\nlocated between Rabat, the administrative capital, and\nCasablanca, the economic capital. While intervening in\nmore than 80 per cent of the total undertaken projects,\nthey serve only 40 per cent of the market, and the rest 60\nper cent is satisfied by international ECs. The principal\nengineering services are: construction, infrastructure,\nwater and environment, agriculture (including fishing\nand forestry), industries and mines (Alami, Beidouri &\nThe engineering market is very competitive with\nvolatile business patterns, low barriers to entry and\nstrong impact of political decision-making (FIDIC,\n2012). Accordingly, intelligent systems, continuously\nimproved PM processes, and effective decision anal-\nysis processes are among the urgent needs for ECs to\nsurvive in today's tougher competition (FMCI, 2011).\nThis research aims at developing and proposing a\nuseful and practical prescriptive intelligent project\nmanagement maturity model (IP3M) that will serve\nas an action plan for a gradual and methodical imple-\nmentation of such combined systems in the case of\nMoroccan engineering sector (MES).\nInspired by the extensive literature on intelligence\nmaturity models (MMs), project management matu-\nrity model (PMMM) and project decision-making,\nand an in-depth analysis of their strengths and weak-\nnesses, this article aims at developing and testing a\nprescriptive IP3M, applicable first to MES and poten-\ntially extendable to PBOs in Morocco and abroad. The\nconstruction of this IP3M is mainly based on a mixed\nmethods research, combining quantitative and qualita-\ntive methods.\nApproaches to Decision-making\nProject decision analysis is a branch of the decision\ntheory, which is the study of how to make better choices\nwhen faced with uncertainties. This theory is handled\nby authors in two different types of analyses: Normative\ndecision theory that describes how people should make\ndecisions and descriptive decision theory that describes\nhow people actually make decisions. The Foundation\nof this theory can be traced to critical thinking theory\nand process literature (McAuliffe, 2005; Safi & Burrell,\n2007). These two aspects, with regards to the emotional\nbias-critical pitfall (Johnson, 2006; Rombout & Wise,\napproaches that overlap in decisions (Skinner, 2009):\n\u00b7\nIntuitive approach. The manager may intuitively\nthink that he/she is making the right decision\neven if he/she does not have all the required\ninformation.\n\u00b7\nAdvocacy-based approach. In this approach, the\nmanager tries to follow a methodical decision\nprocess, starting by a decision framing and gath-\nering of the needed information, but at the end,\nhe/she turns to his/her feeling and intuition\nas the main decision argument. If the manager\nagrees with the evaluation, he/she will take it\nand make a decision. Otherwise, the manager\nwill request a re-evaluation.\n\u00b7\nDecision analysis approach. This approach aims at\ndiminishing the impact of intuition and feeling\ntowards a logical analysis of a correctly struc-\ntured problem.\nProject Decision   (PDAP)\nThe decision analysis process proposes a practical\nframework of methods and tools to promote crea-\ntivity and help people make better decisions (Keeney,\n1982). The main goal of this process is to help project\nmanagers overcome psychological pitfalls through\nsuitable techniques (Massey, Robinson, & Kaniel, 2006;\nThe PDAP is both practical and effective. It is practical,\nas it can be easily integrated into the processes in place,\nand does not create an additional level of bureaucracy;\nits effectiveness is demonstrated in the next paragraph.\nThe process includes four major phases (Virine &\nDecision framing. Decision framing helps deci-\nsion-makers identify potential problems or\nopportunities; assess business situations;\ndetermine project objectives, trade-offs and\nsuccess criteria, and finally, identify uncertain-\nties. The project manager defines the scope of\nthe decision.\nModelling the alternatives. A mathematical model\ncan help to analyse and estimate future events.\nQuantitative analysis. After the mathematical\nmodel is ready, the analysis may include a\nnumber of steps, depending on the situation.\nActual performance tracking. It includes implemen-\ntation, monitoring, and review of the decisions.\nAs Figure 1 shows, the scalability and flexibility of the\nfour phases allow effective feedbacks and adaptability.\nFigure 1: Project Decision Analysis Framework\n\u00b7 Identifying potential\n\u00b7 Problems and opportunities\n\u00b7 Assessing business situation\n\u00b7 Determining success criteria\n\u00b7 Identifying uncertainties\n\u00b7 Generating alternatives\n\u00b7Creating models for each project alternative\n\u00b7Quantifying the uncertainties\n\u00b7Determining what is most important\n\u00b7Quantifying risks associated with the project\n\u00b7Determining the value of new information\n\u00b7Deciding on a course of action\n\u00b7Implementing the best alternatives\n\u00b7Monitoring the project implementation\n\u00b7Review of decision experience\nDecision\nframing\nModelling the\nsituation\nQuantitative\nanalysis\nActual\nperformance\ntracking\nAdaptability\nSource: Adapted from Virine and Trumper (2008).\nPDAP Effectiveness\nProcess effectiveness is a metric that assesses the quality\nof the process with regard to organizational effective-\nness. It can be captured with several approaches. The\ncompeting value framework (McCartt & Rohrbaugh,\nis one of the most widely used approaches. Developed\ninitially to assess to what extent the studied organiza-\ntion is effective, this model was extended (Schilling,\nOeser & Schaub, 2007) to measure the fitness of the\nprocess to the overall organizational effectiveness. It\nhighlights four dimensions that should be balanced:\n\u00b7\n\nadequate information (empirical perspective):\nreferring to the internal process model;\n\u00b7\n\nclear thinking about this information (rational\nperspective): referring to the rational goal model;\n\u00b7\n\nflexibility and creativity in the process (political\nperspective): referring to the human relations\nmodel; and\n\u00b7\n\nsufficient participation (consensual perspective):\nreferring to the open system model.\nThe correlation between PDAP effectiveness and\norganizational effectiveness is qualitatively drawn in\nFigure 2: Correlation between PDAP Effectiveness and\nOrganizational Effectiveness in Competing Values Framework\nFlexibility\nControl\nExternal\nInternal\nHuman relations\nmodel (flexibility\nand creativity)\nModelling\nthe situation\nDecision\nframing\nQuantitative\nAnalysis\nInternal process\nmodel (adequate\ninformation)\nRational\nmodel (clear\nthinking)\nOpen system\nmodel (sufficient\nparticipation)\nDecision\nframing\nActual\nperformance\ntracking\nModelling\nthe situation\nQuantitative\nanalysis\nDecision\nframing\nQuantitative\nanalysis\nModelling\nthe situation\nDecision\nframing\nModelling the\nsituation\nQuantitative\nanalysis\nActual\nperformance\ntracking\nActual\nperformance\ntracking\nActual\nperformance\ntracking\nBroken arrows note the strength of correlation between\nPDAP phases and competing values within the\norganization.\nBalanced PDAP\nAs defined by Virine and Trumper (2008), PDAP does\nnot consider strategic alignment when implementing\nand tracking decisions. Therefore, it seems very bene-\nficial to reinforce PDAP by a suitable tool that allows\nstrategic alignment of decision-making, especially for\nlarge and sensitive projects. In this regard, balanced\nscorecard introduced by Kaplan and Norton (1992;\nBalanced Scorecard is a performance management\ntool that enables a company to translate its vision and\nstrategy into a tangible set of performance measures.\nHowever, it is more than a measuring device. The score-\ncard provides an enterprise view of an organization's\noverall performance by integrating financial measures\nwith other key performance indicators around customer\nperspectives, internal business processes, and organ-\nizational growth, learning, and innovation. (Kaplan &\nIn order to ensure a strong link with the organization's\nstrategy, the last phase of PDAP, namely actual\nperformance tracking will serve as an information\npreparation phase for Balanced Scorecard (BSC) in\nwhich the adequacy of the decision's impact is tested\nand analyzed with regards to the four perspectives (see\nFigure 3). So far, a decision is either accepted or rejected\nand feedbacks are used to improve and develop a more\nbalanced decision (see Figure 4).\nFigure 3: Project Balanced Scorecard\nFinancial perspective\nIf a project succeeds, how does the\norganization look to stakeholders?\nCustomer perspective\nHow should the project look to the client for the\norganization to achieve its vision?\nInternal perspective\nWhich project processes must be excelled in to satisfy the client?\nOrganizational learning perspective\nHow must the project contribute to organizational learning and improvement?\nVision\nThus, PDAP success will be achieved and sustained\nonly if\n\u00b7\n\nhigh quality information is available and acces-\nsible easily and systematically;\n\u00b7\n\nthe knowledge gained from projects is capitalized;\n\u00b7\n\ncompetitor's knowledge is taken permanently\ninto account;\n\u00b7\n\nproject managers (deciders), whatever their\ndecision styles are (directive, analytical, concep-\ntual or behavioural) (Rowe & Mason, 1987), are\ntrained and accustomed to the process; and\n\u00b7\n\nthis process is integrated into a suitable PM\nprocess.\nFigure 4: Balanced PDAP\nDecision framing\nModelling the situation\nQuantitative analysis\nActual performance tracking\nFinancial perspective Customer perspective\nInternal perspective\nOrganizational learning\nperspective\nProject balanced scorecard\nAdaptability\nSource: Authors' proposal.\nIn sum, PDAP will not be able to provide desired results\nin terms of project decisions improvement unless an\nintelligent PM model is adopted. Such a model will\nensure agility, knowledge capitalization and creation,\nand effective PM processes. In this perspective, the\nintelligent project-based organization model (IPBOM),\nproposed by Alami, Beidouri, and Bouksour (2013a)\ncan serve as a ground for a further MM aiming at\nimplementing, gradually and effectively, an intelligent\nPM business model (see Figure 5).\nIn the next sections, we will try to review intelligence\nand PMMM literature and propose a methodical, useful\nand practical IP3M that fits MES.\nConcept and Origin\nBased on the assumption of predictable patterns,\nMMs represent theories about how organizational\ncapabilities evolve in a stage-by-stage manner along\nan anticipated, desired or logical maturation path\n(Gottschalk, 2009). They are also termed stages-\nof-growth models, stage models or stage theories\nThe development of MMs is viewed as a matter of\ndesign science research by some Information Systems\n(IS) researchers (Becker, Knackstedt, & P\u00f6ppelbu\u00df, 2009;\nMettler & Rohner, 2009). Design science research seeks to\ncreate innovative artefacts that are useful for coping with\nhuman and organizational challenges (Hevner, March,\nDesign of MMs\nThe usefulness of MMs is rarely debated in the literature\ndespite the popularity of MMs. A few studies refer to\nthe process of MM design, and some others to qualities\nand components of MMs as design products. We will\nfocus on the design process of MMs.\nDesign Process\nAs for the process of MM design, De Bruin, Rosemann,\nFreeze, and Kulkarni (2005) and Becker, Knackstedt,\nand P\u00f6ppelbu\u00df (2009) suggest procedure models.\nDe Bruin, Rosemann, Freeze, and Kulkarni (2005)\npropose six phases intended to guide the design of a\ndescriptive MM and its advancement for prescriptive\nand comparative purposes. Becker, Knackstedt, and\nP\u00f6ppelbu\u00df (2009) derive requirements and procedure\nmodel from Hevner et al.'s (2004) design science\nguidelines; they distinguish eight phases that provide\n`a manual for the theoretically founded development\nand evaluation of maturity models'. Actually, Becker,\nKnackstedt, and P\u00f6ppelbu\u00df (2009) propose a similar\nprocess emphasizing the use of existing MMs and an\niterative development:\n1. Scope. The scope phase defines the focus and iden-\ntifies the relevant stakeholders and targeted audi-\nences. It determines the balance between complex\nreality and model simplicity.\n2. Design. The design phase addresses the require-\nments-based design and outlines the principal\nconcept of maturity, structure of levels, dimensions\nand sub-dimensions (the meta-model).\n3. Populate. In the populate phase, the corresponding\ncharacteristics are determined and the maturity\nassessment is defined, which includes the specifica-\ntion of assessment instruments.\n4. Test. The constructed model is tested on content\ncompleteness and intended model scope accuracy\nand the assessment instrument is tested for validity\nand reliability.\nFigure 5: Intelligent   Model (IPBOM) \nExternal Data/Information\nBusiness intelligence system\nRefinement\nintegration\ntransformation\nDM &\nKD\nBA\nCollection\nInformati\non\nReporti\nng\nInformati\non\nIntelligence\nFeedback and monitor\nimpact of action taken\nCollection\nConversion\nCommunication\nCountering\nRequirements\nIntelligence\nGovernance\nProject\nmanagement\nProject portfolio\nselection\nadaptability\nLessons Learned\nIntelligence\nStrategy\nOptimization and\nadaptability\nDecisions\nInternal data/Information\nt\nAcquisition\nRefinement\nStorage\n/Retrieval\nDistribution\nPresentation\nOptimization and\nSource: Alami, Beidouri and Bouksour (2013a).\n5. Deploy. The model is deployed to the initial stake-\nholders and to an independent community.\n6. Maintain. Once deployed, the model needs to be\nkept in use and for a sufficient period of time--say,\na couple of years to ensure its evolution.\nFor designing and populating MMs, different\nexploratory research methods and combinations of\nthese methods are proposed. Commonly mentioned\nmethods are literature analysis, Delphi and case studies\nand focus groups (Becker, Knackstedt, & P\u00f6ppelbu\u00df,\nare less frequently used for constructing MMs \n(Fraser,\nMoultrie, & Gregory, 2002), as these models require a\nsound theoretical foundation. Testing is also mostly\ndone qualitatively. The choice of the relevant research\nmethod is influenced by the scope, stakeholders, and\ntargeted audiences (Lahrmann & Marx, 2010).\nComparison and Evaluation of Most Widely\nUsed MMs\nMethodical Analysis of MMs\nMettler and Rohner (2009) propose a classification\nscheme based on three different dimensions, namely\ngeneral model attributes, MM design and MM\nuse. These dimensions contain 16 attributes that\ncharacterize an MM. For the specificity of this work,\nonly the following attributes are considered: origin,\nmaturity concept, reliability, and assessment. Some\nother attributes are added for their relevance: structure,\nprimary focus, assessor (self-assessment or third-party\nassessment), assessment, decision-making, culture and\nstrategic alignment concerns. The structure attribute\nclassifies the model into process-based, staged-based\nand system-based categories (McBride, Henderson-\nSellers, & Zowghi, 2004). Staged models require total\nmaster of a process before moving forward while\nsystem-based models are mainly based on continuous\nimprovement approach in which maturity is obtained,\nin addition to the implementation of new processes, by\nthe improvement of already established processes.\nProject   Models (PMMMs)\nTable 1 provides a quick summary of the most popular\nproject management MMs found in literature and\nexamined by this research:\nLimitations of Existing Frameworks\nIn general, the existing PMMMs suffer from the\nfollowing limitations:\n\u00b7 The models add bureaucratic red tape to their\n\u00b7 Although aimed at increasing PM maturity, the\nmodels seem to pay little attention to project\nknowledge capitalization and how learning from\npast experience can help improve PM processes.\nWhen mentioned in the models, project knowledge\nmanagement is to be carried out to appropriately\nclose a project from an administrative point of view.\nIn most models, project reviews are in place only at\nthe highest levels of maturity.\nIntelligent MMs\nTable 2 provides a summary of the most popular intelli-\ngent MMs found in literature and their evaluation.\nEvaluation\nSome researchers argue that MMs oversimplify reality\nand lack empirical foundation (Benbasat, Dexter,\nDrury, & Goldstein, 1984; De Bruin, Rosemann, Freeze\npropose adding a configurability aspect to MMs for the\nnecessary flexibility required to overcome internal and\nexternal changes. King and Kraemer (1984) postulate\nthat MMs should focus on factors driving evolution\nand change rather than a sequence of levels towards a\npredefined `end state'. Intelligence MMs are generally\nprocess-based models.\nComparison of PMMMs and Intelligent MMs\nTable 3 summarizes the comparison of MMs with\nregard to its main attributes.\nWhy a New Project   Model?\nThe need for a PMMM is derived from the need of a\nnew intelligent business model that combines flexi-\nbility and agility for MECs. Major benefits of I3PM are\nTable 2: A Literature Review and Evaluation of Intelligence MMs\nName Author Structure Evaluation\nGartner's maturity\nmodel (E)\n(Rayner &\nSchlegel,\nIt defines five levels (with generic labels like\nunaware, tactical, focused, strategic and\npervasive) that are described textually.\n\u00b7\nDoes not define dimensions, but gives textual hints\nconcerning sponsoring, organizational structure, scope\nof BI initiative and metrics. The maturity concept is\nobject centric.\n\u00b7\nReliability is not documented.\n\u00b7\nApplication needs third-party assistance.\nBIMM (business\ninformation\nmaturity model) (F)\n(Williams\n& Williams,\nConcentrates on three success factors\n(alignment and governance, leverage and\ndelivery) and seven key process areas.\n\u00b7\nFocuses on the management perspective especially from\nthe cultural perspective.\n\u00b7\nWell documented with the series of questionnaires to\nassist the users to perform self-evaluation (Rajteri, 2010).\n\u00b7\nHowever, criteria to evaluate the maturity level are not\nwell defined.\nBIDM (business\nintelligence\ndevelopment\nmodel) (G)\n(Sacu &\nConcentrates on three perspectives: people,\nprocess and technology.\nSix stages: predefined reporting, data marts,\nenterprise-wide data warehouse, predictive\nanalytics, operational BI and business\nperformance management (BPM).\n\u00b7\nUsed for business intelligence development rather than\nbusiness intelligence implementation.\n\u00b7\nNot well documented and criteria to evaluate the\nmaturity level are not well defined.\n\u00b7\nConcentrates on the technical aspects rather than\nbusiness point of view.\nTable 1: Structure and Evaluation of PMMMs cited in the Literature\nMM Authors Structure Evaluation\nCapability maturity\nmodel for software\n(CMM\u00ae or CMM-\nSW\u00ae) (A)\n(Paulk, Curtis,\nChris, & Weber,\nA staged model with five maturity levels\n(initial, repeatable, defined, managed and\noptimizing). Each maturity level is composed\nof key process areas (KPAs) which when\nperformed collectively identify requirements\nfor achieving each maturity level.\nCMM is often considered too voluminous (over 500\npages) and complex in nature.\nRequires large investment amounts and needs a long\ntraining time.\nThere is little emphasis on lessons learned from ongoing\nretrospective evaluation of the project management\nprocesses.\nProject management\nmaturity model\n(PMMM) (B)\nA system based model with five maturity\nlevels (common knowledge, common\nprocesses, singular methodology,\nbenchmarking and continuous improvement).\nIts generality and descriptive nature offer little assistance\nas to how an organization can actually move up\nthe maturity curve; except for use in benchmarking\ninformation to improve the PM methodology, there is no\nconsideration of project knowledge management.\nOrganization project\nmanagement maturity\nmodel OPM3 (C)\nA system-based model with five main\ncomponents:\n \u00b7 Directory of best practices\n \u00b7 Directory of capabilities\n \u00b7 List of observable outcomes\n \u00b7 List of key performance indicators\n \u00b7 Improvement plan directory\nAlthough many implementations have been successful,\nthis model seems to be complicated and needs\nimportant training effort and must be managed by a\nwell-established project management office (PMO).\nProjects in controlled\nenvironments\nDefines four key attributes of each project. It\nis divided into stages, each being considered a\ndistinct unit for management purposes.\nA stage is compartmentalized into sub-\nprocesses and has well-defined activities, finite\nlifespan and organizational structure.\nThe deliveries of the stage products indicate\nthe completion of that stage. The project\nstages correspond to the steps in a typical\nproject life cycle.\nDespite several benefits, this model offers--sequential\nand logical roadmap and well-documented\nmethodology--it is not an assessment tool and does\nnot measure PM on a maturity scale. It lacks details\nwith regard to all PM knowledge areas. Also, it does not\naddress the issue of how organizations can continuously\nimprove their PM processes.\nSource: Authors' compilation.\nTable 2 continued\nEBIM (the\nenterprise business\nintelligence maturity\nmodel) (H)\n(Chee-Sok,\nYee-Wai, &\nThis model consists of five core maturity levels\nand four key dimensions, namely information\nquality, master data management, warehousing\narchitecture and analytics.\n\u00b7\nIt is relatively new and not well documented with best\npractices and feedbacks from previous experiences.\n\u00b7\nReliability is documented.\n\u00b7\nDoes not consider knowledge issues.\nIPBOMM (intelligent\nproject based\norganizations\nmaturity model) (I)\n(Alami,\n(Beidouri, &\nBouksour,\nDeveloped to assist companies operating in\nengineering sector so that they can acquire\nagility and flexibility.\nIt is a five-staged model and each stage is\ndefined through specific key process areas.\n\u00b7\nIt is relatively new and not well documented with best\npractices and feedbacks from previous experiences.\n\u00b7\nReliability is documented.\nSource: Authors' compilation.\nTable 2 continued\nTable 3: Comparison of Intelligent MMs\nMM Origin Maturity Concept Primary Focus Assessor Assessment Concerns\n(1) Practice and\nacademic\nProcess Software industry Self-assessment Unclear Strategic alignment\nculture\n(2) Practice and\nacademic\nProcess Project-driven\norganizations\nSelf-assessment Questionnaire Strategic alignment\nculture\n(3) Practice and\nacademic\nProcess Project-driven\norganizations\nSelf-assessment\u00ad\nThird-party\nassessment\nUnclear Strategic alignment\nculture\ndecision-making\n(4) Practice and\nacademic\nProcess Project-driven\norganizations\nSelf-assessment Unclear Unclear\n(5) Practice Object General Third-party assisted Unclear Strategic alignment\n(6) Academic Object IT industry Unclear Questionnaire Unclear\n(7) Practice Process IT industry Self-assessment Unclear Strategic alignment\nculture\ndecision-making\n(8) Academic People\nand Process\nUnclear Unclear Questionnaire Unclear\n(9) Academic People and Process Project-based\norganizations\nSelf-assessment Unclear Strategic alignment\ndecision-making\nSource: Authors' compilation.\nsummarized in Table 4. These benefits are derived from\nIPBOMM model (Alami, Beidouri, & Bouksour, 2013b)\nand reinforced mainly by the introduction of the PM\nmethodology.\nExcept for IPBOMM, MMs analysed above do not\ncombine PM maturity and intelligence maturity, and\nonly a few of them present clear guidance towards\ndesired maturity. These reviewed models are either\nstable but rigid process-based models or flexible with\na considerable risk of instability, especially for devel-\noping countries' businesses. In addition, they are\nperceived as complicated and adding to bureaucracy\nlevels rather than being flexible. An effective MM\nshould rather reflect the actual concerns of the activity\nwith regard to its constraints and challenges.\nTo this effect, authors propose an IP3M based on a\ntypical case study analysis in order to take into consid-\neration, as far as possible, the specificities of MES. IP3M\nis intended to balance between rigidity and stability,\nensured by staged models and flexibility provided by\nthe system-based models.\nMethodology\nThe purpose of this section is to follow MMs' design\nprocess presented earlier to come up with the expected\nIP3M. This process includes six major phases: scope,\ndesign, populate, test, deploy, and maintain phases.\nAuthors are more concerned about the first four\nphases, as deployment and maintenance wil llikely\ntake several years.\nMixed methods research is applied to these phases.\n`Mixed methods research is an approach that combines\nquantitative and qualitative research methods in the\nsame research inquiry. Such work can help develop\nrich insights into various phenomena of interest that\ncannot be fully understood using only a quantita-\ntive or a qualitative method' (Viswanath, Susan, &\nTable 5 exhibits methods and methods' type used to\ndevelop design process phases.\nTable 5: Methods and Methods' Type Used to Develop Design\nProcess Phases\nPhase Method\nMethod's\nType\nScope,\nDesign and\nPopulate\nA case study of a typical Moroccan\nengineering company (MEC)\nQualitative\nA sample of 15 project managers\u00ad\nexperts working in MEC and having\ncapitalized an average of 15 years'\nexperience within 12 different activities\nQuantitative\nAnalytic generalization Qualitative\nTest\n(validation)\ndifferent MECs\nQuantitative\nDouble-round experts (projects\nmanagers) interviews\nQualitative\nSource: Adapted from Alami, Beidouri, and Bouksour (2013c).\nTable 4: Major Benefits of New Intelligent Business Model Dimensions\nModel\nDimensions\nBenefits\nStrategic\nManagement\nCritical\nSuccess\nFactors\nRisk\nManagement\nImprovement\nof Value\nCreation\nCompetitive\nintelligence\n*Adequate and quick response to external opportunities and\nthreats.\n*Effective management of customers' explicit, implicit and\nlatent expectations.\n*Diversification of MEC's book order.\n*Updated external information for opportunity decision\nanalysis.\n+++ ++ ++ +\nBusiness\nintelligence\n*Business analytic and real-time approaches to optimize\nproject and general resource allocation.\n*Strong basis for opportunity decision analysis.\n*High quality-reliable accurate and comprehensive\ninformation for decision analysis.\n*Gathering information from different sources and ensuring\nmastery in cost.\n*Projects portfolio identification and optimization.\n+ +++ ++ +++\nKnowledge\nmanagement\n*Technical and theoretical knowledge development.\n*Help establish a corporate memory that will serves as basis\nfor organizational learning.\n++ ++ ++ +++\nProject\nmanagement\n*Monitors projects risks.\n*Focuses on relevant projects in terms of quality,\nproductivity, client satisfaction, supply chain and internal\norganization.\n*Strengthens leadership image.\n*Optimizes managerial and commercial efforts.\n+ + ++ +++\nGovernance *Effective information sharing policy.\n*Transparent accountability framework.\n*Enables project managers to make informed decision through\nmore decentralized decisions.\n*Modernizes management tools and techniques.\n+++ +++ ++ +++\nSource: Adapted from Alami, Beidouri, and Bouksour (2013c).\nNotes: `+'stands for little positive impact, `++' for moderate positive impact and `+++' for important positive impact.\nRelevance of Case Study Research Method\nAcase study is a research strategy that empirically exam-\nines a concrete example in its actual environment. It can\ninvolve a combination of qualitative and quantitative\nanalyses, whereby the specific procedure depends on the\ncharacteristics of each case study (Rejc, 2005).\nCase study research excels at bringing to us an under-\nstanding of a complex issue or object and can extend\nexperience or add strength to what is already known\nthrough previous research. Case studies emphasize\ndetailed contextual analysis of a limited number of\nevents or conditions and their relationships.\nResearcher Robert K. Yin defines the case study\nresearch method as an empirical inquiry that inves-\ntigates a contemporary phenomenon within its real-\nlife context; when the boundaries between phenom-\nenon and context are not clearly evident and in which\nCritics of the case study method believe that the study\nof a small number and the uniqueness of studied\ncases can offer no grounds for establishing reliability\nor generality of findings. Others feel that the intense\nexposure to study of the case biases the findings. Some\ndismiss case study research as useful only as an explor-\natory tool. Yet, researchers craft studies of real-life situ-\nations, issues and problems.\nIn this research, the uniqueness of the case study\nresearch method will be reinforced by an analytic gener-\nalization of the key findings in the context of Moroccan\nproject-based companies as well as in companies dedi-\ncating a department for project governance.\nGeneralization Method\nEisenhardt (1989) and Eisenhardt and Graebner\n(2007) argue that binding the emergent theory\nwith the existing literature strengthens the internal\nvalidity, generalization (external validity) and the\nlevel of theory building from case study research.\nInternal validity demonstrates a causal relationship,\nin which certain conditions lead to other conditions;\nand external validity tests whether a study's find-\nings could be generalized beyond the immediate case\nThere are two kinds of generalization from case to theo-\nry: statistical generalization and analytic generalization\nestablished by an inference made about a population on\nthe basis of empirical data collected about a sample (Yin,\nnot be considered to be the method of generalizing the\nAnalytic generalization, established by the process\nas an existing theory, is employed as a framework\nwith which to collate the empirical results of the case\nstudy; then, when more cases appear to support the\nsame theory, replication can be claimed (Mccutcheon\n& Meredith, 1993). Analytic generalization can be\nused in either single case or multiple case studies (Yin,\nThis study employs analytic generalization in a single\ncase study design. A single case study (i.e., MEC) is\nused for advocating or refining existing theories. Then,\nthe theory established from the case study could extend\nto other ECs.\nStatistical Generalization\nWhile quantitative methods are used in scope, design,\nand populate sequences to strengthen the findings of\nMEC case study with a sample of 15 project manag-\ners-experts working in MEC and having capitalized\nan average of 15 years' experience within 12 different\nactivities, their main use is in validation sequence.\nIn this sequence, a sample of 13 experts working in\n12 different MECs --members of the Federation of\n  and Consulting Companies\n(FMCI)--were contacted and interviewed.\nAnalytic Generalization\nTable 6 summaries the analytic generalization of MEC's\nfindings to large and small ECs in Morocco.\nScope of IP3M\nMES is chosen for its relevance to the economy and\nbecause it represents the majority of Moroccan PBOs.\nCase study research method is followed to develop a\nsuitable MM for the MES. The organization used in the\ncase study is a large-sized company operating in the\nMES called MEC for confidentiality consideration. Data\nused in this case is collected from:\n\u00b7\n\navailable public information in company's offi-\ncial websites;\n\u00b7\n\npublished activity reports of the company and\nthe holding;\n\u00b7 notes of information, presentations, publications,\nand published statistics of FMCI; and\n\u00b7 \nnational conferences, studies, and workshops\nheld on engineering sector strategic development.\nMEC Case Study\nThe Moroccan multi-disciplinary EC (called MEC for\nconfidentiality reasons) operates across four different\nbusiness units: construction, water and urban plan-\nning, large infrastructure and development. It is the\nnationally recognized leader in the marketplace. The\ncompany has a commitment to service, quality, and\nTable 6: Analytic Generalization of MEC's Findings for MES\nCase Study\nMain Points\nMEC\nLarge Engineering\nCompanies\nSmall Engineering\nCompanies\nStakeholders Sovereign fund\nLarge national and international\ncompanies\nPrivate\nHuman resource qualification\nMore than two engineers per three\ntechnicians\n+ +\nActivities Multi-disciplinary + Specialized\nStrategic Management\nLocation Between Rabat and Casablanca + +\nMission Investment optimization + +\nVision\nGeneral studies, project management\nactivities and training\n+ +\nObjectives\nRegional leadership, exportation and\nstrategic alignment with holding\n+ A reasonable market share\nStrategies\nDiversification, development of new\nhigh value-added services, alliance, etc.\n+ +\nPolitical factors + + +\nEnvironmental factors + + +\nSocial factors + + +\nTechnical factors + + +\nCritical success factors\nKnowledge, cash flow, cost reduction\nand modernization\n+ +\nBusiness Design\nOrganization + + +\nCulture + + \u00ad\nKnowledge issues + + +\nInformation system + + \u00ad\nQuality management system + + \u00ad\nValue Chain\nCommercial process + + +\nSupport process + + +\nProject management process + + \u00ad\nManagement process + + \u00ad\nSource: Adapted from Alami, Beidouri, and Bouksour (2013c).\nNotes: + is used for similarity and \u00ad for difference.\nTable 7: The Intelligent     (IPBOMM)\n(competitive leverage)\nOptimization and Adaptability\nLevel 3 (intelligence\nutilization)\nDecision-making and\nproblem-solving\nDecision-making and problem-solving Project\nteams competency\ndevelopment\nGeneralization to all projects\nGeneralization to all projects \nApplication to most relevant\nprojects\nApplication to most relevant\nprojects\nProject managers'\ncompetency\nLevel 2 (intelligence\nawareness)\nGeneralization to all\nprojects\nApplication to most relevant\nprojects\nApplication to most relevant\nprojects Support staff\ncompetency\nLevel 1 (intelligence\nasset identification)\nApplication to most\nrelevant projects\nData governance (100%) Environmental mapping\nProject intelligence\ncentre\nKnowledge\nmanagement (KM)\nLevel 0 (unawareness)\nNo data governance\nCompetitors' information is not (or rarely) considered\nData are dispersed within multitude data sources\nRequired quality of information is not documented\nNo (or individual) project knowledge capitalization initiatives\nLevels KM BI CI Governance\nSource: Alami, Beidouri, and Bouksour (2013b).\nhigh standards of safety and business ethics (sustain-\nable development chart). MEC is a national sovereign\nfund subsidiary that has a good standing with regards\nto project owners.\nMEC carried out more than 3,000 projects in Morocco\nand abroad. It follows a matrix management structure\nwith a Board of Directors, and consists of a branch, five\ndivisions, 11 technical departments and four supply\nutives. It secures staff loyalty by promoting responsi-\nbility and teamwork while fostering innovation and\nimproving technical skills.\nIP3M Design\nThe intelligent PBOMM (IPBOMM), already developed\nby Alami, Beidouri and Bouksour (2013b) (see Table 7),\nis introduced to a sample of 15 project managers--\nexperts working in MEC and having capitalized an\naverage of 15 years' experience within 12 different\nactivities: building, urban planning, energy, agriculture,\nPM services and environment and software develop-\nment. In order to develop an initial version of MM that\nconsiders the challenges faced through several projects\nthey managed, experts were asked to propose an adap-\ntation of IPBOMM to include PM maturity dimensions.\nThey were also asked to review IPBOMM components\nand transition conditions. Actually, this first task was\nsomewhat easy, as IPBOMM is a staged model tailored\nfor a sector in which companies and different contribu-\ntors are accustomed to PM terminology.\nThis first step resulted in the following five levels of\n\u00b7 Level 0 (unawareness). The organization is not aware\nof the crucial role of high quality information and\naccordingly intelligence initiatives are either indi-\nvidual or non-existent. No PM process is defined\nand documented; however, there may be isolated\ninitiatives to establish particular processes like\nproject initiation and closure processes.\nTable 8: IP3M Initially Proposed by Experts\n(competitive\nleverage)\nOptimization and Adaptability\n(intelligence\nutilization)\nPM processes of all\ncontrolled\nDecision-making and\nproblem-solving\nDecision-making and problem-solving\nProject teams competency\ndevelopment\nGeneralization to all\nGeneralization to all\nApplication to most\nrelevant projects\nApplication to most\nrelevant projects\nProject managers\ncompetency development \n(intelligence\nawareness)\nPM processes of most\nrelevant projects (60%)\nare controlled Generalization to all\nprojects\nApplication to most\nrelevant projects\nApplication to most\nrelevant projects\nSupport staff competency\nPM processes are\n(intelligence\nasset identifica-\ntion)\nApplication of PM\nprocesses to most relevant\nApplication to most\nrelevant projects\n(60%) Data governance\nEnvironmental\nProject intelligence centre\nDefined PM processes\nKM processes\n(unawareness)\nNo data governance\nCompetitors' information is not (or rarely) considered\nData are dispersed within multitude data sources\nRequired quality of information is not documented\nNo (or individual) project knowledge capitalization initiatives\nNo (or ad hoc) PM processes\nLevels PM KM BI CI Governance\nSource: Authors' compilation.\n\u00b7 Level 1 (project intelligence asset identification).\nIntelligence awareness journey begins with capi-\ntalization of the maximum of project knowledge\nthrough the establishment of adequate processes.\nInternal and external data sources are identified and\nPM processes are defined and applied to the most\nrelevant project with regard to an adequate indi-\ncator chosen by the organization (e.g., turnover). A\nproject intelligence centre should manage the matu-\nrity journey and begin by a suitable competencies\ndevelopment policy. (In some PBOs, this task can be\nhandled by a PM office.)\n\u00b7 Level 2 (project intelligence awareness). Intelligence\nprocess and systems are finalized and knowledge\nmanagement (KM) and PM processes are extended\nto cover the entire project portfolio. Simultaneously,\nthe project processes controlling activities are started\nby the most relevant projects. Besides, support staff\nis ready to utilize BI and CI processes in a significant\nportion of the projects.\n\u00b7 Level 3 (project intelligence utilization). Project\nmanagers and project teams are empowered by\nintelligent decision supportive tools and well-\nestablished PM processes. Accordingly, they start\nto base their decisions on high quality internal\nand external information as they have already\ndeveloped the necessary know-how.\n\u00b7 Level 4(competitive leverage). More familiar with the\nuse of intelligence, project manager, project teams\nand support staff begin to search for ways to sustain\na real competitive advantage through an agile\noptimization and adaptation effort with regard to\ncompetitors, stakeholders, and economic framework.\nIP3M Populate Phase\nThe IP3M in Table 8 proposes some key process areas\n(KPAs),namelyPMprocesses,KMprocesses,competitive\nintelligence (CI) processes, business intelligence (BI)\nprocesses,governancepolicyandestablishmentofproject\nintelligence centre with their related Key Performance\nIndicators (KPI) and the required percentage of\ncompletion. Some KPAs are deliberately omitted\n(decision-making, problem-solving, optimization and\nadaptability) to ensure necessary flexibility to succeed in\nthe implementation and adaptation of the model. It is\nup to the project intelligence centre to define the exact\nmeaning of 100 per cent of completion of each KPA.\nAlso, it is up to the top management, through the project\nintelligence centre, to adopt the suitable set of processes\nthat fits at best with organization culture and ambitions.\nFurthermore, this model is supposed to be easy to use,\nscalable and can use processes defined in an already\nexisting Intelligent MM or PMMM.\nThe transition from one level to another is conditioned\nby the completion of related KPAs.\nFinally, the assessment of percentage of completion of\nevery KPA will result in maturity-level assessment.\nIn order to test the applicability, validity and relia-\nbility of the proposed model, 12 double-round inter-\nviews were conducted by authors with a sample of 13\nexperts working in 12 different ECs in Morocco with\nalmost the same characteristics in terms of experience\nand activities. This approach is the most suitable test\nmethod in the case of MECs as the latter are neither\nfamiliar with MM terminology nor with intelligent\nsystem use.\nFirstly, experts were asked to comment on the\nIP3M presented in Table 8. Then, they had to debate\nand comment on the proposed MM in terms of its\ncomponents, transition conditions and the relevance\nof governance in developing soft skills competencies.\nThey agreed upon the four essential needs of PBOs\noperating in engineering sector: project knowledge\nmanagement, internal and external high quality infor-\nmation and, finally, effective project governance.\nThe final version of IP3M had considered experts'\nremarks and recommendations (see Table 9).\nFINDINGS\nMain Remarks and Recommendations\nExperts agreed upon the relevance of such model in\nassessing agility of ECs. However, they recommended\na gradual application of KM, BI, and CI processes\nto projects, starting with the most relevant projects\nbefore generalizing to the rest of the projects. They\nalso proposed `forecasted turnover' and projects\nstrategic ranking as criteria for selecting the most\nrelevant projects. Besides that, they agreed on the\nimportance of feedback to ensure partial continuous\nimprovement especially in establishing and general-\nizing PM and KM processes. With regard to transi-\ntion conditions, experts recognized the importance\nof fulfilment of different KPAs before moving to the\nupper level. With regard to governance maturity, they\nrecommended the completion of the establishment of\nproject intelligence centre before moving to project\nintelligence asset identification level. Finally, they\nrecommended adding the following points to IP3M\nlevels description:\n\u00b7 Level 1 (project intelligence asset identification):\n\u00b0 \nProcess definitions overlap with partial applica-\ntion to take account of feedback.\n\u00b0 PM intelligence centre is established.\n\u00b7 Level 2 (project intelligence awareness):\n\u00b0 \nProcess standardization overlap with partial\ncontrol to take account of feedback.\n\u00b0 \nSupport staff competency development (basic\nand necessary competencies).\n\u00b7 Level 3 (project intelligence utilization):\n\u00b0 \nProcess control is put in place and applied to\nrelevant project.\n\u00b0 \nProject managers' competency develop-\nment is fully completed (basic and necessary\ncompetencies).\n\u00b0 \nProject teams' competency development (basic\nand necessary competencies).\n\u00b0 \nUse of project knowledge and information in\nmaking informed and intelligent decision.\n\u00b0 \nProject managers start using balanced PDAP in\nrelevant decisions with regards to a given criteria.\n\u00b7 Level 4 (competitive leverage):\n\u00b0 \nBalanced PADP is generalized to almost rele-\nvant projects.\n\u00b0 \nProcess control and generalization concepts are\nreframed and revisited based on lessons learned\nfrom project decisions.\nLimitations of IP3M\nThe first and common limitation to all kinds of MMs\nis that they are often viewed as inflexible because of\nthe disciplinary steps they embrace for improvement.\nThey are feared to add to an organization's\nbureaucratic red tape, making it difficult for an\norganization to find creative solutions to technical\nproblems (Herbsleb, Zubrow, Goldenson, Hayes, &\nTable 9: Intelligent    \n(competitive\nleverage)\nOptimization and Adaptability (definition, generalization and control)\nProject\nIntelligence\nUse\nPDAP is applied to all project decisions\nLevel 3 (project\nintelligence\nutilization)\nDecision-making and problem-solving (PDAP applied to most relevant decisions 20%)\nPM processes of all\ncontrolled\nKM processes\nof all projects\ncontrolled\nBI processes of all projects (100%) are\ncontrolled\n\nCI processes of all projects\nProject teams'\ncompetency\ndevelopment\nProject\nmanagers'\ncompetency\ndevelopment\nLevel 2 (project\nintelligence\nawareness)\nPM processes of most\nrelevant projects (60%)\nare controlled\nKM processes\nof most relevant\nare controlled\nBI processes of most relevant projects\n(60%) are controlled\nCI processes of most\nrelevant projects (60%)\nare controlled\nPM processes are\nKM processes\ngeneralization\nto all projects\nBI processes applied to most relevant\nCI processes generalized\nSupport staff\ncompetency\ndevelopment \nBI processes defined \nData governance processes generalized\nLevel 1 (project\nintelligence\nasset\nidentification)\nDefined\nPM\nprocesses\nApplication\nof PM\nprocesses\nto most\nrelevant\nprojects\nKM processes\ndefined\nApplication\nof KM\nprocesses\nto most\nrelevant\nprojects\nData\ngovernance\nprocesses\ndefined\nData\ngovernance\nprocesses\napplied\nto most\nrelevant\nprojects\nCI\nprocesses\n defined\nCI processes\napplied to\nmost relevant\nProject\nmanagement\nintelligence\ncentre\nEnvironmental mapping\n(unawareness)\nNo data governance\nCompetitors' information is not (or rarely) considered\nData are dispersed within multitude data sources\nRequired quality of information is not documented\nNo (or individual) project knowledge capitalization initiatives\nNo (or ad hoc) PM processes\nLevels PM KM BI CI Governance\nSource: Authors' compilation.\nREFERENCES\nAlami, M. O., Beidouri, Z., & Bouksour, O. (2013a). Towards\nan intelligent project based model (IPBOM). International\nAlami, M. O., Beidouri, Z., & Bouksour, O. (2013b). An\nintelligent project based organization maturity model\n(IPBOMM) for Moroccan engineering companies. Asian\nAlami, M. O., Beidouri, Z., & Bouksour, O. (2013c).\nOpportunity analysis of an intelligent project based\norganization model (IPBOM) for Moroccan project based\norganizations: Application to engineering sector. Asian\nBarclay, C. (2008). Towards An integrated measurement of\ninformation system project performance: The project\nperformance scorecard. Information Systems Frontiers,\nBecker, J., Knackstedt, R., & P\u00f6ppelbu\u00df, J. (2009). Developing\nmaturity models for IT management: A procedure model\nand its application. Business and Information Systems\nBenbasat, I., Dexter, A. S., Drury, D. H., & Goldstein, R. C.\n(1984). A critque of the stage hypothesis: Theory and\nempirical evidence. Communications of the ACM, 27(5),\nWith regard to the test method, experts with an\naverage of 15 years' experience but representing\njust about 9 per cent of the PM professionals were\ninterviewed, and that raised serious questions\nabout the deployment and professionals' adherence\nto such organizational change (Alami, Beidouri, &\nFurthermore, as the IP3M is in the deploying phase\nin MEC and as Moroccan businesses are not that\nfamiliar with the maturity terminology, reaping IP3M\nbenefits may take a long time. Meanwhile, because\nthe results take time to be witnessed and the models\ncan be expensive to implement, some organizations\nmight not perceive their benefits (Alami, Beidouri, &\nFinally, the risk pointed out by Herbsleb, Zubrow,\nGoldenson, Hayes, and Paulk (1997) stipulating that\n`Some organizations by becoming \"mature\" fear that\nthey will also develop into risk adverse entities, afraid\nto take risky endeavours (but potentially high pay-off)\nbecause they may lose their high maturity rating' can\nbe a serious limitation of MM.\nCONCLUSION\nThis article proposes and tests a prescriptive IP3M for\ncompanies working in MES. Researchers first adapted a\nbalanced PDAP and then used it in designing method-\nically a hybrid MM--IP3M that balances between\nrigidity and stability, ensured by staged models and\nflexibility provided by system-based models.\nIn addition to a deep literature analysis, authors used\nan agreed-upon MM development methodology with a\ntypical case study and multi-round experts' interview\nto propose, test and validate the model. A Moroccan\nlarge-sized EC has served for developing the IP3M\nwhile experts' interviews methodology was adopted\nfor testing and validating findings.\nThe combination of case study research method and\nexperts' interview technique is supposed to reinforce\nusefulness and applicability of the model in the case of\nMES. However, a more general quantitative test ques-\ntionnaire, targeting a large range of project managers\nworking in a large sample of MES, can be conducted\nto investigate the perception of future users all the way\nwith the potential model deployment constraints.\nBresnen, M., Goussevskaia, A., & Swan, J. (2004). Embedding\nnew management knowledge in project-based organiza-\nChee-Sok, T.,Yee-Wai, S., & William,Y. (2011).Amaturity model\nof enterprise business intelligence. IBIMA (International\nBusiness Information Management Association), 2011, Article\nDe Bruin, T., Rosemann, M., Freeze, R., & Kulkarni, U. (2005).\nUnderstanding the main phases of developing a matu-\nrity assessment model. Proceedings of the Australasian\nConference on Information Systems (ACIS), Sydney.\nEisenhardt, K. M. (1989). Building theories from case\nstudy research. Academy of Management Review, 14(4),\nEisenhardt, K. M., & Graebner, M. E. ( 2007). Theory building\nfrom cases: Opportunities and challenges. Academy of\nFIDIC (International Federation of Consulting Engineers).\nhttp://fidic.org/sites from http://fidic.org/sites/\nFMCI (Moroccan Federation of Consulting and Engineering).\n(2011). Annuaire des adh\u00e9rents-Rabat (FMCI ed.).\nMcBride, T., Henderson-Sellers, B., & Zowghi, D. (2004).\nProject management capability levels: An empir-\nical study. Proceedings of the 11th Asia-Pacific Software\nEngineering Conference (APSEC'04), Busan, South Korea,\nMcCartt, A. T., & Rohrbaugh, J. (1995). Managerial openness\nto change and the introduction of GDSS: Explaining\ninitial success and failure in decision conferencing.\nMcCormack, K., Willems, J., van den Bergh, J.,\nDeschoolmeester, D., Willaert, P., Stemberger, M. I., et\nal. \n(2009). A global investigation of key turning points in\nbusiness process maturity. Business Process Management\nMccutcheon, D. M., & Meredith, J. R. (1993). Conducting\ncase study research in operations management. Journal\nMettler, T., & Rohner, P. (2009). Situational maturity models\nas instrumental artifacts for organizational design.\nProceedings of DESRIST, New York.\nNegash, S., & Gray, P. (2008). Business intelligence. In F.\nBurstein & C. W. Holsapple (Eds), Handbook on deci-\nSpringer.\nNiebecker, K., Eager, D., & Kubitza, K. (2008). Improving\ncross-company management performance with a collab-\norative project scorecard. International Journal of Managing\nOGC (Office of Government Commerce). (2009a). Managing\nsuccessful projects with PRINCE2TM, TSO. UK: The\nStationery Office.\nOGC (Office of Government Commerce) (2009b). Directing\nsuccessful projects with PRINCE2TM, TSO. UK: The\nStationery Office.\nPaulk, M. C., Curtis, B., Chris, M. B., & Weber, C. (1993).\nCapability maturity model for software (Version 1.1)\n(CMU/SEI Report Number: CMU/SEI-93-TR-24).\nSoftware Engineering Institute. Retrieved 15 January,\n2013 from http://resources.sei.cmu.edu/asset_files/\n  Institute (PMI). (2008a). Organizational\nproject management maturity model (OPM3) (2nd ed.).\nNewtown Square, PA:   Institute.\n  Institute (PMI). (2008b). A guide to the\nproject management body of knowledge: PMBOK Guide (4th\ned.). Newtown Square, PA:   Institute.\n  Institute (PMI). (2013). A guide to the\nproject management body of knowledge: PMBOK Guide (5th\ned.). Newtown Square, PA:   Institute.\nQuinn, R. E., & Rohrbaugh, J. A. (1981). A competing\nvalues approach to organizational effectiveness. Public\nFraser, P., Moultrie, J., & Gregory, M. (2002). The use of matu-\nrity models/grids as a tool in assessing product devel-\nopment capability. Proceedings of the IEEE International\nEngineering Management Conference, Cambridge, UK,\nGottschalk, P. (2009). Maturity levels for interoperability in\ndigital government. Government Information Quarterly,\nHerbsleb, J., Zubrow, D., Goldenson, D., Hayes, W., &\nPaulk, M. (1997). Software quality and the capability\nmaturity model. Association for Computing Machinery.\nHevner, A. R., March, S. T., Park, J., & Ram, S. (2004). Design\nscience in information systems research. MIS Quarterly,\nJohnson, J. (2006). My life is failure. West Yarmouth, MA: The\nStandish Group, International.\nKaplan, R. S., & Norton, D. P. (1992). The balanced score-\ncard: Measures that drive performance. Harvard Business\nKaplan, R. S., & Norton, D. P. (1996a). Using the balanced\nscorecard as a strategic management system. Harvard\nKaplan, R. S., & Norton, D. P. (1996b). Balanced scorecard:\nTranslating strategy into action. Boston, MA: Harvard\nBusiness School Press.\nKeeney, R. L. (1982). Decision analysis: An overview.\nKerzner, H. (2001). Strategic planning for project management\nusing a project management maturity model. New York:\nJohn Wiley and Sons.\nKerzner, H. (2004). Project management best practices: Achieving\nglobal excellence (1st ed.). Hoboken, NJ: John Wiley &\nSons.\nKerzner, H. (2005). Using the project management maturity\nmodel: Strategic planning for project management (2nd ed.).\nHoboken, NJ: John Wiley & Sons.\nKerzner, H. (2006). A systems approach to planning, scheduling\nand controlling (9th ed.). Hoboken, NJ: John Wiley & Sons,\nInc.\nKing, J. L., & Kraemer, K. L. (1984). Evolution and organiza-\ntional information systems: An assessment of Nolan's\nLahrmann, G., & Marx, F. (2010). Systematization of matu-\nrity model extensions. Proceedings of DESRIST 2010, St.\nMassey, C., Robinson, D., & Kaniel, R. (2006). Can't wait to\nlook in the mirror: The impact of experience on better-\nthan-average effect. Paper presented at INFORM Annual\nMeeting, Pittsburgh, PA (November 5\u00ad8).\nMcAuliffe, T. P. (2005). The 90 % solution: A consistent approach\nto optimal business decisions. LosAngles, CA:Authorhouse.\nQuinn, J. B., & Rohrbaugh, J. (1983). A spatial model of effec-\ntiveness criteria: Towards a competing values approach to\nRajteri, I. H. (2010). Overview of business intelligence matu-\nrity models. International Journal of Human Science, 15(1),\nRayner, N., & Schlegel, K. (2008). Maturity model overview\nfor business intelligence and performance management.\nStamford: Gartner.\nRejc, B. (2005). A complete methodology for measuring of\ninvestments in information technology (in Slovenian).\nRohrbaugh, J. (2005). Assessing the effectiveness of group\ndecision processes. In S. Schuman (Ed.), The lAF hand-\nJossey-Bass.\nRombout, S., & Wise, D. (2007). Failure to launch: Has poor\nestimating compromised your project? Proceedings of the\nVancouver, BC.\nRowe, A. J., & Mason, R. O. (1987). Managing with style: A\nguide to understanding, assessing, and improving decision\nmaking. San Francisco, California: Jossey Bass.\nSacu, C., & Spruit, M. (2010). BIDM: The business intelligence\ndevelopment model. Proceedings of the 12th International\nConference on Enterprise Information Systems, Funchal,\nMadeira-Portugal.\nSafi, A., & Burrell, D. (2007). Developing advanced deci-\nsion-making skills in international leaders and managers.\nVikalpa: The Journal for Decision Makers, 32(3), 1\u00ad8.\nSchilling, M., Oeser, N., & Schaub, C. (2007). How effective\nare decision analyses? Assessing decision process and\nSkinner, D. C. (2009). Introduction to decision analysis (3rd ed.),\nGainesville, Florida: Probabilistic Publishing.\nVakkayil D. J. (2010). Activity theory: A useful framework\nfor analysing project-based organizations. Vikalpa: The\nVirine, L., & Trumper, M. (2008). Project decisions: The art and\nscience. Vienna: Management Concepts.\nViswanath, V., Susan, A. B., & Hillol, B. (2013). Bridging\nthe qualitative-quantitative divide: Guidelines for\nconducting mixed methods research in information\nWilliams, S., & Williams, N. (2007). The profit impact of business\nintelligence. San Francisco, CA: Morgan Kaufmann.\nWilson, S. (1998). Failed IT projects (the human factor).\ned.umuc.edu/ ~meinkej/inss690/wilson.htm\nYin, R. K. (2009). Case study research: Study and methods (4th\ned.). Thousand Oaks, CA: SAGE.\nYin, R.K. (2011). Qualitative research from start to finish. New\nYork: Guilford.\nOussama Marrouni Alami is the Head of project manage-\nment office in NOVEC--a leading large-sized Moroccan\nengineering company. He has a PhD in Industrial\nEngineering from University Hassan II and has Masters\nin Industrial Engineering and Business Administration\n(MBA), besides a project management professional (PMP)\ncertificate. He has taught in many engineering schools as a\ntemporary professor of project management, business intel-\nligence and global performance management. His research\ninterests are in the areas of decision-making, project\nmanagement, enterprise intelligence, and strategic manage-\nment. He is especially interested in designing maturity\nmodels for intelligent systems implementation in the\ncontext of developing countries. He has published in many\nrefereed academic journals like Asian Journal of Management\nResearch and International Journal of Computer Sciences Issues.\ne-mail: oussama.alami@gmail.com\nOtmane Bouksour is a Professor at Mechanical, CIM and\nIndustrial Engineering Laboratory (LMPGI), University\nHassan II Casablanca, High School of Technology,\nMorocco.\ne-mail: boukso@yahoo.com\nZitouni Beidouri is a Professor at Mechanical, CIM and\nIndustrial Engineering Laboratory (LMPGI), University\nHassan II Casablanca, High School of Technology,\nMorocco.\ne-mail: zbeidouri@gmail.com"
}