{
    "abstract": "The effectiveness of different instrument approach charts to deliver minimum visibility and altitude informa- tion during airport equipment outages was investigated.",
    "reduced_content": "The effectiveness of different instrument approach\ncharts to deliver minimum visibility and altitude informa-\ntion during airport equipment outages was investigated.\nEighteen pilots flew simulated instrument approaches in\nthree conditions: (a) normal operations using a standard\napproach chart (standard-normal), (b) equipment outage\nconditions using a standard approach chart (standard-\noutage), and (c) equipment outage conditions using a\nprototype decluttered approach chart (prototype-outage).\nErrors and retrieval times in identifying minimum alti-\ntudes and visibilities were measured.The standard-outage\ncondition produced significantly more errors and longer\nretrieval times versus the standard-normal condition.The\nprototype-outage condition had significantly fewer errors\nand shorter retrieval times than did the standard-outage\ncondition.The prototype-outage condition produced sig-\nnificantly fewer errors but similar retrieval times when\ncompared with the standard-normal condition. Thus,\nchanging the presentation of minima may reduce risk and\nincrease safety in instrument approaches, specifically with\nairport equipment outages.\nKeywords: approach chart, aviation, complexity, dis-\ntractions, errors, human in the loop simulation, meth-\nods, minima\nInstrument approach procedures (IAPs) are pre-\ncise flight paths that guide aircraft to land. Visual\ncues from the outside environment are normally\nrequired only for landing and rollout. As the air-\ncraft progresses through the procedure, its bound-\naries narrow and funnel it to a position for the\npilot to acquire the airport environment visually.\nRespecting the boundaries of the IAP are essential\nfor safety because they guarantee obstacle clear-\nance and navigational system performance.\nIn terms of error tolerance, the margins are\ntightest at the end of the IAP. Here, the lowest\naltitude is reached, and the pilot must either see\nthe runway or climb away. Pilots need two things\nat this point: the correct altitude and enough vis-\nibility to land. These two values are called min-\nima and are depicted on charts. Altitude minima\nare referred to either as a minimum descent alti-\ntude (MDA) or a decision altitude (DA). Mini-\nmum visibility is the lowest reported visibility\nauthorized to execute the approach. If respected,\nit gives the pilot a good chance of seeing ground\ncues to land. Pilots must compare current visi-\nbility reported with the charted minimum value\nto determine the acceptability of the IAP. Visi-\nbility and altitude minima vary depending on\nmany factors, including lighting systems, ter-\nrain, and navigation precision (Federal Aviation\nPrevious Research\nDue to the criticality of the information, charts\nmust convey these minima effectively and effi-\nciently. Charting has evolved over time mostly\nas a result of accident investigation reports from\nthe National Transportation Safety Board (NTSB)\nand surveys of pilots (Hansman & Mykityshyn,\n1990). The majority of changes have involved\nrequired content. That is, charting evolution has\nbeen in terms of the presence or absence of\ninformation, rather than how the information is\ndelivered from a human performance standpoint\nThe two main producers of charts are the\nFAA's Aeronautical Navigation Products (Aero-\nNav) and Jeppesen Sanderson (Mykityshyn,\nAddress correspondence to Michael Stewart, San Jos\u00e9\nr\nSimplified Approach Charts Improve Data\nRetrieval Performance\nMichael Stewart, Sean Laraway, Kevin Jordan, San Jos\u00e9 State University,\nand Michael S. Feary, NASA Ames Research Center\nJournal of Cognitive Engineering and Decision Making\nCopyright \u00a9 2016, Human Factors and Ergonomics Society.\nSimplified Approach Charts 167\n1991). IAPs are depicted on approach \"plates\"\ninches, usually printed on paper or presented\nwith an electronic interface (see Figure 1).\nThe combination of small physical size and\nhigh information content was identified as oper-\nationally problematic in earlier research (Hans-\nman & Mykityshyn, 1990). Legibility of small\ntext and symbols, as well as information density,\ncreates an unreadable interface in low light and\nturbulent conditions (Mykityshyn, 1991). These\ngeneral design deficiencies are thought to be the\nresult of litigation and the necessity for charts to\nlimit cockpit instrument occlusion when\nmounted on a control yoke (Hansman & Myki-\nApart from legibility limitations, other defi-\nciencies have been identified: Pilot surveys, acci-\ndent reports, and empirical research have\nrevealed that identification of altitudes, naviga-\ntional frequencies, approach minima, notes,\nmissed approach instructions, and information\nFigure 1. Approach plate example.\ndensity are also areas of possible error in infor-\nmation retrieval (Butchibabu & Hansman, 2012;\nOsborne, Huntley, Turner, & Donovan, 1995).\nWith respect to navigational frequencies, the use\nof Morse code identifiers and the symbolic depic-\ntion of a given frequency can be very similar to\nthe identifier and symbol of another frequency\n(Hansman & Mykityshyn, 1990). IAPs often use\none frequency for primary navigation and another\nfor identifying waypoints, missed approach\ncourses, and/or distance-measuring equipment.\nSome identifiers may be identical except for a\npreceding \"I\" that denotes a frequency's status as\na localizer. This similarity has led pilots to mis-\ntakenly choose one frequency in place of the\nother, effectively compromising the navigational\ncapability of the aircraft, which has caused acci-\nAs an example of the problems that approach\ncharts may cause in flight, consider the crash of\nered one of three contributing factors in the acci-\ndent (NTSB, 1975). Specifically, the aircraft\ndescended to an incorrect altitude for the portion\nof the approach being flown. This resulted in a\ncollision with Mount Weather, Virginia.Although\nthe pilots retrieved the correct type of information\nfrom the chart, that information was incorrect for\ntheir current location. In fact, the pilots had a dis-\ncussion regarding the altitude to fly during the\ndescent (NTSB, 1975). Although incorrect train-\ning and air traffic control procedures were also\ninvolved in this accident, the chart's method of\ninformation delivery was a contributing factor.\nThis type of error indicates a more complex prob-\nlem than legibility. In survey research, 25% of\npilot respondents stated that they had confusion\nwith approach minima while using FAA charts\n(Hansman & Mykityshyn, 1990). Information\ndensity from including all user groups' informa-\ntion on a single chart creates the possibility of\nselecting incorrect values. In addition, notes that\ngive exceptions to theses minima are often missed\ndue to pilot perception of lesser importance\ngated the effects of clutter, or information den-\nsity, on pilot performance with respect to infor-\nmation retrieval. Pilots were given a chart on a\ncomputer and retrieved pieces of information\nfrom it (e.g., altitudes, distances). They investi-\ngated arrival, departure, and approach charts\nwith multiple transition paths depicted together.\nIn the decluttered condition, depictions of non-\napplicable paths were removed. In the baseline\ncondition, charts were presented in their original\nform. Because an aircraft can fly only one path,\nthese researchers examined the effects of depict-\ning one versus multiple paths on retrieval time\nand errors. The decluttered format significantly\nreduced information retrieval times. In some\ncases, a nearly 50% reduction was observed.\nInstrument approaches, over departures, yielded\nthe largest reduction in retrieval times. Specifi-\ncally, distances between waypoints and altitudes\nproduced the largest time differences. This sup-\nports the idea that the depiction method of infor-\nmation has a direct impact on the user. However,\nthere was no significant difference in errors\nbetween the two depictions due to a ceiling\neffect. One possible explanation of the lack of\nerror could be the context of the experiment\nbecause it was performed without concurrent\ntasks. As one pilot noted in a study by Myki-\ntyshyn (1991), \"there is an unquestionable dif-\nference between reading a chart at a well-lit desk\nversus using one in flight during bad weather at\nnight.\" Simply put, the context of use makes a\ndifference.\nTo address context and ecological validity,\nOsborne et al. (1995) investigated pictorial missed\napproach (rejected landing) icons and a briefing\nstrip of pertinent approach information against\ntextual descriptions of the procedure. Missed\napproach instructions require fast identification of\ninformation because of the proximity to terrain\nand immediate required climbs and turns. Also,\naccurate and timely retrieval of frequencies,\ncourses, airport elevations, and so on were the\nmotivation for the organized briefing strip\n(Osborne et al., 1995). The study required pilots to\nfly a real aircraft and perform several instrument\napproaches ending with missed approaches. Pilots\nanswered information retrieval questions while\nflying; their accuracy and retrieval times were\nmeasured. Retrieval times were significantly\nreduced for both conditions when using the iconic\nmissed approach depiction and the briefing strip.\nHowever, no differences were found in accuracy\nSimplified Approach Charts 169\nbetween the conditions. This may have been due\nto the training that the participants received before\ndata collection and possibly the simplistic nature\nof the information. The briefing strip and the\niconic missed approach depiction are both found\nin today's approach charts.\nComplexity of Approach Minima\nApproach procedures must accommodate all\npossible users, so they are one-size-fits-all prod-\nucts. User-specific minima are embedded in\nthe chart with other users' minima. As a result,\napproach charts contain information not pertain-\ning to the specific operational situation. Current\nmethods for deriving approach minima are\ndependent on airport equipment status, aircraft\nnavigational capability, aircraft speed, weather,\nand, occasionally, pilot training (FAA, 2007a,\nonly sifting through unnecessary information\nbut also referencing notes within the chart itself\nor noncollocated notices to airman (NOTAMs).\nTheses noncollocated notes are sometimes a\nfactor in determining the value of a minimum\naltitude and/or visibility. For the purposes of\nthis discussion, conditions of inoperative air-\nport equipment are referred to as outages. For\nexample, if the local altimeter setting was not\navailable, there may be a note that states a value\nto add to the minima to compensate for the\nlikely increase in altimeter error.\nTo illustrate this point, we use a fictitious\nexample including weather, aircraft type, capabil-\nity, and approach speed (see Figures 2\u00ad4). First,\nwe determine the category of aircraft, which is\ndecided by aircraft speed. For this example, we are\nNext, we narrow the field by ruling out approach\nminima for which our aircraft is not equipped.\nThis sample aircraft has only lateral navigation,\nwhich rules out any minima including a DA, as\nthis is a nonprecision capability. At this point, the\nfirst two rows and theA, B, and D columns are not\napplicable. Next, we determine if the wind at the\nairport allows a straight-in landing (i.e., without\ncircling). In this example, the wind permits a\nstraight-in landing. What these three steps have\ngiven us is the triangulated number on the bottom\nof the approach plate in Figure 3. Even though a\nnumber is located, it is not complete. Because the\nlocal altimeter setting is not available, the notes at\nthe top of the page dictate the additional amount to\nadd to our minimum to make it correct and legal\n(see Figure 4). In this case, that amount is 100 ft\nand 1/4 mi of visibility. Finally, the minimum alti-\ntude and visibility for our example are 1100 ft and\n1 1/4 mi, respectively. Although this example is\nnot routine, it demonstrates where steps become\nmore complex requiring arithmetic and careful\nreading of text.\nRelevance of Visibility\nRequirements to Pilots\nThere are two main types of visibility\nreported to pilots: runway visual range (RVR)\nand statute miles (SM). RVR is the most accu-\nrate measurement and is reported in hundreds\nof feet (e.g., 1200 RVR). Statute miles and frac-\ntions thereof are reported by automated sensors\nor trained observers (FAA, 2007a). What this\nmeans to pilots is the amount of expected visual\nrange they will experience when near the lowest\naltitude in the IAP. If the visibility is low and\nthe minimum altitude is high, it can lead to a\nFigure 2. Sample scenario for determining minima.\nsituation where the airplane is too high to safely\nland if visual cues are received late. Visibility\nrequirements are established according to sev-\neral variables, such as airport lighting systems,\nheight of minimum altitudes, and runway align-\nment angles (FAA, 1976). For commercial oper-\nvisibilities are legally controlling. Operators are\nnot permitted to initiate an IAP without at least\nthe minimum visibility for the procedure being\nApproach lighting systems have been devel-\noped to aid pilots in the visual acquisition of the\nrunway and its relative alignment angle from the\ninstrument portion of the flight (not requiring\nany outside reference; FAA, 2013a). This means\nthat the visibility requirement for a specific\napproach utilizing an approach lighting system\nis contingent on that system's operation. If it is\ninoperative, the visibility requirement must be\nincreased to compensate for the loss of guidance\n(FAA, 1976). For the purpose of this study,\napproach lighting system malfunctions were pri-\nmarily used to test visibility adjustments.\nTrends in Charting\nRecently, charting has been migrating to elec-\ntronic interfaces, which are free of printing costs.\nThe popularity of this format has been made\napparent by the FAA's creation of formal guid-\nance to handle the use of electronic charting inter-\nfaces by pilots (FAA, 2007b). Popularity of the\nFigure 3. Steps to derive approach minima with notice-to-airman outage from scenario.\nSimplified Approach Charts 171\nelectronic format is also noted by its application\nin the air carrier world. Many U.S. carriers are in\nthe process of transitioning to all electronic charts\nand manuals (Alaska Air Group, 2014; American\nelectronic charts have migrated into the consumer\nworld as mobile applications that are download-\nable to a tablet. ForeFlight is an example of an\nelectronic charting application, and it accounts for\n25% of general aviation chart use (Silva, Jensen,\nEmig, & Hansman, 2014).Adriving factor for the\npresent study was the idea that changes in avia-\ntion charting are necessary and currently possible\nwith electronic interfaces. Future electronic charts\nshould be free of unnecessary problems because\nthe system affords plasticity. Rather than merely\nevolving the current medium of charting, there\nis a need to provide new content and structure to\nenhance safety and usability.\nTime and Attention\nConstraints in Approach\nPreparation\nIdeally, IAPs are reviewed prior to the descent\nphase of flight for effective retrieval of the infor-\nmation necessary to perform the approach (Ricks,\nJonsson, & Barry, 1996). However, there are\nsituations that require preparation to occur after\nthat ideal portion of the flight has passed. This\nhappens when the planned approach changes,\nfor many reasons: wind shift, equipment outage,\naircraft performance, traffic flow rates, and so on\n(Lohr, 2011). Timing of the reassignment may\nplay a large factor in how detrimental the effect\nis. In addition, time-constrained approaches can\nresult from diverting from an intended airport of\nlanding to a secondary choice for unforeseen cir-\ncumstances (e.g., weather or airport closure). This\ncan result in a pilot having less time and more\nconcurrent tasks while preparing for the approach.\nFlying often requires a pilot to attend to mul-\ntiple pieces of information and perform several\ntasks in close temporal proximity (e.g., monitor-\ning the aircraft and reading a checklist). Concur-\nrent task management has been explored in the\ncontext of aviation and many other domains. If\nconcurrent tasks are not expected and interfere\nwith the primary task, they become a distraction.\nSeverity of the distraction involves its modality\n(e.g., visual or auditory), complexity, and dura-\ntion, as well as the complexity of the previous\ntask (Gillie & Broadbent, 1989). Complicated\nprimary tasks are affected more by distractions\nthan are simple tasks.Also, distractions based on\nthe same modality as the primary task are more\ndetrimental than distractions through another\nmodality. Chart reading is a complex visual task,\nand complicated visual distractions are detri-\nmental to many aspects of flying. Pilots are not\ntrained on how to manage distractions: When\nFigure 4. Steps to read notes and add penalties.\nfaced with competing tasks, they often neglect\none in favor of the other, and the hierarchy of\ntasks is not always consistent (Dismukes, 2006;\nLoukopoulos, Dismukes, & Barshi, 2003). We\nexploited these issues to show the limitations of\ncurrent charting.\nError Categories in\nRetrieving Minima\nAfter analyzing the context of use and design\nstructure, we identified four broad categories\nand named them as possible causes for using\nincorrect minima: arithmetic error, omitted pro-\ncedure error, incorrect procedure error, and\nselection error. Each error category has many\npossible examples within its scope. Addition-\nally, the categories are not mutually exclusive,\nand descriptions of each are given.\nArithmetic Error\nAdjustments to minima typically require\nadding a penalty. This presents the possibil-\nity for error due to incorrect calculation of the\narithmetic problem. In our previous example\n(see Figure 4), we needed to add 100 ft to the\nMDA. This illustrates the potential to arrive at\nthe incorrect minimum altitude. However, the\nmagnitude and directionality of the possible\nerror are difficult to determine.\nOmitted Procedure Error\nAdjusting minima is a procedure. Therefore,\npilots must be aware of the need to apply the\nappropriate procedure if the situation requires\nit. If a pilot is unaware or mistakenly omits the\nprocedure, the penalty will not be respected.\nIncorrect Procedure Error\nMinima adjustment procedures vary. If a\nnonstandard penalty replaces the inoperative\ncomponents table but the pilot applies the\ninoperative components table, which would be\nstandard, he or she would be performing an\nincorrect procedure (see Figure 5).\nSelection Error\nBecause the approach chart is a tool designed\nfor all user groups, its information content is\nhigh, and its interface real estate is low. This\ndensity creates a situation in which more than\none possibility is presented, thereby increasing\nthe possibility of making an incorrect selection.\nNumber, spacing, units, and typography may\nall play a factor in the likelihood of a selection\nerror.\nPrototype Approach\nPlate Design\nThe primary goal of the prototype approach\nplate used in this study was to design out as\nmuch possibility for error as feasible and then\nmitigate the remaining amount (see Figure 6).\nNonapplicable aircraft approach categories and\nminima were eliminated. This lowered the pos-\nsibility of choosing the incorrect minimum as\nthe result of a selection error. Next, because the\npresent chart design does not label any of the\nnumbers in the minima section, unit-type dif-\nferentiation and proper selection are the product\nof declarative knowledge. Therefore, we added\nlabels to denote units for minima (e.g., RVR,\nSM, and AGL), to reduce the memorization\nrequirements, and to increase selection accuracy\nof visibility values and minimum altitudes.\nMinimum altitudes and visibilities were set in\nbold, underlined font to increase salience and\nperceived importance. This was motivated by\nresearch investigating methods of directing\nattention to specific information in maps (Wick-\nens,Ambinder, &Alexander, 2004). To differen-\ntiate height-above-ground-level from altitude,\nwe added parentheses and in regular nonbold\nfont a unit labeled \"AGL\" next to it. A dark\nmagenta label was added to the top of the min-\nima box to denote the category and type of\napproach in use (e.g., Category A ILS). Color\nwas used to be unique and associated with a spe-\ncific piece of information. In addition, color was\nused to connect associated information. For\nexample, NOTAMs that affected the minimum\naltitude were boxed in red dashes, as was the\nmodified minimum altitude. This was a way to\nshow that the two were connected and the reason\nfor the amended minimum. Blue solid boxes\nwere used for visibility. The use of color to guide\nthe user was indirectly motivated by the salience\nmethods of Wickens et al. (2004). Because the\nprocedure designer preconceives visibility and\naltitude penalties, all arithmetic was automatically\nSimplified Approach Charts 173\napplied when necessary. The purpose of this\nwas to eliminate the possibility of making arith-\nmetic errors and to delete the notes section of\nthe plate. Although the main purpose of this\nstudy was not to reinvent the approach plate, it\nwas necessary to eliminate the issues thought to\nbe problematic with the current design for a rea-\nsonable comparison. It is also well understood\nthat implementing a system for reliable dynamic\ncharts would require extensive research and\neffort.\nPurpose\nThe purpose of the present study was to\ninvestigate whether approach plate minima pre-\nsentation can be improved to reduce or remove\nFigure 5. Inoperative components or visual aids table.\nerrors and decrease time when used during time-\ncompressed instrument approaches. Specifi-\ncally, this study compared a prototype method\nof prederived minima designed to relieve the\npilot of workload during any use case. Because\ncharting is migrating to an electronic format\nFAA, 2007b), the feasibility of creating a more\ndynamic and tailored approach plate is high.\nApproaches with outages added to the min-\nima pose a complex visual distraction. Charts\nmust be robust to all use cases and aid the pilot\nas an effective work tool. Current approach plate\ndesign may be problematic if used concurrently\nwith other tasks requiring attention. Late\napproach preparation was explored to identify\nhow the chart works as a real-time tool with dis-\ntractions. Furthermore, using a flight simulator,\nwe duplicated flight tasks associated with the\ndescent-and-approach phase of flight, making\nthe demands on the pilot as realistic as possible\nwithout endangering people by testing in a real\nFigure 6. Prototype approach plate design example.\nSimplified Approach Charts 175\naircraft. The simulator requires many similar\nvisual scanning requirements as compared with\nan airplane, increasing validity.\nHypotheses\nThe process of identifying approach minima\ncan range from retrieving one number from a\nsmall group of numbers to a multistep process\ninvolving other information sources and mental\ncalculation. We hypothesized that the number\nof errors in identifying the correct visibility\nand minimum altitude from the chart would\nincrease as NOTAM outages were added to the\ncharted minima (e.g., approach lights out of\nservice). When no noted outages were added\nto the minima, we expected that the number of\nerrors would be very low. Error rates from the\nprototype chart were expected to be comparable\nto the standard chart without noted outages.\nRetrieval times were expected to increase due\nto the addition of procedural steps as outages\nto the minima were applied. When no out-\nages were added to the minima, retrieval times\nwere expected to be the shortest due to the task\nrequiring the fewest steps. Outages from the\nprototype chart were expected to yield similar\nretrieval times as the standard chart without any\noutages.\nMethod\nParticipants\nWe recruited 18 pilot participants: 2 women\nCenter pilot participant pool. Recruitment con-\nsisted of fliers and emails sent to potential\nrecruits. Participants were required to hold at\nleast a private pilot's certificate with instrument-\nairplane rating. We did not control for age,\ngender, education, or ethnicity. Participant flight\nsample included a diverse set of pilot qualifica-\ntions, including seven private instrument pilots,\nseven commercial pilots, one flight instruc-\ntor, one instrument instructor, and two airline\ntransport pilots also certified as instrument\ninstructors. Compensation for participating was\nUS$20 per hour. Data from questionnaires were\nkept secure by de-identifying the participant's\nname and replacing it with a number. One par-\nticipant's data were excluded from analysis due\nto a communication between the participant and\na previous participant, and that participant was\nreplaced.\nMaterials and Apparatus\nAll sessions took place in a simulator room.\nThe certified desktop simulator used was a per-\nsonal computer\u00adaided training device with radio\nnavigation and a color monitor. Precision Flight\nControls, Inc., of Rancho Cordova, California,\nmanufactured the Cirrus II model flight controls\nand the Digital Avionics Standard radio stack.\nChecklists were custom made for the simulation\nand supported only the descent-and-approach\nportion of flight.\nComputerized surveys were used for both the\npre- and poststudy surveys. Excel spreadsheet\nsoftware was utilized for recording participant\nretrievaltimesmeasuredbyastopwatch.Approach\nplates were printed with a high-quality color\nprinter to remain faithful to the original design.\nPrototype charts were AeroNav charts modified\nwith PowerPoint to create the revised depiction of\nthe notes and minima sections (see Figure 6). All\nplates used were current and downloaded from the\nFAA's terminal procedures publication service:\nhttp://www.faa.gov/air_traffic/flight_info/aero\nnav/digital_products/dtpp/.\nProcedure\nParticipants read and signed the informed\nconsent form, then were given the prestudy\ndemographic questionnaire on a laptop com-\nputer. Next, they received a verbal briefing of\nthe experiment (e.g., how many approaches\nthey would fly, what was expected). Participants\nwere instructed how to operate the simulator;\nautopilot and flight director use was demon-\nstrated prior to the beginning of the practice\nsession. Participants were then given one prac-\ntice approach and coached on operational issues\nwith the simulator. Autopilot or flight director\nuse was required during the final approach por-\ntion of the flight. This was required so that all\npilots could utilize the \"RVR 1800 authorized\nwith use of (autopilot; flight director; head-up\ndisplay; decision altitude) AP, FD or HUD to\nDA\" note for some approaches. Each partici-\npant flew 15 approaches under three conditions\n(five approaches each). The standard-outage\ncondition involved five approaches using stan-\ndard FAA charts with outages affecting the\ncharted minima (i.e., airport equipment out-\nages). The standard-normal condition required\nfive approaches using standard FAA charts\nwithout outages. The prototype-outage condi-\ntion involved five approaches using the pro-\ntotype charts with analogous outages to the\nstandard-outage condition. Each equipment out-\nage condition was replicated between the stan-\ndard plate and the prototype plate, but no spe-\ncific approaches were repeated to avoid memo-\nrizing the criteria. Charts were categorized into\nthree conditions: A = prototype-outage, B =\nstandard-outage, and C = standard-normal. The\norder of conditions was counterbalanced so\nthat each chart condition could be tested first.\nThe condition sequence was ABC, CBA, BAC,\nwith participants randomly assigned to each\ncondition group. Participants started in the air\nbefore the initial descent had begun and were\nradar vectored to the approach by the researcher,\nbased on a predetermined route, with scripted\nair traffic control instructions (see Figures 7 and\n8). Participants were asked to write down the\nvisibility requirement, primary navigation aid\nfrequency, missed approach altitude, and the DA\nor MDA as applicable. The responses written\ndown were compared with the correct answers\nafter data collection. Feedback was not given\nto the participants on answer accuracy. Errors\nwere analyzed and placed into their appropriate\ncategory or categories. Omitted procedure error\nwas identified when a participant would select\nthe appropriate minimum but not add a penalty.\nIncorrect procedure error was identified when\na participant would add a penalty that was not\nappropriate for the condition. Selection error\nwas identified when a participant chose a value\nlisted on the chart that was not appropriate for\nthe condition. The participant's notes revealed\narithmetic error when an addition error on the\nscratch paper was obvious. When errors were\nnot identifiable, they were designated as other.\nDesign\nThis study was based on a repeated measures\nexperimental design that compared the three\nFigure 7. Lateral flight path flown by participants with air traffic control communications, speeds, and context\nnotes.\nSimplified Approach Charts 177\nconditions (standard-outage, standard-normal,\nand prototype-outage). Dependent variables were\nconsistent among all conditions: correct or incor-\nrect minimum altitude and minimum visibility\nidentification (i.e., errors) and retrieval times\nfor identifying minima. Mean error rates and\nretrieval times were analyzed through a repeated\nmeasures analysis of variance (ANOVA) to deter-\nmine if differences existed among conditions.\nMauchly's test of sphericity was performed to\ntest the assumption of uniform levels of variance.\nA Huynh-Feldt correction was applied when this\nassumption was violated. Degrees of freedom\nwere rounded down to the nearest whole number\nand reported in the event that a Huynh-Feldt cor-\nrection was applied. Post hoc pairwise compari-\nsons were made with the Fisher-Hayter test for\nrepeated measures data (Huitema, 2011). For pair-\nwise comparisons, effect size was measured with\nCohen's d. Pearson correlation coefficients were\ncalculated to identify correlations between the\nnumber of errors and numerical participant demo-\ngraphic data. Due to outliers in age (84 years)\nand flight time (10,000 hours), correlational tests\nwere performed with and without the outliers to\ngauge their influence. Participants were randomly\nassigned to three groups, which dictated the order\nof approaches they received. This measured if the\npreceding chart type led the participant into a dif-\nferent level of performance. A one-way ANOVA\nwas performed to test for differences among the\ncounterbalanced groups' error rates and retrieval\ntimes. All tests were performed at a .05 level of\nsignificance.\nResults\nEffects of Counterbalancing\nOrder on Errors and Retrieval Times\nTo assess the effect of chart presentation\norder on errors, a one-way ANOVA was per-\nformed. This compared each of the three chart\norders (ABC, BAC, CBA) against the errors\nin each chart type: A, B, and C. There was no\nsignificant difference in mean errors across\npresentation order. Because retrieval time was\nalso a dependent variable and therefore sub-\njected to the same counterbalancing system, a\nsecond one-way ANOVA was performed. This\nassessed the counterbalancing system's effect\non retrieval times. No significant mean differ-\nences were found to exist across presentation\norder. Because no effects of the counterbal-\nancing order were found, all of the data were\ngrouped for subsequent analyses.\nErrors\nThe hypotheses that error rates would be\ngreater due to outages affecting the minima, as\nwell as relatively low when used during normal\nFigure 8. Vertical flight path flown by participants with air traffic control communications, speeds, and context\nnotes.\noperations, were both confirmed. When outages\nwere added to the standard chart's minima, mean\nchart was used in normal conditions, mean\nhypothesis that an alternative prototype depic-\ntion of the minima would reduce errors when\noutages were added was also confirmed. Mean\nThese mean differences were statistically signif-\nHayter tests were performed to test all pairwise\ncomparisons. All three tests revealed significant\nmean differences. The standard chart with out-\nages produced significantly more errors than did\nd = 4.73. Surprising, the prototype chart with\noutages had a significantly lower mean number\nof errors than did the standard chart used during\nd = 0.75. Finally, the standard chart during normal\nconditions produced significantly fewer mean\nerrors than did the standard with outages, qF-\nBecause participants made such a large num-\nber of errors when outages were added to the\nstandard charts, Pearson correlations were per-\nformed between error rates and participant\ndemographic data in an attempt to explain some\nof this effect. Total flight time, flight time in the\nlast 3 months, number of instrument approaches\nin an airplane in the last 3 months, number of\ninstrument approaches in a simulator in the last\n3 months, and age were compared with error\nrates (see Table 1). The only significant correla-\ntion with errors was with the number of instru-\nment approaches flown in an airplane in the last\ntailed, r2 = .332. Interestingly, instrument\napproaches in a simulator revealed nonsignifi-\ncant results with another very low r value. Tests\nperformed without the two outliers revealed\nsimilar results.\nErrors were identified and categorized by\ntype, then graphed to illustrate their respective\nproportion of the total errors (see Figure 10).\nOmitted procedure error and selection error\nwere the two most common and constituted 44%\nand 34% of the total errors, respectively. Unex-\nplainable errors that did not have an identifiable\ncause accounted for 6% of the total errors.\nRetrieval Times\nThe hypotheses that outages affecting the min-\nima would increase retrieval times and that the\nprototype would reduce retrieval times given the\nsame conditions were confirmed. Mean retrieval\ntimes (in seconds) increased when outages\nwere added to the standard chart (M = 57.19,\nSD = 27.82) versus the standard chart in normal\nthe prototype chart with outages yielded shorter\nFigure 9. Mean error rates for each chart condition.\nSimplified Approach Charts 179\nmean retrieval times than the standard chart with\nThese mean differences (based on Huynh-Feldt\ncorrection) were significantly different, F(1, 18)\nwere performed to test all pairwise comparisons.\nResults comparing the standard chart with out-\nages against the standard chart during normal\ntotype chart with outages against the standard\nchart with outages were also significant, qF-H(2,\ndifferences between the prototype with outages\nand the standard chart during normal operations\nwere similar and nonsignificant. Three Pearson\ncorrelations were also performed to determine if\nthere was a relationship between number of errors\nin each condition and length of time to retrieve\nthe answers. None of the results were significant.\nVisual analyses of the scatterplots revealed no\nnoticeable relationships. With the prototype chart\nand the standard chart during normal operations,\nthere were simply too few data points to see any\nsystematic relationship. Pearson r values were as\nThe standard chart with outages had many data\npoints but was completely unsystematic, r(16) =\nSubjective Survey Responses\nResponses to the poststudy survey revealed\npart or parts of the standard approach plates are\nthe minima section was confusing; another 50%\n(n = 6) said that the briefing and notes section\nwas confusing. Approximately 16% (n = 3) of\nparticipants believed that there was information\non the charts that was unnecessary. Forty-four\nTable 1: Pearson Correlations of Mean Error\nRates and Demographic Information\nMean\nErrora\nInstrument approaches last 3 months \naAeronautical Navigation Products with exceptions.\nFigure 10. Error proportions by type.\nFigure 11. Mean retrieval times.\npercent (n = 8) believed there was information\nmissing from the chart that would have been\nbeneficial. In addition to simple yes/no ques-\ntions, participants were asked to explain the\nspecific issues that they thought were confusing.\nSeveral participant quotes explain the issues:\n\u00b7\n\u00b7 \"Minimums increase are specified separately for\nceiling and visibility, so you have to compute both\nseparately. A unified minimum would be clearer.\"\n\u00b7\n\u00b7 \"Text often very dense especially when explain-\ning many nonstandard variations (effects of inop\ncomponents or missing equipment).\"\n\u00b7\n\u00b7 \"I don't like NOAA plates where you have to go\nto a separate place (the INOP table) to figure out\nalternate minimums when approach equipment is\nINOP. I like Jeppesen plates where all the info is\non the plate you are using.\"\n\u00b7\n\u00b7 \"If I haven't flown for awhile I often forget what\nis what in the minima area until I review it, and the\nsame goes for the profile and plan views as well.\nThere's a lot of information and often repeating\ninformation in parenthesis does not always help to\nsimplify things.\"\n\u00b7\n\u00b7 \"The LDA approach minima were confusing as to\nwhich minima I had to use.\"\nDiscussion\nExpected and Unexpected\nPerformance\nWe investigated the effects of minima depic-\ntion and airport equipment outages on errors\nand retrieval times. Our goal was to identify\nand assess different problems with charted\nminima as they pertain to human performance\nlimitations. In addition, we analyzed a possible\nmitigation strategy by comparing a prototype\napproach chart to the current approach charts.\nLower error rates were observed with the pro-\ntotype chart versus the standard chart when\noutages affected the minima. In fact, mean\nerrors were approximately 26 times less with the\nprototype chart. Error rates were also approxi-\nmately 5 times less with the standard chart\nduring normal operations as compared with the\nstandard chart with outages affecting the min-\nima. These results were generally in line with\nour hypotheses. In contrast, the prototype chart\nwith outages yielded approximately 5 times\nfewer errors than the standard chart in normal\noperations. This finding was unexpected, as the\ntwo chart types were hypothesized to be compa-\nrable in all performance aspects.\nThe errors observed during normal opera-\ntions with the standard chart may be attributed to\nseveral factors, but one explanation could be the\ninconsistent spacing of rows and columns\nbetween different approach configurations. For\nexample, the ILS 01R in Washington Dulles and\nthe ILS Z 16R at Paine Field are north/south\nrunways, using more longitudinal space of the\nchart and compression of other parts. In this\ncase, the result is an instrument landing system\n(ILS) minima row that is half the height of the\nothers. Several participants chose second-row\nminima when they should have selected from\nRow 1. Numbers are also centered in the column\nthey occupy. If the minima are applicable to all\ncategories of aircraft (e.g., ABCD), the informa-\ntion will not be aligned with the row below it\nand will have a large blank area to the left, which\nis generally where people start reading. Further-\nmore, the presence of noncivilian information,\ndistinguished by parentheses, caused errors for\nparticipants using the standard chart in normal\nconditions. Participants would choose the wrong\n(military) number as their visibility minimum.\nThese issues might be the result of a learned\nhabit as they quickly retrieve information.\nJeppesen uses parentheses to depict height above\nground level, which is applicable to the civilian\nuser. If users are exposed to both government\nand Jeppesen formats, there is a possibility of\nnegative transfer with respect to the meaning of\nparentheses. This unexpected result may indi-\ncate that the lack of unit labeling and selection\nerror possibilities are problematic.\nTime Pressure\nEvery trial was intentionally time constrained\nto simulate an approach change near the airport\nand to add realism. This forced the participants\nto use the chart as a real-time work tool, which\nrequired its use to be mixed with primary flight\ntasks, such as monitoring aircraft parameters,\nnavigating, and communicating with air traffic\ncontrol. When the chart was used simply as a data\nextraction interface (i.e., search and identify),\nflight interference was relatively low, as was chart\nuse interference. Pilots were able to make quick\nSimplified Approach Charts 181\ntransitions between monitoring the aircraft and\nextracting pieces of information from the chart.\nIn contrast, when the chart required multiple steps\n(i.e., when outages were added), the primary task\nof flying the airplane was sometimes neglected.\nSpeed, checklists, and navigation frequency iden-\ntification were common tasks that were discarded\nwhen the chart required abnormal amounts of\nattention. One participant wrote in the poststudy\nsurvey, \"Most charts are simple, but some charts\nhave an impenetrable wall of text that can require\na great deal of decision making.\"\nConversely, there were times when the flying\ntasks would take priority over the intricate steps of\nthe chart.This caused the chart to be revisited mul-\ntiple times, eventually leading to some very com-\nplicated retrieval errors. For example, one partici-\npant knew about a required procedure but was\nsimply unable to concentrate on it long enough to\narrive at the correct answer. This resulted in an\narithmetic error, a selection error, and an incorrect\nprocedure error in a single case. Throughout the\nentire study, no participants asked for a delay to\nprepare for the approach. At no time was it said\nthat delays were not allowed. This was a fascinat-\ning occurrence, as there were many approaches\nthat were not set up completely, yet the pilot\nelected to continue. It is unclear if this phenome-\nnon was an artifact of flying in a simulator or if\npilots felt compelled to continue for some other\nreason.\nErrors and Retrieval Times\nOur data showed no relationship between\ncorrect answers and retrieval times for any of\nthe three chart types. This has different mean-\ning depending on which chart type is discussed.\nOmitted procedure error, incorrect procedure\nerror, and arithmetic error differed in the amount\nof time that it took to get to the wrong answer.\nIncorrect procedure errors and arithmetic errors\nexhibited longer retrieval times and incorrect\nanswers, whereas omitted procedure errors were\nshorter. Therefore, the retrieval times could be fast\nand inaccurate or slow and inaccurate. In addition,\nomitted procedure errors as a result of not using\nthe inoperative components or visual aids table\nwere particularly interesting. Several participants\ndid not use the table even though it was attached\nto a clipboard in front of then. In reality, it would\nbe more difficult to access and not co-located\nwith the charts in use. This may indicate that\npilots are not familiar with its purpose or usage.\nFurthermore, if pilots do not use this table when\nit is given to them, it is unlikely that they use it in\nreality. Last, the prototype-outage chart's lack of\ncorrelation with time and errors is not meaningful\ndue to the lack of data points.\nError rates were most likely high in the stan-\ndard chart, with outages due to the complexity of\nthe procedural steps in combination with the\ncomplexity of the task of flying. Additionally,\npilot knowledge and training of how to handle\nthese issues appeared to be highly variable, as\nindicated by the observed differences in errors\nand retrieval times. This combination was\nenough to render the information presentation\nineffective in certain cases. Overall retrieval\ntimes were in line with the hypothesis, as well as\nsimilar to Butchibabu and Hansman's (2012)\ndecluttering results with information retrieval\nfrom approach procedures. When unnecessary\ninformation is removed, it reduces complexity\nand allows for faster identification of important\ninformation. Average retrieval times were\nreduced by approximately 28% with the proto-\ntype chart as compared with the standard chart\nwith outages affecting the minima. Furthermore,\nthis increase in speed did not come at the cost of\nincreased error. During high-workload phases of\nflight, reducing retrieval times is undoubtedly a\npositive outcome. Limiting the duration of cock-\npit distractions allows for more resources to be\napplied to understanding the current situation.\nImplications\nThis study provided empirical support for\nidentifying the limitations of standard approach\nminima depiction in delivering information to\npilots in time-compressed situations with equip-\nment outages. These findings in and of them-\nselves should not be mistaken for an overall\nevaluation of the standard approach plate but\nrather a small subset of unusual use cases. Mostly,\nthese findings, along with others preceding them,\nshould be taken as a cue that aviation charting\ncould be improved. Prior limiting factors, such\nas printing costs, color ink, and paper thickness,\nare no longer issues. High-resolution screens\nand automatic dependent surveillance\u00adbroadcast\nconnectivity could allow the user to update data\nin real time and display them on an electronic\ninterface. Initial charting design for any procedure\nshould incorporate known human perceptual and\ncognitive limitations, with special consideration\nfor the context of use, environmental as well as\nsituational.\nLimitations\nGeneralizability of this study may be limited\nto AeroNav charts because Jeppesen utilizes\nan alternative method of depicting approach\nminima. However, certain notes and NOTAM\nchanges would be similar in the Jeppesen for-\nmat. Utilizing a simulator may have produced\ndifferent behavior than that seen in actual flight.\nThis study focused on realism but undoubtedly\nfell short in several areas. Because this study\nwas performed as a single-pilot operation, there\nmay be differences in the way that two-crew\noperators handle situations with instrument\napproaches. It was beyond the scope of this\nproject to address these issues.\nFuture Research\nThis research required long data collection\nsessions; therefore, it was limited in scope.\nMany separate yet closely associated areas are\nstill in need of exploration. First, comparing\nJeppesen approach plates with the same proce-\ndures and study design is a logical next step in\nfully understanding performance limitations in\napproach minima depiction. Second, exploring\ntwo-crew operations would address areas that\nthis study could not. Effects of crew coordi-\nnation, crosschecking, and briefing would be\nfurther areas to examine. Third, NOTAM depic-\ntion as it pertains to other aspects of charting\nwill need to be explored. Because NOTAMs\ncan affect other parts of the chart besides the\nminima section, a comprehensive investigation\nis required to gauge their impact on operational\nsafety. Finally, the impact of time pressure as an\nindependent variable during abnormal and nor-\nmal operations would be useful in determining\nexactly how detrimental it is to performance.\nConclusions\nThis study provides support for the pre-\nvious studies on approach plate decluttering\nand information depiction. In comparison with\nButchibabu and Hansman (2012) and Osborne\net al. (1995), we also noticed a significant\nreduction in time spent extracting information\nfrom approach charts. However, unlike previous\nstudies, we believe that flying tasks, abnormal\nconditions, and time pressure created by our\nsimulated scenarios were able to exploit further\nissues. In high-workload situations complicated\nby airport equipment outages, we noticed a large\nincrease in errors identifying correct approach\nminima. In addition, our prototype method\nof depiction appeared to be very effective at\nmitigating errors in all use cases and should be\nexplored further for possible use. By automating\nmany of the charting procedures and changing\nthe depiction of information, we believe that\naviation safety could be improved.\nReferences\nAlaska Air Group. (2014). Retrieved from http://splash\n.alaskasworld.com/Newsroom/ASNews/ASstories/AS_\nAmerican Airlines. (2013). Retrieved from hub.aa.com/en/nr/\npressrelease/american-airlines-completes-electronic-flight-\nbag-implementation\nButchibabu, A., & Hansman, R. J. (2012). Evaluating the depiction\nof complex RNAV/RNP Procedures and analyzing a potential\nde-cluttering technique (Unpublished master's thesis). Massa-\nchusetts Institute of Technology, Cambridge.\n2-tablet-devices\nDismukes, K. (2006). Concurrent task management and prospec-\ntive memory: Pilot error as a model for the vulnerability of\nexperts. In Proceedings of the Human Factors and Ergonomics\nNASAAmes Research Center.\nFederal Aviation Administration. (1976). United States standard\nfor terminal instrument procedures (TERPS). Washington, DC:\nU.S. Department of Transportation.\nFederal Aviation Administration. (2007a). Instrument procedures\nhandbook. Washington, DC: U.S. Department of Transportation.\nFederal Aviation Administration. (2007b). Use of Class 1 or Class\n2 electronic flight bag (EFB) (AC No. 91-78). Washington,\nDC: U.S. Department of Transportation.\nFederal Aviation Administration. (2013a). Aeronautical information\nmanual. Washington, DC: U.S. Department of Transportation.\nFederal Aviation Administration. (2013b). Pilot's handbook of\naeronautical knowledge. Washington, DC: U.S. Department of\nTransportation.\nGillie, T., & Broadbent, D. (1989). What makes interruptions dis-\nruptive? A study of length, similarity, and complexity. Psycho-\nHuitema, B. E. (2011). The analysis of covariance and alterna-\ntives. East Lansing, MI: Wiley.\nLohr, G. W. (2011). System oriented runway management: A\nresearch update. Paper presented at the Ninth USA/Europe\nSimplified Approach Charts 183\nAir Traffic Management Research and Development Seminar,\nBerlin, Germany.\nLoukopoulos, L. D., Dismukes, R. K., & Barshi, I. (2003). Concur-\nrent task demands in the cockpit: Challenges and vulnerabili-\nties in routine flight operations. In The proceedings of the 12th\nInternational Symposium on Aviation Psychology. Dayton,\nOH: NASAAmes Research Center.\nMykityshyn, M. G. (1991). Design and evaluation of advanced\nelectronic cockpit display for instrument approach informa-\ntion (Unpublished master's thesis). Massachusetts Institute of\nTechnology, Cambridge.\nNational Transportation Safety Board. (1975). Trans World Air-\nOsborne, D., Huntley, M., Turner, J., & Donovan, C. (1995).\nThe effect of instrument approach procedure chart design on\npilot search speed and response accuracy: Flight test results.\nCambridge, MA: VOLPE National Transportation Systems\nCenter.\nRicks, W. R., Jonsson, J. E., & Barry, J. S. (1996). Managing\nApproach Plate Information Study (MAPLIST): An informa-\ntion requirements analysis for approach chart use. Hampton,\nVA: NASA Langley Research Center.\nSilva, S., Jensen, L., Emig, J., & Hansman, R. J. (2014). Study on\npilot perception and valuation of ADS-B traffic and weather\nservices (TIS-B & FIS-B). Paper presented at FAA Joint Uni-\nversity Program Quarterly Meeting, Atlantic City, NJ.\nWickens, C. D., Ambinder, M. S., & Alexander, A. L. (2004). The\nrole of highlighting in visual search through maps. Paper pre-\nsented at Human Factors and Ergonomics Society 48th Annual\nMeeting, New Orleans, LA.\nMichael Stewart received his MS in human factors/\nergonomics from San Jos\u00e9 State University. He is a\nsenior research associate for the San Jos\u00e9 State Uni-\nversity Research Foundation in the Aerospace Cogni-\ntive Engineering group, NASAAmes Research Center.\nHis research has focused on human performance issues\nwith instrument procedures and assessment methods in\nsafety critical operations. His flying background\nconsists primarily of Part 121 airline operations.\nSean Laraway received his PhD in the experimental\nanalysis of behavior from Western Michigan Univer-\nsity. He is an associate professor in the Department\nof Psychology and adjunct faculty in the MS pro-\ngram in human factors/ergonomics at San Jos\u00e9 State\nUniversity. His current research interests include\nlearning, motivation, behavior analysis, consumer\nbehavior, and human factors/ergonomics.\nKevin Jordan is professor emeritus of psychology at\nSan Jose State University. He received both his MS\nand PhD in cognition and perception from Kansas\nState University. Jordan has published and presented\nextensively with an emphasis on the visual percep-\ntion of various aspects of the objects in our environ-\nment (i.e., orientation, spatial frequency, length).\nAdditional work has focused on lexical memory,\nattentional issues involved in processing information\nin head-up displays, and speed-based clearances for\ntaxiway navigation.\nMichael S. Feary is the lead of the Aerospace Cogni-\ntive Engineering group, NASAAmes Research Cen-\nter. His research is focused on the development of\ntools and measures to support the evaluation of\nhuman-automation interaction in complex, safety-\ncritical environments. He received his PhD from\nCranfield University in human factors engineering.\n"
}