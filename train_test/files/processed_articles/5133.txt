{
    "abstract": "Abstract\nRecently, there has been renewed interest in so-called evidence-based policy making. Enticed by the grand promises of\nBig Data, public officials seem increasingly inclined to experiment with more data-driven forms of governance. But while\nthe rise of Big Data and related consequences has been a major issue of concern across different disciplines, attempts to\ndevelop a better understanding of the phenomenon's historical foundations have been rare. This short commentary\naddresses this gap by situating the current push for numerical evidence within a broader socio-political context,\ndemonstrating how the epistemological claims of Big Data science intersect with specific forms of trust, truth, and\nobjectivity. We conclude by arguing that regulators' faith in numbers can be attributed to a distinct political culture, a\nrepresentative democracy undermined by pervasive public distrust and uncertainty.\n",
    "reduced_content": "Commentary\nDatatrust: Or, the political quest\nfor numerical evidence and the\nepistemologies of Big Data\n Keywords\nBig Data, evidence-based policy making, quantification, trust in numbers, mechanical objectivity, epistemology\nOver the past few years, there has been growing interest\nin so-called `evidence-based policy making'. While the\nconcept is not new (Solesbury, 2002), the latest push for\nmore data-driven modes of governance has been con-\nsiderable (Haskins, 2014). Against the backdrop of\nmultiple crises, policymakers seem ever more inclined\nto legitimize specific ways of action by referring to\n`hard' scientific evidence suggesting that a particular\ninitiative will eventually yield the desired outcomes\n(Urahn, 2015). Across many areas of public service--be\nit healthcare, education, or law enforcement--a steady\ninflux of ``data for policy'' (European Commission\n(EC), 2015a) is meant to offer guidance in a moment\nmarked by high levels of complexity and uncertainty\nLegislators' current emphasis on evidence and\nresults correlates with a recent techno-scientific devel-\nopment--the advent of Big Data (Mayer-Scho\n\u00a8 nberger\nand Cukier, 2013). While state bureaucracies have\nrelied on statistics and numerical information for cen-\nturies (Cohen, 2005), new analytical techniques promise\nto improve upon former methods in several ways:\nWhereas data analysis has traditionally been costly\nand time-consuming, it is now fast and cheap; whereas\npreviously one had to settle for samples, the ongoing\ncomputerization of society makes it possible to glean\ndata from entire populations; whereas once there was\nneed for theory, through sheer volume the data now\nspeak for themselves; whereas in the past measurements\nwere tainted by human bias, agnostic algorithms now\nguarantee an impartial view from nowhere. Together,\nthe alleged qualities of Big Data technologies feed\ninto what Rob Kitchin (2014a) has described as the\n``articulation of a new empiricism'', which operates as\na ``discursive rhetorical device'' designed to promote\nthe utility and value of new analytical services.\nPolicymakers on either side of the Atlantic have\nbought into the hype, usually without much regard\n1IT University of Copenhagen, Denmark\n2University of Vienna, Austria\nCorresponding author:\nGernot Rieder, IT University of Copenhagen, Rued Langgaards Vej 7,\nEmail: gernot.rieder@univie.ac.at\nBig Data & Society\nReprints and permissions:\nsagepub.com/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons Attribution-\nNonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use, reproduction\nand distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nfor nuance or subtlety. In official documents and\nspeeches, Big Data is referred to as the ``new oil of the\ndigital age'' (EC, 2012), the next ``industrial revolution''\nasset'' (EC, 2015b) for creating value, increasing prod-\nuctivity, and boosting growth. The technology is not\nonly expected to improve public administration by\n``advanc[ing] government efficiency'' (Executive Office\nof the President (EOP), 2014) and enabling ``better ser-\nvices'' (EC, 2013), but also to support ``evidence-\ninformed decision making'' (EC, 2015a) by providing\nreal-time feedback, generating solutions, and predicting\noutcomes, always ensuring that ``regulation is empiric-\nally justified in advance'' (Sunstein, 2012). Although this\nfocus on technology-driven benefits has in some cases\nexpanded to include consideration of potential risks\nand pitfalls, political leaders remain firmly committed\nto ``harness[ing] the power of Big Data'' (Kalil and\nMuch effort has already gone into challenging the\nbuzz-laden assumptions of modern-day ``data-ism''\n(Brooks, 2013). Investigating both the politics and\npower of contemporary data practices, scholars from dif-\nferent disciplinary backgrounds have identified a range\nof social, ethical, and legal issues--from privacy and\nsecurity (Ohm, 2010) to transparency and accountability\n(Pasquale, 2015), bias and discrimination (Barocas and\nSelbst, 2015)--emphasizing that Big Data's presumed\nbenefits may come at a cost. But while there has been a\nsteady stream of critical reactions across academia and\nthe media, attempts to gain a better understanding of the\nsocio-historical foundations of policymakers' push for\nnumerical evidence have been rare. Put differently, even\nthough the rise of Big Data and related consequences has\nbeen a major issue of concern, its significance for and\nembeddedness in a long-standing culture of measure-\nment and quantification has not. As Barnes (2013) poign-\nantly states: ``Big Data, little history.''\nOne reason for this lack of historical contextualization\ncan be attributed to the dynamics of Big Data discourse:\nPresented as a rupture and revolution with no ties to the\npast, discussions about Big Data have focused on the\nmodalities of change rather than forms of continuity.\nThe `now' is said to be fundamentally different from\nwhat came before, the `new' supersedes the `old'. This\nnarrative of novelty and disruption, exemplified in notions\nsuch as Anderson's (2009) ``Petabyte Age'', is both power-\nful and convenient, but discourages appreciation of Big\nData as a specific amalgamation, a ``conjuncture of differ-\nent elements, each with their own history, coming together\nat this our present moment'' (Barnes, 2013). Yet it is pre-\ncisely the recognition of Big Data's diverse roots, its con-\nnection to prior epistemic practices, that may provide\ngreater insight into the current excitement's underlying\nnorms and values.\nSuch exploratory analysis requires some conceptual\nrethinking: Instead of narrowly defining Big Data in\nmere technical terms--e.g., Laney's (2001) popular\n`three Vs', which reductively characterize Big Data as\nan increase in (data) volume, velocity, and variety--it\nseems more productive to think of it as the termino-\nlogically contingent manifestation of a complex socio-\ntechnical phenomenon that rests on an interplay of\ntechnological, scientific, and cultural factors (cf. boyd\nand Crawford, 2012). While the technological dimension\nalludes to advances not only in hardware, software, but\nalso infrastructure and the scientific dimension com-\nprises both mining techniques and analytical skills,\nthe cultural dimension refers to (a) the pervasive use\nof ICTs in contemporary society and (b) the growing\nsignificance and authority of quantified information in\nmany areas of everyday life, including public adminis-\ntration and decision making. Ultimately, this broader\ninterpretative approach may assist in ``deconstructing\nthe black boxes of Big Data'' (Pasquale, 2015) by\npaying attention not only to the mechanical, but also\nto the mental workings of an otherwise opaque\nphenomenon.\nInvestigations into the roots and antecedents of Big\nData may take different paths: Barnes and Wilson\n(2014), for instance, examine the origins of the social\nphysics movement, whose monistic urge--that is, the\nassumption that the laws of physics apply to both nat-\nural and social worlds--was later incorporated into\nspatial analysis, shaping the use of Big Data in pre-\nsent-day geography. Morozov (2014), drawing on\nMedina's (2011) Cybernetic Revolutionaries, details the\nAllende administration's Project Cybersyn to highlight\nthe intellectual affinities between socialism, cybernetics,\nand Big Data, while Grandin (2014), citing Dingens\n(2005), reports on the Pinochet regime's Condor data\nbank to locate the ``anti-socialist origins of Big Data'',\na juxtaposition of historical events illustrating that the\nidea of data-facilitated control may in fact appeal to\ndifferent ends of the political spectrum. Last but not\nleast, Mackenzie (2013) provides an empirical account\nof how recent shifts in programming practice relate to\nwhat Adams et al. (2009) have labeled ``regimes of\nanticipation'', demonstrating how the\ncurrent emphasis on machine learning and predictive\nmodelling is entangled with a concerted cultural effort\nto reduce uncertainty by fostering the continuous\nassessment of the `not yet'.\nWhile these examples offer unique perspectives, each\nfocusing on particular cases and ideas, they are also\nsimilar in that they seek to situate Big Data discourse\nwithin a larger historical context, attributing meaning\nto what all too often takes the form of pure marketing.\nWe suggest that such attempts to historicize and con-\ntextualize are crucial as they may (a) provide better\n2 Big Data & Society\ninsight into the epistemological foundations of contem-\nporary data science, (b) deepen our understanding of\nthe norms, values, and expectations driving the current\nclimate of hope and hype, and (c) indicate potential\nsocial and ethical ramifications, serving as a guiding\ncompass at a time when technical innovation continues\nto outpace government regulation (Rubinstein, 2013).\nWe would like to contribute to this research agenda by\nsuggesting what may prove another fruitful avenue of\ninvestigation: The data hype's reliance on specific forms\nof trust, truth, and objectivity.\nAs boyd and Crawford (2012) have argued, Big Data\nis not just about technological progress, but about a\n``widespread belief that large data sets offer a higher\nform of intelligence and knowledge that can generate\ninsights that were previously impossible''. Leonelli\n(2014) makes a similar argument, stressing that the nov-\nelty of Big Data science does not lie in the sheer quan-\ntity of data involved, but in the ``prominence and status\nacquired by data as commodity and recognized\noutput.'' But where does this prominence and status\ncome from and what exactly are the roots of the\nbelief that more data equals better insight?\nAn initial answer would be that data are often per-\nceived as raw, objective, and neutral--the ``stuff of\ntruth itself'' (Gitelman, 2013). But, as historians of sci-\nence and technology have repeatedly shown, concep-\ntions of objectivity, truth and truthfulness, trust and\ntrustworthiness may vary, they are ``situated and his-\ntorically specific'' (Gitelman, 2013). Therefore, it is\nimportant to clarify which particular version of these\nconcepts manifests within Big Data discourse. One way\nto identify such differences is through comparison,\nwhich may involve tracing conceptual shifts and\nchanges over time.\nIn his book The Social History of Truth, Shapin\n(1994) emphasizes the central role of trust in building\nand maintaining social order. Societies are made\nthrough acts of trust--without trust, they may falter\nand collapse. The allocation of trust and trustworthi-\nness can thus be understood as the ``great civility'',\ngranting the conditions in which people can colonize\neach others' mind. Although often rendered invisible,\ntrust as the ``cement of society'' is also essential to the\nconstruction and establishment of epistemic systems.\nThe production of scientific knowledge, for instance,\nrests on myriads of social and material interactions,\nwhich take for granted the reliability of numerous sta-\nbilized norms and relationships. As a result, scientific\ndistrust and skepticism only takes place ``on the mar-\ngins of trusting systems.''\nBut such systems of trust are not fixed--conceptions\nof whom to trust, what to trust, and in what circum-\nstances, are subject to change: While in premodern soci-\nety it was the politically and economically independent\ngentleman who was generally conceived as a credible\ntruth-teller, modern society accorded trust to the ``abstract\ncapacities'' (Giddens, 1990) of ``faceless institutions''\n(Shapin, 1994). The veracity of testimony was no longer\nunderwritten by personal virtue, but by an elaborate\nsystem of institutionalized norms and standards, rigor-\nously policed in a great ``panopticon of truth'' (Shapin,\n1994). A different form of trust first accompanied and then\nsuperseded the premoderns' faith in the integrity of the\nsolitary knower and the moderns' confidence in the rigor\nof institutionalized expertise, a type of trust that has\ngained considerable traction with the arrival of Big\nData: people's trust in numbers.\nWhile the general history of quantification can be\ntraced back much further, Desrosie\n17th-century English political arithmetic as the ``basic\nact of all statistical work (in the modern sense of the\nterm), implying definite, identified, and stable unities.''\nWhereas early records of baptisms, marriages, and bur-\nials were meant to attest to the existence of individuals\nand their family relations, later statistical surveys such as\nthe one underlying the 18th-century French ``adunation''\nwere intended to support the unification of national\nterritory in order to establish a ``politico-cognitive con-\nstruction of a space of common measurement''.\nExamples such as these highlight the close relationship\nbetween statistics and state-making: Numbers allowed\nfor coherence and generality, enabling central govern-\nments to exercise administrative control over matters\nof taxation and economic development at a time when\nthe familiarity of face-to-face interactions gradually gave\nway to the anonymity and complexity of expanding\ntrade and business networks.\nBut behind those numbers still stood individual\nexperts and prestigious institutions--numbers did not\nspeak for themselves. Quite to the contrary, it was the\ncultivated judgment of an administrative elite that\nguaranteed the trustworthiness of numerical informa-\ntion; deployed by outsiders, statistics counted for little.\nAs Porter (1995) explains, numbers could only ``provide\na modest supplement to institutional power.'' Their\ncredibility rested on the authority and integrity of a\nbureaucracy whose members believed that measure-\nments only became useful when subject to expert inter-\npretation. For them, nothing could be reduced to\ninflexible laws, abstract formulas, or technical routines.\nAgreements were reached through informal discussion\nrather than formal procedures. In general, decisions\nwere rarely entrusted to the numbers.\nThe demand for quantitative rigor increased during\nthe first half of the 20th century: Instead of expert judg-\nment, the pursuit of technical discipline required an\n``ideal of self-sacrifice''; instead of professional auton-\nomy, the desire for precision imposed adherence to a\nstrict ``regime of calculation''; instead of elite\nRieder and Simon 3\ndiscretion, it became necessary to ``manage by the num-\nbers'' (Porter, 1995). The result was what Porter refers to\nas the ``cult of impersonality'', a specific culture of quan-\ntification that seeks to reduce the human element as\nmuch as possible, preferring formalized principles to\nsubjective interpretation, uniform standards to meth-\nodological tinkering, the rule of law to the rule of\nmen. The goal was to attain ``mechanical objectivity''\n(Daston and Galison, 1992), a disinterested science\nthat ``eradicates all that is personal, idiosyncratic, per-\nspectival.'' In this brave new world, trust no longer res-\nides in the integrity of individual truth-tellers or the\nveracity of prestigious institutions, but is placed in\nhighly formalized procedures enacted through disci-\nplined self-restraint. Numbers cease to be supplements.\nThey are couched in a rhetoric of factuality, imbued with\nan ethos of neutrality, and presented with an aura of\ncertainty. They step out of the shadows of their human\ncreators, enter center stage, and, in the arguments and\nclaims of countless profiteers, start to speak for\nthemselves.\nWhat are the reasons for this shift toward mechanical\nobjectivity? On the one hand, technological progress\nplayed a significant role. The growing availability of\never more capable machinery changed the face of the\naccounting profession. The idea was powerful: The\nmore mechanized a process, the more automated a pro-\ncedure, the less the need for--and danger of--subjective\nhuman intervention (Venturini et al., 2014). In the words\nof Daston and Galison (2010), ``instead of freedom of\nwill, machines offered freedom from will''. The virtuous\nmachine was conceived as the ``ultimate outsider'', and it\nwas not long until ``it became the greatest in the king-\ndom of quantification'' (Porter, 1995). Consequently, the\n``honest instrument'' with its ``glow of veracity'' both\nserved as a means to and symbol of mechanical object-\nOn the other hand, there was a social dimension:\nThe pursuit of quantitative rigor was seen as a strategy\nto adapt to new external pressures in a rapidly changing\npolitical environment. War and economic crisis had left\ntheir marks, and the dynamics of democracy increased\nthe need for hard evidence and professional account-\nability. Confronted with public distrust, invasive audit-\ning, and competing political demands, bureaucratic\nagencies and scientific communities sought to withstand\nscrutiny and minimize responsibility by adhering to\nrigid protocols and explicit decision criteria. This will-\ningness for personal restraint is a sign of professional\nweakness rather than strength: The more permeable the\nboundaries of a discipline, the higher its vulnerability to\noutside criticism, the more tempting the language of\nmechanical objectivity becomes. Consequently, the\nappeal of standardized methods is especially great in\ncultures where the faith in other forms of trust has\nbeen shattered. As Porter (1995) notes, methodological\nstrictness and objective rules may serve as an alternative\nto trust and shared beliefs. Where trust is missing and\nsuspicion prevails, numbers are meant to fill the gap:\nRegarded as carefully measured matters of fact, they\nare expected to offer a sense of fairness and justice,\na way of making decisions without having to decide, a\nchance to de-politicize legislation. This push for imper-\nsonal numerical evidence is however not so much rooted\nin the inner workings of quantitative professions, but in\nthe needs and demands of a specific socio-political cul-\nture, a democratic system undermined by pervasive dis-\ntrust and uncertainty. It is on these grounds that the Big\nData phenomenon continues to blossom.\nThe epistemic promises of Big Data connect to the\nideal of mechanical objectivity in several ways, not only\nfortifying but also expanding the appeal of the doctrine:\nFirst, a child of new analytical techniques and the\nprogressing computerization of society, Big Data\npledges to extend the reach of automation, from data\ncollection to matters of storage, curation, and analysis.\nThe virtuous machine emerges as ever more powerful as\nit covers increasingly large parts of the analytical and\ndecision-making process.\nSecond, by capturing massive amounts of data and\nfocusing on correlations rather than causes, Big Data\nclaims to reduce the need for theory, models, and, in\nextension, human expertise. In addition, modern data\nanalysis software is often thoroughly opaque, with a\nphenomenology that emphasizes both uniformity and\nimpersonality.\nThird, Big Data promises to expand the realm of\nwhat can be measured. Trackers, social media, and\nthe Internet of Things allow to trace and gauge move-\nments, actions, and behaviors in ways that were previ-\nously unfeasible. Fully quantified and free from bias,\nBig Data pushes the tenets of mechanical objectivity\ninto ever more areas of application.\nFourth and finally, settling for neither the present\nnor the past, Big Data aspires to calculate what is yet\nto come. Smart, fast, and cheap predictive techniques\nare meant to support decision making and optimize\nresource allocation across many government sectors,\napplying a mechanical mindset to the colonization of\nthe future.\nThe limitations of these ``sociotechnical imaginaries''\n(Jasanoff and Kim, 2009) have been discussed elsewhere\n(e.g., Kitchin, 2014b), but the point here is to develop a\nbetter understanding of how the current language of Big\nData-related hope and hype intersects with and relies on\nparticular forms of trust and objectivity, which, in turn,\ncan be conceived as products of a specific socio-political\nculture. In a climate of distrust, crisis, and uncertainty,\nofficials' adherence to supposedly impartial numbers\nmay be regarded as a strategy of defense, an attempt\n4 Big Data & Society\nto shield themselves from increased public and judicial\nscrutiny. It is not by coincidence that the European\nCommission, whose authority continues to be challenged\nby citizens and national governments alike, has emerged\nas one of the most zealous political quantifiers.\nBig Data has been repeatedly criticized for its positiv-\nist epistemology and its support of techno-capitalism,\nand while such criticism has its merits, it pays little atten-\ntion to the circumstances and dynamics that contribute\nto the creation and internalization of corresponding\nnorms and values. Our proposition is simple: Instead of\nfocusing exclusively on the potential consequences of the\nBig Data phenomenon, we can gain additional insight\nfrom examining its social and political, but also its tech-\nnical and epistemic roots. Such an approach may foster\nmore, not less, critical engagement as it shifts the perspec-\ntive and situates Big Data discourse within a broader\nhistorical narrative. As Barnes and Wilson (2014) argue:\nBy showing that Big Data is historical, we show the\nassumptions that were built into it, as well as the con-\ntestations around them. Big Data becomes no longer a\nblack box, self-contained, sealed and impregnable, but\nis opened up, available for verbalist discussion and\ncontestation.\nWe wholeheartedly agree.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with\nrespect to the research, authorship, and/or publication of this\narticle.\nFunding\nThe author(s) disclosed receipt of the following financial sup-\nport for the research, authorship, and/or publication of this\nReferences\nAdams V, Murphy M and Clarke AE (2009) Anticipation:\nTechnoscience, life, affect, temporality. Subjectivity 28(1):\nAnderson C (2009) The end of theory: The big data deluge\nmakes the scientific method obsolete. Wired. Available at:\nBarnes TJ (2013) Big Data, little history. Dialogues in Human\nBarnes TJ and Wilson MW (2014) Big Data, social physics,\nand spatial analysis: The early years. Big Data & Society\nBarocas S and Selbst AD (2015) Big Data's disparate impact.\nCalifornia Law Review (forthcoming 2016). Available at:\nboyd D and Crawford K (2012) Critical question for Big\nData. Provocations for a cultural, technological, and\nscholarly phenomenon. Information, Communication &\nBrooks D (2013) The philosophy of data. New York Times.\nion/brooks-the-philosophy-of-data.html (accessed 2 May\nCohen BI (2005) Triumph of Numbers: How Counting Shaped\nModern Life. New York, NY: W. W. Norton & Company.\nDaston L and Galison P (2010) Objectivity. New York, NY:\nZone Books.\nDaston L and Galison P (1992) The image of objectivity.\nDesrosie\n` res A (1998) The Politics of Large Numbers. A\nHistory of Statistical Reasoning. Cambridge, MA:\nHarvard University Press.\nDingens J (2005) The Condor Years: How Pinochet and his\nAllies Brought Terrorism to Three Continents. New York,\nNY: The New Press.\nEuropean Commission (EC) (2012) From Crisis of Trust\nto Open Governing. Available at: http://europa.eu/rapid/\nEuropean Commission (EC) (2013) EU Leaders Call for\nAction on Digital Economy, Innovation and Services.\nAvaialble at: http://ec.europa.eu/newsroom/dae/document.\nEuropean Commission (EC) (2014a) The Data Gold\nRush. Available at: http://europa.eu/rapid/press-release_\nEuropean Commission (EC) (2014b) Towards a Thriving\nData-Driven Economy. Available at: http://ec.europa.eu/\ninformation_society/newsroom/cf/dae/document.cfm?\nEuropean Commission (EC) (2015a) Data for Policy: When\nthe Haystack Is Made of Needles. A Call for Contributions.\nAvailable at: http://ec.europa.eu/digital-agenda/en/news/\ndata-policy-when-haystack-made-needles-call-contributions\nEuropean Commission (EC) (2015b) Making Big Data Work\nfor Europe. Available at: https://ec.europa.eu/digital-\nExecutive Office of the President (EOP) (2014) Big Data:\nSeizing Opportunities, Preserving Values. Available at:\nhttp://www.whitehouse.gov/sites/default/files/docs/big_\ndata_privacy_report_5.1.14_final_print.pdf (accessed 2\nGiddens A (1990) The Consequences of Modernity.\nCambridge: Polity Press.\nGitelman L (ed.) (2013) `Raw Data' Is an Oxymoron.\nCambridge, MA: MIT Press.\nGrandin G (2014) The anti-socialist origins of big data. The\nNation. Available at: http://www.thenation.com/article/\nanti-socialist-origins-big-data/ (accessed 2 May 2016).\nHaskins R (2014) Show Me the Evidence: Obama's Fight for\nRigor and Results in Social Policy. Washington, DC: The\nBrookings Institution.\nJasanoff S and Kim S-H (2009) Containing the atom:\nSociotechnical imaginaries and nuclear power in the\nRieder and Simon 5\nKalil T and Zhao F (2013) Unleashing the Power of Big Data.\nThe White House Blog. Available at: https://www.white-\nKitchin R (2014a) Big Data, new epistemologies and para-\nKitchin R (2014b) The Data Revolution. Big Data, Open Data,\nData Infrastructures & Their Limitations. London: Sage.\nLaney D (2001) 3D management: Controlling data volume,\nvelocity and variety. Available at: http://blogs.gartner.\nManagement-Controlling-Data-Volume-Velocity-and-\nLeonelli S (2014) What difference does quantity make? On the\nepistemology of big data in biology. Big Data & Society\nMackenzie A (2013) Programming subjects in the regime of\nanticipation: Software studies and subjectivity. Subjectivity\nMayer-Scho\n\u00a8 nberger V and Cukier K (2013) Big Data. A\nRevolution That Will Transform How We Live, Work,\nAnd Think. New York, NY: Houghton Mifflin Harcourt.\nMedina E (2011) Cybernetic Revolutonaries: Technology and\nPolitics in Allende's Chile. Cambridge, MA: MIT Press.\nMorozov E (2014) The planning machine. New Yorker.\nAvailable at: http://www.newyorker.com/magazine/2014/\nNowotny H, Scott P and Gibbons M (2001) Re-thinking\nScience: Knowledge and the Public in an Age of\nUncertainty. Cambridge: Polity Press.\nOhm P (2010) Broken promises of privacy: Responding to the\nsurprising failure of anonymization. UCLA Law Review 57:\nPasquale F (2015) The Black Box Society: The Secret\nAlgorithms that Control Money and Information.\nCambridge, MA: Harvard University Press.\nPorter TM (1995) Trust in Numbers: The Pursuit of\nObjectivity in Science and Public Life. Princeton, NJ:\nPrinceton University Press.\nRubinstein IS (2013) Big Data: The end of privacy or a new\nShapin S (1994) A Social History of Truth: Civility and Science\nin Seventeenth-Century England. Chicago: The University of\nChicago Press.\nSolesbury W (2002) The ascendancy of evidence. Planning\nSunstein CR (2012) Regulation in an Uncertain World.\nNational Academy of Sciences. Available at: https://\nwww.whitehouse.gov/sites/default/files/omb/inforeg/\nUrahn SK (2015) A tipping point on evidence-based policy-\nmaking. Governing. Available at: http://www.governing.-\ncom/columns/smart-mgmt/col-state-local-government-tip-\nping-point-evidence-based-policymaking.html (accessed 2\nVenturini T, Laffite NB, Cointet J-P, et al. (2014) Three maps\nand three misunderstandings: A digital mapping of climate\nThis article is a part of Special theme on Critical Data Studies. To see a full list of all articles in this special\ntheme, please click here: http://bds.sagepub.com/content/critical-data-studies.\n6 Big Data & Society"
}