{
    "abstract": "Background Unrelieved pain among nursing home (NH) residents is a well- documented problem. Attempts have been made to enhance pain management for older adults, including those in NHs. Several evidence-based clinical guidelines have been published to assist providers in assessing and managing acute and chronic pain in older adults. Despite the proliferation and dissemination of these practice guide- lines, research has shown that intensive systems-level implementation strategies are necessary to change clinical practice and patient outcomes within a health-care set- ting. One promising approach is the embedding of guidelines into explicit protocols and algorithms to enhance decision making.",
    "reduced_content": "Addressing methodological challenges\nin implementing the nursing home pain\nmanagement algorithm randomized\ncontrolled trial\nMary Erseka,b, Nayak Polissarc, Anna Du Pend, Anita Jablonskie, Keela Herrf\nand Moni B Neradileka\nBackground Unrelieved pain among nursing home (NH) residents is a well-\ndocumented problem. Attempts have been made to enhance pain management for\nolder adults, including those in NHs. Several evidence-based clinical guidelines have\nbeen published to assist providers in assessing and managing acute and chronic pain\nin older adults. Despite the proliferation and dissemination of these practice guide-\nlines, research has shown that intensive systems-level implementation strategies are\nnecessary to change clinical practice and patient outcomes within a health-care set-\nting. One promising approach is the embedding of guidelines into explicit protocols\nand algorithms to enhance decision making.\nPurpose The goal of the article is to describe several issues that arose in the design\nand conduct of a study that compared the effectiveness of pain management algo-\nrithms coupled with a comprehensive adoption program versus the effectiveness\nof education alone in improving evidence-based pain assessment and manage-\nment practices, decreasing pain and depressive symptoms, and enhancing mobility\namong NH residents.\nMethods The study used a cluster-randomized controlled trial (RCT) design in\nwhich the individual NH was the unit of randomization. The Roger's Diffusion of\nInnovations theory provided the framework for the intervention. Outcome measures\nwere surrogate-reported usual pain, self-reported usual and worst pain, and self-\nreported pain-related interference with activities, depression, and mobility.\nResults The final sample consisted of 485 NH residents from 27 NHs. The investiga-\ntors were able to use a staggered enrollment strategy to recruit and retain facilities.\nThe adaptive randomization procedures were successful in balancing intervention\nand control sites on key NH characteristics. Several strategies were successfully\nimplemented to enhance the adoption of the algorithm.\nLimitations/Lessons The investigators encountered several methodological chal-\nlenges that were inherent to both the design and implementation of the study. The\nmost problematic issue concerned the measurement of outcomes in persons with\nmoderate to severe cognitive impairment. It was difficult to identify valid, reliable,\naPhiladelphia Veterans Affairs Medical Center, Philadelphia, PA, USA, bUniversity of Pennsylvania School of Nursing,\nPhiladelphia, PA, USA, cThe Mountain-Whisper-Light Statistics, Seattle, WA, USA, dDepartment of Family Medicine,\nUniversity of Washington School of Medicine, Seattle, WA, USA, eSeattle University College of Nursing, Seattle, WA, USA,\nfUniversity of Iowa College of Nursing, Iowa City, IA, USA\nAuthor for correspondence: Mary Ersek, University of Pennsylvania School of Nursing, 418 Curie Blvd., Room 329,\nEmail: ersekm@nursing.upenn.edu\nDESIGN\nPain management algorithm clinical trial 635\nand sensitive outcome measures that could be applied to all NH residents regard-\nless of the ability to self-report. Another challenge was the inability to incorporate\nadvances in implementation science into the ongoing study\nConclusions Methodological challenges are inevitable in the conduct of an RCT.\nThe need to optimize internal validity by adhering to the study protocol is compro-\nmised by the emergent logistical issues that arise during the course of the study.\nIntroduction\nConducting clinical trials in any setting is challeng-\ning. However, the nursing home (NH) environment\ncan be particularly daunting. Implementing a com-\nplex multimodal intervention adds to the investiga-\ntors' anxieties. Unexpected challenges occur,\nregardless of the care with which the research team\nplans and executes the study. In sharing and dis-\ncussing the `hits' and `misses', an investigative team\ncan contribute to science by allowing others to learn\nfrom their experiences. In this spirit, we describe\nour experiences conducting a randomized con-\ntrolled trial (RCT) to test a set of pain assessment\nand management algorithms (step-by-step flow-\ncharts for clinical use) in 27 Washington State NHs.\nWe focus on several design decisions we made and\nsome challenges we faced as a result of these deci-\nsions. We also discuss other obstacles that we had to\novercome. Our examples of these `untoward conse-\nquences' and other challenges may provide insight\nand guidance to other investigators.\nRationale for the study\nPain is a common problem among older NH resi-\ndents and is associated with depression, sleep dis-\nturbance, decreased mobility, increased health-care\nutilization, and physical and social role dysfunction\n[1\u00ad3]. Despite the scope of the problem and its neg-\native consequences, there is much evidence that\npain is often not assessed and is undertreated in this\nvulnerable group, even though evidence-based\nguidelines for assessing and treating pain are avail-\nChanging clinical practice involves attention to\nmultiple factors that influence individuals' or\ngroups' willingness and ability to incorporate new\nknowledge or a new system of care. This use of mul-\ntiple strategies to encourage the adoption of evidence-\nbased practices is a staple of implementation\nscience, which the National Institutes of Health\ndefine as `the scientific study of methods to promote\nthe integration of research findings and evidence-\nbased interventions into health-care policy and\npractice' (http://grants.nih.gov/grants/guide/pa-files/\nseeks to understand the behavior of health-care pro-\nfessionals and support staff, health-care organiza-\ntions, consumers and family members, and policy\nmakers in context as key variables in the sustainable\nadoption, implementation, and uptake of evidence-\nbased interventions. Implementation scientists rec-\nognize that there may be two components being\ntested in a clinical trial: the intervention itself (in\nthis case, the pain management algorithm) and the\nimplementation approaches [10].\nOne classic and widely used framework to under-\nstand, study, and facilitate the adoption of new\nbehaviors into regular practice is the Rogers'\nDiffusion of Innovations Theory [11]. According to\nthis theory, an innovation is an idea or a process\nthat is perceived as new by an individual or a group.\nDiffusion is the process by which an innovation is\ncommunicated and adopted over time among mem-\nbers of the social system. Many successful strategies\nfor changing clinical practice incorporate Rogers'\nideas. Potentially successful change strategies\ninclude providing feedback to care providers from\n`influential colleagues', multidisciplinary teams,\nfollow-up reminders, and academic detailing, which\ninvolves providing practicing clinicians with spe-\ncific education about best practices [12,13]. Gilbody\net al. [14] reported that clinician education alone\nwas ineffective in changing care practices, but com-\nplex multifaceted interventions that incorporated\nclinician education were successful. Specific strate-\ngies within these multicomponent interventions\ninclude collaborative patient management, clini-\ncian education, enhanced roles for nurses, and use\nof opinion leaders. The authors also identified the\nuse of algorithms as an effective method for chang-\ning practice.\nClinical algorithms are visual road maps that use\na step-by-step decision-making process to enhance\nclinicians' ability to make sound clinical decisions\nbased on best evidence [15]. Clinical trials con-\nducted in diverse settings have shown that assess-\nment and treatment algorithms are effective in\nimproving practice and patient outcomes [16\u00ad18].\nThe aim of the study was to examine the effective-\nness of a set of pain management algorithms coupled\nwith a comprehensive adoption program in improving\nevidence-based pain assessment and management\npractices, decreasing pain and depression, and\nimproving mobility among NH residents. The algo-\nrithm (ALG) intervention was compared to an educa-\ntion (EDU)-only control. Table 1 lists the specific aims\nand accompanying hypotheses of the trial. Figure 1\nrepresents an outline of the study procedures.\nStudy design decisions\nThe study used a cluster RCT design with NHs as the\nunit of randomization. We chose to randomize\nfacilities rather than individuals within facilities to\nminimize cross-contamination between interven-\ntion and control participants, which can dilute\ntreatment effects [19]. Using a standard approach\nfor RCTs, randomization occurred following recruit-\nment of NH residents within each facility and com-\npletion of the baseline measurements, and prior to\ninitiating any intervention activities (ALG) or\nclasses (EDU). Assignment to ALG or EDU was made\nby the statistician coauthors (M. B. N./N. P.). To\nmanage enrollment, data collection, and other\nstudy activities, facilities were enrolled in several\nstudy procedures were approved by the Swedish\nMedical Center Institutional Review Board (IRB)\nEligible NH residents were (1) 65 years or older;\n(2) receiving residential, long-term care at the facil-\nity (not Medicare-funded skilled nursing or rehabili-\ntation services); and (3) experiencing moderate to\nsevere pain at some time in the week prior to screen-\ning. Participants gave signed consent; the surrogate\ndecision maker agreed to participation whenever a\nresident was incapable of providing consent. We\nchose to include persons with moderate to severe\ncognitive impairment because they comprise nearly\n50% of the NH residents [20], and we wanted to\nmaximize the generalizability of our study findings.\nAlso, older persons with cognitive impairment are\nat greater risk for underdetection and undertreat-\nment of pain than older persons who are cognitively\nWe applied principles of the Diffusion of\nInnovations Theory to several strategies that we\nimplemented to support adoption of the proposed\nclinical changes. First, the ALG intervention focused\non the facility, rather than individual clinicians or\nprimary care providers (PCPs). This approach was\nchosen primarily because of the relative infrequency\nof physician visits to the NH [24,25], the educa-\ntional needs of the NH staff, and the central role of\nthe NH staff in assessing pain. Also, the goal of\nchanging the NH culture and making systematic\nchanges to promote acceptance and use of the algo-\nrithms dictated a focus on the facility rather than\nSecond, the intervention focused on the assess-\nment and treatment algorithms to address pain.\nEach facility received copies of a pain management\nalgorithm book for all licensed nursing staff. The\nalgorithm book contained 11 linked algorithms\ncovering the following topics: general pain assess-\nment (see Figure 2), pain assessment and manage-\nment in cognitively impaired NH residents, opioid\ninitiation and titration, acetaminophen administra-\ntion, guidance on appropriate use of nonsteroidal\nanti-inflammatory agents, pharmacologic treat-\nment of neuropathic pain, and assessment and\ntreatment for three common side effects, that is,\nTable 1. Study Aims and Hypotheses\nAims Hypotheses\nAim 1. Evaluate the effectiveness of a pain management\nalgorithm coupled with intense diffusion strategies (ALG)\nas compared with pain education (EDU) alone in\nimproving pain, mobility, and depression among nursing\nhome residents at the 14\u00ad16 weeks timepoint.\nHypothesis 1-1. At posttreatment (timepoint 2), ALG residents will\ndemonstrate greater decreases in surrogate-reported pain than residents\nin the EDU group.\nHypothesis 1-2. At posttreatment (timepoint 2), ALG residents will\ndemonstrate less depression, less self-reported pain intensity and pain-\nrelated interference, and enhanced mobility compared with residents in\nthe EDU group.\nAim 2. Determine the extent to which adherence to the\nALG and organizational factors are associated with\nchanges in residents' mobility, pain, and depression\nand the extent to which changes in these variables\nare associated with changes in outcomes.\nHypothesis 2-1. Pain treatment plans for residents in ALG facilities will\nshow greater pre- to posttreatment increases in adherence than will EDU\nfacilities.\nHypothesis 2-2. Pre- to posttreatment changes in residents' mobility,\npain, and depression will be associated with adherence to the\nalgorithms and organizational factors.\nAim 3. Evaluate the persistence of changes in process\nand outcome variables at long-term follow-up (6 months\npostintervention).\nHypothesis 3-1. Differences between ALG and EDU residents' outcomes\nwill be maintained at 6-month follow-up (timepoint 3).\nHypothesis 3-2. Differences in adherence to the ALG, pre- and post-ALG\nintervention, will be maintained at 6-month follow-up (timepoint 3).\nALG: algorithm intervention; EDU: education-only control.\nPain management algorithm clinical trial 637\nconstipation, sedation, and delirium. Also included\nin each section were `Guiding Principles', formatted\nas bulleted lists, as well as tables of commonly used\npain medications. The investigators drafted the\nbook, which was based on the most current pub-\nlished clinical guidelines [8,27\u00ad29] and high-quality\nliterature reviews [30] available at the time of the\nstudy. All content was then reviewed by a panel of\nsix nationally recognized experts in geriatric pain\nmanagement and dementia. To keep the content\ncurrent throughout the project, we revised the book\n2 years after the initial edition was produced, using\nan updated literature and expert panel review.\nIn addition to copies of the pain management\nalgorithm book, intervention facilities received a\nthree-ring binder containing supplemental, high-\nvalue resource materials as well as an additional\ncopy of the algorithm book to serve as a central ref-\nerence guide in the facility. Each nursing unit and\nstaff development coordinator also received copies\nof the resource binder. The algorithm and reference\nmaterials addressed several barriers affecting pain\nmanagement, which included misconceptions\nabout pain in older adults, evaluation of pain in NH\nresidents with cognitive impairment, older adults'\nincreased sensitivity to medication side effects, and\nWe provided staff education and support for\nusing the algorithm and resource materials. One of\nthe investigators (A. D. or M. E.) led one class each\nweek for 4 weeks. The classes covered each algo-\nrithm, and content was reviewed as necessary. Each\nclass was offered as many as three times to facilitate\nattendance across shifts. We also videotaped the\nclasses for staff who were unable to attend the live\nsessions. Case studies were incorporated into classes\nto demonstrate use of the algorithms. We also\nencouraged staff to discuss challenging pain man-\nagement cases from their own practice and demon-\nstrated how to apply the algorithms to these cases.\nThird, we guided each facility in forming a pain\nmanagement team that comprised clinical champi-\nons and opinion leaders from multiple disciplines.\nThe purpose of the teams was to provide leadership,\nstability, and guidance for implementing the algo-\nrithm into practice; each team included one or more\n`clinical champions'. These teams began meeting\nduring the third week of the classes and continued\nfor 2 weeks after the classes ended. They worked\nwith one of the investigators (A. D.) to identify and\naddress organizational barriers to pain management\nand to discuss challenging specific pain problems\nencountered in NHs. The pain teams were also\ncharged with reviewing and customizing multiple\nchart forms (e.g., pain flow sheets, pain assessment\nforms) and policies developed by the investigators\nfor incorporation into the facility's procedures and\nprocesses.\nFourth, we procured the support and involve-\nment of PCPs. Upon randomization of facilities to\nthe intervention, staff identified PCPs who regularly\npracticed in the facility. These clinicians received a\nletter from the Medical Director and investigators\nthat introduced the project and outlined the study\naims and procedures. They were given the investiga-\ntors' telephone numbers and email addresses and\nencouraged to contact any of them if they had ques-\ntions or concerns. The letter also invited them to\nattend a 30-min web conference that elaborated the\nalgorithm process and explained the rationale for\nfocusing on facility-wide efforts to enhance pain\nassessment and management rather than direct\nengagement with PCPs. Each PCP received a US$100\nFacility orientation to ALG\nactivities\n\u00ad Identify & orient pain\nmanagement team\n\u00ad C ollect baseline data\n(tim epoint 1)\n\u00ad C ontact prim ary care\nproviders\n\u00ad Facility orientation to\nEDU activities\n\u00ad Collect baseline data\n(tim epoint 1)\n\u00ad timepoint 2 posttreatm ent data collection\n\u00ad C onduct 4 classes\n\u00ad Facilitate pain team\n\u00ad Conduct 4 classes\n\u00ad Booster activities\n\u00ad Tim epoint three 6-m onth F/U data collection\nRandom ization by facility\nTreatm ent (ALG)\nControl (EDU)\nW eeks 1\u00ad3: Introductory Activities\n\u00ad R esident screening and consenting\n\u00ad Facility orientation to project\n\u00ad Schedule classes\n\u00ad C ontinue pain team\nactivities\nFigure 1. Schematic of the study activities.\nhonorarium for watching the webinar and was\ninvited to join the pain team.\nOur fifth strategy was aimed at maintaining\nadherence to the algorithm and other pain manage-\nment practices after the period of intensive training\nand pain team start-up activities. Approximately 8\nweeks following the intervention, we initiated\nbiweekly `boosters', which continued for 8 weeks.\nBoosters included items such as pens and magnets\nfeaturing pain-related logos, and `Pain-Free Zone'\nposters. We also sent `Fast Facts FAXes' containing\nbrief descriptions of information that was presented\nin the algorithm classes. In some facilities, we con-\nducted telephone conferences with pain team mem-\nbers that focused on continued problem solving\naround specific cases or strategies for overcoming\nbarriers to implementation of the algorithms.\nAnother methodological decision we made in\ndesigning the trial was to avoid a `standard care' or\n`no intervention' control condition. We based our\ndecision on the idea of `resentful demoralization'\nthat occurs when people feel as though they are\nreceiving less-than-optimal treatment [33,34]. Our\nexperience working with NHs has shown that\nadministration and staff are eager for any assistance\nto improve care. If we had provided half of the\nfacilities with little or nothing, the inequity between\nintervention and control facilities and participating\nNH residents could hamper recruitment, morale,\nand willingness to stay involved in the project.\nSimilar problems also could have occurred with a\nwait-list treatment design, because wait-listed facili-\nties would have to provide baseline data and then\nwait several months to receive the intervention.\nAlthough we recognized that control facilities might\nhave demonstrated some improvement in pain and\nin processes or outcomes, we believed that educa-\ntion alone was much less likely to change signifi-\ncantly the practices and NH resident outcomes\ncompared with the ALG intervention. Thus, the\nEDU arm satisfied the goal of minimizing frustra-\ntion and attrition, while maximizing statistical\npower to detect significant differences between the\nALG and EDU groups.\nThe EDU procedure consisted of four classes\nscheduled as 1-h weekly in-services. The content\ncovered basic principles of pain assessment and\nmanagement for frail, older adults. Similar to the\nALG classes, videotapes of each session were made\navailable at every EDU facility.\nThe NH residents were the primary unit of analy-\nsis for addressing the specific aims of the study, and\nNo\nYes\nYes\nIs\nresident\ncurrently\n(in past 7 days)\nexperiencing any\ntype of\npain?\nIs pain\na result of a\ntreatable etiology\n(e.g., UTI)?\nYes\nNo\nDoes\ntreatment resolve\npain?\nYes\nNo\nCan resident give\nself-report?\nReassess as\nappropriate\nConduct\ninitial pain\nassessment\nGo to the\nPain in Nonverbal\nResidents\nAlgorithm\nTreat\netiology as\nwell as pain\nIf pain is mild to\nmoderate, go to the\nAPAP Algorithm\nor\nIf pain is moderate to\nsevere, go to the\nOpioids Algorithm\nand\nIf pain is from acute\ninflammation or bony\nmetastases, go to\nNSAIDs algorithm\nGo to the\nNeuropathic Pain\nTreatment\nAlgorithm\nand\nIf pain is moderate\nto severe, go to the\nOpioids Algorithm\nIf pain is\nNEUROPATHIC\nIf pain is\nMIXED\nIf pain is\nNOCICEPTIVE\nConduct pain\ncharacter\nassessment\nNo\nFigure 2. General pain assessment algorithm.\nUTI: urinary tract infection; NSAIDs: nonsteroidal anti-inflammatory drugs; APAP: acetaminophen.\nPain management algorithm clinical trial 639\nall analyses were based on intention to treat. We\nused linear mixed models [35] to ascertain the asso-\nciation between outcome variables and predictors.\nAll linear mixed models included a random effect\nfor the facility to account for the possible correla-\ntion of NH residents' outcomes within each facility.\nWe carried out both unadjusted and covariate-\nadjusted comparisons of outcomes between the\nALG and EDU groups. The unadjusted comparison\nof outcomes included ALG versus EDU as a predic-\ntor (a binary variable). The covariate-adjusted mod-\nels included factors selected into the linear mixed\nmodel with the forward stepwise variable selection\ntechnique (p < 0.05 for inclusion). As an alternative\nto the forward stepwise technique, we also consid-\nered the backward elimination technique (p > 0.05\nfor exclusion). After covariates were selected, the\ngroup (ALG vs. EDU) was added into the model, and\nthe covariate-adjusted association between the\ngroup and the outcome was ascertained. All calcula-\ntions were performed in the statistical language R,\nAddressing challenges in\nimplementing the study\nDespite careful planning and consideration of alter-\nnatives to the study design, we encountered several\nchallenges. One major challenge involved our\nattempts to test a complex, multimodal interven-\ntion in a variety of facilities. We used an RCT\ndesign, which is the gold standard for evaluating\ntherapies [36]. This model maximizes internal\nvalidity, often at the expense of external validity; it\ntypically is used in efficacy studies where the focus\nis on delivery of a standard treatment or interven-\ntion to a homogeneous group under optimal condi-\ntions [37]. The RCT also is used in effectiveness\nstudies such as ours, where the intervention is\ndelivered in a `real-world setting' [37]. Although\nfidelity to the study protocol is critical to the RCT\nstudy design, process evaluation and measures are\nless emphasized than outcomes. In contrast, imple-\nmentation studies often incorporate formative and\nsummative evaluation of processes, including rates\nof adoption and fidelity to the clinical interven-\ntion. These are critical elements of the implementa-\ntion study design [10].\nIn our study, we included evaluation of changes\nin process measures and their association with\npatient outcomes as one specific aim (Table 1, spe-\ncific aim 2). Our two process variables were a meas-\nure of adherence to the algorithms that used a\nchart audit tool [38] and a survey of organizational\nstructures and processes that supported and\nreflected pain best practices. In addition, we con-\nducted focus group interviews at four intervention\nfacilities in order to capture qualitative data about\nfacilitators and barriers to the adoption of the algo-\nrithms.\nHowever, we missed opportunities to collect pro-\ncess data that could have provided insight into our\nfindings. One example of a missed opportunity was\nour failure to explore the reasons for, and effects of,\nlow-PCP engagement in the study. Out of approxi-\nmately 75 PCPs who practiced in the intervention\nfacilities, only 2 viewed the webinar explaining the\nstudy and the algorithms. Moreover, few were\ninvolved in the pain teams. Because our focus was\non the nursing staff and medical directors at the\nfacilities, we did not monitor or address potential\nPCP nonadherence to evidence-based pain prac-\ntices. When we conducted our focus groups at the\nend of the study, some nursing staff reported that\nPCPs' refusal to respond to pain assessment data or\nfollow staff's recommendations was sometimes a\nproblem. Had we incorporated ongoing, intensive\nmonitoring of barriers, and addressed these barriers\nduring the study (as is done in some implementa-\ntion studies), we would have maximized the effec-\ntiveness of the intervention.\nAnother key issue arose as a result of our decision\nto include the NH residents with moderate to severe\ncognitive impairment. Of the 485 NH residents\nenrolled in the study, 361 (74%) were determined to\nbe able to provide reliable self-report at baseline. At\n(68%) participants provided reliable self-report,\nrespectively.\nBecause 26%\u00ad32% of our study participants could\nnot to provide reliable self-report, we were unable to\nuse NH resident report of pain without losing statis-\ntical power. Thus, we needed a primary outcome\nmeasure that could be collected for all NH residents,\nregardless of the ability to communicate verbally.\nInitially, we chose the Functional Independence\nMeasure (FIM) to assess ability to ambulate, either\nin a wheelchair or walking. This outcome seemed\nappropriate in that physical functioning frequently\nis used as an outcome in pain therapy trials [39] and\nin that the FIM is a valid, reliable, and widely used\nmeasure that allows for an objective evaluation that\nis not reliant on patient report [40\u00ad42]. Moreover,\nMorrison et al. [43] reported a significant, negative\nassociation between pain and FIM-locomotion\nscores in a large sample of older adults with pain.\nEarly in the trial, however, we realized that our sam-\nple of patients was very physically impaired; thus,\nthe FIM was unlikely to be sensitive enough for the\nrelatively small improvements that could be\nexpected. For this reason, we examined other out-\ncomes that were measured in all NH residents:\ndepression, pain behaviors, and surrogate (certified\nnursing assistant (CNA)) reports of usual pain inten-\nsity.\nThe Cornell Scale for Depression in Dementia\nwas collected for all NH residents; its reliability and\nvalidity are supported in persons with dementia, as\nwell as those without dementia [44\u00ad47]. However,\ndepression was a secondary outcome measure in\nthat it was influenced by, but not solely attributable\nto pain; thus, it was not an appropriate primary out-\ncome measure.\nWe then considered the pain behaviors tool,\nChecklist of Nonverbal Pain Indicators (CNPI). We\nhad initially chosen the scale because psychometric\ndata that were available at the time suggested that it\nwas reliable, valid, and clinically useful. It assessed\nonly six groups of behaviors on rest and with move-\nment and was readily understood by CNAs.\nHowever, subsequent reviews [48] as well as data\nfrom our study [49] demonstrated that the CNPI\nhad psychometric deficiencies that raised questions\nabout its suitability as the primary outcome for\npain.\nWe finally chose a surrogate pain intensity meas-\nure as the primary outcome for all the NH residents.\nWe used the Iowa Pain Thermometer (IPT), a tool\nthat uses a graphic representation of a thermometer\nin which the base is white and becomes increasingly\nred as one moves up the column. The base is\nanchored with the words `no pain', and the top of\nthe thermometer is anchored with `the most intense\npain imaginable', with additional word descriptors\nbetween these two extremes to represent different\nlevels of pain intensity. In all, 13 evenly spaced cir-\ncles, corresponding with numeric values from 0 to\n12, are placed between the thermometer's verbal\ndescriptors. Several studies have shown that the IPT\nis reliable, valid, and generally preferred over other\npain intensity tools by older adults [50\u00ad52].\nCNAs were chosen as the surrogate reporters of NH\nresidents' pain. Research has shown that with proper\ntraining, CNA proxy reports can be highly accurate\n[53]. Their estimates have been found to correlate sig-\nnificantly higher with resident's reports than esti-\nmates from other care providers [54,55]. CNAs were\nasked to observe the participant at rest and also dur-\ning movement or transfers that occurred during\nmorning care and report each behavior observed.\nBased on behaviors they observed, they reported resi-\ndents' pain using a scale in which 0 = no pain to 12 =\nthe most intense pain imaginable. To ensure that\nCNAs completed the IPT and the CNPI accurately, we\nconducted in-service training sessions at every facility\nprior to beginning data collection. Each facility also\nreceived an 8-min training DVD to educate new CNAs\nand CNAs who were unable to attend the in-service\ntraining. To minimize missing data and to assure\naccuracy further, research assistants interviewed\nCNAs after participants' morning care and marked\nthe CNAs' responses to both the IPT and CNPI, clari-\nfying instructions and items whenever necessary.\nRelying on surrogate pain reports was not entirely\nsatisfactory, because self-reported pain is generally\nviewed as the gold standard for measuring this sub-\nreported IPT allowed us to include the entire sample\nin the analysis. Studies of outcomes in persons with\nadvanced dementia and persons at end of life fre-\nquently use surrogate-reported outcomes because\npatient report usually is unavailable [59\u00ad61].\nWe retained self-reported usual and worst pain\nintensity as secondary outcomes, again using the\nIPT. Only data from participants who could provide\nverbal, reliable responses were included in the self-\nreported pain outcomes. Participants who were\ncompletely nonverbal or unable to respond to the\nquestion, `Have you experienced aches, pains or dis-\ncomfort in the past week?' (alternative phrases, e.g.,\n`Do you hurt anywhere?' or `Do you have any sore\nspots?' were used, when necessary) and to rate their\npain intensity were listed as `nonverbal'. Participants\nalso had to give reliable responses. Reliability was\nassessed in one of two ways. When the study began,\nparticipants were asked to describe the worst pain\nthey had ever experienced and to locate its intensity\non the IPT scale. A response was considered valid\nwhenever the participant reported experiencing\ntheir worst pain and located it on the top third of\nthe IPT (all reported having experienced severe pain\nas their worst). Some participants, however, strug-\ngled with assessment even though they otherwise\nseemed capable of responding to other questions in\nthe interview. As a result of discussions of this prob-\nlem with the data collection staff and among the\ninvestigators, an alternate approach was taken. The\nresearch assistant interviewing the participant\nreviewed the participant's answers for usual, worst,\nleast, and current pain. Whenever all responses were\nconsistent (e.g., worst pain was greater than least\npain), then the participant was assessed as provid-\ning reliable answers. When responses were not con-\nsistent, the research assistant then asked the\nparticipant for clarification (e.g., `How is your least\npain higher than your current pain?'). If the partici-\npant changed the response to a logically consistent\none, the response was then marked reliable. If the\nparticipant still could not correct the discrepancy,\nthe response was considered unreliable, and the\nparticipant's data were not included in the analyses.\nNH recruitment and retention\nWe initially estimated that 20 facilities (10 ALG and\n10 EDU) would yield an adequate sample of partici-\npating NH residents. Because of the relationships\nthat were forged during previous projects [62\u00ad64],\nwe were able to secure the commitment of 22 facili-\nties prior to initiating the study. However, fewer\nPain management algorithm clinical trial 641\nthan the expected number of NH residents were eli-\ngible and/or willing to participate at each facility.\nTo enroll additional NHs, we again called upon\npartners from earlier studies, and also asked\nDirectors of Nursing at participating facilities to rec-\nommend the study to their colleagues at nonpar-\nticipating NHs. Although 6 of the 22 originally\nselected facilities did not participate (one because of\nclosure), we were able to leverage our community\nconnections and recruit 28 facilities. One of these\nfacilities served as a pilot site, leaving us 27 NHs\navailable for randomization.\nInitially, we enrolled facilities in pairs to make\ndata collection and other activities manageable.\nThis decision turned out to have advantages as well\nas disadvantages. At times, the staggered enrollment\nallowed NHs to remain in the study. Several NHs\nwanted to defer enrollment because they antici-\npated a state survey in the next month, experienced\nturnover in key administrative or nursing staff,\nstruggled with inadequate staffing, or were in the\nthroes of an ownership change. Our ability to slate\nthem for a later entry into the study actually facili-\ntated retention. The lag time between recruitment\nand enrollment, however, was problematic because\nsome facilities initiated their own pain manage-\nment programs or moved on to other clinical pri-\norities while waiting to be enrolled. When these\nfacilities were finally invited to enroll in the study,\nthey declined. The administrative turnover could\ncreateproblems,aswell.WhenevertheAdministrator\nor Director of Nursing Services who signed the orig-\ninal agreement left the facility, the successor did not\nalways feel obliged to honor the agreement.\nRandomization also was complicated by enroll-\ning facilities in multiple waves. We initially planned\nto recruit facilities in pairs and, at the same time,\nbeds), ownership (for profit or not for profit), and\nquality (based on number of deficiencies or stars on\nthe five-star quality rating system). These matched\nfacilities were to be randomized one to interven-\ntion, one to control, with equal chance of assign-\nment. This strategy was successful in the first several\ngroupings but failed later on when our choices\nbecame more limited: we often enrolled facilities\nsimply because they were ready to participate. As a\nresult, the statisticians had to revise the randomiza-\ntion procedure. That is, 6 of the first 18 facilities\nwere not paired and were randomized singly with\nan equal chance of assignment to either condition.\nThe last nine facilities were randomized with an\nadaptive randomization schema that set the proba-\nbility of each possible assignment according to the\nresulting balance in the allocation of ALG versus\nEDU on key facility characteristics. There was a\nhigher probability for assignments that maintained\nor improved the balance of facility characteristics\nbetween arms than for assignments that lessened\nthat balance.\nAlthough the adaptive randomization proce-\ndures required more work, the effort involved paid\noff. Table 2 compares the intervention and control\nsites on the matching variables. Minimal differences\nwere found between intervention and control facili-\nties on these factors.\nLessons learned and conclusion\nIn the absence of an ideal testing situation in which\none has unlimited resources, all study design deci-\nsions necessarily involve the consideration and\nweighing of options on the basis of scientific princi-\nples such as internal and external validity. Moreover,\nthe resulting decisions reflect the research team's\nbest judgment given the existing scientific tools.\nOur experiences may guide investigators who plan\nTable 2. Characteristics of participating nursing homes (N = 27)\nCharacteristic Participating Nursing Homes p valuea\nNumber of deficiencies\n Greater than Washington State average 7 7\nOwnership\nGovernment 1 \nSD: standard deviation; CMS: Centers for Medicare and Medicaid Services.\naChi-squared test for number of deficiencies, Fisher's exact test for ownership, and unpaired two-sample t-test with unequal variances for ranked and\ncontinuous variables.\nfuture implementation trials or other trials among\nNH residents.\nFirst, we encourage any research team that sets\nout to test the effectiveness of a complex interven-\ntion to consider using theories and methods prom-\nulgated by implementation scientists. This field is\ngrowing rapidly, as demonstrated by journals such\nas Implementation Science and the establishment of\nthe Dissemination and Implementation Research in\nHealth Study Section (DIRH) at the National\nrecent article on hybrid designs for effectiveness\nand implementation studies provides extremely\nhelpful recommendations for ways to design trials\nthat maximize both internal and external validity.\nDamschroder and colleagues [67] reviewed pub-\nlished implementation theories and synthesized\ntheir findings into a comprehensive framework for\nimplementation research. While these articles were\nnot published in time for us to apply them to our\nstudy, our own experience during this study under-\nscores their potential value in future studies.\nA second lesson that we learned from our work\non this study should prompt researchers to con-\nsider carefully the challenges of conducting pain\nresearch in persons who cannot self-report. Many\nof the core recommended outcomes for chronic\npain clinical trials rely on patient report. Although\nthe authors of these recommendations acknowl-\nedge that, at times, behavioral observation or proxy\nreport of outcomes is necessary, they have made no\nrecommendations for specific measures [68]. In\ntheir comprehensive review, Herr and colleagues\n[48] evaluated every published pain behavioral\nassessment tool for older persons with cognitive\nimpairment and found that no measure was ade-\nquate for every population or setting. An expert\npanel reviewed several of the tools and, based on\nseveral characteristics, including clinical utility,\nrecommended two of the tools [69]; however, other\nstudies question the psychometric properties of\nthese tools [49,70]. There is an urgent need to iden-\ntify or develop a more specific, sensitive, and clini-\ncally useful pain measure for nonverbal persons.\nWe suggest that, while these vulnerable persons\nshould still be included in clinical pain trials,\nresearchers should, for their part, exercise great\ncaution in choosing outcomes.\nImproving the quality of pain management\ndelivered to NH residents is an urgent health-care\nneed. This article describes a complex clinical trial\ndesigned to improve pain assessment and manage-\nment practice in NHs. We describe several decisions\nthat were made to maximize internal and external\nvalidity, as well as to address the logistical chal-\nlenges we encountered. In addition, we discuss sev-\neral problems that arose during the course of the\nstudy and the ways in which we approached these\nchallenges. It is our hope that the insights and strat-\negies gained from this study will assist others in\ndesigning future studies and addressing anticipated\nchallenges.\n"
}