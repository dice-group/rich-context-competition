{
    "abstract": "Abstract\nThis paper draws from critical data studies and related fields to investigate police officer-involved homicide data for Los\nAngeles County. We frame police officer-involved homicide data as a rhetorical tool that can reify certain assumptions\nabout the world and extend regimes of power. We highlight the possibility that this type of sensitive civic data can be\ninvestigated and employed within local communities through creative practice. Community involvement with data can\ncreate a countervailing force to powerful dominant narratives and supplement activist projects that hold local officials\naccountable for their actions. Our analysis examines four Los Angeles County police officer-involved homicide data sets.\nFirst, we provide accounts of the semantics, granularity, scale and transparency of this local data. Then, we describe a\n``counter data action,'' an event that invited members of the community to identify the limits and challenges present in\npolice officer-involved homicide data and to propose new methods for deriving meaning from these indicators and\nstatistics.\n",
    "reduced_content": "Original Research Article\nThe conundrum of police\nofficer-involved homicides:\nCounter-data in Los Angeles County\nMorgan Currie, Britt S Paris, Irene Pasquetto and\nJennifer Pierre\n Keywords\nData, police, community, hackathon, Los Angeles, infrastructure\nIntroduction\nNow data seems like a dry and boring word, but with-\nout it, we cannot understand our world and make it\nbetter. How can we address concerns about use of\nforce, how can we address concerns about officer\ninvolved shootings, if we do not have a reliable grasp\nof the demographics and the circumstances of those\nincidents? [. . .] Without complete and accurate data,\nwe are left with ideological thunderbolts, and that\nhelps spark unrest and distrust and does not help us\nget better. --FBI Director James Coney, February 12,\nspate of killings of unarmed African Americans by\npolice officers around the United States. Incidents\nthat took place in Ferguson, Missouri; Baltimore;\nNew York; and Los Angeles, among others, ignited a\nfrustrated public who took to the streets and launched\nsocial media campaigns to challenge the violence and\nracial profiling by police officials. Local and national\nadministrations responded by implementing task forces\nand new policies around officer conduct. Yet even with\nnew corrective measures in place, the disturbing trend\nof racially targeted violence exposed the difficulty of\ntallying the extent of these killings, thanks to a signifi-\ncant gap of data on the number of police officer-\ninvolved homicides (POIHs) across the US. Scholars\nof Criminal Justice, Public Health, and Public Policy\nhave all documented these failings since the 1970s,\nexposed the data's alarming incompleteness to a wider\nLos Angeles Department of Information Studies, University of California,\nCorresponding author:\nBritt S Paris, UCLA, 290 Charles E Young Dr N Los Angeles,\nEmail: parisb@ucla.edu\nBig Data & Society\nbds.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License (http://\nwww.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-\nat-sage).\nreporter Reuben Fischer-Baum notes, the FBI's\nSupplementary Homicide Report (SHR)--the fed-\neral database of police shootings generally referenced\nby news reports--is an inadequate accounting of\nsuch statistics because it only publishes police\nhomicides declared `justified' (Fischer-Baum, 2014).\nFurthermore, law enforcement agencies are not man-\ndated to report these deaths, leading to a reporting rate\nof less than a third. When states do report, the data\ncould be differently collected across states and local\nSuch elisions in official data come at a time of so-\ncalled data deluge as we increasingly turn to data as a\nmechanism for solving societal problems. This impulse\nwas on display in one of President Barack Obama's first\nMemorandums in office. The Transparency and Open\nGovernment initiative in 2009 committed to ``unprece-\ndented levels of openness,'' most visibly through a web-\nsite of federal databases, data.gov (Obama, 2009). The\nwebsite's thousands of executive agency datasets are\navailable without fees and with minimal licensing\nrestrictions; they provide a window into government\nprocesses such as budgeting, environmental oversight,\nand scientific research. Providing a rich set of resources\nfor research and technological innovation, the website\nalso promises greater insight into government\nprocedures.\nThe lack of data on POIHs, however, reveals that\nthere are ongoing gaps in the government's transpar-\nency efforts. Despite the enormous apparati our gov-\nernment invests in other types of data collection,\ndata.gov currently contains no downloadable national\ndatabase of POIH data and only links to a website\nmaintained by the Department of Justice, where the\ndata is not easily accessible or downloadable.4 While\nObama's Police Data Initiative is a recent step towards\nremedying this situation, official information on such\nkillings remains fragmentary and difficult to find (Smith\nand Austin, 2015). National-level data are overall inter-\nested in measures of accountability, yet the ellipses in\nthese datasets seem primarily to result from the lack of\na data assemblage that would support the consistent\ncollection and recording of data, as well as the dissem-\nination of the data that is collected, even though these\nlarge organizations would ostensibly have the resources\nand labor power to oversee efficient data production.\nSome of the best-kept statistics on national POIH\nare not government-based but collected by activist\ngroups and newspapers. Two of the largest,\nKilledByPolice.net and Fatal Encounters, are civilian\nefforts. Operation Ghetto Storm, published by the\nMalcolm X grassroots committee, released a 2012\nreport using statistical information from local police\ndepartments on police killings of African Americans\nin the U.S. The Center for Policing Equity at UCLA\nsimilarly collects and analyzes information on police-\ncivilian encounters, studying racial profiling as one of\nfour primary areas of concern. Recently, both The\nGuardian and The Washington Post have also estab-\nlished their own national counts on POIH in the U.S.5\nThe data on homicides collected by law enforcement\nand civic groups provides a case to examine the cultural\nand political dimensions of such statistics and to pos-\nition this data within power struggles to own, manage,\nand share it among different groups. This approach is\nin line with the growing area of research called critical\ndata studies, a body of scholarship that shares concerns\nwith critical informatics, statactivism, critical making,\nand critical information studies. Critical data studies\nseeks to explore data as situated in complex assem-\nblages of action, from data collection and categoriza-\ntion to its subsequent cleaning, storing, and\ndissemination. This framework also considers how\nthis data is then granted meaning and value as it\nbecomes operable in different situations. Using this the-\noretical understanding of data, this research then asks\nhow we can move beyond dissecting and analyzing\nPOIH data towards understanding it as a lever of pol-\nitical action. We have found through our research that\ncommunity groups are concerned with augmenting the\ncurrent gaps in local and national data collecting and\npublishing this data themselves. Through mixed-meth-\nods data collection, analysis, and visualization, activists\ncan provide an alternative to the official statistical\nellipses and foster a call to political action.\nIn what follows, we lay out existing research con-\nducted within critical data studies and related fields\nand situate our research on POIH data within this lit-\nerature. We present a critical analysis of existing Los\nAngeles County POIH data to understand how the\nevents and evidence surrounding a life taken become\nrepresented as a metric imbued with rhetorical power.\nFinally, we describe what we term, after Dalton and\nThatcher, a counter-data action, a hackathon that\ninvited community groups to examine and re-interpret\nPOIH data. The event outcomes challenge the existing\n``official'' data by examining it and remixing it with\nPOIH data collected by local media and community\ngroups in Los Angeles in an effort to build counter-\nnarratives to the federal accounts.\nSituating data in assemblages\nA major goal of critical data studies is to understand\ndata as situated in socio-technical systems that sur-\nround its production, processing, storing, sharing, ana-\nlysis, and reuse. Data assemblages, as Kitchin terms\nthese vast systems, are comprised not just of database\ninfrastructures, but also the ``technological, political,\n2 Big Data & Society\nsocial and economic apparatuses that frames their\nnature, operation and work'' (Kitchin et al., 2015).\nData assemblages are maintained by the practices that\nemerge around them, including their production and\ncollation with other data systems, their subsequent dis-\ntribution by scientific literature or financial markets,\nand citizen efforts to work with data. A growing body\nof research examines the labor and political economies\nentailed in the reproduction of these assemblages,\nfocusing on practices as diverse as meteorological\ndata (Bates, 2015); data produced by for-profit educa-\ntion companies (Williamson, 2016), and order security\ndata (Ajana, 2015). In this literature, the production of\ndata assemblages is not a neutral, technical process, but\na normative, political, and ethical one that is contingent\nand often contested, with consequences for subsequent\nanalysis, interpretation, and action (Kitchin, 2014).\nData assemblages also function as a representation\nof knowledge, with the ability to shape what we know\nand what we do based on that knowledge. These sys-\ntems carry complex epistemological implications that\nencourage careful consideration of what sorts of know-\nledge we can derive from data, as well as practical\nimplications--what types of action should be taken\nbased on the knowledge resulting from data. As such,\nwe are encouraged to question how decisions made in\nthe design and use of these tools shape our understand-\ning of the world in which we live.\nLiterature from critical data studies implicates the\nfollowing three considerations of data assemblages: an\nepistemological stance that views data as consisting of\nmaterial and discursive systems that reify certain\nassumptions about the world, as well as involve and\nextend regimes of power; the need to investigate meth-\nods and designs of data construction, including choices\nmade about definitions of phenomena, granularity, and\nscope of the dataset, and a dataset's position within\nwider assemblages of support; and finally, the import-\nance of counter-data action, or engagement with a crit-\nical framework through practical applications in which\nindividuals actively interrogate data and their relation\nto it, as well as improve data literacy in communities\nthat have particular stakes in certain data sets.\nData as a rhetorical tool\nCritical data studies generally critiques the widely held\nunderstanding of data as an objective set of facts that\nexist prior to ideology, politics, or interpretation\n(Kitchin, 2014). The common adage ``the data speaks\nfor itself'' assumes that this data can be used to deter-\nmine direct meaning that transcends context or\ndomain-specific knowledge.6 In contrast, data is here\nunderstood as a contingent set of processes that shape\nthe objects represented. Observations are therefore not\nsimply supported by data, but are generated by them,\ngiving data rhetorical power (Rosenberg, 2013).\nThe position that data is not a transparent and\nobjective phenomenon but can function as a rhetorical\ntool, inherently tied to the technological, political,\nsocial, and economic infrastructures that sustain it,\nallows it to be investigated as a real force in the\nworld. Data can, as Ian Hacking puts it, ``make\npeople up'' once people define themselves and build\ninstitutions based on the categories of a data ontology,\nwhether mental health schemas or the census (Hacking,\n1986). There is accordingly a double-sidedness to data,\nas Alain Desrosieres asserts, since it functions both as a\ndescription for what we know as well as a basis for\naction, particularly when the data is inscribed in\nstable systems and institutions. The more opaque,\npowerful, and efficient the systems, the more capably\nthe data can resist critique and operate as something\nreal in a reinforcing loop (Rosenberg, 2013). Statistical\ntechniques, scientific proofs, and government records\nall lend themselves to this type of reality, as the material\nrecordings become a basis for wide agreement and\nhence objectivity.\nCrime statistics in this way have long been a con-\ntested source of discursive power. Writing in 1965\nSavitz and Johnston called attention to the dangers of\nrhetoric promoting an ``aura of infallibility'' that often\nsurrounds crime statistics (1049). The authors discuss\nthe media's role in not properly conveying the limited\nnature of crime reporting statistics adequately enough\nto the public. As this data shapes our understanding of\nphenomena, we then must ask what it is evidence of and\nhow its rhetorical strength or weakness is constituted\nby the assemblages in which it is situated.\nMethods of infrastructural inversion\nInfrastructure studies works in tandem with critical\ndata studies to offer a method for analyzing the deci-\nsions made at various steps of data gathering, manage-\nment, design, and display (Bowker, 2007; Bowker et al.,\n2010). This literature argues that at any given moment,\ndata are only snapshots that have been composed\nthrough the modeling and ``cooking'' that happens in\nthe algorithmic process of data capture (Bowker, 2007).\nThe production of data is not inevitable; protocols,\norganizational processes, measurement scales, cate-\ngories, and standards are designed, negotiated, and\ndebated in the process of data generation. As such,\nthe method of infrastructural inversion proposed by\nStar and Bowker lays bare the historical development\nof certain statistical and classificatory tools that then\nare co-constitutive of how users, and the society in\nwhich they are situated, see the world (Star and\nBowker, 1999). Infrastructural inversion seeks to\nCurrie et al. 3\nuncover those infrastructures--technical, social, polit-\nical, and economic systems that facilitate certain types\nof knowledge--that have become invisible as a result of\ntheir efficiency or ubiquity. The relationship of infra-\nstructure and the symbolic realms of power is, for\nexample, seen in Bowker and Star's 1999 examination\nof the International Statistical Classification of\nDiseases and Related Health Problems (ICD) for clas-\nsifying death (Star and Bowker, 1999). This classifica-\ntion situates disease in the system so that the political,\nethical, and social contingencies appear naturalized.\nPhil Agre's potent and portentous 1994 work in\nWired declared that with the massive increase in data\nbeing generated over 20 years ago, methods of data\nproduction must become more transparent. However,\none will note that this prescription for data transpar-\nency has hardly been heeded. Infrastructural inversion\nmust often excavate how the ownership and manage-\nment of data systems impact the types of treatment or\nstatistical application applied to data sets. Additionally,\nan analysis must be sensitive to how semantics, or the\nway that the data is related to definitions, is of utmost\nimportance to the meaning derived from a particular\ndataset. The ways data are described or labeled, for\ninstance, may invite comparisons between datasets\nthat are not warranted, while more explicit labeling\nencourages clear and necessary comparisons (Agre,\n1996). Transparency of data production, semantics,\nand the level of information that is captured--its\ngranularity--are all facets that serve as clues about\nthe data's production. Consequently, an investigation\nof how data on POIH is generated must examine the\nassemblages of which it is part, and its relation to tech-\nnical, economic, and ideological assumptions. These\nattributes exist in combination with the work that\ndata does in the world and how these can influence\ndifferent ways of communicating, expressing, and\ntaking action.\nThe case for counter-data action\nHistory tells us that statistical data can serve as the\nbasis for political activism. In 19th century France\nand Prussia, social reformers and labor activists\nworked with civil servants to gather statistics on the\nconditions of labor to improve workers' living condi-\ntions, unemployment, and hygiene, while in Germany\nreformers used population statistics to introduce social\nprotections such as disability insurance (Desrosie\n` res\ndies depart from 19th century conceptions of statistics\nthat parsed social and economic issues such as poverty\nand health as objective, distinct from passion, and\npolemics. Scholars of critical data scholars, rather, set\nout to expose ``the double role of statistics in\nrepresenting as well as criticizing reality'' (Desrosie\n` res\nand Naish, 2002). They understand data, per\nDesrosieres, as both a kind of description and basis\nfor action. It is through this lens that data practices\ncan ignite new forms of activism and resistance.\nCritical geographers Dalton and Thatcher call acts\nof resistance to politically dominant datasets counter-\ndata action (Dalton and Thatcher, 2014). This notion\ndraws from their work in critical geographic informa-\ntion systems (GIS), an approach that diverges from the\nconventional view of geographic maps as a model of the\nworld, to an understanding of maps as political and\nlegal claims on reality. Based on this framework, pur-\nveyors of Public Participatory GIS engage ``counter\nmapping'' as a method of emancipatory action--gener-\nally by a community looking to reclaim or denounce\nexternal dominance of resources. In a similar vein, pur-\nveyors of ``statactivism'' use this term to describe\n``emerging forms of collective actions that use numbers,\nmeasurements, and indicators as a means of denunci-\nation and criticism'' (Bruno et al., 2014). Statactivists\nmight collect and deploy data that does not exist to\nmake a cause more visible--an historic example of\nthis is the case of AIDS activists in the 1980s--or\nresist or reject official state indicators and benchmarks\nthrough original data collection. These practices might\nanalyze different types of data of varying levels of\ngranularity, collected from different organizations\nwhich all presume to shed light on the same phenom-\nena, so that the contingent and negotiated aspects of\ndata might come to the fore. These examples are all acts\nof appropriation and intervention, a means of wresting\ncontrol of the power of statistics by either decrying cer-\ntain authoritative metrics or devising new ones.\nAn example of this type of counter-data action\nrelated to crime reporting can be found in Conroy\nand Scassa's discussion of a data collection model for\nsexual assault reporting developed in Philadelphia\n(Conroy and Scassa, 2015). The authors reflect on the\nunreliability of sexual assault data and reveal that the\ndata generally only address the issue of bringing about\nan awareness of the gaps in reporting. The scholars\npropose a model that involves extensive collaboration\nbetween the Philadelphia Police Department and local\nwomen's advocacy groups to attempt a more proper\nhandling of sexual assault reporting. As part of this\nmodel, the authors suggested the women's groups con-\nduct annual reviews of sexual assault reports that were\ndeemed unfounded in order to aid in assessing incidents\nof mishandling. This model directly addresses the nebu-\nlous nature and tenuous understanding of government\ntransparency, especially considering its significant ties\nto accountability and subsequent abilities to address\ninstitutional deficiencies through the promotion\nof community values (Conroy and Scassa, 2015).\n4 Big Data & Society\nThese overarching concepts set an important basis\nfor the community-centered framework we set for our\ncounter-data action.\nWe draw from this work, along with critical data\nstudies and related literature, the need to engage in\ncounter-data action in which researchers address their\nown positionality, carefully consider the implications of\nthe data they use, and work to find ways to resist uneth-\nical uses of data (Dalton and Thatcher, 2014). We sug-\ngest that there are certain affordances in investigating\nsensitive civic data in relation to the assemblages that\nsustain and support the data sets, how data is con-\nstructed, as well as the effects of the data in society at\nlarge as a result of their use or rhetoric surrounding the\ndata. It is also important to ask what questions can and\ncannot be answered by the data.\nAs we will discuss in the following sections, we begin\nby analyzing four POIH data assemblages, then\ndescribe an event in which members of the community\nengaged with these POIH datasets in a unique counter-\ndata action. Our goals at this event were first, to iden-\ntify the limits and challenges present in the local and\nfederal metrics that are already publicly available on\nPOIH, then to propose new methods for deriving\nmeaning from indicators and statistics. In this way,\nwe seek to lay bare the various apparatuses that nego-\ntiate process and deploy POIH.\nSetting the stage for our counter-data action are four\ndatasets of POIH data for Los Angeles County. During\nthe hackathon, we explored, remixed, and reinterpreted\nthese four databases. Two are managed at the federal\nlevel, the FBI's SHR, the National Center for Health\nStatistics' (NCHS), National Vital Statistics System\n(NVSS), and two by local organizations, the Los\nAngeles Times Homicide Report, and the Youth Justice\nCoalition (YJC). In the following section, we describe\nthese four datasets and introduce each as a data assem-\nblage with unique elements of institutional, legal, finan-\ncial, and material support (Kitchin et al., 2015).\nPOIH databases of Los Angeles County\nThe first of our datasets is the FBI's Supplementary\nHomicide Report (SHR). The SHR, the most fre-\nquently cited among the federal datasets, was begun\nin 1962 as part of the more extensive Uniform Crime\nReporting (UCR) database that the FBI has main-\ntained for 85 years.7 While the older UCR provides\nannual counts of all recorded homicides in aggregate\nnumbers, the SHR supplements the UCR with granular\ndetails that provide some context of the event, particu-\nlarly the victims' relation to offenders (Federal Bureau of\nThese details are manually recorded by local law\nenforcement agencies on a voluntary form; how the\nform is filled out might vary, and data fields are treated\nas optional (see Figure 1 for the form.). Once completed,\nthe form is then compiled and coded either by the FBI or\nby state-reporting agencies to produce the statistical data\nfor all counties in the U.S. that report it. By recording\ninformation into the form's column labeled ``circum-\nstances,'' the SHR allows agencies to report data on\njustifiable homicides by law enforcement--coded as\n``Felon Killed by Police Officer'' (code 81). The FBI\noffers no evidence as to whether it provides additional\noversight over the accuracy of the forms.\nAs is clear from ongoing criticisms, the SHR has\nvery weak institutional, legal, and financial ensembles\nof support. Because the report is not legally mandated,\nmany states decline to participate. In data released on\ning on this classification during certain years, with\nWashington D.C., Montana, and Nebraska opting\nout of reporting at least 12 years and Florida opting\nout entirely (``Bureau of Justice Statistics UCR and\nNIBRS Participation,'' n.d.). Even if a form is sub-\nmitted, data entry is often incomplete--law enforcement\nreporting a homicide will not always include demo-\ngraphic data, for instance. According to the Guardian,\nand race. When the victim was a black male, basic iden-\ntifying data on the offender was omitted more often,\nSHR's decentralized, bottom-up approach also cre-\nates problems with consistency: data gathered from\nlocal sources confront variable software and media to\nmake the recordings, differences that are hidden in the\naggregate. As a White House press release reported,\nCamden PD ``cobbles together 41 systems that have\nindividual value, but are not designed to work together,\nrequiring their beat officers to enter the same data mul-\ntiple times'' (Smith and Austin, 2015). Without stand-\nardization, the report cautioned, analysis of these\nsources may not be meaningful. Additionally, the\nSHR provides only information based on the initial\npolice investigation, not on subsequent decisions\nmade by prosecutors or courts.\nOur second dataset, the NVSS, gathers reports that\noriginate from death certificates by a coroner or med-\nical examiner, as required by law in 36 states (``Easy\nAccess to the FBI's Supplementary Homicide\nReports,'' n.d:; Enten, 2012; Federal Bureau of\nInvestigation, 2015). In contrast to the voluntary\nSHR, the NVSS is mandatory. To be classified as a\nPOIH, this form must certify manner-of-death as a\nhomicide, then provide additional detail in an open\ntext field that asks the coroner to ``describe how the\ninjury occurred''. Only if an officer is listed as a perpet-\nrator in this description is the death coded, through the\nInternational Classification of Disease-10 codes, as\nCurrie et al. 5\n``Death by legal intervention.'' Problems of reliability\ncrop up, however, because the instructions for complet-\ning the form do not explicitly indicate that police\ninvolvement be mentioned at all, while coroners may\nnot even know if the deceased was involved in an\nattempted arrest at the time of death. (Loftin et al.,\n2003) Studies have shown the inadequacy of this data,\nwith underreporting as high as 51% in some cases\n(Sherman and Langworthy, 1979). The NVSS lack of\nguidelines for the death certification makes underre-\nporting inevitable. Furthermore, unlike the SHR, the\nNVSS only provides aggregate data at the county level,\nobscuring demographic data at the level of each inci-\ndent. So while NVSS captures the most detail, counting\nmany aspects that the other datasets do not such as\nmeasures of victim marital status and educational\nattainment, it does not make this data public except\nThe third data set, the LA Times' (LAT) comprehen-\nsive Homicide Report, gathers statistics and analysis on\nall deaths within Los Angeles County. The Report is a\npart of the LAT Data Desk; it uses, at a very minimum,\npolice reports corroborated with the coroner's reports,\nand it sometimes supplements these with investigative\nreporting on cases when money and time allow. The\ndata for each homicide is displayed publicly online on\na dynamic map, as well as in individual posts with\ndescription about each death. Each post is organized\nthrough statistical data capturing neighborhood in\nwhich the death occurred, gender, age, race and ethni-\ncity, cause of death, and whether an officer was involved.\nThe LAT is very interested in questions of access and, as\nsuch, their website makes information on these homi-\ncides easily accessible (Burghardt, 2014). Their interface\ncombines quantitative numbers on police homicides with\naccompanying qualitative information found through\ntheir investigations. LAT has an FAQ on its website\nwith information about how the Homicide Report\ndata is collected and processed, and each individual\npost includes the contact information of the author for\nquestions or concern from the public. The LAT's data is\nbrowsable but not downloadable on its website; individ-\nuals can request the statistical data, which the LAT pro-\nvides in the form of an Excel spreadsheet.\nSHR, NVSS, and LAT have concerns of much wider\nscope than the specifics of POIH;8 they are exhaustive\nstatistical classification systems that attempt to capture\nan entire range of phenomena--all homicides or all\ndeaths. Our fourth dataset, a report of the deceased\ncollected by the YJC, in contrast, devotes personnel\nto explicitly capture POIH data. The YJC is a commu-\nnity organization devoted to issues around incarcer-\nation, youth, and race. The organization's report is a\ndatabase that uses coroner's reports corroborated with\npolice reports, and in some cases makes it report based\non interviews with the family of the deceased, as well as\neye witnesses and community members in the area\nwhere the victim was killed. Accompanying demo-\ngraphic data (age, gender, race), data on the neighbor-\nhood and address where the homicide occurred, and\ndate of death, the YJC in some cases also provides a\nphotograph of the deceased and a short description for\neach incident of police homicide (for example, ``Called\nto mental health facility; officers claimed they shot\nbecause Saucedo approached with `sharp object.'')\nTheir website is not as widely known as the LAT\nHomicide Report, nor do they incorporate any sort of\ninteractive elements to the display of their information,\nbut they do make available for download the PDF that\ndocuments this information.\nThe two county-only datasets by LAT and YJC\ndiverge from the federal datasets in at least four impor-\ntant ways. First, the county data offers more granularity\nthan the federal accounts, with data points capturing the\nplace where the individual was killed and the victim's\nname. Second, in contrast to the federal datasets, the\nlocal data often uses more than one source to verify\nand detail the incidents. The local datasets also introduce\nqualitative information at the level of each death, some-\ntimes as a result of investigatory effort. Finally, the local\nstatistics are dynamic. In controversial cases, both orga-\nnizations follow and document legal proceedings that\ntake place following the homicide and adjust accounts\nas new information comes to light, capturing contesta-\ntions that can occur as a homicide are deemed justified or\nunjustified. The federal SHR, in contrast, maintains local\npolice agencies as the arbiters of a death's justifiability.\nThe numbers do not capture any subsequent legal proce-\ndures that might prove the contrary (Loftin et al., 2003).\nThe local data, it should be acknowledged, is limited\nfor research in that it does not scale up: the methods\nused by these sources are specific to local phenomenon\nand cannot be analyzed alongside local data from other\ncounties that do not use the same collection methodol-\nogies. Yet we found that the local data provide a coun-\nter-narrative to the strictly quantitative data found in\nthe federal accounts that naturalizes these recordings as\nofficial facts. Local data is a rhetorical tool that shapes\nhow we understand police homicides. As we describe\nbelow, the counter-data action entailed considering this\nsmaller-scale local data with the larger federal data\ntroves to find cases in which the data did not match,\nas well as to bring qualitative, interpretive analysis to\nbear on our understanding of POIH.\nA counter-data action:\nThe POIH hackathon\nOur approach lies in pushing the critical understanding\nof sensitive civic data toward the exploration of new\n6 Big Data & Society\ncommunity-based mixed-method approaches to data\nanalysis. In order to do so, we hosted a civic hackathon\nduring which we engaged with local Los Angeles com-\nmunity groups to re-interpret the data sets and develop\nmeaningful practices around POIH data in accordance\nwith diverse sensibilities, experiences, and needs. We\ntake seriously the claim that ``we are our tools,'' as\nthe quantification of human features and actions can\nboth enable and place limits on knowledge and action\nthon, as an example of counter-data action, aimed to\nallow researchers and citizens to reclaim such tools,\nparticipate in their development, and employ them to\nbuild alternative discourses and meanings.\nWe conceptualized the hackathon as a hacker-maker\nspace (HMS), a context that generally focuses on open-\naccess workshops devoted to teaching and learning\nthrough creative and technical work (DiSalvo et al.,\n2012). What distinguishes HMS events from the trad-\nitional hackathon is a focus on the material dimensions\nof the objects of investigation (DiSalvo et al., 2012).\nDuring these events, the traditional ``creative mis-use''\nof a piece of technology is realized along with its ``hands-\non re-construction'' (Schrock, 2014). Participants re-\nconstruct objects produced from one particular design\ntradition, but deploy different assumptions and\nnew design and collection methods. Such strategies are\nproposed, tested, and processed, and, in doing so, sim-\nultaneously ``learned,'' in an act similar to Matt Ratto's\ncritical making. Critical making focuses on interroga-\ntions of the socio-technical through tracing back the\nways ``things are made'' in order to produce, re-produce,\nor imagine various objects (Ratto, 2011).\nAmong the primary goals of the hackathon was to\ncollectively investigate how the POIH data sets were\nconstructed. During the hackathon, we worked side-\nby-side with the participants with the goal of under-\nstanding the ways different actors collect and organize\nPOIH data--in tabular and visual formats, in coding\npractices and on social media--in order to imagine\nhow these processes might proceed otherwise. The\nawareness that we gained through this process of critical\nmaking provided us with new ways to independently re-\ninterpret and make sense of the local and federal data on\nPOIH. The rest of this section discusses the different\ninterpretations or sense-making projects developed at\nthe hackathon. We categorize these projects into three\nmain types: data as creative practice; triangulation with\ndifferent types of qualitative content, primarily social\nmedia; and alternate metrics. Our goal was neither to\nimprove the validity and reliability of POIH data, nor\nto come up with policy recommendations, but to explore\nthe ways in which dissident and creative approaches to\ndata analysis can reveal something new and unexpected\nabout their contingent nature.\nOverview of the POIH hackathon\nWe invited the public to investigate POIH data at the\nHackathon on Police Brutality held in February, 2015\nat UCLA (see Figure 2). In preparation for the hacka-\nthon, we gathered and organized the four data sets on\nLos Angeles County POIH and made these available in\na public Google spreadsheet. We advertised the event\nwidely, attracting nearly 50 individuals, who ranged\nfrom students and professors to members of police\nwatchdog groups, for the four-hour event. The event\nopened with a panel comprising speakers to talk\nabout their experiences in investigating police abuses\nand brutality. Speakers included lead reporters from\nthe LAT Homicide Report, representatives from the\nStop LAPD Spying Coalition, and Andrew Schrock\nfrom the University of Southern California's\nInnovation Lab. The LAT reporters described in\ndetail how they collect, analyze, and visualize data\nrelated to POI homicides in Los Angeles County.\nStop LAPD Spying representatives discussed the\nsocial and technical challenges that occur when com-\nmunity groups try to make sense of the POIH phenom-\nenon, while Schrock provided some background\nknowledge about the use of a hackathon event as a\nform of social action.\nAfter the panel, participants organized themselves\ninto four teams. The Stop LAPD Spying Coalition\nled a discussion on police officer POIHs in LA\nCounty. A second group began analyzing inconsisten-\ncies between the federal databases and local databases,\nwhile a third group scanned social media networks in\norder to gain insights about specific discovered unre-\nported cases. The last group worked to visualize the\nextant POIH data to disseminate to the public.9\nPOIH data as a creative practice\nMembers of the visualization team devised a multi-\nmedia project that combined the addresses of all\nPOIH sites contained in YJC's data set with Google\nStreet View images of the locations where the events\ntook place. The goal was to display the site-specific\nimages side-by-side in columns and rows (see Figure\n3). Before being able to merge the two datasets, we\nworked closely with YJC members and other hacka-\nthons' participants to create an Excel file with all the\nlocations of the homicides. Indeed, because the YJC\ndataset originated as a word document manually com-\npiled entry by entry, the counter-data action provided\ncomputer science students who helped YJC convert\ntheir datasets into a spreadsheet for easier processing.\nOnce displayed, the POIH spreadsheet gained strik-\ning spatial and visual dimensions of locales that are, if\nnot specifically and singularly identifiable, then\nCurrie et al. 7\nsufficiently reminiscent of an everyday milieu. If viewers\ncan identify with these images at all, then it renders\nmore palpable the realities of incidents of POIH occur-\nring at these sites. Furthermore, these images can be\nanalyzed in order to identify common environmental\nfeatures of POIH sites--whether POIH occur more\noften in streets with particular architectural features\nor surrounded by other physical features, in parks, or\nnear certain types of buildings or institutions. The work\nproduced by the visualization team in this way encour-\naged those at the hackathon to think critically about\nthe spatial dimension of incidents of POIH.\nPOIH social media data and qualitative content\nSome of those in attendance at the hackathon were\ndrawn to the challenge of supplementing the available\nPOIH data with qualitative narratives surrounding the\nPOIH incidents. This group mined social media for any\nindications of online presence for victims, drawing from\nthe individual names in the YJC dataset. Narrowing the\nsearch to 2012, the most recent year of available SHR\ninformation, the group searched through social media\nsites--Facebook, Twitter, Tumblr, YouTube, and per-\nsonal blogs--to identify online presence and lingering\ntraces of POIH victims.\nThree main types of online presence emerged: per-\nsistence of the deceased's activity online, in the form of\nblog posts or Facebook comments they wrote while still\nalive; sensationalized commentary surrounding the\nvictim, particularly in the form of YouTube comments\non videos capturing the incident; and social media\nmemorials dedicated to the deceased, with comments\nfrom family members, friends, and others.10 Though\nwe found at least one of the three types of online\nsocial media presence for the majority of the victims\nsearched, there remained a portion with no online\ntrace at all, a phenomenon that cannot be properly\nexplained without further research. This sort of work\ndirectly acknowledges and memorializes the deceased,\nas searching for and curating these details aid in pro-\nviding a narrative of each victim beyond that of a single\nnumerical entry in a collected database.\nPOIH data as alternate metrics\nAs a third outcome, the hackathon focused on under-\nstanding the shortcomings of the federal POIH data by\ncomparing various datasets. Accordingly, the data\nmining team performed an in-depth analysis of the mul-\ntiple inconsistencies between the LA Times data and\nSHR data set. For example, the LAT Homicide\nReport data indicated 38 POIHs in contrast with the\nsame geographical area. Initially, the hackathon\nparticipants established the goal of identifying the five\nunreported cases of 2012 in the SHR. However, the\nsituation revealed a much more complicated nature\nthan first expected. In the SHR, the group found that\nthere were 11 reported homicides that did not match\nthe LAT Homicide Report based on age, gender, and\ndate. In the LAT Homicide Report, there were 18 that\ncould not be accounted for in the SHR based on age,\ndate, and location. Of the documented instances of\nPOIH in both datasets, just 23 POIHs were consistent\nbetween the two datasets. The group found that five\nwere very close to matching both databases, but were\na year off in age, or reported the death in an adjoining\nneighborhood. Overall, the information contained in\nthe two datasets was largely inconsistent. Thus, it was\nobserved that discrepancies exist not only in the count\nof the deceased itself, but also in the details of each\naccount.\nDiscussion: The social values of data\nThe focus on engendering critical dialogue and creative\nreinterpretation of POIH data at the local level is abso-\nlutely fundamental to the work we present in this paper.\nOne of the more important outcomes of our exercise in\ncounter-data activism was collectively uncovering some\nof the ``values'' leading to the production of the local\nand federal POIH data sets and how these choices\ninform any knowledge production based on the data.\nIn this case, the hackathon found that POIH data at the\nlocal level produced contrasting indicators of lived real-\nity and then used this finding to help participants\nunderstand the choices that shaped the data. The\nhackathon in this way demonstrated the existence of\nlarge incongruities between the datasets and spoke to\nthe contingent choices made by the different organiza-\ntions that collect, store, and report this data. In this\ndiscussion section, we present three examples of differ-\nences that came to light over the course of the\nhackathon--distinctions that affect how knowledge of\nPOIH is produced and ultimately normalized.\nFirst, participants of the alternate metrics group dis-\ncussed how each dataset reveals the decisions made\nabout what details to collect on each homicide, a\nchoice that involves biases of what should be visible\nand invisible within a schema. These variances in\ngranularity bounded the analysis at the hackathon by\nthe level of detail and comparability possible across\ndatasets. This constraint, which hindered analysis,\nbecame a source of discussion. All schemas capture\nrace, gender, and age, but otherwise categories varied.\nOnly the local data included the incident address and\nnames of deceased. LAT and YJC incident accounts\nhad information on whether victims were intoxicated,\nwhether domestic abuse was involved, and whether\n8 Big Data & Society\nwitnesses dispute the account, but such information is\nnot categorized in a schema. The federal datasets have\nno categories for purportedly non-lethal actions, such\nas tasing, that may lead to death. Furthermore, all\ndatasets failed to capture certain information, such as\nstatistics about the number of officers who fired,\nnumber of bullets fired, or number of bullets hit--all\ndetails that could shed light on ``on differential `kill\nratios''' of certain police agencies compared to others\nSecond, the social media group found that qualita-\ntive details at the incident level of the local data reveal\ncommunity concerns around particular deaths--con-\ncerns that are smoothed over and rendered anodyne\nwhen represented solely in statistical form. For exam-\nple, a Facebook memorial for a young woman includes\nposts by family and friends dedicated to issues around\npolice violence and advocacy for the mentally ill. One\ncomment describes that the young woman died after\n``cradling a small ball peen hammer in the lobby of\nthe Asian Pacific Family Center where she was receiv-\ning mental health services.'' The post goes on,\n``Witnesses at the scene reported that the young\nwoman was sitting calmly with the hammer in her lap\nbefore the police arrived.'' The comment then ends with\na general call for more awareness during police\nresponses to the mentally ill: ``It is also a place for us\nto advocate on behalf of other people like the young\nwoman so that the ignorance of mental health by law\nenforcement does not lead to another precious life\ncut short.'' Qualitative details such as this at the inci-\ndent level can restore the narratives of witnesses\nand loved ones, making concrete what otherwise\nbecomes a formal abstraction. Highlighting and parsing\nthese details contribute to a continued awareness of the\ncontested nature of the data used to represent these\nincidents.\nFinally, during the general discussion with the pan-\nelists at the hackathon, the question arose of whether\nthe datasets were counting the same phenomena. What\nconstitutes a POIH is not simple or clear-cut, and\nenforcement agencies cannot turn to law to determine\nwhat constitutes a POIH. The datasets subtly differ in\nhow they define and circumscribe a complex and often\npolitically fraught phenomenon. The FBI's SHR, for\ninstance, does not specify the definition of a justified\nhomicide beyond ``the killing of a felon by a peace offi-\ncer in the line of duty'' (``Uniform Crime Reporting\nsification are ``unjustified'' homicides, a designation\nthat by definition criminalizes victims of homicides,\nnor does the definition count deaths that are not dir-\nectly traceable to homicide by an officer, such as suicide\nor intoxication, even if these are effects related to the\nofficers' presence. Nor does Code 81 count deaths on\nfederal property or by federal agents.11 The NVSS simi-\nlarly only counts deaths in which the underlying cause\nwas directly attributed to ``legal interventions'' by an\nofficer.12 Both the NVSS and SHR assume the victim is\na ``felon'' or ``lawbreaker''; such semantics a priori\ncriminalize the deceased, endowing the schema the\npower to define the dead prior to investigation or trial.\nThe symbolic power of semantics is also found in the\nclassification of POIH in the ICD, the schema used by\nthe NVSS. The CDC's ICD-10 uses the same code for\nhomicides by law enforcement as it does acts of war and\nlaw enforcement. When there is little distinction\nbetween homicides by act of war, a designation\nwidely held to be noble, and those caused by law\nenforcement, it is possible to assume that the classifica-\ntion is based on a legal, moral, and ethical character of\nhomicides of this nature, showing the contamination of\nthese factors on ICD's narrative of classification.\nPolicy makers are looking to correct the failings of\nPOIH data. An executive task force that formed after\nthe shooting of Michael Brown in Ferguson, MO, for\ninstance, recommended that local law enforcement\nagencies require federal agencies to report when their\nObama's Police Data Initiative seeks to remedy the\nsituation with open data standards that clarify and\nstreamline reporting procedures for law enforcement\nagencies. Through better data and data-driven solu-\ntions, FBI Director Comey insists, we can avoid emo-\ntionally driven claims and instead deploy ``ideological\nagnostics that look to information to try to solve prob-\nlems'' (Comey, 2015). Yet, our work at the hackathon\nrevealed that any national account of killings by police\nofficers, even one that redresses current failings, makes\nchoices about how to define a POIH, how to capture\nconflicting accounts, and the granularity of data about\nthe death to include. These remain interpretive matters\nconstituting the socio-technical dimensions of the data\nin any case.\nIn sum, data can be employed to encourage a critical\nconception of events, revealing patterns that suggest\nalternate paths for accounting for phenomena, particu-\nlarly to augment governance systems widely character-\nized as broken, or in serious need of repair. Rather than\nacting as conclusive evidence, data can be the starting\npoint to ask new questions that come to light, both\nthrough reinterpretations and creative practice.\nReflections on the particular outcomes of our coun-\nter-data action and the overarching themes they relay\nabout the nature of the data in many ways circle back\nto the major themes of critical data studies discussed\nthroughout the literature review: that data assemblages\nare fraught with semantic import, that they operate as a\nset of relations reproduced by interest groups and\nmaterial infrastructures, and that POIH data can lead\nCurrie et al. 9\nto a creative array of outcomes in the areas of analyt-\nical, qualitative, and visualization work.\nThat said, we also realize that this event only\nscratched the surface. As a data assemblage itself, the\nhackathon had clear limitations bounded by the short\ntime frame of four hours, by the academic institution\nthat hosted it, by the potential inaccessibility of the\nevent to potential participants geographically and\notherwise, and by the data literacies of the participants,\nmany of whom were students, professors, or already\nembedded in activist networks. Overall, we present\nthe hackathon as a preliminary template for more sus-\ntained engagement between the datasets analyzed and\ncommunities they have meaning to. The event lasted\nonly one afternoon, and we cannot yet point to indica-\ntors of substantial social change that arose from it.\nCertainly, there were tangible outcomes, such as the\nvisual representations of the data, the articulation of\nthe inconsistencies present in the databases analyzed,\nand the campus and community relationships formed.\nYet in comparison to other forms of ongoing commu-\nnity-based participatory research that might involve\nprolonged policy work or coalition building,13 we\nacknowledge the constraints present in the particular\ncounter-data action we chose.\nDespite these limitations, it is worth noting that the\nmethods at the hackathon can serve as examples for at\nleast preliminary communal connection with and deeper\nunderstanding of data. Ultimately, we believe that more\nwork is necessary for a counter-data action such as this to\nhave a prolonged impact on how public understandings\napply a critical perspective to POIH data. Two outcomes\nThis report is authorized by law Title 28, Section 534, U.S. Code. While you are not required to respond, your cooperation in using this form to list data pertaining to all\nhomicides reported on your Return A will assist the FBI in compiling comprehensive, accurate data regarding this important classification on a timely basis. Any questions\nregarding this report may be addressed to the FBI, Criminal Justice Information Services Division, Attention: Uniform Crime Re ports/Module E-3, 1000 Custer Hollow Road,\ncontains a valid OMB control number. The form takes approximately 9 minutes to complete.\n1a.Murder and Nonnegligent Manslaughter\nList below for each category specific information for each murder and nonnegligent homicide and/or justifiable homicide show n in item 1a of the monthly Return A. In\naddition, for justifiable homicide list all justifiable killings of felons by a citizen or by a peace officer in the line of duty. A brief explanation in the circumstances column regarding\nunfounded homicide offenses will aid the national Uniform Crime Reporting Program in editing the reports.\nAge\nSex\nRace\nEthnicity\nAge\nSex\nRace\nEthnicity\n*\n** - See reverse side for explanation\nRecorded\nEdited\nd\ne\nr\ne\nt\nn\nE\ns\ns\ne\nr\nd\nd\na\nl\ni\na\nm\n-\nE\n/\ny\nb\nd\ne\nr\na\np\ne\nr\nP\nVerified\nAdjusted\nMonth and YearAgency Identifier\nDo Not Write\nIn These Spaces\nData Code\nWeapon Used\n(Handgun, Rifle, Shotgun,\nClub, Poison, etc.)\nIncident\nVictim**\nSituation*\nOffender** Relationship of Victim\nto Offender\n(Husband, Wife, Son,\nFather, Acquaintance,\nNeighbor, Stranger, etc.)\nCircumstances\n(Victim shot by robber, robbery victim\nshot robber, killed by patron during\nbarroom brawl, etc.)\ne\nt\na\nt\nS\ny\nc\nn\ne\ng\nA\nTitle\nSheriff, Chief, Superintendent, Commanding Officer\nFigure 1. Form for Supplementary Homicide Report.\nFigure 2. The Hackathon on Police Brutality held on 14\nFebruary 2015 at the University of California, Los Angeles.\n10 Big Data & Society\nthat represent a step in this direction are a branch-off\nproject being conducted by two of the authors currently,\nas well as an ongoing relationship with the Stop LAPD\nSpying Coalition. First, two of the authors of this paper\nare working to build off these findings to inform the cre-\nation and implementation of a police harassment report-\ning mobile application for students on the UCLA\ncampus, a project that will ideally extend the reach and\nimpact of this discussion in a variety of physical and\naffective ways. Second, the ongoing relationship of the\nauthors with the Stop LAPD Spying Coalition as an out-\ncome of the hackathon has led to a public panel on issues\nof data, surveillance, and policing, and also a role in the\ndevelopment of a data justice project as part of the coali-\ntion's efforts to regain control of data collected about\ncommunity members by the police. These outcomes are\nthe beginnings of what we hope will continue to develop\ninto beneficial counter-data projects that aid in sustaining\na bridge between this type of academic work and the\nwork of community organizers and coalitions.\nConclusion\nThe dimensions of data explored by critical data studies\nare key in helping us as a society to understand how\ndata is produced and how it does work in the world,\nespecially in relation to circumstances surrounding the\ndevelopment and use of POIH data. It is difficult to\nknow how data is developed and how, by its very exist-\nence--however incomplete--it affects wider under-\nstanding of the phenomena these data are supposed\nto represent or encapsulate. Engaging with this data\nin counter-data actions at local levels, would, as we\nhave found with our hackathon, remedy widespread\nproblems relating to the rhetoric framing data as\nunquestioned truth or a true reflection of the world.\nThese counter-data actions are useful for the commu-\nnities increasingly affected by data-based governance,\nas they are a juncture at which citizens can better\nunderstand why data is produced and the processes\nby which it is generated, and that arguments pointing\nto data are not unassailable.\nFor example, President Obama's Police Data\nInitiative seeks to set open data standards that pre-\nscribe reporting procedures for law enforcement agen-\nstored, and disseminated data would be part of a larger\nassemblage under the auspices of the open data move-\nment--a constellation that involves open formats, open\nsoftware, open data institutions (such as Code for\nAmerica and the Open Knowledge Foundation), and\nopen data principles--which will possibly shape the\npresentation of this data in the future, if not the com-\nplete production of the data itself. California is leading\nin this trend; it published its POIH data online as an\nopen dataset from the California Department of Justice\nin September 2015. It will be interesting to adherents of\ncritical data studies and data science to follow how this\neffort continues to develop and its effects on govern-\nance and law enforcement.\nYet, even if states follow suit and publish open\nPOIH data, it is likely that data collection practices\nwill continue to differ across states. Many states will\nstill not bother to collect the data because they are\nnot legally bound to. We argue that interrogating the\ndata at the level of infrastructure, production, storage\nand dissemination and finding discrepancies in these\nlevels in community-based, counter-data actions can\nframe where there are tensions in the various official\nstate accounts. These differences suggest which\nFigure 3. The scraped images of Daniel Schwarz and Visualization Team, from Google Street View, based on address data from the\nYouth Justice Coalition. Sample of 6 from over 335.\nquestions should be asked of this data--what are the\ninterests, standards, procedures, and ideologies\ninvolved with the construction of the data, and then\nhow can these be meaningfully communicated? These\ncounter-actions can provide an alternate mode of\nknowledge production in which communities can inter-\nact with and interpret qualitative and quantitative data\nin creative or unexpected ways. As such, we argue that\ncritical data studies expand its gaze to more thoroughly\ndevelop modes of counter-data action that take ser-\niously the interpretation and representation of know-\nledge gained through working with sensitive data sets.\n"
}