{
    "abstract": "Abstract\nSocial scientists and computer scientist are divided by small differences in perspective and not by any significant\ndisciplinary divide. In the field of text analysis, several such differences are noted: social scientists often use unsupervised\nmodels to explore corpora, whereas many computer scientists employ supervised models to train data; social scientists\nhold to more conventional causal notions than do most computer scientists, and often favor intense exploitation of\nexisting algorithms, whereas computer scientists focus more on developing new models; and computer scientists tend to\ntrust human judgment more than social scientists do. These differences have implications that potentially can improve the\npractice of social science.\n",
    "reduced_content": "Commentary\nAdapting computational text analysis\nto social science (and vice versa)\nPaul DiMaggio\n Keywords\nTopic models, text analysis, unsupervised models, interpretation, sentiment analysis, supervised models\nBased on my admittedly fortunate experience collabor-\nating with computer scientists on both research and\nteaching, I can report that the era of the ``two cultures''\nchasms, I have found modest differences in orientation,\nof which I shall mention three, reflecting computer\nscientists' and social scientists' respective intellectual\ntraditions. These differences require social scientists to\ndo some extra work to adapt the powerful tools that\ncomputer scientists provide to social-science problems,\nbut offer in return insights that can improve the way\nwe think about explanation more broadly. Because\nmy own ``Big Data'' comprises texts, I shall limit\nmy observations to computational text analysis\nFirst difference: Supervised vs.\nunsupervised machine learning\nTopic modeling and many other text-analysis tools\nhave their roots in machine learning. Typically, in\nmachine learning problems, one has a class of cases\nof known type and a class for which the type is\nunknown (Almeydin, 2014). One divides the former\ninto a ``training set'' and a ``testing set''; develops a\nmodel based on the former that is predictively effective\nfor the latter; and applies that model to classify the\ncases for which the type is unknown. An excellent\nexample of this approach is Jockers and Mimno\n(2013), who used supervised topic models (``supervised''\nrefers to models based on cases of known type) to\nidentify the gender of anonymous or pseudonymous\nauthors of 19th-century novels. Supervised models\nhave had a wide range of practical applications\n(think, e.g. the Netflix challenge, where contestants\nused supervised-learning models to improve Netflix's\nability to recommend to users films that they would\nenjoy).\nArguably, however, the major strides in computa-\ntional text analysis in recent years--and the ones of\ngreatest use to social scientists--have entailed the devel-\nopment of unsupervised approaches to exploring the\nlatent structure of textual corpora: Latent Dirichlet\nDepartment of Sociology, Princeton University, Princeton, NJ, USA\nCorresponding author:\nPaul DiMaggio, Department of Sociology, Princeton University, 130\nEmail: dimaggio@princeton.edu\nBig Data & Society\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons NonCommercial-NoDerivs CC-BY-NC-ND: This article is distributed under the terms of the Creative Com-\nmons Attribution-NonCommercial-NoDerivs 3.0 License (http://www.creativecommons.org/licenses/by-nc-nd/3.0/) which permits\nnon-commercial use, reproduction and distribution of the work as published without adaptation or alteration, without further permission provided the\noriginal work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).\nAllocation and related approaches like Correlated\nTopic Models and Dynamic Topic Models (Blei,\n2012). Social scientists have used such models product-\nively, for example in identifying innovative patents\n(Kaplan and Vaikli, 2014), assessing the political lean-\nings of economists (and correlating these with\npolitical behavior and research conclusions) (Jelveh\net al., 2014), and discerning previously unrecognized\ncontinuities among historical waves of the US\nwomen's movement (Nelson, 2014). But unlike super-\nvised models, for which straightforward means of\nvalidation using held-out samples are available, assess-\ning the quality of solutions from unsupervised models is\nmore challenging, with criteria that are more varied and\nless definitive.\nIn other words, the shift from supervised to unsuper-\nvised models, especially in some areas of greatest inter-\nest to social scientists, requires many of us to move\noutside our comfort zone in accepting interpretive\nuncertainty and to develop robust ways to interpret\nand validate the results of our models.2 There have\nbeen promising developments in this respect\n(e.g. Grimmer and Stewart, 2013) and room for more\nprogress. The key may be starting with interpretive\nmethods borrowed from the humanities, but then\ndisciplining the results through statistical validation.\nFor example, a model interpretation, combined with\ninformation external to the corpus, may lead one to\nhypothesize that the prevalence of some topics should\nbe associated with particular classes of authors, or to\nanticipate temporal patterns in topic prevalence\nSecond difference: Machine-learning vs.\nstatistical explanation\nWhereas social scientists customarily obsess over caus-\nality and rely on formal tests of statistical significance,\ncomputer scientists using supervised models focus on\nresults. The first topic-model presentation I attended\nused the method to identify public records particularly\nlikely to require redaction, out of a set of records too\nimmense for humans to screen by hand. The only meas-\nure that mattered was whether the models improved\nprediction (which they did).\nEven where held-out samples are not available,\nhowever, computer scientists seem to devote more\nattention to designing models and less on statistical\nvalidation (at least in the social-scientific sense) of\nmodel solutions. I suspect that this (admittedly sty-\nlized) difference is reinforced by variation in disciplin-\nary skill sets: Computer scientists can write new\nalgorithms faster than most social scientists can\nlearn them. In the tradition of supervised machine\nlearning, this makes sense because if you create a\nbetter model, you will be rewarded instantly with\nbetter results. This approach carried over (at least at\nfirst) into unsupervised models, as computer scien-\ntists wrote new algorithms at an alarming rate.\nFrom a computer-science standpoint, this made\nsense: algorithms tend to solve big problems, rather\nthan nibble at the edges of small ones.\nSocial scientists, by contrast, tend to learn a method\nand adapt it to their needs, in large part because their\nlearning costs are much higher.3 Social scientists there-\nfore tend to be more interested in model-testing and\ncuration than computer scientists (though there are\nexceptions on both sides (e.g. Boyd-Graber et al.,\n2014)), attempting to get the most out of the programs\nthey have mastered. From this standpoint, social scien-\ntists have good reason to invest in corpus curation,\nbecause it may be their most efficient way to boost\nthe quality of their results.\nThere is another difference, which is likewise consist-\nent with the supervised-learning roots of text modeling,\nbut has more to do with underlying approaches to\nexplanation. Many computer scientists (with notable\nexceptions (e.g. Pearl, 2009)) seem less concerned with\ncausality and with model confirmation than are many\nsocial scientists. It is not that they care less about\ngetting models right; rather they understand ``getting\nit right'' in a different (and I am beginning to suspect\nmore useful) way than do most social scientists, focus-\ning on model plausibility, utility, and descriptive, as\nopposed to causal, validation. Social scientists accus-\ntomed to obsessing over model specification and statis-\ntical significance may find this emphasis frustrating, at\nleast at first. (As a novice topic-model user, I literally\ncould not believe that there was no target function\nI could use as a simple goodness-of-fit criterion to\nchoose among model solutions.) Ultimately, however,\nthe computer-science perspective is liberating, as it\nforces us to recognize real interpretive uncertainty\nand seek out appropriate and substantively relevant\nforms of validation fitted to specific research goals.\nThird difference: Computer scientists\ntrust humans more than social\nscientists do\nFrom Alan Turing (1950) onward, much work in com-\nputer science, especially in Artificial Intelligence, has\nsought to create algorithms that can replicate the\nresults of human problem solving. The difficulty of\nthis task has generated great respect among many com-\nputer scientists for the human brain (which, as com-\nputers go, is an impressive piece of hardware). This\ntradition has influenced Natural Language Processing\nand, especially, Sentiment Analysis, where human rea-\nsoning is routinely described as a ``gold standard''\n2 Big Data & Society\nagainst which algorithmic output should be judged.\nTasks like the Netflix Challenge induce computer sci-\nentists to write programs that try to simulate human\nevaluation processes; and much research on sentiment\nanalysis employs as training sets human reviews from\nwebsites like Yelp or Rotten Tomatoes that combine\ntext and summary evaluations (for a thoughtful review\nBy contrast, social scientists, at least those who have\npaid attention to work in cognitive psychology, are\ndeeply suspicious of human judgment. I, for one,\nharbored the hope (of which my computer science\ncolleagues have disabused me) that computational ana-\nlysis could free us from dependence on pesky humans,\nwhose judgments are clouded by hard-wired errors of\nreasoning (Kahneman, 2003); schematic (Nisbett and\nWilson, 1977) and ideological priors (Graham et al.,\n2009); and vulnerability to emotional environments\n(Hammond, 2000), poverty (Mullainathan and Shafir,\nAs anyone who has ever hand-coded text or super-\nvised others in doing so is aware, measures of\ninter-rater reliability are correlated directly with the\ninsignificance of the information one wants to extract\nfrom the data. Give two coders of, say, a corpus of\narticles describing episodes of civil unrest, a factual\nquestion (e.g. where did the demonstration take\nplace?) and they are very likely to agree. Ask them\nsomething more interesting (what grievances did par-\nticipants express?) and convergence will be more diffi-\ncult to achieve. Likewise, human coders are good at\nstraightforward linguistic tasks, such as distinguishing\nbetween homonyms with very different meanings. But\nthey are less trustworthy when differences of perspec-\ntive shape the emotional context framing their judg-\nments. For example, asked to code the affective tone\nof the sentence, ``the Isis fighters celebrated their rout\nof the Iraqi troops,'' an Isis supporter is more likely to\ndiscern positive sentiment than would a coder sitting\nin Washington or Erbil. Computer scientists who\ntreat human judgments as a gold standard and social\nscientists who see in sentiment-analysis programs an\nantidote to human imperfection will often be disap-\npointed, as algorithms and humans seem to be bad at\npretty much the same types of tasks. For now at least,\nwe can savor the irony that each group is most skeptical\nabout the entities (algorithms or people) with which its\nexpertise is most closely associated.\nWhat do social scientists need?\nThree priorities follow from these observations, two for\ntopic models and one for sentiment analysis:\n1. We need better ways to choose among potential\nmodels of a textual corpus. Some outstanding work\nis already being done on model diagnostics by\nboth computer scientists (Boyd-Graber et al., 2014;\nscientists (Roberts et al., 2014). The challenge is that\ndifferent criteria point in different directions: statis-\ntical goodness-of-fit measures tap conformity to\nmodel assumptions that are unrealistic descriptions\nof the world, but are useful as yardsticks for measur-\ning variation in texts produced by different authors\nor at different times. Measures of model robustness\ncan identify solutions at the center of a model space\n(e.g. by measuring distances between solutions and\nusing multi-dimensional scaling to project them onto\na space), but the relationship between centrality and\nmodel quality has yet to be established (Marshall,\n2013). Even solutions that successfully predict\ntypes in testing samples may not be the ``best'' by\ncriteria of semantic interpretability (Chang et al.,\n2009). Approaches that focus on the fit or robustness\nof topics that are analytically important to the inves-\ntigator seem particularly promising for many pur-\n2. We need better guidelines for curating textual data\npre-analysis. Why is it so important to have general-\nizable criteria for solution quality? Because such cri-\nteria could guide us in choices about curating\ncorpora before modeling them. Most topic-modeling\nprograms require lots of decisions that most social\nscientists are ill-equipped to make. To the extent that\npackages put the method within the grasp of the\nsocial scientific masses, the default will be king.\nBut these choices matter: What is best for one\ncorpus may not be best for all, and we need rules\nof thumb for helping analysts to base choices on\nfeatures of their corpora and research questions.\nMoreover, social scientists' relative strength may lie\nin pre-processing data sets (as opposed to fine-tuning\nalgorithms). One promising class of methods\ninvolves using natural language processing tools to\nseparate terms that should be treated differently (e.g.\ndistinguishing homonyms through part-of-speech\nidentification) or uniting terms that should be trea-\nted as the same (e.g. using named entity recognition\nto identify organizations or actors that may be\nreferred to in slightly different ways). A second\nimportant class comprises strategies to transcend\nthe bag-of-words assumption without sacrificing its\ncomputational advantages--for example, by iden-\ntifying information-rich N-grams, employing tuples\n(pairs of words co-present within sentences, a\nmethod developed by Nag, 2015), or building net-\nwork-analytic approaches into modeling strategies\n(Inouye et al., 2014). What are the costs and benefits\nDiMaggio 3\nof such strategies? How do different curation tech-\nniques affect the quality of solutions, and how might\nthat vary by type of text and analytic objective? To\nmy knowledge, there has been little systematic\nresearch on this topic, in part due to the absence\nof agreed-upon criteria for judging quality. In\nother words, progress on this priority depends\nupon progress on the previous one.\n3. We need to figure out what humans are good for and\nwhen algorithmic solutions may be preferable to\nhuman judgment. This is particularly the case for\nautomated text coding, where systematically flawed\nhuman judgment can deform the performance of\nlearning algorithms, and, a fortiori, especially if algo-\nrithms incorporate, however inadvertently, judg-\nments based on irrational prejudice (Barocas and\nSelbst, forthcoming; Sweeney, 2013). More gener-\nally, complex judgments modeled from human\ninput may fail whenever human raters are influenced\nby factors unrelated to the ostensible goal (e.g. iden-\ntifying the quality of a restaurant) or if principles by\nwhich humans generate ratings are heterogeneous\nacross raters (or within raters over time)--for exam-\nple if some people rate films based on their plots and\nothers rate them based on a filmic aesthetic. Because\nsentiment analysis is such a powerful complement to\ntopic models for the interpretation of texts, as well as\nfor the algorithms that power on-line recommenda-\ntion systems, sentiment analysis may be the best\nplace to begin to address this third priority. I suspect\nthat human judgment is useful in rating sentiment,\nbut only when criteria are clearly articulated, specific\nto a single domain, and applied by domain experts in\nlabor-intensive ways.4 But I know of no research\nthat either supports or disconfirms this intuition.\nEngagement with computational text analysis\nentails more than adapting new methods to social-\nscience research questions. It also requires social sci-\nentists to relax some of our own disciplinary biases,\nsuch as our preoccupation with causality, our assump-\ntion that there is always a best-fitting solution, and our\ntendency to bring habits of thought based on causal\nmodeling of population samples to interpretive mod-\neling of complete populations. If we do, the encounter\nwith machine learning may pay off not just by provid-\ning tools for text analysis, but also by improving the\nway we use more conventional methods. To be sure,\nthere are risks in going against the grain. But this is a\ngreat time for social scientists to get involved in com-\nputational text analysis, because the field is relatively\nyoung, the challenges are intellectually captivating,\nand there is still time to influence the shape that\nthese methods will take as they enter the social\nsciences.\nDeclaration of conflicting interest\nThe author(s) declared no potential conflicts of interest with\nrespect to the research, authorship, and/or publication of this\narticle.\nFunding\nThe author(s) received no financial support for the research,\nauthorship, and/or publication of this article.\nNotes\n1. In some ways, computer scientists who contribute to text\nanalysis are as similar to humanists (e.g. in their emphasis\non interpretation rather than hypothesis testing and their\nunderstanding of contextual validity) as they are to most\nsocial scientists. Were it not for the generosity of compu-\nter-science colleagues in educating me about computa-\ntional text analysis, sharing their insights, correcting\ninitial (and sometimes persistent) misperceptions, and put-\nting up with endless questions, I would never have been\nable to work in this area or write this essay. I am especially\ngrateful to three patient and wise tutors, David Blei,\nChristiane Fellbaum, and David Mimno, none of whom\nshould be presumed to agree with opinion expressed\nherein.\n2. In thinking about interpretive uncertainty, I would suggest\nan analogy to internal and external validity and distinguish\nbetween what we might call ``internal uncertainty'' (how\ncan we be sure that our interpretation of the meaning of a\ntopic is better than an alternative interpretation?) and\n``external uncertainty'' (recognizing that the same text\nwill speak in different ways and be interpreted differently\nby different audiences).\n3. Sociology and political science graduate programs are\nbeginning to produce a trickle of scholars with the statis-\ntics and programming skills to participate fully in cutting-\nedge methodological work, a development that is all to the\ngood. Based on observation of previous methods, how-\never, I would predict that the rate at which our graduate\nprograms produce such scholars will be exceeded by the\nrate at which new methods are codified in statistical pack-\nages that will be used (and abused) by social scientists with\nfewer technical skills, making research on such issues as\npre-processing and model choice even more important.\n4. In comments on an earlier draft, my colleague Christiane\nFellbaum pointed out that humans who might find it very\ndifficult to agree on the meaning or affective tone of a\nparticular sentence, have no trouble understanding one\nanother in practice. Rather than give up on human\ncoding of complex texts, she suggests, we should try to\nunderstand and model the interpretive variation.\nReferences\nAlmeydin E (2014) Introduction to Machine Learning, 3rd ed.\nCambridge, MA: MIT Press.\nBarocas S and Selbst A (2016) Big data's disparate impact.\nCalifornia Law Review 104. Available at http://ssrn.com/\n4 Big Data & Society\nBlei DM (2012) Probabilistic topic models. Communications\nBlei DM, Ng AY and Jordan MI (2003) Latent Dirichlet\nallocation. Journal of Machine Learning Research 3:\nBoyd-Graber J, Mimno D and Newman D (2014) Care and\nfeeding of topic models: Problems, diagnostics and\nimprovements. In: Airoldi E, Blei D, Erosheva E, et al.\n(eds) Handbook of Mixed Membership Models and their\nApplications. Boca Raton, FL: CRC Press, pp. 3\u00ad41.\nChang J, Boyd-Graber J, Gerrish S, et al. (2009) Reading tea\nleaves: How humans interpret topic models. In: Advances\nin Neural Information Processing Systems 1 (NIPS-09).\nDiMaggio P, Nag M and Blei DM (2013) Exploiting affinities\nbetween topic models and the sociological perspective\non culture: Applications to newspaper coverage of U.S.\nGilbert DT (1991) How mental systems believe. American\nGraham J, Haidt J and Nosek BA (2009) Liberals and con-\nservatives rely on different sets of moral foundations.\nJournal of Personality and Social Psychology 96:\nGrimmer J and Stewart B (2013) Text as data: The promise\nand pitfalls of automatic content analysis methods for pol-\nHammond KR (2000) Judgments Under Stress. New York,\nNY: Oxford University Press.\nHardin C and Banaji MR (2013) The nature of implicit preju-\ndice. In: Shafir E (ed.) The Behavioral Foundations of\nPublic Policy. Princeton, CA: Princeton University Press,\nInouye DI, Ravikumar P and Dhillion IS (2014) Admixture\nof Poisson MRFs: A topic model with word dependencies.\nProceedings of the 31st International Conference on\nMachine Learning, Beijing, China. JMLR: W&CP 32:\nJelveh Z, Kogut B and Naidu S (2014) Political language in\neconomics. Columbia Business School Research Paper\nNo. 14-57. Available at: http://papers.ssrn.com/sol3/\nKahneman D (2003) A perspective on judgment and choice:\nMapping bounded rationality. American Psychologist 58:\nKaplan S and Vaili K (2014) The double-edged sword of\nrecombination in breakthrough innovation. Strategic\nManagement Journal Epub ahead of print 2 July 2014.\nLau JH, Newman D and Baldwin T (2014) Machine reading\ntea leaves: Automatically evaluating topic coherence and\ntopic model quality. In: Proceedings of the 14th conference\nof the European chapter of the association for computational\nlinguistics. Gothenburg, Sweden: Association for\nLiu B (2010) Sentiment analysis and subjectivity.\nIn: Indurkhya N and Damerau FJ (eds) Handbook of\nNatural Language Processing, 2nd ed. Boca Raton, FL:\nTaylor and Francis Group.\nMarshall E (2013) Defining population problems: Using topic\nmodels for cross-national comparison of disciplinary\nMimno D and Blei D (2011) Bayesian checking fo topic\nmodels. Proceedings of the 2011 Conference on Empirical\nMethods in Natural Language Processing, Association for\nComputational Linguistics.\nMimno D, Wallach HM, Talley E, et al. (2011) Optimizing\nsemantic coherence in topic models. In: Proceedings of the\nconference on empirical methods in natural language pro-\ncessing, Edinburgh, Scotland. Association for\nMullainathan S and Shafir E (2013) Scarcity: Why Having\nToo Little Means So Much. New York, NY: Henry Holt\nand Company.\nNag M (2015) Meaning is relational: The changing contexts\nof the keyword risk' in the New York Times using a bag-\nof-tuples topic model. Paper presented at Texts II\nConference, Princeton University, June.\nNisbett RE and Wilson TE (1977) Telling more han we can\nknow: Verbal reports on mental processes. Psychological\nNelson LK (2014) The Power of Place: Structure, Culture\nand Continuities in U.S. Women's Movements. PhD\nDissertation, University of California, Berkeley. Proquest\nPearl J (2009) Causality, 2nd ed. New York, NY: Cambridge\nUniversity Press.\nRoberts M, Stewart BM and Tingley D (2014) Navigating the\nlocal modes of Big Data: The case of topic models.\nAvailable at: http://scholar.harvard.edu/files/dtingley/\nShiller RJ (2015) Irrational Exuberance, 2nd ed. Princeton,\nCA: Princeton University Press.\nSnow CP (1959) The Two Cultures. Cambridge, UK:\nCambridge University Press.\nSweeney L (2013) Discrimination in online ad delivery.\nTourangeau R and Yan T (2007) Sensitive questions in sur-\nTuring AM (1950) Computing machinery and intelligence.\nThis article is part of a special theme on Colloquium: Assumptions of Sociality. To see a full list of all articles\nin this special theme, please click here: http://bds.sagepub.com/content/colloquium-assumptions-sociality.\nDiMaggio 5"
}