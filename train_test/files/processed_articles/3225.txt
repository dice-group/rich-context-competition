{
    "abstract": "Abstract\nIn a Markov decision problem with hidden state variables, a posterior distribution\nserves as a state variable and Bayes' law under an approximating model gives its law of\nmotion. A decision maker expresses fear that his model is misspecified by surrounding\nit with a set of alternatives that are nearby when measured by their expected log\nlikelihood ratios (entropies). Martingales represent alternative models. A decision\nmaker constructs a sequence of robust decision rules by pretending that a sequence\nof minimizing players choose increments to a martingale and distortions to the prior\nover the hidden state. A risk sensitivity operator induces robustness to perturbations\nof the approximating model conditioned on the hidden state. Another risk sensitivity\noperator induces robustness to the prior distribution over the hidden state. We use\nthese operators to extend the approach of Hansen and Sargent (1995) to problems that\ncontain hidden states. The worst case martingale is overdetermined, expressing an\nintertemporal inconsistency of worst case beliefs about the hidden state, but not about\nobservables.\nNon-technical summary\nThis paper deals with a fundamental question of applied economics: how should decision-\nmakers, especially economic policy decision-makers, behave if they wish to take account of\nthe fact that their knowledge of the economy is no more than incomplete. This is of key\nimportance for central banks, which continually have to take monetary policy decisions that\nare necessarily based on models, ie on systematic simplifications of reality, the precise details\nof which can never be understood with complete certainty.\nThis problem can be specifically related to the debate that has been conducted on the risk of\ndeflation in the USA and Europe. In 2003, short-term nominal interest rates were at an all-\ntime low, as was inflation. In this context, it should be remembered that nominal interest rates\ncannot be negative and that the real interest rates which are relevant to economic planning are\nnominal interest rates less inflation. Statistical models which have been used up to now, and\nwhich have been used by central banks very successfully for forecasts under conditions of\nstrictly positive inflation, may turn out to be unsuitable for new, more extreme conditions. For\nexample, given deflation (in other words, negative inflation), if nominal interest rates are\nalmost equal or equal to zero, real interest rates are, of necessity, positive. These, in turn, slow\ndown the economy and may therefore further accelerate deflation. A traditional model might\ngive disastrous recommendations even though it has functioned well in \"normal\" times.\nThis is one of the reasons why central banks do not rely blindly on statistical models, but\nrather draw on their experience and intuition under rarer but riskier conditions. It may rightly\nbe claimed that deflation in the USA has been prevented inter alia by the Fed acting in a\nforward-looking manner and attaching particular importance to worst case scenarios, even\nthough traditional models make no provision for these.\nWhat position does this paper take up in this context? It develops principles on which\neconomic policymakers can draw if the \"true\" model of the world is unknown to them. It\nthereby departs from the existing analytical methodology which studies the economic policy\nissues on the assumption that all the economic agents know the \"correct\" model and that\neveryone knows the same, correct model. Although conducting analyses on this assumption\nhas enormous practical advantages, there is no perception of how risky the unconscious use of\na possibly incorrect model is under extreme conditions, even if such conditions are very\nunlikely.\nNicht technische Zusammenfassung\nDiese Arbeit besch\u00e4ftigt sich mit einer fundamentalen Frage der angewandten Volkswirt-\nschaftslehre: Wie sollen sich Entscheidungstr\u00e4ger, insbesondere in der Wirtschaftspolitik,\nverhalten, wenn sie ber\u00fccksichtigen wollen, dass sie die Wirtschaft nur unvollst\u00e4ndig kennen.\nDies ist von zentraler Bedeutung f\u00fcr Zentralbanken, die kontinuierlich geldpolitische Ent-\nscheidungen treffen m\u00fcssen, die notwendigerweise auf Modellen beruhen, also auf systemati-\nschen Vereinfachungen der Wirklichkeit, deren Zusammenh\u00e4nge man notwendigerweise nie\nmit v\u00f6lliger Sicherheit wird verstehen k\u00f6nnen.\nKonkret l\u00e4sst sich dieses Problem auf die Diskussion anwenden, die in Bezug auf die Gefahr\neiner Deflation in den USA und Europa gef\u00fchrt wurde. Kurzfristige Nominalzinsen waren\n2003 auf historisch niedrigem Niveau, ebenso die Inflation. Man bedenke dabei, dass Nomi-\nnalzinsen nicht negativ sein k\u00f6nnen, und dass die f\u00fcr wirtschaftliche Planungen relevanten\nRealzinsen gleich Nominalzins minus Inflation sind. Bisher benutzte statistische Modelle, die\nvon Zentralbanken unter Bedingungen strikt positiver Inflation sehr gut f\u00fcr Vorhersagen ver-\nwendet werden konnten, sind m\u00f6glicherweise f\u00fcr neue, extremere, Bedingungen nicht geeig-\nnet. Wenn zum Beispiel bei einer Deflation (also negativer Inflation) die nominellen Zinsen\nfast oder gleich Null sind, liegen notwendigerweise positive Realzinsen vor. Diese wiederum\nbremsen die Konjunktur und k\u00f6nnen somit eine Deflation noch beschleunigen. Ein herk\u00f6mm-\nliches Modell k\u00f6nnte unter Umst\u00e4nden katastrophale Empfehlungen geben, obwohl es in\n,,normalen\" Zeiten gut funktioniert hat.\nDies ist einer der Gr\u00fcnde, warum Zentralbanken nicht blind auf statistische Modelle vertrau-\nen, sondern unter seltenen, aber risikoreichen Bedingungen auf ihre Erfahrung und Intuition\nzur\u00fcckgreifen. Es kann mit Recht behauptet werden, dass eine Deflation in den USA auch da-\ndurch vermieden wurde, dass die Fed vorausschauend agiert hat, und ,,worst case\" Szenarien\nbesonderes Gewicht verliehen hat, obwohl herk\u00f6mmliche Modelle diese nicht vorsehen.\nWie ordnet sich diese Arbeit in diese Diskussion ein? Sie erarbeitet Prinzipien, auf die wirt-\nschaftliche Entscheidungstr\u00e4ger zur\u00fcckgreifen k\u00f6nnen, wenn ihnen das ,,wahre\" Modell der\nWelt nicht bekannt ist. Damit weicht sie von der bisherigen Analysemethodik ab, die wirt-\nschaftspolitische Fragestellungen unter der Annahme untersucht, dass allen Wirtschaftssub-\njekten das ,,richtige\" Modell bekannt ist, und dass alle das gleiche, richtige Modell kennen.\nW\u00e4hrend es enorme praktische Vorteile hat, Analysen unter dieser Annahme vorzunehmen,\nhat man kein Gef\u00fchl daf\u00fcr, wie riskant der unbewusste Gebrauch eines vielleicht falschen\nModells unter extremen Bedingungen ist, selbst wenn diese sehr unwahrscheinlich sind.\nRecursive Robust Estimation and Control Without\nCommitment\n1 ",
    "reduced_content": "Recursive robust estimation and\ncontrol without commitment\nLars Peter Hansen\n(University of Chicago)\nThomas J. Sargent\n(New York University and Hoover Institution)\nDiscussion Paper\nSeries 1: Economic Studies\nDiscussion Papers represent the authors' personal opinions and do not necessarily reflect the views of the\nDeutsche Bundesbank or its staff.\nEditorial Board: Heinz Herrmann\nThilo Liebig\nKarl-Heinz T\u00f6dter\nDeutsche Bundesbank, Wilhelm-Epstein-Strasse 14, 60431 Frankfurt am Main,\nPlease address all orders in writing to: Deutsche Bundesbank,\nReproduction permitted only if source is stated.\n Introduction\nIn problems with incomplete information, optimal decision rules depend on a decision maker's\nposterior distribution over hidden state variables, called qt(z) here, an object that summarizes\nthe history of observed signals. A decision maker expresses faith in his model when he uses\nBayes' rule to deduce the transition law for qt(z).1\nBut how should a decision maker proceed if he doubts his model and wants a decision\nrule that is robust to a set of statistically difficult to detect misspecifications of it? We begin\nby assuming that, through some unspecified process, a decision maker has arrived at an\n*Lars Peter Hansen, University of Chicago. Email: l-hansen@uchicago.edu;\nThomas J. Sargent, New York University and Hoover Institution. Email: ts43@nyu.edu.\nWe thank Ricardo Mayer and especially Tomasz Piskorski for helpful comments on earlier drafts of this\nWe thank In-Koo Cho for encouragement.\npaper.\napproximating model that fits historical data well. Because he fears that his approximating\nmodel is misspecified, he surrounds it with a set of all alternative models whose expected\nlog likelihood ratios (i.e., whose relative entropies) are restricted or penalized. The decision\nmaker believes that the data will be generated by an unknown member of this set. When\nrelative entropies are constrained to be small, the decision maker believes that his model\nis a good approximation. The decision maker wants robustness against these alternatives\nbecause, as Anderson, Hansen, and Sargent (2003) emphasize, perturbations with small\nrelative entropies are statistically difficult to distinguish from the approximating model.\nThis paper assumes that the appropriate summary of signals continues to be the decision\nmaker's posterior under the approximating model, despite the fact that he distrusts that\nmodel. Hansen and Sargent (2005) explore the meaning of this assumption by studying a\nclosely related decision problem under commitment to a worst case model.\nSection 2 formulates a Markov control problem in which a decision maker with a trusted\nmodel receives signals about hidden state variables. By allowing the hidden state vector to\nindex submodels, this setting includes situations in which the decision maker has multiple\nmodels or is uncertain about coefficients in those models. Subsequent sections view the\nmodel of section 2 as an approximation, use relative entropy to define a cloud of models that\nare difficult to distinguish from it statistically, and construct a sequence of decision rules that\ncan work well for all of those models. Section 3 uses results of Hansen and Sargent (2005)\nto represent distortions of an approximating model in terms of martingales defined on the\nsame probability space as the approximating model. Section 4 then defines two operators, T1\n, respectively, that are indexed by penalty parameters (1\n). In section 5, we use\nT1 to adjust continuation values for concerns about model misspecification, conditioned on\nknowledge of the hidden state. We use T2 to adjust continuation values for concern about\nmisspecification of the distribution of the hidden state. We interpret 1\nas penalties\non pertinent entropy terms\nSection 6 discusses the special case that prevails when 1\nand relates it to a decision\nproblem under commitment that we analyzed in Hansen and Sargent (2005). We discuss\nthe dynamic consistency of worst case beliefs about the hidden state in subsections 6.4\nand 6.6. Section 7 describes the worst case distribution over signals and relates it to the\ntheory of asset pricing. Section 8 interprets our formulation and suggests modifications of\nit in terms of the multiple priors models of Epstein and Schneider (2003a) and Epstein\nand Schneider (2003b). Section 9 briefly relates our formulation to papers about reducing\ncompound lotteries. Section 10 specializes our section 5 recursions to compute robust decision\nrules for the linear quadratic case, and appendix A reports useful computational tricks for\nthis case. Section 11 concludes. Hansen and Sargent (2005) contains an extensive account of\nrelated literatures. An application to a decision problem with experimentation and learning\nabout multiple submodels appears in Cogley, Colacito, Hansen, and Sargent (2005).\n2 A control problem without model uncertainty\nFor t  0, we partition a state vector as xt\n=\nyt\nzt\n, where yt\nis observed and zt\nis not. A\nvector of st\nof observable signals is correlated with the hidden state zt\nand is used by the\ndecision maker to form beliefs about the hidden state. Let Z denote a space of admissible\nunobserved states, Z a corresponding sigma algebra of subsets of states, and  a measure\non the measurable space of hidden states (Z, Z). Let S denote the space of signals, S a\ncorresponding sigma algebra, and  a measure on the measurable space (S, S) of signals.\nSignals and states are determined by the transition functions\n= y\n, yt\n, at\n= z\n(xt\n, at\n= s\n(xt\n, at\nwhere {wt+1\n: t  0} is an i.i.d. sequence of random variables. Knowledge of y0\nand y\nallows\nus to construct yt\nrecursively from signals and actions. Substituting (3) into (1) gives the\nrecursive evolution for the observable state in terms of next period's shock wt+1\n:\n= y\n[s\n(xt\n, at\n), yt\n, at\n]\n.\n= \u00af\ny\n(xt\n, at\nEquations (2) and (3) determine a conditional density (zt+1\n|xt\n, at\n) relative to the prod-\nuct measure  \u00d7 .\nLet {St\n: t  0} denote a filtration, where St\nis generated by y0\n, ..., st\n. We can\napply Bayes' rule to  to deduce a density qt\n, relative to the measure , for zt\nconditioned\non information St\n. Let {Xt\n: t  0} be a larger filtration where Xt\nis generated by x0\n,\n, ..., wt\n. The smallest sigma algebra generated by all states for t  0 is X\n.\n=\nXt\n; the\nsmallest sigma algebra generated by all signals for t  0 is S\n.\n=\nSt\n. Let A denote a\nfeasible set of actions, which we take to be a Borel set of some finite dimensional Euclidean\nspace, and let At\nbe the set of A-valued random vectors that are St\nmeasurable. Given the\nrecursive construction of xt\nin equation (1) - (2) and the informational constraint on action\nprocesses, xt\nis Xt\nmeasurable and yt\nis St\nmeasurable.\nAs a benchmark, consider the following decision problem under incomplete information\nabout the state but complete confidence in the model (1), (2), (3):\nmax\nE\nT\ntU(xt\n, at\nTo make problem 2.1 recursive, use  to construct two densities for the signal:\n(s|yt\n, zt\n, at\n)\n.\n= (z, s|yt\n, zt\n, at\n)d(z)\n(s|yt\n, qt\n, at\n)\n.\n= (s|yt\n, z, at\n)qt\n(z)d(z). (5)\nBy Bayes' rule, qt+1\n(z) =\nR\n(z,st+1|yt,z,at)qt(z)d(z)\n(st+1|yt,qt,at)\n q\n, yt\n, qt\n, at\n). In particular applica-\ntions, q\ncan be computed with methods that specialize Bayes' rule (e.g., the Kalman filter\nor a discrete time version of the Wonham (1964) filter).\nTake (yt\n, qt\n) as the state for a recursive formulation of problem 2.1. The transition law\nis (1) and\n= q\n, yt\n, qt\n, at\nLet  =\ny\nq\n. Then we can rewrite problem 2.1 in the alternative form:\nProblem 2.2. Choose a sequence of decision rules for at\nas functions of (yt\n, qt\n) for each\nt  0 that maximizes\nE\nT\ntU(xt\n, at\nsubject to (1), (6), a given density q0\n(z), and the density (st+1\n|yt\n, zt\n, at\n). The Bellman\nequation for this problem is\nW(y, q) = max\naA\nU(x, a) +  W [(s, y, q, a)] (s|y, z, a)d(s) q(z)d(z). (7)\nIn an infinite horizon version of problem 2.2, W = W.\nExamples from outside economics appear in Elliott, Aggoun, and Moore (1995). Problems\nthat we are especially interested in are illustrated in the following four examples.\nExample 2.3. Model Uncertainty I: two submodels. Let the hidden state z  {0, 1} index a\nsubmodel. Let\n= zt\n= s\n(yt\n, z, at\nThe hidden state is time invariant. The decision maker has a prior probability Prob(z =\n0) = q. The third equation in (8) depicts two laws of motion. Cogley, Colacito, and Sargent\n(2005) and Cogley, Colacito, Hansen, and Sargent (2005) study the value of monetary policy\nexperimentation in a model in which a is an inflation target and s\n(y, z, a, w) = \u00af\ny\n(y, z, a, w)\nfor z  {0, 1} represent two submodels of inflation-unemployment dynamics.\nExample 2.4. Model Uncertainty II: a continuum of submodels. The observable state y takes\nthe two possible values {yL\n, yH\n}. Transition dynamics are still described by (8), but now there\nis a continuum of models indexed by the hidden state z  [0, 1]\u00d7[0, 1] that stands for unknown\nvalues of two transition probabilities for an observed state variable y. Given z, we can use\nthe third equation of (8) to represent a two state Markov chain on the observable state y\n(see Elliott, Aggoun, and Moore (1995)), P =\n) = z. The\ndecision maker has a prior f0\n) on z; f0\nare beta distributions.\nExample 2.5. Model Uncertainty III: A components model of income dynamics with an\nunknown fixed effect in labor income. The utility function U(at\n) is a concave function of\nconsumption at\nis the level of financial assets, and y1t\n= st\nis observed labor income.\nThe evolution equations are\n- at\n]\nwhere wt+1\n N(0, I) is an i.i.d. bivariate Gaussian process, R  -1 is a gross return on\nfinancial assets y2,t\nis an unobserved constant component of labor income, and\nis an unobserved serially correlated component of labor income. A decision maker has a\n).\nExample 2.6. Estimation of drifting coefficients regression model. The utility function\nU(xt\n, at\n) = -L(zt\n- at\n), where L is a loss function and at\nis a time-t estimator of the\ncoefficient vector zt\n. The evolution equation is\n= zt\n= yt\n\u00b7 zt\nwhere wt+1\n N(0, I) and there is a prior q0\n(z) on an initial set of coefficients.\n2.2 Modified problems that distrust (s|y, z, a) and q(z)\nThis paper studies modifications of problem 2.2 in which the decision maker wants a decision\nrule that is robust to possible misspecifications of equations (1)-(2). Bellman equation (7)\nindicates that the decision maker's concerns about misspecification of the stochastic struc-\nture can be focused on two aspects: the conditional distribution of next period's signals\n(s|y, z, a) and the distribution over this period's value of the hidden state q(z). We pro-\npose recursive formulations of a robust control problem that allow a decision maker to focus\non either or both of these two aspects of his stochastic specification.\n3 Using martingales to represent model misspecifica-\ntions\nEquations (1)-(2) induce a probability measure over Xt\nfor t  0. Hansen and Sargent\n-measurable function Mt\nwith EMt\n= 1 to create a distorted\nprobability measure that is absolutely continuous with respect to the probability measure\nover Xt\ngenerated by the model (1) - (2). The random variable Mt\nis a martingale under this\nbaseline probability measure. Using Mt\nas a Radon-Nikodym derivative generates a distorted\nmeasure under which the expectation of a bounded Xt\n-measurable random variable Wt\nis\n~\n.\n= EMt\nWt\n. The entropy of the distortion at time t conditioned on date zero information\nis E (Mt\nlog Mt\n) or E(Mt\nlog Mt\n).\n3.1 Recursive representations of distortions\nIt is convenient to factor a density Ft\nfor an Xt\n-measurable random variable Ft\n=\nFt\nwhere ft+1\nis a one-step ahead density conditioned on Xt\n. It is useful to factor Mt\nin a similar way. Thus, to represent distortions recursively, take a nonnegative martingale\n{Mt\n: t  0} and form\n=\nMt\nif Mt\nMt\nand\nMt\nt\nmj\nThe random variable M0\nhas unconditional expectation equal to unity. By construction, mt+1\nhas date t conditional expectation equal to unity. For a bounded random variable Wt+1\nthat is Xt+1\n-measurable, the distorted conditional expectation implied by the martingale\n{Mt\n: t  0} is\n|Xt\n)\n|Xt\n)\n=\n|Xt\n)\nMt\n|Xt\n)\nprovided that Mt\nto model distortions of the conditional probability\ndistribution for Xt+1\ngiven Xt\n. For each t  0, construct the space Mt+1\nof all nonnegative,\n-measurable random variables mt+1\nfor which E(mt+1\n|Xt\nThe conditional (on Xt\n) relative entropy of a nonnegative random variable mt+1\nt\n)\n.\n|Xt\n) .\n3.2 Distorting likelihoods with hidden information\nThe random variable Mt\nis adapted to Xt\nand is a likelihood ratio for two probability distrib-\nutions over Xt\n. The St\n-measurable random variable Gt\n= E (Mt\n|St\n) implies a likelihood ratio\nfor the reduced information set St\n; Gt\nassigns distorted expectations to St\n-measurable ran-\ndom variables that agree with Mt\n, and {Gt\n: t  0} is a martingale adapted to {St\nDefine the Xt\n-measurable random variable ht\nby\nht\n.\n=\nMt\nE(Mt|St)\nif E (Mt\n|St\n1 if E (Mt\n|St\nand decompose Mt\nas\nMt\n= ht\nGt\nDecompose entropy as\nE(Mt\nlog Mt\n) = E [E (ht\nlog ht\n|St\n) + Gt\nlog Gt\n] .\nt\n(ht\n)\n.\n= E (ht\nlog ht\n|St\n) as the conditional (on St\n) relative entropy.\nWe now have the tools to represent and measure misspecifications of the two components\n(s|y, z, a) and q(z) in (7). In (10), Mt\ndistorts the probability distribution of Xt\n, ht\ndistorts the probability of Xt\nconditioned on St\n, Gt\ndistorts the probability of St\n, and mt+1\ndistorts the probability of Xt+1\ngiven Xt\n. We use multiplication by mt+1\nto distort  and\nmultiplication by ht\nto distort q; and we use 1\nt\n) to measure mt+1\nt\n(ht\n) to measure\nht\n.\nSection 4 uses these distortions to define two pairs of operators, then section 5 applies\nthem to form counterparts to Bellman equation (7) that can be used to get decisions that\nare robust to these misspecifications.\n4 Two pairs of operators\nThis section introduces two pairs of operators, (R1\nt\nt\n, T2). In section 5, we use\nthe T1 and T2 operators to define recursions that induce robust decision rules.\nt\nbe an Xt+1\n-measurable random variable for which E exp -Wt+1\n\n|Xt\n<\n. Then define\nt\n|) = min\n|Xt\nt\n)\n= - log E exp -\n\n|Xt\nThe minimizing choice of mt+1\nis\nm\n=\n\nE exp -Wt+1\n\n|Xt\nIn the limiting case that sets the entropy penalty parameter  = , R1\nt\n|) =\n|Xt\n). Notice that this expectation can depend on the hidden state. When  < , R1\nt\nadjusts E(Wt+1\n|Xt\n) by using a worst-case belief about the probability distribution of Xt+1\nconditioned on Xt\nthat is implied by the twisting factor (12). When the conditional moment\nrestriction E exp -Wt+1\n\n|Xt\n<  is not satisfied, we define R1\nt\nto be - on the relevant\nconditioning events.\nWhen the Xt+1\n-measurable random variable Wt+1\ntakes the special form V (yt+1\n),\nt\n(\u00b7|) operator defined in (11) implies another operator:\n(T1V |)(y, q, z, a) = - log exp -\nV [(s, y, q, a), z]\n\n(z, s|y, z, a)d(z)d(s).\nThe transformation T1 maps a value function that depends on next period's state (y, q, z)\ninto a risk-adjusted value function that depends on (y, q, z, a). Associated with this risk\nadjustment is a worst-case distortion in the transition dynamics for the state and signal\nprocess. Let  denote a nonnegative density function defined over (z, s) satisfying\n(z, s)(z, s|y, z, a)d(z)d(s) = 1. (13)\nThe corresponding entropy measure is:\nlog[(z, s)](z, s)(z, s|y, z, a)d(z)d(s) = 1.\nIn our recursive formulation, we think of  as a possibly infinite dimensional control vector\n(a density function) and consider the minimization problem:\nmin\n(V [(s, y, q, a), z] + 1\nlog[(z, s)]) (z, s)(z, s|y, z, a)d(z)d(s)\nsubject to (13). The associated worst-case density conditioned on Xt\nis t\n(z, s)(z, s|xt\n, at\n)\nwhere\nt\n(z, s) =\nexp -V [(s,yt,qt,at),z]\n\nE exp -V [(st+1,yt,qt,at),zt+1]\n\n|Xt\nt\nFor  > 0, let ^\nWt\nbe an Xt\n-measurable function for which E exp - ^\nWt\n\n|St\n< . Then\ndefine\nt\n^\nWt\n| = min\nhtHt\nE ht\n^\nWt\n|St\nt\n(ht\n)\n= - log E exp -\n^\nWt\n\n|St\nThe minimizing choice of ht\nis\nh\nt\n=\nexp - ^\nWt\n\nE exp - ^\nWt\n\n|St\n.\nWhen an Xt\n-measurable function has the special form ^\nWt\n= ^\nV (yt\n, qt\n, zt\n, at\nt\ngiven by\n(15) implies an operator\nV |)(y, q, a) = - log exp -\n^\nV (y, q, z, a)\n\nq(z)d(z).\nThe associated minimization problem is:\nmin\n^\nV (y, q, z, a) +  log (z) (z)q(z)d(z)\nsubject to (16), where (z) is a relative density that satisfies:\nand the entropy measure is\n[log (z)](z)q(z)d(z).\nThe optimized density conditioned on St\nis t\n(z)qt\n(z), where\nt\n(z) =\nexp - ^\nV (yt,qt,z,at)\n\nE exp - ^\nV (yt,qt,z,at)\n\n|St\n5 Control problems with model uncertainty\nWe propose robust control problems that take qt\n(z) as the decision maker's state variable for\nsummarizing the history of signals. The decision maker's model includes the law of motion\n(6) for q (Bayes' law) under the approximating model (1), (2), (3). Two recursions that\ngeneralize Bellman equation (7) express alternative views about the decision maker's fear of\nmisspecification. A first recursion works with value functions that include the hidden state\nz as a state variable. Let\n\nW(y, q, z) = U(x, a) + E  \nW[(s, y, q, a), z] x, q , (18)\nwhere the action a solves:\nW(y, q) = max\na\nE U(x, a) + E  \nW[(s, y, q, a), z] x, q, a y, q, a . (19)\nThe value function \nW depends on the hidden state z, whereas the value function W in (7)\ndoes not. A second recursion modifies the ordinary Bellman equation (7), which we can\nexpress as:\nW(y, q) = max\na\nE U(x, a) + E W[(s, y, q, a)] x, q, a y, q, a . (20)\nAlthough they use different value functions, without concerns about model misspecifica-\ntion, formulations (18)-(19) and (20) imply identical control laws. Furthermore, W(y, q)\nobeys (19), by virtue of the law of iterated expectations. Because Bellman equation (20)\nis computationally more convenient, the pair (18)-(19) is not used in the standard problem\nwithout a concern for robustness. However, with a concern about robustness, a counter-\npart to (18)-(19) becomes useful when the decision maker wants to explore distortions of\nthe joint conditional distribution (s, z|y, z, a).2 Distinct formulations emerge when we\n2Another way to express his concerns is that in this case the decision maker fears that (2) and (3) are\nboth misspecified.\nreplace the conditional expectation E(\u00b7|y, q, a) with T2(\u00b7|2\n) and the conditional expectation\nE(\u00b7|x, q, a) with T1(\u00b7|1\n) in the above sets of recursions. When 1\n(20) lead to value functions and decision rules equivalent to those from either (18)-(19) or\n< +, they differ because they take different views about\nwhich conditional distributions the malevolent player wants to distort.\n5.0.1 Which conditional distributions to distort?\nThe approximating model (1), (2), (3) makes both tomorrow's signal s and tomorrow's\nstate z functions of x. When tomorrow's value function depends on s but not on z, the\nminimizing player chooses to distort only (s|y, z, a), which amounts to being concerned\nabout misspecified models only for the evolution equation (3) for the signal and not (2)\nfor the hidden state. Such a continuation value function imparts no additional incentive to\ndistort the evolution equation (2) of z conditioned on s and x.3 A continuation value that\ndepends on s but not on z thus imparts concerns about a limited array of distortions that\nignore possible misspecification of the z evolution (2). Therefore, when we want to direct\nthe maximizing agent's concerns about misspecification onto the conditional distribution\n(s|y, z, a), we should form a current period value that depends only on the history of the\nsignal and of the observed state. We do this in recursion (23) below.\nIn some situations, we want to extend the maximizing player's concerns about misspec-\nification to the joint distribution (z, s|y, z, a) of z and s. We can do this by making\ntomorrow's value function for the minimizing player also depend on z. This will prompt\nthe minimizing agent to distort the joint distribution (z, s|y, z, a) of (z, s). In recursions\n(21)-(22) below, we form a continuation value function that depends on z and that extends\nrecursions (18), (19) to incorporate concerns about misspecification of (2).\nThus, (21)-(22) below will induce the minimizing player to distort the distribution of z\nconditional on (s, x, a), while the formulation in (23) will not.\n5.1 Value function depends on (x, q)\nBy defining a value function that depends on the hidden state, we focus the decision maker's\nattention on misspecification of the joint conditional distribution (z, s|y, z, a) of (s, z).\nWe modify recursions (18)-(19) by updating a value function according to\n\nW(y, q, z) = U(x, a) + T1  \nW(y, q, z)|1\nafter choosing an action according to\nmax\na\nW(y, q, z)|1\n \n \n) for \n, \nthat make the problems well posed.4 Updating the value\nfunction by recursion (21) makes it depend on (x, q), while using (22) to guide decisions makes\n3Dependence between (s, z) conditioned on x under the approximating model means that in the process\nof distorting s conditioned on (x, a), the minimizing player may indirectly distort the distribution of z\nconditioned on (x, a). But he does not distort the distribution of z conditioned on (s, x, a)\nare typically needed to make the outcomes of the T1 and T2 operators be finite.\nactions depend only on the observable state (y, q). Thus, continuation value \nW depends on\nunobserved states, but actions do not. To retain the dependence of the continuation value\non z, (21) refrains from using the T2 transformation when up-dating continuation values.\nThe fixed point of (21)-(22) is the value function for an infinite horizon problem. For the\nfinite horizon counterpart, we begin with a terminal value function and view the right side\nof (21) as mapping next period's value function into the current period value function.\n5.2 Value function depends on (y, q)\nTo focus attention on misspecifications of the conditional distribution (s|y, z, a), we want\nthe minimizing player's value function to depend only on the reduced information encoded\nin (y, q). For this purpose, we use the following counterpart to recursion (20):\nW(y, q) = max\na\n] (x, q, a) 2\n \n \n). Although z is excluded from the value function W, z\nmay help predict the observable state y or it may enter directly into the current period\nreward function, so application of the operator T1 creates a value function that depends on\n(x, q, a), including the hidden state z. Since the malevolent agent observes z, he can distort\nthe dynamics for the observable state conditioned on z via the T1 operator. Subsequent\napplication of T2 gives a value function that depends on (y, q, a), but not z; T2 distorts the\nhidden state distribution. The decision rule sets action a as a function of (y, q). The fixed\npoint of Bellman equation (23) gives the value function for an infinite horizon problem. For\nfinite horizon problems, we iterate on the mapping defined by the right side of (23), beginning\nwith a known terminal value function. Recursion (23) extends the recursive formulation of\nrisk-sensitivity with discounting advocated by Hansen and Sargent (1995) to situations with\na hidden state.\n5.3 Advantages of our specification\nWe take the distribution qt\n(z) as a state variable and explore misspecifications of it. An\nalternative way to describe a decision maker's fears of misspecification would be to perturb\nthe evolution equation for the hidden state (1) directly. Doing that would complicate the\nproblem substantially by requiring us to solve a filtering problem for each perturbation of\n(1). Our formulation avoids multiple filtering problems by solving one and only one filtering\nproblem under the approximating model. The transition law q\nfor q(z) in (6) becomes a\ncomponent of the approximating model.\n< +, the decision maker trusts the signal dynamics (s|y, z, a)\nbut distrusts q(z). When 2\n< +, the situation is reversed. The two-\nformulation thus allows the decision maker to distinguish his suspicions of these two aspects\nof the model. Before saying more about the two- formulation, the next section explores\nsome ramifications of the special case in which 1\nand how it compares to the single \nspecification that prevails in versions of our decision problem under commitment.\ncase\nFor the purpose of studying intertemporal consistency and other features of the associated\nworst case models, it is interesting to compare the outcomes of recursions (21)-(22) or (23)\nwith the decision rule and worst case model described by Hansen and Sargent (2005) in\nwhich at time 0 the maximizing and minimizing players in a zero-sum game commit to\na sequence of decision rules and a single worst case model, respectively. Because there is\na single robustness parameter  in this \"commitment model\", it is natural to make this\ncomparison for the special case in which 1\n.\nWhen a common value of  appears in the two operators, the sequential application T2T1\ncan be replaced by a single operator:\nT2  T1 U(x, a) + W(y, q) (y, q, a)\n= - log exp -\nU(x, a) + W [(s, y, q, a)]\n\n(s|y, z, a)q(z)d(s)d(z).\nThis operator is the outcome of a portmanteau minimization problem where the minimization\nis over a single relative density (s, z)  0 that satisfies5\n(s, z)(s|y, z, a)q(z)d(s)d(z) = 1,\nwhere  is related to  and  defined in (13) and (16) by\n(s, z) = (z, s|z)(z)q(z)d(z),\nwhere this notation emphasizes that the choice of  can depend on z. The entropy measure\nfor  is\n[log (s, z)](s, z)(s|y, z, a)q(z)d(s)d(z),\nand the minimizing composite distortion  to the joint density of (s, z) given St\nis\nt\n(s, z) =\nexp -U(yt,z,at)+W[(s,yt,qt,at)]\n\nE exp -U(yt,z,at)+W[(st+1,yt,qt,at)]\n\n|St\n6.2 Special case U(x, a) = ^\nU(y, a)\nWhen U(x, a) = ^\nU(y, a), the current period utility drops out of formula (24) for the worst-\ncase distortion to the distribution, and it suffices to integrate with respect to the distribution\n5For comparison, recall that applying T1 and T2 separately amounts to minimizing over separate relative\ndensities  and .\n that we constructed in (5) by averaging  over the distribution of the hidden state. Proba-\nbilities of future signals compounded by the hidden state are simply averaged out using the\nstate density under the benchmark model, a reduction of a compound lottery that would\nnot be possible if different values of  were to occur in the two operators.\nTo understand these claims, we deduce a useful representation of t\n, ht\n):\nmin\nmt+1Mt,htHt\nE ht\nt\n)|St\nt\n(ht\n)\nsubject to E (mt+1\nht\n, where E (gt+1\n|St\n) = 1, a constraint that we impose\nbecause our aim is to distort expectations of St+1\n-measurable random variables given current\ninformation St\n. The minimizer is\nm\n=\nE(gt+1|Xt)\nif E (gt+1\n|Xt\n|Xt\nand h\nt\n|Xt\n) . Therefore, m\nh\nt\nand the minimized value of the objective is\nt\n(m\n, h\nt\n) = E [gt+1\n)|St\n]  ~t\nThus, in distorting continuation values that are St\n-measurable, it suffices to use entropy\nmeasure ~t\ndefined in (25) and to explore distortions to the conditional probability of St+1\n-\nmeasurable events given St\n. This is precisely what the gt+1\nrandom variable accomplishes.\nassociated with T2T1 in the special case in which U(x, a) = ^\nU(y, a) implies a\ndistortion t\nin equation (14) that depends on s alone. The iterated operator T2T1 can be\nregarded as a single risk-sensitivity operator analogous to T1:\nU(y, a) + W(y, q) (y, q, a) (26)\n= ^\nU(y, a) -  log exp -\nW((s, y, q, a))\n\n(s|y, q, a)d(s).\nIn section A.4 of appendix A, we describe how to compute this operator for linear quadratic\nproblems.\n6.3 Comparison with outcomes under commitment\nAmong the outcomes of iterations on the recursions (21)-(22) or (23) of section 5 are time-\ninvariant functions that map (yt\n, qt\n) into a pair of nonnegative random variables (mt+1\n, ht\n).\nFor the moment, ignore the distortion ht\nand focus exclusively on mt+1\n. Through (9), the\ntime-invariant rule for mt+1\ncan be used to a construct a martingale {Mt\n: t  0}. This\nmartingale implies a limiting probability measure on X\nXt\nvia the Kolmogorov\nextension theorem. The implied probability measure on X\nwill typically not be absolutely\ncontinuous over the entire collection of limiting events in X\n. Although the martingale\nconverges almost surely by virtue of Doob's martingale convergence theorem, in the absence\nof this absolute continuity, the limiting random variable will not have unit expectation. This\nmeans that concerns about robustness persist in a way that they don't in a class of robust\ncontrol problems under commitment that are studied, for example, by Whittle (1990) and\n6.3.1 A problem under commitment and absolute continuity\nLet M\nbe a nonnegative random variable that is measurable with respect to X\n, with\n) = 1. For a given action process {at\n: t  0} adapted to {Xt\n: t  0}, let W\n.\n=\n\ntU(xt\n, at\n) subject to (1)-(2). Suppose that  > 0 is such that E exp -1\n\nW\n<\n. Then\n\n(W\n)\n.\n= min\nW\n) + E(M\nlog M\n= - log E exp -\n\nW\nThis static problem has minimizer M\n\n\nW\n)\n\nW\n]\nthat implies a martingale M\nt\n=\nE (M\n\n|Xt\n) .7 Control theory interprets (29) as a risk-sensitive adjustment of the criterion\nW\n(e.g., see Whittle (1990)) and gets decisions that are robust to misspecifications by\nsolving\nmax\n- log E exp -\n\nW\n.\nIn a closely related setting, Whittle (1990) obtained time-varying decision rules for at\nthat\nconverge to ones that ignore concerns about robustness (i.e., those computed with  = +).\nThe dissipation of concerns about robustness in this commitment problem is attributable\nto setting   (0, 1) while using the undiscounted form of entropy in the criterion function\n(28). Those features lead to the existence of a well defined limiting random variable M\nwith expectation unity (conditioned on S0\n), which means that tail events that are assigned\nprobability zero under the approximating model are also assigned probability zero under the\ndistorted model.8\n6The product decomposition (9) of Mt\nimplies an additive decomposition of entropy:\nE (Mt\nlog Mt\n) =\nE [Mj\n|Xj\nSetting E(M0\n) = 1 means that we distort probabilities conditioned on S0\n.\n7See Dupuis and Ellis (1997). While robust control problems are often formulated as deterministic\nproblems, here we follow Petersen, James, and Dupuis (2000) by studying a stochastic version with a relative\nentropy penalty.\n8Because all terms on the right side of (27) are nonnegative, the sequence\nE (mj\nlog mj\n)\nis increasing. Therefore, it has a limit that might be + with positive probability. Thus,\nlimt\nE(Mt\nlog Mt\n) converges. Hansen and Sargent (2005) show that when this limit is finite almost\nsurely, the martingale sequence {Mt\n: t  0} converges in the sense that limt\nE ( |Mt\n- M\nwhere M\nis measurable with respect to X\n.\n= \nXt\n. The limiting random variable M\ncan be used to\n6.3.2 Persistence of robustness concerns without commitment\nIn our recursive formulations (21)-(22) and (23) of section 5, the failure of the worst-case\nnonnegative martingale {Mt\n: t  0} to converge to a limit with expectation one (conditioned\n) implies that the distorted probability distribution on X\nis not absolutely continu-\nous with respect to the probability distribution associated with the approximating model.\nThis feature sustains enduring concerns about robustness and permits time-invariant robust\ndecision rules, in contrast to the outcomes with discounting in Whittle (1990) and Hansen\nand Sargent (2005), for example. For settings with a fully observed state vector, Hansen\nand Sargent (1995) and Hansen, Sargent, Turmuhambetova, and Williams (2004) formulated\nrecursive problems that yielded time-invariant decision rules and enduring concerns about\nrobustness by appropriately discounting entropy. The present paper extends these recursive\nformulations to problems with unobserved states.\n6.4 Dynamic inconsistency of worst-case probabilities about hid-\nden states\nThis section links robust control theory to recursive models of uncertainty aversion by ex-\nploring aspects of the worst case probability models that emerge from the recursions defined\nin section 5. Except in a special case that we describe in subsection 6.6, those recursions\nachieve dynamic consistency of decisions by sacrificing dynamic consistency of beliefs about\nhidden state variables. We briefly explore how this happens. Until we get to the special case\nanalyzed in subsection 6.6, the arguments of this subsection will also apply to the general\ncase in which 1\n.\nt\nt\n, respectively, imply worst-case probability\ndistributions that we express as a pair of Radon-Nikodym derivatives (m\n, h\nt\n). The positive\nrandom variable m\ndistorts the distribution of Xt+1\nconditioned on Xt\nand the positive\nrandom variable h\nt\ndistorts the distribution of events in Xt\nconditioned on St\n. Are these\nprobability distortions consistent with next period's distortion h\n? Not necessarily, because\nwe have not imposed the pertinent consistency condition on these beliefs.\n6.5 A belief consistency condition\nTo deduce a sufficient condition for consistency, recall that the implied {M\n: t  0} should\nbe a martingale. Decompose M\nin two ways:\nM\n= m\nh\nt\nG\nt\n= h\nG\n.\nThese equations involve G\nand G\nt\n, both of which we have ignored in the recursive for-\nmulation of section 5. Taking expectations of m\nh\nt\nG\nt\nG\nconditioned on St+1\nyields\nG\nt\nE m\nh\nt\n= G\n.\nThus,\ng\n= E m\nh\nt\nconstruct a probability measure on X\nthat is absolutely continuous with respect to the probability measure\nassociated with the approximating model. Moreover, Mt\n= E(M\n|Xt\n).\nis the implied multiplicative increment for the candidate martingale {G\nt\n: t  0} adapted\nto the signal filtration. Moreover,\nClaim 6.1. A sufficient condition for the distorted beliefs to be consistent is that the process\n{h\nt\n: t  0} should satisfy:\nh\n=\nm\nh\nt\nE(m\nh\nt\n)\nif E m\nh\nt\nh\nt\nThis condition is necessary if G\nThe robust control problem under commitment analyzed by Hansen and Sargent (2005)\nsatisfies condition (30) by construction: at time 0 a single minimizing player chooses a pair\n(m\n, h\nt\n) that implies next period's h\n. However, in the recursive games defined in the\nrecursions (21)-(22) and (23) in section 5, the date t minimizing agent does not have to\nrespect this constraint. A specification of h\ngives one distortion of the distribution of the\nhidden state (conditioned on St+1\n) and the pair (m\n, h\nt\n) gives another. We do not require\nthat these agree, and, in particular, do not require that the probabilities of events in Xt\nbe\ndistorted in the same ways by the date t determined worst-case distribution (conditioned on\n) and the date t + 1 worst-case distribution (conditioned on St+1\n).\nA conflict can arise between these worst-case distributions because choosing an action is\nnaturally forward-looking, while estimation of z is backward looking. Dynamic inconsistency Reason\nfor\ninconsis-\ntency\nof any kind is a symptom of conflicts among the interests of different decision makers, and\nthat is the case here. The two-player games that define the evaluation of future prospects\n(T1) and estimation of the current position of the system (T2) embody different orientations\n\u00ad T1 looking to the future, T2 focusing on an historical record of signals.\nThe inconsistency of the worst-case beliefs pertains only to the decision maker's opinions\nabout the hidden state. If we ignore hidden states and focus on signals, we can assem-\nble a consistent distorted signal distribution by constructing g\n= E m\nh\nt\nand\nnoting that E g\n|St\n= 1, so that g\nis the implied one-period distortion in the signal\ndistribution. We can construct a distorted probability distribution over events in St+1\nby\nusing\nG\n=\ng\nj\nUnder this interpretation, the pair (m\n, h\nt\n) is only a device to construct g\n. When the\nobjective function U does not depend directly on the hidden state vector z, as is true in many\neconomic problems, the consistent set of distorted probabilities defined by (31) describes the\nevents that directly influence decisions.\n9This consistency condition arguably could be relaxed for the two player game underlying (23). Although\nwe allow mt+1\nto depend on the signal st+1\nand the hidden state zt+1\n, the minimizing solution associated\nwith recursions (23) depends only on the signal st+1\n. Thus we could instead constrain the minimizing agent\nin his or her choice of mt+1\nand introduce a random variable ~\nthat distorts the probability distribution\nconditioned on st+1\nand Xt\n. A weaker modified consistency requirement is that\nh\n=\n~\nm\nh\nt\nE ~\nm\nh\nt\nfor some ~\nwith expectation equal to one conditioned on st+1\nand Xt\n.\n6.6 Discounting and preferences influenced by hidden states are\nthe source of intertemporal inconsistency\nIf  = 1 and if U(x, a) does not depend on the hidden state, we can show that the dis-\ntortions (mt+1\n, ht\n) implied by our recursions satisfy the restriction of Claim 6.1 and so are\ntemporally consistent. Therefore, in this special case, the recursive games imply the same\ndecisions and worst case distortions as the game under commitment analyzed by Hansen\nand Sargent (2005). For simplicity, suppose that we fix an action process {at\n: t  0} and\nfocus exclusively on the assignment of distorted probabilities. Let {Wt\n: t  0} denote the\nprocess of continuation values determined recursively and supported by choices of worst-case\nmodels.\nConsider two operators R1\nt\nt\nwith a common . The operator R1\nt\nimplies a worst-case\ndistribution for Xt+1\nconditioned on Xt\nwith density proportional to:\nm\n=\n\nE exp -Wt+1\n\n|Xt\n.\nThe operator R2\nt\nimplies a worst-case model for the probability of Xt\nconditioned on St\nwith\ndensity:\nh\nt\n=\nE exp -Wt+1\n\n|Xt\nE exp -Wt+1\n\n|St\n.\nCombining the distortions gives\nm\nh\nt\n=\n\nE exp -Wt+1\n\n|St\n.\nTo establish temporal consistency, from Claim 6.1 we must show that\nh\n=\n\nE exp -Wt+1\n\nwhere\nh\n.\n=\nE exp -Wt+2\n\n|Xt\nE exp -Wt+2\n\n|St\n.\nThis relation is true when  = 1 and U does not depend on the hidden state z. To accom-\nmodate  = 1, we shift from an infinite horizon problem to a finite horizon problem with a\nterminal value function. From value recursion (21) and the representation of R1\nexp -\n\n E exp -\n\n,\nwhere the proportionality factor is St+1\nmeasurable. The consistency requirement for h\nis therefore satisfied.\nThe preceding argument isolates the role that discounting plays in delivering the time\ninconsistency of worst case beliefs over the hidden state. Heuristically, the games defined\nby the recursions (21)-(22) or (23) give intertemporal inconsistency when  < 1 because\nthe decision maker discounts both current period returns and current period increments\nto entropy; while in the commitment problem analyzed in Hansen and Sargent (2005), the\ndecision maker discounts current period returns but not current period increments to entropy.\n7 Implied worst case model of signal distortion\nThe martingale (relative to St\n) increment gt+1\nht\n|St\n) distorts the distribution of\nthe date t + 1 signal given information St\ngenerated by current and past signals. For the\nfollowing three reasons, it is interesting to construct an implied g\nfrom the m\nassociated\nt\nor T1 and the h\nt\nassociated with R2\nt\nFirst, actions depend only on signal histories. Hidden states are used either to depict\nthe underlying uncertainty or to help represent preferences. However, agents cannot take\nactions contingent on these hidden states, only on the signal histories.\nSecond, in decentralized economies, asset prices can be characterized by stochastic dis-\ncount factors that equal the intertemporal marginal rates of substitution of unconstrained\ninvestors and that depend on the distorted probabilities that investors use to value contin-\ngent claims. Since contingent claims to consumption can depend only on signal histories\n(and not on hidden states), the distortion to the signal distribution is the twist to asset\npricing that is contributed by investors' concerns about model misspecification. In partic-\nular, under the approximating model, gt+1\nE[gt+1|St]\nbecomes a multiplicative adjustment to the\nordinary stochastic discount factor for a representative agent (e.g., see Hansen, Sargent, and\nTallarini (1999)). It follows that the temporal inconsistency of worst case beliefs discussed\nin section 6.4 does not impede appealing to standard results on the recursive structure of\nasset pricing in settings with complete markets.10\nThird, Anderson, Hansen, and Sargent (2003) found it useful to characterize detection\nprobabilities using relative entropy and an alternative measure of entropy due to Chernoff\n(1952). Chernoff (1952) showed how detection error probabilities for competing models give\na way to measure model discrepancy. Models are close when they are hard to distinguish\nwith historical data. Because signal histories contain all data that are available to a decision\nmaker, the measured entropy from distorting the signal distribution is pertinent for statistical\ndiscrimination. These lead us to measure either E g\nlog g\n|St\nor a Chernoff counterpart\nOur characterizations of worst case models have conditioned implicitly on the current\n11Anderson, Hansen, and Sargent (2003) show a close connection between the market price of risk and\na bound on the error probability for a statistical test for discriminating the approximating model from the\nworst case model.\nperiod action. The implied distortion in the signal density is:\nt\n(z, s)(z, s|yt\n, z, , at\n)t\n(z)qt\n(z)d(z)d(z)\nwhere t\nis given by formula (14) and t\nis given by (17). When a Bellman-Isaacs condition\nis satisfied,12 we can substitute for the control law and construct a conditional worst case\nconditional probability density for st+1\nas a function of the Markov state (yt\n, qt\n). The process\n) : t  0} is Markov under the worst case distribution for the signal evolution.\nThe density qt\nremains a component of the state vector, even though it is not the worst case\ndensity for zt\n.\n8 A recursive multiple priors model\nTo attain a notion of dynamic consistency when the decision maker has multiple models,\nEpstein and Schneider (2003a) and Epstein and Schneider (2003b) advocate a formulation\nthat, when translated into our setting, implies time varying values for 1\n. Epstein\nand Schneider advocate sequential constraints on sets of transition probabilities for signal\ndistributions. To implement their proposal in our context, we can replace our fixed penalty\nparameters 1\nwith two sequences of constraints on relative entropy.\nIn particular, suppose that\nt\nt\nt\nis a positive random variable in Xt\n, and\nt\n(ht\nt\nt\nis a positive random variable in St\n. If these constraints bind, the worst-case\nprobability distributions are again exponentially tilted. We can take 1\nt\nto be the Xt\n-\nmeasurable Lagrange Multiplier on constraint (32), where m\n exp -Wt+1\nt\nt\nt\n(m\nt\n. The counterpart to R1\nt\n) is\nt\n)\n.\n=\nt\n|Xt\nE exp -Wt+1\nt\n|Xt\n.\nSimilarly, let 2\nt\nbe the St\n-measurable Lagrange multiplier on constraint (33), where h\nt\n\nexp - ^\nWt\nt\nt\nt\n(h\nt\nt\n. The counterpart to R2\nt\n( ^\nWt\n) is\nt\n( ^\nWt\n)\n.\n=\nE ^\nWt\nexp - ^\nWt\nt\n|St\nE exp - ^\nWt\nt\n|St\n.\nThese constraint problems lead to natural counterparts to the operators T1 and T2.\n12For example, see Hansen, Sargent, Turmuhambetova, and Williams (2004) or Hansen and Sargent (2004).\nConstraint formulations provide a justification for making 1\nstate- or time-\ndependent. Values of 1\nwould coincide if the two constraints were replaced by a\nsingle entropy constraint E [ht\nt\n)|St\nt\n(ht\n)  t\n, where t\nis St\n-measurable. Lin,\nPan, and Wang (2004) and Maenhout (2004) give other reasons for making the robustness\npenalty parameters state dependent.13 With such state dependence, it can still be useful to\ndisentangle misspecifications of the state dynamics and the distribution of the hidden state\ngiven current information. Using separate values for 1\nachieves that.\n9 Risk sensitivity and compound lotteries\nJacobson (1973) pointed out a link between a concern about robustness, as represented in\nthe first line of (11), and risk sensitivity, as conveyed in the second line of (11). That link has\nbeen exploited in the control theory literature, for example, by Whittle (1990). Our desire\nto separate the concern for misspecifying state dynamics from that for misspecifying the\ndistribution of the state inspires two risk-sensitivity operators. Although our primary interest\nis in representing ways that the decision maker can respond to model misspecification, our\ntwo operators can also be interpreted in terms of enhanced risk aversion.14\n9.1 Risk-sensitive interpretation of R1\nt\nt\noperator has an alternative interpretation as a risk-sensitive adjustment to contin-\nuation values that expresses how a decision maker who has no concern about robustness\nprefers to adjust continuation values for their risk. The literature on risk-sensitive control\nuses adjustments of the same log E exp form that emerge from an entropy penalty and a\nconcern for robustness, as asserted in (11). There are risk adjustments that are more general\nthan those of the log E exp form associated with risk-sensitivity. In particular, we could\nfollow Kreps and Porteus (1978) and Epstein and Zin (1989) in relaxing the assumption that\na temporal compound lottery can be reduced to a simple lottery without regard to how the\nuncertainty is resolved, which would lead us to adjust continuation values by\n~\nt\n)|Xt\n])\nfor some concave increasing function . The risk-sensitive case is the special one in which\n is an exponential function. We focus on the special risk-sensitivity log E exp adjustment\nbecause it allows us to use entropy to interpret the resulting adjustment as a way of inducing\nrobust decision rules.\nt\nand the reduction of compound lotteries\nWhile (17) shows that the operator R2\nt\nassigns a worst-case probability distribution, another\ninterpretation along the lines of Segal (1990), Klibanoff, Marinacci, and Mukerji (2003), and\n13These authors consider problems without hidden states, but their motivation for state dependence would\ncarry over to decision problems with hidden states.\n14Using detection probabilities, Anderson, Hansen, and Sargent (2003) describe senses in which the risk-\nsensitivity and robustness interpretations are and are not observationally equivalent.\nErgin and Gul (2004) is available. This operator adjusts for state risk differently than does\nthe usual Bayesian approach of model averaging. Specifically, we can regard the transforma-\nt\nas a version of what Klibanoff, Marinacci, and Mukerji (2003) call constant ambiguity\naversion. More generally, we could use\n~\nt\n( ^\nWt\n) = -1E ( ^\nWt\n)|St\nfor some concave increasing function . Again, we use the particular `log E exp' adjustment\nbecause of its explicit link to entropy-based robustness.\n10 Linear quadratic problems\nFor a class of problems in which U is quadratic and the transition laws (1), (3), (2) are\nlinear, this section describes how to use deterministic linear quadratic control problems to\ncompute T1, T2, and T2  T1. We consign details to appendix A. We begin with a remark\nthat allows us to simplify the calculations by exploiting a type of certainty equivalence.\n10.1 A useful form of certainty equivalence\nWe display the key idea in the following pair of problems that allow us easily to compute\nthe T1 operator. Problem 10.1 is a deterministic one-period control problem that recovers\nthe objects needed to compute the T1 operator defined in problem 10.2.\nProblem 10.1. Consider a quadratic value function V (x) = -1\nx x - , where  is a\npositive definite matrix. Consider the control problem\nmin\nv\nV (x) +\n\nsubject to a linear transition function x = Ax + Cv. If  is large enough that I - -1C C\nis positive definite, the problem is well posed and has solution\nThe following problem uses (34) and (35) to compute the T1 operator:\nProblem 10.2. Consider the same value function V (x) = -1\nbut now let the transition law be\nx = Ax + Cw\nwhere w  N(0, I). Consider the problem associated with the T1 operator:\nmin\nm\nE[mV (x) + m log m].\nThe minimizer is\nm  exp\n-V (x)\n\n= exp -\n(w - v) -1(w - v) +\nw \u00b7 w -\nlog det \nm is\nEm log m =\n|v|2 + trace( - I) - log det  .\nThus, we can compute T1 by solving the deterministic problem 10.1. We can also com-\npute the T2 and T2  T1 operators by solving appropriate deterministic control problems.\nIn appendix A, we exploit certainty equivalence to compute these operators for the linear\nquadratic problem that we describe next.\n10.2 The linear quadratic problem\nThis section specializes the general setup of section 2 by specifying a quadratic return func-\ntion and a linear transition law. The return function or one period utility function is\nU(xt\n, at\n) = -\nat\nxt\nat\nxt\n.\nThe transition laws are the following specializations of (1), (2), and (3):\n= s\n+ y\nyt\n+ a\nat\nyt\nzt\nat\nyt\nzt\n+ Hat\nwhere wt+1\n N(0, I) is an i.i.d. Gaussian vector process. Substituting from the evolution\nequation for the signal (36), we obtain:\n= (s\n+ y\n)yt\n+ s\nzt\n+ (s\nH + a\n)at\n+ s\n,\nwhich gives the y-rows in the following state-space system:\n= Axt\n+ Bat\n= Dxt\n+ Hat\n.\n= s\n+ y\n.\n= s\n.\n= s\nH + a\n.\n= s\nG.\nApplying the Kalman filter to model (37) gives the following counterpart to (2), (4),\n(s|y, z, a), and (6):\nx = Ax + Ba + Cw (38)\n\n\n()(s - \nwhere w is a standard normal random vector, K2\n() is the Kalman gain\nthe innovation s - \n(z - \nz) + Gw, and \ns is the expectation of s conditioned\nand the history of the signal. Equation (38) is the counterpart of (2), (4), while\nequations (39)-(40) form the counterpart to the law of motion for (sufficient statistics for)\nthe posterior, q = q\n(s, y, q, a). Under the approximating model, the hidden state z is\na normally distributed random vector with mean \nz and covariance matrix . Equations\n(39) and describe the evolutions of the mean and covariance matrix of the hidden state,\nrespectively.\n10.3 Differences from situation under commitment\nBy not imposing distortions to \nz and  on the right side of (39), the decision maker disregards\nprior distortions to the distribution of z. By way of contrast, in the commitment problem\nanalyzed in Hansen and Sargent (2005), distortions to \nz and  are present that reflect\nhow past states and actions altered the worst case probability distribution for z.15 Unlike\nthe setting with commitment, in the present setup without commitment, (\nz, ) from the\nordinary Kalman filter are state variables, just as in the standard linear quadratic control\nproblem without a concern for robustness.\nThe decision maker explores perturbations to the conditional distributions of w and z.\nLetting the altered distribution of w depend on the hidden state z allows for misspecification\nof the hidden state dynamics. Directly perturbing the conditional distribution of z is a\nconvenient way to explore robustness to the filtered estimate of the hidden state associated\nwith the approximating model. We perturb the distribution of w by applying the T1\noperator and the distribution of z by applying the T2 operator. Section A.2 of appendix A\nexploits the certainty equivalence ideas conveyed in problem 10.1 to compute the T2 T1 and\nT1 operators for the recursions (21)-(22). Section A.3 describes how to compute the T2  T1\noperator of section 4 for formulating the game defined by the recursions (23) of section 5.\nThe games in sections A.2 and A.3 allow 1\n. Section A.4 describes how to compute the\ncomposite operator (26) of section 6.2. The associated game requires that 1\n.\n11 Concluding remarks\nFor a finite 1\n, the operator T1 captures the decision maker's fear that the state and signal\ndynamics conditioned on both observed and hidden components of the state are misspecified.\nFor a finite 2\n, the operator T2 captures the decision maker's fear that the distribution of the\nhidden state conditioned on the history of signals is misspecified. Using different values of 1\nin the operators T1 and T2 gives us the freedom to focus distrust on different aspects\n15Hansen and Sargent (2005) also analyze a linear quadratic problem under commitment.\nof the decision maker's model. That will be especially useful extensions of our framework to\ncontinuous time settings.\nSpecifications with 1\nemerge when we follow Hansen and Sargent (2005) by adopting\na timing protocol that requires the malevolent agent to commit to a worst case model {Mt+1\n}\nonce and for all at time 0. Hansen and Sargent (2005) give a recursive representation for the\nsolution of the commitment problem in terms of R1\nt\nt\noperators with a common but\ntime-varying multiplier equal to \nt\n. The presence of t causes the decision maker's concerns\nabout misspecification to vanish for tail events. Only for the undiscounted case does the\nzero-sum two player game with commitment in Hansen and Sargent (2005) give identical\noutcomes to the recursive games in this paper. As noted in section 6.6, when  < 1, the gap\nbetween the outcomes with and without commitment is the source of time-inconsistency of\nthe worst case beliefs about the hidden state.\nMuch of the control theory literature (e.g., Whittle (1990) and Basar and Bernhard\n(1995)) uses the commitment timing protocol. Hansen and Sargent (2005) show how to\nrepresent parts of that literature in terms of our formulation of model perturbations as\nmartingales.\nA Computations for LQ problems\nA.1 Three games\nWe use the certainty equivalence insight from subsection 10.1 to solve three games. The key\nstep in each is to formulate an appropriate linear quadratic discounted dynamic programming\nproblem. Game I enables us to compute the T2  T1 and the T1 operators required by\nrecursions (21)-(22). Game II formulates a linear regulator that we use to compute the\nrecursions in formulation (23). Game III formulates a recursion for the operator (26) that\nis pertinent when 1\n.\nA.2 Game I\nThis subsection shows how to apply the certainty equivalent insight from section 10.1 to com-\npute the recursions (21)-(22) (i.e., \"maximize after applying T2 T1, but update by applying\nT1\") for the linear quadratic case. In game I, a decision maker chooses a after first applying\nT2  T1 to the sum of the current return function and a discounted continuation value. This\nmakes a depend on y and the estimate of the hidden state \nz, but not on z. However, by\nupdating the value function using T1 only, we make the continuation value function depend\non the hidden state z. We adopt the convention that we discount the continuation value\nfunction and then add to it the current return function and the undiscounted penalties on\nthe two entropies.\nRewrite evolution equation (38) - (39) as\n\n\ny\nz\n\nz\n\n =\n\n\n\n\n\n\ny\nz\n\nz\n\n +\n\n\n\n a +\n\n\n()G\n\n w\n=\n\n\n\n y\n\nz\n+\n\n\n\n a\nz - \nz\n+\n\n\n()G\n\nUnder the approximating model, w is a multivariate standard normal random vector and\nz - \nz is distributed as a normal random vector with mean zero and covariance matrix .\nThe logic expressed in (11) and (15) that define R1\nt\nt\nshows that application of T2 T1 to\na function amounts to minimizing another function with respect to the distributions of z and\nw. We shall exploit this logic and calculate T2  T1 by solving the corresponding minimiza-\ntion problem. In the present linear-quadratic-Gaussian case, we can exploit the certainty\nequivalence property from section 10.1 and minimize first over the conditional means of\nthese two distributions, then construct the minimizing conditional covariances later, thereby\nexploiting the idea in problem 10.2. Because a Bellman-Isaacs condition is satisfied, the\nlinear-quadratic-Gaussian structure allows us simultaneously to perform the maximization\nover a and the minimization over the distorted means of z and w associated with the T2 T1\noperator. We do this by forming a zero-sum two-player game that simultaneously chooses\nthe decision a, a distortion u to the mean of z - \nz, and a distortion ~\nv to a conditional mean\nof w, all as functions of y, \nz. Here ~\nv can be interpreted as the mean of v conditioned on y, \nz.\n(In section A.2.2, we shall compute a vector v that is the distorted mean of w conditioned\non y, \nThus, we consider the transition equation:\n\n\ny\nz\n\nz\n\n =\n\n\n\n y\n\nz\n+\n\n\n\n a\nu\n+\n\n\n()G\n\n ~\nv\nWrite the single period objective as:\n-\na y z\n\n\n\n\n\n\na\ny\nz\n\n +\n|~\na u ~\nv y \nz ()\n\n\n\n\n\n\na\nu\n~\nv\ny\n\nz\n\n\n\n\n\n\nwhere\n() =\n\n\n\n\n\n\n\n\n\n\n\n\nConstruct a composite action vector:\n~\na =\n\n\na\nu\n~\nv\n\nand composite state vector\n~\nx =\ny\n\nz\n\ny\nz\n\nz\n\n = ~\nA~\nx + ~\nB()~\na,\nand the single period objective as\n-\n~\na ~\nx\n~\na\n~\nx\n,\nand write the discounted next period value function as\nV (y, z, \nz, ) = -\n\ny z \nz ()\n\n\ny\nz\n\nz\n\n - ().\n16Note that T1 makes v depend on y, z, \nz, and that application of T2 then conditions down to y, \nz, in effect\nrecovering the mean of v conditional on (y, \nz).\nThen pose the problem17\nmax\na\nmin\nu,~\nv\n-\n~\na ~\nx\n~\na\n~\nx\n+ V (y, z, \nThe composite decision rule is\n~\n() +  ~\nB() () ~\nB()\n+  ~\nB() () ~\nA ~\nx.\nUsing the law of motion from the Kalman filter\nto express  in terms of , the composite decision rule can be expressed as\n\n\na\nu\n~\nv\n\n .\n= - ~\nF()\n\n\ny\nz\n\nz\n\n = -\n\n\n~\n()\n~\n()\n~\n()\n\n\n\n\ny\nz\n\nz\n\nwhich looks like the decision rule for an optimal linear regulator problem. The robust\ncontrol law for the action is given by the first block in (46). In the second line, we have\nadded z, which at this stage is a superfluous component of the state vector, so that the\ncorresponding columns of ~\nF() are identically zero; ~\na is by construction a function of (y, \nz).\nThis superfluous state variable will be useful in section A.2.2 when we compute a continuation\nvalue function that depends on (y, z, \nz).\nTo make the extremization in (45) well posed, we require that 1\nbe large enough to\nsatisfy the `no-breakdown' condition that\nI\n- \n()\n()\n()\n\n\n()G\n\n\nis positive definite. Otherwise, the parameter pair (1\n) is not admissible. This is a\nbivariate counterpart to a check for a no-breakdown condition that occurs in robust control\ntheory. When the no-breakdown condition is violated, the minimizing agent can make the\nobjective equal to -.\nA.2.2 T1 and the worst case E[w|y, z, \nz]\nIt remains for us to compute the distortion to the mean of w conditional on y, z, \nz that\nemerges from applying the T1 operator to a continuation value. The T1 operator allows a\nminimizing agent to exploit his information advantage over the maximizing agent by let-\nting the mean distortion in w depend on z, the part of the state that is hidden from the\nmaximizing agent.\n17Note here how we discount the continuation value function, then add the current return and the penalized\nentropies.\nTaking the control law for a computed in (46) as given, we can compute the mean v of\nthe worst case w conditional on y, z, \nz by using the evolution equation (41):\n\n\ny\nz\n\nz\n\n =\n\n\n\n\n\n\ny\nz\n\nz\n\n -\n\n\n\n ~\n()\n\n\ny\nz\n\nz\n\n +\n\n\n()G\n\n v\n= \u00af\nA()\n\n\ny\nz\n\nz\n\n + \u00af\nC()v.\nAfter substituting the decision rule for a from (46), we can write the objective as\n-\na y z\n\n\n\n\n\n\na\ny\nz\n\n +\ny z \nz \u00af\n()\n\n\ny\nz\n\nz\n\n +\nwhere\n\u00af\n()\n.\n=\n\n\n\n\n- ~\n()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n- ~\n()\n\n\n\n .\nProvided that\nI -  \u00af\nC() () \u00af\nis positive definite, the control law for v is18\nI -  \u00af\nC() () \u00af\nC() () \u00af\nA\n\n\ny\nz\n\nz\n\nwhich, by using (40) to express  as a function of , we can express as\nv = \u00af\nF()\n\n\ny\nz\n\nz\n\n .\nThe updated value function is\n() = \u00af\n() +  \u00af\nA () \u00af\nA\nA () \u00af\nI -  \u00af\nC() () \u00af\nC() () \u00af\nAt first sight, these recursions seem difficult because they call for updating the matrix\nvalued functions  for all hypothetical values of the definite matrix . Fortunately, it\nsuffices to perform these calculations only for a sequence of 's calculated over the horizon\nof interest, which is easy. Given a sequence of 's starting from an initial condition, the\n's for the value functions can be computed starting from a terminal value using backward\ninduction. In particular, we can first compute a sequence of matrices  using forward\ninduction on (40), then compute a corresponding () sequence using backward induction\non (49). Both forward and backward recursions are Riccati equations.\n18If the matrix defined in (47) is not positive definite, then 1\nis below the break-down point.\nA.2.3 Worst case shock distribution\nThe worst case distribution for w conditioned on (y, z, \nz) is normal with mean v given by\n()\n.\n= I -\n\n\u00af\nC () \u00af\nC\n.\nA.2.4 Worst case hidden state distribution\nThe worst case mean of z conditional on (y, \nz) is\nu = - ~\n()\n\n\ny\nz\n\nz\n\n ,\n(recall that ~\ncontains zeros in the columns that multiply z), and its covariance matrix is:\n()\n.\n=\n\n-\n\n\nI\n\n\n\n\n,\nprovided that this matrix is positive definite. Otherwise, 2\nis below its breakdown point.\nA.2.5 Consistency check\nThe third row of (46) computes the mean ~\nv of w, conditional on the information set available\nto the maximizing agent, namely, (y, \nz), but not z. In formula (48), we computed the mean\nv of w conditional on the information set of the minimizing agent, namely, (y, z, \nz). A\ncertainty equivalence result asserts that ~\nv is the expectation of v conditioned on (y, \nz). This\ngives us the following consistency check.\nOne formula for ~\nv is computed by using the control law of v and substituting for the\ndistorted expectation for z:\n~\nv = \u00af\nF()\n\n\ny\n\nz - ~\n()y - ~\n()\nz\n\nz\n\n = \u00af\nF()\n\n\n- ~\n() I - ~\n()\n\n y\n\nz\n.\nUsing certainty equivalence, we computed ~\nv = - ~\ny\n^\nz\n. Taken together, we have the re-\nstriction\n- ~\n() ~\n() = \u00af\nF()\n\n\n- ~\n() I - ~\n()\n\n .\nA.2.6 Worst case signal distribution\nIn this section, we recursively construct the distribution of signals under the distorted prob-\nability distribution. Recall the signal evolution:\ns = Dx + Ha + Gw.\nUnder the approximating model, the signal next period is normal with mean\n\n\nz + Ha\nand covariance matrix\n\n+ GG .\nThe distorted mean of the signal conditioned on the signal history is:\n\u00af\n\nu + G~\nv) + Ha\nwhich by virtue of the second and third blocks of rows of (46) can be written\n\u00af\ns = \u00af\n()y + \u00af\n()\nwhere\n\u00af\n()\n.\n~\n() - G ~\n()\n\u00af\n()\n.\n~\n() - G ~\n().\nThe distorted covariance matrix is:\n\u00af\n+ G()G .\nThe relative entropy of this distortion conditioned on the reduced information set of the\nsignal history is\n(\u00af\ns - \ns) \ns - \ns) + trace(\n - I) - logdet\u00af\n + logdet\nTo construct the distorted dynamics for y, start from the formula for y from the first\nblock in (36), namely, y = s\ns + y\ny + a\na. Substituting for the robust decision rule for\na from the first block of row of (46) and replacing s with with \u00af\ns + (s - \u00af\ny = [y\ny+s\n\u00af\n()-(s\nH +a\n) ~\n()]y+[s\n\u00af\n()-(s\nH +a\n) ~\n()]\nz+s\n(s -\u00af\ns).\nTo complete a recursive representation for y under the worst case distribution, we need\na formula for updating \nz under the worst case distribution. Recall the formula for \nz under\nthe approximating model from the Kalman filter (39) or (41):\n\n~\n~\n()]\n\nz - Ha)\nor\n\n~\n~\n()]\n()(s - \ns).\nUsing the identity\ns - \ns = (s - \u00af\ns) + (\u00af\ns - \ns)\n= (s - \u00af\ns) + [ \u00af\n]y + [ \u00af\n]\nz\nin the above equation gives:\n\n~\n()[ \u00af\n] y\n~\n()[ \u00af\n] \n()(s - \u00af\nTaken together, (52) and (53) show how to construct \nz from the signal history under the\ndistorted law of motion. The innovation s - \u00af\ns under the distorted model is normal with\nmean zero and covariance matrix \u00af\n.\nA.3 Game II\nWe now turn to the linear quadratic version of a game associated with the recursion (23)\ndescribed in section 5.2, in which we update the value function using T2  T1. We exploit\nour certainty equivalence insights from section 10.1. Like Game I, this game allows 1\n.\nHere we do not need to keep track of the evolution of z. Instead it suffices to focus only on\nthe two equation system:\ny\n\nz\n=\ny\n\nz\n+\n(z - \nz) +\na +\n()G\nAs in Game I, we need to choose the mean distortion u for z - \nz, and the mean distortion\nv for w, where both means distortions are conditioned on (y, \nz).\nA.3.1 Computing a, u, and ~\nv\nWe apply the same argument as for Game I, but to a smaller state vector. Thus, we work\nwith the evolution equation\ny\n\nz\n=\ny\n\nz\n+\nu +\na +\n~\nv\nor\n~\nx = ~\nAx + ~\nB()~\na,\nwhere ~\nx and ~\nx is the next period's value of ~\nx. The\nmatrices A and ~\nB differ from those in Game I because z is not included in ~\nx.\nPartition blocks of the matrix () defined in (42) as\nconformably with ~\na, ~\nx,\nso that the (1, 1) block pertains to ~\na, the (2, 2) block to ~\nx, and so on. Write the discounted\nnext period value function as\nV (~\nx) = -\n\n(~\nx) ()~\nx - ().\nThen the composite robust control is:\n~\n() +  ~\nB() () ~\nB()\n+  ~\nB() () ~\nA ~\nx\n.\n= -\n\n\n~\n()\n~\n()\n~\n()\n\n ~\nwhere - ~\n()~\nx is the control law for a, - ~\n()~\nx is the control law for the mean u of the\ndistorted distribution for z - \nz, and - ~\n()~\nx is the control law for ~\nv, the mean of the\ndistorted distribution for w conditional on (y, \nz).\nFor the extremization problem to be well posed, we require that (1\n) be large enough\nthat\nI\n- \n()\n()\n()\n()G\nis positive definite.\nThe value function recursion is the Riccati equation:\n+  ~\nA() () ~\n+  ~\nB() () ~\nA\n() +  ~\nB() () ~\nB()\n+  ~\nB() () ~\nA .\nThis recursion computes a matrix in the quadratic form that emerges from applying the\ncomposite T2  T1 operator.\nA.3.2 Worst case distribution for w conditional on (y, \nz, z)\nWe now compute the mean v of the distorted distribution for w that emerges from applying\nthe T1 operator alone to the continuation value. The mean distortion v depends on the\nhidden state z, as well as on (y, \nz). To prepare the minimization problem that we use to\ncompute T1, first impose the control law for a in evolution equation (54):\ny\n\nz\n= ~\nA\ny\n\nz\n-\n~\n()\ny\n\nz\n+\n(z - \nz) +\n()G\nw\n= \u00af\nA()\ny\n\nz\n+ \u00af\nH()(z - \nz) + \u00af\nThe following certainty-equivalent problem recovers the feedback law for v associated\nmin\nv\n-\n\ny \nz ()\ny\n\nz\n+\nv v\nwhere the minimization is subject to (57) with v replacing w. The minimizing v, which is\nthe worst case mean of w conditional on (y, \nz, z), is\nI -  \u00af\nC() () \u00af\nC() () \u00af\nA\ny\n\nz\n+ \u00af\nH()(z - \nz)\n= - \u00af\n()(z - \nz) - \u00af\n()\ny\n\nz\n= - \u00af\nF()\n\n\nz - \nz\ny\n\nz\n\n .\nConditional on (y, \nz, z), the covariance matrix of the worst case w is\n() = I -\n\n\u00af\nC() () \u00af\nC()\nwhich is positive definite whenever the breakdown condition (56) is met.\nNext, we want to compute the matrix \u00af\n() in the quadratic form in (z - \nz) y \nz\nthat emerges from applying the T1 operator. First, adjust the objective for the choice of v by\nconstructing a matrix \u00af\n(), with row and column dimension both equal to the dimension\nof (z - \nz) y \nz , that we now redefine as:19\n\u00af\n() =\n\n\n\n\n()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n()\n\n\n\n .\nThe matrix in the quadratic form in (z - \nz) y \nz for the minimized objective function\nthat emerges from applying the T1 operator is:\n\u00af\n() = \u00af\n() + \n\u00af\nH()\n\u00af\nA()\n() \u00af\nH() \u00af\nA() +\n\u00af\nH()\n\u00af\nA()\n() \u00af\nI -  \u00af\nC() () \u00af\nC() () \u00af\nH() \u00af\nA() .\nA.3.3 Worst case distribution for z - \nz: N(u, ())\nKnowing \u00af\n() allows us to deduce the worst case distribution for z - \nz conditional on (y, \nz)\nin another way, thereby establishing a useful cross check on formula (55). Use the partition:\n\u00af\n() =\n\u00af\n() \u00af\n()\n\u00af\n() \u00af\n()\nwhere \u00af\n() has the same dimension as z - \nz and \u00af\n() has the same dimension as\ny\n\nz\n.\nThe covariance matrix of z - \nz is\n() = -\n\u00af\n()\n19Note that we are recycling and changing notation from section A.2.\nwhich is positive definite when (1\n) satisfies the no-breakdown restriction (56). The mean\nof the distorted distribution of z - \nz is\nu = - \u00af\n()\ny\n\nz\n.\nComputing u at this stage serves as a consistency check because it was already computed;\nit must be true that\n~\n() = \u00af\n().\nGiven this choice of u, a second consistency check compares the formula for ~\nv to the formulas\nfor v and u; ~\nv is a distorted expectation of v conditioned on y and \nz. Thus,\n~\n() = \u00af\nF()\n- ~\n()\nI\n.\nA.3.4 Worst case signal distribution\nThe mean of the distorted signal distribution given the signal history for Game II is\n\u00af\ns = D - D2\n~\n() - G ~\n() ~\nx,\nand the distorted covariance matrix is:\n\u00af\n+ G()G\nwith the Game II versions of () and () given by (58) and (59), respectively. The\nreduced information measure of entropy is given again by formula (51). The worst case\nevolution for y and \nz expressed in terms of s - \u00af\ns is constructed as in Game I in formulas\n(52) and (53), but using the Game II control law ~\nfor a.\nA.4 Game III\nGame III applies our certainty equivalence insight from section 10.1 to compute iterations\non (26). This game assumes that 1\n, presumes that the period objective function does\nnot depend on the hidden state, and works entirely with the reduced information set y, \nz.\nThe evolution of the baseline model is:\ny\n\nz\n=\ny\n\nz\n+\na +\n()G\nw +\n(z - \nz).\nUnder the benchmark model, the composite shock\n()G\nw +\n(z - \nis a normally distributed random vector with mean zero and covariance matrix\n()\n.\n=\n()\n()\nwhich can be factored as\n() = ~\nC() ~\nC()\nwhere ~\nC() has the same number of columns as the rank of (). This factorization can\nbe accomplished by first computing a spectral decomposition:\n() = U()V ()U()\nwhere U() is an orthonormal matrix and V () is a diagonal matrix with nonnegative\nentries on the diagonal. Partition V () by filling out its upper diagonal block with zeros:\nV () =\n()\n.\nThe diagonal entries of V2\n() are presumed to be strictly positive, implying that V2\n() has\nthe same dimension as the rank of (). Partition U() conformably:\n() .\nThe matrix ~\nC() is then\n~\nFinally, let\n~\nC() =\n~\n()\n~\n()\nwhere ~\n() has as many rows as there are entries in y and ~\n() has as many entries as \nz.\nWe solve this game by simultaneously distorting the distribution of the composite shock\ndefined in (60) instead of separately distorting the distributions of the components w and\n(z - \nz) of the composite shock. With this modification, we can solve the robust control\nproblem as if there were no hidden Markov states. Let ~\nC()~\nu denote the mean of the\naggregate shock defined in (60). Write the single period objective as:\n-\na y\na\ny\n+\n\n~\nu ~\nu = -\na ~\nu y \nz ()\n\n\n\n\na\n~\nu\ny\n\nz\n\n\n\n\nwhere\n() =\n\n\n\n\n\n\n\n .\nForm an augmented control:\n~\na =\na\n~\nu\nand an augmented state:\n~\nx =\ny\n\nz\n.\nWrite the state evolution as:\n~\nx = ~\nA~\nx + ~\nB()~\na\nwhere\n~\nB()\n.\n=\n~\n()\n~\n()\n.\nWrite the discounted next period value function as\nV (~\nx) = -\n\n(~\nx) ()~\nx - ().\nThen the composite robust control is:\n~\n() +  ~\nB() () ~\nB()\n+  ~\nB() () ~\nA ~\nx\n.\n= -\n~\n()\n~\n()\n~\nx\nwhere - ~\n()~\nx is the control law for a and - ~\n()~\nx is the control law for u.\nFor the minimization part of the problem to be well posed, we require that  be large\nenough that\nI -  ~\nC() () ~\nC()\nis positive definite. The value function recursion is the Riccati equation:\n() = ~\n+  ~\nA() () ~\nA()\n+  ~\nB() () ~\n() +  ~\nB() () ~\nB()\n+  ~\nB() () ~\nA .\nThe worst case covariance matrix for the composite shock is\n~\nC() I -\n\n\n~\nC() () ~\nC()\n~\nC() ,\nwhich is typically singular but larger than ().\nReferences\nAnderson, E., L. Hansen, and T. Sargent (2003). A quartet of semigroups for model\nspecification, robustness, prices of risk, and model detection. Journal of the European\nBasar, T. and P. Bernhard (1995). H-Optimal Control and Related Minimax Design\nProblems (second ed.). Birkhauser.\nBergemann, D. and J. Valimaki (1996). Learning and strategic pricing. Econometrica 64,\nChernoff, H. (1952). A measure of asymptotic efficiency for tests of a hypothesis based on\nCogley, T., R. Colacito, L. Hansen, and T. Sargent (2005). Robustness and u.s. monetary\npolicy experimentation. unpublished.\nCogley, T., R. Colacito, and T. Sargent (2005). Benefits from u.s. monetary policy exper-\nimentation in the days of samuelson and solow and lucas. unpublished.\nDupuis, P. and R. S. Ellis (1997). A Weak Convergence Approach to the Theory of Large\nDeviations. Wiley Series in Probability and Statistics. New York: John Wiley and\nSons.\nElliott, R. J., L. Aggoun, and J. B. Moore (1995). Hidden Markov Models: Estimation\nand Control. New York: Springer-Verlag.\nEpstein, L. and M. Schneider (2003a, November). Independently and indistinguishably\nEpstein, L. and M. Schneider (2003b, November). Recursive multiple priors. Journal of\nEpstein, L. and S. Zin (1989). Substitution, risk aversion and the temporal behavior of\nconsumption and asset returns: A theoretical framework. Econometrica 57, 937\u00ad969.\nErgin, H. and F. Gul (2004). A subjective theory of compound lotteries. unpublished.\nHansen, L. P. and T. Sargent (1995, May). Discounted linear exponential quadratic\nHansen, L. P., T. Sargent, and T. Tallarini (1999). Robust permanent income and pricing.\nHansen, L. P. and T. J. Sargent (2004). Misspecification in recursive macroecononmic\ntheory. Princeton University Press, forthcoming.\nHansen, L. P. and T. J. Sargent (2005). Robust estimation and control under commitment.\nunpublished.\nHansen, L. P., T. J. Sargent, G. A. Turmuhambetova, and N. Williams (2004). Robust\ncontrol, min-max expected utility, and model misspecification. manuscript, University\nof Chicago and New York University.\nJacobson, D. H. (1973). Optimal stochastic linear systems with exponential performance\ncriteria and their relation to deterministic differential games. IEEE Transactions for\nJohnsen, T. H. and J. B. Donaldson (1985). The structure of intertemporal preferences\nJovanovic, B. (1979). Job matching and the theory of turnover. Journal of Political Econ-\nJovanovic, B. (1982, May). Selection and the evolution of industry. Econometrica 50(3),\nJovanovic, B. and Y. Nyarko (1995). The transfer of human capital. Journal of Economic\nJovanovic, B. and Y. Nyarko (1996, November). Learning by doing and the choice of\nKlibanoff, P., M. Marinacci, and S. Mukerji (2003). A smooth model of decision making\nunder ambiguity. Northwestern University.\nKreps, D. M. and E. L. Porteus (1978). Temporal resolution of uncertainty and dynamic\nLin, J., J. Pan, and T. Wang (2004). An equilibrium model for rare-event premia and its\nimplication for option pricing. Review of Financial Studies forthcoming.\nMaenhout, P. J. (2004). Robust portfolio rules and asset pricing. Review of Financial\nStudies forthcoming.\nPetersen, I. R., M. R. James, and P. Dupuis (2000). Minimax optimal control of stochastic\nuncertain systems with relative entropy constraints. IEEE Transactions on Automatic\nWhittle, P. (1990). Risk-Sensitive Optimal Control. New York: John Wiley & Sons.\nWonham, W. J. (1964). Some applications of stochastic differential equations to optimal\nThe following Discussion Papers have been published since 2004:\nSeries 1: Economic Studies\n1 2004 Foreign Bank Entry into Emerging Economies:\nAn Empirical Assessment of the Determinants\nand Risks Predicated on German FDI Data Torsten Wezel\n2 2004 Does Co-Financing by Multilateral Development\nBanks Increase \"Risky\" Direct Investment in\nEmerging Markets? \u00ad\nEvidence for German Banking FDI Torsten Wezel\n3 2004 Policy Instrument Choice and Non-Coordinated Giovanni Lombardo\nMonetary Policy in Interdependent Economies Alan Sutherland\nin an Asymmetric Currency Area Giovanni Lombardo\n5 2004 FDI versus cross-border financial services: Claudia M. Buch\nThe globalisation of German banks Alexander Lipponer\n6 2004 Clustering or competition? The foreign Claudia M. Buch\ninvestment behaviour of German banks Alexander Lipponer\n7 2004 PPP: a Disaggregated View Christoph Fischer\n8 2004 A rental-equivalence index for owner-occupied Claudia Kurz\n9 2004 The Inventory Cycle of the German Economy Thomas A. Knetsch\nUsing Data from the Ifo Business Survey Thomas A. Knetsch\nin Germany J\u00f6rg D\u00f6pke\nto Germany \u00ad a Structural Factor Approach Sandra Eickmeier\n13 2004 Consumption Smoothing Across States and Time: George M.\nInternational Insurance vs. Foreign Loans von Furstenberg\nin Japan and its Usefulness for\nInflation Forecasting and Policymaking Koichiro Kamada\nCurrency Union in Case of Member Countries\nof Different Sizes and Output Persistence Rainer Frey\nEvidence from privately-held firms Alexander Ljungqvist\nA comparative analysis of the explanatory power\nof accounting and patent information for the Fred Ramb\nmarket values of German firms Markus Reitzig\n18 2004 The Economic Impact of Venture Capital Astrid Romain, Bruno\nvan Pottelsberghe\n19 2004 The Determinants of Venture Capital: Astrid Romain, Bruno\nAdditional Evidence van Pottelsberghe\nspeed of adaption: Are innovators special? Ulf von Kalckreuth\nTheory and results for Germany and other Michael Scharnagl\nOECD countries Karl-Heinz T\u00f6dter\n22 2004 Asset Prices in Taylor Rules: Specification, Pierre L. Siklos\nEstimation, and Policy Implications for the Thomas Werner\nECB Martin T. Bohl\nCycles: The Experience of Countries in L\u00facio Vinhas\nthe Baltics and Central Eastern Europe de Souza\nMonetary Policy and the Dynamics of\nthe Term Structure of Interest Rates Ralf Fendel\n25 2004 How the Bundesbank really conducted Christina Gerberding\nmonetary policy: An analysis based on Andreas Worms\nreal-time data Franz Seitz\n26 2004 Real-time Data for Norway: T. Bernhardsen, \u00d8. Eitrheim,\nChallenges for Monetary Policy A.S. Jore, \u00d8. R\u00f8island\nForecast Consumer Spending in Real Time? Dean Croushore\n28 2004 The use of real time information in Maritta Paloviita\nPhillips curve relationships for the euro area David Mayes\n29 2004 The reliability of Canadian output Jean-Philippe Cayen\ngap estimates Simon van Norden\n30 2004 Forecast quality and simple instrument rules - Heinz Gl\u00fcck\na real-time data approach Stefan P. Schleicher\nforward-looking monetary policy: Thomas J. Jordan\nThe Swiss case Carlos Lenz\nMarcel R. Savioz\n32 2004 Estimating Equilibrium Real Interest Rates Todd E. Clark\nin Real Time Sharon Kozicki\nEvidence from panel data analysis Karsten Ruth\nDevelopment to Asymmetric Growth of\nManufacturing Industries: George M.\nCommon Claims vs. Evidence for Poland von Furstenberg\nstochastic general equilibrium model Jana Kremer\n36 2004 Inflation and core money growth in the Manfred J.M. Neumann\neuro area Claus Greiber\n37 2004 Taylor rules for the euro area: the issue Dieter Gerdesmeier\nof real-time data Barbara Roffia\nEmpirical evidence on creative accounting J\u00fcrgen von Hagen\nwith fiscal rules in the EU Guntram B. Wolff\nin different financial systems Marcel Tyrell\n40 2004 Expected budget deficits and interest rate swap Kirsten Heppke-Falk\nspreads - Evidence for France, Germany and Italy Felix H\u00fcfner\nbased on autoregressions with a\nMarkov-switching intercept Malte Kn\u00fcppel\n1 2005 Financial constraints and capacity adjustment\nin the United Kingdom \u00ad Evidence from a Ulf von Kalckreuth\nlarge panel of survey data Emma Murphy\nfactors in the euro area analyzed in a\nlarge-scale factor model Sandra Eickmeier\n3 2005 Financial intermediaries, markets, F. Fecht, K. Huang,\nand growth A. Martin\nin Europe: does it fit or does it fail? Peter Tillmann\n5 2005 Taxes and the financial structure Fred Ramb\nof German inward FDI A. J. Weichenrieder\n6 2005 International diversification at home Fang Cai\nand abroad Francis E. Warnock\n7 2005 Multinational enterprises, international trade,\nand productivity growth: Firm-level evidence Wolfgang Keller\nfrom the United States Steven R. Yeaple\n8 2005 Location choice and employment S. O. Becker,\ndecisions: a comparison of German K. Ekholm, R. J\u00e4ckle,\nand Swedish multinationals M.-A. Muendler\nevidence from German sectoral data Alexander Lipponer\nand the degree of backward linkages Kamal Saggi\nstock market comovement Marco Del Negro\n12 2005 The determinants of intra-firm trade: in search Peter Egger\nfor export-import magnification effects Michael Pfaffermayr\nabsorptive capacity: evidence from quantile Sourafel Girma\nregressions Holger G\u00f6rg\n14 2005 Learning on the quick and cheap: gains James R. Markusen\nfrom trade through imported expertise Thomas F. Rutherford\nevidence from German treasury auctions J\u00f6rg Rocholl\n16 2005 Consumption, wealth and business cycles: B. Hamburg,\nwhy is Germany different? M. Hoffmann, J. Keller\n17 2005 Tax incentives and the location of FDI: Thiess Buettner\nevidence from a panel of German multinationals Martin Ruf\nEuro/Dollar Exchange Rate Karsten Ruth\nDeutschland mit Hilfe von Filterverfahren Stefan Stamfort\nEuropean economies with the euro area? Sandra Eickmeier\nEvidence from a structural factor model J\u00f6rg Breitung\n21 2005 Asymptotic distribution of linear unbiased J.-R. Kurz-Kim\nestimators in the presence of heavy-tailed S.T. Rachev\nstochastic regressors and residuals G. Samorodnitsky\nWelfare Costs of Nominal Rigidities over\nthe Business Cycle Matthias Pastian\n23 2005 The cross-sectional dynamics of German J. D\u00f6pke, M. Funke\nbusiness cycles: a bird's eye view S. Holly, S. Weber\n24 2005 Forecasting German GDP using alternative Christian Schumacher\nfactor models based on large datasets\nsetting? \u00ad micro-evidence from German\nmetal-working industries \u00ad Harald Stahl\nuncertainty Wolfgang Lemke\nJ. Hilscher, J. Szilagyi\n28 2005 Recursive robust estimation and control Lars Peter Hansen\nwithout commitment Thomas J. Sargent\nSeries 2: Banking and Financial Studies\n1 2004 Forecasting Credit Portfolio Risk A. Hamerle,\nT. Liebig, H. Scheule\nAn Empirical Analysis of US Corporate Klaus D\u00fcllmann\nCredit Exposures Monika Trapp\n3 2004 Does capital regulation matter for bank Frank Heid\nbehaviour? Evidence for German savings Daniel Porath\nbanks St\u00e9phanie Stolz\n4 2004 German bank lending during F. Heid, T. Nestmann,\nemerging market crises: B. Weder di Mauro,\nA bank level analysis N. von Westernhagen\n5 2004 How will Basel II affect bank lending to T. Liebig, D. Porath,\nemerging markets? An analysis based on B. Weder di Mauro,\nGerman bank level data M. Wedow\nGerman savings banks and credit cooperatives Daniel Porath\nand bank efficiency in Germany Michael Koetter\n2 2005 The supervisor's portfolio: the market price\nAnalysis and models for risk aggregation Carsten Wehn\n3 2005 Do banks diversify loan portfolios? Andreas Kamp\nA tentative answer based on individual Andreas Pfingsten\nbank loan portfolios Daniel Porath\n4 2005 Banks, markets, and efficiency F. Fecht, A. Martin\n5 2005 The forecast ability of risk-neutral densities Ben Craig\nof foreign exchange Joachim Keller\nrequirements Frank Heid\nbusiness cycle: evidence for German St\u00e9phanie Stolz\nsavings and cooperative banks Michael Wedow\nindustrial countries: driven by fundamentals\nor different treatment? Thorsten Nestmann\n9 2005 Accounting for distress in bank mergers M. Koetter, J. Bos, F. Heid\nC. Kool, J. Kolari, D. Porath\n10 2005 The eurosystem money market auctions: Nikolaus Bartzsch\na banking perspective Ben Craig, Falko Fecht\nVisiting researcher at the Deutsche Bundesbank\nThe Deutsche Bundesbank in Frankfurt is looking for a visiting researcher. Visitors should\nprepare a research project during their stay at the Bundesbank. Candidates must hold a\nPh D and be engaged in the field of either macroeconomics and monetary economics,\nfinancial markets or international economics. Proposed research projects should be from\nthese fields. The visiting term will be from 3 to 6 months. Salary is commensurate with\nexperience.\nApplicants are requested to send a CV, copies of recent papers, letters of reference and a\nproposal for a research project to:\nDeutsche Bundesbank\nPersonalabteilung\nWilhelm-Epstein-Str. 14\nGERMANY"
}