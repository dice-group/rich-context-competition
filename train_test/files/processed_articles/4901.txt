{
    "abstract": "Abstract\nRecent calls to improve the quality of education in schools have drawn attention to the importance of teachers' preparation\nfor work in classroom settings. Although the practicum has long been the traditional means for pre-service teachers to learn\nand practice classroom teaching, it does not always offer student teachers the time, safe practice experiences, repetition,\nor extensive feedback needed for them to gain adequate knowledge, skills, and confidence. Well-designed simulations can\naugment the practicum and address these gaps. This study evaluated the design of simSchool (v.1), an online simulation for\npre-service teachers, using student teachers' ratings of selected factors, including realism, appropriateness of content and\ncurriculum, appropriateness for target users, and user interaction. Based on these ratings, the study identified strengths\nand weaknesses, and suggested improvements for the software. Participant ratings varied considerably but indicated that\ncertain aspects of the simulation, such as its educational value, classroom challenges, and simulated student characteristics,\nwere moderately well received. However, user interface navigation and the range and realism of simulated teacher\u00adstudent\ninteractions should be improved.\n",
    "reduced_content": "sgo.sagepub.com\nCreative Commons CC BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access page (http://www.uk.sagepub.com/aboutus/openaccess.htm).\nArticle\nTeacher education programs must now train teachers to work\nin environments that will demand increasingly complex\nskills and knowledge, along with greater accountability and\ndemonstrated teaching effectiveness. Practice teaching is a\nlong-respected education component of this training, allow-\ning student teachers to build their classroom knowledge,\nskills, and confidence before taking full responsibility for\nclassroom teaching (Arnett & Freeburg, 2008). However,\nproviding an effective practicum experience is often an\nadministrative and logistical challenge, demanding strong\nuniversity\u00adschool partnerships, the integration of theory and\npractice, and, ideally, a broad range of teaching situations in\nthe face of limited time and resources (Allen & Wright, 2013;\nSimulation techniques have been used as training and\nfeedback tools for many years in occupations such as\nmedicine, aviation, military training, and large-scale\ninvestment where real-world practice is dangerous, costly,\nor difficult to organize (for example, see Drews &\nBackdash, 2013). In pre-service teacher education, class-\nroom simulations can help pre-service teachers to trans-\nlate their theoretical knowledge into action through\nrepeated trials without harming vulnerable students, and\nthey can provide more practice time and diversity than\nlimited live practicum sessions (Carrington, Kervin, &\nOne such simulation is simSchool (www.simschool.org),\ndesigned to provide teaching skills practice in a simulated\nclassroom with a variety of students, each with an individual\npersonality and learning needs. simSchool has been shown in\nseveral studies to have potential as a practice and learning\ntool for pre-service teachers (Badiee & Kaufman, 2014;\nChristensen, Knezek, Tyler-Wood, & Gibson, 2011; Gibson,\n2007). Although simSchool has been under development for\npublished research has addressed its design as an instruc-\ntional tool. To address this gap, the current study evaluated\nthe design of simSchool (v.1) from the perspective of its tar-\nget users, pre-service teachers, providing both quantitative\nand qualitative evidence of its strengths, weaknesses, and\nareas for improvement.\nBackground\nResearch on student learning maintains that teachers are the\nmost important school-related factor influencing student\n1Simon Fraser University, Burnaby, British Columbia, Canada\nCorresponding Author:\nDavid Kaufman, Simon Fraser University, Burnaby, British Columbia, V5A\nEmail: dkaufman@sfu.ca\nDesign Evaluation of a Simulation for\nTeacher Education\nFarnaz Badiee1 and David Kaufman1\n Keywords\nsimulation, simSchool, design evaluation, pre-service, teacher education\n2 SAGE Open\nachievement (Edutopia, 2008). Teacher education programs\ntrain our teachers, providing initial and ongoing support,\nresources, and hands-on experience, to prepare them for their\nteaching careers.\nThese programs face at least two important challenges\nthat call for a more sophisticated education process. On one\nhand, teachers need an ever-growing set of knowledge, skills,\nand attitudes to meet their responsibilities; on the other hand,\nfaced with decreased funding, increased regulation, and\ngrowing competition for available teaching jobs, they must\nclearly demonstrate their competencies in enhancing stu-\nTeaching Practice and the Practicum\nClassroom teaching practice provides most student teachers\nwith their first experience in applying the knowledge and\nexercising the skills that they study. The practicum is\nintended to give pre-service teachers the opportunity to\ndevelop practical skills and knowledge, receive feedback\nfrom experts and professionals, and gain experience with\nstudents and the school environment that can directly help\nthem to prepare for classroom teaching. Also, practicum\nexperiences allow teacher candidates to learn and grow in\nprotected settings (Girod & Girod, 2008). Therefore, field\nexperiences are often identified as the most important aspect\nof teacher education programs (Arnett & Freeburg, 2008;\nHowever, the practicum is fraught with difficulties,\nincluding a lack of appropriate field placements, particularly\nfor rural, special-needs, and rarely found conditions; short-\nages of host teachers willing to provide their time and exper-\ntise; host teachers' poor teaching practices, particularly with\nspecial-needs students; limited opportunity for repeated\npractice; and poor integration with the university curriculum\nMcPherson, Tyler-Wood, Mcenturff, & Peak, 2011; Wilson,\nfore, important to consider ways to augment the traditional\npracticum to enhance both the quantity and quality of stu-\ndents' pre-service teaching experience.\nSimulation-Based Practice\nClassroom simulations are starting to offer the possibility of\nenhancing the practicum by providing new opportunities for\npre-service teachers to practice their skills. A simulation is a\nsimplified but accurate, valid, and dynamic model of reality\nimplemented as a system (Sauv\u00e9, Renaud, Kaufman, &\ntion and gaming as a scientific discipline, noted that the\nmeaning of \"to simulate\" stems from the Latin simulare, \"to\nimitate,\" and defined it as \"a conscious endeavor to repro-\nduce the central characteristics of a system in order to under-\nstand, experiment with, and/or predict the behavior of that\nSimulation involves play, exploration, and discovery, all ele-\ntory in adult education, initially in the form of abstract\nrepresentations using physical components such as paper and\npencil or playing boards and, more recently, in many types of\ncomputer-based virtual environments (Ramsey, 2000).\nSimulations are distinguished from games in that they do\nnot involve explicit competition; instead of trying to \"win,\"\nsimulation participants take on roles, try out actions, see the\nresults, and try new actions without causing real-life harm.\nSimulations, when paired with reflection, offer the possibil-\nKraft, Hynes, and Hughes (2014) pointed out that an effec-\ntive simulation produces a sense of realism that leads the\nuser to regard the simulated world as real in some sense:\nThese environments must provide a personalized experience\nthat each teacher believes is real (i.e., the teacher \"suspends his/\nher disbelief\"). At the same time, the teacher must feel a sense of\npersonal responsibility for improving his or her practice\ngrounded in a process of critical self-reflection. (p. 22)\nSuspension of disbelief and this sense of personal respon-\nsibility work together to engage the learner in the simulation\nprocess so that it becomes a \"live\" experience; feedback and\nreflection complete a cycle so that the learner can conceptu-\nalize and ultimately apply the new learning (Kolb, 1984).\nSimulations have many advantages for teacher education,\nparticularly now that new technologies support more realis-\ntic modeling of classrooms and students. McKeachie (1994)\nmaintained that the main advantage of an effective educa-\ntional simulation is that students are active participants rather\nthan passive observers, and such a shift in roles motivates\nstudents. Simulations can provide a venue for practicing and\nrefining the transfer to the classroom of newly learned theory\nand skills, based on experimentation, feedback from simu-\nlated students, reflection/debriefing, and repetition\nthis way, failure becomes part of an ongoing learning process\nrather than a block to achievement (Carstens & Beck, 2005).\nThe role-play aspect of classroom simulations supports stu-\ndents in taking on and practicing unfamiliar teaching roles,\ndeveloping new self-efficacy and professional identity over\ntime (Carrington et al., 2011; Gibson, Christensen, Tyler-\nWood, & Knezek, 2011). In simulations, scenarios can be\nencountered that are ethically or logistically difficult to cre-\nate in the real world, such as high-stress urban environments\nor mixed groups of special-needs students; pre-service teach-\ners can begin to prepare for these before they experience\nthem in real life (Dieker, Hynes, Stapleton, & Hughes, 2007;\nDieker et al., 2014). With simulations, learners can make\nmistakes without harming actual students--an advantage\nthat is particularly pronounced when training for work with\nBadiee and Kaufman 3\ndifficult or special-needs learners (Dieker et al., 2014; Ferry\net al., 2004). Finally, simulations using commonly available\ntechnologies offer a low-cost alternative to extending teach-\ning practice time in the field.\nThe Importance of Simulation Design\nRealizing a simulation's potential in any learning situation\ndepends on a range of factors, including its fidelity, usability,\nrelationship to learning goals, and learning processes. As\nsimulations have developed in sophistication and have\nbecome accepted teaching tools in business, medicine, and\nother disciplines, researchers and practitioners have come to\nagree on a broad set of design and implementation principles\nfor effective learning support.\nDrawing on experience in disciplines other than teaching,\nDieker et al. (2014) identified three critical components in\nteaching simulations that affect learning of new behaviors.\nOne is \"a sense of real presence\" so that the users in some\nsense \"suspend disbelief,\" engage with the simulated envi-\nronment as real, and feel personal responsibility to improve\ntheir practice (Dede, 2009). Related but distinct is the con-\ncept of fidelity, the validity of the simulation model (the\ndegree to which the simulation represents reality); fidelity\nensures that learning from the simulation is valid and trans-\nfers to practice in real life (Alessi & Trollip, 2001).\nDieker et al. (2014) also highlighted the importance for\nsimulation-based learning of a cyclical process of action,\nfeedback and debriefing, and modified action. This is known\nin the military asARC, or theAction Review Cycle (Holman,\nDevene, & Cady, 2007). A meta-analysis by Gegenfurtner,\nQuesada-Pallar\u00e8s, and Knogler (2014) confirmed that feed-\nback after simulation activity led to greater self-efficacy and\nskills transfer.\nThe third component, only partly realized in today's simu-\nlations, is personalized learning through flexible environ-\nments that focus on assessing and teaching the specific new\nskills needed by the learner (Dieker et al., 2014). One aspect\nof personalized learning that is incorporated into some simu-\nlations is user control over levels of difficulty, which increases\nself-efficacy beliefs and skills transfer (Gegenfurtner et al.,\nmaintained that effective simulations should allow learners to\nchange simulation parameters, repeat the experiment, and\ndirectly observe the consequences.\nPerhaps the most comprehensive set of recommended simu-\nlation design features comes from Issenberg, McGaghie,\nPetrusa, Gordon, and Scalese's (2005) comprehensive system-\natic review, covering 34 years and 109 studies of high-fidelity\nmedical simulations. This review identified 10 simulation fea-\ntures that facilitate effective learning (Table 1); the features are\napplicable outside the medical domain and have been recom-\nmended by many simulation experts and education researchers,\nThe above design criteria, focusing on learning processes,\nare chiefly concerned with whether or not the simulation is\neffective in terms of producing defined learning outcomes\nfor users. Usability, or the ease with which users are able\ncarry out tasks using the software, is not directly addressed\nbut is a fundamental determinant of the user's experience\nwith the software. Usability is distinct from utility, or whether\nthe software is capable of carrying out its intended tasks\n(Microsoft, 2000). Clearly, both are important, if implied,\ndesign criteria for an effective simulation.\nThe simSchool Classroom Simulation\nsimSchool (www.simschool.org) is a web-based classroom\nsimulation designed to provide pre-service teachers with the\nopportunity to practice different classroom teaching skills.\nThe player in simSchool has the role of a teacher responsible\nfor teaching and managing a classroom of students, choosing\na grade between 7 and 12. simSchool provides student teach-\ners with the opportunity of practicing classroom teaching\nskills by analyzing student differences, adapting instructions\nto learners' needs and characteristics, and getting feedback\nfrom the simulation as the results of their teaching actions\nand choices (simSchool, 2011). Each simStudent (simulated\nstudent) has a profile that includes information about person-\nality, academics, and teacher's reflections; these profiles are\nmodeled on real student profiles in actual teachers' records.\nThe profile include statements about the simStudent's behav-\nior and learning preferences. Each has an individual person-\nality with settings on six dimensions: expected academic\nperformance, openness to learning, conscientiousness toward\ntasks, extroversion or introversion, agreeableness, and emo-\ntional stability; settings range from very negative to very\npositive on each dimension, with about 20 different possible\npoints on each of the six dimensions (Badiee & Kaufman,\nTable 1. Simulation Conditions for Effective Learning.\nCondition %a\nEducational feedback 47\nRepetitive practice 39\nIntegration into the curriculum 25\nRange of difficulty levels 14\nMultiple learning strategies 10\nAbility to capture variations in clinical conditions 10\nExperimentation without adverse consequences 9\nReproducible, standardized experiences,\nstudents as active learners\nClearly stated goals and defined outcomes 6\nValidity of the simulation model 3\nSource. Summarized from Issenberg, McGaghie, Petrusa, Gordon, and\naPercentage of 109 reviewed articles reporting evidence of effectiveness.\n4 SAGE Open\nIn the simSchool classroom, the player must select tasks\nand conversational exchanges that best fit the students'needs,\nand simStudents respond with changes in their expressions\nand responses. The teacher's choices in interaction with sim-\nStudents affect their academic outcomes and behaviors, and\nthe player should make appropriate decisions to help students\non their given learning tasks (Zibit & Gibson, 2005).\nAs the simulation runs, the player is required to make\nmany choices about organizing the lesson, managing the\nclassroom, and interacting with individual students. These\nissues have been identified as significant areas that underlie\nthe quality of instruction for teachers (Nelson, 2002). Based\non their simulation experience, student teachers can practice\ndecision making and refine their classroom teaching strate-\ngies (Zibit & Gibson, 2005). simSchool is designed to sup-\nport the user in developing expertise and thinking like a\nteacher. Success in the simulation comes through helping\nsimStudents improve, both in their academic performance\nand their behavior. simSchool is intended to be used on an\nongoing basis as part of the pre-service curriculum, with an\ninstructor's guidance (Deale & Pastore, 2014).\nRecent studies have evaluated simSchool's effectiveness\nfor general teaching practice (Badiee & Kaufman, 2014;\nDeale & Pastore, 2014), for the development of student\nteachers' self-efficacy (Christensen et al., 2011; Gibson et al.,\n2011), and for learning to work with diverse and special-\nneeds student populations (McPherson et al., 2011; Rayner\n& Fluck, 2014). These have indicated a range of positive\nlearning outcomes for pre-service teachers after simSchool\nuse. The Rayner and Fluck study also captured, in qualitative\ncomments, users' general opinions about the simulation's\nrealism and ease of use. These questioned the simulation's\nrealism (particularly simulated student responses) and identi-\nfied difficulties with the user interface (particularly the\nmechanics of task and response selection). The article also\nsuggested that simSchool's realism could be improved by\nextending its virtual classroom to include inter-student inter-\nactions and by improving the classroom's visual realism.\nUnlike the above studies, the research reported considers\nthe initial user experience with simSchool based on a series\nof brief introductory sessions. Rather than introducing the\nsimulation as part of a formal teaching preparation program,\nthis experiment studies initial user perceptions of and experi-\nences with the software, identifying the key factors that sup-\nport or inhibit its user acceptance, usability, and utility for\naugmenting the practicum experience.\nMethod\nThis research was done as part of a pilot study of the overall\neffectiveness of simSchool in a pre-service teacher education\nprogram in a mid-sized Western Canadian university. Results\nrelated to simSchool's effectiveness for teacher preparation\nare presented in Badiee and Kaufman (2014) and are not\naddressed in this article.\nResearch Questions\nThe design evaluation, intended for a preliminary user-ori-\nented evaluation of simSchool's usability and relevance, was\nguided by two broad questions:\n1. Research Question 1: What do student teachers see\nas the strengths and weaknesses of simSchool?\n2. Research Question 2: What design features of sim-\nSchool need to be improved to meet student teachers'\nperceived preparation needs?\nThe questions were addressed through a combination of\nquantitative and qualitative methods, as described below.\nParticipants\nTwenty-two student teacher volunteers from a teacher educa-\ntion program at a Western Canadian university took part in\nthe study. Their program is made up of a combination of pro-\nfessional coursework and practicum experience. Because\nthey came from several class cohorts in the program, some\nparticipants had participated in a practicum, whereas others\nhad not. For the purposes of this evaluation, the study did not\ndistinguish among cohorts.\nExperiment and Instrument\nBecause the study relied on busy volunteer participants, the\nexperiment was conducted in a single session with breaks\nbetween brief experimental tasks. The experiment was con-\nducted outside the education curriculum; in contrast, Rayner\nand Fluck's (2014) study embedded the simulation sessions\nin the formal curriculum, was conducted over a longer\nperiod, and included formal training for the simulation facili-\ntator. In this study, the facilitator relied on the simSchool\nmanual and self-study to learn the software prior to the\nexperiment.\nThe experiment consisted of three sessions with sim-\nSchool Version 1. The first session was used simply for prac-\ntice with one simStudent, and the research assistant circulated\nand assisted any student teachers who were unclear about\nwhat to do. Then, student teachers worked through the simu-\nlation \"for real\" with one simStudent and then with five sim-\nStudents. There was a debriefing step after each session.\nDuring the debriefings, participants received and were able\nto discuss their simSchool-generated performance results.\nThe experimental tasks and assigned times are shown in\nData related to simSchool's design were collected from a\npost-experiment questionnaire based on standards of effec-\ntive simulation design. The questionnaire used five-point\nscales to rate the simulation's realism and other features, as\nwell as three open-ended questions about the simulation's\ndesign. SPSS Version 21 was used to produce descriptive\nBadiee and Kaufman 5\nstatistics (frequencies and percentages). Due to the small\nnumber of responses, thematic analysis for the open-ended\nquestions was done manually using Microsoft Word.\nResults\nParticipant Backgrounds\nTable 3 shows selected participant background characteris-\ntics. The great majority of participants (86.4%) were female.\nTwo thirds rated their computer skills as intermediate. Less\nthan a third (31.8%) had used computer-based simulations\nfor education, but the majority (84.2%) had used computer-\nbased simulations in another context. Following their sim-\nSchool use, less than one fifth (18.2%) of student teacher\nparticipants indicated that they planned to use what they had\nlearned in the simulation in actual classrooms; however,\nalmost three quarters (72.7%) responded that they were not\nsure whether they wanted to do so in the future.\nQuantitative Ratings\nParticipant ratings of simSchool's realism (fidelity) are sum-\nmarized in Table 4. Overall, ratings were moderate, with the\nmean rating of the highest rated characteristic, \"the chal-\nlenges of a typical teacher in the classroom,\" 3.73 out of 5. Of\nthe participants, 68.1% rated these challenges as \"realistic\" or\n\"very realistic.\" The realism of simStudent profiles was rated\nat a similar level, with a mean of 3.71; 71.4% rated the pro-\nfiles as \"realistic\" or \"very realistic.\" \"Characteristics of sim-\nSchool students compared to those of real students\" received\na mean rating of 3.27, with 50.0% of the participants rating\nthese as \"realistic or \"very realistic.\" The lowest rated charac-\nteristic was \"conversations between you as a teacher and sim-\nrated these simulated conversations as \"unrealistic\" or \"very\nunrealistic.\" The remaining three items were rated toward the\nmidpoint of the rating range, with ratings spread across \"unre-\nalistic,\" \"unsure,\" and \"realistic.\" \"Options for assigning\nclassroom tasks to simStudents\" was rated 2.77 out of 5, with\nratings somewhat evenly spread over the middle three rating\ncategories. The remaining three characteristics--classroom\ndesign, simStudents' behavior, and academic performance\noutcomes--were rated close to the scale midpoint of 3, indi-\ncating that participants were divided about these features and\non average were unsure about their realism.\nTables 5 through 7 show participant ratings for other\naspects of the simulation. Four items (clarity of purpose,\neducational value, concept coverage, and generalizability)\nwere rated with respect to content and curriculum appropri-\nateness (Table 5); the highest mean rating was for the simula-\ntion's educational value (3.14 out of 5, with 3 = \"good\"). It is\nworth noting that 86.3% of the respondents rated this charac-\nteristic \"good,\" or higher. The lowest rating (2.77) was for its\ngeneralizability. All four items were rated \"good\" (the mid-\npoint of the scale) by the largest percentage of participants.\nTable 6 shows participant ratings for the appropriateness\nof simSchool for its target users. All mean ratings in this\ngroup were below the scale midpoint of 3, between \"poor\"\nand \"good,\" reflecting users' somewhat negative opinions.\nThe items \"It is motivational to use\" and \"I find it fun\"\ntively). Lowest rated were \"It effectively stimulates my cre-\nativity\" (M = 2.41) and \"It matches with my previous\nexperience\" (M = 2.50). The item \"It is flexible for different\nusers,\" which refers to an important criterion for effective\nsimulations, received a \"poor\" or \"very poor\" rating by\nWhen asked about simSchool's user interaction (Table 7),\nparticipants gave a rating over 3 to only one item--the\nappropriate use of graphics, color, and sound (3.23 out of 5).\nOther items were rated less than 3.0 (\"good\"). Participants\ngave low to moderate ratings (Ms between 2 and 3, or \"poor\"\nand \"good\") to other items about ease of use and about effec-\ntive use of feedback and user control.\nTable 2. simSchool Experiment Tasks and Approximate Times.\nStep Task Time (min)\n2 Work with one simStudent (practice) 20\n4 Work with one simStudent (experiment) 20\n6 Work with five simStudents (experiment) 30\nTable 3. Selected Participant Background Characteristics.\nCharacteristic n (%)\nSelf-rated computer skill (n = 21)\nHave used computer-based simulation for education (n = 22)\nHave used computer-based simulation in other context(s)\nPlan to use what you learned in the simulation in the classroom\n6 SAGE Open\nTable 6. Ratings of simSchool Appropriateness for Target Users (n = 22).\nM (SD)a Very poor (%) Poor (%) Good (%) Very good (%) Excellent (%)\nPlease rate the following aspects of simSchool:\naBased on a 5-point scale with 1 = very poor, 5 = excellent.\nTable 7. Ratings of simSchool User Interaction (n = 22).\nM (SD)a Very poor (%) Poor (%) Good (%) Very good (%) Excellent (%)\nPlease rate the following aspects of simSchool:\n Graphics, color, and sound are used for\nappropriate instructional reasons\n It gives me control over the rate and the\nsequence of the simulation\naBased on a 5-point scale: 1 = very poor, 5 = excellent\nTable 4. Participant Ratings of simSchool Realism (n = 22).\nHow realistic did you find the following\nfeatures of simSchool? M (SD)a Very unrealistic (%) Unrealistic (%) Unsure (%) Realistic (%) Very realistic (%)\nThe characteristics of simStudents\ncompared with the characteristics of real\nstudents\nThe design of the simSchool classroom\ncompared with a real classroom situation\nThe outcome of simStudents' academic\nperformance\nConversations between you as a teacher\nand simStudents\nOptions for assigning academic tasks to\nsimStudents\nTeachers' challenges represented in\nsimSchool\naBased on a 5-point scale, with 1 = very unrealistic, 5 = very realistic.\nTable 5. Ratings of simSchool Content and Curriculum (n = 22).\nM (SD)a Very poor (%) Poor (%) Good (%) Very good (%) Excellent (%)\nPlease rate the following aspects of simSchool:\naBased on a 5-point scale, with 1 = very poor, 5 = excellent.\nBadiee and Kaufman 7\nFinally, one additional item asking about the simulation's\nfreedom from racial, ethnic, and gender stereotypes received\na relatively high mean rating of 3.55 out of 5.\nOpen-Ended Questions\nThree open-ended questions gathered qualitative data from\nthe 22 participants about their opinions and perceptions of\nsimSchool. The following themes in their comments were\nrelevant to the simulation design:\nQuestion 1: What did you like most about simSchool?\nRespondents identified the following:\n\u00b7\n\u00b7 The variety of options for interaction and having con-\nversation with simStudents (n = 5)\n\u00b7\n\u00b7 The variety in responses and attitudes of simStudents\nand the change and development of their academic\nperformance (n = 5)\n\u00b7\n\u00b7 Simulation feedback in the form of interim and final\nresults, spreadsheets and graphs, and/or student per-\nformance (n = 4)\nSome participants appreciated the richness of certain aspects\nof the simulation, including the interactions with simStudents,\nthe simStudents' different attitudes, and the responsiveness of\ntheir academic achievement to the teacher's decisions in the\nsimulation. These are all key design features that contribute to\nsimSchool's effectiveness for pre-service teacher classroom\npractice. However, these features were only identified by small\nnumbers of participants (four or five for each theme).\nQuestion 2. What did you like least about simSchool?\nThe following themes were reported:\n\u00b7\n\u00b7 Inappropriate, limited, or unrealistic options for con-\nversation and interaction with simStudents (n = 12)\n\u00b7\n\u00b7 Difficulty with the interface in navigating through the\noptions for interaction and conversation with simStu-\ndents (n = 9)\n\u00b7\n\u00b7 simStudents' responses to the chosen tasks/conversation\noptions did not always seem to suit or make sense (n = 5)\nA larger number of participants noted difficulties with the\nrealism of the simulation's conversation and interaction\noptions (n = 12); some also criticized the plausibility of stu-\ndent responses (n = 5). Nine participants noted difficulties\nwith the user interface.\nQuestion 3. Please provide any suggestions you have for\nimproving simSchool and/or its use with student teachers.\nRespondents provided the following:\n\u00b7\n\u00b7 Have a clearer, more user friendly, and ordered cate-\ngorization of comments in the interface for navigation\nand interaction with simStudents (n = 9)\n\u00b7\n\u00b7 Allow more realistic options for a variety of interac-\ntions, conversations, and teaching styles (n = 6)\n\u00b7\n\u00b7 Allow users to create their original comments for\ninteraction with simStudents (n = 5)\nThese suggestions are consistent with the weaknesses\nidentified in response to Question 2 above.\nDiscussion\nResearch Question 1: What do student teachers see as\nthe strengths and weaknesses of simSchool?\nIn general, participant ratings of simSchool varied widely\nand were moderate rather than highly positive. Regarding the\nsimulation's fidelity, respondents regarded as most realistic\nthe classroom challenges experienced by the user as a simu-\nlated teacher, the simStudent profiles and learning character-\nistics, their simulated classroom behaviors, and their\nacademic performance outcomes (although the last two only\nreceived ratings close to \"good\"). The realism of simulated\nconversations between simStudents and the teacher received\na low rating, as did correspondence with users' previous\nexperience. These ratings were consistent with participants'\nwritten comments, which identified \"most liked\" features as\nconversation and interaction options, variety in simStudent\nresponses and attitudes, and changes in their academic per-\nformance in response to teacher actions.\nOverall, ease of use and stimulation of user creativity\nreceived low ratings, whereas comments identified the \"least\nliked\" features as the user interface for conversation and\ninteraction with simStudents, general navigation in the user\ninterface, the realism of simStudents' responses, and general\nease of use.\nThese results suggest that users were not quite able to sus-\npend their disbelief and enter fully into their roles as teach-\ners, and that they were not able, given their short exposure to\nthe simulation, to easily choose and carry out required tasks.\nResults of other studies (e.g., Christensen et al., 2011) sug-\ngest that using and believing the simulation might become\neasier given time and support for new users to become more\nfamiliar with the software and with how to respond to its\nunderlying student models. Also, simSchool's flexibility for\ndifferent users, an important simulation design criterion, was\nrated \"poor\" or \"very poor\" by 50% of users, indicating that\nthey were not aware of the software's capabilities for defin-\ning multiple student learning needs and for changing the\nclass size and learning requirements; this was probably also\ndue to the short experimental time.\nRatings were above 3 (\"good\") for the simulation's clarity\nof purpose; the educational value of simSchool content; the\nappropriate use of graphics, color, and sound; and sim-\nSchool's freedom from racial, ethnic, and gender stereotypes.\nThese, together with the high proportion (86.3%) of partici-\npants rating \"educational value\" as \"good\" or higher, and\npositive comments on simSchool's feedback, suggest that\n8 SAGE Open\nnew users in the study recognized the simulation's potential\nas a learning tool despite their initial difficulties.\nThese findings are valuable because they come from the\nreflection and feedback of student teachers--the main target\nusers of simSchool. However, given the short times available\nfor participants to practice and work with the simulation,\nthey reflect first impressions about the simulation as well as\nfrustrations that might have been mitigated with longer prac-\ntice time and simulation sessions. For example, the effective-\nness of feedback through student responses received a low\nrating, although the student teachers appreciated receiving\nfeedback and being able to see and compare their perfor-\nmance results. It is worth noting here that in longer experi-\nments, instructors worked with users to help them fully\nunderstand and learn from the system's feedback, suggesting\nthat limited debriefing time might have negatively affected\nuser opinions about feedback.\nResearch Question 2: What design features of simSchool\nneed to be improved to meet student teachers' perceived\npreparation needs?\nThrough low ratings of some aspects of the program and\nin written comments, participants argued for improvements\nin the conversation and interaction options between simStu-\ndents and teachers, as well as improvements in the user inter-\nface. These comments suggest that improving these aspects\nof the simulation could lessen initial user frustration and\nimprove its overall effectiveness.\nConclusion\nThis study looked at users' initial responses to simSchool\nbased on limited training and brief simulation sessions.\nAlthough these initial perceptions and opinions might well\nchange with increased exposure and instructor support, they\nindicate issues that need to be addressed to use the simula-\ntion effectively for pre-service teaching practice. These\nresults are consistent with Rayner and Fluck's (2014) obser-\nvations in that both reflect the effects of participants' limited\ntime working with the simulation. Taken together, these two\nstudies confirm that for effective training, the version of sim-\nSchool evaluated in this study requires longer periods of use\nand stronger instructor support than in their experiments.\nThe results reported in this article do suggest that addressing\nusability and fidelity issues could reduce these time and\nresource requirements, encouraging its wider use. Despite\nthe moderate to low ratings, the student teacher participants\nin this study found overall that simSchool is an instructional\nprogram of educational value.\nStudy Limitations\nThis design evaluation was conducted within a short time\nframe. Due to participants' extremely full schedules, they\nwere only available for one simulation period, which limited\nthe time available for them to practice with the simulation.\nThis did not allow time for them to become comfortable with\nthe user interface, to acclimate to the simulated teacher's role\nand required behaviors, or to practice with a more realistic\n18-student classroom. Finally, the sample of students\ninvolved in the study might be considered biased, because it\ninvolved willing volunteer student teachers (primarily\nfemale) rather than a randomly selected sample. Therefore,\nthe generalizability of the results is limited.\nFurther Research\nThe results of this study suggest several areas for further\ndesign evaluation work, beginning with addressing the limi-\ntations identified above by providing a longer time frame and\na larger participant sample to test whether the negative rat-\nings in this study would lessen with more learning time.\nEvaluation of specific design criteria could provide more tar-\ngeted feedback for simSchool developers. Some of these\nissues have been addressed in Version 2 of the software, so\nfuture studies will be conducted with this version.\nUsing a sample of participants at different stages in their\nteacher education program could help to evaluate how partici-\npants'prior knowledge and experience affect simSchool's per-\nceived design strengths and weaknesses and whether practice\nwith the simulation might affect whether or not student teach-\ners plan to use simulations such as simSchool in the future. It\nwould also be useful to evaluate, with teacher educators, the\nsimulation's content and curriculum appropriateness.\nAuthors' Note\nFarnaz Badiee is now at the Center for Teaching, Learning, and\nTechnology, University of British Columbia.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect\nto the research, authorship, and/or publication of this article.\nFunding\nThe author(s) received no financial support for the research and/or\nauthorship of this article.\nReferences\nAldrich, C. (2004). Simulations and the future of learning. San\nFrancisco, CA: Pfeiffer.\nAldrich, C. (2005). Learning by doing: The essential guide to simu-\nlations, computer games, and pedagogy in e-learning and other\neducational experiences. San Francisco, CA: Jossey-Bass.\nAlessi, S. M., & Trollip, S. R. (2001). Multimedia for learning:\nMethods and development (3rd ed.). Boston, MA: Allyn & Bacon.\nAllen, J. M., & Wright, S. E. (2013). Integrating theory and practice\nin the pre-service teacher education practicum. Teachers and\nBadiee and Kaufman 9\nArnett, S. E., & Freeburg, B. W. (2008). Family and consumer sci-\nences pre-service teachers: Impact of an early field experience.\nJournal of Family and Consumer Sciences Education, 26, 48-55.\nBadiee, F., & Kaufman, D. (2014). Effectiveness of an online\nsimulation for teacher education. Journal of Technology and\nBillingsley, G. M., & Scheuermann, B. K. (2014). Using virtual\ntechnology to enhance field experiences for pre-service special\neducation teachers. Teacher Education and Special Education,\nBradley, E. G., & Kendall, B. (2014). A review of computer simula-\ntions in teacher education. Journal of Educational Technology\nCarrington, L., Kervin, L., & Ferry, B. (2011). Enhancing the\ndevelopment of pre-service teacher professional identity via\nan online classroom simulation. Journal of Technology and\nCarstens, A., & Beck, J. (2005). Get ready for the gamer generation.\nChristensen, R., Knezek, G., Tyler-Wood, T., & Gibson, D. (2011).\nsimSchool: An online dynamic simulator for enhancing teacher\npreparation. International Journal of Learning Technology, 6,\nCrookall, D. (2010). Serious games, debriefing, and simulation/\nDeale, D., & Pastore, R. (2014). Evaluation of simSchool, an\ninstructional simulation for pre-service teachers. Computers in\nDede, C. (2009). Immersive interfaces for engagement and learn-\nDewey, J. (1938). Experience and education. New York, NY:\nCollier and Kappa Delta Pi.\nDieker, L. A., Hynes, M., Stapleton, C., & Hughes, C. (2007).\nVirtual classrooms: STAR simulator: Building virtual environ-\nments for teacher training in effective classroom management.\nDieker, L. A., Rodriguez, J. A., Lignugaris/Kraft, B., Hynes, M.\nC., & Hughes, C. E. (2014). The potential of simulated envi-\nronments in teacher education: Current and future possibilities.\nDrews, F. A., & Backdash, J. D. (2013). Simulation training in\nhealth care. Reviews of Human Factors and Ergonomics, 8,\nDuffy, T., & Cunningham, D. (2001). Constructivism: Implications\nfor the design and delivery of instruction. In D. Jonassen (Ed.),\nHandbook of research on educational communications and\ntechnology. Bloomington, IN: The Association for Educational\nCommunications and Technology. Retrieved from http://www.\naect.org/edtech/ed1/\nDuke, R. D. (1980). A paradigm for game design. Simulation &\nDuke, R. D., & Geurts, J. L. A. (2004). Policy games for strate-\ngic management. Amsterdam, The Netherlands: Rozenberg\nPublishers.\nEdutopia. (2008). Why is teacher development important: Because\nstudents deserve the best. Retrieved from http://www.edutopia.\norg/teacher-development-introduction\nFerry, B., Kervin, L., Cambourne, B., Turbill, J., Puglisi, S.,\nJonassen, D., & Hedberg, J. (2004). Online classroom simula-\ntion: The \"next wave\" for pre-service teacher education? In R.\nAtkinson, C. McBeath, D. Jonas-Dwyer, & R. Phillips (Eds.),\nBeyond the comfort zone: Proceedings of the 21st ASCILITE\nComputers in Learning in Tertiary Education. Retrieved from\nhttp://www.ascilite.org.au/conferences/perth04/procs/ferry.\nhtml\nFerry, B., Kervin, L., Hedberg, J. G., Turbill, J., Cambourne, B., &\nJonassen, D. (2005). Operationalizing nine design elements of\nauthentic learning environments in a classroom-based on-line\nGegenfurtner, A., Quesada-Pallar\u00e8s, C., & Knogler, M. (2014).\nDigital simulation-based training: A meta-analysis. British\nGibbons, A. S., Fairweather, P. G., Anderson, T. A., & Merrill, M.\nD. (1997). Simulation and computer-based instruction: A future\nview. In C. R. Dills & A. J. Romiszowski (Eds.), Instructional\ndevelopment: State of the art (pp. 772-783). Englewood Cliffs,\nNJ: Instructional Technology Publications.\nGibson, D. (2007). simSchool and the conceptual assessment frame-\nwork. In D. Gibson, C. Aldrich, & M. Prensky (Eds.), Games\nand simulations in online learning: Research and development\nGibson, D., Christensen, R., Tyler-Wood, T., & Knezek, G. (2011).\nsimSchool: Enhancing teacher preparation through simulated\nclassrooms. In M. Koehler & P. Mishra (Eds.), Proceedings\nof Society for Information Technology & Teacher Education\nGibson, D., & Halverson, B. (2004). simSchool: Preparing tomor-\nrow's teachers to improve student results. In R. Ferdig, C.\nCrawford, R. Carlsen, N. Davis, J. Price, R. Weber, & D.\nA. Willis (Eds.), Proceedings of the Society for Information\nTechnology & Teacher Education Annual Conference 2004\nGirod, M., & Girod, G. (2008). Simulation and the need for qual-\nity practice in teacher preparation. Journal of Technology and\nHettler, L., Gibson, D., Christensen, R., & Zibit, M. (2008). sim-\nMentoring: Guiding development from virtual to real teaching!\nStowe, VT: CurveShift.\nHixon, E., & So, H.-J. (2009). Technology's role in field experi-\nences for preservice teacher training. Educational Technology\nHolman, P., Devane, T., & Cady, S. (2007). Change handbook: The\ndefinitive resource on today's best methods for engaging whole\nsystems (2nd ed.). San Francisco, CA: Berrett-Koehler.\nHowey, K. (1996). Designing coherent and effective teacher education\nprograms. In J. Sikula, T. Buttert, & E. Guyton (Eds.), Handbook\nNew York, NY: Macmillan.\nHuizinga, J. (1955). Homo Ludens: A study of the play element in\nculture. Boston, MA: Beacon Press. (Original work published\nIssenberg, S. B., McGaghie, W. C., Petrusa, E. R., Gordon, D. L., &\nScalese, R. J. (2005). Features and uses of high-fidelity medi-\ncal simulations that lead to effective learning: A BEME sys-\nKolb, D. A. (1984). Experiential learning: Experience as the\nsource of learning and development. Englewood Cliffs, NJ:\nPrentice Hall.\nLyons, J. (2012). Learning with technology: Theoretical foundations\nunderpinning simulations in higher education. In M. Brown,\nM. Hartnett, & T. Stewart (Eds.), ascilite 2012 Proceedings.\nWellington, New Zealand: Massey University. Retrieved from\nimages/custom/asclite2012_proceedings.pdf\nMcKeachie, W. J. (1994). Teaching tips: Strategies, research, and\ntheory for college and university teachers (9th ed.). Lexington,\nMA: D.C. Heath.\nMcPherson, R., Tyler-Wood, T., Mcenturff, A., & Peak, P. (2011).\nUsing a computerized classroom simulation to prepare pre-\nservice teachers. Journal of Technology and Teacher\nMicrosoft. (2000). Usability in software design. Redmond, WA:\nMicrosoft Corporation. Retrieved from https://msdn.microsoft.\nNelson, B. (2002). Quality teaching a national priority. Unicorn\nParente, D. H. (1995). A large-scale simulation for teaching busi-\nness strategy. In D. Crookall & K. Arai (Eds.), Simulation and\ngaming across disciplines and cultures (pp. 75-82). Thousand\nOaks, CA: SAGE.\nPhillion, J., Miller, P. C., & Lehman, J. D. (2005). Providing\nfield experiences with diverse populations for preservice\nteachers: Using technology to bridge distances and cultures.\nMulticultural Perspectives, 7, 3-9.\nRamsey, G. (2000). Quality matters: Revitalising teaching: Critical\ntimes, critical choices. Sydney, Australia: New South Wales\nDepartment of Education and Training.\nRayner, C., & Fluck, A. (2014). Pre-service teacher's percep-\ntions of simSchool as preparation for inclusive education: A\npilot study. Asia-Pacific Journal of Teacher Education, 42,\nSauv\u00e9, L., Renaud, L., Kaufman, D., & Marquis, J.-S. (2007).\nDistinguishing between games and simulations: A systematic\nreview. Journal of Educational Technology & Society, 10,\nsimSchool. (2011). About simSchool. Retrieved from www.sim-\nschool.org/about\nUlrich, M. (1997). Links between experiential learning and simu-\nlation and gaming. In J. Guerts, C. Joldersma, & E. Roelofs\n(Eds.), Gaming/simulation for policy development and organi-\nzational change: Proceedings of the 28th Annual International\nConference of the International Simulation and Gaming\nAssociation (ISAGA) (pp. 269-275). Tilburg, The Netherlands:\nTilburg University Press.\nWilson, S. M., Floden, R. F., & Ferrini-Mundy, J. (2001). Teacher\npreparation research: Current knowledge, recommendations,\nand priorities for the future. Seattle: Center for the Study of\nTeaching Policy, University of Washington.\nYoung, M. (1998). Rethinking teacher education for a global future:\nLessons from the English. Journal of Education for Teaching,\nZibit, M., & Gibson, D. (2005). simSchool: The game of teach-\ning. Innovate Online, 1(6). Retrieved from http://www.\ninnovateonline.info/pdf/vol1_issue6/simSchool___The_\nGame_of_Teaching.pdf\nAuthor Biographies\nFarnaz Badiee, at the time of this study, was an M.A. candidate\nin the Educational Technology and Learning Design Program at\nthe Faculty of Education, Simon Fraser University. She is now\nan instructional designer/project manager at the Centre for\nTeaching, Learning and Technology at the University of British\nColumbia.\nDavid Kaufman has served as director of Course Design, BC Open\nLearning Agency, and professor and director of the Medical\nEducation Unit in Dalhousie University's Faculty of Medicine.\nCentre at Simon Fraser University (SFU). He is currently a profes-\nsor in the Faculty of Education at SFU and conducts research on\ndigital games and simulations for learning, and as tools to to\nenhance the social, emotional and cognitive lives of older adults."
}