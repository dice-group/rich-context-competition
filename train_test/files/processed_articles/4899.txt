{
    "abstract": "Abstract\nSharing social media research datasets allows for reproducibility and peer-review, but it is very often difficult or even\nimpossible to achieve due to legal restrictions and can also be ethically questionable. What is more, research data\nrepositories and other research infrastructure and research support institutions are only starting to target social media\nresearchers. In this paper, we present a practical solution to sharing social media data with the help of a social science\ndata archive. Our aim is to contribute to the effort of enhancing comparability and reproducibility in social media\nresearch by taking some first steps towards setting standards for sustainable data archiving. We present a showcase\nfor sharing social media data with the example of a big dataset containing geotagged tweets (several months of continued\ngeotagged tweets from the United States from 2014 and 2015; nearly half a billion tweets in total) through a research\ndata archive. We provide a general background to the process of long-term archiving of research data. After some\nconsideration of the current obstacles for sharing and archiving social media data, we present our solution of archiving\nthe specific dataset of geotagged tweets at the GESIS Data Archive for the Social Sciences, a publicly funded German data\narchive for secure and long-term archiving of social science data. We archived and documented tweet IDs and additional\ninformation to improve reproducibility of the initial research while also attending to ethical and legal considerations, and\ntaking into account Twitter's terms of service in particular.\n",
    "reduced_content": "Original Research Article\nArchiving information from geotagged\ntweets to promote reproducibility and\ncomparability in social media research\nKatharina Kinder-Kurlanda1, Katrin Weller1,\nWolfgang Zenk-Mo\n\u00a8ltgen1, Ju\n\u00a8rgen Pfeffer2 and Fred Morstatter3\n Keywords\nData archiving, data sharing, ethics, social media data, Twitter, geo-data\nIntroduction\nIn May 2016, a group of researchers shared a dataset\nonline which they had compiled from the dating site\nOKCupid (Kirkegaard and Bjerrek\u00e6r, 2014). The data-\nset included information such as usernames, gender,\nlocation and sexual preferences of nearly 70,000 users\nand its publication led to a critical discussion among\nresearchers about several ethical questions such as the\nlack of OKCupid users' informed consent and the dif-\nficulties of anonymization.1 In particular, it was criti-\ncized that the researchers claimed that it was ethically\nand legally defensible to publicly share the dataset as\nthe data was already published. However, even if a user\nof an online platform knowingly shares a piece of infor-\nmation by posting it on the platform, Big Data analysis\ncan publicize and amplify it in a way the user never\nintended or agreed to (Zimmer, 2016). Many of the\nbasic requirements of research ethics \u00ad protecting user\nprivacy, maintaining data confidentiality and minimiz-\ning harm \u00ad are not sufficiently addressed in this scen-\nario. Zimmer (2010) argues that it is our responsibility\n1GESIS \u00ad Leibniz Institute for the Social Sciences, Ko\n\u00a8ln, Germany\n2Bavarian School of Public Policy, Technical University of Munich, Munich,\nGermany\n3Information Sciences Institute, University of Southern California, Marina\nDel Rey, California, USA\nCorresponding author:\nKatharina Kinder-Kurlanda, GESIS \u00ad Leibniz Institute for the Social\n\u00a8ln, Germany.\nEmail: katharina.kinder-kurlanda@gesis.org\nCreative Commons NonCommercial-NoDerivs CC BY-NC-ND: This article is distributed under the terms of the Creative Com-\nmons Attribution-NonCommercial-NoDerivs 4.0 License (http://www.creativecommons.org/licenses/by-nc-nd/4.0/) which permits\nnon-commercial use, reproduction and distribution of the work as published without adaptation or alteration, without further permission provided the\noriginal work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).\nBig Data & Society\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\njournals.sagepub.com/home/bds\nas scholars to ensure that research methods and pro-\ncesses remain rooted in long-standing ethical practices:\n`Concerns over consent, privacy and anonymity do not\ndisappear simply because subjects participate in online\nsocial networks; rather, they become even more import-\nSharing social media content repurposed for\nresearch cannot be divorced from the wider debates\nabout the role of ethical research practices within\ndata science. There is currently a concern that the\nresearch practices of data science do not make use of\nestablished tools of research ethics regulation or that\nsome practitioners are even rejecting ethics regulations\noutright (Metcalf and Crawford, 2016). However, as\nthe number of case studies from various disciplines is\ngrowing, social media research is also increasingly\naiming at improving practices, which includes an \u00ad\noften ethically motivated \u00ad strive for better standards\nfor validity (e.g., Fricke, 2014), comparability and\nreproducibility of research results. Amongst others,\nissues of representativeness (Boyd and Crawford,\nWith this paper, we contribute to the aim of improv-\ning social media research practices by combining two\npreviously distinct efforts: approaches to measure qual-\nity and representativeness of big datasets collected from\nTwitter on the one hand (contributed by Morstatter\nand Pfeffer), and initiatives to establish a framework\nfor sharing datasets used in social media research\nthrough archiving in a sustainable and documented\nway on the other hand (contributed by Kinder-\nKurlanda, Weller and Zenk-Mo\n\u00a8 ltgen). In this paper,\nwe are also looking at the issue of data sharing as an\narea within a research project's lifetime that is of par-\nticular concern for many of the debated and as of yet\nunsolved ethical issues surrounding the use for research\nof data `found' on the internet. Data sharing thus may\nhelp to address the ethical concerns surrounding repro-\nducibility and `best practice' research, but may also\nsometimes be hard to bring in line with ethical issues\narising out of the origin of the data as user-generated\ncontent.\nIn an interdisciplinary effort all authors of this paper\ncame together to archive2 a large-scale dataset collected\nfrom Twitter. The dataset was collected specifically to\nallow for archiving and future reuse and to serve as a\nreference dataset for geotagged tweets. We explored the\nchallenges when archiving several months of continued\ngeotagged tweets from the United States from 2014 and\n2015 (about half a billion tweets altogether). While the\ndataset was large, there was no guarantee that the data\nwe collected was representative of the population that\nfuture researchers might wish to study, for example, all\nTwitter users or even all users posting geotagged tweets\n(Ruths and Pfeffer, 2014). Moreover, a collection of\ngeotagged tweets provided by the Twitter API (which\nemploys opaque sampling techniques) was not guaran-\nteed to be complete or to provide a representative\nsample of all geotagged messages on Twitter\nNevertheless, geotagged Twitter data is particularly\nuseful for research. For example, it has been used to\nhelp first responders gain situational awareness in dis-\naster scenarios (Verma et al., 2011) or to uncover global\npatterns of tourism travel (Hawelka et al., 2014). There\nis also potential with this kind of data to learn more\nabout various other spatio-temporal patterns, for\nexample, of biodiversity conservation activities (Di\nMinin et al., 2015). Knowing the location from which\na user is tweeting is also useful to gauge the value of the\ndata she is producing (Morstatter et al., 2014). In add-\nition, the location information allows comparison of\nTwitter data with other, `offline' data, for example,\nsocio-demographic variables from censuses or surveys,\nhealth data, geographic information, environmental\ndata, etc. Our dataset can also serve as a reference\ndataset for comparative work, for example, for\nresearchers studying similar characteristics of geo-\ntagged tweets with other datasets (other periods of\ntime and other geographical regions) who want to com-\npare their results to existing work. Our dataset can also\nbe used for quality control, for example, to test repro-\nducibility of the existing dataset or to study the impact\nof platform changes on social media data, as Twitter\nchanged the way geotagged information was created\nhalfway through our data collection. To summarize,\nthere are various possibilities for new research projects\nto be performed on this data which makes archiving\neven more desirable. At the same time, the fact that\nthe data is geotagged makes it more sensitive in terms\nof user privacy, which requires special consideration\nduring a formal archiving process. At present, there\nare first approaches to archiving Twitter-based datasets\nthat comply with Twitter's Terms of Service, but they\nare usually not rooted in practical archiving experience\nand therefore lack measures for long-term availability\nor documentation. They also do not yet focus on the\nspecific setup of geotagged data. With this paper, we\nwant to fill these gaps by proposing a way to handle\nand archive geotagged tweets and to make a reference\ndataset available for reuse. To this end, we archived the\ndataset in the German Data Archive for the Social\nSciences at GESIS, founded in 1960 as one of the first\narchives for social science data. It specializes in survey\ndata of interest to social and political scientists and has\naccumulated expertise, tools and networks in this area.\nThe archive recently started archiving social media\ndata, which poses some unique challenges but also the\nopportunity to make new use of a well-established data\nsharing infrastructure. A pilot project archived a\n2 Big Data & Society\nTwitter dataset related to the Federal Elections in\nGermany 2013; as a result, a set of IDs from all\ntweets sent by election candidates and information\nabout candidates' Facebook profiles was archived and\nis available for reuse (Kaczmirek and Mayr, 2015). The\ndataset used in the present case study goes beyond that,\nas it is bigger and more complex due to the inclusion of\ngeo-information.\nAs shown in the section titled `Challenges in archiv-\ning Twitter data', there are legal, ethical, practical and\ntechnical challenges when archiving tweets (and geo-\ntagged tweets in particular) which require novel\napproaches that deviate from the standard practices\nfor survey data. Our solution for archiving the geo-\ntagged tweets balances three requirements: sharing leg-\nally and ethically, sharing to allow for reproducibility\n(e.g., precise documentation) and sharing to allow for\nnovel questions and reuse (i.e. researcher friendly data\nprovision).\nFirst, we will explain some general principles for\narchiving research data with particular focus on experi-\nences from the social sciences.\nSharing for reproducibility in specialized archives\nResearch data archives are built on the premise that\nscience is not an individual endeavour; rather, research-\ners aim to achieve provisional results for others to criti-\ncize and build upon. In order for this continued critique\nto happen, researchers are required to make transpar-\nent and understandable the way in which they have\ncome to their conclusions. In the quantitative social\nsciences, for example, research striving for objectivity\nis required to be reproducible (Popper, 1959). In add-\nition to a sound methodology section in publications,\nresearch data sharing plays a major role in achieving\nreproducibility of research. It is for this reason that\nthere is a long tradition of specialized archives that\nfacilitate research data sharing in the social sciences\nand in empirical social research in particular.\nConducting large surveys is also very costly and using\nthe data to answer multiple research questions is there-\nfore highly advantageous. However, there are also well-\nknown obstacles to sharing data for reuse or reprodu-\ncibility such as researchers' fear of opening their\nresearch to attack, legal limitations due to intellectual\nproperty and data protection issues, and in particular\nthe effort required to prepare the data for reproducibil-\nity and reuse. Offering reproducibility always requires\nmuch work, effort and knowledge in documentation,\npreservation and curation of digital data (Borgman,\n2012). Specialized data archives thus play an important\nrole in sharing research data. The GESIS archive is\npublicly funded and offers mainly long-term preserva-\ntion for digital survey data, which is reviewed,\nprocessed and documented to provide easily re-usable\ndatasets to the scientific community following well-\nestablished archiving standards for social science\ntion can be accessed via an online catalogue.3 Over\ntime, archives have developed sophisticated standards\nand procedures for archiving digital data. For example,\nthere are archiving and data provisioning workflows\nwhich require (a) following documented procedures in\narchiving, (b) ensuring that preserved information is\nunderstandable and findable for researchers and (c)\nguaranteeing long-term preservation of the data\nThe documented procedures applied in most archives\nconcern the registration of research data with persistent\nidentifiers, its archiving, distribution and long-term\npreservation. Archiving follows an established work-\nflow (Schumann and Recker, 2013): First, acquisition\ntakes place; second, processing is performed (e.g.,\nquality control, documentation); third, storage occurs\n(i.e. preservation actions are taken); and fourth, dissem-\nination and access are provided (e.g., include in\ncatalogue).4\nTo ensure that the documented information is under-\nstandable and findable, documentation of research data\nat the GESIS archive occurs in accordance with the\nData Documentation Initiative (DDI) metadata stand-\nard (http://www.ddialliance.org/). DDI is the most\nimportant standard for the description of quantitative\nsocial science research data and covers the whole data\nlife cycle (Vardigan et al., 2016). The datorium reposi-\ntory used in this example contains DDI-compliant\ndocumentation for the datasets which allows to cite,\nfind and better understand them. We will show below\nthat this documentation is, however, currently still\ninsufficient to document all the details required for\nreproducibility of a social media dataset.\nLong-term preservation refers to the fact that digital\ninformation is by no means stable. Its accessibility and\nunderstandability depend on storage media, hard- and\nsoftware environments and formats. In order to pre-\nserve digital objects such as the desired documentation\nof a data collection process for the long term, they need\nto be constantly altered and, for example, file formats\nrequire constant updating (Recker and Mu\nArchives ensure long-term preservation in a continuous\nprocess of data curation.\nIn the past, the GESIS archive focused on providing\nsurvey data to social scientists. However, disciplinary\nboundaries are becoming less important when it comes\nto the sharing of research data, particularly for\nresearchers who are trying to understand social phe-\nnomena on the web or who are working with new\nand computational approaches (Kinder-Kurlanda and\nWeller, 2014). A growing number of researchers are\nKinder-Kurlanda et al. 3\nusing multiple or mixed methods and want to utilize\ndata of different types and from various primary and\nsecondary sources (Borgman, 2012). Social media data\nand particularly Twitter data are in especially high\ndemand.\nResearch with Twitter data\nThere is a growing body of scholarly publications that\nutilize Twitter data to study various phenomena. In\nfact, Twitter has become one of the most frequently\ntargeted platforms in social media research (Tufekci,\nexplained by the platform's popularity: While Twitter's\nactive user community is relatively small, a search of\nthe publications database Scopus retrieves more publi-\ncations about Twitter than about the `bigger' platforms\nYouTube and Wikipedia (Weller, 2015). Twitter's APIs\nmake it relatively easy to access user data, Twitter has\nthe advantage of relatively simple privacy settings\n(Zimmer and Proferes, 2014b), a clear structure and\nshort texts; all of which may have also increased its\npopularity in research. Some researchers consequently\nare referring to Twitter as the `model organism' of\nsocial media research \u00ad and Tufekci (2014) has outlined\nthe problematic consequences this has for the field.\nProferes (2014a) have conducted meta-analyses of\nTwitter studies that illustrate their diversity, for\nexample, when it comes to approaches used for data\ncollection, sample sizes or research ethics. There are,\nhowever, only a small number of publications that\nuse preexisting datasets (Zimmer and Proferes,\n2014a). Most significantly, there is currently no bench-\nmark dataset (in the sense of a `standard' dataset, for\nexample, for a specific timeframe or topic that fulfills\nagreed-upon quality requirements) and no possibility to\neasily relate data and results from one publication to\nthose from another. Frequently, information given\nabout data used for a study does not enable others to\neven reproduce the same dataset. All this puts the val-\nidity and expressiveness of Twitter research into\nquestion.\nValidity and reproducibility in Twitter\nresearch\nValidity of Twitter research is also to some degree ques-\ntioned by the lack of clarity about its representativeness\n(Boyd and Crawford, 2012). This problem has already\nbeen addressed in different ways. Ruths and Pfeffer\n(2014) urge to consider whether a given dataset is rep-\nresentative of the actual population one wishes to\nstudy. Bruns and Stieglitz (2014) describe different\nlevels on which representativeness of Twitter data\nneeds to be considered, the most important distinction\nbeing between whether a Twitter-based dataset is rep-\nresentative of all Twitter data or of specific user groups\nand whether Twitter data can be representative of\n(parts of) society at all. They highlight how the specific\ncharacteristics used to retrieve a dataset (e.g., hashtags)\nmay filter specific types of users from the entire user\ncommunity (e.g., those speaking a specific language).\nBusch (2014) also points out how decisions made in\nsampling and filtering may highlight certain aspects of\ntargeted data and obscure others. Other research has\ninvestigated the bias in the APIs provided to research-\ners by Twitter (e.g., Morstatter et al., 2013). In our case,\nthe completeness of the geotagged tweets data returned\nfrom the Twitter Streaming API varied: Over 90% of\nall geotagged tweets for the United States were returned\nthrough the service for the first half of the data (col-\nlected in 2014). The second half of the data (collected in\n2015), however, indicates a considerable sampling bias\nwhich still warrants further exploration and was con-\nnected to Twitter fundamentally changing the way it\nreported its data during this time: It moved from an\nautomated geotag-only feature to including the `place'\nfeature which allowed users to set their own location.\nWhen Twitter switched to the place feature, we received\nsubstantially less data with the geotag query.\nUnderstanding (and documenting) underlying biases\nof collection methods is the first step towards methodo-\nlogical standards in social media research and towards\nenabling validity and reproducibility. The next import-\nant step is to share the data and code used in a research\nproject.\nChallenges in archiving Twitter data\nTwitter is but one, albeit a remarkable, case for investi-\ngating possibilities for sharing and archiving social\nmedia data. On the one hand, it is the only major\nsocial media platform so far that has made significant\nattempts to publicly preserve their entire history of data\n(Stone, 2010), although their agreement with the\nLibrary of Congress (2013) has not yet led to any tan-\ngible outcome (Zimmer, 2015). On the other hand,\nTwitter itself currently5 prohibits sharing of collected\nTwitter datasets to a considerable degree; the Twitter\nTerms of Service are the first challenge when archiving\nTwitter data. The Twitter Developer Agreement\n(Twitter, 2014) states: `if you provide Content to third\nparties, including downloadable datasets of Content or\nan API that returns Content, you will only distribute or\nallow download of Tweet IDs and/or User IDs'. Some\nexceptions are being made for lists of tweets in PDF and\nexcel files,6 but it is not allowed to provide bigger data-\nsets in their native JSON format for third party usage.\nTwitter has even demanded that individual researchers\n4 Big Data & Society\nstop sharing Twitter datasets. For example, the dataset\nused by Cha et al. (2010) was originally provided on the\nauthors' institutional website for download but has\nsince been removed upon Twitter's request (MPI-\nSWS, 2010). Legal challenges based on the Twitter\nTerms of Service thus are the first set of obstacles for\narchiving and sharing Twitter data.\nResearch ethics. A second set of issues arises out of ethi-\ncal concerns for users' privacy and their consent to being\nstudied. Particularly, when dealing with large volumes\nof user generated content, obtaining informed consent\nto research from the users of a social media platform is\ndifficult or even impossible (Zook et al., 2017). While\nusers may have formally agreed to their data being used\nas stated in the platform's Terms of Service by clicking\n`OK', they may not even be aware of being observed by\nresearchers (Hutton and Henderson, 2015). It thus\nbecomes even more important to take steps to protect\nusers' privacy. However, there is a high risk that indivi-\nduals may be re-identified from publications, published\ndatasets or additional material (Zimmer, 2010).\nResearchers working with social media data need to\nmake decisions about how to protect users in ways\nappropriate for the specific context, research topic and\nuser-group (Weller and Kinder-Kurlanda, 2015). For\nexample, data from vulnerable groups may require dif-\nferent handling than politician tweets.\nTechnical challenges. Technical challenges to archiving\nTwitter data are connected to the way the data needs\nto be shared: Providing a list of tweet IDs as suggested\nby Twitter (instead of a file containing the complete\ntweet texts and metadata such as author and time-\nstamp) means that to recreate the dataset, every indivi-\ndual tweet needs to be requested again via its ID from\nthe API \u00ad a process referred to as rehydrating. This\nprocess requires some additional time and tools\nduring the research process and we offer assistance in\nour archiving solution (see below). The Twitter\nDeveloper Agreement (Twitter, 2014) requires research-\ners to `Delete Content that Twitter reports as deleted or\nexpired; Change treatment of Content that Twitter\nreports is subject to changed sharing options (e.g.,\nbecome protected); and Modify Content that Twitter\nreports has been modified'. Sharing only tweet IDs\nensures that a user's decision to delete a tweet will\nalso result in that tweet being removed from future\nand (ideally also) existing data collections. However,\nsharing only tweet IDs also means that someone who\nwants to re-build the dataset from the IDs may find\nthat many of the tweets are no longer available. It\nmay not be possible to create the exact Twitter dataset\ntwice and archiving tweet IDs is thus no guarantee for\nreproducibility of Twitter-based research. In fact, every\nrehydration may result in a different dataset as more\nand more tweets are deleted over time. What is more,\ncontent may no longer be available once platform func-\ntionalities change, for example, once Twitter modifies\nthe way in which geotagging works (see below).\nDocumentation standards. Archiving Twitter data is also\nchallenged by a lack of established standards for doc-\numentation of the different stages of data collection,\nprocessing and analysis for social media data. The\nexamples for social media data sharing listed in the\nsection `Current approaches to sharing datasets col-\nlected from Twitter' mostly include little explicit data\ndocumentation or definition of what the data's essential\nproperties to be preserved are. One solution to this\nissue is to extend the well-established standards for\nmetadata and documentation of social science survey\ndata to also be applicable to social media data.\nCurrent approaches to sharing datasets\ncollected from Twitter\nDespite the challenges, several approaches for sharing\nTwitter data with other researchers or with the broader\npublic already exist. The current approaches to sharing\ndatasets collected from Twitter come from the follow-\n1. Individual researchers or projects provide the data-\nsets they have used for publications on their own\nwebsite, on university websites or through third\nparty platforms.\n2. Conference organizers and other publishers of scho-\nlarly work provide the datasets used for publica-\ntions. For example, the ICWSM conference has\nbeen including datasets for accepted conference\npapers since 2012.7 Users request access by emailing\na usage agreement.8\n3. Third parties, commercial companies or individual\nlaymen make available datasets via their websites.\n4. Libraries and (web) archives provide sets of collected\ntweets. The GESIS archive's social media election\ndata (Kaczmirek and Mayr, 2015) and the geotagged\ntweets in this paper are some of the first examples of\nthis.\nWhile most of these examples already allow for sec-\nondary use of Twitter datasets, data is not yet presented\nin a way that advances social media research more gen-\nerally. Datasets are not presented in a sustainable\nformat that can be referenced consistently (e.g., via a\ndigital object identifier (DOI)) and that is guaranteed to\nbe available over time. Most fundamentally, they also\nusually lack detailed information about how data was\ncollected and processed. Documentation standards or\nKinder-Kurlanda et al. 5\nmetadata guidelines (comparable to the DDI standard\nmentioned above) are not yet available for social media\nresearch. Possibly as a consequence of these gaps, avail-\nable datasets are not frequently re-used in the research\ncommunity. During a series of expert interviews, it was\nshown that at least more advanced researchers were\nreluctant to re-use datasets collected by others if they\nhad no way to judge quality due to a lack of informa-\ntion about how the data had been produced (Weller\nand Kinder-Kurlanda, 2015). Documentation and dis-\nsemination in accordance with archival best practice\nmay improve datasets' attractiveness. Archives decide\nwhich 'significant properties' of a digital object are\nindispensable and therefore need to be preserved for\nthe long term `to ensure its continued access, use, and\nmeaning, and its capacity to be accepted as evidence of\nwhat it purports to record' (Grace et al., 2009). One of\nseveral strategies for determining significant properties\n(Faniel and Yakel, 2001) is a people-centric approach\nthat considers the producers and re-users of data and\ntheir requirements. At the GESIS archive, these consid-\nerations of past and future data users are paired with a\nprocess-centric approach that also takes into account\nthe different steps of the collaborative social science\nresearch process (Schumann and Recker, 2013).\nRequired information about the social science research\nprocess includes how, when and why data was created\nand details of how it was processed and analyzed. In the\ncase of survey data intended to be preserved for re-use\nby quantitative social scientists who want to test\nhypotheses, it is required that contextual information\nsuch as the composition of the target population and\nthe selection of respondents is preserved as well as the\ndata itself (Recker and Mu\ngeotagged Twitter dataset, we are addressing a different\ntarget audience, namely computational social scientists\nas well as other social media researchers; a different\ntype of data, namely geotagged Twitter data; and\npotentially more diverse methodologies that we need\nto make allowances for. Not everyone may want to\ntest hypotheses and `kludginess' of methods is both\ncommon and required in internet-based research\n(Karpf, 2012). We have to consider the needs of the\nproducers and users of the archived dataset, as well as\nthe overall characteristics of this new type of dataset. In\nour example, contextual pieces of information that we\nneed to preserve in addition to the tweets themselves\nare shapefiles9 and the codes used for collection, clean-\ning and analysis. The codes together with the documen-\ntation also provide information about collection details\nsuch as time frames, geographic selection of tweets and\nassignment of states by geographic coordinates. In\nother cases, such necessary contextual information\nmay include, for example, explanations about the hash-\ntags used for collection. We will now take a closer look\nat our specific dataset and its properties before explain-\ning our approach to archiving it.\nThe dataset\nThe dataset used in this work consists of geotagged\nTwitter posts obtained by setting up our own data col-\nlection pipeline (see Figure 2). In this section, we out-\nline the methodology and tools used to collect these\ntweets.\nTargeting a specific dataset\nTo assemble the dataset used in this work, we collected\ngeotagged tweets from within the United States from 1\nfor the same time period in 2015. Tweets with geoloca-\ntion were selected within a geographic bounding box\nstates using a script. The tweet location was provided\nby the users who tagged their tweets using Twitter's\n`geolocation' feature: a feature that allows the user to\nleverage the latitude/longitude information from the\ndevice's GPS sensor to add location information to\nthe tweet. The geolocation could also be derived from\nthe wifi or IP addresses in the case of a tweet being\nauthored on a desktop or laptop computer. While wifi\nprovides a very accurate location with an average error\nIP address is rarely used in these cases. The geolocation\ninformation was thus accurate to the sub\u00adcity-block\nlevel and was provided in real time. Another benefit\nof this information source was that it came from the\nuser's current position and not from the user's profile\nlocation field. This gave us the benefit of timelines as we\ndid not need to rely on the user to change her location\nmanually in real time. It also gave us the benefit of\naccuracy. One drawback of this data outlet was that\nonly about 1% of all users chose to geolocate their\ntweets, making data from this outlet relatively sparse.\nA shift in location information\nIn April 2015, Twitter substantially changed the way\nusers shared their location. Users were still able to\npost their geolocation through the geotagging feature,\nbut they were now also prompted to tag their location\nwith the `place' where their tweet was produced.12\nBefore the change, the only information that was\nrevealed was the latitude/longitude pair indicating the\nlocation on Earth where the tweet was created. After\nthe change, the user chose the name of their location\nfrom a dropdown list thus allowing for a potentially\nricher dataset that could also include the place name\n(e.g., a coffee shop in New York City), an ID and in the\n6 Big Data & Society\ncase of larger places (e.g., cities), a geographic bound-\ning box. The downside of the `place' is that the infor-\nmation is prone to human error, may reflect whimsical\ndecisions and that it is much easier to add `wrong'13\nlocations. Our data collection script only collected the\ncoordinates field (i.e. the geolocation provided by GPS,\nwifi or IP address) as this was all that was available at\nthe start of the crawl. When Twitter unveiled the `place'\nfeature, we did not modify the crawler to collect it.\nHowever, as one can see in Figure 1, the change in\nthe way Twitter handled locations had a major\nimpact on the number of actual geotagged tweets in\nour sample. The overall number of tweets with geo-\ngraphic information went up due to the new geotagging\nfeature, and thus the data collection with the API got\nsampled more dramatically. Previously, collecting\ntweets with a geographic bounding box ensured a\nhigh sampling rate (Morstatter et al., 2013). This was\nno longer the case. While the change between the first\nand the second half of the data was obviously due to\nthis platform effect, the smoother change in the number\nof geotagged tweets happening between mid-August\nand mid-September 2014 cannot be explained at this\npoint.\nCollection methodology\nTwitter provides two API endpoints called the\n`Streaming APIs'.14 We collected the data using the\nFilter API, which provides tweets in real time. The\nFilter API allows to supply parameters that direct the\ncrawl. The API further allows for three types of para-\nmeters: keywords, usernames and geographical regions\nthat we wish to crawl. Geographic regions are provided\nas geographic bounding boxes in the form of a south-\nwest and northeast latitude/longitude pair.\nOnce these parameters are specified, the Filter API\nreturns the tweets immediately after they are produced.\nOne caveat is that the Filter API returns a sample of the\ntweets matching the parameters, at most 1% of all of\nthe data available on Twitter. We leveraged the API to\ncollect geotagged tweets originating within the United\nStates15 using the Twython16 library, a popular Python\nTwitter API interface. All of the collected data was\nstored in a MySQL database. Figure 2 shows the\nsteps involved in collecting and archiving the data.\nFirst, the query with the geographic bounding box is\nsent to the Filter API. The API returns the sample of\nthe matching tweets to the MySQL database used to\nstore the data. For archiving, we exported all Tweet\nIDs into separate text files for months and counties.\nFinally, these were compressed into ZIP-files to archive\nthem in datorium.\nArchiving the project dataset\nSo far we have explored (a) general practices in archiv-\ning research data, (b) general challenges of handling\nand archiving Twitter data and (c) the particular char-\nacteristics of our case study dataset composed of geo-\ntagged tweets. In the following, we are combining these\nthree dimensions and present our solution for archiving\ny\na\nD\nr\ne\np\ns\nt\ne\ne\nw\nT\nn\no\ni\nl\nl\ni\nM\nFigure 1. Number of tweets per day in our dataset.\nKinder-Kurlanda et al. 7\nthe dataset considering requirements from data archiv-\ning practice and Twitter specifics. For future research-\ners to use any archived dataset in a way that allows\nthem to assess its explanatory power in the context of\ntheir research question, the dataset and complementary\nmaterial need to be documented in such a way as to\nmake the exact circumstances of its origination trans-\nparent without overwhelming researchers with the level\nof detail of documentation. These two requirements\nneed to be balanced. A third requirement for archiving\nis that it occurs in accordance with legal and ethical\nframeworks, which also means to balance the obliga-\ntion for transparency and reproducibility with privacy\nconsiderations. Out of these three sets of requirements,\nwe can distill the following questions and answers that\nneed to be dealt with when archiving our dataset:\n1. What is required for archiving and sharing to occur\nlegally and ethically? We need permission to share all\ndata that the dataset is based on, for example, we\nneed to check usage agreements not only of the geo-\ntagged Twitter data but also of any additional data\nthat it is enriched with. In our case, this concerns the\nshapefiles, but it could be other information, for\nexample, census data. We also need to decide how\nto contend with the issues around privacy and miss-\ning informed consent.\n2. What is required for supporting reproducibility? We\nneed to document in detail how the dataset was con-\nstructed. For example, this includes information\nabout analysis scripts that show how we controlled\nfor longitude/latitude issues in the dataset. For\nreproducibility, we also need to archive the tweets\nexactly in the way in which they were used in a spe-\ncific study \u00ad which may not be the way in which the\ndata should be presented to make it easy to reuse it\nfor other new projects.\n3. What is required for allowing new questions to be\nasked of the data? We need to provide the data in a\nuser-friendly way so that it is easy to download and\nallows researchers to quickly assess its value for\nanswering different research questions. For example,\nwe may want to provide all tweets during a certain\nperiod or from a certain geographical area.\nSelecting an archival setup\nWe decided to archive the dataset via the datorium\nrepository at GESIS17 datorium is a light-weight shar-\ning platform for social science research data which\nenables researchers to deposit, document and publish\ntheir data (Wira-Alam et al., 2015). It thus allows\nresearchers across the world to upload and share their\ndatasets. The fact that it is hosted by a publicly funded\nresearch service institute guarantees that data is stored\nsecurely and persistently. For each dataset, datorium\nguarantees that it will be available for at least 10\nyears. Each uploaded dataset also receives a DOI\nwhich is persistent and unique and makes the dataset\ncitable and accessible. All metadata of the dataset are\nmade available via the DOI registration services da-ra18\nand DataCite19 by assigning the DOI to the datorium\ndataset. Our dataset is citable as Pfeffer and Morstatter\n(2016). datorium uses different access categories for\nresearchers to share the uploaded data. Consequently,\ndata may be openly accessible to everyone, accessible\nonly after registration, restricted to be accessed only\nafter the data depositor has accepted a request or acces-\nsible only after an embargo period. We chose to make\nour dataset accessible upon request after an embargo\nperiod.20 To request the data, researchers need to state,\namongst other information, their institutional affilia-\ntion and the topic of the planned research. The dator-\nium repository also allows choosing a license for the\ndataset, preferably one of the creative commons\nlicenses. Thus, researchers can ensure, for example,\nthat there is an attribution of their work or that\nFigure 2. Schematic of the collection pipeline.\n8 Big Data & Society\nusage is for scientific purposes only. Archive staff advise\non and eventually approve the level of access and licen-\nsing to ensure that sharing complies with legal and\nethical requirements. The datorium repository thus\nallows to control who has access to what data.\nArchive staff also apply (partially automated) checks\nof the quality and level of disclosiveness of the data\nto avoid accidental sharing of sensitive information.\nData aggregation and date/time information\nWe aggregated information extracted from tweets to\nthe level of US counties, of which there are 3108 in\nthe continental part of the United States (without\nAlaska, Hawaii and territories). The county-level\ninformation can later be aggregated to the state\nlevel. The grouping of tweets to counties was based\non the tweets' geolocation. Tweets are generated in\ndifferent time zones. If we want to aggregate and ana-\nlyze them on a daily basis, we need to make a decision\non whether to split the days at midnight in each time\nzone or for one specific time zone. We decided on the\nlatter as we were just covering tweets from four time\nzones and events most likely are discussed in real-time\nwithin these time zones. As a consequence, we stored\nall tweets in UTC time zone in the database when we\ncollected the tweets and subtracted 6 hours (\u00bc US\nCentral Time Zone) to decide on the day of a tweet.\nWe ignored daylight saving differences in time zones\n(e.g., Arizona).\nArchived data, code and shapefiles\nThe dataset itself was archived in the form of text files.\nThese files did not include any raw tweets, that is, not\nthe tweet text, user names, timestamps or other meta-\ndata usually provided through the API \u00ad and also not\nthe explicit geocodes from the tweets. Instead, we\narchived tweet IDs only in order to comply with the\nTwitter Terms of Service, which means that anyone\nwho wants to reuse the data will have to rehydrate\nthe tweets based on their IDs. To improve user friendli-\nness, we also archived some basic analysis results,\nnamely aggregated counts of hashtags. Overall, we\narchived 53 files (48 files with tweet IDs, two scripts\nand three help files) with about 21 GB of data in\nzipped files, organized as follows (for [date], we used\nthe month of data collection, six each in 2014 and\n. state_id_[date].zip: Text files per state for one day\nincluding IDs of geotagged tweets of the states.\n. county_id_[date].zip: Text files per county for one\nday including IDs of geotagged tweets of the\ncounties.\n. state_hash_[date].zip: Text files per state for one day\nincluding hashtag counts of geotagged tweets of the\nstates.\n. county_hash_[date].zip: Text files per county for one\nday including hashtag counts of geotagged tweets of\nthe counties.\n. state_codes.txt: US states mapped to two-digit\ncodes.\nWe hence published the tweet ID data in such a way\nthat it easily can be correlated with other data that is\navailable on the county level, for example, census data,\nhealth data, environmental data or other measurement\ndata. In order to understand collection and processing\nof the data, scripts and shapefiles were shared.\nSpecifically, we shared the Python script used for data\ncollection with the Twitter API and the Python script\nused for sorting geotags. In the documentation of our\ndataset, we also link to a Github page containing the\nPython scripts used for collection and analysis21 to\nallow for more interaction and feedback between\nresearchers. The county shapefile (with geo-polygone\ninformation of US counties) originated from the\nUnites States Census Bureau website,22 the other sha-\npefile (with geo-polygone information of US states cre-\nated from the county file) was created with the Dissolve\ngeo-processing tool in QGIS 2.6.1 Brighton (QGIS\nAlmost all potential uses of the dataset rely on the\n`rehydration' of the list of tweet IDs by the future user.\nTo lower the barriers to using the dataset, we offer\nassistance for rehydration in two ways: We archived\nin datorium a `Python Script to rehydrate Tweets\nfrom Tweet IDs'23 to retrieve tweets from the API.\nWe also link to the `Hydrator' tool in the documenta-\ntion.24 This tool also allows rehydration and its docu-\nmentation links to more information about the process\nof rehydration.\nA first step towards setting standards for\nfuture archiving\nWe were trying to improve best practice by setting an\nexample, but were limited in what we could accomplish\nin terms of setting actual standards for archiving social\nmedia data at the current point in time. Setting such\nstandards will require involving others, such as, for\nexample, the DDI community, other archives and\nresearchers working with different kinds of social\nmedia data. Nevertheless, our sharing solution in the\narchive satisfied the demands mapped out at the begin-\nning of this section.\nSharing legally and ethically. Sharing of the geotagged\ntweets occurred with legal requirements and ethical\nKinder-Kurlanda et al. 9\nconsiderations in mind. As described above, only tweet\nIDs and aggregated information (i.e. the counts of\nhashtags) are stored to comply with Twitter's require-\nments. The datorium system further allows us to retain\ncontrol over who has access to the data and for what\npurposes it will be used. There are still no standards for\nhandling the lack of informed consent from social\nmedia users who may also have certain privacy expec-\ntations. Archiving only tweet IDs addresses this issue to\na certain degree: Removing a tweet from Twitter also\nmeans that the tweet will be removed from future ver-\nsions of the dataset as deleted tweets cannot be rehy-\ndrated. Users therefore have at least some form of\ncontrol. However, we are still sharing information\nfrom users who may be unaware of being the target\nof research. This is why we decided to additionally con-\ntrol access to ensure that only researchers who we can\nexpect to adhere to common principles of research\nethics access the data. Each access request is decided\non individually based on the information provided in\nthe application (e.g., research topic, methods, etc.)\nAdditionally, the geolocation information may pose a\nparticular threat to privacy. Thus, while this feature\nneeds to be explicitly activated by users, we do not\nprovide detailed geoinformation in datorium \u00ad it can\nhowever still be accessed on Twitter itself once the\ntweets have been rehydrated. After some deliberation,\nwe decided that in the interest of replicability such a\nsolution would be acceptable, if not ideal. The\nshapefiles posed no issue as they can be used and\nshared in publications, as long as the US Census\nBureau is acknowledged as their source (which we\ndo). Our sharing solution thus aims to balance privacy\nrequirements and the (ethical) obligation to make\nresearch reproducible and comparable. We expect\nthat it will require deliberation and careful considera-\ntion for every individual social media dataset shared in\nthe future in order to find similar (and never ideal)\ncompromises that balance conflicting demands.\nSharing to ensure reproducibility and comparability. While\nnot all data is publicly available to everyone in our\nsolution (it is to researchers after request, though),\nthe detailed documentation of the dataset in datorium\nusing the DDI standard and the provision of code\nallows everyone to check how collection, cleaning and\nanalysis were performed. This applies to geographic\nand time coverage, technical infrastructures used for\ndata collection and assignment of geographic coordi-\nnates to US states. However, more detailed information\ncould only be described in a non-standardized way or\nnot at all due to the lack of metadata standards cover-\ning the specific tweet data type and related data collec-\ntion issues. Examples of such additional information\nrequired for reproducibility of geotagged Twitter data\nare: API biases (i.e. the API would only return a sample\nof respective tweets upon a specific query); changes in\ndata availability and formats (e.g., Twitter made\nchanges to its geotagging feature in the middle of\ndata collection); or explanations about code and\n(ready-made) scripts used in collection, cleaning and\nanalysis (in addition to the code itself).\nSharing to allow for new research projects. The data was\naggregated into easily downloadable, user-friendly\nunits containing tweet IDs of single months/days.\nAdditional aggregated information was added to\nallow other researchers to base new investigations\nupon the data. Standardized metadata (compatible\nwith DDI) for the whole dataset was created within\ndatorium to inform secondary users about the research\nmethods and context. The documentation includes\ninformation such as the title of the dataset, the primary\nresearchers, the dataset's availability (restricted), the\nsubject area, a topic classification, the collection\nperiod, notes, publications already made using this\ndataset and other information. A citation suggestion\nis also included. The usage of a DOI for citation of\nthe exact dataset in datorium enables unambiguous\nidentification of the data and should be considered a\nmajor benefit. We also shared a script to assist research-\ners in the process of rehydration.\nConclusion\nWe successfully archived a dataset of geotagged tweets\nthat can now be used in various ways: It can be used for\nsecondary research, that is, if researchers want to\naddress new research questions based on the existing\ndataset. This could, for example, be sentiment analyses\nof tweets per US state or content analyses of how cer-\ntain topics have been discussed across the United\nStates. The dataset can also be used to enrich other\nexisting datasets, such as survey data or statistical\ndata (e.g., surveys on internet usage or census data)\nor data from other social media platforms. It can also\nbe used for comparisons with other, similar datasets,\nfor example, tweets from other periods of time and for\ntesting reproducibility. The dataset is particularly inter-\nesting for studying the impact of platform effects on\nsocial media data as Twitter changed the way geo-\ntagged tweets were handled between the two time per-\niods of our data collection and as we witnessed different\nsampling effects of the API.\nOur dataset will be useful for researchers across sev-\neral disciplines, both for those who work with social\nmedia data to answer specific research questions and\nfor those who want to assess the quality of social\nmedia data in general. In addition, this particular data-\nset also is a use case of archiving that serves the more\n10 Big Data & Society\ngeneral purpose of establishing a routine for document-\ning and sharing social media data. We show that\nTwitter data can be archived in the form of meaningful\ncollections of tweet IDs, that is, stored as filtered by\nregion and time and enriched with documentation of\ncollection methods (via shared code, additional data\nsuch as shapefiles and metadata about the collection\nprocess). Assigning a persistent DOI to the dataset\nallows us to establish referencing standards. This and\nthe guaranteed availability for at least 10 years under-\nscore the official nature of this dataset. Restricting the\naccess to the dataset as well as storing only tweet IDs\nhelps to secure compliance with Twitter's Terms of\nService and users' privacy protection. Although this\nconstitutes significant achievements, there is more\nwork ahead and some open challenges remain.\nFirst of all, we cannot solve the challenge that tweets\ncan only be archived and shared in the form of tweet\nIDs, which means additional effort to rehydrate the\ntweets and data loss due to deleted tweets. For a\nresearcher accessing the data via the archive, it is\nimpossible to recreate the original dataset exactly.\nUnless Twitter changes its policy here (e.g., by allowing\nto save and share the entire tweet texts for research\npurposes), full reproducibility of a given dataset may\nnot become possible. In fact, sharing tweet IDs has just\nbecome more difficult: Twitter's new Terms of Service,\nin effect since June 2017, state that it is not allowed to\nexpress written permission of Twitter.25 Had these\nterms already been in effect in our case, it would not\nhave been possible to share our dataset without apply-\ning for an individual permission from Twitter \u00ad which\nthey may or may not have granted. It thus has become\neven more difficult to share data for the sake of research\ntransparency. However, researchers are also in constant\nnegotiation with Twitter about improving data sharing\noptions. For example, Twitter reacted to researchers'\nconcerns over the new Terms of Service by clarifying\nthat it would still be possible for researchers from\nSecond, possibilities for documentation of existing\nrepositories need to be extended and adjusted to fit\nboth traditional and novel requirements for reproduci-\nbility. As data can only be shared in very limited ways,\nthe sharing of other information and materials becomes\neven more important. For example, additional fields in\ndatorium to allow documentation of API bias, usage of\npopular scripts and social media platform functionality\nchanges and the points in time at which they occur\nwould improve future social media archiving projects.\nAs a next step, we will propose a draft of a metadata\nformat for social media data archiving to be discussed\nby the research community and by DDI practitioners in\norder to set a standard format. In addition to petition-\ning platform providers to allow more data sharing for\nresearch purposes, we see the sharing of additional\ninformation and materials as the most promising way\nto make social media research more transparent and to\nimprove its quality.\nThird, while we aimed to protect social media users'\nprivacy, we only achieved this to a certain extent and\nwe could not solve the issue of the lack of informed\nconsent. Our aim to protect privacy on the one hand\nand to make research reproducible and comparable on\nthe other forced us to compromise on both.\nWe see our attempt at archiving the Twitter dataset\nas a step towards establishing archiving best practice\nfor social media data. Due to the lack of standards in\nthis area, we followed well-established archiving stan-\ndards for survey data. While many of the steps per-\nformed in survey data archiving could be applied to a\nsocial media dataset (e.g., establishing significant prop-\nerties to be preserved for the long term), some had to be\nadapted (e.g., documentation of data collection proce-\ndures) as best as possible within the existing infrastruc-\ntures and conventions. Based on this experience, we\nsuggest the following requirements for future standards\nfor archiving social media data:\nTo ensure that others can understand or even repro-\nduce the process of constructing the initial dataset, var-\nious additional information and materials need to be\nprovided. This concerns programming code (scripts or\ncodes used for collection and cleaning), information on\nthe collection setup (APIs, software, services and hard-\nware used), information about time and place of the\ncollection, information about social media platform\nfunctionality changes and information on sampling\ncaused by the way the data is provided to researchers\n(e.g., the API). In addition, it should be best practice to\noffer assistance to other researchers who want to repro-\nduce the dataset, for example, by sharing a rehydration\nscript.\nTo ensure that issues of representativeness can be\naddressed, any available information on the specific\nuser groups as content providers needs to be\ndocumented.\nTo advance ethically reflective social media data\nsharing, it needs to be best practice to establish a care-\nfully considered balance between protecting user inter-\nests and ensuring research transparency that is also in\nadherence with the data provider's terms of service. The\nsharing of information and materials in addition to the\ndata needs to be facilitated to make it easier to find such\na balance. Sharing legally and ethically also means to\nfollow the changes and updates in terms of services and\npolicies and to participate in negotiations about data\nsharing for the sake of reproducibility with platform\nproviders.\nKinder-Kurlanda et al. 11\nFinally, it remains to be seen how much of the prac-\ntices described here can be transferred to datasets col-\nlected from other social media platforms. In the\nmeantime, researchers who study alternative social\nmedia platforms may profit from archived Twitter\ndatasets as a source for enabling cross-platform studies.\n"
}