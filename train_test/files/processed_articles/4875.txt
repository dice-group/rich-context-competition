{
    "abstract": "Abstract\nVisually induced illusions of self-motion are often referred to as vection. This article developed and\ntested a model of responding to visually induced vection. We first constructed a mathematical model\nbased on well-documented characteristics of vection and human behavioral responses to this illusion.\nWe then conducted 10,000 virtual trial simulations using this Oscillating Potential Vection Model\n(OPVM). OPVM was used to generate simulated vection onset, duration, and magnitude responses\nfor each of these trials. Finally, we compared the properties of OPVM's simulated vection responses\nwith real responses obtained in seven different laboratory-based vection experiments. The OPVM\noutput was found to compare favorably with the empirically obtained vection data.\nCorresponding author:\nTakeharu Seno, Faculty of Design, Kyushu University, 4-9-1 Shiobaru, Minami-ku, Fukuoka 815-8540, Japan.\nEmail: seno@design.kyushu-u.ac.jp\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License\n(http://www.creativecommons.org/licenses/by/4.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sage-\npub.com/en-us/nam/open-access-at-sage).\ni-Perception\njournals.sagepub.com/home/ipe\n",
    "reduced_content": "Article\nThe Oscillating Potential\nModel of Visually\nInduced Vection\nTakeharu Seno\nFaculty of Design, Kyushu University, Minami-ku, Fukuoka, Japan\nKen-ichi Sawai\nGraduate Schools for Law and Politics, The University of Tokyo,\nBunkyo-ku, Tokyo, Japan\nHidetoshi Kanaya\nFaculty of Human Informatics, Aichi Shukutoku University, Nagakute-shi,\nAichi, Japan\nToshihiro Wakebe\nFaculty of Human Relations, Fukuoka Jo Gakuin University, Minami-ku,\nFukuoka, Japan\nMasaki Ogawa\nFaculty of Design, Kyushu University, Minami-ku, Fukuoka, Japan\nYoshitaka Fujii\nResearch Organization of OIC, Ritsumeikan University, Ibaraki, Osaka,\nJapan\nStephen Palmisano\nUniversity of Wollongong, Wollongong, NSW, Australia\n Keywords\nvection, latency, duration, magnitude, index, model\nIntroduction\nWhen a large area of the visual field is stimulated by coherent motion, stationary observers\noften (illusorily and incorrectly) perceive that they themselves are moving (typically in\nthe opposite direction to the stimulus motion). This type of visually induced illusion of\nself-motion has traditionally been referred to as ``vection'' (e.g., Dichgans & Brandt, 1978;\nhowever, see Palmisano, Allison, Schira, & Barry, 2015, for other alternative uses of this term\nin the context of self-motion perception). While there are considerably earlier documented\nobservations of vection,1 the first systematic experimental examinations of this phenomenon\nonly appeared in print in the early 1970s. Following Brandt, Dichgans, and Koenig's (1973)\nseminal paper, hundreds of vection studies have since been published. A recent PubMed\nsearch for the term vection produced 358 papers and book chapters (search conducted on\nthe 19th August, 2017). Of these vection articles, there have also been several major reviews\nof this literature, including comprehensive reviews of the early vection research (see Dichgans\n& Brandt, 1978; Howard, 1982), as well as later reviews of more recent vection developments\n(e.g., Hettinger, Schmidt, Jones, & Keshavarz, 2014; Palmisano, Allison, Kim, & Bonato,\n\u00a8 ljama\nDue to recent improvements in virtual reality and self-motion simulation technology,\nvection is now becoming an increasingly popular topic of research. For example, one\nparticularly active area of vection research is the investigation of potential relationships\nbetween visually induced vection and visually induced motion sickness (e.g., D'Amour,\nreview). However, despite the recent upsurge in scientific research on vection, there have\nbeen comparatively few attempts to mathematically model the phenomenon itself (see\nJu\n\u00a8 rgens, Kliegl, Kassubek, & Becker, 2016; Zacharias & Young, 1981, for two exceptions;\nboth models were focused on explaining the onset latency of visually induced illusions of self-\nrotation, known as circular vection). This article seeks to remedy this situation by developing\na mathematical model of how observers respond to visually induced vection. Specifically, this\nmodel is aimed at explaining how the (objective) state of vection might be translated into the\nobserver's (subjective) vection ratings and other reporting behaviors. Thus, the model must\nbe able to capture both the reported characteristics of the vection time course (its reported\nonset latency, its reported duration, the occurrence of reported dropouts, etc.) as well as the\nkey aspects of its reported subjective experience (such as its reported strength or intensity).\nWhile vision is not the only modality that can induce illusions of self-motion (see also\nauditory, haptokinetic, arthokinetic, and biomechanical vection),2 the majority of studies\nconducted to date have investigated visually induced self-motion (see Palmisano et al.,\n2015, for a recent review). Traditionally, this ``visual'' vection research has examined how\ndifferent visual stimulus parameters affect the onset, strength, and speed of the vection\nexperience (see Riecke, 2010). However, more recent research has also begun to examine\nhow visually induced vection is influenced by cognitive factors (e.g., Lepecq, Giannopulu, &\nBaudonniere, 1995; Riecke, Schulte-Pelkum, Avraamides, von der Heyde, & Bu\nand the simultaneous stimulation of the nonvisual self-motion senses (e.g., Keshavarz,\nHettinger, Vena, & Campos, 2014; Riecke, Va\n\u00a8 ljama\ncurrently have a much greater understanding of visually induced vection, this article focusses\nspecifically on developing a mathematical model for visually induced vection. From this point\non in the article, we will refer to ``visually induced vection'' simply as ``vection.'' As the few\npast models have focused primarily on circular vection, we have instead chosen to focus on\nlinear vection in the present article--as research on illusory self-translation has increased\ndramatically in recent years with the use of computer-generated vection studies. Accordingly,\nthe model will be developed based on well-documented observations about responses to\nlinear vection, and then tested using empirical response data obtained in seven recent\nexperimental studies examining different types of linear vection.\nIn past studies, three characteristics of vection responding have been repeatedly observed:\n(a) there is a finite delay of 1 to 10 s after display motion begins before vection onset is first\nreported, (b) there is then an increase in reported vection strength over time until reported\nvection strength eventually plateaus, and (c) vection dropouts are often reported after the\ninitial vection induction and before the display motion ceases (e.g., Dichgans & Brandt, 1978;\nHoward, 1982; Riecke, 2010). As the vection-inducing motion stimuli used in these studies\ntypically had constant speeds and were presented continuously, these characteristics of\nhuman vection responding suggest that subjective experiences of vection are both unstable\nand oscillatory. The past research also indicates that there can be substantial individual\ndifferences in vection responding to the same inducing stimulus (in terms of both reported\nvection strength and reported vection time course). Thus, we aimed to incorporate all of these\naspects of human vection responding into our mathematical model.\nIn principle, there are many potential benefits of creating a viable model of vection\nresponding. Using such a model, large numbers of conditions can be investigated as the\noutputs of millions of simulated trials can be generated easily. By varying the internal\nparameters of our model, we aimed to simulate the substantial individual differences in\nhuman responding observed in past vection experiments. If successful, these model\nsimulations should reveal important insights into (a) the origins of these individual\ndifferences in reporting or responding and (b) the processes or mechanisms involved in\nboth consciously experiencing and responding to vection. This in turn should suggest new\nfuture directions for human vection research. In the past, the construction of mathematical\nmodels for vision science has led to increased research activity into, and improved\nknowledge of, many different types of perceptual phenomena (such as motion perception\nand surface perception--see Adelson & Bergen, 1985; Motoyoshi, Nishida, Sharan, &\nThis article will focus on developing a mathematical model of responding to visually\ninduced vection: The Oscillating Potential Vection Model (OPVM). There are no specific\nsensory input variables included in the model. The model instead includes a general\nparameter representing the inducing potential of the optic flow. The focus of the model is\ntherefore on generating the following three vection response outputs (similar to those\nobtained in most typical laboratory experiments) based on this simulated inducing\nstimulus: (a) vection onset latency, (b) simulated vection duration, and (c) vection\nstrength. To investigate the limitations of the model and to further refine it, we also tested\nour model by comparing the simulated onset latency, duration, and magnitude responses\ngenerated by the model to equivalent responses obtained from human observers in real\nvection experiments.\nThis model investigates the processes underlying vection responding to visual motion\nstimulation. Vection is typically induced by large patterns of optical flow. However, the\nmodel is not focused on relationships between physical modulations of this optic flow and\nSeno et al. 3\nthe objective experience of vection, but instead it focusses on how the reported subjective\nexperience of vection might be generated.\nConstructing the Mathematical Model\nThe mathematical model was constructed to conform to the following well-documented\nproperties of vection responding:\nProperty 1: There will always be a finite delay between the start of the visual motion\nstimulation and the onset of vection (e.g., Brandt et al., 1973; Bubka, Bonato, &\nPalmisano, 2008; Dichgans & Brandt, 1978). During this initial period in the trial, the\nobserver typically perceives the optic flow as being entirely due to object motion. Vection\nonset latency is thought by many to represent the time it takes to resolve sensory conflicts\ngenerated by presenting optic flow displays to physically stationary observers (Ju\n\u00a8 rgens et al.,\n& Troje, 2017; Zacharias & Young, 1981). Since the vestibular stimulation which would\nnormally accompany this type of visual self-motion information is absent, this visual-\nvestibular conflict is proposed to cause the observed delay between the start of visual\nmotion stimulation and the first report of vection. However, this vection onset latency\nmight also represent the time it takes to suppress the default visual processing responsible\nfor object motion perception, prior to the actual induction of vection (e.g., Palmisano, Barry,\nProperty 2: After the initial onset of vection, the observer first perceives a mixture of\nobject-and-self-motion before he or she eventually experiences exclusive self-motion\n(known as vection saturation--see Dichgans & Brandt, 1978). As a result, vection\nmagnitude generally builds toward a plateau over the course of the trial (e.g., Apthorp &\nProperty 3: Vection can ``dropout'' after induction--particularly when the induced vection\nis weak or ambiguous. It is common in these situations for the observer to experience a\nperceptual alternation between vection (ON) and nonvection (OFF) periods (e.g., Brandt\nAny model of vection responding must therefore be capable of simulating both supra- and\nsubthreshold vection experiences during continuous periods of visual motion stimulation.\nAccordingly, OPVM includes a threshold () that demarks ON and OFF vection periods (ON\nperiods occur whenever the modeled response exceeds the threshold for reporting a conscious\nexperience vection).\nVection response output at time t during the trial (i.e., V t\n\u00f0 \u00de) is described by the following\nformula (with 1 and 0 representing ON and OFF vection periods, respectively):\nV t\n\u00f0 \u00de \u00bc\n\u00f0 \u00de ! \n0 otherwise\n\nwhere v t\n\u00f0 \u00de describes internal state regarding the potential for the participant to experience\nvection, and  is the threshold for reporting a conscious experience of vection.\nWe also employed a function vtrend t\n\u00f0 \u00de that increased this potential gradually over time\n(to satisfy aforementioned Properties 1 and 2), as well as a periodic function voscil\u00f0t\u00de (to satisfy\naforementioned Property 3):\nv t\n\u00f0 \u00de \u00bc vtrend t\n\u00f0 \u00de \u00c1 voscil t\n\u00f0 \u00de\nDirectly after the start of the stimulus motion \u00f0t \u00bc 0\u00de, the vection response output V t\n\u00f0 \u00de\nshould be 0 (i.e., only object motion should be perceived at this time). v\u00f0t\u00de should then\nincrease over time, eventually starting to plateau following expected vection saturation.\nThus, we set the function vtrend t\n\u00f0 \u00de as follows:\nvtrend t\n\u00f0 \u00de \u00bc 1 \u00c0 exp \u00c0t\n\u00f0 \u00de\nwhere the parameter  controls the latency to vection onset through vtrend t\n\u00f0 \u00de.  depends on\nvisual motion stimulation S (which is regarded as the inducing potential of the optic flow).\nWhen there is no visual motion stimulation (S \u00bc 0), then \u00f00\u00de will be 0. However, when a\nvection inducing motion stimulus is presented (S 4 0), then  S\n\u00f0 \u00de 4 0. S and \u00f0S\u00de both\nincrease with the vection inducing potential of the optic flow (e.g., they should increase as\nthe size of the optic flow pattern increases--Dichgans & Brandt, 1978). As \u00f0S\u00de increases, the\nacceleration rate of vtrend\nalso increases, which should result in shorter onsets and stronger\nmagnitudes of vection responding. This is how the relationship between the visual motion\nstimulation and vection responding was incorporated into the model.\nTo model the alternation between ON and OFF vection reporting periods, we used a\nsimple sinusoidal function:\nvoscil\u00f0t\u00de \u00bc\nsin\u00f02t=T\u00de \u00fe \nwhere T is the period of the oscillation during the plateau phase and  controls the value of\nthe oscillation center. To perceive optic flow as being due to self-motion, it has been\nspeculated that the system would need to first inhibit the default visual processing which is\nresponsible for normally perceiving object or scene motion (e.g., Palmisano, Barry, De Blasio\n& Fogarty, 2016). The  and T values in this model control the oscillation between ON and\nOFF vection responding. It was proposed that they might represent the degree of inhibition\nof object motion processing (so as to instead favor self-motion processing) and the amount of\ntime such inhibition is successful over the course of the ``trial,'' respectively.\nOur mathematical model of vection (OPVM) was thus created by multiplying these\ntwo functions, vtrend t\n\u00f0 \u00de and voscil t\n\u00f0 \u00de. An example of the behavior of this model can be seen\nin Figure 1. The equation is able to satisfy all three of the vection properties identified\npreviously in Constructing the Mathematical Model section. Values of vtrend t\n\u00f0 \u00de and\nvoscil\u00f0t\u00de can range from 0 to 1. The internal potential v\u00f0t\u00de is therefore also able to vary\nModeling Empirically Observed Individual Differences\nIn this section, we will introduce and explain our mathematical model. Each parameter\ninvolved in the model (, , T, and ) is important in determining the subjective vection\nresponse output (V\u00f0t\u00de). Figure 2(a) shows the simulated internal potential and resulting\nvection response output when the values of , , T, and  are 0.1, 3, 10, and 0.6,\nrespectively. As  increases from 0.1 to 1 in Figure 2(b), the simulated vection onset\nlatency can be seen to decrease. When  is reduced from 3 to 1.2 in Figure 2(c), the\nduration of the ON periods are reduced (e.g., compared with Figure 2(a)). The value of T\ncan also be seen to affect the duration of ON and OFF periods. As T increases from 10 to 20,\nthe initial ON duration increases and the frequency of switching between ON and OFF\nperiods decreases (see Figure 2(d)). By modifying the values of these parameters, it should\nSeno et al. 5\ntherefore be possible to model empirically observed individual differences in human vection\nresponding.\nChoosing the Vection Indices to Model\nWe next used OPVM response output to reconstruct the typical vection indices obtained in\nhuman laboratory experiments. In the past, the three most commonly employed measures of\nvection3 obtained in such studies have been (a) the latency to vection onset (i.e., the delay\nbetween the start of the visual motion stimulation and the observer's first reported experience\nof illusory self-motion), (b) the total duration of the vection (i.e., the total amount of time that\nthe observer reported experiencing vection during the trial), and (c) magnitude estimates or\nratings of the vection experience (e.g., verbal ratings using a linear scale from 0 \u00bc no vection\nto 100 \u00bc very strong vection) (see Figure 3).\nIn our review of the recent literature, we found more than 50 papers where all three of\nthese measures were obtained in the same experiment (see Allison, Ash, & Palmisano, 2014;\nApthorp & Palmisano, 2014; Bonato & Bubka, 2006; Bonato, Bubka, Palmisano, Phillip, &\nFleet, & Potechin, 1998; Guterman, Allison, Palmisano, & Zacher, 2012; Keshavarz et al.,\nThompson, Riecke, & Bu\nFigure 1. The Oscillating Potential Vection Model (OPVM). The horizontal black arrows indicate ``TIME'' from\nthe stimulus onset. The black fluctuating sinusoidally curved line indicates the simulated internal state of the\nparticipant over time. Whenever this curved line exceeds the threshold indicated by the green dashed line,\nvection will be reported (the onset of reported vection can therefore be estimated as the first time the curved\nline cuts the threshold). The tan boxes in the figure indicate ``with vection periods.'' Thus, the total size of these\nsaw-toothed tan areas can be converted into an estimate of the overall vection magnitude for the trial.\nPalmisano, & Ito, 2011; Seno, Palmisano, Ito, & Sunaga, 2012; Shirai, Imura, Tamura, &\nGonza\nFigure 2. Examples of OPVM behavior with different , , T, and  parameter sets. The horizontal and vertical\naxes are time and the value of v\u00f0t\u00de, respectively. The simulated participant experiences vection when v t\n(indicated by bold lines on the horizontal axes). Please see the main text for descriptions of a)-d) above.\nFigure 3. A schematic illustration of the three vection measures: latency, duration, and magnitude.\nThe horizontal black arrow indicates ``TIME'' between the onset and offset of the stimulus presentation.\nBoxes 1, 2, and 3 indicate ``with vection periods'' and the spaces between them indicate ``vection dropouts''.\nSeno et al. 7\nWhile other studies did not obtained all three measures together, most obtained at least one\nor more of them4 (e.g., Allison, Zacher, Kirollos, Guterman, & Palmisano, 2012; Andersen &\n\u00a8 rgens,\nHoward & Heckmann, 1989; IJsselsteijn, de Ridder, Freeman, Avons, & Bouwhuis, 2001;\nAllison, & Howard, 2006; Palmisano, Apthorp, Seno, & Stapley, 2014; Palmisano, Bonato,\nPalmisano, Riecke, & Nakamura, 2015; Tanahashi, Ujike, & Ukai, 2012; Tarita-Nistor,\nGonza\n\u00b4 lez, Markowitz, Lillakas, & Steinbach, 2008; Telford & Frost, 1993; Telford, Spratley,\nIn these laboratory studies, the human observers were exposed to patterns of optic flow.\nThen, they typically had to press a button when they first experienced vection and hold this\nbutton down as long as this experience continued (releasing the button if the vection\n``dropped out'' and pressing it again if the experience returned). The observers would then\nalso typically provide a magnitude rating of the vection experience for that trial after the\ndisplay motion had ceased.5\nReconstructing Vection Onset, Duration, and Magnitude From OPVM Response Output\nWe next used the OPVM response output to reconstruct each of these vection measures\n(onset, duration, and magnitude). Since a conscious vection experience occurs whenever\nv\u00f0t\u00de ! , the first instance of v\u00f0t\u00de !  in a simulation trial was used as the onset of vection.\nThe total duration of vection was then calculated by summing all of the times in the\nparticular simulation trial when v\u00f0t\u00de ! . And finally, an estimate of the vection magnitude\nfor the trial was calculated by integrating the area that the v\u00f0t\u00de function covers above the\nthreshold line.\nTesting OPVM\nTo investigate OPVM, we next conducted a large-scale virtual vection experiment. The three\nsimulated response measures (onset latency, duration, and magnitude) were generated for\neach of the trials in this virtual experiment. Afterward, we compared this simulated response\ndata with real data obtained previously in seven different vection experiments.\nVirtual Vection Experiment\nOPVM was used to simulate a virtual vection experiment consisting of 10,000 trials. The aim\nwas to generate vection onset, duration, and magnitude response data which displayed\nindividual differences similar to those commonly seen in human participants (i.e., due to\ntheir different sensitivities to vection, different response biases, etc.). To this end, the values\nof each parameter used in the simulation were randomly drawn from uniform\ndistributions--except for , which was drawn from a log-uniform distribution for each\nvirtual trial. These uniform (other than ) and log-uniform (in the case of )\n1 for . While  was free to span all possible values between 0 and 1, the ranges of  and T\nwere determined during earlier pilot simulations. The value of  was chosen from a log-\nuniform distribution since this parameter has an exponential effect on the behavior of v\u00f0t\u00de.\nThe size of  was limited, because at larger values, there would be no simulated vection\ndropouts (i.e., instead, the range of  we chose allowed for possible perceptual alternations\nbetween vection ON and OFF periods).\nResults of the Virtual Experiment\nThe vection onset, duration, and magnitude data generated by OPVM for each of the 10,000\nsimulated trials is shown in Figure 4. These data are plotted as the correlations between (a)\nvection latency and magnitude, (b) vection duration and magnitude, and (c) vection latency\nand duration.\nHigh correlations were found between all three of these simulated vection indices. In this\nanalysis, ``no vection'' responses were treated as having a duration of 0 s and an onset latency\nduration\nlatency\nlatency\nmagnitude\nduration\nlatency\nmagnitude\nduration\nmagnitude magnitude\nduration\nlatency\nFigure 4. The top three panels show the relationships between the virtual vection onset, duration, and\nmagnitude responses generated by OPVM (only the first 1,000 of the total 10,000 trials are shown here for\nthe sake of visibility). Significance levels are all p <.001. The bottom three panels show their corresponding\nheat maps. Intensity indicates the density of data points (i.e., brighter cells include more data points).\nSeno et al. 9\nof 40 s. In trials where vection was experienced, the sum of the onset and duration values was\nalways less than 40 s (since there was always a finite delay before vection was experienced and\nmotion stimulation only lasted 40 s). This is the reason that no data points appear in the\nupper right field of the latency-duration plot (Figure 4). Thus, these latency and duration\ndata were not fully independent of each other (they were at least partially methodologically\ndependent on each other).\nOPVM Performance Compared With Laboratory Vection Data\nTo further test the model, we next compared the simulated vection data (discussed in the\nTesting OPVM section) with real vection data obtained in seven different laboratory\nexperiments. This real data consisted of human vection onset latency, duration, and\nmagnitude responses. The details of these laboratory experiments are described in the\nfollowing subsections.\nLaboratory Experiments\nFive out of these seven laboratory experiments had been published as scientific articles (in\neither English or Japanese--see Ogawa, Ito, & Seno, 2015; Ogawa & Seno, 2016; Ogawa,\nKanaya, 2016). The remaining two experiments have yet to be published as papers.\nHowever, they have been both presented at international conferences (ICP: Ogawa, Seno,\nHuman participants. These experimental data were obtained from 107 different individuals\n(who were undergraduate students, graduate students, as well as staff and faculty members\nof Kyushu University). Participants reported no health issues at the time of testing. They had\neither normal or corrected to normal vision and no history of vestibular system diseases.\nWhile some of the authors of this article were participants, they did not know the purpose of\nthese studies at the time of testing. Written informed consent was obtained from all\nparticipants prior to testing.\nApparatus. The vection stimuli were generated by and controlled via computers (MacBook\nPro, MD101J/A, Apple Inc., Cupertino, CA; or ALIENWARE M18x, Dell Inc., Round\nPanasonic Corporation, Osaka, Japan) which had a resolution of 1920 \u00c2 1080 pixels and a\nrefresh rate of 60 Hz. These experiments were all conducted in a dark room and participants\nalways sat on a rocking chair to enhance their vection experience. No chin-rests or head-rests\nwere used. Viewing distance to the display was held constant at approximately 57 cm across\nall of these experiments.\nStimuli. Two different types of experimental stimulus displays were used. In some\nexperiments, a radially expanding optic flow stimulus was used, whereas in the remainder,\na vertical optic flow stimulus was used. In both cases, these visual motion displays subtended\na visual area of 100 (horizontal) \u00c2 80 (vertical) degrees2 and the stimulus motion always\nlasted 40 s. The stimulus motion completely filled the display. Thus, the size of the\nstimulus and the display were approximately the same. The radially expanding pattern of\noptic flow consisted of white dots (38 cd/m2) presented on a black background (0 cd/m2).\nThis display simulated forwards self-motion in depth at 16 m/s relative to a 3D cloud of\n16,000 randomly positioned dots (see Figure 5, Top). As individual dots disappeared off the\nedges of the screen, they were moved back in depth to the far depth plane, thereby creating an\nendless optic flow display. Approximately 1,240 dots were visible in each frame, with each dot\nsubtending a visual angle of 0.03 to 0.05 (their size remained constant as their simulated\ndistances from the observer changed). Since these dots did not form a density gradient,\nmotion perspective was the only cue to motion in depth. The second stimulus display\npresented the constant upward motion of a black grid (0 cd/m2) on a uniform white\nbackground (38 cd/m2)--it simulated downward self-motion at 18/s (see Figure 5,\nBottom). One side of each square in this rectangular grid subtended approximately 8 in\nvisual angle.\nProcedure. Participants observed these vection-inducing stimuli while sitting on a rocking\nchair inside a dark viewing chamber. Their task was (a) to press a button when they first\nexperienced illusory self-motion and (b) to keep this button depressed as long as the\nexperience continued (which provided data about both the onset latency and the duration\nof vection). After each stimulus presentation, they also had to report the subjective strength\nof their vection experience using 101-point rating scale (from 0 \u00bc no vection to 100 \u00bc very\nFigure 5. Schematic illustrations of the two types of stimuli used in the experiments in this article. (Top)\nRadially expanding optic flow. (Bottom) A vertically moving grid pattern.\nstrong vection). Each stimulus display condition was repeated four times in each experiment.\nThe 317 data sets used in this analyses were the result of testing 1,268 discrete vection trials.\nEach of the individual data sets consisted of the average onset, duration, and magnitude\nvalues obtained for a single subject in one experiment.\nResults\nLaboratory vection data. Correlational analyses were conducted on 317 discrete sets of\nlaboratory-obtained vection data. Figure 6 shows the relationships between the three\ndifferent vection measures. All combinations of these measures were found to generate\nsignificant correlations (latency\u00admagnitude, R (317) \u00bc \u00c0.55, p < .001; duration\u00admagnitude,\nthree correlation coefficients were significantly different to each other (z \u00bc 2.13, p \u00bc .03,\nmagnitude, duration-magnitude and latency-duration, and latency-magnitude and latency-\nduration). Magnitude ratings were found to account for 30% of the variability in vection\nonset latency and 44% of the variability in vection duration. The strongest relationship was\nfound for the two time course measures--with vection duration accounting for $62% of the\nvariability in vection onset latency responses. The strength of this relationship between\nvection onset and duration was presumably due in part to the unavoidable trade-off\nbetween the two time course measures (as vection onset latency increased, vection duration\nlatency\nlatency\nmagnitude\nduration\nlatency\nmagnitude\nduration\nmagnitude magnitude\nduration duration\nlatency\nFigure 6. The top three panels show the vection onset, duration, and magnitude responses obtained in the\nseven laboratory experiments. The bottom three panels show their corresponding heat maps. Intensity again\nindicates the density of data points (i.e., brighter cells include more data points).\ntypically decreased. As noted earlier, these latency and duration data were at least partially\nmethodologically dependent on each other).\nComparison of OPVM and laboratory results. When we compared the corresponding virtual and\nlaboratory vection data with each other, we noticed a number of similarities in their\ndistributions. To better visualize these similarities between OPVM-generated and human\ndata, we superimposed data points from our earlier virtual (Figure 4, Top) and laboratory\n(Figure 6, Top) plots--thereby creating the new Figure 7.6\nThis new figure depicts the relationships between latency and magnitude, magnitude and\nduration, as well as latency and duration for the OPVM and laboratory-based vection\nresponse data. Both the OPVM and human data were found to produce (a) significant\npositive relationships between magnitude and duration (R \u00bc .87 and R \u00bc .66, respectively),\n(b) significant negative relationships between magnitude and latency (R \u00bc \u00c0.56 and R \u00bc \u00c0.55,\nrespectively), and (c) significant negative relationships between latency and duration\nOPVM also appeared to be successful in generating substantial variability in the\nresponding. Indeed, this variability in responding appeared to mimic (at least superficially)\nsome of the individual differences seen in the human responding. However, OPVM's\nresponding appeared to be less variable than the human responding. These discrepancies\nin response variability appeared to be more obvious in the latency versus magnitude\nand the duration versus magnitude plots (compared with the latency versus duration plot).\nThese discrepancies will be discussed in detail later.\nDiscussion\nIn this article, we developed and tested a model of responding to visually induced vection, the\nOPVM. OPVM was constructed based on three well-documented properties of the vection\nexperience: (a) that there is a finite delay before the reported onset of vection, (b) that there is\na subsequent increase of reported vection magnitude over time until vection responding\neventually plateaus, and (c) that vection dropouts are reported to occur (after vection\ninduction and before the display motion ceases). Next, in our 10,000 virtual trial\nsimulation experiment, we attempted to model not only these three properties of vection\nbut also commonly observed individual differences in vection responding (by altering the\nvalues of key parameters of OPVM: , , T, and ). Vection onset latency, duration, and\nFigure 7. Comparisons of OPVM's simulated data (blue) with the empirical data (red) obtained in the\nlaboratory vection experiments.\nmagnitude estimates were reconstructed (based on the OPVM response outputs) for each\nvirtual trial. Finally, we compared the performance of our model with the results of previous\nlaboratory studies which obtained the same vection measures. Statistical analyses of the real\nand model-based vection data indicated that all three measures correlated significantly with\neach other.\nOur results demonstrate that both overall and specific vection responding (including\nindividual differences) can be described quite well by OPVM. However, there also\nappeared to be some notable inconsistencies between the real and simulated vection\nresponse data. These can best be seen in the Latency-Magnitude correlation (Figures 7,\nLeft) and the Duration-Magnitude correlation (Figure 7, Middle) plots. In the latter case,\nmagnitude ratings appeared to be considerably larger for longer vection durations during\nsimulation, whereas the equivalent relationship between magnitude and duration was\nnoticeably weaker for the real vection data. We speculate that this particular\ndiscrepancy might reflect idiosyncrasies in human responding rather than potential\ninadequacies of OPVM. During the vection experiments, participants observed each\nvisual motion display for 40 s and only provided their magnitude ratings after the\ndisplay motion ceased. It is likely that the magnitude ratings made by our human\nparticipants did not accurately reflect the average strength of their vection experience\nacross the entire trial but instead were biased by stronger vection experiences they had\ntoward the end of the trial. If this explanation is valid, then this real versus simulated\nvection data discrepancy might reflect a recency effect.7 Future work should thus be aimed\nat incorporating such human response characteristics (particularly those common when\nmaking perceptual judgments) into OPVM.\nTo better understand and predict the conscious experience of vection, OPVM will need to\nbe further developed and refined. In the current version of OPVM, we utilized sinusoidal and\nexponential functions in an attempt to model the experience of vection. However, these are\nrather simple mathematical functions. It is likely that more complex mathematical functions\nmay be required to improve the model (e.g., it is highly likely that temporal changes in both\nhuman perception and responding may be different from the sinusoidal changes currently\nincorporated into OPVM). This will undoubtedly require further empirical investigations of\nvection (obtaining new data by using different display manipulations and other measurement\nmethods). For example, several previous studies have had participants press different buttons\nthat correspond to the subjective magnitude of the vection they are experiencing at the time\n(no vection, weak, modest, and strong) and then examined the total amount of time that each\nof these buttons was depressed during the trial (e.g., Mohler et al., 2005; Riecke et al., 2006,\nYamaguchi, & Shinoda, 2015). The accumulation of these magnitude values over entire\nstimulus presentation period was then used to assess the overall vection experience. Other\nstudies have used joysticks, slider devices, or levers to collect continuous ratings of vection\nmagnitude over the entire course of each trial (e.g., Apthorp, Nagle, & Palmisano, 2014;\nWeech & Troje, 2017). By employing similar methods, we might be able to analyze the\ntendencies of the temporal change in vection strength more precisely and incorporate the\nresults into OPVM. Vection strength and time averaging should therefore be further\nexamined in future.\nAs noted earlier, another potential issue with the current investigation was that the latency\nand duration data (both reported in seconds) were not fully independent of each other.\nAs in the majority of past laboratory studies, these data were at least partially\nmethodologically dependent on each other (because the trial duration was fixed; therefore,\nlonger vection onsets would be more likely to be associated with shorter vection\ndurations--even factoring in the possibility of subsequent vection dropouts). An\nalternative way to examine the relationships between these temporal vection measures\nmight be to recode the latter duration measure as a percentage of the time that vection\nwas experienced as a function of the entire stimulus presentation period (as has been\nrecently suggested by Keshavarz et al., 2017). For example, a vection experience lasting\n30 s during a 40-s stimulus presentation period would be recoded as a % duration value of\n75. Reexamining our model with this and other alternative vection response measures should\ntherefore also be a future task for us.8\nFurthermore, vection is not restricted to vision, but vection can also be induced by\nstimulating other sensory modalities, for example, auditory vection (e.g., Va\n\u00a8 ljama\n\u00a8 e & Sell,\n\u00a8 ljama\n\u00a8 e, 2009, for review) and cutaneous vection (Murata, Seno, Ozawa, & Ichihara,\n2014). In the development of OPVM, only the properties of visually induced vection were\nconsidered. However, there are similarities between the vection experiences induced by visual\nand other perceptual modalities. Thus, it is possible that the model could be applied or\nextended to vection induced by other nonvisual modalities.\nAlthough the OPVM has room for improvement as noted earlier, the current version is\ncapable of describing the reported experience of vection quite well (despite its rather\nsimplistic component functions). OPVM therefore has the potential to be a useful tool in\nunderstanding both the overall and specific experiences of vection.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or\npublication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or\npublication of this article: This work was supported by the Program to Disseminate Tenure Tracking\n(Grants-in-Aid for Young Scientists B and Scientific Research C) to H.K., from Ministry of\nEducation, Culture, Sports, Science and Technology of Japan. Part of this work was carried out\nunder the Cooperative Research Project Program of the Research Institute of Electrical\nCommunication, Tohoku University.\nNotes\n1. For example, Helmholtz (1867/1925) reported vection that he experienced while viewing a quickly\nmoving river from above on a bridge.\n\u00a8 ljama\n\u00a8 e,\nstimulation have both been reported to produce similar (although often less compelling) illusions of\nself-motion in blindfolded observers. Illusory self-motion can also be induced by passively rotating\nthe limbs of blindfolded observers (e.g., Howard, Zacher, & Allison, 1998) or having them step on a\n3. While these are the most common, other possible vection measures include the subjective speed of\nthe self-motion (e.g., Apthorp & Palmisano, 2014; Brandt et al., 1973; de Graaf, Wertheim, & Bles,\nYoung, Dichgans, Murphy, & Brandt, 1973) as well as changes in pupil dilation (e.g., Ihaya, Seno, &\nbody sway (e.g., Apthorp, Nagle, & Palmisano, 2014; Palmisano, Pinniger, Ash, & Steele, 2009;\nPalmisano, Apthorp, Seno, & Stapley, 2014; Wei, Stevenson, & Ko\ntypes of physical motions (e.g., Carpenter-Smith, Futamura, & Parker, 1995; Miller, O'Leary, Allen,\n& Crane, 2015; Nesti, Beykirch, Pretto, & Bu\nCrane, 2015), nonvisual self-motion aftereffects (e.g., Cuturi & MacNeilage, 2014), and EEG (e.g.,\nPalmisano, Barry, De Blasio, & Fogarty, 2016) have also been proposed to serve as vection measures.\n4. The choice of which vection measures to include in such studies was likely made based primarily on\npractical reasons. It was often not possible to obtain all three vection measures together because of\nstudy design limitations.\n5. Ratings are most commonly of the vection's strength or magnitude (Brandt et al., 1973). However,\nratings of its perceived speed (e.g., Kim & Palmisano, 2008), convincingness (e.g., Riecke et al.,\n2006), realism (e.g., Kruijff, Riecke, Trepkowski, & Kitson, 2015), degree of saturation (e.g.,\nAllison, Howard, & Zacher, 1999; McAnally & Martin, 2008), and distance travelled (e.g.,\nPalmisano, 2002) have also been obtained.\n6. In terms of statistics, a similarity index is often used to compare multiple models (i.e., the\ncomparisons between two or more models). Thus, in this study, it was difficult to show a certain\nsimilarity index between the raw data and simulated data. For this reason we provide qualitative,\nrather than quantitative, statements here.\n7. In perceptual tasks, observers are able to judge the temporal average, but their judgments appear to\nbe strongly dependent on local information around the time of stimulus offset (cf. VSS: Sato,\n8. We should state here again that latency and duration responses (both in seconds) were at least partially\nmethodologically dependent. Even with this aspect, we still believe that the behaviors of all three\n(absolute) vection indices (onset, duration, and magnitude) are important for understanding the\nbehaviors of the inner parameters underlying vection responding in the brain. These three indices\nare the most commonly obtained in human laboratory studies. In the past, the onset and duration\nvection measures have almost always been reported as absolute times in seconds. It is possible that\nthese three measures used in the current investigation (onset, duration, and magnitude) might best\nrepresent different aspects of the overall vection experience (as suggested earlier by Palmisano & Chan,\n2004). Consistent with this notion, experimental display manipulations are often reported to have\ninconsistent effects across these three different vection measures. For example, it is common for\nsignificant effects to be found between experimental and control conditions for vection magnitude,\nbut not for onset latency and measures (e.g., Palmisano et al., 2011). This might suggest the need for a\nmore comprehensive index of vection responding (e.g., Keshavarz et al.'s ``% duration'' index could be\na possible candidate). In a number of recent studies, vection rating and time course measures have\nbeen collected simultaneously (instead of sequentially). Possibly, the increased use of such\nmethodology might facilitate the creation a new and superior index of vection.\nReferences\nAdelson, E. H., & Bergen, J. R. (1985). Spatiotemporal energy models for the perception of motion.\nAllison, R. S., Ash, A., & Palmisano, S. (2014). Binocular contributions to linear vertical vection.\nAllison, R. S., Howard, I. P., & Zacher, J. E. (1999). Effect of field size, head motion, and rotational\nvelocity on roll vection and illusory self-tilt in a tumbling room. Perception, 28, 299\u00ad306. doi:\nAllison, R. S., Zacher, J. E., Kirollos, R., Guterman, P. S., & Palmisano, S. (2012). Perception of\nsmooth and perturbed vection in short-duration microgravity. Experimental Brain Research, 223,\nAndersen, G. J., & Braunstein, M. L. (1985). Induced self-motion in central vision. Journal of\nApthorp, D., Nagle, F., & Palmisano, S. (2014). Chaos in balance: Non-linear measures of postural\nApthorp, D., & Palmisano, S. (2014). The role of perceived speed in vection: Does perceived speed\nAsh, A., & Palmisano, S. (2012). Vection during conflicting multisensory information about the axis,\nAsh, A., Palmisano, S., Apthorp, D., & Allison, R. S. (2013). Vection in depth during treadmill walking.\nAsh, A., Palmisano, S., Govan, D. G., & Kim, J. (2011). Display lag and gain effects on vection\nexperienced by active observers. Aviation, Space, and Environmental Medicine, 82, 763\u00ad769. doi:\nAsh, A., Palmisano, S., & Kim, J. (2011). Vection in depth during consistent and inconsistent\nBecker, W., Raab, S., & Ju\n\u00a8 rgens, R. (2002). Circular vection during voluntary suppression of\nBerthoz, A., Pavard, B., & Young, L. R. (1975). Perception of linear horizontal self-motion induced by\nperipheral vision (linearvection): Basic characteristics and visual-vestibular interactions.\nBles, W. (1981). Stepping around circular vection and coriolis effects. In J. Longand, & A. Baddeley\n(Eds.), Attention and performance IX (pp. 47\u00ad61). Hillsdale, NJ: Lawrence Erlbaum Associates.\nBonato, F., & Bubka, A. (2006). Chromaticity, spatial complexity, and self-motion perception.\nBonato, F., Bubka, A., Palmisano, S., Phillip, D., & Moreno, G. (2008). Vection change exacerbates\nsimulator sickness in virtual environments. Presence: Teleoperators and Virtual Environments, 17,\nBrandt, T., Dichgans, J., & Bu\n\u00a8 chele, W. (1974). Motion habituation: Inverted self-motion perception\nBrandt, T., Dichgans, J., & Koenig, E. (1973). Differential effects of central versus peripheral vision on\negocentric and exocentric motion perception. Experimental Brain Research, 16, 476\u00ad491.\nBrandt, T., Wist, E. R., & Dichgans, J. (1975). Foreground and background in dynamic spatial\nBubka, A., & Bonato, F. (2010). Natural visual-field features enhance vection. Perception, 39,\nBubka, A., Bonato, F., & Palmisano, S. (2008). Expanding and contracting optic-flow patterns and\nCarpenter-Smith, T. R., Futamura, R. G., & Parker, D. E. (1995). Inertial acceleration as a measure of\nlinear vection: An alternative to magnitude estimation. Perception & Psychophysics, 57, 35\u00ad42.\nCuturi, L. F., & MacNeilage, P. R. (2014). Optic flow induces nonvisual self-motion aftereffects.\nD'Amour, S., Bos, J. E., & Keshavarz, B. (2017). The efficacy of airflow and seat vibration on reducing\nde Graaf, B., Wertheim, A. H., & Bles, W. (1991). The Aubert-Fleischl paradox does appear in visually\nDelorme, A., & Martin, C. (1986). Roles of the retinal periphery and depth periphery in linear vection\nand visual control of standing in humans. Canadian Journal of Psychology, 40, 176\u00ad187.\nDichgans, J., & Brandt, T. (1978). Visual-vestibular interaction: Effects on self-motion perception\nand postural control. In R. Held, H. W. Leibowitz, & H.-L. Teuber (Eds.), Handbook of\nDiels, C., Ukai, K., & Howarth, P. A. (2007). Visually induced motion sickness with radial displays:\nEffects of gaze angle and fixation. Aviation, Space, and Environmental Medicine, 78, 659\u00ad665.\nFushiki, H., Takata, S., & Watanabe, Y. (2000). Influence of fixation on circular vection. Journal of\nGiannopulu, I., & Lepecq, J. C. (1998). Linear-vection chronometry along spinal and sagittal axes in\nGurnsey, R., Fleet, D., & Potechin, C. (1998). Second-order motions contribute to vection. Vision\nGuterman, P. S., Allison, R. S., Palmisano, S., & Zacher, J. E. (2012). Influence of head orientation and\nviewpoint oscillation on linear vection. Journal of Vestibular Research, 22, 105\u00ad116.\nHaibach, P., Slobounov, S., & Newell, K. (2009). Egomotion and vection in young and elderly adults.\nHeld, R., Dichgans, J., & Bauer, J. (1975). Characteristics of moving visual scenes influencing spatial\nHettinger, L. J., Schmidt, T., Jones, D. L., & Keshavarz, B. (2014). Illusory self-motion in virtual\nenvironments. In K. S. Hale, & K. M. Stanney (Eds.), Handbook of virtual environments: Design,\nimplementation, and applications (2nd ed. pp. 435\u00ad466). New York, NY: CRC Press.\nHoward, I. P. (1982). Human visual orientation. New York, NY: John Wiley & Sons.\nHoward, I. P., & Heckmann, T. (1989). Circular vection as a function of the relative sizes, distances,\nHoward, I. P., Zacher, J. E., & Allison, R. S. (1998). Post-rotatory nystagmus and turning sensations\nafter active and passive turning. Journal of Vestibular Research, 8, 299\u00ad312.\nIhaya, K., Seno, T., & Yamada, Y. (2014). Piu\n` mosso: Fast self-motion makes cyclic action faster in\nvirtual reality. Revista Latinoamericana de Psicologi\u00b4a, 46, 53\u00ad58.\nIJsselsteijn, W., de Ridder, H., Freeman, J., Avons, S. E., & Bouwhuis, D. (2001). Effects of\nstereoscopic presentation, image motion, and screen size on subjective and objective corroborative\nmeasures of presence. Presence: Teleoperators and Virtual Environments, 10, 298\u00ad311.\nIshida, M., Fushiki, H., Nishida, H., & Watanabe, Y. (2008). Self-motion perception during conflicting\nIto, H., & Shibata, I. (2005). Self-motion perception from expanding and contracting optical flows\nIto, H., & Takano, H. (2004). Controlling visually induced self-motion perception: Effect of overlapping\ndynamic visual noise. Journal of Physiological Anthropology and Applied Human Science, 23, 307\u00ad311.\nJi, J. T. T., So, R. H. Y., & Cheung, R. T. F. (2009). Isolating the effects of vection and optokinetic\nnystagmus on optokinetic rotation-induced motion sickness. Human Factors, 51, 739\u00ad751.\nJu\n\u00a8 rgens, R., Kliegl, K., Kassubek, J., & Becker, W. (2016). Optokinetic circular vection: A test of\nvisual-vestibular conflict models of vection nascensy. Experimental Brain Research, 234, 67\u00ad81.\nKano, C. (1991). The perception of self-motion induced by peripheral visual information in sitting and\nKennedy, R. S., Hettinger, L. J., Harm, D. L., Ordy, J. M., & Dunlap, W. P. (1996). Psychophysical\nscaling of circular vection (CV) produced by optokinetic (OKN) motion: Individual differences and\nKeshavarz, B., Hettinger, L. J., Vena, D., & Campos, J. L. (2014). Combined effects of auditory and\nKeshavarz, B., Riecke, B. E., Hettinger, L. J., & Campos, J. L. (2015). Vection and visually induced motion\nKeshavarz, B., Speck, M., Haycock, B., & Berti, S. (2017). Effect of different display types on vection\nKim, J., & Palmisano, S. (2008). Effects of active and passive viewpoint jitter on vection in depth. Brain\nKim, J., & Palmisano, S. (2010a). Visually mediated eye movements regulate the capture of optic flow in\nKim, J., & Palmisano, S. (2010b). Eccentric gaze dynamics enhance vection in depth. Journal of Vision,\nKim, J., Palmisano, S., & Bonato, F. (2012). Simulated angular head oscillation enhances vection in\nKruijff, E., Riecke, B., Trepkowski, C., & Kitson, A. (2015). Upper body leaning can affect forward\nself-motion perception in virtual environments. Proceedings of the 3rd ACM Symposium on Spatial\nLepecq, J.-C., Giannopulu, I., & Baudonniere, P.-M. (1995). Cognitive effects on visually induced body\nLubeck, A. J. A., Bos, J. E., & Stins, J. F. (2015). Interaction between depth order and density affects\nMcAnally, K. I., & Martin, R. L. (2008). Sound localisation during illusory self-rotation. Experimental\nMergner, T., Schweigart, G., Mu\n\u00a8 ller, M., Hlavacka, F., & Becker, W. (2000). Visual contributions to\nhuman self-motion perception during horizontal body rotation. Archives Italiennes de Biologie, 138,\nMiller, M. A., O'Leary, C. J., Allen, P. D., & Crane, B. T. (2015). Human vection perception using\nMohler, B. J., Thompson, W. B., Riecke, B., & Bu\n\u00a8 lthoff, H. H. (2005). Measuring vection in a large\nscreen virtual environment. Proceedings of the 2nd ACM symposium on applied perception in graphics\nMotoyoshi, I., Nishida, S., Sharan, L., & Adelson, E. H. (2007). Image statistics and the perception of\nMurata, K., Seno, T., Ozawa, Y., & Ichihara, S. (2014). Self-Motion perception induced by cutaneous\nMursic, R. A., Riecke, B. E., Apthorp, D., & Palmisano, S. (2017). The Shepard-Risset glissando:\nNakamura, S. (2006). Effects of depth, eccentricity and size of additional static stimulus on visually\nNakamura, S. (2010). Additional oscillation can facilitate visually induced self-motion perception: The\nNakamura, S. (2012). Effects of stimulus eccentricity on the perception of visually induced self-motion\nNakamura, S. (2013a). The minimum stimulus conditions for vection--Two- and four-stroke apparent\nNakamura, S. (2013b). Separate presentation of additional accelerating motion does not enhance\nNakamura, S. (2013c). Effects of additional visual oscillation on vection under voluntary eye movement\nconditions--Retinal image motion is critical in vection facilitation. Perception, 42, 529\u00ad536.\nNakamura, S. (2013d). Visual jitter inhibits roll vection for an upright observer. Perception, 42,\nNakamura, S. (2013e). Rotational jitter around the observer's line of sight can facilitate visually\ninduced perception of forward self-motion (forward vection). Multisensory Research, 26, 553\u00ad560.\nNakamura, S., Palmisano, S., & Kim, J. (2016). Relative visual oscillation can facilitate visually induced\nNakamura, S., Seno, T., Ito, H., & Sunaga, S. (2010). Coherent modulation of stimulus colour can\nNakamura, S., Seno, T., Ito, H., & Sunaga, S. (2013). Effects of dynamic luminance modulation on\nvisually induced self-motion perception: Observers' perception of illumination is important in\nNakamura, S., & Shimojo, S. (1998). Stimulus size and eccentricity in visually induced perception of\nhorizontally translational self-motion. Perceptual and Motor Skills, 87, 659\u00ad663.\nNakamura, S., & Shimojo, S. (1999). Critical role of foreground stimuli in perceiving visually induced\nNakamura, S., & Shimojo, S. (2003). Sustained deviation of gaze direction can affect ``inverted vection''\nNesti, A., Beykirch, K. A., Pretto, P., & Bu\n\u00a8 lthoff, H. H. (2015). Self-motion sensitivity to visual yaw\nNordahl, R., Nilsson, N. C., Turchet, L., & Serafin, S. (2012). Vertical illusory self-motion\nthrough haptic stimulation of the feet. Proceedings of the IEEE VR Workshop on Perceptual\nOgawa, M., Ito, H., & Seno, T. (2015). Vection is unaffected by circadian rhythms. Psychology, 6,\nOgawa, M., & Seno, T. (2014). Vection is modulated by the semantic meaning of stimuli and\nOgawa, M., & Seno, T. (2016). Vection strength can be socially modulated through conformity to the\nreported perception of others. Transactions of the Virtual Reality Society of Japan, 21, 23\u00ad29.\nOgawa, M., Seno, T., Ito, H., & Okajima, K. (2016). Vection strength is determined by the subjective size\nof a visual stimulus modulated by amodal completion. Paper presented at the 31st International\nOgawa, M., Seno, T., Matsumori, K., & Higuchi, S. (2015). Twenty-hour sleep deprivation does not\naffect perceived vection strength. Journal of Behavioral and Brain Science, 5, 550\u00ad560.\nOhmi, M., & Howard, I. P. (1988). Effect of stationary objects on illusory forward self-motion induced\nOhmi, M., Howard, I. P., & Landolt, J. P. (1987). Circular vection as a function of foreground-\nPalmisano, S. (1996). Perceiving self-motion in depth: The role of stereoscopic motion and changing-\nPalmisano, S. (2002). Consistent stereoscopic information increases the perceived speed of vection in\nPalmisano, S., Allison, R. S., & Howard, I. P. (2006). Illusory scene distortion occurs during perceived\nPalmisano, S., Allison, R. S., Kim, J., & Bonato, F. (2011). Simulated viewpoint jitter shakes sensory\nPalmisano, S., Allison, R. S., Schira, M. M., & Barry, R. J. (2015). Future challenges for vection\nresearch: Definitions, functional significance, measures, and neural bases. Frontiers in Psychology,\nPalmisano, S., Apthorp, D., Seno, T., & Stapley, P. J. (2014). Spontaneous postural sway predicts the\nPalmisano, S., Barry, R. J., De Blasio, F. M., & Fogarty, J. S. (2016). Identifying objective EEG\nPalmisano, S., Bonato, F., Bubka, A., & Folder, J. (2007). Vertical display oscillation effects on forward\nvection and simulator sickness. Aviation, Space, and Environmental Medicine, 78, 951\u00ad956.\nPalmisano, S., Burke, D., & Allison, R. S. (2003). Coherent perspective jitter induces visual illusions of\nPalmisano, S., & Chan, A. Y. C. (2004). Jitter and size effects on vection are immune to experimental\nPalmisano, S., & Gillam, B. J. (1998). Stimulus eccentricity and spatial frequency interact to determine\nPalmisano, S., Gillam, B. J., & Blackburn, S. G. (2000). Global perspective jitter improves vection in\nPalmisano, S., & Kim, J. (2009). Effects of gaze on vection from jittering, oscillating, and purely radial\nPalmisano, S., Kim, J., & Freeman, T. C. A. (2012). Horizontal fixation point oscillation and simulated\nPalmisano, S., Mursic, R., & Kim, J. (2017). Vection and cybersickness generated by head-and-display\nmotion in the Oculus Rift. Displays, 46, 1\u00ad8.\nPalmisano, S., Pinniger, G. J., Ash, A., & Steele, J. R. (2009). Effects of simulated viewpoint jitter on\nPalmisano, S., Summersby, S., Davies, R. G., & Kim, J. (2016). Stereoscopic advantages for vection\nPrevic, F. H., & Donnelly, M. (1993). The effects of visual depth and eccentricity on manual bias,\nRiecke, B. E. (2010). Compelling self-motion through virtual environments without actual self-\nmotion--Using self-motion illusions (`vection') to improve user experience in VR. In J.-J. Kim\nRiecke, B. E., & Feuereissen, D. (2012). To move or not to move: Can active control and user-driven\nmotion cueing enhance self-motion perception (``vection'') in virtual reality? Proceedings of the ACM\nRiecke, B. E., Feuereissen, D., Rieser, J. J., & McNamara, T. P. (2011). Spatialized sound enhances\nbiomechanically-induced self-motion illusion (vection). Proceedings of the SIGCHI Conference on\nRiecke, B. E., Freiberg, J. B., & Grechkin, T. Y. (2015). Can walking motions improve visually induced\nRiecke, B. E., & Jordan, J. D. (2015). Comparing the effectiveness of different displays in enhancing\nRiecke, B. E., Schulte-Pelkum, J., Avraamides, M. N., Von Der Heyde, M., & Bu\nCognitive factors can influence self-motion perception (vection) in virtual reality. ACM Transactions\nRiecke, B. E., Va\n\u00a8 ljama\n\u00a8 e, A., & Schulte-Pelkum, J. (2009). Moving sounds enhance the visually-induced\nself-motion illusion (circular vection) in virtual reality. ACM Transactions on Applied Perception, 6,\nRosenblatt, S. D., & Crane, B. T. (2015). Influence of visual motion, suggestion, and illusory motion on\nSasaki, K., Seno, T., Yamada, Y., & Miura, K. (2012). Emotional sounds influence vertical vection.\nSato, H., Motoyoshi, I., & Sato, T. (2013). Perception of global trend from dynamic stimuli. Paper\npresented at the Vision Sciences Society (VSS) 13th Annual Meeting, Naples, Florida, USA (May\nSauvan, X. M., & Bonnet, C. (1993). Properties of curvilinear vection. Perception & Psychophysics, 53,\nSauvan, X. M., & Bonnet, C. (1995). Spatiotemporal boundaries of linear vection. Perception &\nSeno, T., Abe, K., & Kiyokawa, S. (2013). Wearing heavy iron clogs can inhibit vection. Multisensory\nSeno, T., & Fukuda, H. (2012). Stimulus meanings alter illusory self-motion (vection)--Experimental\nSeno, T., Funatsu, F., & Palmisano, S. (2013). Virtual swimming--Breaststroke body movements\nSeno, T., Ito, H., & Sunaga, S. (2009). The object and background hypothesis for vection. Vision\nSeno, T., Ito, H., & Sunaga, S. (2010). Vection after effects from expanding/contracting stimuli. Seeing\nSeno, T., Ito, H., & Sunaga, S. (2011). Attentional load inhibits vection. Attention, Perception, &\nSeno, T., Ito, H., Sunaga, S., & Palmisano, S. (2012). Hunger enhances vertical vection. Perception, 41,\nSeno, T., Kitaoka, A., & Palmisano, S. (2013). Vection induced by illusory motion in a stationary\nSeno, T., & Nagata, Y. (2016). The strength of sense of immersion positively correlates with vection\nstrength. Transactions of the Virtual Reality Society of Japan, 21, 3\u00ad6. [written in Japanese].\nSeno, T., Ogawa, M., Tokunaga, K., & Kanaya, H. (2016). The facilitation of vection by ``full-grass-\nwater method''. Transactions of the Virtual Reality Society of Japan, 21, 411\u00ad414. [written in\nJapanese].\nSeno, T., & Palmisano, S. (2012). Second-order motion is less efficient at modulating vection strength.\nSeno, T., Palmisano, S., & Ito, H. (2011). Independent modulation of motion and vetion aftereffects\nrevealed by using coherent oscillation and random jitter in optic flow. Vision Research, 51,\nSeno, T., Palmisano, S., Ito, H., & Sunaga, S. (2012). Vection can be induced without global-motion\nSeno, T., Palmisano, S., Ito, H., & Sunaga, S. (2013). Perceived gravitoinertial force during vection.\nSeno, T., Palmisano, S., & Nakamura, S. (2016). Effects of prior walking context on the vection induced\nby different types of global optic flow. Paper presented at the Visual Science of Art Conference\nSeno, T., Palmisano, S., Riecke, B. E., & Nakamura, S. (2015). Walking without optic flow reduces\nSeno, T., Yamada, Y., & Palmisano, S. (2012). Directionless vection: A new illusory self-motion\nSeya, Y., Shinoda, H., & Nakaura, Y. (2015). Up-down asymmetry in vertical vection. Vision Research,\nSeya, Y., Tsuji, T., & Shinoda, H. (2014). Effect of depth order on linear vection with optical flows. i-\nSeya, Y., Yamaguchi, M., & Shinoda, H. (2015). Single stimulus color can modulate vection. Frontiers\nShirai, N., Imura, T., Tamura, R., & Seno, T. (2014). Stronger vection in junior high school children\nShirai, N., Seno, T., & Morohashi, S. (2012). More rapid and stronger vection in elementary school\nTamada, Y., & Seno, T. (2015). Roles of size, position, and speed of stimulus in vection with stimuli\nprojected on a ground surface. Aerospace Medicine and Human Performance, 86, 794\u00ad802.\nTanahashi, S., Ujike, H., & Ukai, K. (2012). Visual rotation axis and body position relative to the\nTarita-Nistor, L., Gonza\n\u00b4 lez, E. G., Markowitz, S. N., Lillakas, L., & Steinbach, M. J. (2008). Increased\nrole of peripheral vision in self-induced motion in patients with age-related macular degeneration.\nTarita-Nistor, L., Gonzalez, E. G., Spigelman, A. J., & Steinbach, M. J. (2006). Linear vection as a\nfunction of stimulus eccentricity, visual angle, and fixation. Journal of Vestibular Research, 16,\nTelford, L., & Frost, B. J. (1993). Factors affecting the onset and magnitude of linear vection.\nTelford, L., Spratley, J., & Frost, B. J. (1992). Linear vection in the central visual field facilitated by\nThurrell, A., & Bronstein, A. (2002). Vection increases the magnitude and accuracy of visually evoked\nTrutoiu, L. C., Mohler, B. J., Schulte-Pelkum, J., & Bu\n\u00a8 lthoff, H. H. (2009). Circular, linear, and\ncurvilinear vection in a large-screen virtual environment with floor projection. Computers &\nVa\n\u00a8 ljama\n\u00a8 e, A. (2009). Auditorily-induced illusory self-motion: A review. Brain Research Reviews, 61,\nVa\n\u00a8 ljama\n\u00a8 e, A., & Sell, S. (2014). The influence of imagery vividness on cognitive and perceptual cues in\nvon Helmholtz, H. (1867/1925). Physiological optics (Vol. 3, 3rd ed). Menasha, WI: The Optical Society\nof America.\nWeech, S., & Troje, N. F. (2017). Vection latency is reduced by bone-conducted vibration and noisy\ngalvanic vestibular stimulation. Multisensory Research, 30, 65\u00ad90.\nWei, K., Stevenson, I. H., & Ko\n\u00a8 rding, K. P. (2010). The uncertainty associated with visual flow fields\nand their influence on postural sway: Weber's law suffices to explain the nonlinearity of vection.\nWong, S. C. P., & Frost, B. J. (1981). The effect of visual-vestibular conflict on the latency of steady-\nstate visually induced subjective rotation. Perception & Psychophysics, 30, 228\u00ad236.\nYoung, L. R., Dichgans, J., Murphy, R., & Brandt, T. (1973). Interaction of optokinetic and vestibular\nstimuli in motion perception. Acta Oto-Laryngologica, 76, 24\u00ad31.\nZacharias, G. L., & Young, L. R. (1981). Influence of combined visual and vestibular cues on human\nperception and control of horizontal rotation. Experimental Brain Research, 41, 159\u00ad171.\nAuthor Biographies\nTakeharu Seno: is an associate professor in the Faculty of Design\nat Kyushu University, in Fukuoka, Japan. His research topic has\nbeen ``Vection'' for more than 15 years. He became interested in\nvection while working on his PhD under the supervision of\nProfessor Takao Sato at the University of Tokyo and later on\nas a post-doctoral fellow working with Professor Hiroyuki Ito at\nKyushu University. Also, he studied and worked in the\nUniversity of Wollongong under the supervision of Professor\nStephen Palmisano, in Wollongong, Australia.\nKen-ichi Sawai: is a research associate in Graduate Schools for\nLaw and Politics at The University of Tokyo. He received a PhD\nin Information Science and Technology from The University of\nTokyo. His main research interests are mathematically\nunderstanding the human perception and cognition.\nHidetoshi Kanaya: is an assistant professor in the Faculty of\nHuman Informatics, Aichi Shukutoku University, Japan. He\nreceived PhD in Psychology from The University of Tokyo\nunder the supervision of Professor Takao Sato. His research\ninterests include visual perception (motion, depth), attention,\nself-motion, multimodal perception and action, and embodied\ncognition.\nToshihiro Wakebe: is a lecturer at Fukuoka Jo Gakuin University\nin Fukuoka, Japan. He has investigated in human memory based\non experimental psychology and cognitive neuroscience. He got a\nPhD in psychology from the University of Tokyo (supervisor:\nYohtaro Takano) and later devoted himself to research on\nmemory and plasticity using rTMS, tACS, ECoG, and EEG at\nDepartment of Medicine, the University of Tokyo (supervisor:\nKatsuyuki Sakai).\nMasaki Ogawa: is a researcher of Faculty of Design, Kyushu\nUniversity, Japan. He received his Ph.D in Design from Kyushu\nUniversity in 2015. His research interests are visual attention and\nillusory self-motion perception (vection).\nYoshitaka Fujii: is a post-doctoral fellow at Ritsumeikan\nUniversity. His insterets are in depth pereception, stereo vision\nand vection. He recieved a PhD from Tokyo Institute of\nTechnology (Tokyo, Japan), and worked in York University\n(Canada), Tokyo institute of technology, Kanazawa Institute\nof Technology and Kyushu University (Japan).\nStephen Palmisano: is an associate professor in the School of\nPsychology at the University of Wollongong. His research\ninvestigates how people perceive their own self-motions (both\nreal and illusory) and how having two eyes benefits their\nperception of depth. Stephen became interested in both areas\nof research while working on his PhD under the supervision of\nScientia Professor Barbara Gillam at UNSW and later on as a\npost-doctoral fellow working with Distinguished Research\nProfessor Ian P. Howard at the Centre for Vision Research,\nYork University, Canada."
}