{
    "abstract": "Abstract\nAlgorithms, once obscure objects of technical art, have lately been subject to considerable popular and scholarly scrutiny.\nWhat does it mean to adopt the algorithm as an object of analytic attention? What is in view, and out of view, when we\nfocus on the algorithm? Using Niklaus Wirth's 1975 formulation that ``algorithms \u00fe data structures \u00bc programs'' as a\nlaunching-off point, this paper examines how an algorithmic lens shapes the way in which we might inquire into con-\ntemporary digital culture.\n",
    "reduced_content": "Original Research Article\nAlgorithms and their others:\nAlgorithmic culture in context\nPaul Dourish\n Keywords\nAlgorithms, practice, materiality, configurations, visibility, code\nIntroduction\nDuring my time as an undergraduate student in com-\nputer science, algorithms were objects of concern in a\nvariety of ways \u00ad as practical rubrics for the design of\neffective and efficient computer programs, as catalogs\nof ways of working, as abstract formulations in text-\nbooks and research papers, or as mathematical conun-\ndrums that might appear in exam papers. Alongside\ncompilers, libraries, specifications, languages, and\nstate machines, they formed part of the intellectual fur-\nniture of that world.\nFrom that perspective, it's rather odd to find that\nalgorithms are now objects of public attention, arising\nas topics of newspaper articles and coffee shop conver-\nsations. When digital processes become more visible as\nelements that shape our experience, then algorithms in\nparticular become part of the conversation about how\nour lives are organized. From discussions over the role\nthat algorithms might play in hiring (Hansel, 2007) or\ncredit scoring (Singer, 2014) to inquiries into the\nassumptions behind the algorithms that set the ambient\ntemperature in office buildings (Belluck, 2015), an\nawareness has developed that algorithms, somehow\nmysterious and inevitable, are contributing to the\nshape of our lives in ways both big and small.\nThe public discussion of algorithms emerges out of\n(and arises at the intersection of) a series of other\nconversations. Some, for example, are entwined with\ndiscussions of ``Big Data,'' with a focus on the ways\nthat online activities create data streams from which\nalgorithms extract patterns that guide the action of\ninstitutions, corporations and states. Others frame dis-\ncussions of algorithms in terms of automation and in\nparticular the kinds of high-speed action associated\nwith, say, programmed trading in stock markets,\nhigh-frequency automated trades carried out by com-\nputer systems without human intervention (Buenza and\nMillo, 2013). Still others are concerned with the ways\nthat algorithmic developments are transforming aspects\nof the labor relation, positioning human being as\nresources to be deployed according to programmed\nresponses to demand, for instance in ride-sharing ser-\nvices like Uber (e.g. Rosenblat and Stark, 2016). Each\nof these is a broader or ongoing conversation into\nwhich the algorithmic has become incorporated.\nRelatedly, algorithms have also become objects of\nacademic attention in social and cultural studies,\noften in the context of similar concerns. Working\nUniversity of California, Irvine, CA, USA\nCorresponding author:\nPaul Dourish, University of California, 5086 Donald Bren Hall, Irvine,\nEmail: jpd@ics.uci.edu\nBig Data & Society\nbds.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License (http://\nwww.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-\nat-sage).\nacross a number of areas, including finance, labor pol-\nitics, governance, public policy, and organizational\nstrategy, scholars such as Barocas (2014), Gillespie\nattention to the way that algorithms are embedded\nwithin topics of academic investigation or indeed may\nconstitute a significant new topic of attention in them-\nselves. As with the public discussion, this academic\ninterest in algorithms is sometimes driven by the way\nthat algorithms are beginning to arise as objects of sig-\nnificance within existing academic domains; in other\ncases, it arises as part and parcel of a broader interest\nin harnessing the tools of cultural analysis to under-\nstand contemporary digital culture and its platforms\nHowever, the complex embedding of the topic of\nalgorithms into these related concerns raises some diffi-\nculties. In particular, it requires us to be careful about\nthe bounds and limits of algorithms and their function-\ning. Just what is it that we have in view when we focus\non ``algorithms'' as the central object of analytic\nattention?\nIn 1975, the pioneering computer scientist Niklaus\nWirth published a book entitled ``Algorithms \u00fe Data\nStructures \u00bc Programs'' (Wirth, 1975). Wirth was one\nof a group of researchers and academics who developed\nand advocated for the idea of ``structured program-\nming,'' an approach to the design and engineering of\nsoftware systems that emphasized the stepwise, modu-\nlar decomposition of problems and a similarly struc-\ntured approach to software design and construction.\nThis approach made computer programs easier to\ndevelop (especially by teams of programmers) and\neasier to analyze, as well as more naturally aligning\ncomputer programs, as engineering artifacts, with the\nsorts of mathematical mechanisms by which they could\nbe analyzed and assessed. Wirth did not simply cheer\nfor this position from the sidelines; his own work in\nprogramming language design and development pro-\nvided software engineers with the tools they needed to\nadopt the model, which soon became (and indeed, in\nvariant forms, remains) standard industrial practice.\n``Algorithms \u00fe Data Structures \u00bc Programs'' focused\non the practice of software design in the structured\nprogramming tradition, setting out the case for the\nmutual design of algorithmic processes and the regular-\nized data representations or ``data structures'' over\nwhich they would operate. At a time when the develop-\nment and analysis of algorithms was the dominant and\nmost prestigious area of computer science, Wirth\nwanted to emphasize the concomitant importance of\ndata structures for those building effective software\nsystems.\nWirth's formulation \u00c0 algorithms \u00fe data structures\n\u00bc programs \u00c0 highlights important concerns too for\nthose concerned with algorithms and digital culture.\nThe first is that algorithms and programs are differ-\nent entities, both conceptually and technically.\nPrograms may embody or implement algorithms (cor-\nrectly or incorrectly), but, as I will elaborate, programs\nare both more than algorithms (in the sense that pro-\ngrams include non-algorithmic material) and less than\nalgorithms (in the sense that algorithms are free of the\nmaterial constraints implied by reduction to particular\nimplementations).\nThe second, related, observation is that since algo-\nrithms arise in practice in relation to other computa-\ntional forms, such as data structures, they need to be\nanalyzed and understood within those systems of rela-\ntion that give them meaning and animate them. There\nis, in other words, within Wirth's formula, an analytic\nwarrant for a relational and differential analysis of\nalgorithm alongside data, data structure, program, pro-\ncess, and other analytic entities. This is not to dissolve\nthe algorithm in a sea of relations, but rather to under-\nstand how algorithm \u00ad as a technical object, as a form\nof discourse, as an object of professional practice, and\nas a topic of public or academic concern \u00ad comes to\nplay the particular role that it does.\nThe goal of this paper is to sketch just this sort of\nrelational analysis and to place algorithm in juxtapos-\nition with other relevant terms both in order to identify\naspects of the scope and limits of ``algorithm'' as a con-\nceptual tool, and to understand how algorithms come\nto act within broader digital assemblages. As Neyland\n(2016) notes, the danger to be guarded against here is\ntaking an essentializing view of algorithms. Similarly,\nmy argument here should not be read as an essentialist\nargument, seeking a foundational truth of the nature of\nalgorithms as natural occurrences. No such naturalism\ncan be sustained. Instead, the argument here is one of\nethnographic responsibility and practical politics. With\nrespect to ethnographic responsibility, I note that\n``algorithm'' is a term of art within a particular profes-\nsional culture \u00ad that of computer scientist, software\ndesigners, and machine learning practitioners \u00ad and I\nseek to understand the limits and particularlities of that\nterm's use as a members' term, its emic character, in\nmuch the same way as we might similarly explore,\nrespect, and analyze the consequences of members'\nterms within other cultural milieux. Secondly, as a\nmatter of practical politics, I take it that the domain\nof Big Data is one into which social science seeks to\nmake an intervention, and suggest that critiques of\nalgorithmic reasoning that set their own terms of refer-\nence for key terminology are unlikely to hit home.\nAgain, this is not to grant primacy or authority to a\ntechnical interpretation; the goal rather is to\n2 Big Data & Society\nunderstand what that technical interpretation is, and\nwhat consequences it might hold for social and cultural\nanalysis. The paper takes up the question of what algo-\nrithms do within the domain of Big Data's professional\npractices, as ``convening'' objects (Ananny, 2016), and\nas objects that live in dynamic relations to the other\nmaterial and discursive elements of software systems\nand the setting that produce them. In doing so, I\nhope to be able to identify fruitful directions for\ntaking up the algorithm as an object of attention\nwithin software studies and allied domains.\nAlgorithms and their others\nIn computer science terms, an algorithm is an abstract,\nformalized description of a computational procedure.\nAlgorithms fall into different types according to their\nproperties or domains \u00ad combinatorial algorithms deal\nwith counting and enumeration, numerical algorithms\nproduce numerical (rather than symbolic) answers to\nequational problem, while probabilistic algorithms pro-\nduce results within particular bounds of certainty.\nAlgorithms may also vary in terms of their analytic\ncharacteristics, such as generalized performance char-\nacteristics (e.g. how their mean-time or best-time per-\nformance varies with the size of the data sets over which\nthey operate). As part of the stock-in-trade of computer\nscientists and software engineers, some algorithms are\nknown by the names of their inventors (Dijkstra's algo-\nrithm, the Viterbi algorithm, Gouraud shading, or\nRivest-Shamir-Adelman) while others are known by\nconventional names (e.g. QuickSort, Fast Fourier\nTransform, Soundex, or sort-merge join).\nThe significance of some of these properties \u00ad for-\nmalization, abstraction, identity, and so on \u00ad becomes\nclearer when we look at algorithms in the context of\ntheir ``others'' \u00ad related but distinct phenomena that\nemphasize different aspects of the sociotechnical assem-\nbly. In speaking of what an algorithm ``is'' and ``is\nnot,'' I am not asserting its stable technical identity;\nrather, my motive is to be ethnographically true to a\nmembers' term and members' practice. As such, then,\nthe limits of the term algorithm are determined by\nsocial engagements rather than by technological or\nmaterial constraints. While social understandings and\npractices evolve, algorithm, as a term of technical art,\nnonetheless displays for members some precision and a\nmeaning within a space of alternatives. When technical\npeople get together, the person who says, ``I do algo-\nrithms'' is making a different statement than the person\nwho says, ``I study software engineering'' or the one\nwho says, ``I'm a data scientist,'' and the nature of\nthese differences matters to any understanding of the\nrelationship between data, algorithms, and society.\nAccordingly, an investigation of the particular territory\nstaked out by the term ``algorithm'', in among other\nrelated terms and phenomena, seems worthwhile, espe-\ncially if the algorithm is presented as a site of particu-\nlarly valuable leverage in contemporary debates.\nWith that caution in mind, then, we can consider the\nwork that the term ``algorithm'' does and might do for\nsocial analysis contextually.\nAlgorithm and automation\nPerhaps the most diffuse concern expressed by discus-\nsion of algorithms is that which uses the notion meto-\nnymically to address the regime of digital automation\nmost broadly. Here, the concern is not with algorithms\nas such, but with a system of digital control and man-\nagement achieved through sensing, large-scale data\nstorage, and algorithmic processing within a legal, com-\nmercial, or industrial framework that lends it authority.\nWe might point here to discussions of credit scoring\n(e.g. Zarsky, 2016), digitally enhanced public surveil-\nlance (e.g. Graham and Wood, 2003), or plagiarism\ndetection (e.g. Introna, 2016) as cases where concerns\nwith the algorithmic, in part or in whole, stand in for\ncritiques of the larger regime of computer-based moni-\ntoring and control. To be sure, crucial issues of labor\npolitics, social justice, personal privacy, public account-\nability, and democratic participation are thrown up by\nthis technologically enabled system of management,\nand the expansion of the sorts of regulative, coercive,\nand divisive processes that are the legacy of Charles\nBabbage and Frederick Taylor, and algorithms play a\ncritical role in these. Indeed, these are among the most\nimportant areas of political analysis that an under-\nstanding of ``algorithm'' as a term of technical art\nand practice can illuminate. Nonetheless, the wholesale\nequation of algorithm and automation makes this work\nmore, rather than less, difficult. If we want to be able to\nspeak of algorithms analytically in order to identify\ntheir significance as specific technical and discursive\nformulations then we need to be able to better identify\nhow they operate as part of, but not as all of the larger\nframework.\nAlgorithm and code\nAt a greater level of specificity, we might consider the\ndistinctions to be drawn between algorithms and code.\nIn various forms, code has been a particular focus of\nattention in software studies, acting as it does as a site\nof material, textual, and representational production.\nCode is software-as-text, and particularly in the form\nof ``source code,'' the human-readable expressions of\nprogram behavior that are the primary focus of pro-\ngrammers' productive attentions, it has perhaps been\nparticular by those working under the umbrella of\n``critical code studies'' (see, e.g., Berry, 2011; Montford\nIn textbooks and research papers, algorithms are\noften expressed in what is informally called ``pseudo-\ncode,'' a textual pastiche of conventional programming\nlanguages that embodies general ideas that most lan-\nguages share without committing to the syntactic or\nsemantic particulars of any one. Pseudo-code expresses\nthe abstract generality of an algorithm, the idea that it\ncan be operationalized in any programming language\nwhile transcending the particulars of each. It also\nexpresses the promise of an algorithm, the idea that it\nis code-waiting-to-happen, ready to be deployed and\nbrought to life in programs yet to be written (Introna,\n2016). The idea that the relationship between the algo-\nrithm and the code is largely a temporal one is perhaps,\nthen, not surprising, and yet there are distinctions that\nhave a good deal of significance from an analytic per-\nspective. I will outline four here.\nFirst, while the transformation of an algorithm\n(described in mathematical terms or in pseudo-code)\ninto code may be relatively straight-forward (although\nit is not necessarily so), the reverse process \u00ad to read the\nalgorithm off the code \u00ad is not at all a simple process.\nThere are a number of circumstances in which this need\narises. Assessing whether an algorithm has been cor-\nrectly implemented by a piece of code, for example, is\none case of attempting to ``read off'' the algorithm (as\nimplemented) from the code, and the complexity of this\nis made clear by the many cases in which errors slip\nthrough. Within the domain of Internet security, for\nexample, there have been a number of headline cases\nlately where trusted code did not in fact correctly imple-\nment the algorithm that it was meant to embody, leav-\ning systems open for attack and data breaches; the\n``Heartbleed'' incident is among the best known\n(Durumeric et al., 2014). The difficulty of reading an\nalgorithm off the code also lies at the heart of patent\ndisputes (over whether a given piece of code does or\ndoes not implement a protected algorithm, for instance)\nas well as simply cropping up as a practical problem for\na programmer charged with understanding, maintain-\ning, modifying, or porting an existing software system\nwritten by another (or sometimes even the code we\nwrote ourselves).\nSecond, algorithms and code have different locality\nproperties. One of the reasons, in fact, that the algo-\nrithm may not be easy to read off the code is that the\nalgorithm may not happen all in one place. The algo-\nrithm, an apparently singular object when it appears on\nthe page of a book, becomes many different snippets of\ncode distributed through a large program. Even if they\nhappen in sequence when a program is executed, they\nmay not occur together or even nearby within the text\nof a program. In a program, they may be intermixed\nwith elements of other algorithms, or they might simply\nbe distributed between different modules, different\nmethods, or different functions, so that they operate\nof the algorithm is (intentionally or unintentionally)\nobscured.\nThird, algorithms are manifest differently on differ-\nent code platforms. Object-oriented languages, proced-\nural languages, functional languages, and declarative\nlanguages are all based on different paradigms for\ncode expression and so will express the same algorithm\nquite differently. Particular examples of those language\nstyles have different features and different sets of\nlibraries, and will be able to rely on those in different\nways to carry out some of the algorithm's operations.\nDifferent computer architectures, different data storage\ntechnologies, different arrangements of memory hier-\narchy, and other features of a platform mean that the\ncode of an algorithm is highly variable and highly spe-\ncific. The ``governing dynamics'' of algorithms\n(Ananny, 2016), then, are only in part algorithmic;\nthey are as much platform effects.\nThe fourth observation is something of a corollary\nto the others, although one with particular conse-\nquences. One reason that an algorithm can be hard to\nrecover from a program is that there is a lot in a pro-\ngram that is not ``the algorithm'' (or ``an algorithm'').\nThe residue is machinic, for sure; it is procedural, it\ninvolves the stepwise execution of one instruction fol-\nlowed by another, and it follows all the rules of layout,\ncontrol flow, state manipulation, and access rights that\nshape any piece of code. But much of it is not actually\npart of the \u00ad or any \u00ad algorithm. An algorithm might\nexpress, for example, how to transform one kind of\ndata representation into another, or how to reach a\nnumerical result for a formula, or how to transform\ndata so that a particular constraint will hold (e.g. to\nsort numbers) \u00ad but actual programs that implement\nthese algorithms need to do a lot more besides. They\nread files from disks, they connect to network servers,\nthey check for error conditions, they respond to a user\ninterrupting a process, they flash signals on the screen\nand play beeps, they shuffle data between different stor-\nage units, they record their progress in log files, they\ncheck for the size of a screen or the free space on a disk,\nand many other things besides. An algorithm may\nexpress the core of what a program is meant to do,\nbut that core is surrounded by a vast penumbra of\nancillary operations that are also a program's respon-\nsibility and also manifest themselves in the program's\ncode. In other words, while everything that a program\ndoes and that code expresses is algorithmic in the sense\nthat it is specified in advance by formalization, it is not\nalgorithm, in the sense that it goes beyond things that\nalgorithms express, or even what the term ``algorithm''\nsignals as a term of professional practice.\n4 Big Data & Society\nAlgorithm and architecture\nThe third distinction that it is useful to take up is that\nbetween algorithm and architecture. This is an elabor-\nation of part of the earlier discussion, but an elabor-\nation that has particular relevance in the context of\ncontemporary networked systems.\nI noted above that algorithms, in the sense of par-\nticular formulations of program behavior, may not be\neasily localizable in code. That is, although they are\noften defined in terms of a ``sequence of steps'' or\n``sequence of operations'', that sequence may not be\nlaid out as a sequence of statements or sequence of\nlines in a program's text. The algorithm, then, is dis-\ntributed or fragmented in a program.\nMost contemporary programs of any complexity,\nhowever, are extremely large \u00ad often numbering in the\nhundreds of thousands or millions of lines of code \u00ad\nand must be arranged according to some organizational\nstructure in order to help programmers and teams\nmanage their complexity and comprehend the whole.\nSo-called software ``architecture'' concerns the arrange-\nment of units, modules, or elements of a larger system,\nand the patterns of interaction between those units. The\nnature of the units and the nature of the communica-\ntion between them depend both on the system's archi-\ntecture and on the underlying platform. Units might\nrelate to each other as libraries, as inheritance hierar-\nchies, as containerized components, as client/server, or\nin a host of related ways. The details are not of rele-\nvance to the argument here, but the point is this: first,\nthat ``the algorithm'', to the extent that it can be treated\nas a unit, may not be localized even within a module,\nnever mind within a simple extent of code; and second,\nthat modules may be highly isolated from each other,\ntheir code unavailable to each other, perhaps written by\ndifferent programmers, running on different computers,\nlocated within different administrative and manage-\nment domains, and so forth.\nFor instance, we might talk of the algorithm by which\nthe Internet manages the flow of data in a Transmission\nControl Protocol (TCP) stream. Data flow must be regu-\nlated so as to avoid congestion on transmission lines,\nand indeed the development of a new congestion avoid-\nance algorithm in the late 1980s was crucial in allowing\nthe Internet to scale to its current size (Jacobson, 1988).\nThis ``algorithm'' though is hard to locate in practice. It\nis an algorithm that governs the behavior of two parties,\nthe two end-points of a communication on a network, so\nthey are, by definition, almost always on two different\ncomputers. Those different computers quite likely run\ntwo different implementations of the TCP/IP protocols,\nwritten by different people, and quite possibly the pri-\nvate, undisclosed code belonging to two different organ-\nizations. Galloway (2004) has examined protocol as a\nform of decentralized control, focusing on the questions\nof conformance and regulation that underlie networked\nactions, but the protocol, as an agreement or specifica-\ntion to which both parties must conform, obscures, to\nsome extent, the algorithm itself. The algorithm specifies\nhow a protocol should be implemented but it cannot be\neasily located as an algorithm in the running system,\ndistributed as it is between different sites. More gener-\nally, the factoring of system behavior into a range of\ncomponents, some of which are bound together in the\nsame address space, some of which are distributed as\ndifferent threads or processes, some of which are imple-\nmented on different computers, many of which are vis-\nible to each other only through restricted interfaces,\noften means that the ``algorithm'' can not only not be\nlocated within an easily delineated stretch of code, but\nnot even within a single computer or the network of a\nsingle organization.\nGiven how many contemporary systems are net-\nwork-based or network-backed, are designed for\nlarge-scale clusters, or even just depend on multi-core\nor graphics processor-based architectures common in\ncontemporary personal platforms from desktops to\nwearables, the question of distribution is pervasive.\nIntrona (2016) suggests the language of Barad's\n(2007) agential realism as a way of thinking about\nthis, recognizing that the ``algorithm'' is itself an ``agen-\ntial cut'', a means of constituting some semi-stable\nobject within a dynamic and unfolding socio-technical\nassembly. This does not diminish the power of ``algo-\nrithm'' as a way of accounting for the operation of a\ndigital assemblage, by any means, but it does imply that\n``algorithm'' may dissolve into nothing when we drill\ndown into the specific elements of a system that might\nbe subject to audit or focused critical or forensic exam-\nination (c.f. Kirschenbaum, 2008). Introna's analysis\nshows that we should examine both what work it\ntakes to identify certain aspects of a running system\nas the manifestations of an algorithm, and also what\nis achieved through that collective process and practice\nof identification.\nAlgorithm and materialization\nThe final distinction to explore here is that between the\nalgorithm and its manifestation not just in a piece of\ncode or even in a larger software system but in a specific\ninstantiation \u00ad as a running system, running in a par-\nticular place, on a particular computer, connected to a\nparticular network, with a particular hardware config-\nuration. All of these critically shape the effect that the\nalgorithm has.\nThat material configurations limit the effectiveness\nor reach of algorithms is no surprise; algorithmic for-\nmulations do not take into account the storage speeds,\nnetwork capacities, instruction pipelines, or memory\nhierarchies, each of which can have a crucial effect on\nalgorithmic performance. More interestingly, though,\nthe converse is also true \u00ad our experience of algorithms\ncan change as infrastructure changes.\nConsider an example taken from nuclear weapon\nsimulation (see Dourish and Mazmanian, 2013). Due\nto nuclear test ban treaties, the nuclear powers have not\ndetonated nuclear weapons in several decades.\nHowever, they continue to develop and introduce new\nweapons. To do so with no testing would be foolhardy,\nand so new designs are tested but only through simu-\nthat it was the ability to produce credible digital simu-\nlations of nuclear explosions that made test limitation\ntreaties possible. At this point, the design of new\nnuclear warheads and weapons is so intrinsically tied\nto the technology of simulation that one could cite the\ntechnology of simulation as one of the major limits\nupon the production of new weapons. Advances in\nsimulation technology make new simulations practical,\nand those new simulations open up new avenues for\nweapons design. Note that the algorithms do not need\nto change in this scenario; only the technologies upon\nwhich they are implemented. The simulation \u00ad the algo-\nrithm \u00ad remains unchanged, but the shifting techno-\nlogical base upon which an implementation of that\nalgorithm runs means that the capacities of that algo-\nrithm and its effectiveness within a design process is\nchanging. New technologies shift the effect and\nimpact of an algorithm without changing the algorithm\nitself; they expand the bounds of algorithmic\npossibility.\nSecurity infrastructures are a second area where\nthese changes have made a difference. For instance,\neven simplistic so-called ``brute-force attacks'' on pass-\nword systems (systematically attempting every possible\npassword) that were once infeasibly hard with simple\npassword technology are now trivial; more sophisti-\ncated attacks on more complicated cryptographic sys-\ntems are similarly now just a matter of assembling\nenough computing power.\nIn a wide-ranging examination of algorithms that\ntakes the Viterbi path algorithm as its key example,\nMackenzie (2005) takes up some of these questions.\nThe algorithm is powerful and has many applications,\nbut much of what makes it effective in our world is the\nfact that particular implementations of the algorithm\ncan be embodied in devices and infrastructures with\nspecific operating capacities. Mackenzie's analysis\nfocuses on digital temporality, and here we find a key\nconcern with algorithms and their materialization. To\nspeak of an algorithm like the Viterbi algorithm as\n``fast'' is to speak of its complexity, its efficiency and\nthe conditions that limit its performance, but this tells\nus nothing about how quickly or slowly it might actu-\nally perform in practice. The only things that have\nactual measurable performance (measured in seconds\nor fractions thereof) are implementations, in software\nor in silicon. The algorithm, in other words, must be\nunderstood both as a formalized account of computa-\ntional possibilities and as a practical tool, and the rela-\ntionship between these two is not fixed.\nInscrutibility\nStretching across all these discussions are a series of\ndistinctions that seem to anchor the social analysis of\nalgorithms. Algorithms are presented as fast, rather\nthan slow; as automated, rather than hands-on; as\nmachinic, rather than human. Each of these presents\na series of problems when algorithms move into new\ndomains.\nPerhaps the most significant contrast, though, con-\ncerns the problems of inscrutability. The focus of sev-\neral examinations has been the question of\naccountability and assessment thrown up by the fact\nthat algorithms are opaque; their operation cannot be\nexamined as easily as those of human actors, for a var-\niety of reasons, leading us to look for new ways to make\nalgorithmic processes visible, to render algorithms\naccountable, and to find within the algorithmic process\nsome opportunity for audit, external review, and exam-\nI draw on a recent article in these pages by Jenna\nBurrell (2016), who lays out some of the foundations\nfor algorithmic opacity in order to trouble some of\nthese calls for audit.\nAlgorithmic opacity\nBurrell begins from the problems posed by opaque\nalgorithms. For those for whom algorithmic practice\npotentially embodies an end-run around traditional\nforms of legislative accountability, this opacity is a\nsevere problem, and some, such as Pasquale (2015),\nhave argued that algorithms need to be available to\naudit. Burrell points out, though, that there are mul-\ntiple different sources of algorithmic opacity, with dif-\nferent relations to mechanisms of redress such as audit.\nThe first is the trade-secret protection that governs\nmany of the algorithms that lie behind services such\nas Google, Facebook, and Twitter, but also those\nthat are used by financial institutions and other corpor-\nations. Audit might have the most force here, where\nalgorithms are held as secrets. A second source of opa-\ncity is that the ability to read or understand algorithms\nis a highly specialized skill, available only to a limited\nprofessional class; it depends upon particular education\nand training. This suggests that audit, at least under\n6 Big Data & Society\ncontemporary arrangements, will always be a professio-\nnalized and specialized technical practice; with respect\nto audit, we might be concerned about the problems\nthat have attended financial audit in cases like that of\nEnron, for example. However, most problematic is\nBurrell's third source of opacity. As she notes, many\nof the algorithms that have social and cultural signifi-\ncance, including those that shape the flow of informa-\ntion in social media, the distribution of search results in\nsearch engines, and the production of recommenda-\ntions in online retail, are statistical machine learning\nalgorithms. Operating over large amounts of data,\nthey observe, characterize, and act on patterns that\narise in the data. But these patterns are purely statistical\nand probabilistic phenomena \u00ad they are not human des-\nignations. A ``top-down'' approach might operate in\nterms of human-identified traits, and then seek to find\nthem in the data; the bottom-up approach of statistical\nmachine learning is to identify the patterns first and\nthen see if they can be made sense of for human\nneeds. So, for example, a ``bottom-up'' algorithm for\nhandwriting recognition has no concept of the alpha-\nbet. It has not been programmed with the shape of the\nletters ``A'' or ``g''. It has instead exposed to thousands\nof examples, on the basis of which it is programmed to\nrecognize certain arrangements of strokes as being\ncharacteristic of particular letters. Audit, in this case,\nhas no power to reveal what the algorithm knows,\nbecause the algorithm knows only about inexpressible\ncommonalities in millions of pieces of training data.\nThe questions of what we know and what we can say\nabout the operation of machine learning or Big-Data\nalgorithms of this sort is a key issue at stake in algo-\nrithmic analysis. During my years of computer science\ntraining, to have an algorithm was to know something.\nAlgorithms were definitive procedures that lead to pre-\ndictable results. The outcome of the algorithmic oper-\nation was known and certain. Much of the debate\nabout ``algorithms'' at the moment focuses on a par-\nticular class of algorithm \u00ad statistical machine learning\ntechniques \u00ad that produce, instead, unknowns. More\naccurately, they produce analyses of data that are\nknown and understood in some terms (in terms of the\nformal properties of the data set \u00ad its patterns and\nregularities) but unknowable in others (in the terms of\nthe domain that the data represents.) When my credit\ncard company deems a particular purchase or stream of\npurchases ``suspicious'' and puts a security hold on my\ncard, the company cannot explain exactly what was\nsuspicious \u00ad they know that there's something odd\nbut they don't know what it is.\nWhen algorithms come to play a role in social\naffairs, this begins to matter. As reported by Gillespie\n(2011), activists in the Occupy Wall Street (OWS)\nmovement were surprised to note that the OWS\nactivities never became a ``trending topic'' on Twitter\n(highlighted because of user activity). Some were con-\nvinced that this must have indicated censorship; after\nall, how could the latest pop sensation's haircut or new\ntattoo be more important than this mass political\naction? The engineers at Twitter were adamant that\nno censorship had gone on, but were themselves\nunable to explain why OWS had not become a trending\ntopic. They can explain the algorithm (although it's a\ntrade secret, so they don't) \u00ad the factors that contribute,\nthe ordering and weighting of different properties of\ntweets and hashtags \u00ad but that is not, in itself, enough\nto account for what happens in the system. To under-\nstand that, one must be able to characterize the specific\ndynamics of the ever-roiling mass of data \u00ad the way that\npeople pick up ideas, the dynamics of how they repeat\nthem, the geographical waves of interest, all going by at\nmillions of tweets per minute. It is not just that we\ncannot easily recreate the circumstances and forensic-\nally figure this out (as Heraclitus 2.0 might say, you\ncannot step twice into the same data stream) but also\nthat the patterns that are being analyzed are ephemeral.\nAnd yet we need to find ways to narrate them.\nAlthough the forms of analysis in which statistical\nmachine learning techniques are embedded are referred\nto with the term ``Big Data,'' there are in fact two scalar\nmoves at work. The first is a move from small to big \u00ad\nfrom individual data to large data sets, from one record\nto an accumulated mass of data (as in the Quantified\nSelf movement \u00ad c.f. Neff and Nafus, 2016), or from\none person to a large population. This is not only the\nscalar move from which Big Data gains both its name\nbut also certain claims to statistical meaningfulness,\nand it is the move that allows statistical techniques to\nstart to describe features of populations. The second\nmove, though, is from big to small again, and it is the\nkey move in narrating or accounting for the results of\nBig Data analysis. Machine learning techniques cluster\ndata but humans read and narrate the clusters that arise\nas signaling certain categories of people \u00ad pregnant\nwomen, dual-income Minneapolis families in the\nmarket for a new car, disaffected voters, or people\nlikely to cheat on their taxes. Each act of categorization\n\u00ad or more accurately, of narration \u00ad is a move from big\nto small, a reduction of a mass of data points to a\nnarrative element or a defining characteristic, drawn\ngenerally from the domain of which we want to\nknow. Electoral data is gathered in order to tell us\nabout voters, and so we find voters in it; purchase\ndata formulates people as consumers, and so we find\nconsumer categories in it. And we find not only voters\nand consumers, but voters and consumers who can be\nmade sense of in terms that make sense in the domain \u00ad\ngeography, income, lifestyle, history, engagement,\ninterests, and inclinations. Big Data analysis says\n``this happens along with that'' but the narratives we\ntell of why are human ones, not technical ones. We are\ninclined only to find things in Big Data that we\nexpected, in some sense, to find \u00ad or at least, we find\nthe kinds of things that we can make sense of.\nIt is useful here, then, to return to Wirth's formula-\ntion \u00ad algorithms \u00fe data structures \u00bc programs. It\nspeaks to the inherent duality of algorithms and data\nin the production of running systems, and the problems\nof attempting to understand one without the other.\nWirth speaks of data structures, rather than data,\nbecause algorithms are designed around data structures\n\u00ad about forms and regularities rather than around con-\ntent. (An algorithm for sorting numbers is the same no\nmatter what the numbers \u00ad and indeed the same algo-\nrithm should also be able to sort names, files, or dates.)\nSimilarly, Burrell's concern with opacity also directs us\nto be concerned about structures and regularities in\ndata sets and the mechanisms by which we struggle to\nname them. Concerns with algorithms as inscrutable\nand illegible may direct us instead towards the need\nto example the sources of the apparent legibility of\ndata.\nSome recent moves by European legislators have\nshifted the conversation from ``audit'' to ``explan-\nation,'' arguing that citizens who are substantively\naffected by the action of an algorithmic system should\nhave a right to an explanation of how that decision was\nmade (Goodman and Flaxman, 2016). The notion of\n``explanation'' here reflects the duality of algorithm and\ndata and the way that each can play a role in automated\ndecision-making. At the same time, though, it begs\nother questions, including, first, what degree of explan-\nation can successfully ``explain'' results, and, perhaps\nmore pertinently, how the production of such an\nexplanation \u00ad which must, of course be generated algo-\nrithmically \u00ad can be itself explained.\nDirections\nWhat lessons might we draw from this analysis and\nwhat directions does it suggest for future analytic\nwork around algorithms? Should we conclude that the\nterm ``algorithm'' is too beset with problems and mis-\nunderstandings to function effectively in critique, and\nthat perhaps it is time to declare a moratorium on its\nuse? Conceptual confusions certainly abound, but the\nterm still carries weight and value if we can appropri-\nately locate it within a larger analytic frame.\nOne consequence is to pair analyses of algorithms\nwith analyses of the various phenomena of data \u00ad\ndata items, data streams, and data structures \u00ad upon\nwhich they operate and in relation to which they are\nformulated. The rise of interest in Big Data techniques\ncourse a significant source of interest in algorithms in\nthe first place, but the topic of data structures \u00ad the\nspecific representations that organize data in order to\nmake it processable by algorithms \u00ad have been less\nprominent. The consequences of representational\nforms \u00ad of the way that data must be shaped to be\nprocessed by databases or other informational systems\nciples of data archives (e.g. Edwards et al., 2011) or the\nrelationships between data format, data transmission,\nand representation (e.g. Dourish, 2015; Galloway,\n2004) \u00ad is the necessary dual of algorithmic processing.\nWhile privacy discusses focus on data generation\nand accumulation, data organization \u00ad the data struc-\ntures of Wirth's aphoristic equation \u00ad require similar\nscrutiny.\nA second concern to which our attention might be\ndrawn on the basis of this exploration is the question of\nalgorithmic identity. How might we go about identify-\ning and pinpointing algorithms in consequence of the\nvagaries of implementation and the flux of evolution?\nHow can algorithms be isolated and examined, and\nhow much sense does it even make to attempt that\nexercise? Calls for audit and accountability, or even\nthe manifestation of particular algorithms in order to\ntrace aspects of their history or movements, require\nsome attention to the identity conditions upon which\nalgorithmic sameness or similarity are founded. As\nGillespie (2012) has noted, algorithms shift and evolve\nin deployment, particularly those hidden behind trade\nsecrecy barriers; talking in any coherent way about\n``Google's search term prediction'' algorithm, for\nexample, is deeply problematic given the invisible\nshifts in implementation and strategy that lie behind\nthe scenes. Mackenzie (2005) considers the patterns of\nrepeatability that algorithms embody within them-\nselves, although one might extend his analysis to con-\nsider the forms of repeatability at work in either the\nsuccessive use of algorithms over different data sets,\nor the multiple embodiments of ``the same'' algorithm\nin different platforms and technologies. Again, the con-\ncern is not to engage in an essentializing project with\nthe goal of laying down the criteria for algorithmic\nsameness; the concern is more to understand how algo-\nrithms are identified as, used as, or made to be the same\nin different settings, circulating as they do among plat-\nforms, institutions, corporations, and applications.\nIn turn, then, this might direct our attention towards\na third concern, that of the temporalities of algorithms\n\u00ad not just the temporalities of their own processes\n(although those matter, because not all algorithms pro-\nduce answers quickly) but also the temporalities of their\nevolution as implemented and deployed. Perhaps espe-\ncially important here are the co-evolution of algorithms\nand data streams, particularly in cases where these are\n8 Big Data & Society\nmutually influential. An algorithm for, say, modeling\nclimate data is not directly tied to the climate data\nitself, although it might influence the design of new\nsensors and data collection instruments (Edwards,\n2010), but the algorithm by which Twitter determines\nthe ``trending topics'' that it will report does exist in a\nfeedback loop with the data over which it operates,\nsince trending topics displayed to users of Twitter and\ninfluence their own action, including the topics they\nsearch and the postings they retweet and comment\nupon.\nThese concerns with algorithmic identity and evolu-\ntion point towards an alternative approach to algo-\nrithm studies which might put aside the question of\nwhat an algorithm is as a topic of conceptual study\nand instead adopt a strategy of seeking out and under-\nstanding algorithms as objects of professional practice\nfor computer scientists, software engineers, and system\ndevelopers. What power does the notion of ``algo-\nrithm'' have within their conversations and collabor-\nations, and in what way are algorithms invoked,\nidentified, traded, performed, produced, boasted of,\ndenigrated, and elided? What are computer scientists\ndoing with they ``do'' algorithms, and for whom? In\nthis approach, we might examine algorithm as a feature\nof the world of professional practice and as a member\ncategory. A useful model here might be Eric\nLivingstone's (1986) ethnographic study of the work\nof mathematicians and the role and nature of ``proof''\nin their lived work. Focusing on the ``proof'' not as an\nabstract truth but as a material form, something to be\nwritten on blackboards, demonstrated in conversation,\nand codified into academic career narratives,\nLivingstone provides an account of the emergence of\nan object of professional practice within the everyday\npractical work of a scientific community. As studies by\nbegin to show, algorithms may benefit from a similar\napproach. Wendy Chun (2008) has argued cogently for\nthe need to resist fetishizing technical objects such as\nsource code or algorithm, pointing out that a capitula-\ntion to purely technical accounts risks obscuring the\nsocial and cultural practices by which those technical\nobjects are animated in practice. While acknowledging\nthe force of this argument, I have suggested that both\nethnographic responsibility and practical politics\nrequire that the term ``algorithm'' as an analytic cat-\negory must nonetheless be wielded with some precision.\nClearly, its emic character is not the limit of what can\nbe said for, with, or about it but we must nevertheless\nbe at least conscious of where and when we make delib-\nerate moves to invoke the term in order to do new\nconceptual work, and with what consequences. If the\nterm ``algorithm'' appears in social analyses to mean\njust what it means emically, then it risks missing the\nmany other elements in relation to which the algorithm\narises; but by corollary, if it appears in social analyses\nwith some new and different meaning, then it becomes\ndifficult to imagine critiques hitting home in the places\nthat we hope to effect change.\nFinally, one of the more intriguing issues to arise in\nthis exploration, and perhaps one that merits further\nattention, is the relationship between algorithmic and\nnon-algorithmic within technological practice. That is,\nif algorithms are distinguishable elements of software\ndesign, delineable, identifiable, and perhaps even name-\nable, then we also begin to recognize that there are\nother elements in software systems that are machinic\nand programmed but not actually themselves governed\nby the sorts of things that are normally demarcated as\n``algorithms.'' Some may be expressible algorithmically,\nbut they are not themselves the things with which algo-\nrithm designers or algorithm analysts concern them-\nselves. These include the happenstance interaction of\ndifferent systems not necessarily designed in concert\n(such as the interactions between different flows on a\nnetwork, different services on a server, or different\nmodules in an application, but they also include the\nwork ``around the edges'' of algorithms even in their\nmost direct implementation \u00ad the housekeeping, the\nerror-checking, the storage management, and so on.\nGiven the easy slippage between ``algorithmic'' and\n``machinic,'' or between ``algorithmic'' and ``auto-\nmated,'' the emergence of a category of programmed\nbut not algorithmic activity within computer systems \u00ad\nnot governed by algorithms in the sense in which that\nterm is used within computational practice \u00ad is intri-\nguing and suggestive. Certainly, it speaks to the poten-\ntial problems that software studies might have in\ntalking to some of its potential audiences if it talks\npurely in terms of ``algorithms''. Further, it speaks to\nthe disappearance within algorithm-oriented analysis of\nthe work of making algorithms work. Perhaps, too, it\nsuggests some useful parallels with, say, the elements of\nengineered systems that are not themselves outcomes of\nprocesses of design or engineering, and other gaps,\nholes, and rifts between systems-as-manifest and sys-\ntems-as-studied.\nUnderstanding the limits and specificities of ``algo-\nrithm,'' then, holds out the opportunity both to engage\nmore meaningfully in interdisciplinary dialogue and to\nopen up new areas for analysis around the edges of\nalgorithmic systems.\n"
}