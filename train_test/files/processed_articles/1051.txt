{
    "abstract": "PNAS is one of world's most cited multidisciplinary scientific journals. The PNAS official classification structure of subjects is reflected in topic labels submitted by the authors of articles, largely related to traditionally established disciplines. These include broad field classifications into physical sciences, biological sciences, social sciences, and further subtopic classifications within the fields.",
    "reduced_content": "Elena Erosheva*, Stephen Fienberg\u00a7, and John Lafferty\u00a7\u00b6\n*Department of Statistics, School of Social Work, and Center for Statistics and the Social Sciences, University of Washington, Seattle, WA 98195; and\n \nPNAS is one of world's most cited multidisciplinary scientific\njournals. The PNAS official classification structure of subjects is\nreflected in topic labels submitted by the authors of articles, largely\nrelated to traditionally established disciplines. These include broad\nfield classifications into physical sciences, biological sciences, social\nsciences, and further subtopic classifications within the fields.\nFocusing on biological sciences, we explore an internal soft-\nclassification structure of articles based only on semantic decom-\npositions of abstracts and bibliographies and compare it with the\nformal discipline classifications. Our model assumes that there is a\nfixed number of internal categories, each characterized by multi-\nnomial distributions over words (in abstracts) and references (in\nbibliographies). Soft classification for each article is based on\nproportions of the article's content coming from each category. We\ndiscuss the appropriateness of the model for the PNAS database as\nwell as other features of the data relevant to soft classification.\nThe Proceedings is there to help bring new ideas\npromptly into play. New ideas may not always be right,\nbut their prominent presence can lead to correction. We\nmust be careful not to censor even those ideas which\nseem to be off beat.\nSaunders MacLane (1)\nAre there internal categories of articles in PNAS that we can\nobtain empirically with statistical data-mining tools based\nonly on semantic decompositions of words and references used?\nCan we identify MacLane's ``off-beat'' but potentially path-\nbreaking PNAS articles by using these internal categories? Do\nthese empirically defined categories correspond in some natural\nway to the classification by field used to organize the articles for\npublication, or does PNAS publish substantial numbers of\ninterdisciplinary articles that transcend these disciplinary bound-\naries? These are examples of questions that our contribution to\nthe mapping of knowledge domains represented by PNAS\nexplores.\nMathematical and statistical techniques have been developed\nfor analyzing complex data in ways that could reveal underlying\ndata patterns through some form of classification. Computa-\ntional advances have made some of these techniques extremely\npopular in recent years. For example, 2 of the 10 most cited\nof clustering for gene-expression patterns (2, 3). The traditional\nassumption in most methods that aim to discover knowledge in\nunderlying data patterns has been that each subject (object or\nindividual) from the population of interest inherently belongs to\nonly one of the underlying subpopulations (clusters, classes,\naspects, or pure type categories). This implies that a subject\nshares all its attributes, usually with some degree of uncertainty,\nwith the subpopulation to which it belongs. Given that a rela-\ntively small number of subpopulations is often necessary for a\nmeaningful interpretation of the underlying patterns, many data\ncollections do not conform with the traditional assumption.\nSubjects in such populations may combine attributes from\nseveral subpopulations simultaneously. In other words, they may\nhave a mixed collection of attributes originating from more than\none subpopulation.\nSeveral different disciplines have developed approaches that\nhave a common statistical structure that we refer to as mixed\nmembership. In genetics, mixed-membership models can ac-\ncount for the fact that individual genotypes may come from\ndifferent subpopulations according to (unknown) proportions of\nan individual's ancestry. Rosenberg et al. (4) use such a model\nto analyze genetic samples from 52 human populations around\nthe globe, identifying major genetic clusters without using the\ngeographic information about the origins of individuals. In the\nsocial sciences, such models are natural, because members of a\nsociety can exhibit mixed membership with respect to the\nunderlying social or health groups for a particular problem being\nstudied. Hence, individual responses to a series of questions may\nhave mixed origins. Woodbury et al. (5) use this idea to develop\nmedical classification. In text analysis and information retrieval,\nmixed-membership models have been used to account for dif-\nferent topical aspects of individual documents.\nIn the next section, we describe a class of mixed-membership\nmodels that unifies existing special cases (6). We then explain\nhow this class of models can be adapted to analyze both the\nsemantic content of a document and its citations of other\npublications. We fit this document-oriented mixed-membership\nmodel to a subcollection of the PNAS database supplied to the\nparticipants in the Arthur M. Sackler   Mapping\nKnowledge Domains. We focus in our analysis on a high-level\ndescription of the fields in biological sciences in terms of a small\nnumber of extreme or basis categories. Griffiths and Steyvers (7)\nuse a related version of the model for abstracts only and attempt\na finer level of description.\nMixed-Membership Models\nThe general mixed-membership model that we work with relies\non four levels of assumptions: population, subject, latent vari-\nable, and sampling scheme. Population level assumptions de-\nscribe the general structure of the population that is common to\nall subjects. Subject-level assumptions specify the distribution of\nobservable responses given individual membership scores. Mem-\nbership scores are usually unknown and hence can be viewed also\nas latent variables. The next assumption is whether the mem-\nbership scores are treated as fixed or random in the model.\nFinally, the last level of assumptions specifies the number of\ndistinct observed characteristics (attributes) and the number\nof replications for each characteristic. We describe each set of\nassumptions formally in turn.\nThis paper results from the Arthur M. Sackler   of the National Academy of\nSciences, ``Mapping Knowledge Domains,'' held May 9\u00ad11, 2003, at the Arnold and Mabel\nBeckman Center of the National Academies of Sciences and Engineering in Irvine, CA.\nTo whom correspondence should be addressed. E-mail: elena@stat.washington.edu.\n\u00a9 2004 by The National Academy of Sciences of the USA\nPopulation Level. Assume there are K original or basis subpopu-\nlations in the populations of interest. For each subpopulation k,\ndenote by f(xjkj\n) the probability distribution for response\nvariable j, where kj\nis a vector of parameters. Assume that,\nwithin a subpopulation, responses to observed variables are\nindependent.\nSubject Level. For each subject, membership vector   (1\n, . . . ,\nK\n) provides the degrees of a subject's membership in each of the\nsubpopulations. The probability distribution of observed re-\nsponses xj\nfor each subject is defined fully by the conditional\nprobability Pr(xj)  \u00a5kk\nf(xjkj\n) and the assumption that\nresponse variables xj\nare independent, conditional on member-\nship scores. In addition, given the membership scores, observed\nresponses from different subjects are independent.\nLatent-Variable Level. With respect to the latent variables, one\ncould assume that they are either fixed unknown constants or\nrandom realizations from some underlying distribution.\n1. If the membership scores  are fixed but unknown, the\nconditional probability of observing xj\n, given the parameters\n and membership scores, is\nPrxj\n;  \n\nK\nk\nfxj\nkj\n2. If membership scores  are realizations of latent variables\nfrom some distribution D\n\n, parameterized by vector , then\nthe probability of observing xj\n, given the parameters, is\nPrxj\n,  \n\nK\nk\nfxj\nkj\n\ndD\n\nSampling Scheme. Suppose R independent replications of J dis-\ntinct characteristics are observed for one subject, {x\n(r), . . . ,\nx\nJ\n(r)}\nR\nr1. Then, if the membership scores are treated as realiza-\ntions from distribution D\n\n, the conditional probability is\nPr\nx\nr, . . . , x\nJ\nR\n, \n\n\nJ \nR \nK\nk\nfx\nj\nrkj\n\ndD\n\n.\nWhen the latent variables are treated as unknown constants, the\nconditional probability for observing R replications of J variables\ncan be derived analogously. In general, the number of observed\ncharacteristics J does not need to be the same across subjects, and\nthe number of replications R does not need to be the same across\nobserved characteristics.\nOne can derive examples of mixed-membership models from\nthis general set up by specifying different choices of J and R and\ndifferent latent-variable assumptions. Thus, the ``grade-of-\nmembership'' model of Manton et al. (8) assumes that polyto-\nmous responses are observed to J survey questions without\nreplications and uses the fixed-effects assumption for the mem-\nbership scores. Potthoff et al. (9) use a variation of the grade-\nof-membership model by treating the membership scores as\nDirichlet random variables; the authors refer to the resulting\nmodel as ``Dirichlet generalization of latent class models.''\nErosheva (6) provides a formal latent-class representation for\nthe grade-of-membership model approach. In genetics, Prit-\nchard et al. (10) use a clustering model with admixture. For\ndiploid individuals, the clustering model assumes that R  2\nreplications (genotypes) are observed at J distinct locations\n(loci), treating the proportions of a subject's genome that\noriginated from each of the basis subpopulations as random\nDirichlet realizations. Variations of mixed-membership models\nfor text documents called ``probabilistic latent semantic analysis''\n(11) and ``latent Dirichlet allocation'' (12) both assume that a\nsingle characteristic (word) is observed a number of times for\neach document, but the former model considers the membership\nscores as fixed unknown constants, whereas the latter treats them\nas random Dirichlet realizations.\nThe mixed-membership model framework presented above\nunifies several specialized models that have been developed\nindependently in the social sciences, genetics, and text-mining\napplications. In the text-mining area, initial work by Hofmann\n(11) on probabilistic latent semantic analysis was followed by the\nwork of Blei et al. (12), who proposed a Dirichlet generating\ndistribution for the membership scores and the use of variational\nmethods to estimate the latent Dirichlet allocation model pa-\nrameters. Minka and Lafferty (13) developed a more accurate\napproximation method for this model.\nA natural extension of the original analyses in the text-mining\narea that have been based on a single source is to combine\ninformation from multiple sources. Cohn and Hofmann (14)\npropose a probabilistic model of document content and hyper-\ntext connectivity for text documents by considering links (or\nreferences) in addition to words, thus essentially combining two\ndistinct characteristics; they treat the membership scores as\nfixed. Following Cohn and Hofmann, we adopt a mixed-\nmembership model for words and references in journal publi-\ncations but treat the membership scores as random Dirichlet\nrealizations. Barnard et al. (15) develop similar and alternative\napproaches for combining different sources of information.\nMixed-Membership Models for Documents\nWe can use the general model framework for documents con-\nsisting of abstracts and references by representing a document as\nd  ({x\n(r2)}), where x\n(r1) is a word (w) in the abstract and\nx\n(r2) is a reference (r) in the bibliography, rj  1, . . . , Rj\n. By\nadopting the ``bag-of-words'' assumption, we treat the words in\neach abstract as independent replications of the first observed\ncharacteristic (word). Similarly, under the assumption of a ``bag\nof references,'' we treat references as independent replications\nof the second observed characteristic (reference). Thus, the\nrepresentation of a document consists of word counts n(w, d)\n(the number of times word w appears in document d) and\nreference counts n(r, d) (1 if the bibliography of d contains a\nreference to r, and 0 otherwise). In this context, subpopulations\nrefer to topical aspects.\nThe parameters  of our model are: Dirichlet (hyper)param-\n, . . . , K\nfor the generating distribution of the member-\nship scores and aspect multinomial probabilities for words\n(w)  p(wk) and references 2k\n(r)  q(rk), k  1, 2, . . . , K.\nIn the generative model, documents d  ({x\n(r2)}) are\nsampled according to the following sequence,\n  Dirichlet, [4]\nx\nr1  multinomialp\n\n, where p\n\n\n\nK\nk\nx\nr2  multinomialq\n\n, where q\n\n\n\nK\nk\nwhere \u00a5w 1k\n(r)  1, k  1, . . . , K. Because\ndistributions of words and references in a document are convex\ncombinations of the distributions of the aspects, the aspects can\nbe thought of as extreme or basis categories for a collection of\ndocuments. The sampling of words and references in the model\ncan be interpreted also as a latent classification process in which\nan aspect of origin is drawn first for each word and for each\nreference in a document, according to a multinomial distribution\nparameterized by the document-specific membership scores ,\nand words and references then are generated from correspond-\ning distributions of the aspects of origin (6). Rather than a\nmixture of K latent classes, the model can be thought of as a\n``simplicial mixture'' (13) because the word and reference\nprobabilities range over a simplex with corners 1k\n,\nrespectively.\nThe likelihood function is thus\npd \nDir\n\nw\np\n\nwnw,d\n\nr\nq\n\nrnr,dd [7]\n\ni\ni\n\ni\ni\n\n\nk\ni\n\nw\np\n\nwnw,d\n\nr\nq\n\nrnr,dd,\nwhere integrals are over the (K  1) simplex.\nIt is important to note that the assumption of exchangeability\namong words and references (conditional independence given\nthe membership scores) does not imply joint independence\namong the observed characteristics. Instead, the assumption of\nexchangeability means that dependencies among words and\nreferences can be explained fully by the membership scores of\nthe documents. For an extended discussion on exchangeability in\nthis context, see ref. 16.\nAlternative Model for References\nFor the analysis of PNAS publications in the next section, we\nassume multinomial sampling of words and references. Although\nmultinomial sampling is computationally convenient, it is not a\nrealistic model of the way in which authors select references for\nthe bibliography of an article. We briefly describe an example of\nmore realistic generative assumptions for references.\nSuppose an article focuses on a sufficiently narrow scientific\narea. In this case, the authors may have essentially perfect\nknowledge of the literature, and thus they would pay separate\nattention to each article in their pool of references as they\nconsider whether to include it in the bibliography. Under these\ncircumstances, given that the pool of references contains R\narticles, we assume that a document is represented as d \n({x\n, . . . , xR1\n), where x\n(r1) is a word in the abstract,\nR is the number of references, and x2\n, . . . , xR1\nare all references\nin the pool. Reference counts do not change: they are given by\nn(r, d)  1 if the bibliography of d contains a reference to r and\nby n(r, d)  0 if otherwise.\nThen our model for generating documents would be to sample\n and x\n(r1), according to Eqs. 4 and 5, and sample xj\n, j  2, . . . ,\nR  1, according to\nxj\n Bernoulliq\n\nxj\n, where q\n\nxj\n \n\nK\nk\njk\nThe likelihood function based on this alternative model would\nnot only take into account which documents contain which\nreferences, but it also would incorporate the information about\nwhich references documents do not contain.\nBoth the basic model for references and any alternatives still\nwould need to reflect the time ordering on publications and\ninclude in the pool of possible references only those that have\nbeen published already, perhaps even with a short time lag.\nHowever, even such changes are unlikely to produce a ``correct''\nmodel for citation practices.\nEstimating the Model\nThe primary complication in using a mixed-membership model\nsuch as is shown in Eqs. 4\u00ad6, in which the membership proba-\nbilities are random rather than fixed, is that the integral in Eq.\n7 cannot be computed explicitly and therefore must be approx-\nimated. Two approximation schemes have been investigated\nrecently for this problem and the associated problem of fitting\nthe model. In the variational approach (12), the mixture terms\np\n\n(w)  \u00a5\n(w) are bounded from below in a product\nform that leads to a tractable integral; the lower bound is then\nmaximized. A related approach, called expectation\u00adpropagation\n(13), also approximates each mixture term in a product form but\nchooses the parameters of the factors by matching first and\nsecond moments. Either of these approximations to the integral\n(Eq. 7) can be used in an approximate expectation\u00ad\nmaximization (EM) algorithm to estimate the parameters of the\nmodels. It is shown in ref. 13 that expectation\u00adpropagation in\ngeneral leads to better approximations than the simple varia-\ntional method for mixed-membership models, although we ob-\ntained comparable results with both approaches on the PNAS\ncollection. The results reported below use the variational\napproximation.\nThe PNAS Database\nThe National Academy of Sciences provided the database for the\nparticipants of the colloquium. We focused on a subset of all\n2001) of PNAS, thereby ignoring articles published in the social\nand physical sciences unless they have official dual classifications\nwith one classification in the biological sciences. The reason for\nthis narrowing of focus is 2-fold. First, the major share of PNAS\npublications in recent years represents research developments in\nthe biological sciences. Thus, of 13,008 articles published in\nThe share of social and physical sciences articles in volumes\ncollection of articles is characterized by mixed membership in a\nnumber of internal categories, and social and physical sciences\narticles are unlikely to share the same internal categories with\narticles from the biological sciences. We also automatically\nignore other types of PNAS publications such as corrections,\ncommentaries, letters, and reviews, because these are not tra-\nditional research reports. Among the biological sciences articles\nin our database, 11 articles were not processed because they did\nnot have an abstract, and 1 article was not processed because it\ndid not contain any references.\nPNAS is one of world's most cited multidisciplinary scientific\njournals. Historically, when submitting a research paper to\nPNAS, authors have to select a major category from physical,\nbiological, or social sciences and a minor category from the list\nof topics. PNAS permits dual classifications between major\ncategories and, in exceptional cases, within a major category. The\nlists of topics change over time to reflect changes in the National\nAcademy of Sciences sections. PNAS, in its information for\nauthors (revised in June 2002), states that it classifies publica-\ntions in biological sciences according to 19 topics; the numbers\nof published articles and numbers of dual-classified articles in\neach topic are shown in Table 1.\nThe topic labels provide a classification structure for pub-\nlished materials, and most of the articles are members of only a\nsingle topic. For our mixed-membership model, we assume that\nthere is a fixed number of extreme internal categories or aspects,\neach of which is characterized by multinomial distributions over\nwords (in abstracts) and references (in bibliographies). Aspects\nare determined from contextual decompositions in such a way\nthat a multinomial distribution of words and references in each\ndocument is a convex combination of the corresponding distri-\nbutions from the aspects. The convex combination for each\narticle is based on proportions of the article's content coming\nfrom each category. These proportions, or membership scores,\ndetermine soft classifications of articles with respect to internal\ncategories.\nResults\nChoosing a suitable value for the number of internal categories\nor aspects, K, in this type of setting is difficult. In our analyses,\nwe focused largely on two versions of the model: one with 8\naspects and the other with 10. The set of parameters in our model\nis given by multinomial word and reference probabilities for each\naspect and by the parameters of Dirichlet distribution, which is\na generating distribution for membership scores. There are\nnumbers of parameters involved, it is difficult to assess the extent\nto which the added pair of aspects actually improves the fit of the\nmodel to the data. On the basis of a set of preliminary compar-\nisons, we found little to choose between them in fit and greater\nease of interpretation for the eight-aspect model. Therefore, we\nreport only the results of the eight-aspect model here.\nTo determine whether there are certain contexts that corre-\nspond to the aspects, we examine the most common words in the\nestimated multinomial distributions. In Table 2, we report the\nfirst 15 of the high-probability words for each aspect, filtering out\nso-called stop words, words that are generally common in\nEnglish. An alternative way would be to discard the words from\nthe ``stop list'' before fitting the model. If the distribution of stop\nwords is not uniform across the internal categories, this alter-\nnative approach may potentially produce different results.\nThe following interpretations are based on examination of 50\nhigh-probability words for each aspect. Note that enumeration of\nthe aspects is arbitrary. The first aspect includes words such as\nCa2, kinase, phosphorylation, receptor, and G (protein) chan-\nnel, which pertain to cell signaling and intracellular signal\ntransduction. It is likely that, in this aspect, signal transduction\nTable 1. Biological sciences publications in PNAS volumes 94\u00ad98\nby subtopic\nTopic n\nThe numbers of articles with dual classifications are given in parentheses.\nTable 2. High-probability words for each aspect\nAspect 1 P Aspect 2 P Aspect 3 P Aspect 4 P Aspect 5 P Aspect 6 P Aspect 7 P Aspect 8 P\nis considered as applied to neuron signaling as indicated by the\nwords synaptic, neurons, voltage. It is interesting that Ca2 in the\nfirst aspect is the highest-probability contextual word over all\nthe aspects. Frequent words for the second aspect indicate that\nits context is related to molecular evolution that deals with\nnatural selection on the population and intraspecies level and\nmechanisms of acquiring genetic traits. Words in aspect 3 pertain\nmostly to the plant molecular biology area. High-probability\nwords in aspect 4 relate to studies of neuronal responses in mice\nand humans, which identify this aspect as related to develop-\nmental biology and neurobiology. Aspect 5 contains words that\ncan be associated with biochemistry and molecular biology.\nWords in aspect 6 point to genetics and molecular biology.\nFrequent words for aspect 7 contain such terms as immune, IL\n(or interleukin), antigen, (IFN) gamma, and MHC class II, which\npoint to a relatively new area in immunology, namely, tumor\nimmunology. The presence of such words as HIV and virus\nin aspect 7 indicates a more general immunology content.\nFor aspect 8, words such as increase or reduced, treatment,\neffect, fold, and P (assuming it stands for P value) correspond to\ngeneral reporting of experimental results, likely in the area of\nendocrinology.\nAs for words, multinomial distributions are estimated for the\nreferences that are present in our collection. For estimation, we\nTable 3. High-probability references by aspect\nFor each aspect, the top references are shown in order of decreasing probability, according to the model. The\ncount of each reference in the PNAS collection is shown in the right column (C).\nonly need unique indicators for each referenced article. After the\nmodel is fitted, attributes of high-probability references for each\naspect provide additional information about its contextual in-\nterpretation. Table 3 provides attributes of 15 high-probability\nreferences for each aspect that were available in the database\ntogether with PNAS citation counts (number of times cited by\nPNAS articles in the database). Notice that, because the model\ndraws from the contextual decomposition, having a high citation\ncount is not necessary for having high aspect probability. In\nTable 3, high-probability references for aspect 1 are dominated\nby publications in Nature; references in aspect 7 are mostly\nNature, Cell, and Science publications from the mid-1990s.\nExamining titles of the references (see Table 5, which is\npublished as supporting information on the PNAS web site,\nwww.pnas.org), we see that manuals, textbooks, and references\nto methodology articles seem to be prominent for many aspects.\nThus, among the first 15 high-probability references, all 15 from\naspect 3 and more than half from aspect 4 are of this method-\nFig. 1. Distributions by aspect of the posterior means of membership scores for articles published in evolution and genetics.\nological type. In contrast, most high-probability references for\naspect 7 are those that report new findings. Titles of the\nreferences indicate neurobiology content for aspect 1, molecular\nevolution for aspect 2, and plant molecular biology for aspect 3,\nwhich is in agreement with our conclusions based on high-\nprobability words. For other aspects, titles of high-probability\nreferences help us refine the aspects. Thus, aspect 4 mostly\npertains to the study of brain development, in particular, via\ngenetic manipulation of mouse embryo. Aspect 5, identified as\nbiochemistry and molecular biology by the words, can be de-\nscribed as protein structural biology by the references. Aspect 6\nmay be labeled in a more detailed way as ``DNA repair,\nmutagenesis, and cell cycle.'' The references for aspects 7 and 8\nshift their focuses more toward HIV infection and studies of\nmolecular mechanisms of obesity.\nAmong frequent references for the eight aspects, there are\nseven PNAS articles that share a special feature: they were all\neither coauthored or contributed by a distinguished member of\nthe National Academy of Sciences. In fact, one article was\ncoauthored by a Nobel prize winner, and two were contributed\nby other Nobelists. Although these articles do not have the\nhighest counts in the database, they are notable for various\nreasons; e.g., one is on clustering and gene expression (2), and\nit is also one of the two highly cited PNAS articles on clustering\nthat we mentioned in the Introduction. These seven articles may\nnot necessarily be off-beat, but they may be among those that\nfulfill MacLane's petition regarding the special nature of PNAS.\nFrom our analysis of high-probability words, it is difficult to\ndetermine whether the majority of aspects correspond to a single\ntopic from the official classifications in PNAS biological science\npublications. To investigate whether there is a correspondence\nbetween the estimated aspects and the given topics, we examine\naspect loadings (means of posterior membership scores) for each\narticle. Given estimated parameters of the model, the distribu-\nTable 4. Mean decompositions of aspect membership scores (Lower), together with a graphical representation of this\ntable (Upper)\nTopic\nFor clarity, the six lowest-frequency topics, which make up 3.4% of the biological sciences articles, are not shown.\ntion of each article's loadings can be obtained by means of Bayes'\ntheorem. The variational and expectation\u00adpropagation proce-\ndures provide Dirichlet approximations to the posterior distri-\nbution p(d, ) for each document d. We use the mean of this\nDirichlet as an estimate of the weight of the document on each\naspect. Histograms of these loadings are provided in Fig. 1 for\narticles in evolution and genetics. Relatively high histogram bars\nnear zero correspond to the majority of articles having small\nposterior membership scores for the given aspect. Among the\narticles published in genetics, some can be considered as full\nmembers in aspects 2, 3, 4, and 6, but many have mixed\nmembership in these and other aspects. Articles published in\nevolution, on the other hand, show a somewhat different behav-\nior: the majority of these articles comes fully from aspect 2.\nThe sparsity of the loadings can be gauged also by the\nparameters of the Dirichlet distribution, which are estimated as\nDirichlet, which is the generative distribution of membership\nscores, is ``bathtub-shaped'' on the simplex; as a result, articles\ntend to have relatively high membership scores in only a few\naspects.\nTo summarize the aspect distributions for each topic, we\nprovide mean loadings and the graphical representation of these\nvalues in Table 4 Upper. Larger values correspond to darker\ncolors, and the values below some threshold are not shown\n(white) for clarity. As an example, the mean loading of 0.2883 for\npharmacology in the first aspect is the average of the posterior\nmeans of the membership scores for this aspect over all phar-\nmacology publications in the database. Note that this percentage\nis based on the assumption of mixed membership and can be\ninterpreted as indicating that 29% of the words in pharmacology\narticles originate from aspect 1, according to our model.\nExamining the rows of Table 4, we see that most subtopics in\nbiological sciences have major components from more than one\naspect (extreme or basis category). Examining the columns, we\ncan gain additional insights in interpretation of the extreme\ncategories. Aspect 8, for example, is the aspect of origin for a\nmedical sciences articles, according to the mixed-membership\nmodel. The most prominent subtopic is evolution; it has the\ngreatest influence in defining an extremal category, aspect 2.\nThis is consistent with a special place that evolution holds among\nthe biological sciences by standing apart both conceptually and\nmethodologically.\nFinally, we compare the loadings (posterior means of the\nmembership scores) of dual-classified articles to those that are\nsingly classified. We consider two articles as similar if their\nloadings are equal for the first significant digit for all aspects.\nOne might interpret singly classified articles that are similar to\ndual-classified as articles that should have had dual classification\nbut did not. We find that, for 11% of the singly classified articles,\nthere is at least one similar dual-classified article. For example,\nthree biophysics dual-classified articles with loadings 0.9 for the\nsecond and 0.1 for the third aspect turned out to be similar to 86\nsingly classified articles from biophysics, biochemistry, cell bi-\nology, developmental biology, evolution, genetics, immunology,\nmedical sciences, and microbiology.\nConcluding Remarks\nWe have presented results from fitting a mixed-membership\nmodel to PNAS biological sciences publications, from 1997 to\n2001, providing an implicit semantic decomposition of words and\nreferences in the articles. The model allows us to identify\nextreme internal categories of publications and to provide soft\nclassifications of articles into these categories. Our results show\nthat the traditional discipline classifications correspond to a\nmixed distribution over the internal categories. Our analyses and\nmodeling were intended to capture a high-level description of a\nsubset of PNAS articles.\nIn an often-quoted statement, Box remarked: ``all models are\nwrong'' (17). In our case, the assumption of a bag of words and\nreferences in the mixed-membership model clearly oversimpli-\nfies reality; the model does not account for the general structure\nof the language, nor does it capture the compositional structure\nof bibliographies. Many interesting extensions of the basic model\nwe have explored are possible, from hierarchical models of topics\nto more detailed models of citations and dynamic models of the\nevolution of scientific fields over time. Nevertheless, as Box\nnotes, even wrong models may be useful. Our results indicate\nthat mixed-membership models can be useful for analyzing the\nimplicit structure of scientific publications.\nWe thank Dr. Anna Lokshin (University of Pittsburgh, Pittsburgh) for\nhelp with interpreting model results from a biologist's perspective. E.E.\nwas supported by National Institutes of Health Grants 1 R01\n2. Eisen, M. B., Spellman, P. T., Brown, P. O. & Botstein, D. (1998) Proc. Natl.\n3. Tamayo, P., Slonim, D., Mesirov, J., Zhu, Q., Kitareewan, S., Dmitrovsky, E.,\n4. Rosenberg, N. A., Pritchard, J. K., Weber, J. L., Cann, H. M., Kidd, K. K.,\n6. Erosheva, E. A. (2002) Ph.D. thesis (Carnegie Mellon University, Pittsburgh).\n8. Manton, K. G., Woodbury, M. A. & Tolley, H. D. (1994) Statistical Applications\nUsing Fuzzy Sets (Wiley Interscience, New York), p. 312.\n9. Potthoff, R. G., Manton, K. G., Woodbury, M. A. & Tolley, H. D. (2000) J.\n12. Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3,\n13. Minka, T. P. & Lafferty, J. (2002) Uncertainty in Artificial Intelligence:\nProceedings of the Eighteenth Conference (UAI-2002) (Morgan Kaufmann, San\nPress, Cambridge, MA).\n15. Barnard, K., Duygulu, P., Forsyth, D., de Freitas, N., Blei, D. M. & Jordan, M. I.\n16. Blei, D. M., Jordan, M. I. & Ng, A. Y. (2003) in Bayesian Statistics 7: Proceedings\nof the Seventh Valencia International Meeting, eds. Bernardo, J. M., Bayarri,\nM. J., Dawid, A. P., Berger, J. O., Heckerman, D., Smith, A. F. M. & West, M.\n(Oxford Univ. Press, Oxford), pp. 25\u00ad44.\n17. Box, G. E. P. (1979) in Robustness in Statistics, eds. Launer, R. L. & Wilkinson,\nG. G. (Academic, New York), p. 202."
}