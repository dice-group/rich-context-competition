{
    "abstract": "Abstract. We report three behavioral experiments on the spatial characteristics evoking illusory face\nand letter detection. False detections made to pure noise images were analyzed using a modified\nreverse correlation method in which hundreds of observers rated a modest number of noise images\n(480) during a single session. This method was originally developed for brain imaging research,\nand has been used in a number of fMRI publications, but this is the first report of the behavioral\nclassification images. In Experiment 1 illusory face detection occurred in response to scattered dark\npatches throughout the images, with a bias to the left visual field. This occurred despite the use of\na fixation cross and expectations that faces would be centered. In contrast, illusory letter detection\n(Experiment 2) occurred in response to centrally positioned dark patches. Experiment 3 included\nan oval in all displays to spatially constrain illusory face detection. With the addition of this oval the\nclassification image revealed an eyes/nose/mouth pattern. These results suggest that face detection\nis triggered by a minimal face-like pattern even when these features are not centered in visual focus.\n",
    "reduced_content": "a Pion publication\nFaces in the mist: illusory face and letter detection\nCory A. Rieth\nDepartment of Psychology, University of California, San Diego, La Jolla, CA 92093-0109, USA;\ne-mail: crieth@ucsd.edu\nKang Lee\nDepartment of Psychology, University of California, San Diego, La Jolla, CA 92093-0109, USA, and\nInstitute of Child Study, University of Toronto, Toronto, ON M5R 2X2, Canada; e-mail: kang.lee@utoronto.ca\nJiangang Lui\nDepartment of Biomedical Engineering, School of Computer and Information Technology, Beijing Jiaotong\nUniversity, Beijing 100044, China; e-mail: liujg@fingerpass.net.cn\nJie Tian\nSchool of Life Science and Technology, Xidian University, Xi'an 710071, China, and Institute of\nAutomation, Chinese Academy of Sciences, P. O. Box 2728, Beijing 100190, China; e-mail: tian@ieee.org\nDavid E. Huber\nDepartment of Psychology, University of California, San Diego, La Jolla, CA 92093-0109, USA;\ne-mail: dhuber@ucsd.edu\n Keywords: vision, face perception, reverse correlation, letter perception, top down, false detection.\n1 Introduction\nWhen looking at randomly positioned lunar craters, arbitrary wisps of cloud, or a scattered\npile of rocks, one often has the impression of seeing a face. Illusory detection is termed\n\"pareidolia\", and popular examples include the Man on the Moon, the face in the Cydonia\nregion of Mars, and the faces of numerous religious icons in toasted food (Svoboda 2007).\nProviding many other examples, a blog called \"faces in places\" catalogs everyday objects that\nlook like faces (http://facesinplaces.blogspot.com/). Although these objects are not mistaken\nfor actual faces, they evoke the percept of a face in a compelling manner. In contrast to false\nface recognition, which is the mistaking of one face for another, illusory face detection is the\nreported detection of a face when no face image exists.\nThe process of falsely recognizing visible faces has been heavily investigated, particularly\nas it relates to false identifications during police lineups (Lindsay et al 1991), but the processes\nunderlying face detection, especially illusory face detection, are not well understood at the\nbehavioral level (Lewis and Edmonds 2003). Nevertheless, recent research has examined\nillusory detection and similar paradigms using neuroimaging. The fusiform face area (FFA)\nis an area in the inferotemporal cortex that exhibits greater responses for faces than most\nother objects (Kanwisher et al 1997). The FFA is not only preferentially active when viewing\nfaces (e.g., bottom-up processing) but is also active during top-down face processing--\nfor example, when imagining faces (O'Craven and Kanwisher 2000), when anticipating\nfaces (Esterman and Yantis 2010), and when interpreting bistable images as faces (Andrews\net al 2002; Hasson et al 2001). However, these tasks either present a coherent bottom-up\nsignal (e.g., a bistable image that is easily interpreted as a face) or rely on the introspective\nprocesses of the observer (e.g., instructions to imagine a face). To address these limitations,\nwe developed a new technique for eliciting illusory face detection that provides completely\nambiguous noise, thus providing a relatively pure measure of top-down processing without\nreliance on introspection. Using this paradigm, we examined the neural correlates of both\nZhang et al 2008). In the current experiments we used this same paradigm to provide the\nfirst behavioral account of the visual template that observers likely used while experiencing\nillusory detection in these fMRI experiments.\nIn this illusory detection paradigm faces or letters become progressively more difficult to\nperceive throughout the experiment until, unbeknownst to observers, every trial presents\na pure noise image. Using observers' detection responses in combination with measures\nof neural activity, we found that the FFA is selectively active when detecting illusory faces\n(Zhang et al 2008). Additionally, we identified a distributed network of brain areas involved\nin illusory face detection (Li et al 2009, 2010). This network largely overlaps with regions that\nare active when viewing actual faces (Fairhall and Ishai 2007; Ishai 2008), except that some\nearlier visual areas are absent, such as the occipital face area. For illusory letter detection\na similar distributed network of brain regions was identified (Liu et al 2010, 2011). Missing\nfrom these investigations is specification of the spatial attributes of a noise image that tend\nto promote illusory detection of faces or letters. In other words, these studies tell us which\nbrain regions are involved in illusory detection, but they do not tell us what visual properties\nactivated those brain regions. The current experiments answer this question by replicating\nthe illusory face and letter detection experiments outside the scanner. Using a technique\ncalled \"reverse correlation\" (Dayan and Abbott 2001), we computed correlations between\ndetection responses and the noise images. In this way, we determined the aspects of the\nnoise images that trigger illusory detection for faces and letters.\n1.1 Outline of the current experiments\nFaces and letters are two very different classes of objects in terms of their visual properties.\nFor instance, any two faces are much more visually similar to each other than are any two\nletters. In light of these differences a comparison between illusory detection of faces and\nletters may seem unwise. However, beyond the fact that our paradigm has already been used\nin fMRI experiments with these two classes of stimuli there are other advantages to this\ncomparison. For instance, faces and letters are two classes of visual stimuli that have been\nheavily studied, and most adults are expert at identifying both. Furthermore, letters and faces\nappear to be processed in different parts of the brain; and, correspondingly, there are distinct\nneuropsychological deficits for each stimulus class (e.g., prosopagnosia and dyslexia). Of\ncritical importance for the current experiments, the brain regions that are specialized for\nfaces and letters appear in opposite cortical hemispheres: the FFA typically resides in the\nright hemisphere (Kanwisher et al 1997), while the visual word form area typically resides in\nthe left hemisphere (McCandliss et al 2003). This cortical laterality may exhibit itself in the\nform of spatial laterality differences for the noise patterns that promote illusory detection of\nfaces and letters.\nExperiments 1 (illusory face detection) and 2 (illusory letter detection) are direct repli-\nexcept that the current experiments collected data from many more observers to determine\nthe spatial attributes of the noise images that tend to promote illusory detection. Experiment\n460 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\n3 tested whether additional bottom-up constraints could eliminate the noncentrality of face\ndetection by including an oval in the noise images.\nReverse correlation techniques were originally developed to study the spatial characteris-\ntics of neural receptive fields (Dayan and Abbott 2001; Jones and Palmer 1987; Movshon et\nal 1978; Ringach and Shapley 2004). To determine the spatial characteristics that promote\ndetection responses, a correlation is calculated for each observer at each pixel position for the\nrelationship between luminance (e.g., gray scale value as determined by adding pixel noise\nto an image) and whether the observer detected a target on the corresponding trial (in the\ncase of a neuron, detection is determined by spike rate). This analysis creates a \"classification\nimage\" (CI) showing regions of the noise images where luminance correlated with responses.\nTo study illusory detection, our design and analysis deviated from typical behavioral reverse\ncorrelation experiments by using all noise images, averaging detection responses over a large\nnumber of observers, using complex but random images, and establishing the expectancy of\ntargets though training blocks instead of through inclusion of targets on a subset of trials.\nFigure 1 provides a graphical summary of the typical techniques used and an overview of\nthe design of the current study. This variant is new, and our results demonstrate its ability to\nidentify the biases and expectations that underlie detection of an object class.\nMost reverse correlation experiments based on behavioral responses present a true target\nimage combined with independent pixel noise such that detection is influenced by the\nparticular noise pattern on each trial (e.g., Ahumada 1996; Gold et al 2000; Kontsevich and\nTyler 2004). This is also true for studies using neural measurements in humans (Smith et al\n2008, 2009). For example, to find the visual features necessary to detect a smile, observers\nwere shown the Mona Lisa combined with noise and asked to rate her emotional expression\non a scale from sad to happy (Kontsevich and Tyler 2004). Using targets combined with\nnoise to investigate illusory detection of faces and letters is problematic for two reasons.\nFirst, if a target is present, detection is not illusory. Second, a detection task for the same\ntarget image on every trial may differ from illusory detection for any item from the object\nclass. To study top-down expectations for detection of faces and letters as object classes\nwithout contamination from bottom-up information, we needed a task that did not include\nactual target images during the critical experimental trials. We also needed observers to\nexpect any face rather than a particular face (or letter). Therefore, we used a training phase\nthat presented a variety of different centered face/letter images mixed with noise, with\nthese targets becoming progressively more difficult to detect. Eventually, target images were\nomitted entirely, and only noise images were used for the remainder of the experiment. This\ntraining established top-down expectations about what class of object to expect (faces in\nExperiments 1 and 3, and letters in Experiment 2) and where to expect an exemplar from\nthat object class (in the center of the image). Although a previous study has used noise-only\nimages to create a behavioral CI (Experiment 1 of Gosselin and Schyns 2003), this is the first\ntime that this has been done with detection of an object class rather than a specific target\n(e.g., the Mona Lisa's smile) or a specific exemplar (e.g., the letter \"s\"). This is an important\ndistinction. With a known target observers may adopt a search strategy that is unique to that\ntarget (i.e., reliance on specific low-level visual features). In contrast, for the detection of an\nunknown target from an object class, observers are forced to rely on class general top-down\nexpectations.\nThe presence of visible targets appearing throughout the experiment helps observers\nstay focused on the detection task across the thousands of trials used in a typical reverse\ncorrelation experiment. However, illusory detection for an object class would be contami-\nnated by including visible targets on a subset of trials because the preferred image would\nbe heavily biased towards the specific form of the most recently seen target. Therefore, to\nFigure 1. The top panel (a) illustrates the basic design of the experiments. Training started with 40 easy\ntrials, 50% of which contained actual targets. The second block of 40 trials was similar, but the target\nfaces or letters were more difficult to detect. Unknown to observers, the final 40 training trials used\nonly pure noise images. Following training, observers responded to 480 pure noise images presented in\nblocks of 60. The panels (c) and (d) on the bottom left illustrate aspects of typical neural and behavioral\nreverse correlation experiments. The bottom right (d) shows stimuli presented to observers during\nExperiment 1 (top row), Experiment 2 (middle row), and Experiment 3 (bottom row). The same set of\npure noise images were used for all three experiments. Target stimuli for training used 20 different\npictures of male and female Asian faces in the face detection experiments, or the letters \"s\", \"o\", \"r\", \"u\",\n\"a\", \"c\", \"e\", \"m\", and \"n\" in the letter detection experiment. The faces in the hard training images may\nbe hard to see at the size reproduced here but were clearly visible in the experiment, as evidenced by\nthe accuracy of observers.\nkeep observers engaged throughout the experiment, and to reduce boredom and fatigue, we\nused both a smaller number of trials (480) and complex noise images. The use of complex\nnoise images has been shown to produce reliable results and to reduce the number of trials\nrequired for behavioral reverse correlation (Hansen et al 2010). By using complex noise\nimages that lend themselves to many interpretations, it is more plausible that a particular\nimage might contain a target. Nevertheless, even complex noise images cannot produce a\nreliable CI from only 480 observations.\n462 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\nTo gain the necessary statistical power, we analyzed the results over a large group of\nobservers. This allowed us to statically generalize the resulting CI across observers rather\nthan relying solely on within-observer analyses. However, it is possible that each observer\nmight base their detection responses upon a unique, observer-specific spatial pattern. To the\nextent that this occurs, this introduces additional noise into the results, reducing reliability\nof the CI. Furthermore, if each observer viewed a different small set of noise images, the\nresultant CI would include sampling noise across observers and sampling noise across\ndifferent noise images (i.e., both observer and noise image would be random factors). To\naccount for this, in our paradigm we used the same set of 480 noise images for all of the\nobservers instead of using a completely different noise image every trial. In other words,\nwe increased reliability by using a repeated measures design. However, this introduced\nthe issue that our results, while reliable, may be driven by the particular sample of noise\nimages. Therefore, we also counterbalanced the orientation of the 480 noise images across\ndifferent groups of observers to ensure that the particular sample of noise images did induce\nparticular spatial attributes of the CI, such as horizontal or vertical asymmetries. This is an\nimportant control given that several variables of interest were spatial distribution analyses of\nthe classification images (e.g., central versus peripheral or left versus right). A lateral bias\nthat changed with the orientation of the noise images would indicate that the lateral bias was\ninherent in the noise images and, accordingly, that illusory detection was strongly influenced\nby bottom-up attributes.\n2 Materials and methods\nIn total, 699 undergraduate students participated across three experiments: 229 in Experi-\nment 1, 211 in Experiment 2, and 259 in Experiment 3. All observers participated for course\ncredit, gave informed consent, and were debriefed as to the nature of the experiment. The\nstudy was approved by the University of California, San Diego (UCSD) institutional review\nboard.\nNoise images for the experiment were created by combining dark blobs at random spatial\npositions. The randomly positioned blobs were two-dimensional Gaussian distributions with\nthree different spatial standard deviations, resulting in three different blob sizes. Furthermore,\nthe number of randomly positioned blobs varied inversely with their size. These three spatial\nscales were combined to create 480 different noise images that were 480\u00d7480 pixels in size.\nAs viewed, these images subtended 14 deg of visual angle horizontally and vertically. The\nsame 480 noise images were used for all observers in all experiments except for the addition\nof an overlaid oval in Experiment 3. An additional 120 noise images were created for training.\nWe previously used these same stimuli in several fMRI studies with Chinese observers (Li et\nEvery image on every trial contained a black fixation cross in the middle of the image.\nTarget stimuli for face training were created by overlaying each noise image with a true\nface image that was centered. In total, there were 20 different true face images (10 male, 10\nfemale) that were of approximately the same size. Because we sought illusory detection of\nany face, we could have used a mix of different size faces, although doing so would have\nreduced the reliability of the CI (i.e., we induced consistency in terms of the size and location\nof the targets but not the specific form of the targets). These 20 faces were all Asian in\nappearance, which was a reasonable constraint considering that the largest segment of the\nUCSD undergraduate population is Asian. To promote a bias for the center of the display,\nthe image mixing proportion between the true images and the noise images was a Gaussian\ndistribution centered on the image, thus causing the edges of the face to fade into the noisy\nbackground. Two different mixing proportions were used for the first (easy) and second (hard)\nblocks of training, such that the true images were either easily seen or barely discernible. For\nletter training in Experiment 2 noise images were combined with true images of the letters\n\"s\", \"o\", \"r\", \"u\", \"a\", \"c\", \"e\", \"m\", and \"n\". In pilot testing we found that letters with only straight\nsegments were too easy to detect (i.e., illusory detection of straight letters seemed unlikely),\nmost likely because the noise images contained no straight segments. Thus, we chose this\ngroup of letters because they contained curved line segments, which allowed the impression\nthat the pure noise images might contain one of these letters. Participants were not informed\nthat these were the only letters that would appear. Letter stimuli were created using the Arial\ntypeface and blurred with a 7 pixel Gaussian blur to remove hard edges. In the bounded\nimages used in Experiment 3 an oval roughly the size of the training faces was added to all\nimages in the experiment. Examples are shown in Figure 1.\nObservers were instructed to detect faces (Experiments 1 and 3) or letters (Experiment 2).\nFor example, observers who detected faces with the left key were told:\nYou will see a number of images. The task is to press the left arrow if you think there could be a\nface, or the right arrow if not. The task will start easy, but will get very hard. You may feel like\nyou are guessing but other research suggests you can be quite accurate. Focus on the fixation\nin between images. You should respond with the presence of a face about half the time. The\nimages will only stay on screen briefly so respond quickly.\nObservers completed three training blocks of 40 trials each, followed by six experimental\nblocks of 80 trials that contained only pure noise images. Between blocks, observers rested\nfor at least 15 s. The trials within each block were presented in a random order for each\nobserver. For the first two blocks of training half of the trials presented a true image in noise\n(face or letter, as appropriate), while the other half presented pure noise images. The first\ntraining block presented easy to detect targets, the second block presented hard to detect\ntargets, and the third block presented only pure noise images. Between the training blocks\nthey were told that the task would get harder. Before the experimental blocks they were told\nthe difficulty of the task would be maintained. Before both the pure noise training block\nand the first experimental block they were encouraged to respond with detection responses\nabout half of the time.\nEach trial began with a fixation cross presented for 200 ms followed by an image that\nremained on the screen until a response was given or 600 ms elapsed, which was immediately\nfollowed by the fixation cross of the next trial. Observers made responses by pressing labeled\nkeys to indicate detection or nondetection. No feedback was given. Across observers, image\norientation was counterbalanced by presenting the 480 noise images either in their original\norientation or 180 rotated. This manipulation demonstrated that the observed left visual\nfield bias for face detection was not an artifact of the particular 480 pure noise images.\nExperiment 3 included an additional left/right control by counterbalancing response key\nacross observers. Furthermore, in Experiment 3 all of the images (training and noise) were\nhorizontally flipped as compared with their presentation in Experiments 1 and 2 so that the\nright side of the image was mapped to the left side of the image. Unlike rotation, which would\ninvert any face-like pattern that appeared in a particular noise image, horizontal mirroring\nwould preserve any face-like pattern but would place it in the opposite visual field.\nA few observers guessed the nature of the experiment and never detected targets during\nexperimental trials. However, during postexperiment questioning, the vast majority of\n464 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\nobservers indicated that they were convinced that targets appeared on some proportion\nof experimental trials. Across all observers the proportions of trials for which participants\nindicated illusory detections were 32%, 36%, and 36% for Experiments 1, 2, and 3, respectively\n(s.e.m = .013, .012, and .012). Observers whose hit rate for the first training block with\neasy targets was less than 40% or who had fewer than five illusory detections during the\nexperimental trials were eliminated from further analysis. These criteria eliminated 24.5% of\nparticipants from Experiment 1 (173 remained, 79 with the original image orientation and\nmirrored images and the original response keys, 52 with mirrored images and the swapped\nresponse keys, 43 with mirrored and rotated images and the original response keys, and 53\nwith mirrored and rotated images and the swapped response keys). Response statistics for\nthe remaining observers are shown in Table 1.\nTable 1. Mean response measures for the observers that met the criteria for inclusion.\nBlock Hit rate False alarm\nrate\nd\nEasy training\nExperiment 3: bounded face\ndetection\nHard training\nExperiment 3: bounded face\ndetection\nNoise-only training\nExperiment 3: bounded face\ndetection\nNoise-only experimental\nExperiment 3: bounded face\ndetection\nNote: Standard error of the means are given in parentheses; na = nonapplicable.\nBecause our experimental method is new we used two methods to analyze the results.\nBoth reached the same conclusions regarding the spatial distribution of correlation values\nacross the classification images. In the first analysis we created a separate CI for each observer\nin the traditional manner and compared the median correlations between different image\nregions using a repeated measures ANOVA. Because each observer rated only 480 images,\nthese median correlation values based on individual CIs were small. However, because these\nvalues were analyzed across individuals, regional differences were reliable. This method\nof analysis allowed us to make claims regarding the population of observers, and it also\nallowed us to evaluate the role of between-observer control factors such as image orientation.\nHowever, because this method was based on median correlations within a spatial region, it\ndid not allow analyses of the distribution of correlation values across pixels within a spatial\nregion. To analyze these distributions, a second analysis method evaluated a single between-\nobserver CI for each experiment by correlating the proportion of detection responses for\neach image with the luminance of each pixel. The significance of this CI and measurements\nof it were then evaluated using null sampling distributions that were generated by repeatedly\nshuffling observer responses (i.e., Monte Carlo sampling).\n3.1 Repeated measures analyses of individual CIs\nIn the first analysis method a CI was created for each observer by correlating their detec-\ntion/nondetection response with the luminance (i.e., gray scale value) of each pixel across\nthe 480 noise images viewed during the experimental portion of the study. The spatial\ndistribution of CIs for each experiment were analyzed by finding the median pixel correlation\nwithin different spatial regions of interest for each observer's CI. These median correlation\nvalues were then analyzed using an ANOVA with observer as a random factor. Control factors\nsuch as image rotation and response key were included in the analyses. Correlation values\nwere largest for the central regions, and so all analyses were performed on the center ninth\nof the CIs, based on an evenly spaced three-by-three grid over the entire image.\nFirst, we compared the left and right halves of the center region (see insets at the top of\nFigure 2). Dark areas on the left of images were more correlated with detections than the right\nthe center region were compared, revealing no differences for Experiment 1, F(1,171) < 1, or\nTo provide a more fine-grained spatial analysis, the center region, which resulted from\na three-by-three grid over the whole image, was itself further divided into three rows by\nthree columns (see inset of Figure 2, upper right). For Experiment 1 the only significant\nwas middle, to left, to right, and post hoc tests, adj = .017, showed that the middle column\nthese effects were largely driven by the center region, which had much larger correlations\nmiddle-right, lower-left, and lower-middle regions were additionally more correlated than\nIn contrast to Experiment 2, corrected comparisons showed that pixels in the upper-left\nregion had stronger correlations than the middle-left, middle-right, and lower-right regions,\nt  3.39, p-values  .001, and that the center and lower middle had higher correlations than\nNext, we report the results of the control variables. These control variables were coun-\nterbalanced across observers, and the focus of these analyses was on interactions between\nthe control variables and the spatial characteristics of the CIs. There were no interactions\nwith image orientation for Experiment 1, F-ratios < 1.45, p-values > .238. In Experiment\n2 = .092. The interactions of image orientation with halves are shown along the left and\nmiddle columns of Figure 2. For the images shown in their original orientation, the right was\nsignificantly more correlated than the left, t(85) = 2.26, p = .026, and there was a marginal\n466 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\ndifference such that the bottom was more correlated than the top, t(85) = 1.93, p = .056.\nBoth of these effects reversed when the images were rotated: left more correlated than right,\nof the column-by-orientation interaction, adj = .017, showed that for the original orientation\nimages there were differences between the center columns and each side: both t(85)  3.22,\nboth p-values  .002. But for the rotated images both the center and left regions had stronger\nwere no significant interactions with image rotation or response key for any of the analyses,\nFigure 2. Repeated measures analyses of individual classification images (CIs) based on the median\ncorrelations within different regions of each observer's CI. The left column compares the left and right\nhalves of the center region of the image as indicated by the inset at the top of the column. Between\nobservers the 480 noise images were rotated, and the results of this control variable are shown, which\nproduced an interaction effect only for illusory letter detection. Error bars are \u00b11 standard error of the\nmean difference between the median left and median right correlation for each observer. The center\ncolumn shows the correlations in the top and bottom center regions of the image in a similar manner.\nError bars are \u00b11 standard error of the mean difference between the median top and median bottom\ncorrelation for each observer. The right column compares correlation values in the three-by-three grid\nshown in the inset. Error bars are \u00b11 standard error of the mean median correlation.\n3.2 Monte Carlo analyses of between-observer CIs\nA second set of analyses was based on between-observer CIs rather than on the individual\nCIs. A between-observer CI was calculated based on the correlation between pixel luminance\n(i.e., gray scale value) and the proportion of observers who gave detection responses to\nan image containing that pixel. The detection proportions for each image were computed\nas the number of detection responses divided by the sum of the number of detection and\nno-detection responses (i.e., excluding no-response trials). Including no-response trials\ndid not change the results. It is worth noting that these between-observer CIs were nearly\nidentical in appearance to the average of the individual CIs. Null hypothesis distributions\nwere determined separately for each pixel location. Thus, if there were a systematic bias in\nthe noise images (i.e., a tendency for dark areas to be on the left), it would be reflected in\nthe null sampling distributions. These analyses allowed a fine-grained spatial evaluation by\nexamining clusters of pixels within the CIs.\nThe expected distribution of correlation values at each pixel location from random\nresponding was determined by running 5,000 Monte Carlo simulations for each experiment.\nFor each Monte Carlo simulation the mapping between the 480 detection probabilities and\nthe 480 images was randomly reshuffled. The resulting means and standard deviations at\neach pixel location were used to calculate z-scores for each observed pixel correlation, which\nare displayed in the right column of Figure 3. To verify that the correlation values were\nnormally distributed, we performed a Lilliefors test (i.e., a Kolmogorov-Smirnov test with\nunknown parameter values) separately for each of the 230,400 pixels of each experiment.\nSetting  = .05, 5% of the pixels produced correlation distributions that differed significantly\nfrom a normal distribution (i.e., the proportion of rejections was exactly as expected based\non the chosen type-I error rate).\nNext, the distribution of correlation values was assessed by counting the number of pixels\nin the top versus bottom and in the left versus right that exceeded a chosen correlation\nthreshold. Correlation thresholds were defined by the proportion of the largest absolute\ncorrelations; a rank-ordered list of all the absolute correlations for the entire image was\nformed from largest to smallest, and different proportions of this list were included in the\nanalyses. As shown in Figure 4, the pixel counts for one region were subtracted from the\nother region to yield a measure of relative spatial bias. The black lines in the figures show the\nobserved biases, and the dashed red lines show 95% confidence intervals for this measure\nbased on the Monte Carlo simulations. Similar to the repeated measures analyses, these\nanalyses were carried out only for the middle region of the display, as shown by the insets\nof the figure. As seen in the left column of Figure 4, face detection revealed a left bias (both\nExperiment 1 and Experiment 3), replicating the ANOVA analyses. As seen in the right column\nof Figure 4, only bounded face detection (Experiment 3) showed any reliable vertical bias,\nwith the most reliable correlations found in the top half.\nBeyond assessing different spatial regions, the between-observer CIs were used to assess\nthe nature of pixel clusters (i.e., correlations between pixels). To some degree, regions of\ncorrelated pixels were expected because the noise images contained Gaussian blobs rather\nthan independent pixel noise. However, because the noise images contained Gaussian blobs\nof different sizes, we could evaluate biases for pixels of different cluster sizes across the\nthree experiments. Regions were defined as groups of contiguous pixels with the absolute\nvalue of correlations above a threshold proportion. The number of contiguous regions, mean\nsize of regions, and standard deviation of region sizes were computed for varying threshold\nproportions for the observed between-observer CIs and the Monte Carlo CIs. The results are\nplotted in Figure 5. For small threshold proportions the observed data of all three experiments\nrevealed fewer clusters than expected by chance and that those clusters were larger and more\n468 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\nFigure 3. Left: the average of the 40 true images viewed during training. Right: the between-observer\nclassification images (CIs) for Experiment 1 (top, N = 173), Experiment 2 (middle, N = 188), and\nExperiment 3 (bottom, N = 201). Each pixel's color is defined by its z-score as calculated from a null\ndistribution generated by 5,000 Monte Carlo simulations. The z-score color map scales are shown to the\nright of each CI. A Sid\u00e1k correction for  = .05 places the z-cutoff at -5.05: only negative z-scores (i.e.,\nthe yellow and red regions) reliably correlated with the proportion of detection responses, indicating\nthat observers based their detections on dark rather than on light patches. The color mapping is\nscaled for each experiment so that the top and bottom 0.1% of correlations are shown with the same\nminimum or maximum color.\nvariable in size than would be expected. However, these effects were greatly magnified for\nletter detection, which had the smallest number of regions that were of the largest size.\n4 Discussion\n4.1 Summary of results\nIn a pure noise illusory detection paradigm Experiment 1 produced a distributed, but reliable,\nCI that was biased towards dark areas of the left side of the noise images. The observed\ncorrelations were significant and larger than would have occurred with random responding,\nand yet there was no obvious structure to the CI. Instead, the CI revealed a seemingly random\npattern of peripheral dark patches with a left bias. This distributed pattern occurred despite\nthe use of a fixation cross on all trials and centered faces during initial training. Experiment\n2 used the same technique for a task that induced illusory letter detection, addressing the\nFigure 4. The distribution of correlation values within different regions of the between-observer\nclassification images (CIs). These graphs show the difference in the number of pixels that fall into one\nregion of the CI versus another region (e.g., left minus right) as a function of a threshold proportion\nthat determined which pixels to include in the analysis (i.e., the threshold proportion indicates the\nproportion of all pixels to include in the analysis based on the absolute magnitude of correlation\nvalues). Thus, in moving from left to right, the graphs use an increasingly liberal criterion for inclusion\nof pixels. The black line shows this analysis based on the observed data, and the red dashed lines are\n95% confidence intervals as determined by Monte Carlo sampling. The left column shows lateral bias\n(left minus right), and the right column shows vertical bias (top minus bottom), with these regions\nshown in the insets.\npossibility that illusory detection of any object class would yield similar results. However,\nthere was no consistent laterality bias, and letter detection was strongly influenced by dark\npatches in the center of the pure noise images (in fact, these correlations were more central\nthan expected based on the training images, as can be seen by comparing the left and right\ncolumns of Figure 3). Furthermore, there were interactions for letter detection between the\norientation of the images and the lateral biases in the images, which was not seen in the\nface detection experiments. Experiment 3 used the same procedure as Experiment 1 with\nthe addition of an oval on the noise images to test if this would induce a more face-like CI\nby spatially constraining the location of illusory detections. The CI for Experiment 3 does\nhave the rough appearance of a face, but still reveals a left bias. The regions corresponding to\nthe dark areas of a face (eyes/eyebrows, nostrils, and mouth: upper left, center, and lower\n470 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\nFigure 5. Monte Carlo analyses of between-observer classification images to evaluate clusters of\ncorrelated pixels. For pixel correlations greater in magnitude than the proportion threshold the number\n(left column), size (middle column), and standard deviation (right column) of spatially contiguous\ngroupings of pixels are plotted. The experimentally observed values are in black, and 95% confidence\nintervals from the Monte Carlo sampling are plotted as red dashed lines.\nmiddle, respectively) correlated more strongly with detection responses, with a tendency for\nthe left to be more strongly correlated than the right.\n4.2 Methodological implications and considerations\nUnlike previous studies using behavioral reverse correlation, these experiments investigated\nillusory detection of an object class rather than a specific target exemplar. Furthermore, these\nexperiments demonstrated that between-observer classification images can be obtained\nusing a small number of noise images with many observers.\nThe use of an illusory detection paradigm (i.e., only noise images) introduces a complica-\ntion in that some observers may produce much higher false alarm rates than other observers\n(Wenger et al 2008). To the extent that this occurs, it introduces noise in the CIs because some\nobservers respond due to a bias to respond in general rather than respond based on a good\nmatch between the noise image and their internal template. For this reason it was important\nto carefully assess the reliability of the CIs for illusory detection, and so we used two different\nanalysis techniques to test the generality of the statistical conclusions. While there were\nindividual differences in response rates, both analysis techniques produced qualitatively\nsimilar results: (1) illusory face detection was left lateralized despite the expectation of\ncentral targets; (2) unbounded face detection occurred in response to dark patches dispersed\nthroughout the noise image; and (3) illusory detection of letters occurred in response to\ncentral dark patches and was more consistently driven by the bottom-up information\ncontained in the noise images.\nIn interpretating these results, we must consider the training images that established the\ndemand characteristics of the detection task. To promote reliable results, the training images\nappeared in the same location, were roughly the same size, and did not include the full\ndiversity of all possible faces or letters. If training had presented faces or letters of different\nsizes and at different positions, then the CIs would most likely have been dispersed in all\nconditions (although for methods examining reverse correlation with detection at different\nlocations, see Tjan and Nandy 2006). Rather than using training images, Gosselin and Schyns\n(2003) used a pure noise procedure with only verbal instructions about what to detect.\nTheir paradigm required a few dedicated observers taking part in multiple sessions, and the\ntarget stimulus was a specific letter or the form of a mouth within the context of visible face\noutline rather than an object class. Their mouth detection experiment is of particular interest\nbecause it most closely corresponds to our Experiment 3 in that both studies provided the\noutline of the face while asking that observers detect interior components of the face. Similar\nto their results, Experiment 3 produced the CI that most closely resembled a face. This\nvalidated our paradigm, which was very different from the Gosselin and Schyns paradigm\nin many respects. This validation was important because Experiment 1 produced radically\ndifferent results from other uses of reverse correlation, suggesting that observers detected\nfaces in different regions of the pure noise images despite the use of a fixation cross and\ndespite initial training that faces would occur only in the center of the display.\nOne potential concern in comparing the results of letter and face detection is that the\nimages of the letters viewed during training were slightly smaller than the faces viewed during\ntraining (although note that, as presented in noise, their subjective sizes are comparable; see\nFigure 1). Even so, the CI for the letter detection task revealed a pattern that was more\ncentralized than the actual letters viewed during training, whereas the CI for the face\ndetection task of Experiment 1 revealed a pattern that was less centralized than actual\nfaces viewed during training. Thus, slight differences in the size of the training objects cannot\nexplain the difference in the spatial dispersion of the CIs.\n4.3 Theoretical implications\nThis paradigm was originally developed to study the neural correlates of illusory detection\nwith fMRI, which is a technique that is limited to a modest numbers of trials. The fMRI\nexperiments identified distributed patterns of neural activation involved in top-down\nBy collecting data from a large number of observers, the current experiments examined\nbehavioral results with this paradigm to ascertain the spatial patterns that tend to promote\nillusory detection. Thus, between the prior fMRI experiments and the current behavioral\nexperiments we have identified both the neural and visual attributes of illusory face and\nletter detection.\nUnlike face detection, the spatial distribution for letter detection was more tightly focused\non the center. This difference is consistent with the hypothesis that top-down face processing\nis less constrained by spatial position, which produced the seemingly random pattern in\nExperiment 1 due to the superposition of separate spatially displaced face-like patterns.\nUnlike illusory letter detection, illusory face detection also revealed a left bias, which is\n472 C. A. Rieth, K. Lee, J. Lui, J. Tian, D. E. Huber\nconsistent with prior work with visible faces and with the anatomical location of face-specific\nareas of the cortex. However, this left bias in Experiment 1 could have resulted from an\nexpectation for faces to appear on the left, or from a central form that was itself left biased\n(e.g., stronger emphasis on the left eye), such as observed in Experiment 3. It is notable\nthat the observed correlations in Experiment 3 resemble the dark central features of a face\n(e.g., eyes/nose/mouth) but not other face features such as ears or forehead. In summary,\nby stripping away bottom-up visual information, we obtained support for the claim that\ntop-down face processing is relatively unconstrained by the task demand to detect objects at\nthe point of fixation.\nWe interpret this as evidence that top-down face detection is more strongly driven by form\nthan by the location of that form. In other words, if observers responded to face-like patterns\nregardless of where on the screen those patterns occurred, then the summation of all the\nseparate face detections would produce a spatially distributed pattern similar to what was\nobserved. An alternative interpretation is that each observer consistently expected faces in a\ndifferent spatial region (e.g., some observers expected faces on the left, while others expected\nfaces on the right). The current results cannot determine whether the dispersion pattern\nof Experiment 1 reflects individual observer differences or whether it reflects individual\ntrial differences. But regardless of which explanation is correct, both explanations entail\ndetection of faces in noncentral portions of the display despite the use of central faces\nduring training and the use of a fixation cross on all trials. These results suggest that face\ndetection is systematically triggered by sensory information even if that information is\nfound in unexpected locations. Thus, illusory face detection in everyday situations may\nbe a common occurrence due to a tendency to detect faces based on a simple minimal\neye/nose/mouth pattern not only within the current focus of the eyes but also for more\nperipheral areas of a visual scene. This does not necessarily indicate that face detection is\nmore accurate than letter detection. Rather, because there is a high cost when failing to detect\na true face (e.g., mistaking your wife for a hat, Sacks 1985), there may be a lower threshold\nfor the information necessary to trigger face detection, even in locations where no face is\nexpected. This results in detection of faces that do exist at the cost of occasional illusory face\ndetection.\nBoth face detection experiments showed a left-side bias. This bias is consistent with\nbehavioral studies and neural evidence. Behavioral research has established a bias toward\nSergent 1984). Furthermore, studies using the \"bubbles\" reverse correlation technique found\nqualitative (Gosselin and Schyns 2001; Schyns et al 2002) and quantitative (Gosselin et al\n2010) evidence for a left-side bias. Because the right hemisphere of the brain receives initial\ninput from the left visual field, electrophysiological studies finding larger responses in the\nright cortical hemisphere when viewing a face are consistent with a left-side bias (Bentin et\nlateralization for faces was also confirmed with neuroimaging data (Kanwisher and Yovel\nleft side of a face and the right hemisphere, observers with greater left-side bias in face\nrecognition had greater right lateralized fusiform gyrus activation when viewing faces (Yovel\nOn average, illusory letter detection showed no lateral bias even though a right-side bias\nmight be expected due to the left hemisphere lateralization of language and reading (Binder\n2003) and perceptual biases for the right visual field while reading and detecting letters\nHowever, these prior studies used clearly visible letters, whereas our experiments did not\ninclude any consistent bottom-up information and created strong expectations that letters\nwould appear only in the center. Consistent with our results, other studies using reverse\ncorrelation to study letter detection similarly failed to find spatial biases (Fiset et al 2009;\nCompared with illusory face detection, illusory letter detection produced stronger\ncorrelations and interacted with the orientation of the specific stimuli (i.e., for letter detection\nthe images produced a right-side bias in their original orientation but a left-side bias\nwhen rotated). This suggests that letter detection is more strongly driven by the bottom-up\ninformation contained in the noise images and so there was greater reliability between\nobservers in determining which particular noise images did, or did not, appear to contain\na letter. Furthermore, the central pattern for letters suggests that illusory letter detection is\nmore spatially localized (e.g., the expectation that letters will be well foveated), which may\nhave contributed to the greater between-observer reliability for letters.\nFinally, we consider the relation between these results and brain imaging studies of face\nperception. Our results provide an important missing piece of the puzzle when interpreting\nneural studies of face processing. In conjunction with the currently reported behavioral\nresults, this suggests that face processing has a frequently engaged top-down component\nwhereby the brain creates a face interpretation based on a minimal eyes/nose/mouth pattern,\nregardless of visual location. These results suggest that the areas of the brain involved in face\nperception may be wired to automatically identify faces across the entire visual scene to a\ngreater extent than letters.\n5 Conclusions\nUsing a paradigm previously developed to investigate the neural correlates of illusory\ndetection, our experiments investigated the spatial patterns that promote illusory detection\nof faces and letters. Our results suggest that a minimal face-like pattern is sought when\ndetecting faces (Experiment 3) and that, in the absence of face contour illusory, face detection\ncan occur in peripheral to the expected central location (Experiment 1). In contrast, letter\ndetection produced larger correlation values (i.e., it occurred more consistently in response\nto particular intensities); and, unlike faces, letter detection revealed a strong central bias\n(Experiment 2). Finally, unlike letters, which did not on average produce a lateral bias, face\ndetection was biased towards the left side of the display regardless of whether an oval was\nincluded to constrain face detection. These results suggest that face detection is more heavily\ntop down and less constrained by task expectations (i.e., training that faces appear only in\nthe center) as compared with letter detection.\n"
}