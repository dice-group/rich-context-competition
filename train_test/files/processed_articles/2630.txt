{
    "abstract": "ABSTRACT\nA major obstacle to developing evidenced-based policy is the difficulty of\nimplementing randomized experiments to answer all causal questions of\ninterest. When using a nonexperimental study, it is critical to assess how\nmuch the results could be affected by unmeasured confounding. We\npresent a set of graphical and numeric tools to explore the sensitivity of\ncausal estimates to the presence of an unmeasured confounder. We\ncharacterize the confounder through two parameters that describe the\nrelationships between (a) the confounder and the treatment assignment\nand (b) the confounder and the outcome variable. Our approach has two\nprimary advantages over similar approaches that are currently\nimplemented in standard software. First, it can be applied to both\ncontinuous and binary treatment variables. Second, our method for\nbinary treatment variables allows the researcher to specify three possible\nestimands (average treatment effect, effect of the treatment on the\ntreated, effect of the treatment on the controls). These options are all\nimplemented in an R package called treatSens. We demonstrate the\nefficacy of the method through simulations. We illustrate its potential\nusefulness in practice in the context of two policy applications.\n",
    "reduced_content": "Assessing Sensitivity to Unmeasured Confounding Using a\nSimulated Potential Confounder\nNicole Bohme Carnegiea, Masataka Haradab, and Jennifer L. Hillc\n KEYWORDS\ncausal inference\nsensitivity analysis\nunmeasured confounder\nhidden bias\nomitted variable\nOne of the biggest struggles in policy analysis is the inability to directly study many ques-\ntions of interest using randomized experiments. Attempts to infer causality using nonexperi-\nmental studies are vulnerable to violations of the assumption that requires, colloquially\nspeaking, that all confounders have been measured. Rather than abandoning the goal of\ncausal inference using nonexperimental data, methods that allow researchers to explore sen-\nsitivity of their inferences to violations of this assumption can act as a middle ground. These\napproaches help to build confidence in the results of nonexperimental studies by differentiat-\ning between studies whose results are relatively immune to potential unmeasured confound-\ners versus those whose results might change drastically.\nThis article presents a set of graphical and numeric tools to investigate the sensitivity of\ncausal estimates in nonexperimental studies to the presence of an unmeasured confounder.1\nCONTACT Nicole Bohme Carnegie carnegin@uwm.edu Joseph J. Zilber School of Public Health, University of\naUniversity of Wisconsin-Milwaukee, Milwaukee, Wisconsin, USA\nbNational Graduate Institute for Policy Studies, Tokyo, Japan\ncNew York University, New York, New York, USA\n1Throughout the article we use the term \"unmeasured confounder\" rather than using terms such as \"omitted variable\" or\n\"unobserved covariate\" for the sake of consistency and clarity. In practice it is possible that this variable was measured but\nwas simply omitted from the analysis.\n\u00a9 Nicole Bohme Carnegie, Masataka Harada, and Jennifer L. Hill.\nThis is an Open Access article. Non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly\nattributed, cited, and is not altered, transformed, or built upon in any way, is permitted. The moral rights of the named author(s) have been\nasserted.\nWe characterize the confounder through two parameters which describe (a) the relationship\nbetween the confounder and the treatment assignment and (b) the relationship between the\nconfounder and the outcome variable. Our approach to assessing sensitivity to an unmea-\nsured confounder has two primary advantages over similar approaches (with two sensitivity\nparameters) that are currently implemented in standard software. First, it can be applied to\nboth continuous and binary treatment variables. Second, our method for binary treatment\nvariables allows the researcher to specify three possible estimands (average treatment effect,\neffect of the treatment on the treated, effect of the treatment on the controls). All tools\ndescribed in this article are available in an R package called treatSens.\nBrief Overview of Approaches to Assess Sensitivity to Unmeasured Confounding\nThe term \"sensitivity analysis\" has several meanings in empirical data analysis. In the field of\ncausal inference this term typically refers to approaches that assess the sensitivity of causal\nestimates to the presence of unmeasured confounders. This is sometimes referred to as sensi-\ntivity to \"unmeasured confounding\" or to \"hidden bias\" (Rosenbaum, 2002a). These meth-\nods have a long history in applied statistics, beginning perhaps with the exploration by\nCornfield et al. (1959) into the robustness of the causal link between smoking and cancer, in\nwhich the magnitude of hidden bias necessary to explain away the observed relationship\nbetween smoking and risk of cancer was quantified. Other seminal work in this area includes\nbinary outcome and a categorical covariate by Rosenbaum and Rubin (1983).2 Nevertheless,\ncomparatively little attention has been paid to this important topic compared to other topics\nin causal inference.\nExtant methods for evaluation of sensitivity to hidden bias can be roughly divided into\nsemi- or nonparametric approaches and parametric approaches. Work on semi- or nonpara-\nmetric approaches to sensitivity analysis has been dominated by the contributions of Rose-\nnbaum and colleagues (chapter 4 in Rosenbaum, 2002b provides an overview) although\nothers (for example, Steenland & Greenland, 2004) have made important contributions as\nwell. Rosenbaum presents several methods of assessing sensitivity in studies with matched\npairs of treated and control observations (Rosenbaum, 1987), for analyses with strata con-\ntaining multiple matched controls to each treated observation (Rosenbaum, 1988), for\nmatched case-control studies (Rosenbaum, 1991), and for unmatched, two-sample observa-\ntional studies (Rosenbaum & Krieger, 1990).3 These rely on nonparametric randomization\ntests such as McNemar's test for binary treatments and outcomes (Greenland, 1996; Rose-\nnbaum, 1987) or Wilcoxon signed-rank test for continuous outcomes.4 As an applied exam-\nple, Buckley and Schneider (2007, chapter 9) assess the sensitivity to unmeasured\nconfounding of the causal effect of charter schools on parent satisfaction using Rosenbaum's\nmethods for the Wilcoxon signed-rank test.\n2Ichino, Mealli, and Nannicini (2008) developed a computational approach along this line; sensatt (Nannicini, 2007) performs\ntheir sensitivity analysis in Stata.\n3In Stata, rbounds (DiPrete & Gangl, 2004) performs the sensitivity analysis of Rosenbaum (2002b) for continuous outcome var-\niables, while mhbounds (Becker & Caliendo, 2007) performs the counterpart for binary outcome variables. In R, rbounds (Keele,\n4Some of these methods are nonetheless categorized as a semiparametric due to their reliance on a parametric model to\nestimate propensity scores used to match or stratify.\nAlthough these methods have the appeal of avoiding parametric assumptions, they also\nhave several limitations. First and foremost the bulk of the nonparametric methods require\nthe researcher to first create matched samples (typically based on the propensity score),\nwhich itself can be a labor-intensive process with uncertain results (see, e.g., Hill, Weiss, &\nZhai, 2011). Another concern with these methods is that they have been shown to be sensi-\ntive to the choice of test statistic used (Rosenbaum, 2010).5\nTraditionally, a primary drawback of these approaches was that they only allowed the\nresearcher to explore sensitivity based on a range of assumptions about the relationship\nbetween the unmeasured confounder and the treatment assignment. For instance, in the\nseminal work by Rosenbaum (2002a), the sensitivity parameter G sets bounds on the odds of\none member of a perfectly matched pair receiving the treatment relative to the other receiv-\ning the treatment; the association between the confounder and the outcome, however, is\nassumed to be nearly collinear. This simplification is overly conservative and may lead\nresearchers to be more concerned with violations of ignorability than is merited. In more\nrecent work, Rosenbaum and Silber (2009) have extended this paradigm to decompose the G\nparameter into a constrained set of corresponding parameters that reflect both the associa-\ntion between the unobserved confounder and the treatment as well as the association\nbetween the unobserved confounder and the sign of the difference in outcomes across mem-\nbers of the matched pairs. This extension has the merit of allowing the researcher to consider\na wider range of potential unobserved confounders. However, it loses information about a\ncontinuous outcome variable by dichotomizing the treatment versus control difference into\na simple categorization of a positive or negative difference in outcomes (ignoring the magni-\ntude of this difference).\nParametric approaches to sensitivity analysis have their own strengths and weaknesses.\nThese generally begin with a model familiar to applied researchers, such as a t test for the dif-\nference in means across treatment groups, a standard linear regression, a logistic or probit\nregression for dichotomous dependent variables, or one of several survival models, and then\nmake additional assumptions about the relationship between hypothetical unmeasured con-\nfounders and both the selection to treatment and the outcome measure (for examples, see,\nThese models typically allow for specification of two sensitivity parameters: one that\ndescribes the relationship between the unmeasured confounder and the treatment assign-\nment and one that describes the relationship between the unmeasured confounder and the\noutcome.6 They have the drawback of making potentially restrictive assumptions about the\nparametric form of the models for the outcome and the treatment assignment. Of course,\nfor researchers with a taste for more robust model estimation, this drawback could be\naddressed by using these approaches on matched samples. In other words, these approaches\nallow for, but do not require, use of matching to address concerns regarding parametric\nassumptions.\nGiven the difficulty in implementing randomized experiments and the widespread\nconcern with the assumptions required in nonexperimental studies, it is curious that\n5However, recent work by Rosenbaum (2011) presents a promising alternative statistic.\n6Some methods in this realm (McCandless, Gustafson, & Levy, 2007; Rosenbaum & Rubin, 1983 for instance,) rely on still more\nsensitivity parameters, which we find to be prohibitively complicated for standard usage. A few strategies, such as the one\nsuggested by Altonji et al. (2005) require only one sensitivity parameter but this restriction unfortunately makes it quite diffi-\ncult to interpret.\nsensitivity analysis methods have not gained more traction among applied researchers\ninterested in pursuing causal questions. This persists despite the recent availability of\nsoftware (within Stata and R) to implement the nonparametric methods. We posit that\none of the biggest barriers has been the difficulty of understanding the sensitivity\nparameters in the nonparametric approaches and the related difficulty of calibrating\nthose to the empirical context. For this reason we have pursued the parametric\napproaches that, as we shall demonstrate, allow for sensitivity parameters that are easier\nto understand and calibrate, do not require (but do allow for) matched samples, and\nallow for separate specification of associations between the unmeasured confounder\nand the treatment and the unmeasured confounder and the outcome.\nAmong the parametric methods currently available in standard software, our approach\nmost resembles two existing methods. The first was proposed by Imbens (2003) and is a\nlikelihood-based approach specific to a context with a continuous outcome (with a linear,\nadditive relationship with the covariates and treatment and normally distributed errors),\na binary treatment variable, and a binary unmeasured confounder. Sensitivity parameters\nare specified as the partial correlations between the unmeasured confounder and the\ntreatment and between the unmeasured confounder and the outcome. Optimization\nmethods are used to estimate the treatment effect conditional on specific values of the\nsensitivity parameters.7\nThe second method was proposed by Harada (2013). It uses residualized versions of the\noutcome (from a linear model conditional on the treatment and covariates) and the treat-\nment variable (from a linear model conditional on the covariates) to generate candidate val-\nues of the unmeasured confounder in a constrained range. The algorithm saves the\ncandidate values of the unmeasured confounder that change the estimate of the treatment\neffect by a specified amount. The corresponding values of the sensitivity parameters (partial\ncorrelations from linear models) can then be obtained by fitting the appropriate linear mod-\nels with the unmeasured confounder.8 Both approaches, as currently implemented, target\nthe average treatment effect.\nThe algorithm we propose in this article is likelihood-based like the Imbens method\nbut handles either a binary or a continuous treatment variable. Similar to Harada we\ngenerate candidate values of the unmeasured confounder; however, we draw these\ndirectly from the distribution of the confounder conditional on observed data (as\nderived from the specified complete-data likelihood); consequently our approach is\nmore computationally efficient than that of Harada. Our approach is not as computa-\ntionally efficient as Imbens's approach; however, it fits within a framework that will be\neasier to generalize in future work to accommodate complications such as multilevel\ndata and nonlinear/nonparametric models. Moreover, our approach can target any of\nthree different causal estimands: the effect of the treatment on the treated, the effect of\nthe treatment on the controls, or the average treatment effect. The other two\napproaches, as currently implemented, can only estimate the average treatment effect.\nSimilar to the other two approaches, we have built software that will be available to\nresearchers; ours is implemented in the freely available R software package.\nCausal Inference Notation and Theoretical Framework\nThis work is motivated to address a lack of confidence in the assumption, commonly\ninvoked with observational data, that we have measured all confounders. In statistics, this\nassumption is formalized as a statement about the independence between the potential out-\ncomes and the treatment variable conditional on a set of covariates, X,\nY z\nand is referred to as the ignorability assumption.9 This is a critical assumption, because if it is\nsatisfied, we can identify causal effects simply by appropriately adjusting for the covariates in\nX (for instance by an appropriate model for Y conditional on the covariates and Z or by a\npropensity score approach).\nIt is rare, however, that researchers have confidence that this assumption holds. As a strat-\negy for exploring sensitivity to this assumption, we posit an unmeasured variable, U, that, if\nincluded, would serve to satisfy ignorability. That is, we assume that our set of potential out-\ncomes, Y(Z), is conditionally independent of the treatment assignment, Z, given both the\nvector of observed covariates, X, and an additional unmeasured confounder U. Thus, the\nignorability assumption would relax to the following version,\nY z\nWe illustrate the basic structure of our sensitivity analysis first assuming that our data\ncomprise independent, identically distributed units. In addition, we make modeling assump-\ntions. Specifically, we assume that, if ignorability is satisfied given X and U, the following\nequation holds\n\u00f0 \u00dejX; U\n\u00bd  D byX C zyU C tZ (3)\nThe observed Y for individual i is then given by Yi\nD E[Yi\n(Zi\n)jXi\n, Ui\n] C ei\n, where\nei\nand where by is the vector of regression coefficients for the covariate matrix X\nand t is the true population-level treatment effect.\nGiven the assumed correspondence between potential outcomes and the linear model and\nthe fact that we will be using linear models for the outcome throughout, we will henceforth\nrefer only to observed outcomes in our discussion of the statistical distributions required for\ninference.\nComplete Data Likelihoods and Conditional Distribution of the Unmeasured\nConfounder\nThe goal of our enterprise is to understand what treatment effect estimate we might have\nobtained had we conditioned on a posited unmeasured confounder U. To do this, as\ndescribed in more detail in the following section, we (a) specify a model for the way the\nworld works (in statistical terms, a complete-data likelihood), (b) use this model to derive\nhypothetical values of U based on our assumptions about its relationship with the outcome\nand the treatment (through sensitivity parameters), and (c) estimate the treatment effect\n9Ignorability is typically referred to as \"selection on observables\" in economics and \"all confounders measured\" or\n\"exchangeability\" in the epidemiology literature.\ngiven these potential values of U. This section describes the information pertinent to these\nfirst two steps. We start by specifying complete-data likelihoods for each of two scenarios,\ncorresponding to continuous and binary treatments, respectively.10 We then describe the\nconditional distribution of U that corresponds to each of these models.\nFirst, we motivate the (nonparametric) factorization of the joint complete data likelihood,\np Y; Z; UjX\nYjZ; U; X\nZjU; X\nThis factorization allows us to specify sensitivity parameters that correspond to conditional\nassociations between the unmeasured confounder, U, and both the outcome and the treat-\nment variable in a way that is familiar. In particular (as is made specific below) we can spec-\nify these sensitivity parameters as the coefficient on U in the regression of Y on Z, U, and X\nand the coefficient on U in the regression of Z on U and X. We make the additional assump-\ntion that U?X, giving p3\nU\n\u00f0 \u00de. Although some authors (Gustafson, McCandless,\nLevy, & Richardson, 2010) have argued that this is an overly restrictive assumption, we argue\nfor a conceptualization of U as that portion of the confounder that is independent of X.\nBecause most researchers are used to thinking about conditional associations (e.g., regression\ncoefficients) rather than marginal associations, we feel that this leads to more understandable\nand more easily calibrated sensitivity parameters. Moreover, it reduces the number of sensi-\ntivity parameters required. It also allows for a relatively simple specification for the distribu-\ntion of U.\nOur strategy for recovering treatment effects conditional on U requires generating a\npotential confounder _\nU consistent with the stated complete data likelihood so we can esti-\nmate the true treatment effect by conditioning on both X and the generated _\nU. In the next\nsections we derive the distribution of U given Y, Z, X, and our sensitivity parameters (defined\nbelow) for each of two complete-data likelihoods corresponding to different parametric\nmodels.\nContinuous Treatment Variable\nA reasonable starting point for pursuing this approach is to consider a scenario with contin-\nuous outcome, treatment variable, and unmeasured confounder modeled with normal distri-\nbutions. In particular we posit\nYjX; U; Z \u00bb N Xby C ; zyU C tZ; s2\ny \u00a2xuz\n \nZjX; U \u00bb N Xbz C ; zzU; s2\nz \u00a2xu\nu\nwhere by and bz represent the vectors of regression coefficients for the covariate matrix X,\nand t is the population-level treatment effect. It is natural to think of U as being normally\ndistributed if we conceptualize U as a linear combination of all unmeasured confounders,\nwhich is approximately normally distributed for a sufficient number of confounders or if the\n10We avoid creating a separate set of models for binary outcomes due to the issues with noncollapsibility inherent in such\nmodels (Greenland, Robins, & Pearl, 1999).\nconfounders are themselves normally distributed. With no loss of generality we can assume\nu\nD 1. zy and zz act as sensitivity parameters in the form of regression coefficients that\ndefine the relationship between the unmeasured confounder and the outcome (conditional\non X and Z) and the relationship between the unmeasured confounder and the treatment\nvariable (conditional on X), respectively.\nThis complete data likelihood implies the following distribution for U conditional on the\nother variables (for derivation see the appendix).\nUjX; Z; Y \u00bb N mu \u00a2xzy\nu \u00a2xzy\n \nmu \u00a2xzy\nD\nzz\nz\n~\nz\n~C\nz\n~\nzy\nz\n~\ny\n~\ny\n~\nu \u00a2xzy\nD\nz\n~\nz\n~\ny\n~\ny\n~\nz\n~\n \nwhere ~\nz; ~\n~\nz\n~\ny\ndenote the realized residuals and their respective variances from\nregressions run for Z conditional on X and for Y conditional on Z and X, respectively.\nWe can draw _\nU from an estimated version of this conditional distribution for any valid\ncombination of values for the sensitivity parameters (discussed in the \"General Algorithm\"\nsection) by plugging these values into the formula along with estimates of the required\nresidual variances.\nBinary Treatment Variable\nAlthough it is possible to use the above likelihood as an approximate solution for the situa-\ntion with binary Z, a more appropriate solution is to posit an alternate complete data likeli-\nhood for this scenario\nYjX; U; Z \u00bb N Xby C zyU C tZ; s2\ny \u00a2xuz\n \nZjX; U \u00bb Bernoulli F Xbz C zzU\n\u00f0 \u00de\nU \u00bb Bernoulli pu\nwhere F denotes the probit link. We posit a binary U in this scenario for reasons of mathe-\nmatical convenience.\nThe distribution of U conditional on the sensitivity parameters and observed data corre-\nsponding to this complete data likelihood is not as readily available as in the multivariate\nnormal case. Thus we rely on a computational trick to draw from the correct distribution.\nThis strategy capitalizes on the fact that if the parameters from the complete data likelihood\nwere known, the conditional distribution of U would be straightforward to define as a\nBernoulli distribution with probabilities equal to the ratio of appropriate likelihoods.\nUjY; Z; X \u00bb Bernoulli\npy;z;x;u D 1\npy;z;x\n \nwhere the numerator (representing the joint likelihood of the variables with U set equal to 1)\nand denominator (representing the likelihood after marginalizing over U) can be calculated\nusing the following formulas\ny \u00a2xuz\nexp \u00a1\nY \u00a1 Xby \u00a1 zy \u00a1 tZ\ny \u00a2xuz\n!\n\u00a2 1 \u00a1 F Xbz C zz\n\u00f0 \u00de\n\u00f0 \u00de F Xbz C zz\n\u00f0 \u00de\n\u00f0 \u00deZpu\nand\ny \u00a2xuz\nexp \u00a1\nY \u00a1 Xby \u00a1 tZ\ny \u00a2xuz\n!\n\u00a2 1 \u00a1 F Xbz\n\u00f0 \u00de\n\u00f0 \u00de F Xbz\n\u00f0 \u00de\n\u00f0 \u00deZ 1 \u00a1 pu\n\u00f0 \u00de\ny \u00a2xuz\nexp \u00a1\nY \u00a1 Xby \u00a1 zy \u00a1 tZ\ny \u00a2xuz\n!\n\u00a2 1 \u00a1 F Xbz C zz\n\u00f0 \u00de\n\u00f0 \u00de F Xbz C zz\n\u00f0 \u00de\n\u00f0 \u00deZpu\nThe challenge in making use of this distribution is that we not only do not know the true\nparameters needed to calculate the probabilities for this conditional distribution, we cannot\neven estimate all of them unbiasedly. In order to properly estimate by, t, and s2\ny \u00a2xuz\n, we\nwould need to know U. This motivates an iterative estimation strategy that is a form of Sto-\nchastic EM (expectation-maximization) algorithm (Neilsen, 2000). We iterate between two\nsteps. In the one step we estimate the model parameters in Equation 7 and Equation 8 condi-\ntional on the observed data and a draw of the vector U. In the other step we draw _\nU from its\nconditional distribution (as in Equation 10) conditional on the data and the parameter value\nestimates from the previous step. We repeat these steps enough times that we are confident\nthat we are drawing it from the correct distribution; in our applications this typically took\nSensitivity Analysis Algorithm and Treatment Effect Estimates\nThis section describes the algorithm we use to estimate treatment effects corresponding to a\nset of assumptions about our unmeasured U, codified in our sensitivity parameters. It also\ndescribes some extensions of the general algorithm and the plot that can be produced to dis-\nplay results. The algorithms and plots described here are implemented in the R package\ntreatSens.\nGeneral Algorithm\nFor any valid combination of sensitivity parameters, zz and zy, we generate an estimate of the\ntreatment effect, t, and the corresponding standard error through a multistep process based\non generation of a simulated potential confounder, _\nU, drawn from an estimate of the condi-\ntional distribution of UjY, Z, X. In the case of continuous treatment, this involves first\nobtaining residuals from linear models of E YjX; Z\n\u00bd  and E ZjX\n\u00bd , then plugging the residuals\nand their empirical variances into the closed-form formulas for the mean and variance of _\nU,\nand, finally, drawing _\nU from the corresponding normal distribution with the sensitivity\nparameters set to the given values. Once we obtain a realization of _\nU, we then fit a regression\nof Y on Z, X and _\nU, and record the estimate of t and the standard error of the estimate; we\ndenote these estimates as b\ntk\nzz; zy\n\u00f0 \u00de and ^\ns^\ntk\nzz;zy\n\u00f0 \u00de.\nIn the case of binary treatment, we do not need to estimate residuals, but rather iterate\nbetween estimating the parameters of E YjX; Z; _\nUk\nand E ZjX; _\nUk\nand drawing _\nfrom the distribution of UjY, Z, X, given those parameters. We find that the algorithm typi-\ncally converges in a small number of steps (less than 20 is usually sufficient). Once again the\nrealization of _\nU is used to obtain b\ntk\nzz; zy\n\u00f0 \u00de and ^\ns^\ntk\nzz;zy\n\u00f0 \u00de.\nOf course any single such estimate of t corresponds to just one realization from the\ndistribution of U and as such will reflect the idiosyncratic nature of that draw. A more accu-\nrate estimate is obtained by averaging over K such estimates to obtain b\nt zz; zy\n\u00f0 \u00de D\nK\nP\nK\nb\ntk\nzz; zy\n\u00f0 \u00de. A corresponding standard error estimate11 that reflects both the\nuncertainty conditional on a given draw of _\nU as well as uncertainty across draws\nof _\nU is obtained as ^\ns^\nt zz;zy\n\u00f0 \u00de\nD\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nK\nB\nq\n, where W D 1\nK\nXK\n^\n^\ntk\nzz;zy\n\u00f0 \u00de\nand\nP\nK\nb\ntk\nzz; zy\n\u00f0 \u00de \u00a1b\nt zz; zy\n\u00f0 \u00de\nTo gain an overall picture of the sensitivity of the treatment effect estimate, we divide the\nrange of valid sensitivity parameters into a grid, and compute b\nt for each cell of the grid.\nValid sensitivity parameters are determined by examining the residual variance after condi-\ntioning on observed variables; intuitively, an unmeasured confounder cannot account for\nany more variability in treatment or outcome than is observed. When Z is binary, there is no\nsuch hard constraint, but a probit coefficient on a binary or standardized continuous variable\nin excess of \u00a72 is highly unlikely to be observed in practice, so we restrict our sensitivity\nanalyses to this range when using a probit model.\nVisualization and Interpretation of Results\nWe visually summarize the grid of sensitivity-parameter-specific treatment effect esti-\nmates computed by our sensitivity analysis algorithm using a contour plot such as the\none displayed in Figure 1. For demonstration, we use a simulated data set with a con-\ntinuous outcome, a binary treatment, four observed continuous confounders (all with\nthe same association with the treatment but with varying associations with the out-\ncome), and a binary unobserved confounder. We performed the sensitivity analysis\nacross an 8 by 4 grid with 40 repetitions for each combination of sensitivity\nparameters.\n11This is analagous to the variance formula used for multiple imputation estimates (Rubin, 1987).\nThe visualization combines four different definitions of contours, each represented by a\ndifferent color. The primary result is given by the black contours. Each of these represents\nthe combinations of sensitivity parameters for U that lead to the same estimated treatment\neffect (that is, the estimated coefficient on Z in the regression of Y on Z, X, and U, noted\nalong the contour). For instance, sensitivity parameter pairs (zz D 2, zy D 1) and (zz D 1,\nzy D 1.6) both (approximately) fall on a contour corresponding to a treatment effect estimate\nof .17. The red curve represents the contour along which the treatment effect estimate is\nreduced to zero. For this treatment effect estimate to be driven to zero by a single con-\nfounder, that confounder would have to have a combination of sensitivity parameters that\nwould fall on the line labeled 0--for instance, a confounder whose coefficient in the treat-\nment assignment model was 2 and whose coefficient in the outcome model was 1.3. The\ngray contour is used for calibration and is discussed below.\nThe blue curves bracket the region in which the treatment effect estimate is not significant\nat the 5% level using the aggregated standard error estimate ^\ns^\nt zz;zy\n\u00f0 \u00de. As such, they no longer\nrepresent combinations of sensitivity parameters that lead to the same estimated treatment\neffect, but rather combinations that lead to the same t-statistic ^\nt zz; zy\n\u00f0 \u00de=^\ns^\nt zz;zy\n\u00f0 \u00de. They may\ncross the black contours if the standard error varies strongly with the sensitivity parameters.\nThus the plot indicates that for a positive treatment effect estimate to be driven to nonsignifi-\ncance in our example the confounder would have to have sensitivity parameters at least as\nlarge as those that fall on the lower line labeled \"N.S.\"--for instance, a coefficient of about 2\nin the treatment assignment model and a coefficient of about .9 in the outcome model. A\nconfounder with sensitivity parameters at least as large as those on the upper \"N.S.\" line\nwould produce a significant negative treatment effect (e.g., coefficients of about 2 in the\ntreatment model and about 1.8 in the outcome model).\nWe restrict the range of sensitivity parameters for the coefficient in the model for Y to be\npositive; results in the negative range are a simple reflection of the positive, and thus provide\nno additional information. The x- and y-axes represent regions of no confounding, because\none or both of the sensitivity parameters is set to zero; thus the observed treatment effect\nestimate (0.79 in this simulated example) is used as a label for the x-axis.\nThus far we have been interpreting this plot from the vantage point of a researcher with\nno knowledge of the \"truth.\" Because the data are simulated we know that the true U for\nthese data was generated using sensitivity parameters equal to 1 in both dimensions and that\nthe population effect is .5. We see that the point (1,1) falls reasonably close to the contour\ncorresponding to a treatment effect estimate of .51 (given that this combination of sensitivity\nparameters has a standard error of approximately .15).\nCalibration\nAs other scholars have before us (e.g., Imbens, 2003), we suggest calibrating the\nstrength of these sensitivity parameters by using estimates of the regression coefficients\nfor the observed covariates, X, in the data (from the regression of Y on Z and X and\nfrom the regression of Z on X) as a benchmark. Any confounder with a negative partial\nassociation with the outcome is reverse-scaled so that this coefficient estimate will be\npositive; these estimates are tagged by displaying them as 5. To create a common scale\nfor these coefficients (among themselves and relative to the coefficients that serve as\nour sensitivity parameters) we first standardize all continuous covariates and the out-\ncome to have mean of zero and standard deviation of one. As an additional calibration\naid, we plot a gray contour corresponding to the treatment effect estimate obtained\nwith sensitivity parameters equivalent to the pair of observed coefficients that are far-\nthest from the origin.12 The display of the coefficients for the observed confounders in\nthis example allows us to see that, in order for either no treatment effect or a\nnonsignificant treatment effect to represent the truth, the unmeasured confounder\nwould have to have considerably greater predictive power than the observed\nconfounders.\nUse of Modification Weights to Target Specific Estimands\nThus far in the literature, methods that are similar to ours--that is, parametric methods that\nspecify both the relationship between U and Z as well as that between U and Y (both condi-\ntional on X)--have focused on the average treatment effect as the estimand of interest. How-\never, there has been increasing interest in the past two decades in other estimands, perhaps\nmost notably the effect of the treatment on the treated (ATT) and the effect of the treatment\non the controls (ATC). These estimands may differ from the average treatment effect when\ntreatment effects are not constant (or additive). When the heterogeneity in treatment effects\nis driven by the observed covariates, X, these estimands can be recovered by methods such\nFigure 1. Each contour on the plot reflects the combinations of sensitivity parameters that would lead to\nthe treatment effect estimate used as the label for that contour. The lines labeled \"N.S.\" correspond to the\ntreatment effect estimates that forfeit statistical significance. The pale contour corresponds to the effect\nestimate that would be yielded by an unmeasured confounder with properties equivalent to that of the\nobserved confounder that is farthest from the origin. The plus signs and triangles give the coefficient\nestimates for the observed covariates. The 5 sign reflects a covariate whose coefficient for the outcome\nmodel was negative, prompting a rescaling of the variable by \u00a1 1.\n12It may seem odd that this gray line will not necessarily intersect the symbol for the covariate with the most extreme set of\ncoefficients. This is driven by two considerations. The first is the fact that the plot function provides contours that represent a\nsmoothed fit to the estimated treatment effect estimates at our specified grid points. The second is that the estimates of the\ncoefficients on the observed covariates from the Y model will not be precisely equivalent to estimates from the by in the\nmodel formulation that includes U.\nas inverse probability of treatment weighting (IPTW; see, e.g., Imbens, 2004; Kurth et al.,\nTo target estimands such as ATT and ATC we have incorporated \"modification weights\"\ninto the algorithm. These are similar to the weights used in IPTW with the distinction that\nthey do not condition on U and thus are not functions of the estimates of what we assume to\nbe the true propensity score, Pr Z D 1jX; U\n\u00f0 \u00de. Rather, they are functions of estimates of what\nwe, for clarity, refer to as the \"modification score,\" g x\n\u00f0 \u00de D Pr Z D 1jX\n\u00f0 \u00de. Otherwise these\nweights will be formed similarly to those in traditional IPTW, with modification scores esti-\nmated using probit regression (as a default, in practice any of a variety of prediction models\nfor a binary response could be used). Specifically, if we want to estimate the effect of the\ntreatment on the treated we weight the control observations by b\ng x\ng x\n\u00f0 \u00de\n\u00f0 \u00de (normalized\nso that the sum of these weights is equal to the number of control observations). If we want\nto estimate the effect of the treatment on the controls we weight treated observations by\ng x\n\u00f0 \u00de\n\u00f0 \u00de=b\ng x\n\u00f0 \u00de (again normalized so that the sum of these weights is equal to the number\nof treated observations). Use of modification scores rather than propensity scores assumes\nthat treatment effects do not vary with levels of U after conditioning on X (if they did the\nentire sensitivity analysis strategy would need to change).\nSimulation Study\nWe present a simulation study to demonstrate the performance of our approach in the more\ncomplex setting, binary treatment with weighted estimators.14 We can use this setting to\ninvestigate whether our algorithm is able to recover estimands such as ATE and ATT in the\nsetting where covariate-driven treatment effect heterogeneity exists.\nData-Generating Process\nWe adopt a fairly simple simulation setup that nonetheless captures the key features of the\nproblem. We begin by assuming four independent covariates, X1\n, each distributed as\nan independent standard normal variable. We also posit a covariate M that follows a Ber-\nnoulli distribution with Pr M D 1\n\u00f0 \u00de D :5. We distinguish this covariate because of its role as\nmoderator of the treatment effect (made explicit below). Finally we assume an unmeasured\ncovariate, U, that follows a Bernoulli distribution with Pr U D 1\nBecause this simulation is designed to verify that the algorithms behave as expected, we\ngenerate Z and Y according to a slight variation on our specified complete-data likelihood\ndescribed in Equation 7,\nYjZ; U; X; M \u00bb N ay\nC Xb\ny\nC uy\nM C zyU C tZ C tint\ny \u00a2xuz\n \nZjX; U \u00bb Bernoulli F az\nC Xb\nz\nC uzM C zzU\n\u00f0 \u00de\n\u00f0 \u00de;\nwith ay\ny \u00a2xuz\nD 1. This specification allows for treatment effects to vary based on the\nlevel of observed covariate M; in particular, observations with M D 1 have a treatment effect\n13As far as we know the combination of sensitivity analysis and IPTW has only been used in one applied article (Frank et al.,\n2008); that article did not discuss the specific assumptions that accompany this technique.\n14Simulations for the continuous treatment scenario are not shown given that the mathematical derivations for that scenario\nare straightforward.\nof 3 and those with M D 0 have a treatment effect of \u00a13. In turn it implies that ATE (which\nis always equal to 0 in expectation) is not equal to ATT (which varies with the level of zz).\nWe vary the simulation over combinations of choices for the sensitivity parameters: zz D\nEstimands\nThere are several estimands of interest in this simulation. One set of estimands repre-\nsents different ways of conceptualizing the average treatment effect. One such estimand\nis the population average treatment effect (PATE; which is 0). We also consider the\nmodel-based sample approximation to this, which is the estimated coefficient on Z\nfrom a regression of Y on Z, X, M, and U for our sample; in other words, this estimand\nrepresents the coefficient we would have estimated had we had access to U as an\nobserved covariate. We refer to this estimand as the regression average treatment effect\nA second set of estimands represents ways of conceptualizing the average effect of\nthe treatment on the treated, which differs from PATE because of the treatment effect\nmodification. This includes the population average treatment effect for the treated\n.71). We also consider the model-based sample approximation to these, which is the\nestimated coefficient on Z from a weighted regression of Y on Z, X, M, and U for our\nsample, with weights corresponding to those described in the \"Use of Modification\nWeights to Target Specific Estimands\" section. This is the coefficient we would have\nestimated using a standard inverse probability of treatment weighting (IPTW) approach\nhad we had access to U as an observed covariate; we call it the regression average\ntreatment effect for the treated (RATT).15\nResults\nFigures 2 and 3 present the simulation results that demonstrate the performance of our\napproach targeting two different types of estimands, ATE and ATT, respectively. Simula-\ntions are performed across 15 different combinations of the sensitivity parameters, which\nare presented in the top (zz) and the right (zy) of each figure. For each distinct combination\nof zz and zy, we present three box plots. The box plot in the middle is a summary of our sen-\nsitivity analysis estimates, b\nt zz; zy\n\u00f0 \u00de, over 1,000 simulations. The box plot on the left is a\nsummary of the estimated treatment effects from a regression of Y on Z, X, M, and U, had\nwe had access to U, RATE in Figure 2 and RATT in Figure 3. The box plots to the right are\nthe counterparts from the regression of Y on Z, X, and M assuming no access to the unmea-\nsured confounder; that is, the regression estimate based purely on observed data. Thus, the\nleft box plots can be thought of as the best possible results, while the right box plots are the\nworst case scenario. Finally, PATE and PATT, displayed as red solid line segments in\nFigure 2 and Figure 3, respectively, represent the true population level parameters.\n15We choose not to present results for PATC and RATC for the sake of parsimony since, due to the nature of the problem\n(e.g., PATE is just a weighted average of PATT and PATC) they provide no additional information in this setup.\nFigure 2. Sensitivity analysis results from the simulation for estimates targeting ATE estimands (PATE,\nRATE). Each box plot displays the distribution of estimates/estimands across 1,000 simulations. The left\nbox plot in each cell displays RATE. The middle box plot displays the sensitivity analysis results. The right\nbox plot displays regression estimates that exclude U. Each set of three box plots varies across combina-\ntions of the sensitivity parameters (labels on the top and to the right).\nFigure 3. Sensitivity analysis results from the simulation for estimates targeting ATT estimands (PATT,\nRATT). Each box plot displays the distribution of estimates/estimands across 1,000 simulations. The left\nbox plot in each cell displays RATT. The middle box plot displays the sensitivity analysis results. The right\nbox plot displays regression estimates that exclude U. Each set of three box plots varies across combina-\ntions of the sensitivity parameters (labels on the top and to the right).\nThese figures show that our approach precisely recovers estimands corresponding to a\ngiven set of sensitivity parameters. In both figures, as long as either zz or zy is 0, the medians\nof all three box plots correspond with the red line. This indicates that the treatment effects\nare estimated without bias from their population treatment effects. When zy is positive, the\nmedian of the right box plot is below the red line when zz is negative and above the red line\nwhen zz is positive. This indicates that the treatment effects estimated from a regression of Y\non Z, X, and M are estimated with bias when both of the sensitivity parameters are non-\nzero. On the other hand, the left and middle box plots are centered on the red line represent-\ning the population parameter. Furthermore, the dispersion of our estimates is roughly equiv-\nalent to that of RATE or RATT, which is reassuring. This indicates that our approach\nperforms as well as the regression estimate using the true model including U with regard to\nthese measures, and the treatment effect estimates from our approach are both unbiased for\nboth of these estimands.\nContinuous Treatment Variable Example: Child Care and Externalizing\nBehavior in Young Children\nGiven changing patterns of maternal employment in the United States over the past few\ndecades, there is a great deal of interest in understanding the effects that increasing amounts\nof nonparental care in early childhood might have on children's development. One area that\nhas been particularly controversial is the long-standing debate in developmental psychology\nover whether placement in child care leads to higher levels of \"externalizing behavior\"--\naggression, impulsivity, or disobedience--in young children and in the early school years.\nExcessive externalizing behavior has been seen to be associated with poor academic perfor-\nmance and adverse social consequences from school age through adulthood (Campbell,\nEmpirical results on this question are inconsistent, with some studies showing adverse\neffects on externalizing behavior of early initiation of nonparental care or greater hours in\nCrockenberg & Litman, 1991; Egeland & Hiester, 1995; Han, Waldfogel, & Brooks-Gunn,\nRabinovich, Zaslow, Berman, & Hyman, 1987; Rubenstein, Howes, & Boyle, 1981; Schwarz,\nStrickland, & Krolick, 1974; Vandell & Corasaniti, 1990; Youngblade, Kovacs, & Hoffman,\n1999), while others show no effect or positive effects (Anme & Segal, 2004; Bacharach &\n& Rosenthal, 1991). These studies must naturally be observational, as the need for care is\ndetermined by the situation of any given family.16 However, it seems implausible that we\ncould measure all covariates that might affect both the child care choice and subsequent\nexternalizing behaviors. Thus, this question is a prime candidate for sensitivity analysis. It is\nimportant to understand how sensitive results from observational studies might be to a\npotential unmeasured confounder; for instance, how predictive would such a confounder\n16Even if we could randomize some families to receive center-based care, we could not force them to participate in this care or\nforce those in the control group to not participate in center-based care.\nhave to be to remove support for the hypothesis that nonparental child care impacts exter-\nnalizing behavior?\nWe explore this question using data from the National Institute of Child Health and\nHuman Development (NICHD) Study of Early Child Care and Youth Development (SEC-\nCYD) because several influential studies on this topic were conducted using these data.\nMoreover, the NICHD study is one of the largest, most comprehensive studies of the devel-\nopmental effects of early child care experience. It followed from birth a cohort of more than\n1,300 children from 10 communities across the United States, recording detailed informa-\ntion on the quantity and quality of care experienced, family and socioeconomic variables,\nand cognitive and behavioral outcomes. The design of the study has been described in detail\nelsewhere (see, e.g., National Institute of Child Health and Human Development Early Child\nData and Variables\nEarlier work considering externalizing behavior from the SECCYD data has shown some evi-\ndence for an increase in problem behavior with more time in nonparental care (McCartney\net al., 2010; National Institute of Child Health and Human Development Early Child Care\nResearch Network, 1998, 2003). Following the later studies, we focus on externalizing behav-\nior measured by caregivers at 54 months as an outcome.17 To demonstrate the performance\nof the sensitivity analysis method developed for continuous treatment variables, we use the\naverage hours per week in nonparental care from age 24 to 50 months as our treatment.18\nFollowing the convention from previous studies, we include the following pretreatment\nvariables as potential confounders: child externalizing behavior measured at age 24 months,\nan indicator for whether the child is female, mother's educational attainment, mother's anxi-\nety/depression score at 24 months, total income-to-needs ratio at 24 months, poverty (total\nincome-to-needs ratio less than 2) at 24 months, whether the father is living in the same\nhousehold at age 24 months, and indicators for data collection locations. Although previous\nattempts to address this question often included values of time-varying covariates at post-\ntreatment surveys in the analysis, we did not do so due to the potential for bias that inclusion\nof posttreatment covariates can yield (Gelman & Hill, 2007; Rosenbaum, 1984). We also\nstandardize all continuous variables to create a common scale for interpreting and compar-\ning the magnitudes of the coefficients on the observed covariates relative to the sensitivity\nparameters for the unmeasured confounder, as discussed in the \"Visualization and Interpre-\ntation of Results\" section.\nResults\nFigure 4 contains an analysis of the sensitivity of the estimated coefficient of the continuous\ntreatment to potential unmeasured confounding.19 Most of the observed covariates have a\n17When a child's behavior was evaluated by multiple caregivers, the average of their evaluations was used.\n18Because of a seven-month gap between the Phase I and Phase II studies and the fact that hours per week in care are\nrecorded every four months in Phase II, the variable for average hours in care is created with the following formula:\nP\ncarem\n \n. Because we observed excessively large entries for this\ncontinuous treatment in some cases, we capped the maximum value of time in care at 70 hours.\nU per cell.\nnegative association with externalizing behavior and have been rescaled (multiplied by \u00a11)\nso that the estimated coefficients will be positive; these are represented by 5 on the plot. All\ncontinuous covariates have also been standardized to have a mean of 0 and standard devia-\ntion of 1 to facilitate comparisons of their magnitude to that of the sensitivity parameters.\nThis figure shows that, over a range of plausible sensitivity parameters, the estimated\ntreatment effects range from roughly \u00a1.5 to .8, with the majority of the range consistent\nwith a significant, positive treatment effect. The blue reference lines indicate that the\nsensitivity parameters required for an unmeasured confounder to drive the estimate to non-\nsignificance are larger than the coefficients for the observed confounders by about 50%. To\ndrive the estimate to zero (red reference line), these parameters would have to be about\n200% larger than the largest coefficient estimate for the observed covariates. Such values are\nnot implausible. For instance, consider a confounder with zz D .5 and zy D .4. This corre-\nsponds to a continuous confounder with the following property: when comparing two\ngroups that differ by one standard deviation on this confounder they would also differ by .5\nstandard deviations on the treatment variable (which corresponds to about 6 hours per week\nof nonparental care). This confounder would also have the property that when comparing\ntwo groups that differ by one standard deviation on this confounder they would also differ\nby .4 standard deviations on the outcome variable (which corresponds to 4 on the externaliz-\ning behavior index).\nBinary Treatment Variable Example: National Supported Work Constructed\nObservational Study\nLabor economists have long been interested in whether job training has the potential to\nimprove workers' human capital. However, the answer to this question is often ham-\npered by selection bias. That is, those who are likely to participate in a job training\nFigure 4. Sensitivity analysis results from an analysis of the effect of average hours of nonparental care on\nexternalizing behavior using data from the NICHD study.\nprogram tend to have different earnings potential than those who do not choose to\nparticipate. This earnings potential may or may not be proxied by observed confound-\ners. Thus, several social experiments have been conducted. The National Supported\nWork Demonstration (NSW) was one such experiment. In the NSW evaluation, the\nsamples were randomly assigned to participate in a job training program or not, and\nthus it was straightforward to unbiasedly estimate the effect of participation in this pro-\ngram on subsequent yearly earnings (in 1978).\nConstructed Observational Study Data\nLaLonde (1986) created a unique constructed observational data set by merging the experi-\nmental treatment group from NSW with a nonexperimental control group drawn from the\nPopulation Survey of Income Dynamics (PSID). Both surveys measured the following base-\nline covariates that can be used as potential confounders: education, age, black, Hispanic,\nThese variables are also representative of the types of covariates that were used in standard\nobservational analyses of this research question using other data during that time period.\nLaLonde examined how well the sophisticated econometric techniques at that time could\nrecover the experimental estimates obtained using the NSW data set and discovered that\nnone of them were able to do so reliably. Since then, the data set has been used as a touch-\nstone for new statistical methods that attempt to remove selection bias due to observables in\nobservational studies.\nPerhaps not surprisingly, simple estimators such as the coefficient on the treatment vari-\nable in a linear regression of the outcome on the treatment indicator and observed con-\nfounders fail to recover the experimental benchmark as well. Two potential explanations for\nthis failure present themselves. The first is that linear regression is targeting a different esti-\nmand, a form of ATE (Angrist & Pischke, 2008), rather than the effect of the treatment on\nthose who actually participate in the program (ATT in this constructed observational study);\nassuming there are differences in the characteristics between the treatment and control\ngroups and these differences also drive differences in the sizes of the effects of the programs,\nthese estimands will not be the same. The second explanation is that linear regression is pro-\nducing biased results (either because it does not satisfy ignorability or because it relies on\nincorrect parametric assumptions); that is, even if ATE=ATT for these data, linear regression\nwould not be estimating the ATT unbiasedly.\nWe know from subsequent work on this topic that methods that provide robustness to\nmodel misspecification and that are able to target estimands such as the ATT--such as pro-\npensity score matching and IPTW--have been reasonably successful at reliably recovering\nthe experimental benchmarks in this example when the full set of controls is used (see, e.g.,\nfrom constructed observational studies such as this one is that we cannot ascertain whether\na \"success\" (which occurs when a method closely mirrors the experimental benchmark)\nreflect a situation in which ignorability is satisfied or rather an example of bias cancellation.\n20Notably, removal of 1974 earnings is particularly problematic for these data most probably due to the so-called \"Ashenfelter\ndip\" (due to Ashenfelter, 1978), which describes the phenomenon that those who enroll in job training programs are more\nlikely to have experienced job loss right before the participation (implying that conditioning on only one period of\npretreatment earnings is likely not sufficient for establishing ignorability).\nImbens (2003) used these data to illustrate his approach to sensitivity analysis as well.\nHowever, his sensitivity analysis strategy cannot differentially target the effect of the treat-\nment on the treated. Yet the estimand of interest in the NSW-constructed observational\nstudy (the one that corresponds to the experimental benchmark) is the effect of the treat-\nment on the treated (because in the original experiment, the randomized control group is\nnot systematically different from the treatment group, so estimating the effect for the treated\nis the same as estimating the average effect for the randomized experiment). We compare\nthe ATE and ATT results obtained from our sensitivity analysis strategy to observe the dif-\nferences in our conclusions based on targeting the proper estimand.\nResults\nFigure 5 shows the results of the sensitivity analysis that examines the sensitivity to unmea-\nsured confounding for each of two estimates of the effect of participation in the NSW job\ntraining program. The left panel does not use weights and thus targets an average treatment\neffect (ATE). The right panel uses modification weights to target the ATT. We use standard-\nized coefficients to facilitate comparisons between the coefficients on observed confounders\nand the sensitivity parameters for our posited binary unmeasured confounder. These bench-\nmarking coefficients are more strongly predictive of the treatment assignment in the\nunweighted sample than in the weighted sample, which is not surprising since the weighted\nsample creates greater balance between the treatment and (weighted) control groups. With\none exception, the observed covariates have either similar or reduced power to predict the\noutcome variable in the weighted sample as well.\nThe left panel suggests that absent unmeasured confounding the effect estimate would be\nabout 0. It further suggests that it would take a reasonably strong unmeasured confounder\nthat was negatively associated with treatment but positively associated with the outcome to\nyield a significant positive effect (such effects correspond to the upper-left corner of the\nplot). One such confounder does exist in the observed data, however. On the other hand, if\nthe unmeasured confounder were strongly positively associated with both treatment and\noutcome this would suggest a significant negative treatment effect estimate (upper-right cor-\nner of the plot).\nFigure 5. Sensitivity analysis results from the NSW. Left panel displays results from algorithm that uses no\nweights. Right panel displays results from algorithm that uses modification weights to target the effect of\nthe treatment on the treated.\nConsider instead the right panel with sensitivity analyses that target the ATT. Here more\nthan half of the plot corresponds to significant, positive treatment effect estimates. The level\nof unobserved confounding (as operationalized by the sensitivity parameters) required to\ndrive this estimate to nonsignificance is represented by the blue lines labeled N.S. As a com-\nparison to these values, consider that the strongest observed confounder in the data has coef-\nficients of 0.4 and 0.2 in the response and treatment models, respectively. Therefore it seems\nplausible that the omitted confounder might be equally strong. On the other hand, the omit-\nted confounder required to drive the treatment effect estimate to zero, this confounder (as\nrepresented by the red line labeled \"0\") would have had to be almost twice this strong.\nFurthermore, the \"naive\" treatment effect estimate (that is the regression estimate on\nobserved data), which is close to zero when targeting the ATE, is significant and positive\nwhen targeting the ATT. The larger effects for ATT suggest that the job training program\nwas more effective for the workers who were more likely to participate in the program. The\nstandardized coefficient that targets the ATT corresponds to a treatment effect estimate of\nabout 2,400 dollars per year with a standard error of approximately 700 dollars. This com-\npares favorably with the treatment effect estimate from the original randomized experiment\n(which as previously noted targets the same estimand--the effect of the program on those\nwho participated) which was approximately 1,800 dollars per year. The different conclusions\nreached from these two plots highlights the importance of targeting an appropriate estimand\nwhen performing sensitivity analysis.\nDiscussion\nThis article describes a general approach to sensitivity analysis with specific implementations\nfor models with continuous and binary treatment variables. Our approach makes use of the\nconditional distribution of the unmeasured confounder implied by each of the two models\nto generate candidate realizations of the unmeasured confounder. This allows us to estimate\nthe distribution of treatment effect estimates that correspond to an analysis that conditions\non that confounder. Conveniently, the unmeasured confounder is characterized by sensitiv-\nity parameters that can be interpreted as regression coefficients (from the regression of the\noutcome on the treatment, observed covariates, and unmeasured covariate and from the\nregression of the treatment on the observed covariates and the unmeasured covariate). These\ncoefficients are interpretable to applied researchers who have substantial experience in inter-\npreting regression coefficients. In addition, this specification allows us to benchmark the\nmagnitude of the sensitivity parameters relative to the corresponding coefficients for\nobserved confounders in our data.\nAn important contribution of our approach is the extension of the binary treatment variable\nimplementation to allow for targeting of the effect of two causal estimands that are often of\nstrong interest for policy and practice: the effect of the treatment on the treated and the effect of\nthe treatment on the controls. Given the complexity of the algorithm for the binary treatment,\nparticularly combined with the weighted estimation needed for targeting ATT and ATC, we\nhave performed simulations to verify the properties of the algorithm. Across a wide range of\ncombinations of sensitivity parameters, the algorithm reliably recovers a distribution nearly\nequivalent to that of the regression estimates in a regression controlling for the corresponding\nunmeasured confounder (i.e., it mimics the sampling distributions of RATE or RATT). The\nNSW example highlights the potential practical implications of this feature of our strategy.\nThis approach to assessing sensitivity to unmeasured confounding described in this article\nis a useful complement to any observational study for which it is unclear if ignorability has\nbeen satisfied. Software that implements these algorithms is currently available in the treat-\nSens package on the CRAN archive (for the R software program).\nFunding\nThis research was partially supported by Institute of Education Sciences grant R305D110037.\nEDITORS\nThis article was reviewed and accepted under the editorship of Carol McDonald Connor and Spyros\nKonstantopoulos.\nReferences\nAltonji, J. G., Elder, T. E., & Taber, C. R. (2005). Selection on observed and unobserved variables:\nAssessing the effectiveness of Catholic schools. Journal of Political Economy, 113, 151\u00ad184.\nAngrist, J., & Pischke, J. (2008). Mostly harmless econometrics: An empiricist's companion. Princeton,\nNJ: Princeton University Press.\nAnme, T., & Segal, U. A. (2004). Implications for the development of children in over 11 hours of cen-\nAshenfelter, O. (1978). Estimating the effects of training programs on earnings. Review of Economics\nBacharach, V. R., & Baumeister, A. A. (2003). Child care and severe externalizing behavior in kinder-\nBates, J. E., Marvinney, D., Kelly, T., Dodge, K. A., Bennett, D. S., & Pettit, G. S. (1994). Child care his-\nBaydar, N., & Brooks-Gunn, J. (1991). Effects of maternal employment and child-care arrangements\non preschoolers' cognitive and behavioral outcomes: Evidence from the Children of the National\nBecker, S. O., & Caliendo, M. (2007). Sensitivity analysis for average treatment effects. Stata Journal, 7,\nBelsky, J. (1999). Quantity of nonmaternal care and boys' problem behavior/adjustment at ages 3 and\n5: Exploring the mediating role of parenting. Psychiatry: Interpersonal and Biological Processes, 62,\nBross, I. D. (1966). Spurious effects from an extraneous variable. Journal of Chronic Diseases, 19,\nBuckley, J., & Schneider, M. (2007). Charter schools: Hype or hope?. Princeton, NJ: Princeton Univer-\nsity Press.\nCampbell, S. B. (2002). Behavior problems in preschool children: Clinical and developmental issues.\nNew York, NY: Guilford Press.\nCopas, J. B., & Li, H. G. (1997). Inference for non-random samples. Journal of the Royal Statistical\nCornfield, J., Haenszel, W., Hammond, E. C., Lilienfeld, A. M., Shimkin, M. B., & Wynder, E. L.\n(1959). Smoking and lung cancer: Recent evidence and a discussion of some questions. Journal of\nCrockenberg, S., & Litman, C. (1991). Effects of maternal employment on maternal and two-year-old\nDehejia, R. H. (2005). Practical propensity score matching: A reply to Smith and Todd. Journal of\nDehejia, R. H., & Wahba, S. (1999). Causal effects in nonexperimental studies: Reevaluating the evalu-\nDiPrete, T. A., & Gangl, M. (2004). Assessing bias in the estimation of causal effects: Rosenbaum\nbounds on matching estimators and instrumental variables estimation with imperfect instruments.\nEgeland, B., & Hiester, M. (1995). The long-term consequences of infant day-care and mother-infant\nFarmer, A. D., Bierman, K. L., & The Conduct Problems Prevention Research Group (2002). Predic-\ntors and consequences of aggressive-withdrawn problem profiles in early grade school. Journal of\nField, T., Masi, W., Goldstein, S., & Perry, S. (1988). Infant day care facilitates preschool social behav-\nFrank, K. A. (2000). Impact of a confounding variable on the inference of a regression coefficient.\nFrank, K. A., Sykes, G., Anagnostopoulos, D., Cannata, M., Chard, L., Krause, A., & McCrory, R.\n(2008). Extended influence: National board certified teachers as help providers. Education, Evalua-\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models.\nNew York, NY: Cambridge University Press.\nGreenland, S. (1996). Basic methods for sensitivity analysis of biases. International Journal of Epidemi-\nGreenland, S., Robins, J. M., & Pearl, J. (1999). Confounding and collapsibility in causal inference. Sta-\nGreenstein, T. N. (1993). Maternal employment and child behavioral outcomes: A household econom-\nGustafson, P., McCandless, L., Levy, A., & Richardson, S. (2010). Simplified Bayesian sensitivity analy-\nHan, W.-J., Waldfogel, J., & Brooks-Gunn, J. (2001). The effects of early maternal employment on\nlater cognitive and behavioral outcomes. Journal of Marriage and Family, 63, 336\u00ad354.\nHarada, M. (2011). ISA: Stata module to perform Imbens' (2003) sensitivity analysis. Boston, MA:\nStatistical Software Components, Boston College Department of Economics.\nHarada, M. (2012). GSA: Stata module to perform generalized sensitivity analysis. Boston, MA: Statisti-\ncal Software Components, Boston College Department of Economics.\nHarada, M. (2013). Generalized sensitivity analysis (Technical report). New York, NY: New York\nUniversity.\nHarvey, E. (1999). Short-term and long-term effects of early parental employment on children of the\nHaskins, R. (1985). Public school aggression among children with varying day-care experience. Child\nHill, J. L., Weiss, C., & Zhai, F. (2011). Challenges with propensity score strategies in a high-dimen-\nsional setting and a potential alternative. Multivariate Behavioral Research, 46, 477\u00ad513.\nHofferth, S. (1999). Child care in the first three years of life and preschoolers' language and behavior.\nPaper presented at the biennial meeting of the Society for Research in Child Development,\nAlbuquerque, NM.\nHowes, C. (1988). Relations between early child care and schooling. Developmental Psychology, 24, 53\u00ad57.\nIchino, A., Mealli, F., & Nannicini, T. (2008). From temporary help jobs to permanent employment:\nWhat can we learn from matching estimators and their sensitivity? Journal of Applied Economet-\nImbens, G. W. (2003). Sensitivity to exogeneity assumptions in program evaluation. The American\nImbens, G. (2004). Nonparametric estimation of average treatment effects under exogeneity: A review.\nKeele, L. (2010). An overview of rbounds: An R package for Rosenbaum bounds sensitivity analysis with\nmatched data. White Paper. Retrieved from http://www.personal.psu.edu/ljk20/rbounds%20vignette.pdf\nKurth, T., Walker, A. M., Glynn, R. J., Chan, K. A., Gaziano, J. M., Berger, K., & Robins, J. M. (2006).\nResults of multivariable logistic regression, propensity matching, propensity adjustment, and pro-\npensity-based weighting under conditions of non-uniform effect. American Journal of Epidemiol-\nLaLonde, R. (1986). Evaluating the econometric evaluations of training programs. American Economic\nLevenston, G. K. (2002). A longitudinal analysis of childhood externalizing and internalizing psycho-\npathology as risk factors for criminal offending in adulthood. Dissertation Abstracts International:\nLin, D. Y., Psaty, B. M., & Kronmal, R. A. (1998). Assessing the sensitivity of regression results to\nMacrae, J. W., & Herbert-Jackson, E. (1976). Are behavioral effects of infant day care program spe-\nMagnuson, K. A., Meyers, M. K., Ruhm, C. J., & Waldfogel, J. (2004). Inequality in preschool educa-\nMcCandless, L. C., Gustafson, P., & Levy, A. (2007). Bayesian sensitivity analysis for unmeasured con-\nMcCartney, K., Burchinal, M., Clarke-Stewart, A., Bub, K. L., Owen, M. T., & Belsky, J. (2010). Testing\na series of causal propositions relating time in child care to children's externalizing behavior. Devel-\nMcCartney, K., & Rosenthal, S. (1991). Maternal employment should be studied within social ecolo-\nNannicini, T. (2007). Simulation-based sensitivity analysis for matching estimators. Stata Journal, 7, 334.\nNational Institute of Child Health and Human Development Early Child Care Research Network.\n(1998). Early child care and self-control, compliance, and problem behavior at twenty-four and\nNational Institute of Child Health and Human Development Early Child Care Research Network.\n(2003). Does amount of time spent in child care predict socioemotional adjustment during the\nNeilsen, S. F. (2000). The stochastic EM algorithm: Estimation and asymptotic results. Bernoulli, 6,\nRabinovich, B., Zaslow, M., Berman, P., & Hyman, R. (1987). Employed and homemaker mothers'\nperceptions of their toddlers compliance behavior in the home. Poster presented at the meeting of\nthe Society for Research in Child Development, Baltimore, MD.\nRosenbaum, P. R. (1984). The consequences of adjustment for a concomitant variable that has been\naffected by the treatment. Journal of the Royal Statistical Society, Series A, General, 147, 656\u00ad666.\nRosenbaum, P. R. (1987). Sensitivity analysis for certain permutation inferences in matched observa-\nRosenbaum, P. R. (1988). Sensitivity analysis for matching with multiple controls. Biometrika, 75,\nRosenbaum, P. R. (2002a). Covariance adjustment in randomized experiments and observational stud-\nRosenbaum, P. R. (2002b). Observational studies. New York, NY: Springer.\nRosenbaum, P. R. (2010). Design sensitivity and efficiency in observational studies. Journal of the\nRosenbaum, P. R. (2011). A new u-statistic with superior design sensitivity in observational studies.\nRosenbaum, P. R., & Krieger, A. M. (1990). Sensitivity of two-sample permutation inferences in obser-\nRosenbaum, P. R., & Rubin, D. B. (1983). Assessing sensitivity to an unobserved binary covariate in an\nobservational study with binary outcome. Journal of the Royal Statistical Society. Series B (Methodo-\nRosenbaum, P. R., & Silber, J. H. (2009). Amplification of sensitivity analysis in matched observational\nRubenstein, J. L., Howes, C., & Boyle, P. (1981). A two-year follow-up of infants in community-based\nRubin, D. B. (1987). Multiple imputation for nonresponse in surveys. New York, NY: Wiley.\nSchwarz, J. C., Strickland, R. G., & Krolick, G. (1974). Infant day care: Behavioral effects at preschool\nSteenland, K., & Greenland, S. (2004). Monte Carlo sensitivity analysis and Bayesian analysis of smok-\ning as an unmeasured confounder in a study of silica and lung cancer. American Journal of Epide-\nVandell, D. L., & Corasaniti, M. A. (1990). Child care and the family: Complex contributors to child\ndevelopment. New Directions for Child and Adolescent Development, 49, 23\u00ad37.\nYoungblade, L., Kovacs, D., & Hoffman, L. (1999). The effects of early maternal employment on 3rd\nand 4th grade children's social development. Poster presented at the biennial meeting of the Society\nfor Research in Child Development, Albuquerque, NM.\nZahn-Waxler, C., Usher, B., Suomi, S., & Cole, P. M. (2005). Intersections of biology and behavior in\nyoung children's antisocial patterns: The role of development, gender and socialization. In D. M.\nStoff & E. J. Susman (Eds.), Developmental psychobiology of aggression (pp. 141\u00ad160). New York,\nNY: Cambridge University Press.\nAppendix: Derivation of Conditional Distribution of U in the Multivariate\nNormal Case\nRecall that when U, Z, and Y are normally distributed, we specify the complete-data\nlikelihood as:\nu\nZjX; U \u00bb N bzx C zzu; s2\nz \u00a2xu\nYjX; U; Z \u00bb N byx C zyu C tz; s2\ny \u00a2xuz\nVarying s2\nu\nonly changes the range of possible coefficients, not the qualitative results\nof the sensitivity analysis. The mean and variance of YjX, Z are modified equivalently\nto defining sensitivity parameters zy and zz by setting z0 D su\nz. Thus, the shape of the\ndistribution of b\nt will be unchanged, but varying s2\nu\nhas implications for benchmarking\naccording to coefficients of X, because changing the assumed variance will change the rela-\ntionship to the observed X. For this reason, we take s2\nu\nD 1 and standardize all variables\nin the analysis.\nThis yields a joint distribution\np U; Y; ZjX\n \nz \u00a2xu\nexp \u00a1\nz \u00a1 bzx \u00a1 zzu\nz \u00a2xu\n \ny \u00a2xuz\nexp \u00a1\ny \u00a1 byx \u00a1 zyu \u00a1 tz\ny \u00a2xuz\n!\nAfter factoring p U; Y; ZjX\n\u00f0 \u00de, we obtain the following conditional distributions for U and\n(Y, Z):\nUjX; Z; Y \u00bb N mu \u00a2xzy\nu \u00a2xzy\n \nmu \u00a2xzy\nD\ny \u00a2xuz\nzz z \u00a1 bzx\nz \u00a2xu\nzy y \u00a1 byx \u00a1 tz\n\u00f0 \u00de\nz \u00a2xu\ny \u00a2xuz\ny \u00a2xuz\nz \u00a2xu\nu \u00a2xzy\nD\nz \u00a2xu\ny \u00a2xuz\nz \u00a2xu\ny \u00a2xuz\ny \u00a2xuz\nz \u00a2xu\nand\nY; ZjX \u00bb N myz \u00a2x\n;\nP\nyz \u00a2x\n \nmyz \u00a2x\nD byx C tz; bzx\n\u00f0 \u00de\nSyz \u00a2x\nD\ny \u00a2xuz\nC zy2 zyzz\nz \u00a2xu\nWe see that the distribution in (A3) is a function of the residuals, conditional variances,\nand coefficients from the underlying true models for Y and Z including U. Because U is\nunobservable, we would like to rewrite this distribution in terms of what we can observe in\nour data, plus sensitivity parameters that the analyst can vary. To do so, we need the condi-\ntional distributions of Y and Z without U. We can obtain the distribution of Z given X in a\nsimilar manner to that of p Y; ZjX\n\u00f0 \u00de, which yields\nZjX \u00bb N bzx; s2\nz \u00a2xu\nThus, the observed residuals ~\nz have mean z \u00a1 bzx and variance s2\nz\n~\nz \u00a2xu\nFrom the bivariate normal distribution of Y and Z given X in A4, we see that the distribu-\ntion of Y given Z and X is\nYjX; Z \u00bb N byx C tz C\nzyzz\nz \u00a2xu\nz \u00a1 bzx\n\u00f0 \u00de;\nz \u00a2xu\ny \u00a2xuz\ny \u00a2xuz\nz \u00a2xu\nz \u00a2xu\n!\nThis implies that the residuals ~\ny from a linear model of Y as a function only of the observed\ndata (Z, X) have mean y \u00a1 byx C tz\n\u00f0 \u00de \u00a1 c z\n~and variance s2\ny\n~\nz \u00a2xu\ny \u00a2xuz\ny \u00a2xuz\nz \u00a2xu\nz \u00a2xu\n. Note\nthat c also quantifies the bias in the estimate of t for given coefficients zy and zz, with denom-\ninator given by s2\nz\n~\n. Thus, in this limited case we can directly calculate the bias in b\nt associated\nwith particular values of zz and zy as a function of the variance in ~\nz.\nGiven these distributions, we can now rewrite the conditional distribution of U in terms\nof observables and the coefficients of U:\nUjX; Z; Y \u00bb N mu \u00a2xzy;\nu \u00a2xzy\n \nmu \u00a2 xzy\nD\ny\n~\nzz z\nz\n~\nzy y\n~\nz\n~\ny\n~\nu \u00a2 xzy\nD\nz\n~\ny\n~\nz\n~\ny\n \nz\n~\n@\nz\n~\nSo if we treat zz and zy as sensitivity parameters, we can generate _\nU from this distribution.\nAs an alternative, we consider using the partial correlations of U with Y and Z as\nsensitivity parameters. Note that r\nu z~\nD Cor U; ZjX\n\u00f0 \u00de D zz=\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nz \u00a2xu\np\nD zzsu\n=sz\n~ and\nr\nu y\n~\nD Cor U; YjX\n\u00f0 \u00de D zy=sy\n~\nz\n~\nD zy=sy\n~\nu z\n~\n. Using these we can repara-\nmeterize the conditional distribution of U as:\nUjX; Z; Y \u00bb N mu \u00a2xzy;\nu \u00a2xzy\n \nmu \u00a2 xzy\nD\nru z\n~\nsz\n~\nz\n~C\nru y\n~\ns y\n~\ny\n~\nu \u00a2 xzy\nu z\n~\nu y\n~"
}