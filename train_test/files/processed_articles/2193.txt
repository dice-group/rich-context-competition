{
    "abstract": "The Gerontologist \u00a9 The Author 2010. Published by Oxford University Press on behalf of The Gerontological Society of America.",
    "reduced_content": "\u00a9 The Author 2010. Published by Oxford University Press on behalf of The Gerontological Society of America.\nVol. 50, No. 6, 758\u00ad773 All rights reserved. For permissions, please e-mail: journals.permissions@oxfordjournals.org.\nPurpose: This study was designed to improve the\nmeasurement of financial exploitation (FE) by testing\npsychometric properties of the older adult financial\nexploitation measure (OAFEM), a client self-report\ninstrument. Design and Methods: Rasch item\nresponse theory and traditional validation approaches\nwere used. Questionnaires were administered by 22\nadult protective services investigators from 7 agencies\nin Illinois to 227 substantiated abuse clients. Analyses\nincluded tests for dimensionality, model fit, and addi-\ntional construct validation. Results from the OAFEM\nwere also compared with the substantiation decision of\nabuse and with investigators' assessments of FE using\na staff report version. Hypotheses were generated\nto test hypothesized relationships. Results: The\nmeasures, met stringent Rasch analysis fit and unidi-\nmensionality criteria and had high internal consistency\nand item reliability. The validation results were support-\nive, while leading to reconsideration of aspects of\nthe hypothesized theoretical hierarchy. Thresholds\nwere suggested to demonstrate levels of severity.\n\nImplications: The measure is now available to aid\nin the assessment of FE of older adults by both clini-\ncians and researchers. Theoretical refinements devel-\noped using the empirically generated item hierarchy\nmay help to improve assessment and intervention.\nKey Words: Financial abuse, Mistreatment, Rasch\nmeasurement, Exploitation theory, Theoretical hierarchy\nSelf-Report Measure of Financial Exploitation\nof Older Adults\nKendon J. Conrad, PhD,*,1 Madelyn Iris, PhD,2 John W. Ridings, PhD,3\nKate Langley, MPH,1 and Kathleen H. Wilber, PhD4\n1School of Public Health (MC 923), University of Illinois at Chicago.\n2Leonard Schanfield Research Institute, CJE SeniorLife, Chicago, Illinois.\n3Metropolitan Family Services, Chicago, Illinois.\n4Andrus Gerontology Center (MC 0191), University of Southern California, University Park, Los Angeles.\n*Address correspondence to Kendon J. Conrad, PhD, School of Public Health (MC 923), University of Illinois at Chicago, 1603 West Taylor Street,\nDecision Editor: William J. McAuley, PhD\nIn the last 30 years, because elder mistreatment\nbegan to be widely recognized by social scientists,\nstrides have been made to identify, measure, and\nsubstantiate abuse. Building on a seminal report\nby the National Research Council (2003), research\nhas focused on improving the measurement of\nelder mistreatment to understand better the scope\nof the problem and the associated risk and protec-\ntive factors. Cooper, Selwood, and Livingston\n(2008) in a systematic review of elder mistreatment\nprevalence studies through October 2008 identi-\nfied 49 such studies conducted in more than a\ndozen countries. However, they did not identify\nany studies specifically devoted to the conceptual-\nization and measurement of financial exploitation\n(FE) of older adults. FE is a unique category of\nelder mistreatment that does not have previously\ndeveloped scales to draw from as do other forms\nof abuse. As a result, empirical studies of FE have\nlagged.\nFE has been defined as the illegal or improper\nuse of a vulnerable adult's funds or property\nfor another person's profit or advantage (AARP\nInternational, 2006; National Center on Elder\nAbuse, 1998). In practice, FE may be difficult to\ndetect for a variety of reasons. For example, the\nonset is often gradual and insidious and, lacking\noversight, subtle deception may mimic legitimate\ntransactions and escalate over time. Differentiat-\ning FE from legitimate transactions is challenging\nin that there may be indications of consent by the\nolder adult, for example, a signed document and\nan apparent gift, when in fact the perpetrator has\nused psychological manipulation or misrepresen-\ntation (Wilber & Reynolds, 1996). Cognitive\nimpairment, sensory impairment, or lack of finan-\ncial sophistication may also cloud the distinction\nbetween willing assent and FE. Risks for FE may\nincrease for older adults with paid or unpaid care-\ngivers who have access to their financial assets,\nsuch as bank accounts, investment funds, etc.\n(Anetzberger, 2000). Differentiating FE from legit-\nimate resource sharing and gifting is especially dif-\nficult when the elder is not a reliable reporter\nbecause of cognitive impairment, coercion, or con-\ncern about what will happen to the suspected\nabuser. In addition, other factors such as different\ncultural perceptions of sharing wealth may blur\nthe distinction between generosity and exploita-\ntion (Langan & Means, 1996). (For a more com-\nprehensive review of the FE literature, see Conrad\nConceptual Models\nAlthough conceptual development in elder\nabuse research is sparse, several authors have sug-\ngested theoretical approaches to guide data collec-\ntion efforts and provide effective assessment of\nthe risk factors for and the consequences of differ-\nent types of abuse (Anetzberger, 2000; Godkin,\nWolf, & Pillemer, 1989). For FE, a number of\nindicators of abuse have been identified, for exam-\nple, suspicious signatures on checks, missing docu-\nmentation about financial arrangements, and\nunusual banking activities (National Committee\nfor the Prevention of Elder Abuse, 2008; Quinn &\nOver the last decade, there have been several\nefforts to develop broader conceptual frameworks\nspecific to FE. For example, Wilber and Reynolds\n(1996) identified four components of financial\nelder abuse: vulnerabilities of the elder; character-\nistics of the relationship between the older adult\nand the alleged perpetrator; an assessment of who\nbenefits from the relationship and how; and con-\nsideration of the process and tactics used and\nwhether or not these meet the standards of undue\ninfluence, deceit, coercion, or theft. Building on\nthis framework, Kemp and Mosqueda (2005)\ndeveloped and tested a model, that added several\nnew areas, including the older adult or the transac-\ntions are kept isolated, controlled, or secret; a\nqualified expert assesses neither the elder's capac-\nities nor whether the transaction was in the older\nadult's best interest; common business or personal\nethics are not followed; and the perpetrator does\nnot consider the effect on others including the victim,\nfamily, beneficiaries, or the public welfare system.\nRabiner, O'Keeffe, and Brown (2004) presented\na comprehensive conceptual model that included\nmicro processes such as power and exchange\ndynamics, characteristics of the relationship in\naddition to the victim and perpetrator, status\ninequality, and social networks. They also included\nthe broader sociocultural and policy context to\nunderstand better the etiology of FE.\nThese various models have several commonali-\nties; primary among them is that they recognize\nthe importance of including the perpetrator and\nhis or her characteristics as well as the social net-\nwork. In addition, the relationship itself must be\nassessed in terms of the (a) extent to which the per-\npetrator is in a \"position of trust,\" (b) status\ninequality between perpetrator and victim, (c) pat-\nterns of interaction over time, and (d) extent to\nwhich there is reciprocity versus highly skewed\nbenefits and losses. Although the models help\nexplain the etiology of general abuse and the\nnature of financial abuse, neither do they present\nexamples of statements that represent individual\ncomponents of FE nor do they indicate which\ncomponents are most important or most severe.\nUnderstanding these issues is essential to obtaining\naccurate assessments of types and levels of exploi-\ntation. To address the latter issue, Conrad and\ncolleagues (in press) developed a model using\nconcept mapping that included five concepts in a\nseverity hierarchy that resulted in a measure called\nthe older adult financial exploitation measure\n(OAFEM). The initial OAFEM measure, upon\nwhich this study was based, was developed using\nthree-dimensional concept mapping applying the\nTrochim (1989) mapping technique. Following\nthis approach, concept maps for FE were devel-\noped using two sources. Statements were gener-\nated first from a literature review of all empirical\nand conceptual work on FE available. Subse-\nquently local and national panels of experts (n =\n16) brainstormed descriptive statements of key\nbehaviors related to FE. In this way, any state-\nments from the literature that were not suggested\nby the experts were included by the authors for\nconsideration. The panel of experts then reviewed\nthe list of behaviors, rating the severity of each,\nconceptually sorting the statements into groups,\n \nand naming each group. This information was\nanalyzed and visually presented as \"point and clus-\nter maps\" using Concept Systems Software (Kane &\nTrochim, 2007) that illustrated relationships\namong the FE behaviors as well as their severity\nratings (Conrad et al., in press). Statements were\ngrouped into six clusters, visually depicted as maps,\nand ranked by the experts as follows in descending\nseverity: (a) theft and scams, (b) financial victim-\nization, (c) financial entitlement, (d) coercion, (e)\nsigns of possible FE, and (f) money management\ndifficulties (Conrad et al., in press). The statements\ndeveloped for the concept map were subsequently\nmade into questions, and questionnaires were\ndeveloped for both staff observation and client\nself-report. Nine focus groups, six involving\n44 staff from various agencies and three involving\n20 older adult consumers, were conducted to\nreview and refine the wording of the questions.\nFour cognitive interviews of the client measures\nwere then conducted with substantiated elder abuse\nclients whose input was also incorporated. The\nresulting questionnaire consisted of 82 questions.\nDetails of these focus groups and other qualitative\nwork are beyond the scope of this article, but may\nbe reviewed in Conrad, Iris, and Ridings (2009).\nPurpose of the Study\nThis article reports on the next stage in the\ndevelopment of the OAFEM in which field tests\nwere used to evaluate the instrument. Accordingly,\nwe examined client self-report measures of FE\nusing item response theory, including Rasch mod-\neling, and traditional validation techniques. Our\nspecific objectives were to: (a) test the fit of the\nitems to the model; (b) test the construct dimen-\nsionality of the OAFEM by examining whether or\nnot the items formed a single overarching FE con-\nstruct; (c) assess internal consistency reliability for\nall forms using a standard of .80 person reliability;\n(d) develop short forms that would be user-friendly\nfor clinical applications; (e) examine the appropri-\nateness of the measure for the target population,\nthat is, items centering on the sample as opposed\nto having floor and ceiling effects; (f) further test\nconstruct validity by positing a hierarchy of con-\ncept rankings that conforms to expectations devel-\noped in the prior research phase and then testing a\nset of hypothesized relationships using correlation\nanalysis; and (g) propose a reasonable, although\nspeculative given lack of external validation, cutoff\nto determine FE.\nDesign and Methods\nSample\nDatacollectionwassupportedthrougharesearch\nagreement with the Illinois Department on Aging\n(IDoA), which helped recruit elder abuse providers\nin the state. Seven adult protective services (APS)\nagencies in Chicago and its collar counties assisted\nin the development of a database to estimate the\npsychometric properties of two types of FE mea-\nsures: APS client self-report and APS investigator\n(staff) assessments. We used data from client self-\nreport measures of FE administered via interview\nfor at least one type of elder mistreatment. We\nincluded substantiated clients to ensure a target\nsample that was appropriate for the measures. To\nobtain the full range of the construct and include a\nsubstantial group in the \"floor,\" however, clients\ndid not have to be substantiated for FE.\nIn addition to administering the interview, the\nAPS staff who participated completed a staff obser-\nvation questionnaire on each of the clients they\ninterviewed. Staff received training on the proto-\ncols, including interviewing clients, by the two lead\nauthors. A key component of the interview was the\nassessment of cognitive status using the mini-mental\nstate examination (MMSE; Folstein, Folstein, &\nMcHugh, 1975). To participate in the study, the\nclient had to score at least 17 on the MMSE or, in\nthe judgment of the APS investigator, demonstrate\nadequate cognitive capacity to provide self-report.\nThe human subjects research proposal and informed\nconsent forms were approved by the University of\nIllinois at Chicago (UIC) internal review board\nvia the human subjects subcommittee. All partici-\npating APS staff completed the human subjects\ncommittee online training program of UIC. As\nshown in Table 1, the staff sample (n = 22) was\nTable 1. Demographic Characteristics of Staff Sample\nPercent Numbera\nGender\nRace\naNumbers may not add up to 100% due to missing values\npredominantly women (86.36%). More than half\nwas Caucasian (59.09%), a quarter was African\nAmerican (27.27%), and the remainder Hispanic\nor mixed race. Average years of experience were\n5.46 years. In Table 2, the sample of APS clients\nThe majority was African American (61.3%), more\nthan one third was Caucasian (35.5%), and the\nremainder was of mixed race or other. Most were\nnon-Hispanic (92.9%). The majority was between\nStatistical Analysis\nThe Rasch measurement model (Rasch, 1960)\nwas chosen because of its desirable scaling proper-\nties of linear, interval measurement (Embretson &\nReise, 2000). This was important to accurately\nestablish item hierarchy and distances between\nitems to support theory building and test construct\nvalidity. Therefore, the Rasch model was needed\nto test the theoretical hierarchy developed in prior\nwork. This is a type of construct validation. The\nRasch hierarchy was also useful in examining\ndimensionality, examining the rating scale, testing\nthe fit of items to the model, and in suggesting pos-\nsible cutoff scores. These are also aspects of con-\nstruct validation that can be facilitated with the\nRasch model.\nThe Rasch rating scale model (Wright &\nMasters, 1982), used for this analysis, estimates\nthe probability that a respondent will choose a\nparticular response category for an item as\n-\n= - -\nln ,\nnij\nn i j\nni j\nP\nP\nwhere Pnij\nis the probability of respondent\nn scoring in category j of item i, Pni\n(j-1) is the\nprobability of respondent n scoring in category\nj - 1 of item i, Bn\nis the person measure of respon-\ndent n, Di\nis the difficulty of item i, and Fj\nis the\ndifficulty of category step j. Rating scale categories\nare ordered steps on the measurement scale. Com-\npleting the jth step can be thought of as choosing\nthe jth alternative over the (j - 1)th in the response\nto the item.\nRasch analysis places persons (Bn\n) and items\n(Di\n) on the same measurement scale where the unit\nof measurement is the logit (log odds unit).\nAlthough person reliability in Rasch is analogous\nto Cronbach's alpha in true score theory (Nunnally &\nBernstein, 1994), it is more conservative (usually\nlower) because it estimates standard errors (SEs)\nfor each person and each item (vs. test-wide SE for\nalpha), thereby indicating how reliably persons and\nitems are placed on the scale. Alphas are provided\nfor those who prefer them, but we note that they\ntend to give high estimates due to the inclusion of\nzero and extreme high scores in their calculation.\nUsing the Winsteps Computer Program for these\ncalculations (Linacre, 2009), reliability estimates\nwere calculated from 0 to 1.00 on scales that are\nactually infinite in either direction (Linacre, 2002).\nDimensionality.--Because the Rasch model\nrequires unidimensionality, principal component\nanalysis of residuals is used to examine whether a\nsubstantial factor exists in the residuals after the\nprimary measurement dimension has been esti-\nthere are no hard rules for interpreting principal\ncomponents results, our rule of thumb for unidi-\nmensionality was variance explained of greater\nthan 40% by the measurement dimension (Linacre,\nto define a substantial factor. To be conservative in\ntesting a second dimension, we set less than 15%\n(even lower than Reckase) as the criterion for vari-\nance explained by the first principal component of\nthe residuals, that is, the second dimension. Simply\nput, using 40% and 15% variance as the criteria\nfor the first and second dimensions is a rigorous\ntest in that the measurement dimension must be\nTable 2. Demographic Characteristics of Client Sample\nPercent Numbera\nGender\nRace\n American Indian/Alaskan Native 0.5 1\nHispanic\naNumbers may not add up to 100% due to missing values.\n \nlarge at 40%, whereas the second dimension\nmust be quite small at under 15%. We also tested\ndimensionality using the procedure of Linacre\n(1998b). We extracted two subsets of items rep-\nresenting the opposite poles of the factor. We\nthen measured each subject on each subset of\nitems. We cross-plotted the subject measures and\nobtained correlation coefficients. Additional cri-\nteria for unidimensionality were employed using\nitem fit statistics discussed next.\nQuality Control With Fit Statistics.--Rasch anal-\nysis provides fit statistics to test assumptions of\nfundamental measurement (Wright & Stone,\n1979). \"Fitting the model\" simply means meeting\nbasic assumptions of measurement, for example,\nhigh scorers should endorse or get right almost all\nof the easy items. Once identified, persons and\nitems that \"misfit\" can be examined qualitatively\nto determine the causes of the problems, which\nmay include items with confusing wording or items\nthat assess a construct that is different from the\nprincipal one being measured, that is, multidimen-\nsionality. Understanding poor fit can lead to\nimproving or dropping items. A guide to interpret-\ning fit statistics can be found at http://www\n.rasch.org/rmt/. The Rasch model provides two\nindicators of misfit: infit and outfit for both per-\nsons and items (Wright & Stone).\nPerson fit indicates the extent to which each per-\nson's performance is consistent with the way items\nare used by other respondents. Item fit indicates the\nextent to which the use of a particular item is consis-\ntent with the way sample respondents have answered\nother items. For this type of analysis, values under\nprovide less motivation for item editing than do high\nvalues (Wilson), and they do not disturb the mean-\ning of a measure though they may reduce precision\n(Linacre & Wright, 1994). We also used statistical\nsignificance (p < .05) as a criterion to examine items\nthat should be dropped. Person fit statistics were\nexamined to inform the clinical interpretation of the\nperson measures but no persons were dropped.\nRating Scale.--The proper functioning of the\nrating scale was examined using: (a) fit statistics\nwhere outfit mean squares should be <2.0, (b)\naverage measures advance monotonically with\neach category, and (c) step calibrations increase\nZhu, Updike, & Lewandowski, 1997). We did not\nexpect the \"suspected\" category to perform as a\ntypical rating scale category. We expected it to be\nused very rarely, but, based on qualitative input, it\nwas important to include. A \"not applicable/don't\nknow\" category was coded as missing data.\nThe results tables are modified from Winsteps\nand interpretations. For an overview of Rasch\nanalysis, see Conrad and Smith (2004); for a com-\nplete treatment, see Bond and Fox (2007); and\nRasch Measurement Transactions at http://www\n.rasch.org/rmt/.\nConstruct Validation.--In Rasch analysis, the\nitem hierarchy that is created by the item difficulty\nestimates provides an indication of construct valid-\nity (Smith, 2001). Items should form a ladder with\nlow severity symptoms on the bottom and high\nseverity symptoms on the top. In our prior work\ndeveloping the FE measure (Conrad et al., in press),\n16 experts grouped the items into six categories\nand rated the severity of the items on a scale from\n1 to 5. These item severities were then averaged\nwithin each category. The result was a theoretical\nhierarchy of six conceptual components of FE\narranged in descending severity as follows (expert\nrating in parentheses): Theft and scams (4.31),\nfinancial victimization (4.20), financial entitlement\nWe tested whether the hierarchy developed by the\nexperts was validated compared with the client\nratings given by respondents in the present study\nusing the Rasch calibration on each item and aver-\naging those within each group of items.\nMultitrait, Multimethod Analysis.--Construct\nvalidation also may be tested by setting up a pat-\ntern of theoretical expectations and testing whether\nthose expectations are supported by the data\n(Campbell & Fiske, 1959). As Campbell and Fiske\npointed out, measures of the same construct should\nbe highly correlated especially if they use the same\nmethod of observation.\nMeasures Used in Construct Validation.--The\nIDoA uses a questionnaire for elder abuse investiga-\ntions that covers many forms of elder abuse, includ-\ning FE. The IDoA form contains several sections\nthat ask investigators to circle specific indicators of\neach type of suspected abuse. At the bottom of each\nsection, the staff member is asked to indicate if\nabuse is substantiated. The form also asks investi-\ngators for closing status on the case, identifying\nwhich types of abuse are substantiated. We exam-\nined the correlation of this closing status substanti-\nation decision on FE with results from the OAFEM\nquestionnaires. The following coding was used:\n1)  Client gender: men = 0, women = 1.\nFE substantiation decision: we considered\nFE substantiated if the staff member coded it\n\"verified\" or \"some indication.\" For cases marked\n\"no indication\" or \"unable to verify,\" FE was\nconsidered not substantiated.\nOAFEM staff: the staff reported OAFEM person\nreliability on 227 clients reported by the 22 staff\nwas very high at 0.94 with a Cronbach's alpha\nof 0.97. The Rasch item reliability was also very\nhigh at 0.97. The final 82 items of staff-reported\nFE (similar but not the same as the 79 client-\nreported items) met stringent Rasch analysis fit\nand unidimensionality criteria.\nOAFEM client: details are described in the\nResults section.\nThe direction and strength of construct pairs\ndepends on method and theoretical expectations. We\nset up a pattern of expected correlations roughly cor-\nas follows: NS = nonsignificant, <.1 = low, >.3 =\nmoderate, and >.5 = high. Others have suggested\nlower values based on reviews of research, for\nexample, >.2 = moderate and >.3 = high (Hemphill,\n2003), so there are no absolute guidelines avail-\nable. This hypothesized pattern and resulting\ncorrelations are in the upper right half of Table 4.\nThe diagonal entries are the person reliabilities.\nThe hypothesized correlations are stated above\neach correlation coefficient and are bulleted below:\nClient gender: we had no reason to expect\ndifferential exploitation by gender so all gender\ncorrelations were expected to be NS.\n2)  FE substantiation decision:\n\u00b7\n\u00b7 Moderate correlation with OAFEM and\n\u00b7\n\u00b7 High correlation (because staff complete\nboth) with Older Adult Mistreatment\nAssessment (OAMA) staff FE.\n3)  OAMA staff FE:\n\u00b7\n\u00b7 High correlation (because similar method\nand questions) with OAFEM.\nIn the multitrait, multimethod analyses, the\nmost complete versions of OAMA measures were\nused.\nResults\nOf all 227 clients who completed the OAFEM\nself-report questionnaires via interview, 164 (72%)\nhad at least some indication of FE based on IDoA\n\"verification decision\" criteria.\n1. Test the fit of the items: items were dropped\nbecause they did not meet criteria for fit, that\nis, they had both infit and outfit >1.33, and/or\npoint measure correlation, <.2. Because this\nwas an iterative analysis, 3 of the original 82\nitems were dropped because they misfit, then\nthe analysis was rerun. The remaining 79 items\nfit on the second and final run.\n2. Test construct dimensionality: the variance\nexplained in the remaining 79 items was\ncriterion, was supportive of a strong principal\nmeasurement dimension. Moreover, unidi-\nmensionality was supported because the resid-\nual variance explained by the first contrast\nwas very small--7.0% indicating no substan-\ntial rival dimension. The corresponding per-\ncentages for the measurement dimension and\nfirst factor of residuals respectively were\nresulting correlations using the procedure of\nis, strongly supportive of unidimensionality.\n3. Assess internal consistency reliability using a\nstandard of .80: the Rasch person reliability\n(alpha = 0.96). Similarly, Rasch item reliabil-\n4. Develop short forms that would be user-\nfriendly for clinical applications: to test if a\nmore parsimonious model would also func-\ntion well, we developed two shorter forms\ncontaining 54 items and 30 items respectively\n(Appendix contains items by form informa-\ntion). Because both met stringent Rasch analy-\nsis fit and unidimensionality criteria, we report\non the final 30-item instrument. The short\nform is viewed as most useful, but the longer\nforms provide a bank of items that may be\nuseful in future development of alternative\nforms or computerized adaptive tests.\n \nFor the 54-item version, person reliability was\n0.95. The Rasch person reliability for the 30-item\nform remained high at 0.85 (corresponding to\nCronbach's alpha of 0.93). The Rasch item reli-\nability was also very high at 0.96.\n5. Examine the appropriateness of the measure\nfor the target population: in Figure 1, the\nRasch ruler for the 30-item version is dis-\nplayed. On the far left is the measurement scale\nin logits ranging from -3 to +3. Persons (n =\n227) are arrayed on the left of the dashed line\n(representing the ruler) and the 30 items on the\nright. By convention, the item mean is the 0 point\non the ruler. The items form a hierarchy of\nseverity based on frequency of endorsement\nwith lower severity items (more frequently\nendorsed) at the bottom and higher severity\nitems (less frequently endorsed) at the top. The\npersons are displayed according to their mea-\nsures on the OAFEM scale with low scorers\n(low FE) at the bottom and high scorers (high\nFE) at the top. There is a substantial floor of\npersons at the bottom who are not registering\nany FE. This was expected because all staff\nsubstantiated elder abuse clients were accepted,\nwhether or not they were substantiated specifi-\ncally for FE. Although the persons in the floor\nwere included on the map, they were not\nincluded in the calculation of the person mean\n(M = -0.79 on the left side of the ruler) and\nstandard deviation (SD = 1.02). We interpreted\nthis as reasonably well targeted because the\nperson mean was within one logit and about\none item SD of the item mean of zero.\n6. Test construct validity by positing a hierarchy\nof concept rankings and a set of hypothesized\nrelationships: looking at Table 3, \"Original\nconcept group,\" the ordering of the FE con-\nceptual components was the same in four out\nof six cases for experts, averaging their con-\ncept map ratings, and clients, averaging their\nRasch measurement calibrations. The first dif-\nference between experts and clients was coer-\ncion that jumped in rank from fourth most\nsevere as rated by experts to second most\nsevere based on client endorsements. Clients\nranked abuse of trust fifth whereas experts\nhad ranked it second. However, these differ-\nences are negated by the fact that the model\nSE was 0.36. Therefore, the differences in the\nrankings were not statistically significantly\ndifferent among the four concepts in the mid-\ndle of the expert hierarchy. Specifically, they\nranged from abuse of trust at -0.13 to signs of\npossible abuse at -0.07 to financial entitle-\nwords, using the client rankings, there was a\nstatistical four-way tie among the concepts for\nsecond place.\nversions formed a unidimensional overarching\nmeasure of client-reported FE. Therefore, rather\nthan separating FE into several separate dimen-\nsions, the Rasch results suggested a single hierarchy\nthat could be conceptualized according to its sever-\nity levels. The structure of the client data as seen in\nthe Wright map presented a simpler picture of FE\nthan the expert groups and ratings. Four groups\nwere identified consisting, in descending order of\nseverity, of major theft and scams (MT), lesser theft\nand scams (LT), risk (dropped from the 30-item\nform), and entitlement and expectations (EE).\nExamination of the Wright map (Figure 1) indicates\nthese severity groups using the two-letter suffixes\nabove. These were similar to the experts' concept\ngroups except that signs and risk factors were\nexcluded from the short forms because they do not\nconnote actual exploitation, and the coercion items\nwere incorporated into the other groups because\nthey were dispersed throughout the hierarchy. The\nvalidity of these groups is supported because, on\naverage, they are located over one SE (SE = 0.36)\nfrom each other, that is, average item calibrations\ncan see that MT and EE are nearly 3 SEs apart.\nRegarding correlational validation, we hypoth-\nesized that all gender correlations would be NS\nand they were (Table 4). The other three correla-\ntions, two high and one moderate, were as hypoth-\nesized that was supportive of the OAFEM's\nvalidity.\n7. Identify an appropriate cutoff to determine\nFE: because there is no solely empirical way to\ndetermine a cut-point, we discuss the logic of\nour cut-points below.\nDiscussion\nThis study used Rasch item response theory and\ntraditional validation approaches to examine the psy-\nchometric properties of the OAFEM. Previous work\nwith expert-developed concept maps of FE, focus\ngroups,andcognitiveinterviewsresultedinan82-item\nquestionnaire administered in the present study by\nAPS staff (n = 22) to substantiated clients (n = 227) in\nseven agencies in Illinois. Because no distinct empiri-\ncally validated measure of FE exists, the OAFEM\noffers an important tool for elder abuse research as\nwell as to practitioners working in the field.\nThe OAFEM met stringent Rasch model criteria\nfor item fit and unidimensionality; it had high internal\nFigure 1. Ruler of Rasch measurement person and item hierarchies (item numbers keyed to Appendix). Persons n = 227 and items\n \nconsistency and item reliability. As a unidimen-\nsional measure of FE, it was found to have levels of\nseverity rather than distinct subdimensions. These\nranged from major theft at the high end to lesser\ntheft in the middle to expectations and entitlement\nat the low end. This severity hierarchy helps us to\ndevelop a suggested cutoff score, though it is admit-\ntedly speculative at this early stage.\nIf we look at Figure 1, the person\u00aditem map,\n173 persons endorsed at least one item on the\n30-item OAFEM. Note that above -1.0 on this\nruler, the item meanings and locations indicate\nthat this may be a useful cutoff score. In other\nwords, this level indicates more serious violations\nsuch as \"unexplained disappearances of the elder's\npossessions\" and \"alleged abuser lying about\nspending the elder's money.\" Above this -1.0 level\nwere 102 persons. These persons had a score of\n12 or more of a possible 60 raw score points on\nthe measure. If we use a higher severity of 0 on the\nruler as the criterion for serious FE, there were\n41 persons above this level having even more severe\nsymptomatology, that is, mostly major theft and\nscams. These symptoms included \"alleged abuser\nforcing the older adult into signing legal docu-\nments\" and \"pressuring the older adult to modify\ntheir will.\" Therefore, using cutoffs suggested by\nthe client-reported empirical hierarchy, there were\n102 persons who reported clinically significant FE.\nOf these, 41 were suffering from very severe FE.\nStudy Strengths and Limitations\nThis study developed the largest known data-\nbase of substantiated clients of elder abuse to test\nthe validity of the OAFEM and to suggest cut-\npoints for judgments of severity. Although it had\nwell-targeted clients, expert interviewers, and\nmodern measurement techniques, it was limited to\nthe small geographic area of Cook and surround-\ning counties in Illinois. Although several validity\ntests were applied, many more can be imagined in\nother areas and populations. The groups and cut-\npoints suggested here were based on the logic of\nthe Wright map hierarchy, but are otherwise spec-\nulative, and will require further replication and\nvalidation with external criteria to refine them, for\nexample, using bank records and other financial\ndocuments, and sensitivity\u00adspecificity analysis\nonce a cut-point is defined.\nConclusions\nThese measures, used appropriately as long and\nshort forms, should help to open the neglected area\nof FE of older adults for improved services and\nTable 3. Expert Item Groups and Rankings Compared With\nClient Rankings\nOriginal concept group (expert order) Average measurea\n(client order)\naBased on the client endorsement of the items with a model\nbAbuse of trust and coercion were the only concepts whose\nRasch average measure was out of order with the original\nexpert ranking, but stability of the rankings is in question\nbecause their average calibrations are so close together, that\nis, within 1 SE.\nTable 4. Hypothesized and Actual Correlationsa\nClient gender FE substantiation decision (IDoA) OAMA staff FE OAFEM\nClient gender -- NS NS NS\nFE substantiation decision -- High Moderate\nOAMA staff FE .94b High\nNote: FE = financial exploitation; IDoA = Illinois Department on Aging; OAFEM = older adult financial exploitation\nmeasure; OAMA = Older Adult Mistreatment Assessment.\naHypothesized correlations: NS = non-significant, >.1 = low, >.3 = moderate, and >.5 = high are listed above the actual\ncorrelations.\nbPerson reliabilities of OAMA scales are located on the diagonal.\n**Correlation is significant at the 0.01 level (two tailed).\nresearch. They should improve the understanding of\nprevalence by offering researchers a tested approach\nto the measurement of FE as well as enabling more\naccurate self- and third-party reporting. Using the\nWright map, the measures provided theoretically\nsupportable gradations along the continuum of abuse\nseverity that can enable better decision making.\nImproved measurement will also enable practitio-\nners to screen clients more efficiently, systemati-\ncally, and precisely, so that, with the development of\ncutoff scores, cases may be triaged more effectively\ninto appropriate interventions.\nFunding\n"
}