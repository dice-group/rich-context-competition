{
    "abstract": "Willard L. Rodgers, Mary Beth Ofstedal, and A. Regula Herzog",
    "reduced_content": "Willard L. Rodgers, Mary Beth Ofstedal, and A. Regula Herzog\nSurvey Research Center, University of Michigan, Ann Arbor.\nObjective. This study investigates cohort differences in cognitive functioning among Americans aged 70 or older in\nMethods. The study draws on self-respondent data from four waves of the Asset and Health Dynamics Among the\nOldest Old Study and the Health and Retirement Study surveys collected between 1993 and 2000. Cognitive performance\nscores for each of four components (immediate recall, delayed recall, serial 7s, and mental status) and their sum are\ncompared across cohorts, unadjusted and with adjustments for survey design features and demographic characteristics.\nResults. Unadjusted scores suggest cohort improvements in several components of cognitive functioning between 1993\nfeatures of the survey design (changes in age distribution of the sample across waves and prior exposure to the cognitive\ntests) and changes in the demographic composition of the sample (race, ethnicity, and gender) are adjusted for.\nDiscussion. There appears to have been little improvement of cognitive functioning across recent cohorts of older\nAmericans. However, the study points out the complexities of using panel data to study cohort differences, particularly\nwhen the measures of interest are likely influenced by prior wave participation. Future studies based on other data sources\nare needed.\nFINDINGS that suggest a cohort-related decline in\ndisability among recent cohorts of older Americans have\ngenerated considerable interest in the research as well as the\npolicy arena. Several studies have described lessened functional\nimpairment measured by physical functions such as lifting and\ncarrying and climbing and walking and by activities of daily\nliving (ADLs) such as dressing and eating among recent\ncohorts of elderly people as compared with previous cohorts\nwhen assessed at the same chronological age (Freedman &\nSuch findings have important implications for projecting the\nability of older adults to function independently and care for\nthemselves and for their need for family care, support services,\nand institutionalization--in short for the costs of supporting\nAmerica's oldest population. Whereas past investigations have\nfocused primarily on physical impairments, it is well\nrecognized that the ability to function independently depends\nat least as much on cognitive functioning as on physical\nfunctioning, and that this will increasingly be the case in an\nenvironment of growing technological and informational\ncomplexity. It is therefore of equal interest to learn whether\nthe suggested cohort-related decline extends to cognitive\nfunctioning.\nA few studies have in fact suggested that impairments of\ninstrumental ADLs (IADLs) such as shopping for food and\nmaking telephone calls have declined at least as much as phys-\nical impairment and ADLs across cohorts (Crimmins, Saito,\nmore heavily on cognitive functioning than ADLs. Similarly,\ncohort-related declines in dementia have been reported (Corder\nBroad societal changes would seem to be consistent with such\nfindings. For example, the quantity and quality of education\nhave increased throughout this century, and subsequent cohorts\nhave reaped the benefit of improving education. During this\nsame time, the workplace was transformed from predominantly\nlabor and low-tech jobs to service and high-tech jobs. Both\neducation and complex work benefit cognitive functioning\n(Fillenbaum, Hughes, Heyman, George, & Blazer, 1988; Kohn\nProbably the most direct test to date of improvement in\ncognitive functioning among more recent cohorts of older\nAmericans was reported by Freedman, Aykan, and Martin\n(2001). These authors used nationally representative longitudi-\nnal data from the 1993 wave of the Asset and Health Dynamics\nAmong the Oldest Old Study (AHEAD) and the 1998 wave of\nthe Health and Retirement Study (HRS) to compare two cohorts\nsevere cognitive impairment, as measured by means of a short\nbattery of standard cognitive tests. They reported a decline from\nimpairment and found that this decline was not explained, at\nleast in full, by differences in demographic, socioeconomic, and\nhealth composition of the two cohorts. This represents a rather\ndramatic shift over a relatively short period of time and\ndeserves notice.\nThe combined HRS and AHEAD studies--which began in\nrepresent an attractive opportunity for investigating cohort\ndifferences in cognitive performance. First, the study is\ndesigned to be nationally representative of Americans who\nare 51 years old and older. Second, interviews are conducted\nJournal of Gerontology: SOCIAL SCIENCES Copyright 2003 by The Gerontological Society of America\nevery 2 years and the sample is periodically replenished with\nincoming cohorts (every 6 years). Third, a short battery of\ncognitive performance measures is administered as part of each\ninterview.\nDespite this attractive design, some of its specific features\nmust be carefully considered with regard to making valid cohort\ncomparisons. One set of design features affects the composition\nof the sample. First, to date, the HRS survey has added new\nbirth cohorts only once, in 1998, providing at that point a\nsample representative of the population born in 1947 or before.\nThe remaining biennial surveys only sought interviews with\n51\u00fe age range. Second, proxy respondents are interviewed\nwhen selected respondents are unable or unwilling to partici-\npate themselves. Third, not all respondents who are unable\nor unwilling to participate for themselves are represented by\na proxy. Some die, some are lost to follow-up, some simply\nrefuse, and for some no proxy is available. Many of these\nreasons for attrition are related to cognitive impairment; those\nwho are more impaired are more likely to become non-\nrespondents, and therefore attrition may bias the samples.\nAnother set of design features refers to the specific cognitive\nperformance measures included in the studies. First, the HRS is\na panel study in which the same respondents are re-interviewed\nin each survey wave. Despite replenishment of newly entering\ncohorts in later surveys, most respondents had been surveyed\nbefore, sometimes repeatedly. A number of studies that have\nexamined individual-level changes in cognitive functioning\nover time have found strong learning effects associated with\nrepeated cognitive testing (Jacqmin-Gadda, Fabrigoule, Com-\nmenges, & Dartigues, 1997; Unger, van Belle, & Heyman,\npronounced between the first and second exposure to the\ncognitive tests (Jacqmin-Gadda et al., 1997). Such learning\neffects may confound cohort comparisons using the HRS\u00ad\nAHEAD studies. Second, as we have noted before (Herzog &\nRodgers, 1999), the changing historic and societal context can\naffect knowledge of information from real life, confounding\ncomparisons of cognitive performance over time; the knowl-\nedge of the President's and Vice President's names are good\nexamples, in that it is likely to be influenced by the timing of\nelections or other political events featuring these individuals\nvis-a\n`-vis the interview. Third, the cognitive tests were revised\nslightly after the AHEAD 1993 survey, a change that possibly\nfurther confounds the comparisons. Most importantly, the\nsingle list of 10 nouns for the free recall test that was used in\nfour lists (each containing 10 nouns) assigned to respondents\nin a counterbalanced manner (for more detail, see Ofstedal,\nMcAuley, & Herzog, 2001). Preliminary comparisons of the\nfour new lists in Wave 2 indicated equivalence of list difficulty\n(Herzog & Rodgers, 1999). However, more recent data\n(discussed in the following paragraphs) provide some evidence\nthat one of the lists is more difficult than the other three, and\nalso that the list administered at Wave 1 is more difficult than\nany of those introduced in Wave 2. Fourth, HRS uses a mixed-\nmode design according to which baseline interviews, and\nfollow-up interviews with those over the age of 80, were mostly\nconducted face to face, whereas follow-up interviews with\nyounger respondents were done mostly over the telephone.\nCognitive performance is possibly related to the mode by which\nit is measured, and the mixing of modes therefore creates\na possible source of confounding of differences and changes in\ncognitive scores.\nMETHODS\nData Sets\nThe data used in this study are from the AHEAD and HRS\npanel studies. AHEAD is a longitudinal survey of a nationally\nrepresentative sample of persons who were born in 1923 or\nbefore and who were living in the community at the time of the\nwith sampled respondents and their spouses (of any age). To\ndate, respondents have been reinterviewed three times: in\nbaseline, and follow-up response rates for surviving respon-\ndents have reached or exceeded 94% in all subsequent waves.\nThe HRS, which is similar in design and content to AHEAD,\nbegan in 1992 as a longitudinal survey of a somewhat younger\n2000), and response rates have tended to be slightly higher than\nthose for AHEAD. The AHEAD and HRS surveys were\ncombined in 1998 and the sample was supplemented with new\nbirth cohorts so as to be representative of the entire U.S.\nhousehold population born in 1947 or before (i.e., aged 51 and\nolder in 1998). Data from four waves of interviews were\nrespondents who were at least 70 years old at the time of the\nspecific interview. Further detail on the design of the AHEAD\nand HRS studies is provided elsewhere (Juster & Suzman,\nCognitive Measures\nIn this article we focus exclusively on the cognitive per-\nformance tests that were administered to self-respondents in\nall four waves. These cognitive performance measures were\nchosen for AHEAD and HRS to cover a range of cognitive\nskills and to be suitable for administration over the telephone.\nTo this end, many of the items were drawn from the Telephone\nInterview for Cognitive Status (TICS) screen, which is modeled\nafter the widely used Mini-Mental State Exam and has been\nvalidated specifically for phone use (Brandt, Spencer, &\nFolstein, 1988). The individual items may also be mapped\nonto the cognitive dimensions of fluid intelligence or process\n(counting backwards), crystallized intelligence or product\n(naming objects and president), orientation in time (dates),\nimmediate memory (immediate free noun recall), delayed\nmemory (delayed free noun recall), and working memory\n(serial 7s). For both immediate and delayed free recall tests, the\ninterviewer read a list of 10 nouns, and respondents were asked\nto repeat as many as they could immediately afterward and\nagain several minutes later in the interview. In the serial 7s\nsubtraction test, respondents were asked to subtract 7 from 100\nfor a total of five times. Respondents were also asked to name\nthe date (day, month, year, and day of the week), to name\ncactus and scissors from a brief description, and to identify the\nU.S. President by last name. Finally, respondents were required\nto count backward from 20. On the basis of prior factor\nanalyses (Herzog & Wallace, 1997), we retained for the\nanalyses reported in this article the Immediate Word Recall\n(scores ranging from 0 to 10), the Delayed Word Recall (from\ncomposite Mental Status (MS) score, formulated by adding\nscores on all remaining items, resulting in a composite score\nranging from 0 to 9. (We omitted from our analyses an item\nasking for the name of the U.S. Vice President, because an\ninspection of the proportion answering this correctly each year\nstrongly suggested that there was a period effect that would\nhave contaminated the cohort effects on which we wanted to\nfocus our attention. Details on the scientific justification for\nexcluding this item are provided in the working version of this\narticle, which is available upon request from W. Rodgers.) We\nalso formed an overall cognitive score that is the sum of the\nfour components. Alpha (reliability) coefficients for the overall\nscore range from .72 to .76 across the four waves.\nMissing data rates on the cognitive measures are not\nparticularly high: approximately 2% (averaged across waves,\namong those aged 70 and older at each wave) for the immediate\nand delayed recall tasks; from 0.2% to 1.9% for the items on\nthe MS component; and almost 8% for the serial 7s test. It is\nclear, however, that the data are not missing at random. Those\npersons with poor cognitive ability are more likely to refuse to\nparticipate in these tests, as evidenced first by looking at the\naverage scores on the other components for those with and\nwithout missing data on any one component (see also Herzog &\nWallace, 1997) and second by looking at the average scores at\none wave for those with and without missing data at either the\npreceding or the following wave. Those with any missing data\nat wave t (t \u00bc 1, 2, or 3) but none at wave t \u00fe 1 have total\ncognitive scores 6 or 7 points lower at wave t \u00fe 1 than do those\nwith no missing data at wave t, and similarly those with any\nmissing data at wave t (t\u00bc2, 3, or 4) but none at wave t\u00ff1 have\ntotal cognitive scores 6 or 7 points lower at wave t \u00ff1 than do\nthose with no missing data at wave t. Moreover, and directly\nrelevant to the purposes of this article, the proportion of missing\ndata is not constant across waves. Across the four waves for the\n11 items in the cognitive tests considered in this article, the item\nmissing data rate was 1.4%, but it ranged from a high of 2.5%\nBecause the data are not missing at random, it is important to\ntake account of missing data rather than to delete cases with any\nmissing data. We have done so by using an imputation proce-\ndure that took account of both stable and time-varying covar-\niates and of covariation of the cognitive measures both within\nand across waves. (The imputations were done with IVEware;\nsee Raghunathan, Lepkowski, Van Hoewyk, & Solenberger,\n2001. The three-stage procedure that we used is described in\nthe working paper version of this article.)\nAnalysis Methods\nTo assess trends in the cognitive test scores, we first\nexamined unadjusted average scores for each wave for the\noverall cognitive scale and each of the four component scales.\nWe then used multivariate regression techniques to evaluate the\nextent to which the observed trends could be accounted for by\nstudy design features and by differences in the demographic\ncomposition of cohorts across waves. We consider these factors\nextraneous to cohort differences. Finally, we evaluated the\nhypothesis that cohort differences in educational attainment\ncould explain cohort differences in cognition.\nRegression models were estimated by pooling the samples\nacross all four waves and including indicators for the interview\nwave to test for differences in average score across waves. Four\nmodels were estimated: Model 1 includes only the wave indi-\ncators (the unadjusted model), Model 2 adds the study design\nvariables, Model 3 adds demographic characteristics of respon-\ndents, and Model 4 adds education. Following these primary\nanalyses, we conducted a set of additional analyses to evalu-\nate the potential confounding effects of interview mode, dif-\nferences in word lists, and selection effects. Results of those\nrefinements are discussed briefly at the end of the article. Be-\ncause persons in nursing homes and other institutional settings\nare not represented at Wave 1, respondents in nursing homes\nat later waves are excluded from these analyses to avoid the\nintroduction of a spurious change component. In all analyses,\nthe data were weighted to take account of both the sample\ndesign (which included oversamples of Blacks and Mexican\nAmericans) and poststratification adjustments to Current Pop-\nulation Survey estimates of the proportion of the household\npopulation in cells defined by race, gender, marital status, and\nage ranges. Moreover, all standard errors (and significance\nlevels) were adjusted to account for the complex sample design\nof the AHEAD\u00adHRS studies and the overlap in cases between\nwaves.\nRESULTS\nDescription of Samples at All Waves\nRespondent characteristics that will be treated as covariates\nof cognitive status are listed in the top panel of Table 1, with\nmeans or proportions shown for those with self-interviews at\neach of the four waves. The average age increased almost 2\nyears between Waves 1 and 2; this reflects the study design,\nbecause in those two waves the target population was restricted\nto individuals born in 1923 or earlier. At Wave 3, younger birth\ncohorts were represented, and the average ages at Waves 3 and\n4 are approximately the same as those at Wave 1. The dif-\nferences in proportions with a prior self-interview also reflect\nthe AHEAD\u00adHRS design: In Waves 2 and 4 almost all re-\nspondents had been previously interviewed, whereas in Wave\n3 new cohorts were sampled and interviewed for the first time.\nTable 1 shows that there are also differences on other char-\nacteristics across waves. Level of education increased mono-\ntonically across the four waves. This we interpret as a real\ndifference in the target population, one that reflects a trend\ntoward higher educational attainment in more recent birth\ncohorts. The proportion of respondents who were female and\nwho reported themselves to be Black or African American did\nnot differ significantly across waves, but the proportion who\nsaid that they were Hispanic increased from approximately 3%\nat Waves 1 and 2 to approximately 4% at Waves 3 and 4.\nDescription of Cognitive Scores at All Waves\nThe mean scores on each of the four cognitive tests at each of\nthe four waves are shown in the second part of Table 1. The\nnumber of words recalled both immediately and after a delay\nincreased significantly from Wave 1 to Wave 2, and again from\nWave 2 to Wave 3 (p , :001 in each case), but the change in\naverage scores on each of these measures between Wave 3 and\nWave 4 was small, negative, and not statistically significant.\nScores on the MS scale increased significantly every wave. The\npattern for the serial 7s scores is, by contrast, nonmonotonic:\nthere is a significant decline from Wave 1 to Wave 2 (p , :001),\nfollowed by a return to the Wave 1 level at Waves 3 and 4.\nThe next to last row of Table 1 shows the mean values on the\ntotal cognitive score. There are statistically significant increases\nbetween Waves 1 and 2 and between Waves 2 and 3\n(p , :001), but the difference between Waves 3 and 4 is small\nand not statistically significant. The final row of Table 1 shows\nthat the proportion of respondents with low (10 or fewer) total\nscores declined monotonically across the four waves, from 6%\nAdjustments for Design-Driven Covariates\nThe observed changes in the cognitive scores presented\nin Table 1 may be affected by factors related to the design of\nthe study and thus may not accurately reflect true differences\nin the target population. As noted before, two such factors\nare of special concern because they are expected to be\nrelated to performance on cognitive measures--the changes\nin the age distribution of the sample at the different waves\nand the prior experience with the cognitive tests for many of\nthose interviewed after Wave 1. The correlations between\nage and each of the component cognitive scores are negative,\nin the range of \u00ff.16 (for serial 7s) to \u00ff.30 (for delayed word\nrecall), and that between age and the total score is \u00ff.33.\nThese correlations are strong enough that the changes in\nthe age distribution across waves (which are statistically\nsignificant as shown in Table 1) could contribute substan-\ntially to the differences in cognitive scores between waves.\nThe prior experience with cognitive tests is due to the nature\nof a longitudinal design, which generally builds in a con-\nfounding between period (i.e., the dates on which the data\nare collected) and exposure to the content of the data col-\nlection instrument. If all respondents enter the study at the\nsame time and are reinterviewed on the same schedule, then\nit is impossible to separate the effects of period from those\nof experience. The design of the HRS is such that prior ex-\nposure to the cognitive tests is not completely confounded with\nperiod (because, e.g., new birth cohorts were interviewed for\nthe first time at Wave 3), but there is a strong relationship. The\nimplication is that the pattern of scores that we have observed\nacross waves may be biased because of the effects of prior\nexposure to the tests.\nTo take account of these two design-driven covariates and\nthereby obtain more accurate estimates of changes over time in\nthe cognitive abilities of the target population, we used re-\ngression analyses in which the dependent variable was one of\nthe cognitive measures and the predictors included (in addition\nto dummy variables for the wave of data collection) the age of\nthe respondent and a dummy variable indicating whether or not\nthe respondent had done a prior self-interview (and so whether\nor not the respondent had previously taken the cognitive tests as\npart of the HRS interview).\nThe findings from the regression analyses for the total\ncognitive score are displayed in Table 2. (Parallel regression\nanalyses predicting each of the four component scores were\nalso run but cannot be included in this article because of space\nconstraints. They are included in the working paper version.)\nResults from logit regression analyses predicting the probability\nof a low total score are displayed in Table 3. Model 1 in Table 2\nsimply repeats the information given in Table 1 in a different\nformat to facilitate comparisons with Model 2, which adds the\ndesign-driven covariates. Looking first at the coefficients for\nthe covariates included in Model 2, we see that age has the\nexpected negative relationship to the cognitive score, and the\nexpected positive relationship to the probability of a low total\nscore ( p , :001 in each case), with an estimated decline of more\nthan .3 points on the total score per year. Prior exposure to the\ncognitive tests is also strongly related to the cognitive scores:\nthose who have previously been interviewed score over 1 point\nhigher, in total, than those interviewed for the first time, after age\nis adjusted for.\nAfter the design-driven covariates have been accounted for,\nall of the differences in cognitive scores between waves are\nestimated to be much smaller than the unadjusted differences,\nTable 1. Average Values on Covariates and Cognitive Scores\nfor Self-Respondents\nSignificance for Difference Between Waves\nCovariates\nProp. w/prior\nself-interview(s)\nCognitive Scores\nLow total score:\nNotes: The data are weighted. Standard errors, calculated to take the\nweights and the complex sample design into account, are shown in parenthe-\nses. AA \u00bc African American; HS \u00bc high school; WR \u00bc word recall. The sta-\ntistical significance of difference between adjacent waves takes into account\nboth the complex sample design and the overlap in cases between waves.\nand the adjusted means for Waves 2 and 4 are in fact lower than\nthat for Wave 1. The only improvement that is statistically\nsignificant is that for the total score between Waves 2 and 3,\nand that is followed by a significant decline between Waves 3\nand 4. None of the differences between waves in the probability\nof low total scores remains statistically significant.\nAdjusting for Respondent Characteristics\nTo further understand the observed changes in the cognitive\nscores across the four waves, we estimated a third regression\nmodel to take account of respondent demographic character-\nistics that are related to the cognitive scores. These covariates\ninclude race, ethnicity, and gender (in addition to age, which\nwas already included as a design-driven covariate in Model 2).\nReal changes in the composition of the elderly population on\nthese characteristics across the approximately 6-year period\ncould affect the aggregate cognitive performance. Taking these\ncharacteristics into account does not change the pattern of\nstatistically significant differences between waves, either for the\ntotal scores or for the probability of a low score.\nEducational attainment represents another respondent char-\nacteristic of interest, but in this case the rationale is somewhat\ndifferent. We hypothesize that educational activities are\ncausally related to cognitive performance. The literature on\ncrystallized intelligence--also termed knowledge component\nor product (Salthouse, 1999)--suggests that formal education\nplays an important role in developing cognitive performance\n(Perlmutter & Nyquist, 1990). On the basis of this argument\nwe believe that it is inappropriate to adjust for educational\nattainment because the growing educational attainment across\nmore recent cohorts is part of the phenomenon of increasing\ncognitive performance. Of course, the direction of causation\nbetween education and cognitive performance may be the\nreverse--a higher level of cognitive performance enables higher\nlevels of educational attainment; in other words, education is\nthe outcome. On the basis of this argument it would be par-\nticularly inappropriate to control education away, we suggest,\nbecause we would in part be controlling for the very char-\nacteristic that we are trying to explain and thereby we would\nproduce biased estimates of the cognitive cohort trends.\nNevertheless, because of the wide interest among researchers\nin the role of educational attainment in cognitive functioning,\nwe test a model that includes three indicators of educational\nattainment (Table 2). The first indicator is the number of years\nof education, 0\u00ad17, that the respondent reported completing.\nThe other two indicators are dummy variables for completion of\nhigh school and obtaining a college degree, respectively.\nThese educational variables explain a fairly substantial\nproportion of the variance in the cognitive scores as evidenced\nby the increase in R2 from Model 3 to Model 4. However,\ndespite the substantial relationship between education and\ncognitive scores and the substantial increases in educational\nTable 2. Regressions to Total Cognitive Score for Self-Respondents\nWave 2 vs. Wave 3 *** *** *** ns\nWave 3 vs. Wave 4 ns *** ** ***\nNotes: Standard errors, calculated to take the complex sample design into\naccount, are shown in parentheses. The statistical significance of coefficients\n(noted next to each coefficient) and of the difference in coefficients between\nadjacent waves (noted in rows inserted between adjacent waves) takes into\naccount both the complex sample design and the overlap in cases between\nwaves.\nTable 3. Logistic Regressions to Low Cognitive Score\nWave 2 vs. Wave 3 *** ns ns ns\nWave 3 vs. Wave 4 ns ns ns ns\nNotes: Standard errors, calculated to take the complex sample design into\naccount, are shown in parentheses. The statistical significance of coefficients\n(noted next to each coefficient) and of the difference in coefficients between\nadjacent waves (noted in rows inserted between adjacent waves) takes into\naccount both the complex sample design and the overlap in cases between\nwaves.\nattainment across the four waves (as shown in Table 1), the\ncoefficients for the wave indicators in the fully controlled\nmodel (Model 4) do not differ much from those in the model\nwithout the education controls (Model 3). The only statistically\nsignificant difference between any pair of waves on the total\ncognitive score that remains after education as well as the\ndesign-driven and demographic characteristics are controlled\nfor is the decline between Waves 3 and 4.\nRefinements\nMode of data collection. --One characteristic that is not\nincluded in any of the models shown in Tables 2 and 3 is the\nmode of the interview. Cognitive scores of those who were\ninterviewed by telephone had substantially higher average\nscores on all four of the cognitive tests (p , :001 in each case).\nMoreover, the proportion of respondents interviewed face to\nface varied considerably across the four waves, ranging from\never, we do not think it is appropriate to include mode as a\ncovariate when we are trying to understand the trend in\ncognitive scores. This is because the interview mode may well\nbe the consequence of cognitive status, rather than an influence\non cognitive scores, so that a model that included mode would\nbe misspecified and the estimates of the effects of other\nvariables, such as wave, would be biased. By design, the\npreferred mode of interviewing depends on the age of the\nrespondent, and age is a known predictor of cognitive status, so\nthe inclusion of mode would bias the estimate of the effect of\nage on cognitive status; but the actual mode of the interview is\ninfluenced by characteristics of the respondents, including their\nphysical and cognitive limitations. Across the four waves, 28%\nof those aged 70\u00ad79 were interviewed face to face, and 41% of\nthose aged 80 and older were interviewed by telephone. An\nexperiment conducted as part of the HRS\u00adAHEAD research to\ntest mode differences in randomly assigned modes further\nconfirms the fact that mode per se is not related to cognitive\nscores (for details, see Herzog & Rodgers, 1999).\nDifferences between word lists. --There are two important\npatterns with respect to the adjusted trends in components of\nthe cognitive scores: Scores on the two-word recall tasks were\nconsistently higher at Wave 2 than at Wave 1, and scores on the\nserial 7s task were consistently lower at each of the later waves\nrelative to Wave 1. We have not found a satisfactory expla-\nnation for the lower scores on the serial 7s task at the three\nlater waves; we suspect that it may lie in differences in how the\ninterviewers were trained to administer the task at the first wave\ncompared with later waves. We have, however, found a possible\nexplanation of the increase in scores on the immediate and\ndelayed word recall tasks from Wave 1 to later waves: this may\nlie in the change in the word lists introduced at Wave 2. As\nalready described, at Wave 1 all respondents heard a single list\nof 10 words, but starting at Wave 2 respondents were randomly\nassigned to one of four word lists, all four of them different\nfrom that used at Wave 1. All four lists show a positive trend\nacross the first three waves: that is, at Wave 2 the respondents\nrecalled more of the words on all four of the lists than\nrespondents at Wave 1, and those who heard a given list at\nWave 3 recalled more of those words than did the (different)\nrespondents who heard that list at Wave 2. It appears, however,\nthat the four word lists are not equivalent to one another, and in\nparticular one of the lists appears to be more difficult than the\nthree other lists. This difference between the word lists becomes\neven more dramatic when the scores are adjusted by using\na regression analysis that includes the design-driven covariates\nand respondent characteristics listed for Model 3 in Table 2.\nThe adjusted scores for those given List 2 at Waves 2\u00ad4 are at\nleast slightly lower (and both substantially and significantly\nlower at Wave 4) than those of all respondents at Wave 1,\nwhereas those given the three other lists had consistently (and\nsometimes significantly) higher scores at Waves 2\u00ad4. These\nresults show the sensitivity of the scores on the word recall\ntasks to the specific words in the list, and the difficulty of\ncoming up with equivalent lists.\nThere is no direct evidence concerning the difficulty of the\nword list used at Wave 1 relative to the four lists used at sub-\nsequent waves. We have examined the difficulty of individual\nwords used in these lists as assessed by the proportion of\nrespondents who were able to recall each word in the immediate\nand delayed recall tasks, and although there is a great variability\nin difficulty, we did not find any outliers--that is, no words that\nwere so much more difficult or easy than other words that their\ninclusion in a particular list could explain why that list was easier\nor harder than other lists. A plausible hypothesis, however, is that\nthe observed increase from Wave 1 to later waves is partly, if not\ncompletely, explained by the original word list being more dif-\nficult, on the average, than the lists used at subsequent waves.\nSelection effects. --Although the data analyzed in this article\ncome from a panel study, the specific respondents from whom\ncognitive scores were obtained are not constant from wave to\nwave because of features of the HRS\u00adAHEAD design described\nearlier, such as sample selection, proxy interviewing, moving\ninto a nursing home, and sample attrition related to death, loss\nto follow-up, and refusal. Together, these factors add up to\na substantial turnover in those who were self-interviewed from\none waveto the next. Of all the 19,069self-interviews at Waves1,\nsecond wave of any 2-wave pair--the ``dropouts.'' Contrariwise,\ndid not provide a self-interview in the first wave of any two-wave\npair--the ``recruits.'' The dropouts and recruits, moreover, are\nunlike those who provided self-interviews at two waves of any\ntwo-wave pair--the ``stay-ins.'' The dropouts are approximately\n3 years older on average than the stay-ins, whereas the recruits are\nan average of more than 6 years younger than the stay-ins, in large\npart reflecting the addition of new, younger birth cohorts at Wave\n3. Stay-ins are more likely to be female than either recruits or\ndropouts. Stay-ins also have a higher average income and net\nworth than either recruits or dropouts. Minority groups (Blacks\nand those interviewed in Spanish) comprise a larger proportion of\nthe dropouts than of the stay-ins, Blacks comprise a smaller\nproportion of the recruits, and those interviewed in Spanish and\nof non-Black or non-White ethnicity comprise a larger proportion\nof the recruits.\nEach of the conditions that result in missing cognitive scores\n(mortality, inability to participate, moving into a nursing home,\nand unwillingness to participate) may be related to cognitive\nstatus. If the prevalence of each of these conditions were\nconstant across waves, then they could be ignored because they\nwould have no impact on changes in the average observed\nscores between waves. There is evidence, though, that mortality\nrates among those over the age of 70 have declined in the U.S.\npopulation, and that the proportion of interviews done by proxy\ninformants has increased across the four waves of this study,\nTo quantitatively assess the success with which Model 3 takes\naccount of the probability of providing cognitive scores (or,\ncontrariwise, of not doing a self-interview), we estimated Heck-\nman (1976) selection models. This procedure simultaneously\nmodels level on a dependent variable and the probability that\nthe level on the dependent variable is missing, and it obtains\nmaximum likelihood estimates of the prediction model by taking\nthe selection model into account. The Heckman procedure was\nimplemented by using Stata (StataCorp, 2001) to predict the\ntotal cognitive score, using the design-driven and respondent\ncharacteristics included in Model 3, and using the following,\npartially overlapping set of variables to predict participation at\neach wave: age, gender, race (Black, White, or other), language in\nwhich interview was conducted (English or Spanish), logarithm\nof total household income and of total net worth, whether the\nrespondent reported having had a stroke, and marital status\n(married, living with a partner, or other).\nAs shown in Table 4, the coefficients for the regression\nmodel, and in particular those for the wave indicator variables,\nare quite similar whether or not selection is taken into account.\nDISCUSSION\nIn this article we investigated potential trends in cognitive\nfunctioning across consecutive cohorts of Americans aged 70\nwaves of the AHEAD and HRS studies. These are powerful\nstudies because they collect cognitive performance measures on\nlarge representative samples of America's old population. At the\nsame time, these studies use a complex, multipurpose design that\nposes considerable challenges to the investigation of cohort\ndifferences in cognitive functioning, including a panel design\nwith slightly different definitions of the sample at each wave,\nacross-wave modifications in the measurement of cognitive\nfunctioning, a mixed mode of telephone and face-to-face in-\nterviews, and various forms and levels of attrition across waves.\nOur major finding is that there is little improvement of\ncognitive functioning across the most recent cohorts of\nAmericans aged 70 years old and older. However, we did not\nreach this conclusion until we had performed a number of\nstatistical adjustments for the nature of the cognitive measure-\nment and for the changing composition of the cohort samples.\nSpecifically, we removed one particular item from the cognitive\nbattery about naming the Vice President because the item ap-\npeared very dependent on the specific political context at each\nwave and thus was not a good indicator of individual cognitive\nfunctioning. Using regression analysis, we then adjusted the so-\nmodified cognitive performance scores for differences between\nthe cohorts that purely reflected features of the HRS\u00adAHEAD\ndesign and that might artifactually produce cohort differ-\nences--repeated exposure to the cognitive measures neces-\nsitated by a panel design and the changing age composition\ncaused by the sample replenishment in some, but not all waves.\nThe adjustments drastically reduced the apparent increase in\nunadjusted scores of cognitive performance across waves, in\nmost cases leaving only nonsignificant differences. In other\nwords, the difference between the first and later waves was\nlargely a function of the fact that respondents faced the\ncognitive tests for the first time in 1993 but most of them were\nfamiliar with the tests in later waves. We then additionally\nadjusted the modified cognitive scores by the sociodemo-\ngraphic characteristics of gender, race, and ethnicity. These\ncharacteristics varied across AHEAD and HRS waves and are\nknown to relate to cognitive functioning; thus they could\nartifactually produce cohort differences in cognition. Control-\nling on these characterisitcs did not change the statistical\nsignificance of differences between waves from the pattern\nobserved after controlling only on the design-driven covariates.\nOur final adjustment was for the respondent's level of edu-\ncational attainment, which also did not change the significance\nof any between-wave differences.\nWe also addressed potential effects of attrition that varied\nsomewhat across waves and of the mixed-mode design. Using\nthe Heckman procedure, we tested the potential biasing effect\nof attrition and found little or none. On the potential con-\nfounding by mode, we argued for not adjusting for it, because\nthe assignment of mode is entirely confounded with respondent\ncharacteristics, and including in the regression a mode effect\nin addition to the respondent characteristics would lead to a\nmisspecified equation.\nOur results differ from the results by Freedman and\ndecline in cognitive impairment between the cohorts captured\nTable 4. Estimate Model 3 for Total Cognitive Score, With\nand Without Taking Account of Selection Effects\nUnadj. for Selection Heckman Selection Model\nWave 2 vs. Wave 3 ** *\nWave 3 vs. Wave 4 * *\nNotes: Standard errors, which do not take the complex sample design into\naccount, are shown in parentheses. The statistical significance of coefficients\ndo not take into account either the complex sample design or the overlap in\ncases between waves. The statistical significance of coefficients (noted next to\neach coefficient) and of the difference in coefficients between adjacent waves\n(noted in rows inserted between adjacent waves) takes into account both the\ncomplex sample design and the overlap in cases between waves.\nthe differences in findings can be attributed to a number\nof differences between their studies and our studies. First,\nFreedman used only the first and the third AHEAD waves.\nAccording to our analyses, the first wave was somewhat\natypical, particularly when no adjustments for previous\nexposure to the cognitive tests were made. The other three\nwaves were more similar. Second, Freedman did not adjust for\nprevious exposure. Our analyses (and the literature) demon-\nstrate that previous exposure improves performance scores on\ncognitive tests and that this factor was particularly critical in\nexplaining differences between the first wave, when respon-\ndents saw the cognitive measures for the first time, and later\nwaves, when most respondents had seen the cognitive tests\nbefore. Third, we modified the total cognitive score to remove\na ``misbehaving'' item, whereas Freedman did not. Fourth,\nFreedman combined cognition data from self-respondents and\nproxy respondents and developed a cut-point to dichotomize\nrespondents into those with and without severe cognitive impair-\nment. In our analysis we focused only on self-respondents and\nused both continuous measures for the total and component\nscores, as well as a cut-point for the total cognition score that\ncaptures both moderate and severe cognitive impairment.\nOther aspects of the analyses by Freedman and her\ncolleagues were similar in objectives to ours but utilized\ndifferent methodologies to address the objectives. For example,\nFreedman and colleagues were equally concerned as we were\nabout the missing answers to some of the cognitive tests, but\nwhere they established in a sensitivity-type analysis the range\nof effects with different assumptions about the nature of the\nmissing answers, we imputed the missing answers by reference\nto other nonmissing answers. (We also did a type of sensitivity\nanalysis: we redid all of the models shown in Tables 2 and 3\nby using only cases that had no missing data on any of the\ncognitive items. The coefficients were all either not statistically\nsignificant or, if significant, indicated decline rather than\nimprovement in cognitive status across the four waves.)\nSimilarly, both sets of authors were concerned about non-\nrespondents to the entire interview. The analysis by Freedman\nand associates again used a sensitivity analysis to test the\ninfluence of different assumptions about the nature of those not\navailable for an interview. We instead estimated a Heckman-\ntype of selection model to evaluate the effect of interview\nnonresponse. Neither their analysis nor our analysis of item and\ninterview nonresponse changed the respective main findings;\nFreedman and her colleagues continue to find cohort differ-\nences, and we continue not to find them.\nOur analyses have their own limitations. First, our observation\nperiod is relatively short. We compare cohorts of 70- year-old and\nolder Americans at four time points spanning a 7-year period. The\nsocietal changes mentioned at the beginning of this article may\nrequire a longer time period to exert their effect on cognitive\nfunctioning. Second, and in a related fashion, the cohorts are\nbroadly defined in our investigation and as a consequence overlap\nencompasses still mostly the same birth years as the 1930\u00fecohort\nin 2000. This fact makes the finding of pronounced cohort\ndifferences between them quite unlikely. Third, in our in-\nvestigation cohort effects cannot be separated from time effects\nbecause we do not track cohorts younger than 70 years of age.\nTherefore, it is possible that the lack of cognitive improvement\nobserved for old Americans is in fact true for the entire population\nof cognitive tests--although more detailed than is typical for\na representative population survey--is limited in its dimension-\nality and reliability compared with the extensive batteries used by\nmainstream cognitive psychologists. This is a limitation inherent\nin many large, multipurpose studies and is best addressed\nby coordinating smaller intensive studies with larger, less inten-\nsive ones, thereby allowing the strengths of both types to be\ncombined. We believe that, with these qualifications in mind, our\narticle provides a piece of the answer to the exceedingly\nimportant question about whether cognitive performance has\nimproved across recent cohorts of older Americans.\n"
}