{
    "abstract": "The Gerontologist \u00a9 The Author 2010. Published by Oxford University Press on behalf of The Gerontological Society of America.",
    "reduced_content": "\u00a9 The Author 2010. Published by Oxford University Press on behalf of The Gerontological Society of America.\nVol. 51, No. 3, 354\u00ad366 All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.\nPurpose: This study tested key psychometric prop-\nerties of the Older Adult Psychological Abuse Mea-\nsure (OAPAM), one self-report scale of the Older\nAdult Mistreatment Assessment (OAMA). Design\nand Methods: Items and theory were developed\nin a prior concept mapping study. Subsequently, the\nmeasures were administered to 226 substantiated\nclients by 22 elder abuse staff from 7 agencies in a\nfull-scale field test. The resulting database was used\nto estimate the psychometric properties of the\nOAPAM using the Rasch item response theory model\nand traditional validation techniques. Analyses\nincluded tests for dimensionality, model fit, and theo-\nretical construct validation. Results from the OAPAM\nclient report were validated against the adult protec-\ntive services substantiation decision of abuse and the\nelder abuse staff assessment of psychological abuse\n(PA). Results: The client self-report measures met\nstringent Rasch analysis fit and unidimensionality cri-\nteria and had high person (internal consistency) and\nitem reliability. The validity results supported the use-\nfulness of the client measures and led to reconsidera-\ntion of aspects of the hypothesized theoretical\nhierarchy. A short form was developed. Cut-points\nwere proposed to distinguish levels of PA. Impli-\ncations: The measure is now available to aid in\nthe assessment of PA of older adults by both clini-\ncians and researchers. Theoretical refinements devel-\noped using the Rasch item hierarchy may help to\nimprove assessment and intervention.\nKey Words: Emotional abuse, Psychological abuse,\nElder mistreatment, Rasch measurement, Abuse\ntheory\nThe purpose of this study was to develop and\ntest a self-report measure of psychological abuse\n(PA) of older adults. The National Center on Elder\nAbuse (NCEA) defines emotional or PA as the\ninfliction of anguish, pain, or distress through ver-\nbal or nonverbal acts (NCEA, 2003). Emotional/\nPA (terms used synonymously) includes, but is not\nlimited to, verbal assaults, insults, threats, intimi-\ndation, humiliation, and harassment. In addition,\ntreating an older person like an infant; isolating an\nolder person from his or her family, friends, or\nregular activities; and giving an older person the\n\"silent treatment\" and enforced social isolation\nare examples of emotional/PA (NCEA, 2003).\nSuch treatment would typically occur in private\nand be difficult for third parties to detect.\nA range of instruments that assess elder abuse have\nbeendevelopedoverthepast20years(Bass,Anetzberger,\nEjaz, & Nagpaul, 2001; Canadian Task Force on\nthe Periodic Health Examination, 1994; Dyer &\nAbraham, & Fairchild, 2000; Mount Sinai/Victim\nServices Agency Elder Abuse Project, 1988; Reis &\nNahmiash, 1998). Most have considered multiple abuse\nforms, sometimes including PA, but without specific\nSelf-report Measure of Psychological Abuse of\nOlder Adults\nKendon J. Conrad, PhD,*,1 Madelyn Iris, PhD,2 John W. Ridings, PhD,3\nKate Langley, MPH,1 and Georgia J. Anetzberger, PhD, ACSW4\n1School of Public Health, Department of Health Policy and Administration, University of Illinois at Chicago.\n2Leonard Schanfield Research Institute, CJE SeniorLife, Chicago, Illinois.\n3Metropolitan Family Services, Department of Outcomes and Evaluation, Chicago, Illinois.\n4Department of Management and Labor Relations, Cleveland State University, Ohio.\n*Address correspondence to Kendon J. Conrad, PhD, School of Public Health, University of Illinois at Chicago, 1603 West Taylor Street, Chicago IL\nDecision Editor: William J. McAuley, PhD\nfocus on conceptualizing and assessing PA. Further-\nmore, most screening instruments rely on clinician\nassessments rather than self-report by older adults\n(Marshall,Benton,&Brazier, 2000) and are designed\nto evaluate quality of caregiving (e.g., Bravo,\nGirouard, Gosselin, Archambualt, & Dubois, 1995),\nidentify abusive caregivers of older adults (Reis &\nNahmiash, 1995), or help health professionals to\ndetect problems (Fulmer et al., 1999; Reis &\nof a recently developed patient self-report is\nthe Elder Abuse Suspicion Index (Yaffe, Wolfson,\nLithwick, & Weiss, 2008), a six-item physician to\npatient interview that includes a PA item.\nIn a systematic review of 49 studies of elder\nabuse (Cooper, Selwood, & Livingston, 2008),\n6% of older adults reported significant abuse in\nthe previous month and 5.6% of couples reported\nphysical violence in their relationship in the previ-\nous year. These authors reported that nearly a\nquarter of the older adults reported significant lev-\nels of PA. Sixteen percent of nursing home staff\nadmitted to significant PA of residents, and a third\nof family caregivers reported being involved in sig-\nnificant abuse. However, only a small proportion\nof this abuse was known to protective services.\nOne in six professional caregivers reported com-\nmitting abusive acts but over four fifths reported\nobserving them. Unfortunately, only seven of the\nstudies that were reviewed used measures for\nwhich any type of reliability and validity had been\nassessed (Cooper et al., 2008). Cooper and col-\nleague concluded that valid reliable measures and\nconsensus on what constitutes an adequate stan-\ndard for validity of abuse measures are needed.\nThe small amount of literature published exclu-\nsively on PA of older adults is understandable, given\nthe difficulty in developing a precise definition that\nwould lead to valid and reliable measures. Addition-\nally, any definition of PA may reflect a cultural per-\nspective (Anetzberger, Korbin, & Tomita, 1996;\nMoon, Tomita, & Jung-Kamei, 2001). Furthermore,\nsome believe that the meaning of PA is best repre-\nsented not through any illustrative act but rather\nthrough the perceived effect of the act on the victim,\nwhich then allows for consideration of cultural vari-\nation in definition (e.g., Nerenberg, 2008) and rein-\nforces the importance of obtaining client self-reports.\nPrevalence\nEven though PA is believed to be underreported\nthe percentages of occurrence reported in extant\nstudies indicate the pervasiveness of the problem.\nPillemer and Finkelhor (1988) conducted one of\nthe few random sample studies of elder abuse, sur-\nveying 2020 community-dwelling elderly in the\nBoston area. Overall, they found a rate of abuse of\n3.2%. However, they limited their questions\nregarding PA to verbal aggression only, for which\nthey established a rate of 1.1%. Most recently,\nAcierno and colleagues (2010) conducted a\nnational prevalence study, and based on a sample\nfound a one-year prevalence rate of 4.6% for emo-\ntional abuse, the highest rate for any type of abuse\nqueried. Even higher prevalence rates were found\nby Beach, Schulz, Castle, and Rosen (2010), in\ntheir investigation of financial exploitation\nand psychological mistreatment among African\nAmericans and non-African Americans, in Allegheny\nCounty, PA. They reported significantly higher\nprevalence rates for PA of African American elders\nas compared with non-African Americans: 24.4%\nIn samples of abused older adults, Brownell,\nBerman, and Salmone (1999) found that among\nPA; a similar study by Anetzberger (1998) revealed\nthat 41% of incidents of abuse of older adults were\npsychological. Anetzberger also found that in cases\nwhere there was PA, additional forms of abuse\nwere present 89.7% of the time, including physical\nneglect and financial exploitation. Similarly, the\nNational Elder Abuse Incidence Study (National\nlence rate; Lithwick, Beaulieu, Gravel, and Straka\nPatterson (1999) and Godkin, Wolf, and Pillemer\n72%, respectively), though both studies had small\nsamples. These mixed findings illustrate the diffi-\nculties in establishing a consistent prevalence rate\nfor PA. Differences in the definition and measure-\nment of PA used by each study above may account\nfor some discrepancies and variability.\nConceptual Models\nThe limited research on most forms of elder\nabuse, including PA, has lacked an overall concep-\ntual framework to guide data collection efforts\nand provide effective assessment of the risk factors\nfor and the consequences of different types of\nabuse. Godkin and colleagues (1989) developed\n \nfive conceptual components of abusive relation-\nships. Anetzberger (2000) developed the Explor-\natory Model for Elder Abuse that examined\ncharacteristics of the perpetrator as the primary\nconsideration, and secondarily, characteristics of\nthe victim and the context in a temporal arrange-\nment. The National Research Council's (2003)\nseminal book on elder abuse presents a structure,\nprocess, and outcome model that includes the\nsociocultural context and the transactional pro-\ncesses among the parties leading to abuse.\nThese models have several commonalities; pri-\nmary among them is that they recognize the impor-\ntance of including the perpetrator and his or her\ncharacteristics as well as the social network.\nAlthough the models are able to explain the etiol-\nogy of general abuse, they do not present examples\nof items that represent PA nor do they indicate\nwhich components are most important to elder\nabuse or which are most severe. Understanding\nthese issues is essential to obtaining accurate\nassessments of types and levels of abuse.\nPrior Study: Item Development\nIn the precursor of the present study (Conrad,\nIris, Ridings, Fairman, & Rosen, in press), three-\ndimensional concept mapping (Trochim, 1989)\nwas used to conceptualize PA of older adults.\nStatements were generated from literature review\nand by local and national panels consisting of 16\nexperts in the field of PA. These statements were\nsorted and rated on a 1\u00ad5 scale for severity, using\nConcept Systems software, which grouped the\nstatements into clusters and depicted them as a\nmap. The clusters represent the distinct conceptual\nareas of the overall domain of PA. Based on aver-\nage ratings for all statements in a particular clus-\nter, the clusters were then ranked in order of\nseverity. These concepts in descending order of\nseverity were (1) isolation, (2) insensitivity and dis-\nrespect, (3) shaming and blaming, (4) threats and\nintimidation, and (5) trusted other risk factors.\nThis hierarchy formed the basis for a measurement\nmodel of the construct of PA of older adults.\nThe statements developed for the concept map\nwere subsequently framed as questions, and ques-\ntionnaires were developed for both third party\nobservation and client self-report. Third party\nobservation included completion of the question-\nnaire by an elder abuse investigator, based on his\nor her understanding of the client's report, his or\nher observations while conducting the investiga-\ntion, and any information obtained from others,\nincluding the alleged abuser. Nine focus groups\nwere convened to review the wording of items and\nthe formats of the questionnaires. Six focus groups\nwere conducted with 44 staff members from elder\nabuse investigation/treatment provider agencies.\nThree groups comprised 20 consumers. The par-\nticipants in the staff focus groups consisted of\neither naturally formed work groups (such as a\nteam of elder abuse staff) or were participants in\nour earlier study. Groups of clients were formed\nbased on having been served by the same agency.\nThe meetings were held at several local, nonprofit,\nagency, and business locations. The focus group\nprocess consisted of a review of the PA items that\nwere compiled. Participants were asked to read\neach item and evaluate its relevance to PA, its\nwording, and its clarity. They were also asked to\nreview the ordering and formatting of the ques-\ntions and to suggest additional items. The final\nitems are provided in Table A1.\nCognitive interviews were conducted with four\nclients who were substantiated as having experi-\nenced elder abuse and who had not participated in\nthe focus groups. Details of these focus groups and\nother qualitative work may be reviewed in the\nNational Institute of Justice Report from this study\n(Conrad, Iris, & Ridings, 2009), which resulted in\nthe Older Adult Psychological Abuse Measure\n(OAPAM), the client self-report measure. The\nOAPAM is one scale of the Older Adult Mistreat-\nment Assessment (OAMA), which is now being\ndeveloped as a comprehensive elder abuse assess-\nment procedure (Conrad, Iris, Riley, Mensah, &\nMazza, 2009). The OAMA, in its current form,\nconsists of third party observations and client self-\nreport measures of financial exploitation and PA.\nIn addition to demographics, it has draft versions\nof physical, sexual, and neglect assessments,\nincluding short screeners of all of the above types\nof abuse and descriptive information about alleged\nabusers.\nObjectives\nThe specific objectives of the present full-scale\nfield test of the OAPAM were:\n1. To test the construct dimensionality of the\nOAPAM, that is, Did the items form a single\noverarching PA construct?\n2. To test the fit of the items to the Rasch mea-\nsurement model, that is, rating scale model;\n3. To assess internal consistency reliability;\n4. To develop short forms that would be user-\nfriendly for clinical applications;\n5. To examine appropriateness for the target\npopulation;\n6. To test construct validity by positing a theo-\nretical hierarchy of concept rankings that con-\nforms to expectations developed in a prior\nresearch phase and by testing a set of hypoth-\nesized relationships using correlation analysis;\n7. Propose a reasonable, although speculative\ngiven lack of external validation, cutoff to\ndetermine PA.\nDesign and Methods\nSample\nData collection was supported by a research\nagreement with the Illinois Department on Aging\n(IDOA), which advocated the recruitment of the\nelder abuse providers and clients for the project.\nWith IDOA's support, recruitment was from seven\nadult protective services agencies in Chicago and\nits collar counties. Two samples were established:\nfirst, 22 highly experienced elder abuse staff mem-\nbers were recruited from these agencies. Because\ninterviewing clients with a standardized question-\nnaire was not previously done as part of their\nscreening procedures, the elder abuse staff mem-\nbers were trained in interviewing for this study by\nthe two lead authors. The staff members also com-\npleted the human subjects subcommittee online\ntraining program of the University of Illinois at\nChicago (UIC). The human subjects research pro-\nposal and informed consent forms were approved\nby the UIC institutional review board via the\nhuman subjects subcommittee. All 22 participat-\ning elder abuse staff members were volunteers and\ngave informed consent. Second, the elder abuse\nstaff recruited and screened clients for ability to\nconsent to research participation and for their\nability to serve as reliable reporters of abuse. A key\ncomponent of the interview was the assessment of\ncognitive status using the Mini-Mental State Exam-\nination (MMSE; Folstein, Folstein, & McHugh,\n1975). To participate in the study, the client had to\nscore at least 17 on the MMSE or in the judgment\nof the elder abuse investigator demonstrate ade-\nquate cognitive capacity to provide self-report. The\nelder abuse staff was responsible for obtaining\nclients' consent. In all, 226 clients consented and\ncompleted the OAPAM.\nThe 22 elder abuse staff members administered\nclient self-report measures of PA via interview in\nthe home to the 226 clients who were substanti-\nated for at least one type of elder mistreatment and\nspoke English. They also completed a staff obser-\nvation questionnaire for each of these clients.\nRecruitment was limited to only substantiated cli-\nents to be sure that the population was appropri-\nate for the measures. However, they did not have\nto be substantiated for PA. This meant that there\nwould likely be a substantial group in the \"floor\"\nto be sure there was representation of a full range\nof the construct and power for a yes/no cut-point.\nBackground Characteristics of the Elder Abuse\nStaff and Clients\nThe sample of 22 elder abuse staff was predom-\ninantly female (86.36%). More than half was Cau-\ncasian (59.09%), a quarter was African American\n(27.27%), and the remainder Hispanic or mixed\nrace. The elder abuse staff's average years of on-\nthe-job experience was 5.46 years.\nThe sample of 226 clients was also predomi-\nnantly female (70.4%). The majority of clients\nwere African American (61.3%), more than one\nthird were Caucasian (35.5%), and the remainder\nwere of mixed race or other. Most were non-\nHispanic (92.9%). The majority of clients were\nStatistical Analysis\nTraditional test theory counts the number of\nitems endorsed and uses that as an estimate of the\nperson's level on the construct of interest. The\nRasch measurement model (Rasch, 1960) was cho-\nsen because of its desirable scaling properties of\nlinear interval measurement (Embretson & Reise,\n2000). It places both persons and items on the\nsame ruler. This is useful in judging which items\npersons are likely to endorse, which is helpful in\nsetting cutoff scores. The model provides an item\nhierarchy (seen in Figure 1) that is useful to sup-\nport theory building and test construct validity.\nTherefore, the Rasch model was needed to test the\ntheoretical hierarchy developed in prior work.\nThis is a type of construct validation. The Rasch\nmodel was also useful in testing unidimensionality,\nexamining usefulness of the rating scale, and test-\ning the fit of items to the model. These are also\naspects of construct validation that can be facili-\ntated with the Rasch model.\n \nThe Rasch rating scale model (Wright &\nMasters, 1982) estimates the probability that a\nrespondent will choose a particular response\ncategory for an item as:\n-\n= - -\nln ,\nnij\nn i j\nni j\nP\nP\nwhere Pnij\nis the probability of respondent\nn scoring in category j of item i, Pni\n(j - 1) is the\nprobability of respondent n scoring in category j - 1\nof item i, Bn\nis the person measure of respondent n,\nDi\nis the difficulty of item I, and Fj\nis the difficulty\nof category step j. Rating scale categories are\nordered steps on the measurement scale. Complet-\ning the jth step can be thought of as choosing the jth\nalternative over the (j - 1)th in the response to the\nitem.\nRasch analysis places persons (Bn\n) and items\n(Di\n) on the same measurement scale (illustrated in\nFigure 1) where the unit of measurement is the\nlogit (log odds unit). Person reliability in Rasch is\nanalogous to Cronbach's alpha in traditional test-\ning. It gives an idea of how stably persons are\nplaced on the scale. Because Rasch places both\npersons and items on the same scale, reliability can\nbe estimated for items as well as for persons. The\nWinsteps Computer Program was used for these\nDimensionality.--Because the Rasch model\nrequires unidimensionality, principal component\nanalysis of residuals was used to examine whether\na substantial factor existed in the residuals after\nthe primary measurement dimension had been esti-\nAlthough there are no hard rules for interpreting\nprincipal components results, our rule of thumb\nfor unidimensionality was variance explained of\n>40% by the measurement dimension (Linacre,\nto define a substantial factor. To be conservative in\ntesting a second dimension, <15% (even lower\nthan Reckase) was set as the criterion for variance\nexplained by the first principal component of the\nresiduals, that is, the second dimension. Simply\nput, using 40% and 15% variance as the criteria\nfor the first and second dimensions is a rigorous\ntest in that the measurement dimension must be\nlarge at 40%, whereas the second dimension must\nbe quite small at under 15%. Dimensionality was\nalso tested using Linacre's (1998b) procedure.\nTwo subsets of items were extracted representing\nthe opposite poles of the factor. Each subject was\nthen measured on each subset of items. The subject\nmeasures were cross-plotted and correlation coef-\nficients were obtained. Additional criteria for uni-\ndimensionality were employed using item fit\nstatistics discussed next.\nQuality Control With Fit Statistics.--Rasch\nanalysis provides fit statistics to test assumptions\nof fundamental measurement (Wright & Stone,\n1979). Understanding item misfit can lead to\nimproving or dropping items. The following link\nprovides a handy guide to interpreting fit statistics:\nhttp://www.rasch.org/rmt/rmt82a.htm. The Rasch\nmodel provides two indicators of misfit: infit and\noutfit. For this analysis, items with values less than\n1.33 mean square (MNSQ) on both infit and outfit\nwere considered acceptable quality (R. M. Smith,\nRating Scale.--The proper functioning of the\nrating scale was examined using: (1) outfit MNSQs\nless than 2.0, (2) average measures advance mono-\ntonically with each category, and (3) step calibra-\nZhu, Updike, & Lewandowski, 1997). Based on\nour focus group work, a \"suspected\" category was\nincluded as intermediate between \"yes\" and \"no,\"\nwhere no = 0, suspected = 1, and yes = 2. Given our\nprior experience, it was predicted that this would\nbe a little used category that would not conform to\nthe Rasch model, but it was included to be respon-\nsive to clinical input that said it was needed for\ngreater sensitivity in our measures.\nFor a complete treatment of Rasch analysis, see\nBond and Fox (2007), which includes a glossary of\nRasch measurement terminology. Terminology\nmay also be accessed online via Rasch Measure-\nment Transactions located at http://www.rasch.\norg/rmt/. The tables below were developed from\nexplanations and interpretations.\nConstruct Validation.--In Rasch analysis, the\nitem hierarchy that is created by the item difficulty\nestimates provides an indication of construct valid-\nity (E. V. Smith, 2001). The items should form a\nladder with low-severity symptoms on the bottom\nto high-severity symptoms on the top. In prior\nwork (Conrad et al., in press ), 16 experts grouped\nthe items into six groups and rated the severity of\nthe items on a scale from 1 to 5. These item severi-\nties were then averaged within each group. The\nresult was a theoretical hierarchy of five concep-\ntual components of PA arranged in descending\nseverity (Table 1) as follows (mean expert ranking\nfrom 1 to 5 in parentheses): isolation (1), threats\nand intimidation (2), insensitivity and disrespect\n(3), shaming and blaming (4), and trusted other\nrisk factors (5). To test whether this hierarchy was\nvalidated by the client respondents in this study,\nthe Rasch calibration on each item was obtained,\nand these were subsequently averaged within each\nitem grouping to see if the hierarchy would remain\nthe same, that is, \"client groups\" rankings were\ncompared with the rankings of the \"expert groups.\"\nMultitrait Multimethod Analysis.--Construct\nvalidation also may be tested by setting up a pat-\ntern of theoretical expectations and testing whether\nthose expectations are supported by the data\n(Campbell & Fiske, 1959). As Campbell and Fiske\npointed out, measures of the same construct should\nbe highly correlated and especially so if they use\nthe same method.\nThe IDOA questionnaire, which is required by\nIDOA for elder abuse investigations, covers many\nforms of elder abuse, including PA. The IDOA\nform also asks staff members to give a closing sta-\ntus on the case, identifying which types of abuse\nare substantiated. This closing status substantia-\ntion decision on PA was used to correlate with\nthe OAPAM. The OAPAM was also correlated\nwith OAMA staff data from the 22 elder abuse\nstaff who reported their PA observations on the\n226 substantiated clients. The OAPAM involved\nthese 226 clients providing self-reports on an\ninterview questionnaire. These are described as\nfollows:\n1. Client Gender: coded male = 0, female = 1\n2. Psychological Abuse Substantiation Decision\nof Illinois Department on Aging: PA was con-\nsidered substantiated if it was marked as \"ver-\nified\" or \"some indication.\"\n3. OAMA Staff Psychological Abuse Measure:\nThe Rasch person reliability was high at .87\nwhich corresponded with the Cronbach's\nalpha of .92. The Rasch item reliability was\nvery high at .96. The final 53 items of staff-\nreported PA met stringent Rasch analysis fit\nand unidimensionality criteria.\n4. OAMA OAPAM: Details are described in the\nResults section.\nThe direction and strength of construct pairs\ndepends on method and theoretical expectations. A\npattern of expected correlations roughly corre-\nsetup as follows: NS = nonsignificant, >.1 = low, >.3 =\nmoderate, and >.5 = high. Others have suggested\nlower values based on reviews of research, for\nexample, >.2 = moderate and >.3 = high (Hemphill,\n2003), so there are no absolute guidelines available.\nThis hypothesized pattern, and resulting correla-\ntions are in the upper right half of Table 2. The diago-\nnalentriesarethepersonreliabilities.Thehypothesized\ncorrelations are stated above each correlation coeffi-\ncient in the table and are bulleted subsequently:\n1. Client Gender: There was no reason to expect\ndifferential exploitation by gender so all gen-\nder correlations were expected to be NS.\n2. Psychological Abuse Substantiation Decision:\n\u00b7\n\u00b7 Moderate correlation with OAMA client\nPA\n\u00b7\n\u00b7 High correlation with OAMA staff PA\n3. OAMA Staff Psychological Abuse:\n\u00b7\n\u00b7 High correlation with OAMA client PA\nIn the multitrait multimethod analyses, the most\ncomplete versions of all OAMA measures were\nused.\nShort Form.--For the OAPAM to be most useful\nin both research and clinical settings, a short form\nwould be required. In developing the short form,\nall 31 items were viewed as valid, and our princi-\npal inclusion criterion was representation of the\nitems across the full range of item calibrations. To\ndelete items, more stringent fit criteria were\napplied, that is, either (rather than both) infit or\noutfit greater than 1.33 would qualify the item for\npossible deletion. However, some items with high\noutfit (less of a concern than infit) were still\nincluded if they were needed to cover the full range\nor to prevent gaps along the ruler.\nResults\nIn this section each objective is restated in a\nheader with the accompanying findings.\nTest the Fit of the Items and Rating Scale\nNo items were dropped because they all met our\ncriteria for fit. Specifically, both infit and outfit\nwere less than 1.33 on all items. The rating scale\n \nperformed as expected with the \"unsure\" category\nbeing least used.\nTest Construct Dimensionality\nThe raw variance explained by the measure was\ncriterion, and was supportive of a strong principal\nmeasurement dimension. The unexplained or\nresidual variance that was explained by the first\ncontrast was a small 10.5%. This, along with the\nwell-fitting items, suggested that there was not a\nsubstantial rival dimension. This was supportive\nof unidimensionality. The correlation of the first\nand second factors using Linacre's (1998b) proce-\ndure was .729. This was also supportive of unidi-\nmensionality.\nIn Figure 1, the annotated Rasch ruler, known\nas a Wright map, is displayed. Persons are arrayed\non the left of the dashed line and items on the right\n(item numbers with item abbreviations are used on\nthe Wright map and in the text). The items form a\nhierarchy of severity with lower severity items at\nthe bottom and higher severity items at the top.\nThe persons are also displayed according to their\nmeasure on the PA scale. There is a substantial\nfloor of persons at the bottom who are not regis-\ntering any client-reported PA. The concept that\neach item belongs to is indicated in brackets at\nthe end of the item label, that is, ISO = Isolation,\nT&I = Threats and Intimidation, I&D = Insensitivity\nand Disrespect, and S&B = Shaming and Blaming.\nOnly the ISO concept had a coherent cluster of\nitems which was located at the high-severity end of\nFigure 1. Wright Map of persons and items on the Rasch ruler of client-reported psychological abuse (item number's keyed to\nthe hierarchy. The other concepts were composed\nof items that were not located together at the same\nseverity level but were spread throughout the rest of\nthe severity hierarchy. The two items, Uncomforta-\nbleW/AA and AfraidOfAA, which had formed the\nRisk Factor cluster, were regrouped with the T&I\ncluster because of their unexpectedly high severity.\nAssess Internal Consistency Reliability Using a\nThe Rasch person reliability was very high\nat .86 which corresponds with the Cronbach's\nalpha of .92. The Rasch item reliability was also very\nhigh at .97. The final 31 items of the OAPAM met\nstringent Rasch analysis fit and unidimensionality\ncriteria. The measure as a whole had high person\nand item reliability.\nDevelop Short Forms That Would Be User-friendly\nfor Clinical Applications\nTo test if a more parsimonious model would\nalso function well, a shorter form was developed\ncontaining 18 items. Table A1 contains the items\nby form and factor information. Although the\nshort form is most useful, the longer form provides\na bank of items that may be used in future devel-\nopment of alternative forms or computerized\nadaptive tests.\nThe final 18 items of client-reported PA met\nstringent Rasch analysis fit and unidimensionality\ncriteria and maintained the measurement range of\nthe 31-item ruler. The Rasch person reliability for\nthe 18-item form was still reasonably high at .78\nwhich corresponded with the Cronbach's alpha of\n.87. The Rasch item reliability was very high at .96.\nExamine the Appropriateness of the Measure for\nthe Target Population\nAlthough the persons in the floor were included\non the Wright map (Figure 1), they were not\nincluded in the calculation of the person mean\n(-0.59). This was reasonably well targeted because\nthe person mean was within 1.0 logit and within\nTest Construct Validity With a Hierarchy of\nConcept Rankings and Hypothesized Relationships\nLooking at Table 1, \"Original Concept Group,\"\nthe ordering of the conceptual components of PA\nwas the same for both experts, averaging their\nconcept map ratings, and clients, averaging their\nRasch measurement calibrations. This was sup-\nportive of the construct validity of the measure.\nThe item-by-item details of the expert concepts\nand rankings as well as the client item calibrations\nare located in the Table A1.\nMultitrait Multimethod Analysis of Hypothesized\nRelationships\nIt was hypothesized that all gender correlations\nwould be non-significant and the three correla-\ntions were (Table 2). The other three correlations,\ntwo high and one moderate, were as hypothesized.\nThis was supportive of the criterion validity of the\nIdentify an Appropriate Cutoff to Determine PA\nBecause there is no solely empirical way to\ndetermine a cut-point, for example, using the\nWright map (Figure 1), the logic of the cut-point\ndecision is described in the Discussion.\nDiscussion\nA measure consisting of 31 items was validated as\na unidimensional measure of client-reported PA.\nSubsequently, a shorter form consisting of 18 items\nwas developed. It is notable that only 97 clients\n(43%) in the sample had some indication of PA\nusing IDOA criteria, but this IDOA designation\nlacked specifics about how the decision was arrived\nat or what it means. However, in Figure 1, the\nendorsed at least one symptom of abuse. The per-\nsons are represented by the pound signs (three per-\nsons) and dots (one person) to the left of the\nvertical dashed line. Three persons endorsed all of\nthe symptoms, that is, in the \"ceiling,\" with a defi-\nnite \"yes.\" Thirty-seven persons were in the floor,\nthat is, endorsing 0 symptoms. Above -1.0 on the\nruler, the item meanings, that is, severity of the\nsymptoms going up the scale, and locations indicate\nthat this may be a useful cutoff score for PA. Above\nwere likely to endorse symptoms, such as 23Manip-\nulated, 19SworeOrYelled, 16HurtEsFeelings, and\n8UncomfortableW/AA. These persons scored 12\nor more of a possible 62 raw score. If 0 on the ruler\nis used as the higher criterion for more serious PA,\nthere were 52 persons (24%) above this level\nhaving even more severe symptomatology, such\nas 22MadeFeelSmall, 25TalkedAsIfNotThere,\n \n31MadeAshamed, and 28DelibConfused. Above\n1.0 on the ruler (16 persons, 7%) could be classi-\nfied as extreme PA because the four items above\n24ManipW/drugs, and 11PreventContactOutsd,\nall involve serious psychological isolation, depri-\nvation, and manipulation that border on or may\ninclude physical abuse and/or neglect. Such abuse\nmay have serious, for example, depression, long-\nlasting, and even life-threatening sequelae.\nMultitrait Multimethod Construct Validation\nAs hypothesized, client gender was not signifi-\ncantly related to any indicators. The OAMA corre-\nlations alone were consistent with theoretical\nexpectations. Therefore, based on their concur-\nrence with theoretical expectations, the construct\nvalidity of the OAPAM was supported.\nConcept Analysis\nThe concepts of PA were ranked the same by\nboth the experts and by the client Rasch calibra-\ntions (Table 1). This was supportive of construct\nvalidity. However, the middle three concepts\nThreats and Intimidation (T&I), Insensitivity and\nDisrespect (I&D), and Shaming and Blaming (S&B)\nwere so close in average rank, that is, within one\nstandard error (SE = 0.52) that this ranking may not\nbe reliable. Looking at Figure 1, the Wright Map,\nthe isolation concept clearly had the most severe\nitems (high on the ruler/map). However, the rest of\nthe concepts have their items interspersed through-\nout the ruler without discernable lines of demarca-\ntion. The item 9AfraidOfAA was fairly high on the\nseverity ruler, that is, at -.36. This item and\n8UncomfortableW/AA were originally classified as\nthe \"Risk Factor\" concept. However, such a high\ncalibration was indicative of something more seri-\nTable 1. Expert Item Groups and Rankings Compared With Client Factors and Rankings\nExpert concepts and ranks with Rasch measures\nExpert concept Rank Expert concept name Expert groups average Rasch measurea Client concept rank\naBased on the client endorsement of the items but using the items as grouped by the experts. To calculate the average mea-\nsures, the item calibrations were summed, that is, where items are located on the ruler in Figure 1, and divided by the number of\nitems in that group, for example, seven ISO items. Because most of the ISO items are located high on the ruler, the ISO group/\nconcept has the highest severity.\nbExpert and client rankings were the same, but the middle three were so close in average rank, that is, within one standard\nerror (SE = 0.52), that this ranking may not be reliable.\ncTwo risk factor items involving fear of abuser were reclassified as T&I.\nTable 2. Hypothesized and Actual Correlationsa of OAPAM With Gender, Substantiation Decision, and Staff Psychological\nAbuse (PA) Assessment\nClient gender\nPsychological abuse\nsubstantiation decision (IDOA) OAMA staff PA OAMA client PA\nClient gender\nEmotional Abuse Substantiation\n Decision (IDOA)\nNotes: IDOA = Illinois Department on Aging; OAMA = Older Adult Mistreatment Assessment; OAPAM = Older Adult Psy-\nchological Abuse Measure.\naHypothesized correlations: NS = nonsignificant, >.1 = low, >.3 = moderate, and >.5 = high are listed before the actual corre-\nlations.\nbPerson reliabilities of OAMA scales are located on the diagonal.\n**Correlation is significant at the .01 level (two tailed).\nous than a risk factor so these items were reclassi-\nfied into Threats and Intimidation. This was logical\nbecause the items, that is, \"uncomfortable with\"\nand \"afraid of,\" can be interpreted as sequelae of\nthreats and intimidation.\nThe major point that was taken from this con-\nceptual analysis was that isolation is clearly the\nmost serious type of PA because it may border on\nor include physical abuse, such as physical and\nchemical restraints. The other three types, Threats\nand Intimidation, Insensitivity and Disrespect, and\nShaming and Blaming, do not form a clear hierar-\nchy as concepts, that is, each concept is not at a\ndistinct severity level. Rather, the items within\neach concept vary greatly in severity.\nLimitations\nAlthough this was the largest sample of sub-\nstantiated elder abuse clients that was found, it\nwas still limited to seven agencies in the Chicago\narea. New measures always require further valida-\ntion; that includes this one. Ongoing validation of\nthe Rasch-derived theoretical hierarchy and the\ncutoff scores proposed here will be needed to\nunderstand its most appropriate uses.\nStrengths\nThe OAPAM was developed with expert and\nclient input involving 83 informed stakeholders\n(Conrad, Iris, & Ridings, 2009); data were then\ncollected on 226 substantiated clients and ana-\nlyzed. The results were supportive of the validity\nof using the OAPAM in helping to assess the exis-\ntence and the level of PA of older adults who are\nable to self-report using a MMSE (Folstein et al.,\nas the criterion for adequate cognitive capacity.\nFrom a theoretical perspective, this work has\nclassified items into four types of PA of older\nadults: Isolation, Threats and Intimidation, Insen-\nsitivity and Disrespect, and Shaming and Blaming.\nDespite the limitations and need for further devel-\nopment, these items, used as long and short forms,\nshould help to open the neglected area of PA of\nolder adults for improved services and research.\nThis OAPAM can be widely useful in elder abuse\nresearch and practice because there had been no\nvalidated client-reported measures, and self-report\nby the alleged victim of his or her internal mental\nstate is an important, some might say essential,\nindicator of abuse.\nThe measures provide empirically derived and\ntheoretically supported gradations along the con-\ntinuum of PA severity that can enable better deci-\nsion making by clinicians and supervisors. With\nstandardization, decisions will not be so depen-\ndent on the staff's training, experience, and idio-\nsyncracies. With further development of validated\ncutoff scores, cases may be triaged more effectively\ninto appropriate interventions.\nFuture Directions\nThis study is part of a program of research that is\ndeveloping parallel third party measures that may\nbe used by elder abuse staff as well as other report-\ners, such as police, family members, and neighbors.\nObtaining information from multiple sources is a\ngood way to cross-validate reports as well as to dis-\ncover additional information that may be lacking\nfrom an individual. This type of triangulation of\ndata is a key to accurate assessment, intervention,\nand adjudication. It should help to improve esti-\nmates of prevalence and to study the correlational\nand causal relationships that will help professionals\nto understand better and to ameliorate elder abuse.\nFunding\nThis work was supported by the National Institute of Justice [grant\n"
}