{
    "abstract": "Abstract\nStroke is the leading cause of adult disability worldwide, with up to two-thirds\nof individuals experiencing long-term disabilities. Large-scale neuroimaging\nstudies have shown promise in identifying robust biomarkers (e.g., measures\nof brain structure) of long-term stroke recovery following rehabilitation.\nHowever, analyzing large rehabilitation-related datasets is problematic due to\nbarriers in accurate stroke lesion segmentation. Manually-traced lesions are\ncurrently the gold standard for lesion segmentation on T1-weighted MRIs, but\nare labor intensive and require anatomical expertise. While algorithms have\nbeen developed to automate this process, the results often lack accuracy.\nNewer algorithms that employ machine-learning techniques are promising, yet\nthese require large training datasets to optimize performance. Here we\npresent ATLAS (Anatomical Tracings of Lesions After Stroke), an open-source\ndataset of 304 T1-weighted MRIs with manually segmented lesions and\nmetadata. This large, diverse dataset can be used to train and test lesion\nsegmentation algorithms and provides a standardized dataset for comparing\nthe performance of different segmentation methods. We hope ATLAS release\n1.1 will be a useful resource to assess and improve the accuracy of current\nlesion segmentation methods.\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nBackground & Summary\nApproximately 795,000 people in the United States suffer from a stroke\nsurvivors experience long-term disabilities that impair their participation in\ndaily activities2,3. Careful clinical decision making is thus critical both at the\nacute stage, where interventions can spare neural tissue or be used to\npromote early functional recovery4, and at the subacute/chronic stages, where\neffective rehabilitation can promote long-term functional recovery. Enormous\nefforts have been made to predict outcomes and response to treatments at\nboth acute and subacute/chronic stages using brain imaging.\nAt the acute stage, within the first 24 hours or so after stroke onset,\nclinicians face important, time-sensitive decisions such as whether to\nintervene to save damaged tissue (e.g., administer thrombolytic drugs,\nperform surgery). Clinical brain images such as magnetic resonance imaging\n(MRI) and computerized tomography (CT) scans are routinely acquired to help\ndiagnose and make these urgent clinical decisions. Images obtained often\ninclude lower-resolution CT scans or structural MRIs (e.g., T2-weighted,\nFLAIR, diffusion weighted, or perfusion weighted MRIs), and impressive\nefforts have been made to use these images to automatically detect the lesion\nvolume, predict responses to acute interventions, and predict general\nprognosis. As clinical scans are typically a mandatory part of acute stroke\ncare, there has been excellent progress in using large-scale datasets of the\nacquired images to relate to outcomes and build automated lesion detection\nalgorithms and predictive models over the past few decades5. In addition,\nusing imaging to assess the extent of neural injury within the first few days\nafter stroke can be helpful for informing entry criteria and stratification\nvariables for enrollment in clinical trials of early recovery therapies, which\nhave specific time windows shortly after stroke onset4.\nOn the other hand, there have been fewer advances in large-scale\nneuroimaging-based stroke predictions at the subacute and chronic stages.\nHere, clinicians must triage patients and assign scarce rehabilitation\nresources to those who are most likely to benefit and recover. Brain imaging,\nsuch as MRI, is primarily acquired as part of research studies to understand\nbrain-related changes in response to different therapeutic interventions or to\nprovide valuable additional information, beyond what can be gleaned from\nbedside exams, that can be used to predict rehabilitation outcomes6. As stroke\nis a leading cause of adult disability worldwide, there is a large emphasis\nplaced on predicting and understanding how to best promote long-term\nrehabilitation in these individuals. Although there are fewer MRIs acquired\nduring this time, the most common research scan is a high-resolution T1-\nweighted structural MRI, which is often acquired along with functional MRI and\nhigh-resolution diffusion MRI scans and can show infarcts at the post-acute\nstage. Research using these types of images at this stage of stroke have\nshown promising biomarkers that could potentially provide additional\ninformation, beyond behavioral assessments, to predict an individual's\nlikelihood of recovery for specific functions (e.g., motor, speech) and response\nto treatments7-9. Thus far, measures that include the size, location, and\noverlap of the lesion with existing brain regions or structures, such as the\ncorticospinal tract, have been successfully used as predictors of long-term\nstroke recovery and rehabilitation9-15. However, to date, this has only been\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\ndone in smaller-scale studies, and results may conflict across studies or be\nlimited to each sample. Examining lesion properties with larger datasets at the\nsubacute and chronic stages could lead to the identification of more robust\nbiomarkers for rehabilitation that are widely applicable across diverse\npopulations. Recently, efforts for creating large-scale stroke neuroimaging\ndatasets across all time points since stroke onset have emerged and offer a\npromising approach to achieve a better understanding of the long-term stroke\nrecovery process (e.g., ENIGMA Stroke Recovery;\nhttp://enigma.ini.usc.edu/ongoing/enigma-stroke-recovery/).\nHowever, a key barrier to properly analyzing these large-scale stroke\nneuroimaging datasets to predict rehabilitation outcomes is accurate lesion\nsegmentation. While many acute neuroimaging stroke studies bypass manual\nlesion segmentation by using a visual scoring of lesion characteristics with\nvalidated scoring tools applied by expert raters, research studies that wish to\nexamine the overlap of the lesion with specific brain structures (e.g., in voxel-\nbased lesion symptom mapping, or lesion load methods) require an accurate\nand detailed lesion map. In T1-weighted MRIs, which are often used in\nresearch, the gold standard for delineating these lesions is manual\nsegmentation, a process that requires skilled tracers and can be prohibitively\ntime consuming and subjective16. A single large or complex lesion can take up\nto several hours for even a skilled tracer. As a result of this demand on time\nand effort, this method, which has been used in previous smaller\nneuroimaging studies, is not suitable for larger sample sizes. Based on the\nliterature, most studies with manually segmented brain lesions on T1-weighted\nAccurately segmenting hundreds or thousands of stroke lesions from T1-\nweighted MRIs may thus present a barrier for larger-scale stroke\nneuroimaging studies.\nMany stroke neuroimaging studies have utilized semi- or fully-\nautomated lesion segmentation tools for their analyses. Semi-automated\nsegmentation tools employ a combination of automated algorithms, which\ndetect abnormalities in the MR image, and manual corrections or inputs by an\nexpert. Fully-automated algorithms rely completely on the algorithm for the\nlesion segmentation. While these require little human input or expertise, they\nstill may require significant computational resources and processing time.\nMany of these fully-automated algorithms employ machine learning\ntechniques that require training and testing on large datasets21, and the\nperformance of the algorithm is highly dependent on the size and diversity of\nthe training dataset. While there have been several exciting initiatives\nregarding lesion segmentation in acute clinical imaging, discussed below,\nthere are few publically available large training/test datasets of manually\nsegmented stroke lesion masks on research-grade T1-weighted images that\ncould be used for improving such algorithms. Thus, while both semi- and fully-\nautomated lesion segmentation tools have the potential to greatly reduce the\ntime and expertise needed to analyze stroke MRI data22, it is unclear whether\nthey provide the accuracy needed for rigorous stroke lesion-based analyses.\nIn addition, it is difficult to compare the performance of automated\nlesion segmentation tools as they are often not evaluated for performance on\nthe same dataset. Recently, some exciting initiatives have emerged to\ndevelop better segmentation algorithms using standardized datasets and\nmetrics. In particular, the Ischemic Stroke Lesion Segmentation (ISLES)\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nchallenge is an annual satellite challenge of the Medical Image Computing\nand Computer Assisted Intervention (MICCAI) meeting that provides a\nstandardized multimodal clinical MRI dataset of approximately 50-100 brains\nwith manually segmented lesions23. The ISLES competition encourages\nresearch groups to use the dataset to evaluate their lesion segmentation\nalgorithms and predict acute outcomes to inform clinical decision making. This\napproach is promising for developing better lesion segmentation algorithms\nand predictive models for acute imaging. However, past ISLES challenge\ndatasets have traditionally focused more on using multimodal clinical MRIs to\npredict more acute results, and these algorithms are not easily translatable to\nthe high-quality T1-weighted MRIs typically found in subacute/chronic stroke\nrehabilitation research. Thus, here, we aimed to develop a complementary\nlarge dataset using only anatomical T1-weighted MRIs, which are typically\nacquired in research studies after the acute stage to assess rehabilitation\noutcomes. We anticipate this dataset could be useful for enhancing lesion\nsegmentation methods for T1-weighted images often used in medical\nrehabilitation research.\nHere, we present ATLAS (Anatomical Tracings of Lesions After Stroke)\nRelease 1.1, an open-source dataset consisting of 304 T1-weighted MRIs with\nmanually segmented diverse lesions and metadata. The goal of ATLAS is to\nprovide the research community with a standardized training and testing\ndataset for lesion segmentation algorithms on T1-weighted MRIs. We note\nthat this dataset is not representative of the full range of stroke, as this data\nwas acquired through research studies in which individuals with stroke\nvoluntarily participated, and all participants had to be eligible for a research\nMRI session. However, this dataset may be useful for testing and comparing\nthe performance of different lesion segmentation techniques and identifying\nkey barriers hindering the performance of automated lesion segmentation\nalgorithms. We believe that this diverse set of manually segmented lesions will\nserve as a valuable resource for researchers to use in assessing and\nimproving the accuracy of lesion segmentation tools.\nMethods\nData Overview\n304 MRI images from 11 cohorts worldwide were collected from research\ngroups in the ENIGMA Stroke Recovery Working Group consortium. Images\nconsisted of T1-weighted anatomical MRIs of individuals after stroke. These\nimages were collected primarily for research purposes and are not\nrepresentative of the overall general stroke population (e.g., only including\nindividuals who opt in to participate in a research study, and excluding\nindividuals with stroke who cannot undergo MRI safely).\nFor each MRI, brain lesions were identified and masks were manually\ndrawn on each individual brain in native space using MRIcron24, an open-\nsource tool for brain imaging visualization and defining volumes of interest\n(http://people.cas.sc.edu/rorden/mricron/index.html). At least one lesion mask\nwas identified for each individual MRI. If additional, separate (non-contiguous)\nlesions were identified, they were traced as separate masks. An expert\nneuroradiologist reviewed all lesions to provide additional qualitative\ndescriptions of the type of stroke, primary lesion location, vascular territory,\nand intensity of white matter disease. Finally, a separate tracer performed\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nquality control on each lesion mask. This included assessing the accuracy of\nthe lesion segmentations, revising the lesion mask if needed, and categorizing\nthe lesions to generate additional data such as the number of lesions in left\nand right hemispheres, and in cortical and subcortical regions. This dataset is\nprovided in native subject space and archived (n=304). A subset of this\ndataset was also defaced, intensity normalized, and provided in standard\nspace (normalized to the MNI-152 template, n=229; for an overview of the\ndataset and archives, see Figure 1).\nAll ATLAS contributions were based on studies approved by local ethics\ncommittees and were conducted in accordance with the 1964 Declaration of\nHelsinki. Informed consent was obtained from all subjects. The receiving site's\nethics committee at the University of Southern California approved the receipt\nand sharing of the de-identified data. Data were fully de-identified by removing\nall 18 HIPAA (Health Insurance Portability and Accountability)-protected\nhealth information identifiers, lesions were manually segmented on each MRI,\nand all data were visually inspected before release. In addition, the terms of\nthe data sharing agreements were approved by the University of Southern\nCalifornia's technology transfer office.\nData Characteristics\nAll T1-weighted MRI data were collected on 3T MRI scanners at a resolution\nof 1 mm3 (isotropic), with the exception of data from cohorts 1 and 2 which\nmm (excluded from the normalized dataset). Scanner information (scanner\nstrength, brand) and image resolution are included in the ATLAS meta-data,\nand sample image header information for a subject from each of the cohorts\ncan be found in Supplementary Information.\nCharacteristics of the ATLAS dataset include an average lesion volume\nthe distribution of lesions in the ATLAS dataset (e.g., single versus multiple\nlesions per individual, percent of lesions that are left versus right hemisphere,\nor subcortical versus cortical) can be found in Tables 1 and 2. Overall, slightly\nmore than half of the subjects had only one lesion (58%) while the rest had\nmultiple lesions (42.1%). Lesions were roughly equally distributed between left\nother location such as brainstem or cerebellum). In this dataset, there were\nmore subcortical lesions than cortical lesions (70.7% subcortical, 21.5%\ncortical, 7.7% other).\nTable 1. A total of 304 subjects within 11 cohorts were included in the full\nATLAS Release 1.1 native dataset. The number of brains in which only one\nlesion was found (left/right hemispheres and other locations found within the\nbrainstem and cerebellum, etc.), and the number of brains in which multiple\nlesions were found, are shown.\nCohort\nNumber of\nSubjects\nBrains with One Lesion Brains\nwith\nLeft Right Other\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nMultiple\nLesions\nTable 2. The number of lesions found in each location (i.e. cortical vs.\nsubcortical; left vs. right hemispheres), and other locations (i.e., brainstem,\ncerebellum, etc.) are shown. Here we have included primary lesions as well as\nadditional lesions, resulting in 521 total lesion masks across n=304.\nCohort\nCortical Lesions\nSubcortical Only\nLesions\nOther\nLesion\nLocations\nLeft Right Left Right\n%Total\nLesions\nTraining Individuals Performing Lesion Tracing\nEleven individuals were carefully trained in identifying and segmenting lesions.\nIndividuals had a range of backgrounds, including undergraduate students,\ngraduate students, and postdoctoral fellows. All tracers were given detailed\ninformation regarding neuroanatomy, and underwent standardized training,\nwhich utilized a detailed protocol as well as an instructional video. All tracers\nwere guided through the training process with extensive feedback on lesion\ntracing performance by an expert tracer and in consultation with an expert\nneuroradiologist. The detailed protocol, with pictures of example tracings, is\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nfreely available and can be found on the ATLAS GitHub website\n(https://github.com/npnl/ATLAS/). All individuals were trained on an initial set\nof 5 brains with varying lesion sizes and locations (size range: min: 1,871\n4, Right: 0]). After tracing the first set of 5 lesions, tracings were reviewed by\nan experienced tracer and differences in the lesion masks were discussed\nwith the tracer. One week later, individuals retraced the lesions on the same\nset of 5 brains, but were blinded to their first segmentation attempt to examine\nintra-tracer reliability. After this, each lesion segmentation was reviewed by a\nseparate tracer. In addition, the primary lesion location was identified by an\nexpert neuroradiologist, who also created the meta-data (see Metadata\nbelow). Any questions regarding lesion masks were referred to the\nneuroradiologist. Inter- and intra-rater reliability measures and additional\ntechnical validation of the lesion tracings can be found in Technical Validation\nbelow. Finally, we note that lesion tracing is a subjective process, even across\ntrained individuals. As mentioned in Usage Notes below, any problems,\nquestions, or issues with specific lesion masks can be publically reported on\nour ATLAS GitHub under the Issues page\n(https://github.com/npnl/ATLAS/issues ) so that the community of users can\nmake comments and be aware of any identified issues. We will work to\nresolve any issues in a timely manner.\nIdentifying and Tracing Lesions\nTo identify lesions, each T1-weighted MRI image was displayed using the\nmultiple view option in MRIcron20, which displays the brain in the coronal,\nsagittal, and axial view (see Figure 2). To identify lesions, tracers looked for\ndarker intensities within typically healthy tissue. For lesions that were more\ndifficult to detect with the grayscale setting, colored look-up table settings\n(e.g., \"cardiac\", \"NIH\", or \"spectrum\" settings in MRIcron) were used to provide\nadditional insight. Once the lesion or lesions were identified, the lesion mask\nwas traced using either the coronal or axial view, using either a mouse, track\npad, or tablet (i.e. Wacom Intuos Draw). A combination of MRIcron tools was\nused to draw the lesion masks, which included the 3D fill tool, the pen tool and\nthe closed pen tool. Typically, and especially for larger sized lesions, tracers\nused the 3D fill tool to begin the segmentation. Crosshairs were placed in the\ncenter of the identified lesion and the tool would fill in voxels similar to the one\nat the point of origin with the selected radius and at the sensitivity specified by\nthe difference from origin and difference at edge tools. The pen and closed\npen tool, typically was used to fill in (or remove) the areas that the 3D tool had\nmissed or was used to trace smaller lesions slice by slice. Once completed,\nlesion masks were saved in the volume of interest (VOI) file format with the\nidentifier name \"cXXXXsXXXXtXX_LesionRaw\" (see Data Records and Table\n3 below for full naming conventions). Lesions masks were then checked for\ncorrectness by a separate tracer, who made additional corrections to the\nlesion mask, if needed. After lesions were identified as being correct, masks\nwere smoothed using MRIcron's smooth VOI tool where the full width half\nmaximum parameter was set to 2 mm and the threshold was set to 0.5. These\nmasks were saved in both VOI and NIfTI file formats with the identifier name\n\"cXXXXsXXXXtXX_LesionSmooth\".\nAny additional lesions that were not contiguous with the primary lesion\nmask were drawn as separate lesion masks and labeled. As described in Data\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nRecords, any secondary lesions followed the same procedures as the primary\nlesion mask, but were labeled as Lesion_1, Lesion_2, Lesion_3 and so on,\nwith the naming convention moving from the largest to smallest mask (e.g.,\nLesion_1 is the largest secondary lesion mask). In general, the primary lesion\nmask was the largest lesion, with any secondary lesion masks subsequently\nnamed and ordered by size (largest to smallest). The only exception to this\nwas, in the case of multiple lesions, if the neuroradiologist identified a primary\nstroke location as a different lesion from the largest lesion mask. In these\ncases, we used the lesion identified by the neuroradiologist as the primary\nmask. This occurred in less than 5% of the subjects.\nMetadata\nFor each lesion, we also provided metadata on the lesion properties to give\nthe user additional qualitative information, beyond the binary lesion mask. This\ninformation can be used to quickly sort the dataset based on specific lesion\ncharacteristics (e.g., only left hemisphere lesions, or only subcortical lesions).\nIt can also provide additional insight into the types of lesions that succeed or\nfail for a given lesion segmentation algorithm. The lesion properties were\nmanually reported for each individual lesion mask. These include the number\nof lesions identified and traced, and the location of each lesion (i.e. right/left,\nsubcortical, cortical, or other). In order to count each lesion only once, we\ndefined subcortical lesions as lesions that are contained completely in the\nwhite matter and subcortical structures. Any lesion that extends beyond this\narea and into the cortex is considered a cortical lesion. In this way, cortical\nlesions may extend into the subcortical space, but subcortical lesions do not\nextend into the cortical space. \"Other\" includes the brainstem and cerebellum.\nAn experienced neuroradiologist also identified the following information for\neach individual brain: the type of stroke (e.g., embolic, hemorrhagic), primary\nstroke location, vascular territory, and intensity of white matter disease\n(periventricular hyperintensities, or PVH, and deep white matter\nhyperintensities, or DWMH). White matter hyperintensities were graded using\nthe Fazekas scale25. For periventricular hyperintensities, the following grades\nwere applied: 0 = absence, 1 = \"caps\" or pencil-thin lining, 2 = smooth \"halo\",\n3 = irregular PVH extending into the deep white matter. For deep white matter\nhyperintensities, the following grades were applied: a = absence, 1 = punctate\nfoci, 2 = beginning confluence of foci, 3 = large confluent areas. The white\nmatter hyperintensity ratings are included because areas of white matter\nhyperintensity often pose challenges for lesion segmentation algorithms.\nFinally, scanner strength, brand/model, and image resolution are included in\nthe metadata as well.\nNormalization to a Standard Template, Intensity Normalization, and Defacing\nTo expand access to the dataset, we have also provided a subset of the data\nthat is defaced, intensity-normalized, and normalized to standard (MNI-152)\nspace. Lesion segmentation algorithms vary in whether the input should be in\nnative (subject) space or a standardized space. Therefore, to provide this\noption for users, we also generated a version of the ATLAS dataset in\nstandard space. To convert the images to standard space, MRI images first\nunderwent automated correction for intensity non-uniformity and intensity\nstandardization using custom scripts derived from the MINC-toolkit26\n(https://github.com/BIC-MNI/minc-toolkit). These corrected images were\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nlinearly registered to the MNI-152 template using a version that was\nnonlinearly constructed and symmetric (version 2009;\nhttp://www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009) to normalize\ntheir intracranial volume in a standardized stereotaxic space27. Using the\nresulting transformation matrix, the labels drawn on the MRI images were also\nregistered to the MNI template. The MRI images were resampled using the\nlinear interpolation whereas their labels used a nearest neighborhood\ninterpolation to keep their binary nature. Finally . Freesurfer's mri_deface tools\nwere used to perform the defacing (e.g., to remove any facial structures)\n(https://surfer.nmr.mgh.harvard.edu/fswiki/mri_deface) on all T1-weighted\nimages.\nDue to technical difficulties and differences in scanner image quality, a\nsubset of brains is not included in the standard space conversion, resulting in\na total of n=229 ATLAS brains converted into standard MNI space. Scans\nfrom the two cohorts with 0.9 x 0.9 x 3.0 mm resolution images, collected on\n1.5T scanners, were excluded from this standardized dataset due to their\nlower resolution. In addition, any images that failed registration were excluded.\nPrimary reasons for failed registration include large lesion volumes or poor\nimage quality (e.g., image artifacts, motion artifacts). We are currently working\non manually editing the registrations for these images, which will be released\nin the future. This dataset can be widely accessed from the FCP-INDI archive\n(see Figure 1 and Table 3 for archive details). All images were named in\naccordance with the INDI data policy, following the Brain Imaging Data\nStructure (BIDS), and a meta-data sheet using the INDI naming convention is\nincluded with this dataset.\nProbabilistic Spatial Mapping of ATLAS Lesion Labels\nWe also created a probabilistic spatial mapping of the lesion labels solely to\nvisualize the distribution of lesion masks across the normalized ATLAS\ndataset. We note that this does not provide a representation of a true stroke\ndistribution, but rather shows the distribution of lesions included in this\ndataset. To do this, we performed a population-based averaging of all the\nindividual primary lesion labels in MNI space, producing a voxel-wise map\nwhere values can range from 0 at each voxel (always background for all\nsubjects) to 1 (100% presence of the lesion label across subjects). A\nprobabilistic spatial map of the primary lesions can be found in Figure 3 and a\n3D visualization of the lesion map can be found in the following video link:\nhttps://www.youtube.com/watch?v=Ag5CUsRNY9Q. In addition, this map has\nalso been provided in NIfTI format (.nii.gz) and uploaded to NeuroVault.org,\nan open-source database for neuroimaging data where it can be freely\naccessed (https://neurovault.org/collections/3073/).\nData Records\nThe full raw dataset (native dataset, n=304) is archived with the Archive\nof Disability Data to Enable Policy research at the Inter-university Consortium\nfor Political and Social Research (ICPSR). ICPSR is the world's largest social\nscience data archive that supports several substantive-area archive\ncollections including disability and rehabilitation. ICPSR provides access to\nthe data and provides technical assistance to individuals accessing the data.\nIn addition, a standardized, defaced subset of the dataset (standardized\ndataset, n=229) is archived with the International Data Sharing Initiative, which\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nhosts many widely available neuroimaging datasets such as the Functional\nConnectome Project (FCP-INDI). See Usage Notes for more details regarding\naccess.\nFor the full dataset archived with ICPSR, the naming convention and\ndescription of the files in ATLAS R1.1 can be found in Table 3. Within the\nATLAS R1.1 main folder, there is an excel file with the metadata for the entire\ndataset. The data in this archive is in native space (i.e., original subject space;\nn=304). Throughout the dataset, MRIs are named and sorted based on each\ncohort (c); each cohort is in the format of cXXXX where XXXX is the number\nthat the cohort was assigned (e.g., c0001). There are 11 total cohorts. Within\neach cohort folder are the individual subject(s) folders. Subject folders are\nnamed based on the cohort that they are in (cXXXX), the subject number that\nthey were assigned (sXXXX) and the time point at which they were taken\nweeks apart would have two time points, where t01 is the first time point and\nt02 is the second. Every image starts with the subject identifier of\nEach subject folder has several components: at minimum, each will\nhave the original T1-weighted MRI image (*.nii.gz) and three masks for the\nmain lesion: the unsmoothed lesion mask (*LesionRaw.voi), and two\nsmoothed lesion masks in .voi and .nii.gz formats (*LesionSmooth.voi;\n*LesionSmooth.nii.gz). The LesionRaw volume is the original hand-traced\nlesion volume, while the LesionSmooth volume used a Gaussian smoothing\nkernel (full width half maximum parameter set to 2 mm, threshold set to 0.5, to\novercome small errors between slices in tracing; see Methods above). We\nanticipated that most researchers would use the LesionSmooth volume as it is\nslightly more robust to small slice-by-slice human errors, and therefore\ncreated the .nii.giz version from this. Notably, the .voi files are in an MRIcron\nformat so the masks can be further edited in MRICron if desired. The .nii.gz\nfiles use the standard NIfTI format28 (http://nifti.nimh.nih.gov/nifti-1/), which\ncan be opened, edited, and viewed by most standard neuroimaging software.\nIf a particular subject had multiple lesions, for each additional lesion,\nthere would be three additional lesion masks (e.g. *LesionRaw_1.voi,\n*LesionSmooth_1.voi, *LesionSmooth_1.nii.gz). In general, lesions were\nranked based on size where the largest lesion was considered the main\nlesion. As mentioned previously, if the largest lesion differed from the primary\nlesion identified by the neuroradiologist, we deemed the primary lesion to be\nthe one identified by the neuroradiologist. This occurred in less than 5% of\ncases.\nFinally, in the FCP-INDI archive (standardized dataset, n=229), there is\na separate naming convention, following the Brain Imaging Data Structure\n(http://bids.neuroimaging.io/), adopted by FCP-INDI. Images in this dataset\nhave been normalized to a standard MNI-152 template, intensity normalized,\nand defaced. Table 3 provides a list of all naming conventions and filenames,\nalong with descriptions.\nTable 3. Filenames and file descriptions for ATLAS R1.1 dataset. * represents\na wildcard.\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nhttp://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/36684\nFilename or Identifier Description\ncXXXXsXXXXtXX.nii.gz Raw T1-weighted MRI for each subject, where c = cohort\nnumber, s = subject number, and t = time point\n*LesionRaw.voi Raw primary lesion mask, drawn as a volume of interest in\n*LesionSmooth.voi Smoothed primary lesion mask, drawn as a volume of interest\nin MRICron\n*LesionSmooth.nii.gz Smoothed primary lesion mask, saved as a nifti file\n*LesionRaw/Smooth_1(or 2,\n3, ...).voi/.nii.gz\nRaw and smoothed secondary lesion masks (same as the\nthree above, but for additional lesions)\nhttp://fcon_1000.projects.nitrc.org/indi/retro/atlas.html\nFilename or Identifier Description\nSite, Subject ID, Session Naming convention follows Brain Imaging Data Structure\n(BIDS) recommendations\nTechnical Validation\nEach trained tracer created lesion masks for the same five brains twice,\none week apart, to assess both inter- and intra-tracer reliability. Training\nlesions ranged in size and difficulty (see Methods). Each tracer's lesion masks\nwere compared, providing both inter- and intra-rater reproducibility measures.\nWe first calculated inter- and intra-rater reliability measures using the lesion\nvolumes. Based on lesion volumes, the inter-rater reliability was 0.76\u00b10.14,\nIn addition, we also calculated inter-and intra-rater reliability using the\nDice similarity coefficient (DC), which is a segmentation accuracy metric, and\nHausdorff's distance (HD), which is a metric of the maximum distance\nbetween two volumes surface points. DC allows us to examine not only if the\nvolumes are similar, but also if the same voxels are being selected as part of\nthe lesion mask or not. This is particularly useful for comparing neuroimaging\nvolumes, such as lesion masks. DC is calculated by the formula:\n =\n + ||\nwhere X and Y represent the voxels from each lesion segmentation, and DC\nranges from 0 to 1 (where 0 means there were no overlapping voxels and 1\nmeans that the segmentations were completely the same). HD allows us to\nexamine the distance between the surfaces of two images and thus can be\nused to identify outliers, providing another useful metric for comparing\nneuroimaging volumes. HD is calculated by the formula:\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nwhere x and y represent the surface points from the volumes X and Y\nrespectively. HD is measured in millimeters, and a lower value denotes that\nthe maximum distance between the two images is smaller.\nInter-rater scores (DC, HD) were calculated for each manual\nsegmentation by comparing each individual tracer's lesion mask to the rest of\nthe tracers' lesion masks. Inter-rater DC and inter-rater HD scores were then\naveraged to obtain one final DC score and one final HD score for the initial\nsegmentations (average inter-rater DC for first segmentation: 0.73\u00b10.20;\nsecond segmentations (average inter-rater DC for second segmentation:\nFurthermore, intra-rater DC and HD scores were calculated for each brain\ntraced by comparing the initial segmentation to the secondary segmentation\nfor each tracer; these scores were then averaged to obtain a final intra-rater\nTrained tracers segmented all lesion masks. In addition, each lesion\nmask was checked by a separate tracer, and changes were made to the\nlesion mask as needed. Any difficulty identifying the lesion was discussed with\nthe expert neuroradiologist. Lastly, after the completion of the dataset, lesion\nmasks were checked a second time to ensure correct segmentation and data\ndescriptors. It is important to note that while tracers did participate in a\nthorough training process and segmentations were checked multiple times,\nthis is still a subjective process. Comments regarding the lesion masks can be\nsubmitted as issues on the ATLAS GitHub site\n(https://github.com/npnl/ATLAS/issues), and we plan to publish updated and\nexpanded versions of this dataset based on feedback and comments from\nusers (see Usage Notes).\nUsage Notes\nThe full native-space archived dataset (n=304) can be found at ICPSR:\nhttp://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/36684. For more information\non the data archive, visit the ICPSR website\n(https://www.icpsr.umich.edu/icpsrweb).\nIn addition, a standardized, intensity-normalized, defaced subset of the data\n(n=229) can be found at FCP-INDI:\nhttp://fcon_1000.projects.nitrc.org/indi/retro/atlas.html.\nData is accessible under a standard Data Use Agreement, under which users\nmust agree to only use the data for purposes as described in the agreement.\nUsers of the ATLAS dataset should acknowledge the contributions of the\noriginal authors and research labs by properly citing this article and the data\nrepository link from which they accessed the data.\nAs described above, lesions were segmented using the NITRC open\nsource software MRIcron which can be downloaded from the NITRC website\n(https://www.nitrc.org/projects/mricron). Users can also quickly and easily view\nthe brains on BrainBox (http://brainbox.pasteur.fr/), an open-source Web\napplication to collaboratively annotate and segment neuroimaging data\navailable online29. For additional quick quantification, our group has also\ncreated a small package of scripts called SRQL (Semi-automated Robust\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nQuantification of Lesions), which provide three features: it uses a semi-\nautomated white matter intensity correction to further correct for human errors\nin lesion tracing, outputs a report of descriptive statistics on lesions\n(hemisphere and volume of lesion), and gives users the option to perform\nanalyses in native or standard space (https://github.com/npnl/SRQL)30. In\naddition, as we plan to grow this dataset in the future, additional releases of\ndata or software will be announced on our ATLAS GitHub page\n(https://github.com/npnl/ATLAS/). Any issues or feedback can also be\nsubmitted on the ATLAS GitHub page under \"issues,\" and a team of\nresearchers will address these in a timely manner. Finally, as a general note\nregarding the usage of this dataset, we strongly encourage users to be\ncautious of overfitting training algorithms to this particular dataset. We note\nthat this data is relatively diverse, given the data collection across 11 research\nsites worldwide. However, we caution users against overfitting to only a\nparticular cohort or subset of this data. Future work will aim to provide\nadditional test datasets for users to properly test their algorithms on untrained\ndata.\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nAcknowledgments\nWe thank Dr. Mauricio Reyes for insightful conversations and would\nlike to acknowledge the following people for their assistance on this effort:\nAnthony Benitez, Xiaoyu Chen, Cristi Magracia, Ryan Mori, Dhanashree\nPotdar, Sandyha Prathap. The archiving of this dataset was specifically\nsupported by the NIH-funded Center for Large Data Research and Data\nSharing in Rehabilitation (CLDR; https://www.utmb.edu/cldr) under a Category\nAuthor contributions\nS.-L.L. conceptualized the study, reviewed lesions, analyzed data, established\narchives, and contributed to the writing and editing of the manuscript. J.M.A.\nsegmented and reviewed lesions, oversaw the organization to the\nsegmentation process and contributed to the writing and editing of the\nmanuscript. N.W.B. organized, segmented and reviewed lesions. M.S.\nprovided the neuroradiology expertise and information. K.L.I. and H.K.\nperformed data analysis. H.K. also performed data processing and generated\nthe standardized dataset and probabilistic lesion maps. T.A. provided data\nvisualization expertise and generated the figures/videos. J.C., D.S., A.S. J.I.,\nC.J., W.N., D.V. and S.L. segmented and/or reviewed lesions. P.H., B.K.,\nN.K., L.A.-Z., S.C.C., J.L., S.S., L.T.W., J.W., C.W., C.Y. collected and\nprovided the MRI data. M.L., A.P., and A.S. handled the archiving of the data.\nCompeting interests\nThe authors have no conflict of interest.\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nFigure Legends\nFigure 1. A schematic diagram showing the steps performed on the data for\neach archive release.\nFigure 2. An example of lesion segmentation in MRICron.\nFigure 3. A probabilistic lesion overlap map for the primary lesions from the\nATLAS R1.1 dataset. A 3D visualization of the lesion overlap map can be\nfound at https://www.youtube.com/watch?v=Ag5CUsRNY9Q.\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\nReferences\n1. Benjamin, E.J., et al. Heart Disease and Stroke Statistics-2017\nUpdate: A Report From the American Heart Association.\n2. Feigin, V.L., et al. Global and regional burden of stroke during\n3. Kwakkel, G., Kollen, B.J., Van der Grond, J.V. & Prevo, A.J.H.\nProbability of regaining dexterity in the flaccid upper limb: Impact\nof severity of paresis and time since onset in acute stroke. Stroke\n4. Ren, J., Kaplan, P.L., Charette, M.F., Speller, H. & Finklestein,\nS.P. Time window of intracisternal osteogenic protein-1 in\nenhancing functional recovery after stroke. Neuropharmacology\n5. Group, I.-C. Association between brain imaging signs, early and\nlate outcomes, and response to intravenous alteplase after acute\nischaemic stroke in the third International Stroke Trial (IST-3):\nsecondary analysis of a randomised controlled trial. The Lancet\n6. Burke Quinlan, E., et al. Neural function, injury, and stroke\nsubtype predict treatment gains after stroke. Ann Neurol 77, 132-\n7. Marie-H\u00e9l\u00e9ne, M. & Cramer, S.C. Biomarkers of recovery after\n8. Nijland, R.H.M., van Wegen, E.E.H., Harmeling-van der Wel, B.C.\n& Kwakkel, G. Presence of finger extension and shoulder\nabduction within 72 Hours after stroke predicts functional\n9. Riley, J.D., et al. Anatomy of stroke injury predicts gains from\n10. Cramer, S.C., et al. Predicting functional gains in a stroke trial.\n11. Jongbloed, L.Y.N. Prediction of function after stroke: a critical\n12. Nouri, S. & Cramer, S.C. Anatomy and physiology predict\nresponse to motor cortex stimulation after stroke. Neurology 77,\n13. Prabhakaran, S., et al. Inter-individual variability in the capacity\nfor motor recovery after ischemic stroke. Neurorehabilitation and\n14. Stinear, C. Prediction of recovery of motor function after stroke.\n15. Zhu, L.L., Lindenberg, R., Alexander, M.P. & Schlaug, G. Lesion\nload of the corticospinal tract predicts motor impairment in chronic\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:\n16. Fiez, J.A., Damasio, H. & Grabowski, T.J. Lesion segmentation\nand manual warping to a reference brain: Intra- and interobserver\n17. Montaner, J., et al. Plasmatic level of neuroinflammatory markers\npredict the extent of diffusion-weighted image lesions in\nhyperacute stroke. Journal of Cerebral Blood Flow & Metabolism\n18. Sakamoto, Y., et al. Early ischaemic diffusion lesion reduction in\npatients treated with intravenous tissue plasminogen activator:\ninfrequent, but significantly associated with recanalization.\n19. Thomas, R.G.R., et al. Apparent diffusion coefficient thresholds\nand diffusion lesion volume in acute stroke. Journal of Stroke and\n20. Wittsack, H.-J., et al. MR Imaging in Acute Stroke: Diffusion-\nweighted and Perfusion Imaging Parameters for Predicting Infarct\n21. Pustina, D., et al. Automated segmentation of chronic stroke\nlesions using LINDA: Lesion identification with neighborhood data\n22. de Haan, B., Clas, P., Juenger, H., Wilke, M. & Karnath, H.-O.\nFast semi-automated lesion demarcation in stroke. NeuroImage.\n23. Maier, O., et al. ISLES 2015 - A public evaluation benchmark for\nischemic stroke lesion segmentation from multispectral MRI.\n24. Rorden, C. & Brett, M. Stereotaxic display of brain lesions. Behav\n25. Fazekas, F., Chawluk, J., Alavi, A., Hurtig, H. & Zimmerman, R.\nMR signal abnormalities at 1.5 T in Alzheimer's dementia and\n26. Sled, J.G., Zijdenbos, A.P. & Evans, A.C. A nonparametric\nmethod for automatic correction of intensity nonuniformity in MRI\n27. Collins, L., D., Neelin, P., Peters, T., M. & Evans, A., C. Automatic\n3D intersubject registration of MR volumetric data in standardized\nTalairach space. Journal of Computer Assisted Tomography 18,\n28. Cox, R.W., et al. A (sort of) new image data format standard: Nifti-\n29. Heuer, K., Ghosh, S., Robinson Sterling, A. & Toro, R. Open\nNeuroimaging Laboratory. Research Ideas and Outcomes 2,\n30. Ito, K., Anglin, J. & Liew, S.-L. Semi-automated Robust\nQuantification of Lesions (SRQL) Toolbox. Research Ideas and\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:",
    "reduced_content": "A large, open source dataset of stroke anatomical brain images and manual\nlesion segmentations\nAuthors\nSook-Lei Liew1*, Julia M. Anglin1*, Nick W. Banks1, Matt Sondag1, Kaori L. Ito1,\nHosung Kim1, Jennifer Chan1, Joyce Ito1, Connie Jung1, Nima Khoshab2, Stephanie\nLefebvre1, William Nakamura1, David Saldana1, Allie Schmiesing1, Cathy Tran1,\nDanny Vo1, Tyler Ard1, Panthea Heydari1, Bokkyu Kim1, Lisa Aziz-Zadeh1, Steven C.\nCramer2, Jingchun Liu3, Surjo Soekadar4, Jan-Egil Nordvik5, Lars T. Westlye6,7,\nJunping Wang3, Carolee Winstein1, Chunshui Yu3, Lei Ai8, Bonhwang Koo 8, R.\nAffiliations\n1. University of Southern California, Los Angeles, California, USA\n2. University of California, Irvine, Irvine, California, USA\n3. Tianjin Medical University General Hospital, Tianjin, China\n4. University of T\u00fcbingen, T\u00fcbingen, Germany\n5. Sunnaas Rehabilitation Hospital HT, Nesodden, Norway\n6. NORMENT and KG Jebsen Centre for Psychosis Research, Division of Mental\nHealth and Addiction, Oslo University Hospital, Oslo, Norway\n7. Department of Psychology, University of Oslo, Oslo, Norway\n8. Child Mind Institute, New York, New York, USA\n9. Nathan S. Kline Institute for Psychiatric Research, Orangeburg, New York, USA\n10. University of Texas Medical Branch, Galveston, Texas, USA\n11. University of Michigan, Ann Arbor, Michigan\n Corresponding author: Sook-Lei Liew (sliew@usc.edu)\n* Denotes equal contributions\n.\nCC-BY-NC-ND 4.0 International license\nnot peer-reviewed) is the author/funder. It is made available under a\nThe copyright holder for this preprint (which was\n.\ndoi:"
}