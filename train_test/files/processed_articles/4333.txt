{
    "abstract": "Abstract\nThis article attempts to question modes of sharing and watching to rethink political subjectivity beyond that which is\nenabled and enforced by the current data regime. It identifies and examines a `shareveillant' subjectivity: a form config-\nured by the sharing and watching that subjects have to withstand and enact in the contemporary data assemblage.\nLooking at government open and closed data as case studies, this article demonstrates how `shareveillance' produces an\nanti-political role for the public. In describing shareveillance as, after Jacques Rancie\n`re, a distribution of the (digital)\nsensible, this article posits a politico-ethical injunction to cut into the share and flow of data in order to arrange a more\nenabling assemblage of data and its affects. In order to interrupt shareveillance, this article borrows a concept from\nE\n\u00b4douard Glissant and his concern with raced otherness to imagine what a `right to opacity' might mean in the digital\ncontext. To assert this right is not to endorse the individual subject in her sovereignty and solitude, but rather to imagine\na collective political subjectivity and relationality according to the important question of what it means to `share well'\nbeyond the veillant expectations of the state.\n",
    "reduced_content": "Original Research Article\nShareveillance: Subjectivity between open\nand closed data\nClare Birchall\n Keywords\nSharing, secrecy, opacity, transparency, subjectivity, distribution\nTwo questions dominate current debates at the inter-\nsection of privacy, governance, security, and transpar-\nency: How much, and what kind of data should citizens\nhave to share with surveillant states? And: How much\ndata from government departments should states share\nwith citizens? Yet, these issues are rarely expressed in\nterms of `sharing' in the way that I will be doing in this\narticle. More often, when thought in tandem with the\ndigital, `sharing' is used in reference to either free trials\nof software (`shareware'); the practice of peer-to-peer\nfile sharing; platforms that facilitate the pooling, bor-\nrowing, swapping, renting, or selling of resources,\nskills, and assets that have come to be known as the\n`sharing economy'; or the business of linking and liking\non social media, which invites us to share our feelings,\npreferences, thoughts, interests, photographs, articles,\nand web links. Sharing in the digital context has been\nframed as a form of exchange, then, but also commu-\nIn order to understand the politics of open and\nopaque government data practices, which either share\nwith citizens or ask citizens to share, I will extend exist-\ning commentaries on the distributive qualities of shar-\ning by drawing on Jacques Rancie\n` re's notion of the\n`distribution of the sensible' (2004a) \u00ad a settlement\nthat determines what is visible, audible, sayable,\nknowable and what share or role we each have within\nit. In the process, I articulate `sharing' with `veillance'\n(veiller `to watch' is from the Latin vigilare, from vigil,\n`watchful') to turn the focus from prevalent ways of\nunderstanding digital sharing towards a form of con-\ntemporary subjectivity. What I call `shareveillance' \u00ad a\nstate in which we are always already sharing; indeed, in\nwhich any relationship with data is only made possible\nthrough a conditional idea of sharing \u00ad produces an\nEnglish Department, King's College London, London, UK\nCorresponding author:\nClare Birchall, English Department, King's College London, Virginia Woolf\nBuilding, 22 Kingsway, London WC2B 6LE, UK.\nEmail: Clare.birchall@kcl.ac.uk\nBig Data & Society\nReprints and permissions:\nsagepub.com/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons Attribution-\nNonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use, reproduction\nand distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nanti-politicised public caught between different data\npractices.\nI will argue that both open and opaque government\ndata initiatives involve, albeit differently pitched, forms\nof sharing and veillance. Government practices that\nshare data with citizens involve veillance because they\ncall on citizens to monitor and act upon that data \u00ad we\nare envisioned (`veiled' and hailed) as auditing and\nentrepreneurial subjects. Citizens have to monitor\nthe state's data, that is, or they are expected to innovate\nwith it and make it profitable. Data sharing therefore\napportions responsibility without power. It watches\ncitizens watching the state, delimiting the ways in\nwhich citizens can engage with that data and, therefore,\nthe scope of the political per se.\nOpaque government data practices (practices that we\ncannot see through, that are not readily knowable),\nsuch as those enacted by the NSA and GCHQ via\nthe PRISM, TEMPORA, and XKeyscore surveillance\nprograms as revealed by Edward Snowden, produce\n`closed' data. The main point about closed data in\nrelation to the state (and it is important to note at\nthe outset that the details would be different for com-\nmercial enterprises) is that it is withheld from general\naccess and circulation for reasons concerned with dip-\nlomacy, stability, power play, or security.1 Despite the\nsense of restriction, claim, and withholding here,\nopaque government data practices still involve sharing,\nhowever, not least because they require citizens to\n(often unknowingly) `share' data with the veillant\nstate in a way that renders them visible and trackable.\nBut we should not think of the positions carved out\nfor citizens in each configuration as an oscillation\nbetween agency and impotence. Nor is it quite right\nto think of this as the `equiveillance' diagnosed\nby Steve Mann (2013) \u00ad an evenly poised balance\nbetween surveillant and sousveillant forces. Rather,\nshareveillance constitutes the anti-politicised role the\ndatafied neoliberal security state imagines for its\npublic; the latter is configured more as either a flat\ndataset or a series of individual auditor\u00adentrepreneurs\nthan as a force with political potential. For those of us\nunhappy with the political realm being delimited and\npolitics disavowed in this way, we will need to experi-\nment with ways to interrupt shareveillent subjectivity.\nA radical critique of ubiquitous and default `sharing'\nin the digital context is clearly necessary, but I also\nwant to seek out opportunities to salvage this concept\nin order to imagine a collective political subjectivity\nthat could emerge from within this socio-technical\nmoment (rather than pitching one against it). In this\narticle, then, I will propose that we can interrupt share-\nveillant subjectivity by claiming not a right to access\nmore data or a right to privacy, but a `right to opacity'\n(Glissant, 1997). In the context of shareveillance,\nI am imagining this right as the demand not to be\nreduced to, and interact with, data in ways delimited\nby the state; to resist the terms of engagement set by\nthe two faces of shareveillance (i.e., sharing data with\nthe state and monitoring that shared data). In order\nto make this argument, I will appropriate the term\n`sharing' by calling on the etymological roots of `to\nshare' \u00ad particularly the Old English for `portion'\n(scearu) which points towards a cutting, shearing, a\npart, or division. I will posit a right to opacity that\ncuts into and apart veillant formations and data distri-\nbutions through various tactics such as hacking, data\nobfuscation, decentralisation, encryption, anonymity,\nand anarchic algorithms. Accepting shareveillance\nmeans accepting a `distribution of the sensible' that is\nnot based on equality, necessitating a different, more\nethical distribution, cut, or share by way of a response\non our part. Exploring a right to opacity in the face of\nshareveillance can politicise the concept of `sharing' by\nenvisioning it as an equitable, ethical cut.\nSharing digitally\nToday, sharing with regard to the digital conjures\nup the range of platforms and apps that facilitate the\nharnessing of surplus time, skills, goods, and capacities\nknown as the sharing economy. But this is only the\nlatest incarnation of sharing's articulation within the\ndigital context. Nicholas John (2013) lobbied for shar-\ning to be considered as a keyword for understanding\ndigital culture, in the tradition of Raymond Williams\n(1976). Subsequently, `sharing' is included in Culture\nDigitally's `Digital Keywords'.2 John's contribution to\nthat project mentions sharing in terms of three exam-\nples (2014). First, he calls on computer time-sharing,\nwhich was developed during the late 1950s and early\n1960s to make efficient use of expensive processor\ntime. Second, John includes file sharing, which\ninformed the U.S. Department of Defense's develop-\nment of ARPAnet, and was strengthened by the intro-\nduction of Transmission Control Protocol/Internet\nProtocol (TCP/IP) in 1973 based on the network guid-\ning packets to their destination. Subsequent protocols\nsuch as Hypertext Transfer Protocol (HTTP) and\nSimple Mail Transfer Protocol develop the concept\nthat networks can facilitate direct connections and\ntransfers between hosts. Recent peer-to-peer file-shar-\ning techniques present the latest evolution of such logic\n(see Johnson et al., 2008: 2). Third, John mentions `data\nsharing' as the term that has, after Snowden, come to\ndenote the simple transportation of data. Though all\nthree of these make an appearance, John chooses to\nfocus on a fourth instance: one embedded in the logic\nof web 2.0. In this discussion, he turns to the way in\nwhich social networking sites have appropriated the\n2 Big Data & Society\nterm `sharing' to refer to the imperative and logic of\ncommunication and distribution. Because posting, link-\ning, and liking are all termed `sharing' on social net-\nworking sites, John claims that, in effect, `[s]haring is\nthe fundamental and constitutive activity of Web 2.0'\nIn addition to acting in the service of communica-\ntion, sharing data also has to be understood as a form\nof distribution. Human and non-human actors are\ninvolved in the dissemination of data, documents,\nphotos, web links, feelings, and news across space and\ntime. Such an obvious point is worth making because it\nallows us to think beyond the dominant, morally\ninflected imperative to share or connect with others in\na network through a confessional-communicative style,\ntowards circulation in a purely spatial sense (albeit one\nwith ethico-political implications). It might be useful\nhere to think about such a process as one of spatial\ndifferentiation \u00ad a term borrowed from economics\nthat refers to the uneven dispersal of resources,\ngoods, and services. Differences in natural and human\nresources lead to inequitable access to inputs and out-\nputs. I want to retain this inflection \u00ad of inequality,\ndisparity \u00ad with the intention that it will open the\nway for a broader discussion of the politics or ethics\nof (data) veillance, distribution, and sharing, in the con-\ntext of the state rather than private platforms, in the\nnext section.\nDistribution of the (digital) sensible\nWhereas John's use of the term `distribution' points\ntowards the act of disseminating photos, files, videos,\nin the lexicon of Jacques Rancie\n` re. Rancie\n` re's Le\nPartage du Sensible is translated as a sharing, partition,\ndivision, and, more commonly, distribution of the sens-\nible. This distribution of the sensible is an aesthetico-\npolitical settlement. It is, in Rancie\n` re's words:\na delimitation of spaces and times, of the visible and the\ninvisible, of speech and noise, that simultaneously\ndetermines the place and the stakes of politics as a\nform of experience. Politics revolves around what is\nseen and what can be said about it, around who has\nthe ability to see and the talent to speak, around the\nproperties of spaces and the possibilities of time.\nAesthetics for Rancie\n` re is a distributive regime deter-\nmining what action, reaction, and thought is possible in\nany given situation. It is political precisely because in\nevery `distribution of the sensible' equality is either\nundermined or affirmed. A distribution determines\n`those who have a part in the community of citizens'\n(Rancie\n` re, 2004a: 7); it `reveals who can have a share in\nwhat is common to the community based on what they\ndo and on the time and space in which this activity\nis performed [my emphasis]' (Rancie\nEquality is enacted when those without part, the unrep-\nresented, come to take part; those without a share, have\na share. In a process of subjectivisation,3 this involves\nrefuting the subject position one is allocated by the\nsystem, and finding a position, as well as a name or\nidentity-in-relation that will enable full participation\nand recognition \u00ad akin to the work the term `proletar-\niat' once performed (Rancie\nof politics based on equality, then, is when demands\nfor a new division and sharing of the social whole\nare granted.\nSuch a conception can be helpful in the context of\nopen and opaque government digital data practices,\nand the shareveillant subjectivity that connects them\n(which I will come to below). It makes sense today to\ninclude digital data in an understanding of the sensible\n(that which can be seen, heard, touched, thought). Its\navailability to a subject's veillent capacities or range,\nand the conditions of its visibility (to whom, in which\ncircumstances, to what ends) are usefully thought as\npart of a particular distribution. In any encounter, we\ncan ask: `Who has a share of the data?' and `What kind\nof subjectivity is made more likely as a result of that\ndivision and/or access?' Before turning to discuss these\nquestions in terms of open and opaque government\ndata practices in more detail, I want to pause on the\nlogic of sharing as it pertains to the digital in general,\nfor through this I hope to demonstrate a technological\nunderpinning to the rise of shareveillance.\nSharing as protocological condition\nReturning to John's claim that `Sharing is the funda-\nit is important to note that later, he goes further.\n`It could even be argued that [. . .] the entire internet\nis fundamentally a sharing technology' (179), he\nwrites, citing the importance of open source software\nand programming languages and sharing economies of\nproduction, in the development of websites based on\nuser-generated content. Likewise, Engin Isin and\nEvelyn Ruppert claim that `the ubiquity of various\nuses of digital trances has made data sharing the\nthe emphasis of John's assertion to suggest that sharing\ncan be conceived as the constitutive logic of the\nInternet. Rather than focusing on what users do on\nthe Internet, then, I want to focus more on the idea\nthat sharing operates at a protocological level. My\nuse of this term here draws on Alexander Galloway's\nexposition of computer protocols as standards that\nBirchall 3\n`govern how specific technologies are agreed to,\nadopted, implemented, and ultimately used by people\nThis is not intended as a utopian celebration of the\nInternet's open, or free, origins. Galloway, among\nothers, makes the error of such an assumption clear,\nas he characterises the Internet as a technology marked\nby control and hierarchies of enclosure. Rather, in\npositing sharing as protocological, I want to imply\nsimply that the Internet's grain is, first and foremost,\n`stateless' in the sense that programming intends: as a\nlack of stored inputs. In other words, the basic archi-\ntecture of the Internet does not automatically keep a\nrecord of previous interactions, and so each interaction\nrequest is handled based only on the information that\naccompanies it. For example, the Internet's fundamen-\ntal method for sending data between computers,\nIP, works by sending small chunks of data, `packets',\nthat travel independently of each other. These discrete\npackets are put together at an upper layer, by TCP, yet\nIP itself operates without state. We can also look to\nhow the Web's HTTP serves up requested pages but\ndoes not `remember' those requests. Such discrete com-\nmunications mean that no continuity is recorded.\nAs Tom Armitage points out, because the Internet's\ndefault architecture is open or stateless, it is very good\nat sharing, but not so good at privacy and ownership.4\nBy this, he simply means that `implementing state, or\nprivacy, or ownership, or a pay wall, is effort'.5 State is\na secondary level, patched onto a stateless system. This\nis categorically not to say that the development and\ndesign of the Internet was free from a proprietary\nimpetus, nor that `default' architecture is not conscious\nand intentional; but rather that to refrain from connect-\ning, and thus in a certain sense, sharing with any net-\nwork or user at all, at a purely technical level, is\nsomething that has to be introduced in secondary\nlayers and mechanisms. It also follows that tracking a\nuser's activity has to be imposed at a secondary level.\nNetscape, for example, introduced the cookie \u00ad a by-\nnow ubiquitous text file that stores small amounts of\ndata associated with a domain. For as long as the\ncookie has not expired, it will track the pages a user\nvisits and help build a user profile (see Elmer, 2003).\nIn its stateless formations, before the `effort' to impose\nstatefulness, the Internet, then, can be conceptualised as\na technology of stateless, borderless, always already\nsharing. I want to suggest that sharing (without track-\ning or remembering) in this instance is a rule condition-\ning the possibility of computers communicating with\neach other at all.\nHowever, introducing state, tracking user's\nonline movements, say, foregrounds a different kind\nof `sharing' \u00ad no longer one concerned with open\nand non-accumulative peer-to-peer communication,\nbut rather a `sharing' of the journey, searches, and\ndata transfers from one IP address or an individual\nuser with the web publisher and, often, third parties.\nIndeed, tech companies like Facebook and Google use\nthe word `sharing' when referring to the monetisation\nPrivacy Policy following its acquisition by Facebook,\nfor example, there is a section entitled `Sharing of your\nInformation'.6\nThis links protocol and profits. Illegal and legal\nentities want a share of our data. This would include\nhackers should our data be interesting or profitable\nenough, able to overcome any data loss prevention\nsoftware and systems from firewalls to encryption. It\nwould also include trackers utilised by web publishers,\nsuch as Doubleclick, that log the data we create\nthrough our online activity to customise service and\nadvertising and sell it to third parties. Such trackers\ndo not often announce themselves to us unless we seek\nthem out through anti-tracking browser extensions\n(like Ghostery) or forensic examination of user agree-\nments (which still do not list specific trackers used).\nMany websites have multiple trackers \u00ad cookies and\nbeacons. Ironically, even website publishers that\nemploy trackers are themselves subject to `data leak-\nage' which `occurs when a brand, agency or ad tech\ncompany collects data about a website's audience and\nsubsequently uses that data without the initial pub-\nlisher's permission' (McDermott, 2015). Such secre-\ntions, the unintentional `sharing' of already `shared'\ndata, also highlight the difficulties of not-sharing from\na different perspective.\nThe idea of sharing as protocological is posited here\nto emphasise the fact that specific modes of sharing and\nnot-sharing, as well as the particular distribution of the\n(data) sensible, are determined by ideologically charged\ndispositifs. As Galloway puts it: `protocol is how\ntechnological control exists after decentralisation'\n(2004: 8). Crucially, the conditions of sharing/not shar-\ning today inflect a subjectivity that makes a particular\ncall upon, and imposes a limitation to, the veillant and\nagential capacities of citizens.\nThe sharing assemblage\nDepending on our politics, we will be more or less\nresistant to the sharing of our data in exchange for\nsecurity; depending on our willingness and time to\nread the clauses in different privacy policies, we might\nbe more or less cognizant of what it is, exactly, we are\nsharing with private corporations; depending on how\nmuch attention we paid to the details of the Snowden\nrevelations, we will have greater or lesser understanding\nof the ways in which our communications and move-\nments can be monitored by the state. Regardless of the\n4 Big Data & Society\ndifferentials in knowledge and politics, sharing, I want\nto argue, has to be understood today not as a conscious\nand conscientious act but as a key component of con-\ntemporary data subjectivity.\nData does not unproblematically belong to us in the\nfirst place in order for it then to be `shared'. Rather,\nwe are within a dynamic sharing assemblage: always\nalready sharing data with human or non-human\nagents. I want to identify an ascendant shareveillant\nsubjectivity that is shaped by the play between openness\nand enclosure. `Shareveillance' is intended to capture\nthe condition of consuming shared data and producing\ndata to be shared in ways that produce a subject who is\nat once surveillant and surveilled. To phrase it with a\nslightly different emphasis: the subject of shareveillance\nis one who simultaneously works with data and on\nwhom the data works.\nSharing prevails as a standard of the system because\nof the difficulties of un-sharing data and `effort' of safe-\nguarding or rendering data proprietary. To take the\nfirst of these, it is clear that the ease and speed of copy-\ning digital data means that data already in circulation\ncannot be revoked. Moreover, in the case of cloud stor-\nage, or even back-ups to hard drives, replication of data\nis the default. More than one copy of files often exists\non a hard drive, let alone in different storage facilities.\nIt is also pertinent to point out that it makes little sense\nto talk about an `original' when it comes to digital data,\nthe consequence of which is that data is non-rivalrous\nand thus sharing non-depleting. We could also look to\nthe way in which the use and re-use of different datasets\nfor various applications makes it nonsensical to talk\nabout the un-sharing of data: once it is the life-blood\nof various apps, bringing oxygen to a new economy, it\nis being shared in multiple directions through various\nmedia. We can detect, then, a propensity towards dupli-\ncation, secretion, circulation, and sharing.\nWhile I have pointed towards a distribution of the\ndigital sensible that would encompass private and\npublic, national and transnational entities, for the\nremainder of this article, I want to focus on the ways\nin which state forms of `open' and `closed' data feed\ninto such a distribution.\nOpen and closed government data\nIt is important to note from the outset that the labels\n`open' and `closed' are not essential, but relational,\nadhering to particular moments in space and time.\nWhen articulated to data, the identity of each, and\nthe binary opposition itself, are contingent upon the\npolitical climate, the market, the security complex,\ntechnological capacities, and the veillant conjuncture.\nThe tendency towards secretion identified above should\nbe enough to indicate the provisional nature of any\nidentification of data as `closed'. Likewise, because of\nthe inherently opaque nature of much `open' data\n(which leaves many questions unanswered \u00ad such as\nfor whom was this data collected? To what ends?),\n`open' data is never simply open or transparent.\nOpen government data is generally understood as\nthe provision of big and small digital data on the\npart of government agencies. Readers of this journal\nwill know that alongside a few critical voices, open\ngovernment data is celebrated in the mainstream for\ndemocratising knowledge distribution and research,\ninvigorating economies, increasing efficiency, ensuring\naccountability, and operating as a key element in digital\ndemocracy or `democracy 2.0' (e.g., Goldstein and\nDyson, 2013). Open government data is data shared\nwith no depletion: sharing not in the sense of division,\nbut giving multiple citizens access to the same thing.\nBy contrast, we can understand closed government\ndata as that data which is withheld from public view,\nwhether in the interests of privacy, diplomacy, or\nnational security. As `close' brings forth etymological\nassociations from the old French clore `to shut, to cut\noff from', we can see how citizens are cut off from the\nstate's data, even data they have (perhaps unknow-\ningly) shared. In sharing this kind of data, we have in\neffect given it away. Our `share' can never yield. That is\nto say, without the interventions of whistleblowers or\nhackers, closed government data will never be given the\nopportunity to be put to uses other than those deter-\nmined appropriate by the state.\nIn its open formation, government data is deliber-\nately and strategically shared by the collecting agent; in\nits closed formation, data is deliberately and strategic-\nally not shared. With respect to closed data, particu-\nlarly in the case of state surveillance, citizens share data\nwith a proprietary agent in exchange for the privileges\nthat come with citizenship. We might, that is, con-\nsciously or unconsciously, explicitly or implicitly con-\nsider the collection of our GPS data or phone metadata\na fair price to pay for the freedoms, benefits, and pro-\ntections that come with owning a British (or Australian,\nGerman, American, etc.) passport.\nThis pragmatic attitude to sharing with respect to\nclosed data, the transmission of citizens' activity to a\nveillant other, is echoed in the experience of digital con-\nsumers in general. That is to say, users of social media\nand search engines are familiar with making trade-offs\nbetween services they want and acquiescence to data\ncollection. As well as protocological in a technological\nsense, then, sharing also needs to be thought as a pol-\nitical, cultural, and industry standard. That is to say, it\n`frame[s] the terms and parameters by which elements\nof a system interact and behave' (McStay, 2014: 5).\nAs I state above, sharing is not something we do\nafter possessing data, but is the basis on which having\nBirchall 5\nany relation with that data can be possible at all. All of\nwhich does not necessarily indicate that the data we\nhave shared is digested and absorbed, and immediately\nput to work by any surveillant agent. Rather, to borrow\nthe words of Gus Hunt, the CIA's Chief Technology\nOfficer, it indicates that `collect[ing] everything and\nhang[ing] on to it forever' (see Ingram, 2013) relies on\nthe idea that the archive is `structurally speculative'\n(Andrejevic and Gates, 2014). The uses to which\ncollected data will be put and the meanings it will be\ngiven are dependent on future algorithms and political\nconcerns. This means that in a networked era, we are\nalways already sharing without any actor in the system\nnecessarily knowing precisely why. The principle of\nsharing overrides any uncertainty over the uses to\nwhich shared data can be put. Such a condition is obvi-\nously in the interests of commercial and state surveil-\nlance that, in general, currently have monopolies on\naccruing economic or security value from big, aggre-\ngated archives of data.7\nWhile it might seem as though closed government\ndata is open data's evil twin, open government data is\nnot excluded from this veillant assemblage. All shared\ndata mobilises a politics of visibility, a demand to align\nwith a political and ethical distribution of the digital\nsensible. While the imperative may not be as strong\nwhen compared with the dataveillant capacities of the\nstate, open government data initiatives, about which\nI will provide more detail below, also involve veillance\nbecause the sharing of data includes a call to watch and\nact upon that data \u00ad we are envisioned, watched, ima-\ngined as entrepreneurial and auditing viewers or sub-\njects. Within a logic of shareveillance, both closed and\nopen data contribute to the construction of an anti-\npoliticised data subject and public. The next section\nwill consider how shareveillant subjectivity is produced\nin the context of the state rather than commercial prac-\ntices (though obviously this distinction is undermined\nby the interdependence between some governments and\ntech companies as well as the ways those companies can\nsometimes challenge, exceed, transcend, or evade\nnation state legislation) by looking at two instanti-\nations: the national security dataveillance revealed by\nEdward Snowden, and the open government data ini-\ntiatives implemented by the UK government.\n`Closed' data; securitised veillance\nThe data collected by the NSA, GCHQ, and other\nsecurity agencies around the globe is mostly experi-\nenced as `closed': inaccessible to those without security\nclearance. Before Snowden revealed the programs\nimplemented to collect communications data and meta-\ndata \u00ad programs such as PRISM, which, since 2007,\npermitted the NSA to access data from service\nproviders, and Tempora, which saw GCHQ placing\ninterceptors on fibre-optic cables that handle Internet\ntraffic in and out of the UK \u00ad the programs, too, were\nclosed, secret, opaque. That is not to say that there were\nnot all kinds of secretions regarding those practices:\ndetails or speculations erupting now and again into\nthe public sphere through reportage, whistleblowing,\nor popular cultural representation (what Tim Melley\nrefers to as `the covert sphere' [2012]). Rather than\nfocus on the content of the revelations and whether\nsuch news really was new, however, what I am inter-\nested in is the conceptual apparatus that was available\nto those who wanted to resist or challenge this aspect of\nthe shareveillant assemblage.\nThough domestic protests were subdued, calls to end\nthe NSA's activities, as evidenced on the banners held\nat the march on Washington in October 2013, were\nexpressed as an `end to mass spying'.8 Exercising peo-\nple's imaginations and offending their constitutional\nrights, was the suggestion that their own government\nhad the ability to see them and their actions with-\nout their knowledge or explicit consent. While many\nwould agree that this move towards ubiquitous com-\nmunications surveillance is, indeed, something to resist,\nthe appeal to `privacy' falls rather flat. Privacy is like\nthe light we see from an already dead star. We cling to\nit even though we live in what our digital conjuncture\nhas essentially rendered a post-privacy paradigm. This\ndoes not mean that the concept of privacy is no longer\nimportant: it still organises legal processes, rights-based\ndebate, and common understandings of our own sense\nof self. In some ways, as Andy McStay points out:\nmany social changes since the industrial revolution\ninvolve a net increase in privacy, be this less familiarity\nwith our neighbours, more geographically dispersed\nfamily arrangements, working away from home,\nweakening of religious authority [. . .] greater possibility\nof children having their own bedrooms, increase in car\nYet, the risk of still appealing to privacy in an era of\nubiquitous dataveillance and closed, securitised data, is\nthat it reduces rather than increases political agency\nprecisely because it misunderstands the subjectivity in\nquestion and because privacy claims are particularly\nweak when it comes to collective politics. It cannot\nredistribute the digital sensible.\nTo take the first of these issues, the appeal to privacy\nin the wake of the Snowden revelations misreads the de-\nindividualising character of mass covert data mining.\nThe fear expressed on the banners and placards of the\npoorly attended protests is that the state sees the crowd\nas individuals; a mass that is made up of many `I's, the\nprivacy each of which has been infringed. The concept\n6 Big Data & Society\nof privacy imagines a state violating the rights of a fully\nself-present liberal citizen. But the way in which data\nmining works means that it is not particularly inter-\nested in the actions of individual citizens except in as\nmuch as those citizens are data subjects: how they con-\ntribute to a background pattern upon which an evolu-\ntionary algorithm can work to recognise minority\nanomalies. As Clough et al. write:\nIn the case of personal data, it is not the details of that\ndata or a single digital trail that is important, but\nrather the relationship of the emergent attributes of\ndigital trails en masse that allows for both the broadly\nsweeping and the particularized modes of affective\nmeasure and control. Big data doesn't care about\n``you'' so much as the bits of seemingly random info\nthat bodies generate or that they leave as a data\nNova Spivack, in an article infused with techno-\nutopianism, puts it slightly differently: `We are noise,\nnot signal' (2013). While implicitly conflating transpar-\nency and surveillance, Spivack invokes this argument to\nexcuse the NSA's data scraping: aligned with the\ncommon mantra that if you have done nothing\nwrong, you have nothing to fear from surveillance.\nIt also points towards our delimited role within the\nshareveillant assemblage read from the perspective of\nclosed data.\nThe offence, I suggest, is less the intrusion into\npersonal space and more the anti-political act of only\nimagining the public as an aggregated dataset. It is not\nthat citizens are being spied on that is of most concern\nin this view, but that unless their actions are flagged\nup as extreme outliers, they are not considered\nfully formed political agents worthy of anything more\nthan bolstering an algorithm for data analysis. Rather\nthan being of comfort, the fact that citizens only count\nin terms of their role as flat data has an effect on\nthe scope of political agency (even if this is only an\nimagined agency), and the possibilities therein\nthat this implies for effective, counter-hegemonic col-\nlective action. The political is effectively disavowed by\nshareveillance.\nTo take the second critique of privacy \u00ad that it is a\nweak foundation on which to build collective action \u00ad it\nis one not tied to the digital/Big Data turn, but it is\nnevertheless a critique that has been given a new inflec-\ntion within that context. Privacy has been subject to\ncritique from the Left for its connections with individu-\nalism, the perpetuation of oppression, and property. To\ncall on the right to privacy is to frame the debate in\nterms of an individual's right to limit the access other\npeople, the state, or commercial entities might have to\nher `content' (data, thoughts, feelings, information,\ncommunications) at any time. It reinforces a sense of\na self that lives in political isolation. Therefore, even\nwhen people coalesce around privacy concerns, step\ninto the light of the demos, they do so in order to\ninsist on their right to step back into the apolitical\nshadows of individualism, away from the possibility\nof collective creativity or an identity-in-common.\nIn short, privacy claims are ill-equipped to funda-\nmentally challenge the dataveillance being conducted\nand its essentially uni-directional sharing of informa-\ntion that contributes to the shareveillant subjectivity I\nam outlining. But closed data and opaque data prac-\ntices are only one half of the story.\nOpen data\nThe provision of open data is a professed concern and\ncommitment for many liberal democracies today.9 The\nUK's open government data portal, data.gov.uk, is\nexemplary in this regard, providing public access to\nmany different datasets produced by government agen-\ncies.10 There are many reasons to applaud transparency\nmeasures such as this, especially when compared with\nclosed regimes in which extreme forms of corruption\nare endemic. And yet, this might be an inflammatory\ncomparison, or at least a false construction of the issue.\nFor within ostensibly `open' liberal democracies, we\nmust ask which forms of openness take precedence in\nany particular era, and what kind of subjectivities do\nthey produce. Regions wishing to make the move\ntowards more open forms of society and state often\nlook to those dispositifs already in operation elsewhere\nand thus forms of openness, and the political settle-\nments they compound, travel.\nIn sharing its datasets with citizens, the state adds\nto the interpellation of shareveillant subjects. `Hey,\nthere! Come closer and watch'. The subject not only\nturns to be seen, but also to become vigilant. The\nshareveillant subject is surveilled (possibly without\nher knowledge, given all I have said regarding data-\nveillance), but also has to be seen to be seeing. More\naccurately, the shareveillant subject is asked to see\nthrough: the transparency of the state is the interface\nthat hails us and we cannot but occupy the position\n(whether we feel technically capable or not, whether\nwe perform the function or not) of auditor, analyst,\nwitness. In the process, a characteristic of neoliberal\nlogic is performed: the subject is bequeathed responsi-\nbility without power. She is given the responsibility to\nwatch without the expertise to know what to look for,\nnor the power to act in a meaningful way on what\nmight be found. As Isin and Ruppert recognise, `acts\nof sharing place unique demands on citizen subjects of\nBirchall 7\nThe unique demand is not only to look, for even\nwhile this call to be vigilant is made, the reach widens\nto draw in unelected mediators: app developers, data\nvisualisers, etc. Data entrepreneurs step into the ideo-\nlogical call to help fulfil the demand to watch, to see\n(through) the state. The `datapreneurs' happily perform\nthis function and are also responding to a hailing: to\nhelp operationalise the new `data economy'. This is\nbecause the provision of open government data is\nfuelled not only by its purported social value, but also\nits economic value. In an attempt to stimulate and sup-\nport activity in this economy, governments of devel-\noped and developing nations promote and sponsor\n`app-jams' and `datapaloozas'. The `datapreneur' is\nthe key figure in the success of the open data economy,\nas the actor who must harness the potential of the data\nto create value from raw datasets. For the state and\ndatapreneur alike, data is configured as a resource\nripe for mining and commodification.\nWhere does this leave the shareveillant subject? At\nonce asked to watch the newly transparent state, with\nall its data organs on display, and to rely on the med-\niating and translating functions of a datapreneur to do\nso, this subject is one whose relationship to government\nis shaped by the market. Neoliberal `capitalist realism'\n(Fisher, 2009) has long ensured the public acquiescence\nto and accommodation of the marketisation of many\naspects of social and political life, from education to\nhealth. What is new here is that the market gets to\ndecide the very stakes of the political. I am arguing\nthat the reliance upon data mediators or datapreneurs\nto make the transparency of the state meaningful and\nlegible means that the market decides the distribution\nof the sensible \u00ad what we can know, see, hear, touch,\nencounter. In terms of sharing, only those government\nopen datasets that can be made to yield profit (in some\nform) will be translated by datapreneurs in formats that\nnon-specialist citizens can receive, understand, and\nact upon.\nThe shareveillant subject is required to be vigilant in\norder to be an engaged citizen. Immediately, however,\nthis impossible vigilance of the open state is acknowl-\nedged, and mediators are called upon to select and\npackage information. This means that vigilance is\nalways watchfulness not of the fully transparent state,\nbut of selected mediations brought forth. Transparency\nis obscured by its own impossible glare \u00ad only the\ndata that the market has primed us to want (usually\ndata that can help us make apparently `informed'\nchoices in a complex public\u00adprivate landscape)\nassume the face of state transparency in the data econ-\nomy. The risk is that it becomes increasingly difficult\nto participate in and navigate the state outside of\nthese commodified, shaped, and edited forms of aggre-\ngated data.\nInterrupting shareveillance: New cuts\nThe shareveillent subject, then, is rendered politically\nimpotent from (at least) two, not necessarily distinct,\ndirections. In the face of state and consumer dataveil-\nlance, the subject's choices (whether that be with whom\nto communicate or what to buy) are compulsorily\nshared to contribute to an evolving algorithm to\nmake advertising, say, or governmentality, more effi-\ncient, targeted, precise. The public is configured as\nrich Big Data rather than a network of singularities\nwith resistant potential. Open government portals\nshare the state's data with subjects and, in doing so,\nresponsibilise and isolate individuals and thus disavow\nthe legitimacy of collective power. In addition, this\nform of accountability produces a limited relation\nwith the information provided. In monitoring the\ngranular transactions of government \u00ad in the form of\nUK MPs expenses, for example, now available after the\nscandal of 2009 at www.mpsallowance.parliament.uk \u00ad\nthe armchair auditor is only permitted to spot anoma-\nlies or aberrations in a system she has to otherwise\nacknowledge as fair. This form of sharing, of openness,\nanticipates a limited form of engagement and response.\nAnd, as I have outlined above, even this armchair audi-\ntor able to engage with `raw' data is largely a fiction\nproduced by the rhetoric of open government; the cru-\ncial role that datapreneurs and app developers play in\nmediating data means that the state's sharing and the\nsubject's share of the state are subject to market forces.\nI want to be clear that I am not imagining a once\nfully agential, self-present, sovereign political subject\nwho has now been supplanted by this shareveillant ver-\nsion, compromised by marketised, securitised, and neo-\nliberal apparatus such as algorithmic governmentality\nand open data portals. Political agency (and presence\nand sovereignty) has always been limited by structural\nand relational conditions as well as the fluidity, frag-\nmentation, or fracture of psyches and subjectivities\nidentified by discourses from psychoanalysis to decon-\nstruction. Nevertheless, it is important to recognise the\nparticular discursive-material conditions that curtail\npolitical agency \u00ad render it beside the point, undesir-\nable, unnecessary \u00ad alongside those other inescapable\nmetaphysical limitations. For it is from here that we\ncan more fully understand the particular distribution\nwe are faced with.\nIt is one thing, of course, to diagnose a condition,\nand quite another to prescribe a remedy. If one accepts\nthat shareveillance supports a political settlement not\nconducive to radical equality, and that a more equitable\ndistribution is something to strive for, how might share-\nveillance be interrupted? I would like to offer one pos-\nsible strategy, while recognising that there will be\nothers. The conceptual framework for my interruption\nhinges on the etymology of `share'. From the Old\n8 Big Data & Society\nEnglish, scearu \u00ad `a cutting, shearing, tonsure; a part or\ndivision' \u00ad the root of the meaning of `share' apropos\n`portion', to the term scear, with respect to plowshare,\nmeaning, simply, `that which cuts', cutting clearly res-\nonates within the concept and practice of sharing.\nRather than merely a happy coincidence or useful\ndevice, the fact that a cut lies at the heart of sharing\nattunes us to the `violence' of any distribution.\nThis focus is certainly supported by Rancie\n` re's fram-\ning of the distribution of the sensible, at least in certain\ntranslations:\nI understand by this phrase the cutting up [decoupage]\nof the perceptual world that anticipates, through its\nsensible evidence, the distribution of shares and social\nparties [. . .] And this redistribution itself presupposes a\ncutting up of what is visible and what is not, of what\ncan be heard and what cannot, of what is noise and\nwhat is speech. (Rancie\nWhat share we have of resources, as well as the mode\nof sharing, fall along the lines of a particular distribu-\ntion or cut. The way we share, the conditions and deci-\nsions underlying how and what we share, what I am\ncalling the `cut', create a certain distribution. As well as\nthe appearance of cutting in the etymology of `share',\nI am also mindful of Sarah Kember and Joanna\nZylinska's productive use of it in Life After New\nMedia (2012). Thinking about mediation as a `complex\nand hybrid process' that is `all-encompassing and indi-\nvisible' (Kember and Zylinksa, 2012: xv), the authors\ndraw on a range of thinkers from Henri Bergson to\nKaren Barad and Jacques Derrida to Emmanuel\nLevinas, to imagine cuts (into the temporality of medi-\nation) as creative, ethical incisions and decisions. Thus,\nphotography, to take their most potent example, is:\nunderstood here as a process of cutting through the\nflow of mediation on a number of levels: perceptive,\nmaterial, technical, and conceptual. The recurrent\nmoment of the cut \u00ad one we are familiar with not just\nvia photography but also via film making, sculpture,\nwriting, or, indeed, any other technical practice that\ninvolves transforming matter \u00ad is posited here as both\na technique (an ontological entity encapsulating some-\nthing that is, or something that is taking place) and an\nethical imperative (the command: ``Cut!''). (Kember\nThis leads Kember and Zylinska to ask what it\nmeans to `cut well' (2012: xix). It is a question that\nevery artist must ask themselves and practice, they\nargue. This imperative to cut well extends to all acts\nof mediation (any other technical practice that involves\ntransforming matter), including the kinds of practices\nthat mediate data that I engage with in this article.\nObviously, not everyone who works with data is an\n`artist' in the way we would traditionally understand\nthat term. But if we draw on aesthetics in the\nRancie\n` rean sense \u00ad as a distributive regime that deter-\nmines political possibilities \u00ad then we can begin to see\ndifferent decisions being made as to how and when to\ncut into data and what to reveal or conceal about that\ndecision-making process itself, as ethical or unethical.\nWhen we are cut off from our data (as is the case\nwith closed data), we are not given the opportunity to\nmake our own cuts into it. Equally, if the cut of data is\nsuch that we can only engage with it in ways that sup-\nport a political settlement we might not agree with \u00ad if\nwhat might appear as an ethical provision of data in\nfact supports or makes more efficient an unethical\nsystem \u00ad then our cuts are determined with strict par-\nameters. To cut (and therefore share) differently, to cut\nagainst the grain, we have to interrupt the strictures of\nshareveillance.\nThere are many interruptive cuts I could draw on \u00ad\nhacking, decentralisation, encryption, anonymity \u00ad but\nsome of the most interesting can be encapsulated by the\nterm `data obfuscation'. Finn Brunton and Helen\nNissenbaum (2015: 1) identify a number of different\nobfuscation strategies that all demonstrate a `deliberate\naddition of ambiguous, confusing, or misleading infor-\nmation to interfere with surveillance and data collec-\ntion'. In their book, Obfuscation: A User's Guide for\nPrivacy and Protest, Brunton and Nissenbaum consider,\namong other technologies, the Onion Router (TOR),\nwhich allows for online anonymity through a combin-\nation of encrypting communication and relaying it via\nseveral nodes on the Internet to obscure the source and\ndestination; TrackMeNot, a browser extension that\nfloods search engines with random search terms to\nrender algorithms ineffective; and the privacy plug-in,\nFaceCloak, which encrypts genuine information offered\nto Facebook so that it can only be viewed by other\nfriends who also use FaceCloak. Crucially, each inter-\nrupts the idea of sharing as the default.\nAs a particularly decisive cut that utilises obfusca-\ntion, I will briefly outline a project published in 2016 by\nartist Paolo Cirio called `Obscurity'.11 In the US, the\npublication of police photographs, or `mugshots', of\narrestees is legal under Freedom of Information\nand transparency laws in most states. Websites scrape\nmugshots that have been published elsewhere, some-\ntimes on sites belonging to law enforcement entities,\nand republish the photographs, requesting money\nfrom the arrestee to remove the picture and details. In\n`Obscurity', Cirio and his collaborators have developed\na programme to clone and scramble the data available\non mugshot industry websites such as Mugshots.com,\nJustmugshots.com, and MugshotsOnline.com. Using\nBirchall 9\nalmost identical domain names to these sites, Cirio's\nclone sites show hazy faces that are impossible to iden-\ntify and names that have been changed. While Cirio is\nmost concerned with the right to be forgotten, as the\nissue has come to be referred to in the EU after the\nlandmark case in 2014 that ensured search engines\nlike Google are subject to the existing EU data protec-\ntion directive, we can also read this project as one that\nexposes the risks inherent to `sharing' (the risk of abuse\nand exploitation) and the limits and failures of some\ntransparency initiatives. In addition, with the concerns\nof the current article in mind, the mugshot industry can\nbe thought of as aping, cynically and darkly, the work\nundertaken by datapreneurs to transform open data\ninto profitable forms. After all, the websites Cirio is\nprotesting against indeed have an entrepreneurial, cre-\native approach to re-purposing open data.\nBy cutting into shareveillance, Cirio demands that\nincarceration be seen not as a decontextualised, indivi-\ndualised problem, but as a collective, social issue for\nwhich we all have responsibility. The project exposes\nthe unethical cut of shareveillance with respect to a\nparticular socio-political issue: how, in this case, mug-\nshot websites share data in such a way that presents\nincarceration as an asocial issue, while in the process\nperforming a second tier of punishment (shaming and\nextortion) beyond any lawfully imposed penalties. The\nproject asks us to see incarceration in terms of the pol-\nitical economy as well as the stratified and stratifying\nnature of the carceral state. It cuts into this particular\ndistribution in order to share anew. Creative interrup-\ntions of shareveillance can make ethical cuts, and in the\nprocess, show up the cuts/incisions that have con-\nstructed the neoliberal securitised settlement of which\nshareveillant subjectivity is a part.\nAs well as the digital experiments with obfuscation\noutlined above, cutting into or interrupting shareveil-\nlance might include:\n. imagining forms of transparency that do not just\nmake already inequitable systems more efficient;\n. not using the morally inflected language of sharing\nwhen it comes to personal data (see Prainsack,\n2015); it is not always `good' to share;\n. insisting on a right to opacity rather than privacy.\nIn order to help with the last of these, I turn to the\nlate philosopher E\n\u00b4 douard Glissant. In a very different\ncontext to that with which, this article is engaged,\nGlissant coined the term a `right to opacity'. Glissant\nis writing about an ontological condition of minoritar-\nian subjectivity that resists the demand to be knowable,\nunderstood, and transparent in the racialised terms\nalready set by the dominant group. Unlike privacy,\nwhich rests on a subject who, though is knowable in\nprinciple, has chosen to keep certain things from view,\nopacity insists on the irreducible unknowability of the\nsubject. Inspired by this concept, while respecting its\norigins in work on race, a right to opacity in the digital\ncontext would mean the demand not to be reduced to,\nunderstood as, consume, and share data in ways\ndefined by state or consumer shareveillance. Rather\nthan acts of publicity such as legal marches or on-line\npetitions, I want to argue that we need to meet the\npervasive protocols of inequitable dataveillance\nemployed by the securitised state, and the logic of\nshareveillance with forms of illegibility: a reimagined\nopacity that allows for a politicality currently denied\nto subjects to take meaningful forms.\nThe identity of the shareveilled data object/neo-\nliberal data subject cum dataset is not one that is\nallowed to interact with data in the creation or explor-\nation of radical collective politics. A right to opacity\ncould be mobilised in order to refuse the shareveillant\ndistribution of the digital sensible. It might offer an\nopportunity to formulate a politics based not on priv-\nacy, but rather, opacity; which could, in turn, clear the\nway to imagine a community forming openness and\nexchange rather than its shareveillant manifestation.\nIt is not a case of deciding whether to accept open\ndata as a compensation for opaque data collection\npractices and closed data, but of understanding the dif-\nferent ways in which all are part of the shareveillant\nlogic of digital governmentality, and recognising the\nnew epistemological and ontological calls made upon\nshareveillant subjects.\nA right to opacity means, here, the right to refrain\nfrom sharing in, and being understood according to a\nshareveillant distribution we may not support. In this\nre-attunement, we can reimagine closure as opacity and\npoliticise sharing by understanding it as a series of deci-\nsions and cuts. In a conjuncture that places a premium\non the knowability and surveillability of subjects, in\nwhich everyone must share their data, come forth and\nbe understood as data, these experiments and imagina-\ntive cuts become ethical, political acts.\n"
}