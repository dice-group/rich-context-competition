{
    "abstract": "Security for a growing population of elderly adults. We consider an extract of functional disability data from the National Long Term Care Survey (NLTCS) and attempt to develop disability profiles using variations of the Grade of",
    "reduced_content": "The Annals of Applied Statistics\n\u00a9 Institute of Mathematical Statistics, 2007\nUniversity of Washington, Carnegie Mellon University\nand Universit\u00e9 Toulouse 1\n \n \nSecurity for a growing population of elderly adults. We consider an extract of\nfunctional disability data from the National Long Term Care Survey (NLTCS)\nand attempt to develop disability profiles using variations of the Grade of\nMembership (GoM) model. We first describe GoM as an individual-level\nmixture model that allows individuals to have partial membership in several\nmixture components simultaneously. We then prove the equivalence between\nindividual-level and population-level mixture models, and use this property\nto develop a Markov Chain Monte Carlo algorithm for Bayesian estimation\nof the model. We use our approach to analyze functional disability data from\nthe NLTCS.\n1. Introduction.\n1.1. Background. Data on functional disability are of widespread policy in-\nterest in the United States, especially with respect to planning Medicare and So-\ncial Security spending for a growing population of elderly adults. The concept of\nfunctional disability reflects difficulties in performing activities that are considered\nnormal for everyday living. These activities are usually divided into two types,\nnamely, basic and instrumental activities of daily living (ADL and IADL). ADL\nand IADL outcomes are considered essential in health services research and form\na cornerstone of geriatric medicine. In this article we present a Bayesian analy-\nsis of functional disability among a sample of elderly individuals in the National\nLong Term Care Survey (NLTCS), using basic and extended Grade of Membership\n(GoM) models for multivariate binary response data.\nCenter of Statistics and the Social Sciences, University of Washington, under a Seed Grant to Elena\nA. Erosheva.\nSupplementary material available at http://imstat.org/aoas/supplements\nKey words and phrases. Activities of daily living, Bayesian estimation, functional disability,\ngrade of membership, latent class, mixed membership, partial membership, variational approxima-\ntion.\ning it an important source of information on possible changes in disability over\ntime among the elderly Americans. The NLTCS data on functional disability have\nbeen used to generate some major findings, such as a persistent decline in chronic\ndisability among the elderly Americans [Manton and Gu (1999) and Manton, Gu\nIt is common practice to analyze functional disability data by using totals where\nindividual scores are added together for all items or by subsets [Manton and Gu\n(1999)]. Statistically, adherence to the Rasch model (1960) can provide researchers\nwith a formal justification for reducing the multivariate data down to such total\nscores. It is often the case, however, that functional disability data have a high\namount of heterogeneity that is not explainable by the Rasch model. It may be\npossible to circumvent this problem by reducing the set of functional disability\nitems under consideration, as was illustrated, for example, in the gerontology liter-\nature by Spector and Fleishman (1998). This approach, however, obviously ignores\npotentially relevant information contained in the excluded items.\nIn this paper we use individual-level mixtures to account for heterogeneity in\nfunctional disability data measured with a given battery of items without con-\nsidering the issue of item reduction. We contrast the individual-level mixture as-\nsumption with population-level mixture models that assume individuals can be\nmembers of one and only one subpopulation, such as latent class models [Good-\nman (1974), Lazarsfeld and Henry (1968)]. The central idea of all individual-level\nmixture models is to allow an individual's membership to be a mixture with re-\nspect to population components [Blei, Jordan and Ng (2003), Pritchard, Stephens\nindividual-level mixtures is genetic makeup of individuals who have various de-\ngrees of ancestry in several subpopulations of origin [Pritchard, Stephens and Don-\nnelly (2000)]. Such admixed individuals do not simply belong to one of the original\nsubpopulations with some degree of uncertainty, but their genetic makeup is actu-\nally composed of genes that originated from different subpopulations. Specifically,\nwe use the Grade of Membership (GoM) model introduced in 1978 by Woodbury,\nClive and Garson (1978) and develop its extension to address the following ques-\ntions: How many mixture categories are in the functional disability data under the\nassumption of mixed membership? What are characteristics of each mixture cate-\ngory? What is the population distribution of the individual membership scores?\nWe begin by introducing the NLTCS in Section 2. Next, we describe the GoM\nmodel and its relationship to latent class models via the fundamental representa-\ntion theorem in Section 3. We use this result to develop a fully Bayesian approach\nin Section 4.1, and describe a variational approximation approach as an alterna-\ntive estimation method in Section 4.2. Section 5 develops the extended mixture\nGoM model and corresponding estimation techniques. Section 6 considers the\nquestion of dimensionality selection in terms of the optimal number of mixture\ncategories. Section 7 describes results from simulation studies. Finally, we present\nan individual-level mixture analysis of the NLTCS functional disability data and\nprovide discussions in Sections 8 and 9.\n2. National Long Term Care Survey functional disability data. The\nNLTCS aims to assess chronic disability in the U.S. Medicare-enrolled popu-\nwith a screening survey instrument that selected community-dwelling chronically\ndisabled (based on basic and instrumental activities of daily living) persons for\ndetailed in-home interviews. Once individuals screened-in, the NLTCS followed\nthem longitudinally. The second wave of the survey was in 1984, and all subse-\nquent waves occurred in five-year intervals with the most recent wave completed\nin 2004. The NLTCS replenishes its sample at each wave in order to reflect the cur-\nrent U.S. population 65 and older. While additional components have come and\ngone from post-1982 waves of the NLTCS, key disability questions have stayed\nthe same. For more information on the NLTCS, see Corder and Manton (1991),\nWe consider an extract from the NLTCS that contains data on 6 activities\nof daily living (ADL) and 10 instrumental activities of daily living (IADL) for\n16 binary functional disability measures are described in detail in Manton, Corder\nand Stallard (1993). The 6 ADL items include basic activities of hygiene and per-\nsonal care (eating, getting in/out of bed, getting around inside, dressing, bathing,\nand getting to the bathroom or using toilet). The 10 IADL items include basic ac-\ntivities necessary to reside in the community (doing heavy housework, doing light\nhousework, doing laundry, cooking, grocery shopping, getting about outside, trav-\nelling, managing money, taking medicine and telephoning). Positive responses are\ncoded as 1 = disabled, and negative as 0 = healthy. In the NLTCS, positive ADL\nresponses mean that during the past week the activity had not been, or was not ex-\npected to be, performed without the aid of another person or the use of equipment;\npositive IADL responses mean that a person usually could not, or was not going\nto be able to, perform the activity because of a disability of a health problem. For\na more in-depth discussion, see Manton, Corder and Stallard (1993) and Erosheva\nAt each wave, the survey sample is representative of the 65 years and older U.S.\npopulation at that point in time. High follow-up rates and consistency in ADL and\nIADL questions over time make the NLTCS a unique source of data for study-\ning complex questions such as the dynamics of population changes in disability.\ntotal numbers of impaired ADL and IADL to show declines in disability, but the\nimportant question of \"Why?\" [Cutler (2001)] still remains open. We believe that\nin order to move forward in our understanding of why disability is declining so\nrapidly and whether the decline can be expected to continue, an important first\nstep is to describe heterogeneous multivariate disability manifestations.\nOur ultimate goal is to develop a longitudinal version of the GoM model. Our\nanalysis in this paper represents an attempt to learn disability mixture profiles that\ndescribe the underlying structure of functional disability in the chronically dis-\nabled community-dwelling elderly U.S. population. We make three simplifying as-\nsumptions in this analysis. First, we assume that the nature of the mixture compo-\nnents stays the same over time. For a longitudinal version of the GoM model, keep-\ning profiles the same over time and allowing the population distribution among\nthe profiles to change would allow us to obtain an estimable model. For similar\nreasons, the assumption of time-invariant latent classes is common in latent class\ntransition modeling [see Reboussin et al. (1998), e.g.]. In addition, our exploratory\nanalysis where we analyzed each wave separately using the GoM model, yielded\nprofiles whose characteristics were fairly stable over time, thus confirming that\nthe assumption of profile time-invariance is reasonable in our case. Second, we\nassume no inter-dependencies between longitudinal records on the same individ-\nuals. Violations of this assumption may affect efficiency of our estimates but will\nnot introduce bias. Third, we ignore the sample weights associated with differen-\ntial probabilities of selection into the NLTCS. In fact, we have yet to understand\nhow if at all we could incorporate the weights into the modeling process. We view\nthese three assumptions necessary for this first step toward understanding changes\nin disability over time.\n3. The grade of membership (GoM) model and its latent class representa-\ntion. The GoM model originate in the context of medical applications: when a\ndiagnosis is uncertain, partial membership reflects this uncertainty through allow-\ning different disease symptoms to correspond to different stages of the disease.\nGoM applications now cover a wide spectrum of studies, ranging from studying\ndepression [Davison et al. (1989)] and schizophrenia [Manton et al. (1994)] to an-\nalyzing complex genotype-phenotype relations [Manton et al. (2004)]; for a recent\nreview, see Erosheva and Fienberg (2005). The model remains relatively unfamil-\niar to statistical audiences, however. Despite a multitude of published large-scale\nGoM applications, there are few statistical publications that explore basic GoM\nproperties and demonstrate the model's utility with similar examples [Erosheva\nIn particular, the relationship between individual-level and population-level\nmixture models does not appear to be clearly formulated in the literature.\nSinger (1989) describes the GoM model as a new type of model that is not equiva-\nlent to usual mixture models. Likewise, when comparing the GoM and latent class\ntent class model is nested in the GoM model structure...,\" but \"...if we allow\nlatent class model to have more classes, then it is potentially possible to \"fit\" the\nrealized data set as well as with GoM\" (page 45). On the other hand, Haberman\n(1995) in his review of Manton et al., suggested that the GoM model is a special\ncase of latent class models. He pointed out that a set of constraints imposed upon a\nlatent class model can specify a distribution of manifest variables that is identical\nto that specified by the GoM model.\nIn this Section we describe the GoM and latent class models and present the\nfundamental representation theorem of equivalence between individual-level and\npopulation-level mixture models [Erosheva (2006)].\nGoM and latent class models. Let x = (x1,x2,...,xJ ) be a vector of polyto-\nmous manifest variables, where xj takes on values lj\n Lj\n}, j =\n1,2,...,J, and Lj denotes the number of possible outcomes. Let X = J\nLj\nbe the set of all possible outcomes for vector x.\nTo define the GoM model, let K be the number of mixture components (extreme\nprofiles), and let g = (g1,g2,...,gK) be a latent partial membership vector of K\nnonnegative random variables that sum to 1. For discrete data, each extreme profile\nis characterized by a vector of conditional response probabilities, when a given kth\ncomponent of the partial membership vector is 1 and the others are 0:\nkjlj\n= pr(xj\n= lj\n|gk\nlj\nThe set of conditional response probabilities must satisfy the following constraints:\nlj Lj\nkjlj\nGiven partial membership vector g  [0,1]K , the conditional distribution of\nmanifest variable xj is given by a convex combination of the extreme profiles'\nconditional response probabilities, that is,\npr(xj\n= lj\n|g) =\nK\ngkkjlj\nThe local independence assumption states that manifest variables are condition-\nally independent, given latent variables. Under this assumption, the conditional\nprobability of observing response pattern l is\nf GoM(l|g) = pr(x = l|g)\n=\nJ\npr(xj\n= lj\n|g) =\nJ\nK\ngkkjlj\n, l  X.\nThe local independence assumption is common in latent structure models [Lazars-\nfeld and Henry (1968)]; it says that latent variables fully account for associations\namong the observed responses.\nLet us denote the distribution of g by D(g). Integrating out the latent vari-\nable g, we obtain the marginal distribution for response pattern l in the form of an\nindividual-level mixture\nf GoM(l) = pr(x = l) = f GoM(l|g)dD(g)\n=\nJ\nK\ngkkjlj\ndD(g), l  X.\nUsing similar notation, we can derive the K-class population-level mixture (la-\ntent class) model as a special case of the K-profile GoM model by restricting com-\nponents of the partial membership vector to only take values 0 and 1. Denote the\nrestricted version of the membership vector by g and its probability mass func-\ntion by k\n= pr(g\nk\n= 1). Assuming local independence, we see that the marginal\ndistribution of the manifest variables under the latent class model simplifies to the\nK-component summation:\nf LCM(l) = pr(x = l) = f LCM(l|g)dD(g)\n=\nK\nk\nJ\nkjlj\n, l  X.\nThe probability of observing response pattern l is the sum of the probabilities of\nobserving l from each of the latent classes, weighted by their relative sizes, k.\nOne can visualize the relationship between sets of individual-specific response\nprobabilities under the GoM and latent class models with the same number of\nmixture categories using a geometric approach [Erosheva (2005)].\nFundamental representation theorem. Note that the GoM marginal or integrated\nlikelihood in equation (3) does not simplify to a summation of K components.\nThis is in contrast to the functional form of the likelihood for a population-level\nmixture of K latent classes in equation (4). If we relax the requirement of equality\nof the number of latent classes and extreme profiles, however, following Haberman\n(1995), we can construct a latent class model such that its marginal distribution of\nmanifest variables is exactly the same as that under the GoM model.\nConsider a vector of J polytomous latent variables z = (z1,z2,...,zJ ), each\ntaking on values from the set of integers {1,2,...,K}. Vector z here is the latent\nclassification variable. Denote by Z = {1,2,...,K}J the set of all possible vec-\ntors z. As before, X = J\nLj is the set of all possible outcomes for vector x.\nThen X \u00d7 Z is the index set for the cross-classification of the manifest variables x\nand latent classification variables z.\nTo obtain a latent class representation of the GoM model, we must find a way to\ninterchange the summation and the product operator in equation (3). The following\nlemma provides algebra which allows us to do so.\nLEMMA 3.1. For any two positive integers J and K, and for any two sets of\nreal numbers {ak,k = 1,2,...,K} and {bkj ,k = 1,2,...,K,j = 1,2,...,J},\nJ\nK\nakbkj\n=\nzZ\nJ\nazj\nbzj j ,\nwhere z = (z1,z2,...,zJ ) is such that z  Z = J\nDefine the distribution over latent classes z  Z, conditional on the distribution\nof membership vector g  [0,1]K :\nz\n= ED\nJ\ngzj\n.\nIf (g1,g2,...,gK) has a joint distribution D(g) on [0,1]K , such that g1\n+\n... + gK\n= 1, then z is a probability measure on Z. From the functional form\nof z, it also follows that latent classification variables z1,z2,...,zJ are exchange-\nable.\nTo specify the conditional distribution of the manifest variables given the latent\nvariables z, we need two additional assumptions. First, assume that xj depends\nonly on the jth component of the latent indicator variable z:\npr(xj\n= lj\n|z) = pr(xj\n= lj\n|z1,z2,...,zJ ) = pr(xj\n= lj\n|zj ),\nwhere zj\n {1,2,...,K}, and lj\n {1,...,Lj\n} is the observed value of manifest\nvariable xj . In essence, equation (6) postulates that manifest variable xj is directly\ninfluenced only by the jth component of the latent classification vector z. Second,\nassume that conditional response probabilities in equation (6) are given by\npr(xj\n= lj\n|zj ) = zj jlj\n, zj\nlj\nwhere the set of s is the same as the set of conditional response probabilities for\nthe GoM model. These structural parameters must also satisfy the constraints:\nLj\nzj jlj\n= 1, for all z  Z,j  {1,2,...,J}.\nUnder the local independence assumption, we obtain the probability of observ-\ning response pattern l for the latent class model as\nf (l) =\nzZ\nz\nJ\nzj jlj\n, l  X,\nwhere the probability of latent class z is the expected value of a J-fold product\nof the membership scores z\n= ED( J\ngzj\n). Thus, the probability of observing\nresponse pattern l in equation (8) is the sum of the conditional probabilities of\nobserving l from each of the latent classes, weighted by the latent class probabili-\nties.\nConsider the marginal probability of an arbitrary response pattern l  X for\nthe GoM model provided by equation (3). Applying lemma 3.1 with ak\n= gk,\nbkj\n= kjlj\n, and using properties of expectation, we obtain the marginal proba-\nbility:\nf GoM(l) =\nzZ\nED\nJ\ngzj\nJ\nzj jlj\n,\nwhich is exactly the same as in equation (8). It follows that the GoM model is\nequivalent to a latent class model with a distribution on the latent classes given\nby a functional form of the distribution of membership scores. This equivalence\nstatement can be generalized via the following fundamental representation theo-\nrem:\nTHEOREM 3.2. Given J manifest variables, any individual-level mixture\nmodel with K components can be represented as a constrained population-level\nmixture model with KJ components.\nThe fundamental representation theorem applies to a wider class of mixed mem-\nbership models introduced by Erosheva (2002).\n4. Estimation algorithms for the standard GoM model.\n4.1. Bayesian estimation algorithm.\nData augmentation. The fundamental representation theorem leads us naturally\nto a data augmentation approach in the spirit of those described by Tanner (1996).\nIn this Section we present the Bayesian estimation algorithm for the GoM model,\nDenote by x the set of observed responses xij for all subjects. Denote by \nthe set of conditional response probabilities. For the functional disability data,\nkj\n= pr(xj\n= 1) is the probability of being disabled on activity j for a\ncomplete member of extreme profile k. For subject i, augment observed responses\nwith realizations of the latent classification variables zi\n= (zi1,...,ziJ ). Denote\nby z the set of latent classifications zij on all items for all individuals. In the fol-\nlowing, we use notation p(\u00b7) to refer to both probability density and probability\nmass functions.\nWe assume the distribution of membership scores is Dirichlet with pa-\nrameters . The joint probability model for the parameters and augmented\ndata is\np(x,z,g,,) = p(,) \u00b7 p(x,z,g|,)\n= p(,)\nN\n[p(zi\n|gi)p(xi\n|,zi) \u00b7 D(gi\n|)],\nwhere\np(zi\n|gi) =\nJ\nK\ngzijk\nik\n,\np(xi\n|,zi) =\nJ\nK\nxij\nkj\nzijk ,\nDir(gi\n|) =\n( k\nk)\n(1)\u00b7\u00b7\u00b7 (K)\niK\n,\nand latent classification indicators zijk are such that zijk\n= 1, if zij\n= k, and\nzijk\n= 0 otherwise.\nWe assume the prior on extreme profile response probabilities  is independent\nof the prior on the hyperparameters . We further assume that the prior distribu-\ntion of extreme profile response probabilities treats items and extreme profiles as\nindependent. Thus,\np(,) = p()\nK\nJ\np(kj ).\nWe take p(kj ) to be Beta(1,2), and, for simplicity, in what follows we use\nIf the hyperparameters  are known, it is possible to obtain complete condi-\ntional distributions and use standard software such as BUGS1 to obtain a posterior\ndistribution of the model parameters [Erosheva (2002)]. In reality, the hyperpara-\nmeters are unlikely to be known and need to be estimated. Setting hyperparame-\nters to some fixed values without prior knowledge may bias conclusions and affect\nmodel choice in individual-level mixture models [see the discussion in Airoldi\nIf we assume that the Dirichlet parameter vector  is unknown, we obtain sam-\nples from its posterior distribution via a Metropolis\u00adHastings step within the Gibbs\nsampler. Consider a reparameterization of  = (1,...,K) with 0\n= K\nk\n1The Bayesian inference using Gibbs Sampling project software [Spiegelhalter et al. (1996)]. For\ndetails see http://www.mrc-bsu.cam.ac.uk/bugs/.\nand  = (1,...,K), where k\n= k/0. Then components of vector  reflect\nproportions of the item responses that belong to each mixture category, and 0 re-\nflects the spread of the membership distribution. The closer 0 is to zero, the more\nprobability is concentrated near the mixture categories; similarly, the larger 0\nis, the more probability is concentrated near the population average membership\nscore.\nWe assume that 0 and  are independent since they govern two unrelated qual-\nities of the distribution of the GoM scores. We also assume that the prior distrib-\nution on the GoM scores is independent of the prior distribution on the structural\nparameters. The joint distribution of the parameters and augmented data is\np()p(0)p()\nN\nD(gi\n|)\nN\nJ\nK\ngikxij\nkj\nzijk .\nIn the absence of a strong prior opinion about hyperparameters 0 and , we take\nthe prior distribution p() to be uniform on the simplex and p(0) to be a proper\ndiffuse gamma distribution.\nSampling from the posterior distribution.\n\u00b7 Imputation step: We use a multinomial complete conditional distribution to\nobtain the (m + 1)st draw of latent class indicator variables zij for each i =\n1,...,N, j = 1,...,J:\nij\n Mult(1,p1,...,pK), pk\n gikxij\nkj\n\u00b7 Posterior step:\n\u00ad Sampling . We use the complete conditional distribution to obtain the\n(m + 1)st draw of conditional response probabilities kj ,k = 1,...,K,j =\nkj\nN\nxij zijk,1 +\nN\n(zijk\n- xij zijk) .\n\u00ad Sampling g. We use the complete conditional distribution to obtain the (m +\n1)st draw of membership scores gi, i = 1,...,N:\ni\n+\nJ\nzij1,...,K\n+\nJ\nzijK .\n\u00ad Sampling 0 and . Here we require Metropolis\u00adHastings steps.\nSampling 0. Let the prior p(0) be Gamma(,) with shape parameter  and\ninverse scale parameter . The full conditional distribution for 0, up to a constant\nof proportionality, is\nexp -  -\nK\nk\nN\n\u00d7\nN\n,\nwhere \u00b7\u00b7\u00b7 in p(0\n|\u00b7\u00b7\u00b7) stands for all other variables.\nIn order to obtain the (m + 1)st draw of 0 with the Metropolis\u00adHastings algo-\nrithm, we\n1. Draw a candidate point \nfrom a proposal distribution p(\n|(m)\n);\n2. Calculate the proposal ratio\n=\np(\n|\u00b7\u00b7\u00b7)p((m)\n|\n)\np((m)\n|\u00b7\u00b7\u00b7)p(\n|(m)\n)\n;\n= \nwith probability min{1,r0\n}, otherwise assign (m+1)\n=\n(m)\n.\nWe take the proposal distribution p(\n|(m)\n) to be gamma with the expected\nvalue set at the value of the last draw, (m)\n, and the shape parameter  > 1. The\ninverse scale parameter for the proposal distribution is then /(m)\n, where  plays\nthe role of the tuning parameter for the Metropolis\u00adHastings step. The proposal\nratio for the (m + 1)st draw of 0 is the product of the likelihood component and\nthe component that accounts for the asymmetric proposal distribution:\n= rL\n\u00b7 rA\n,\nwhere\nrL\n=\n\n(m)\nexp -  -\nK\nk\nN\nloggik \n- (m)\n\u00d7\n(\n)\u00b7\u00b7\u00b7 (K(m)\n)\n((m)\n)\u00b7\u00b7\u00b7 (K\n)\nN\n,\nrA\n=\n(m)\n\nexp - (m)\n/\n- \n/(m)\n.\nSampling . The full conditional distribution for , up to a constant of propor-\ntionality, is\np(|\u00b7\u00b7\u00b7)  exp 0\nK\nk\nN\nloggik\nN\n,\nwhere \u00b7\u00b7\u00b7 in p(|\u00b7\u00b7\u00b7) stands for all other variables.\nThe Metropolis\u00adHastings sampling algorithm to obtain the (m + 1)st draw of \nhas three steps:\n1. Draw a candidate point  from a proposal distribution p(|(m));\n2. Calculate the proposal ratio\nr\n=\np(|\u00b7\u00b7\u00b7)p((m)|)\np((m)|\u00b7\u00b7\u00b7)p(|(m))\n;\n3. Assign (m+1) =  with probability min{1,r\n}, otherwise assign (m+1) =\n(m).\nWe chose the proposal distribution for  to be Dir(|K(m)\n,...,K(m)\nK\n). The\nproposal distribution is centered at the previous draw and has reasonably small\nvariance for each component, (m)\nk\nk\n)/(K +1). The proposal ratio for  is\nr\nK\nN\nloggik \nk\n- (m)\nk\n((m)\n0)\u00b7\u00b7\u00b7 ((m)\nK\n(\nK\nN\n\u00d7\n(K(m)\n)\u00b7\u00b7\u00b7 (K(m)\nK\n)\n(K\n)\u00b7\u00b7\u00b7 (K\nK\n)\n\u00b7\n((m)\n)-1 \u00b7\u00b7\u00b7((m)\nK\n(\n)(m)-1 \u00b7\u00b7\u00b7(\nK\n,\nwhere  is a tuning parameter.\n4.2. Variational approximation. Variational approximation methods provide\nan alternative estimation approach by approximating a joint posterior distribution\nwhen the likelihood is intractable [see Jordan et al. (1999)]. They assume the model\nparameters are unknown but fixed. For the GoM model, the integrated likelihood\nfor an individual\np(x|,) =\nJ\nK\ngkxj\nkj\n(1 - kj )1-xj D(dg),\ndoes not have a closed form solution (the individual index i is omitted to sim-\nplify the notation). To compute the joint posterior distribution p(g,z|x,,) of\nthe GoM scores g = (g1,...,gK) and the latent classifications variables z =\n(z1,...,zJ ), we consider N independent fully factorized joint distributions, one\nfor each individual:\nq(g,z|,) = q(g| )\nJ\nq(zj\n|j ).\nHere, (,) is a set of free variational parameters, where  = (1,...,K) and \nis the matrix jk, j = 1,...,J, k = 1,...,K. Assuming q(g| ) = Dir(g| ) and\nq(zj\n|j ) = Mult(1,j1,...,jK), we employ Jensen's inequality to approximate\nthe log-likelihood by a lower bound which becomes a function of the variational\nparameters, (,).\nWe derive (pseudo) maximum likelihood estimates of the model parameters\n(,) by using an approximate EM algorithm. In the E-step, we obtain values\nof variational parameters (,) that yield the tightest possible lower bound. In the\nM-step, we maximize the lower bound with respect to the parameters of the model,\n(,).\nGiven the current estimates of the model parameters (,), the E step consists\nof updates:\njk\n xj\nkj\n(1 - kj )1-xj \u00d7 (k) -\nK\nk ,\nk\n= k\n+\nJ\njk.\nwhere (\u00b7) is the digamma function.\nGiven the current values of the free parameters (,), we find (pseudo) MLE\nof  in a closed form:\nkj\n\nN\nijkxij ,\nwhere i is the individual index. Since no closed form solution is available for the\npseudo MLE of , we need to use an iterative method to maximize the lower bound\nwith respect to . The gradient and the Hessian for the Newton\u00adRaphson algorithm\nare as follows:\nL\nk\n= N\nK\nk\n- (k) +\nN\n(ik) -\nK\nik ,\nL\n) -\nK\n.\nComputations for the variational approximation are simpler and less time-\nconsuming than for MCMC, but the quality of approximation depends on a specific\nfunctional form of the likelihood.\nThe C code for our implementation of the estimation algorithms for the GoM\nmodel is provided as part of supplemental material available at http://imstat.org/\naoas/supplements.\n5. Extended GoM mixture and its estimation. Although there is no time\ndimension in the basic GoM model, the latent class representation essentially de-\nscribes individuals as stochastic \"movers.\" Here, individuals may move between\nextreme profiles when they respond to different items on the questionnaire. With\nthis observation, it is natural to extend the GoM model to incorporate potential\n\"stayers,\" or those individuals that provide item responses in a deterministic fash-\nion, analogous to longitudinal mover-stayer models [Blumen, Kogan and Hol-\nland (1955)]. In the extended GoM mixture model, one compartment represents\n\"movers\" determined by the GoM part and other compartments represent different\nkinds of \"stayers\" determined by specific extreme profiles or by particular cells in\nthe contingency table. The extended GoM model can also be seen as a combina-\ntion of latent class and GoM mixture modeling analogous to the extended finite\nmixture model by Muthen and Shedden (1999).\nFor our analysis in this paper, we introduce one compartment of \"stayers\" for\na specific cell in the table, and leave the question of choosing the number and na-\nture of compartments open. Our choice of the \"stayers\" cell was motivated by two\nobservations. First, in the functional disability data from the NLTCS, the cell that\ncorresponds to the healthy people who report no disabilities is particularly difficult\nto fit with the standard GoM model. Thus, the excess of healthy people can be\nthought of as a set of outliers with respect to the standard GoM model. Second, it\nis known that elderly people move not only from being healthy to being disabled\nbut also from being disabled to being healthy [Gill, Hardy and Williams (2002),\nTherefore, even though the NLTCS participants are initially screened for chronic\ndisability, it is reasonable to assume the presence of healthy \"stayers\" in the data.\nAccordingly, we assume that some proportion of people has zero probability to\nreport a functional activity problem at the time of the survey and that everyone\nelse has nonzero chances to report a functional disability problem according to\nthe basic GoM model. Our specific example of extended GoM mixture model\ncan also be thought of as analogous to zero-inflated Poisson regression [Lambert\nParameter estimation for the compartmental GoM model would be identical to\nthe estimation for the standard GoM model if we knew how many individuals are\nhealthy \"stayers.\" Given that the number of healthy \"stayers\" is not observed, we\nneed to modify parameter estimation taking into account a deterministic compo-\nnent.\nMore formally, we assume existence of: (1) a deterministic compartment of\nhealthy individuals and (2) a stochastic GoM compartment. We denote by  =\n(1,2) the respective weights such that 1\n= 1. Assume individuals in the\nhealthy compartment have no disabilities with probability 1. The distribution of\nresponses for \"movers\" is given by the GoM model with parameters ,.\nWe further augment the data with compartmental indicators to derive the follow-\ning modifications for the MCMC sampling algorithm. Let N be the total number of\nindividuals in the sample and n(m)\nbe the expected value of the all-zero cell count\nfor the GoM compartment at the mth iteration. The expected value of the all-zero\ncell count from the healthy compartment, n(m)\n, can be obtained by subtracting\nn(m)\nfrom the observed all-zero cell count. Denote the number of individuals with\nat least one positive and at least one zero response in their response pattern by nmix.\nThe total number of individuals from the GoM compartment at the mth iteration\nis then n(m)\n+ nmix. We let the prior distribution for compartmental weights  be\nuniform on the simplex, and update  at the end of the posterior step with\n= (m)\n+\nn(m)\nN\n,\n=\n+ nmix\nN\n.\nWe can easily generalize the algorithm to more than two compartments.\n6. Model selection: Choice of dimensionality.\nChoice of dimensionality: Overview. Statistical model selection methods include\nthe Pearson's chi-square goodness of fit test [Pearson (1900)], cross-validation\ntechniques [Hastie, Tibshirani and Friedman (2001)], penalized likelihood criteria\nsuch as the Akaike information criterion (AIC) [Akaike (1973)], the Bayesian In-\nfactors [Kass and Raftery (1995)], reversible jump MCMC techniques [Green\n(1995)], deviance information criteria (DIC) [Spiegelhalter et al. (2002)] and more\nrecent simulation-based analogues to AIC and BIC, called Akaike Information\nCriterion Monte Carlo (AICM) and Bayesian Information Criterion Monte Carlo\n(BICM) [Raftery et al. (2007)], among others.\nSome of these criteria, AIC and BIC in particular, have been criticized as being\nnot applicable for assessing the number of mixture components due to violations\nof the regularity conditions [McLachlan and Peel (2000)]. However, in spite of\nthis, researchers continue to apply both criteria and to study their performance in\na mixture context. Findings in population-level mixture models suggest that AIC\ntends to overestimate the correct number of components [Celeux and Soromenho\nQuestions of dimensionality choice in mixed membership or individual-level\nmixture models have been approached by several authors [Airoldi et al. (2007),\nPritchard, Stephens and Donnelly (2000)]. With one recent exception [Airoldi et\nal. (2007)], however, comparative performances of different selection criteria were\nnot examined. Here, we provide an overview of several computationally feasible\ncriteria and present results from a simulation study where we compare their per-\nformance in the context of the GoM model.\nModel selection criteria: Overview. The Pearson chi-square test is one of the\nmost common goodness-of-fit tests. It is not easily applicable to large sparse ta-\nbles because of a large number of very small counts and, in the present context,\nbecause of the way in which the estimation is done, even if sparseness wasn't a\nproblem, it wouldn't follow the usual chi-square distribution. We find it instruc-\ntive, nonetheless, to examine deviations between expected and observed counts\nfor cells with large observed values via the sum of squared Pearson residuals, see\nBishop, Fienberg and Holland (1975). We refer to this criterion as the truncated\nsum of squared Pearson residuals (SSPR) criterion or 2\ntr\n.\nTo calculate the truncated SSPR criterion, one needs to obtain expected values\nfor selected response patterns r = (r1,...,rJ ), where rj\n= 0 or 1. For example,\nusing draws from the posterior distribution, (s)\nk\nand (s)\nkj\n, s = 1,...,S, and a draw\ng(s) = (g(s)\n,...,g(s)\nK\n) from Dir((s)), the expected count for response pattern r\ncan be computed as\nExpected Count =\nS\nS\nJ\nK\ng(s)\nk\n(s)\nkj\nrj 1 - (s)\nkj\nNote that label switching could present a problem for calculating posterior means\nand the model selection criteria based on them [Stephens (2000)].\nFor the variational approximation, the expected count for response pattern r can\nbe obtained as follows. Let ^\n and ^\n be the pseudo MLE obtained via variational\napproximation and let g(s), s = 1,...,S, be draws from Dir(^\n), for some large S\n(e.g., S = 5000). Then, the expected count for response pattern r can be computed\nas above but with ^\nkj in place of (s)\nkj\nand with g(s)\nk\ncomputed using Dir(^\n).\nA general formulation of the BIC is based on the log-likelihood (x;) and a\nmaximum likelihood estimate ^\n:\nBIC = -2 (x; ^\n) + p log(N),\nwhere p is the number of free parameters in the model and N is the number of data\npoints. To obtain the BIC for the GoM model, we need to evaluate the integrated\nlog-likelihood (x;) at the maximum likelihood estimate of the parameter vector\n = (,). Since the GoM integrated likelihood is intractable, we use variational\nmethods described in Section 4.1 to obtain an approximation to the BIC:\nBIC = -2 ~(x; ^\n, ^\n) + p log(N),\nwhere ^\n and ^\n are the (pseudo) maximum likelihood estimates obtained via varia-\ntional approximation and ~(x; ^\n, ^\n) is the lower bound on the log-likelihood. Mod-\nels with larger values of BIC are preferable.\nBayesian measures of model complexity and fit, namely, DIC, AICM, and\nBICM, are analogous to AIC and BIC but are based solely on posterior simula-\ntion. While these criteria are attractive because of their computational simplicity\nfor a given MCMC simulation, they may present other challenges such as choice\nof the parameters in focus [Spiegelhalter et al. (2002)].\nA general formulation of DIC is based on the concepts of Bayesian deviance\nand the effective number of parameters. Bayesian deviance is defined as\nD() = -2 () + 2log(h(x)),\nwhere () = logp(x|) and h(x) is a function of the data only. Defining the\neffective number of parameters as\npD\n= D() - D(),\nwe compute DIC as follows:\nDIC = D() + 2pD.\nIf we focus on GoM parameters  = (g,), we can compute a version of DIC\ndirectly using S draws from the posterior distribution, g(s)\nik\nand (s)\nkj\n, s = 1,...,S.\nThe two pieces that we need to compute for DIC are\nD(g,) = -2\nN\nJ\nlog\nK\ngikkj\nxij (1 - kj )1-xij ,\nwhere gik\nS\nS\ng(s)\nik\n, and kj\nS\nS\n(s)\nkj\n, and,\nD(g,) = -2\nS\nS\nN\nJ\nlog\nK\ng(s)\nik\n(s)\nkj\nxij 1 - (s)\nkj\nModels with smaller values of DIC are preferable.\nAICM is a penalized version of the posterior mean of the log-likelihoods\n()\n,\nthat can be obtained using only the draws from the posterior simulation [Raftery\net al. (2007)]. For the GoM model, the two pieces we need to compute are\n() =\nS\nS\n(s) and s2 =\nS\nS\n(s) - () 2,\nwhere  = (g,). Notice that () = -D()/2.\n7. Simulation study. We conducted a simulation study to investigate perfor-\nmance of the MCMC and variational approximation methods with respect to para-\nmeter recovery and dimensionality selection. Here, we briefly report main findings\nfrom this study.\nWe selected data generating designs to reflect several important features of func-\ntional disability data. Most noticeably, contingency tables on disability data often\nhave a large number of zero or very small observed cell counts and several very\nlarge cell counts. Large cell counts typically include the all-zero and the all-one\nresponse patterns.\nWe considered 3- and 7-profile data generation scenarios. In the first scenario,\nwe generated 5,000 individual responses on 16 binary items using the GoM model\nwith K = 3 extreme profiles. We chose the profiles to be considered as \"healthy,\"\n\"disabled\" and \"intermediate\" by their conditional response probabilities. Respec-\ntive proportions of the profiles were 0.7,0.2 and 0.1, and the hyperparameter was\n= 0.25 to reflect the fact that individual responses to most items come\nfrom one extreme profile.\nIn the second scenario, we generated 5,000 individual responses to 10 bi-\nnary items using the GoM model with 7 extreme profiles. We chose conditional\nresponse probabilities for 4 profiles so that they could be considered as \"very\nhealthy,\" \"healthy,\" \"disabled\" and \"very disabled.\" The other 3 intermediate pro-\nfiles did not follow the ordering. Profile proportions ranged from 0.05 for one of\nthe intermediate profiles to 0.4 for the \"healthy\" profile, and the hyperparameter\nwas set at 0\nUnder both scenarios, we carried out parameter estimation using the MCMC\nand variational approximation methods for the true values of K. The variational\nmethods consistently provided better estimation for the observed count at the all-\nzero pattern, however, the MCMC approach yielded an overall better fit for the sec-\nond scenario with K = 7. For K = 3, conditional probabilities for the \"healthy\"\nand \"disabled\" profiles were recovered very well with both estimation methods.\nFor the intermediate profile, the variational approximation consistently overesti-\nmated and the MCMC consistently underestimated the conditional response prob-\nabilities. Parameter recovery was noticeably better for K = 3 than for K = 7.\nThis could indicate that the number of items and the sample size in the second\nscenario were too small to provide reliable distinction among different grades of\nmembership, given the selected extreme profiles and hyperparameter values. Vari-\national estimates of the profiles' proportions were closer to the true values than\ncorresponding MCMC estimates under both scenarios. In addition, the MCMC\nestimates of profile proportions had smaller range than the VA estimates.\nFor the MCMC method, given a sufficiently long run, the starting values of \ndid not seem to influence the results, up to a relabeling of the extreme profiles. For\nsmaller values of K, the posterior means obtained through MCMC simulations\nwere very similar for all starting points considered. For this reason we did not\nChoices of optimal K according to different model selection criteria\nCriterion Method K = 3 K = 7\nuse several starting points in higher dimensional cases that would have required\nsubstantial increases of computing time.\nTo investigate performance of different fit indices, we fitted the generated data\nsets using both the MCMC and variational methods separately for several values\nof K. For true K = 3, models fitted with K = 2,3,4,5 were considered; for\ntrue K = 7, models fitted with K = 5,7,9 were considered. Table 1 summarizes\nresults of six goodness-of-fit criteria, two of which rely on the variational approx-\nimation method, while the rest rely on the full MCMC calculations. The values\ntr\nwere calculated for response patterns with observed counts  30 in the first\ncase and  40 in the second case.\nWe see that 2\ntr\nobtained with the variational method and AICM criteria perform\nwell for both data generating scenarios, while BICM underestimates and DIC over-\nestimates the true number of profiles in both cases. The variational approximation\nto BIC underestimates the model complexity for the 3-profile case, while it points\nto the true optimal number of profiles in the 7-profile case.\n8. Analysis of the NLTCS functional disability data. Data on 16 binary\nginal frequencies range from 0.1 for difficulty with eating to 0.7 for doing heavy\nhousework. About 80% of cells in the contingency table have observed counts that\nfrequent response patterns account for 42% of the total observations (Table 2).\nFrom an interpretative standpoint, it is often desirable to have data that satisfy\nlatent unidimensionality, as in the well-known Rasch model. We formally tested\nthe hypothesis of latent unidimensionality, following the approach of Holland\nand Rosenbaum (1986), using series of Mantel\u00adHaenszel tests to detect negative\nconditional association among the 16 variables. We concluded that no monotone\n2The full table is available for downloading from STATLIB at http://lib.stat.cmu.edu/ under the\nlabel NLTCS.\nExpected cell counts for 24 most frequent response patterns under the basic GoM model with K profiles\nNumber of latent profiles K\nunidimensional latent structure model (e.g., one-factor or unidimensional logistic\nitem response models) can provide an acceptable fit for the NLTCS data on 16\nADL/IADL items. Having rejected latent unidimensionality, our next step is to use\nthe GoM analysis to determine characteristics and the number of disability profiles\nin the data.\nThe most apparent feature of the data is the very large observed count of\n\"healthy\" people. Almost 18% report no disabilities (Table 2), despite the fact\nthat the majority of the NLTCS survey participants had been screened-in earlier\nas chronically disabled. A large fraction of \"healthy\" respondents includes disabil-\nity recoveries, as well as survey supplements of the healthy and oldest-old in the\n1994 wave. Since most of the \"healthy\" individuals have been identified earlier as\nchronically disabled, it is important to incorporate these responses in our model.\nWe use the compartmental GoM model to estimate weights of deterministically\nhealthy and partially disabled components. In doing so, we allow the extended\nGoM model to fit the observed count for the all-zero pattern. In addition, we ex-\namine the impact of the introduction of the \"healthy\" compartment on parameter\nestimates and on model choice.\nMCMC sampling. We applied the fully Bayesian approach from Section 4 to es-\ntimate the posterior distribution of the GoM model parameters with the number of\nextreme profiles ranging from K = 3 to K = 15. Extreme profiles for K = 2 were\nidentified as \"healthy\" and \"disabled,\" making the K = 2 GoM model a monotone\nunidimensional latent structure model. Having rejected latent unidimensionality\nearlier, we only considered results for K = 3 and beyond in the rest of our analy-\nsis.\nWe expected individual vectors of membership scores to be dominated by one\ncomponent, hence, we set the prior for 0 to be Gamma(2,10). We chose the\nprior for the relative proportions  to be uniform on the simplex and put uniform\nindependent priors on the conditional response probabilities .\nWe fit the models sequentially in the order of K. For the GoM model with K\nextreme profiles, we set starting values for  to the estimated conditional response\nprobabilities from the latent class model with K classes. We took the posterior\nmean of 0 from the GoM model with K - 1 extreme profiles to be the starting\nvalue for 0 for the GoM model with K extreme profiles. We chose starting values\nfor the hyperparameters  to be equal to the latent class weights estimated from\nthe K class model.\nFor each value of K, we adjusted the tuning parameters  (for 0) and  (for )\nto reach a compromise between the acceptance rates of the Metropolis\u00adHastings\nsteps and the amount of mixing. The acceptance rates for 0 and  varied respec-\ntively from 11% and 28% in lower dimensions to 5% and 9% in higher dimensions.\nSince the acceptance rates were low, we introduced thinning parameter q and kept\nevery qth draw and discarded the rest; q varied from 10 in lower dimensions to\nChoosing the length of a burn-in period did not appear to be a problem with our\ndata. The chains generally did not experience long burn-in periods, except when\nstarting values for the hyperparameters were very far from the posterior means.\nhigher dimensions.\nFor each parameter, we monitored univariate convergence via Geweke diagnos-\ntics, and Heidelberger and Welch stationarity and interval halfwidth tests, available\nfrom the CODA package [Best, Cowles and Vines (1996)]. In addition, we visu-\nally examined plots of successive iterations. To assess convergence of the mul-\ntivariate posterior, we examined successive values of the log-likelihood with the\nsame set of methods. The chains needed far fewer iterations to converge in poste-\nrior means than they needed to converge in distribution for all parameters and the\nlog-likelihood.\nWe ran all chains long enough to reach acceptable convergence levels. We had\nto consider larger number of iterations for higher values of K to accommodate\nslow convergence of the hyperparameters due to slow mixing of the chains. The\nadditional iterations needed to satisfy convergence criteria for hyperparameters\n(after the other parameters have reached convergence) had negligible effect on the\nposterior means of the conditional response probabilities.\nModel selection. Table 2 provides 24 response patterns with observed cell counts\n 100 and corresponding expected counts obtained using draws from the posterior\ndistribution for each K = 3,...,9,10,15. We observe that the model with K = 9\nreplicated the marginal pattern abundance best. It is especially evident that models\nwith K = 10 and K = 15 did not fit the three largest cell counts as well as the\n9-profile model.\nTo select the number of profiles, we used all of the criteria that performed well\nin our simulation study described in Section 6 (the truncated SSPR criterion, the\nvariational approximation to the BIC, and the AICM). We also calculated DIC for\na further comparison, although it overestimated the correct number of profiles in\nthe simulation study.\nTable 3 gives values of the truncated SSPR criterion, 2\ntr\n, for three different\nlevels of truncation, over cells with observed counts  100,25 and 10. All three\ncriteria indicate that the K = 9 model has a better fit in an absolute sense, that is,\nwithout correcting for differences in the degrees of freedom.\nFigure 1 shows plots of the DIC, the BIC approximation, the AICM and the\ntruncated SSPR criterion for the 100 level of truncation. All criteria agree that the\noptimal number of profiles is greater than 7. Recall that in the 7-profile simulation\nstudy the AICM, the BIC approximation, and the truncated SSPR criterion all\nobtained the correct number of components. For the NLTCS data, these criteria\npoint to 7, 10 and 9 profiles, respectively. Although the DIC overestimated the\nTruncated sum of squared Pearson residuals, 2\ntr, for the basic GoM model with K profiles, with\ndifferent levels of truncation\nNumber of latent profiles K\ncorrect number of profiles in our simulation study, it indicates that 9 profiles is the\noptimal number for the NLTCS functional disability data. The value of K = 9 is\nin agreement with the results from truncated SSPR, but is less than the optimal\nchoice of K = 10 identified by BIC.\nWe used the following steps to verify that no label switching had occurred in\nthe MCMC chains. First, we postulated that label switching occasions should be\nvisible as jumps in trace plots of the MCMC iterations when the extreme profiles\nare well separated in the multidimensional space. We found extreme profiles to\nFIG. 1. Goodness-of-fit criteria for the basic GoM model.\nPosterior mean estimates for the basic GoM model with 9 profiles\nExtreme profile number (k)\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\nADL items: (1) eating, (2) getting in/out of bed, (3) getting around inside, (4) dressing, (5) bathing,\n(6) using toilet. IADL items: (7) doing heavy housework, (8) doing light housework, (9) doing laun-\nmoney, (15) taking medicine, (16) telephoning.\nbe well separated in the multidimensional space for all K < 9. That is, there was\nat least one item for which posterior means were at least two standard deviations\naway from each other for each pair of the profiles (Table 4). We then visually\nmonitored chains to identify jumps that could correspond to label permutations\nin the posterior distribution. We observed no jumps for models with K < 9 and\nconcluded that no label switching occurred in those chains.\nWe weren't able to carry out analogous assessments for the GoM models with\nK = 9 and higher since the profiles were no longer well separated (compare, e.g.,\nprofiles k = 1 and 8 in Table 4.3) It is possible that label-switching did occur in\nthose cases which would question validity of posterior mean estimates and the\nuse of DIC and AICM. However, given that the approximate BIC, which is not\n3Standard deviation estimates are provided as part of supplemental material available at\nhttp://imstat.org/aoas/supplements.\nimpacted by label switching, indicated K = 10, a choice of an optimal K around\nthat value seems reasonable.\nWe examined the estimated profiles for K = 7 and K = 9 GoM models. Con-\ntrary to our expectations, we did not find the interpretation of the 7-profile model\nto be more appealing from a substantive point of view. Therefore, we report the\nestimated profiles for the 9-profile GoM model that is identified as the optimal\nby truncated SSPR criteria. Table 4 provides posterior means and standard devi-\nations for the conditional response probabilities, kj\n= pr(xj\n= 1); these\nare probabilities of being disabled on activity j for a complete member of ex-\ntreme profile k. Estimation via variational methods yielded similar results in terms\nof profile interpretation, although variational estimates of conditional probabilities\nwere generally closer to the boundaries of the parameter space.\nGiven that the fit of the all-zero pattern is still not very good for the 9-profile\nGoM model, we turn to the extended GoM mixture model, incorporating a \"deter-\nministically\" healthy compartment.\n8.2. The extended GoM mixture analysis.\nMCMC sampling. We carried out the extended GoM mixture analysis for K =\n3,...,9,10, as described in Section 5. We chose initial values, ran MCMC sam-\nplers, and determined convergence similarly as in Section 8.1. We set an initial\nvalue for the weight of the healthy compartment 1 to be a positive fraction that is\nless than the observed proportion of individuals with all-zero responses.\nModel selection. Table 5 provides the expected and observed cell counts for the\n23 most frequent response patterns; we excluded the all-zero pattern since the ex-\ntended GoM mixture fits it precisely. It is difficult to choose among K = 7,8 or 9\nbased on the expected counts in Table 5, but the model for K = 8 shows the best fit\nas indicated by truncated SSPR over the differing levels of truncation in Table 6.\nAnalogously to the standard GoM model, we computed a version of AICM and\na version of DIC obtained directly from the MCMC output. The AICM plot in\nFigure 2 picks K = 7 profiles, while the DIC plot in Figure 2 suggests the choice\nof K = 8 profiles for the extended GoM mixture model, which is consistent with\nthe SSPR selection. We therefore examine the 8-profile extended GoM mixture\nmodel.\nTable 7 provides the conditional response probabilities for the 8 profiles that\nwe interpret in detail at the end of this section.4 Similarly to results from the stan-\ndard GoM model with 9 profiles, estimated profile weights ^\nk, k = 1,...,K, are all\nclose to 1/K. Estimated proportions of the healthy compartment for K = 3,...,10\nrange from 14% to around 16% (Table 8). The estimated proportion of determin-\nistically healthy individuals from the 8-profile GoM mixture model is ^\n4Standard deviation estimates are provided as part of supplemental material available at\nhttp://imstat.org/aoas/supplements.\nExpected cell counts for 23 most frequent response patterns under extended GoM mixture model\nwith K profiles and a healthy compartment\nNumber of latent profiles K\nComparison of results for the basic and the extended GoM mixture models. The\noptimal dimensionality values identified by truncated SSPR, AICM and DIC cri-\nteria for the extended GoM mixture model are one less than the correspond-\nTruncated sum of squared Pearson residuals, 2\ntr, for extended GoM mixture models with K profiles\nand a healthy compartment, with different levels of truncation\nNumber of latent profiles K\nFIG. 2. DIC (left) and AICM (right) for the GoM mixture model.\ning optimal values for the basic GoM model. The presence of the deterministic\nhealthy compartment therefore reduces the optimal number of profiles by one in\nthe NLTCS disability data.\nThe preferred dimensionality choices are K = 9 and K = 8 for the basic GoM\nand extended GoM mixture models, respectively. Comparing DIC values for these\nmodels, we observe that the extended GoM mixture model provides an improved\nfit to the data. Comparing the estimated conditional response probabilities, we ob-\nserve that all but two \"healthy\" profiles from the 9-profile basic GoM model match\nseven estimated profiles from the 8-profile GoM mixture model closely (see k = 6\nin Table 7 and k = 7 in Table 4, e.g.). Moreover, the two \"healthy\" profiles from\nthe 9-profile basic GoM model do not differ by much (see k = 1 and k = 8 in\nTable 4); in fact, taking standard errors into account, they are identical.5 The un-\nmatched profile from the 8-profile GoM mixture model (k = 1 in Table 7) is the\nnew healthy profile.\nTo aid interpretation, we compare the profiles' estimated conditional response\nprobabilities to the average probabilities for each functional disability item. We\nwould like to see by how much the frequency of disability occurrence for each\nprofile differs from the average frequency of occurrence of the same functional\ndisability in the population as a whole. Relative frequencies for profile k, obtained\nas\nwhere j is the marginal probability for item j, indicate how frequently each dis-\nability is observed for a complete member of the extreme profile in relation to the\npopulation average (Table 9). For example, a complete member of extreme profile\n6 is about seven times more likely to need help with eating than individuals in the\nNLTCS sample need on average (11%).\n5MCMC estimation in our simulation studies identified emerging identical, up to a standard error,\nprofiles when the number of fitted profiles was greater than the number of profiles that generated the\ndata.\nPosterior mean estimates for the extended GoM mixture model with 8 extreme profiles and a\nhealthy compartment\nExtreme profile number (k)\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\n^\nADL items: (1) eating, (2) getting in/out of bed, (3) getting around inside, (4) dressing, (5) bathing,\n(6) using toilet. IADL items: (7) doing heavy housework, (8) doing light housework, (9) doing laun-\nmoney, (15) taking medicine, (16) telephoning.\nTable 9 shows values for relative probabilities greater than 1 in red ink. Among\nestimated extreme profiles in the 8-profile GoM mixture model, we find one\nhealthy profile (k = 1) with all relative frequencies less than the corresponding\npopulation averages, while all other profiles have at least one activity with relative\nPosterior mean estimates and standard deviations of the proportion in the healthy compartment for\nthe extended GoM mixture model with K profiles\n^\nSD( ^\nFunctional disabilities average frequencies and relative frequencies by profile for the K = 8 GoM\nmixture model and for two healthy profiles from the basic K = 9 GoM model (green labels).\nRelative frequencies greater than 1 are in red\nfrequency greater than the population average. In addition, we find that each esti-\nmated profile in the 8-profile GoM mixture model has a unique set of functional\ndisabilities with relative frequencies greater than the corresponding population av-\nerages (no two rows in the table have identical placements of values in red ink).\nWe can say then that the estimated 8-profile GoM mixture solution defines a set\nof admissible profiles in the terminology of Berkman, Singer and Manton (1989).\nMoreover, taking into account standard errors of the estimates (not shown), we\nnotice that all 8 disability profiles are now well separated.\nFIG. 3. Functional disabilities relative frequencies for extreme profile pairs for the K = 8 GoM\nmixture model. Horizontal lines indicate average frequencies in the sample.\nExtreme profiles in black in Table 9 are the seven profiles from the 8-profile\nGoM mixture model that match corresponding profiles from the 9-profile basic\nGoM model closely. The two differing healthy profiles from the basic 9-profile\nGoM model are shown in green ink, and the new healthy profile from the GoM\nmixture model is in blue.\nWhile Table 9 allows us to view all estimated profiles in relation to one other, it\nis not easy to trace each profile separately on this plot. Pairwise plots in Figure 3\nallow us to view individual profiles in detail. Profile k = 2 exhibits relative con-\nditional probabilities greater than 1 for all activities except managing money and\ntelephoning. Relative probabilities for transferring in/out of bed, dressing, toilet-\ning, and light housework for this profile are at least three times the corresponding\naverages in the population.\nProfiles k = 3 and k = 4 show patterns of frequencies that are somewhat similar\nto each other, indicating frequent difficulties with mobility activities, with profile 3\nhaving noticeably higher frequencies on laundry, grocery shopping, and traveling.\nProfile k = 6 is the profile of seriously disabled with most of the disability fre-\nquencies greater than 0.8 and greater than the corresponding average frequencies\nin the population. For a complete member of this profile, difficulties with each eat-\ning, dressing, light housework, managing money, taking medicine, and telephoning\noccur at least four times more often than in the NLTCS sample on average. Profile\nk = 5 points to low probabilities for most ADL and IADL items, but has a spike\nat the probability for doing heavy housework. An individual corresponding to this\nprofile has difficulties with heavy housework one and a half times more often than\nthe average chronically disabled person. This is a significant increase, given that\nthe average frequency to experience difficulty with heavy housework is 0.68 in the\nNLTCS sample.\nProfile k = 8 shows disability frequencies that are slightly higher than the aver-\nage for heavy housework, grocery shopping, traveling and managing money. Pro-\nfile k = 7 exhibits high frequencies for all IADL items, especially for those with\nsignificant cognitive components such as cooking, managing money and telephon-\ning.\nHaving the profile interpretations at hand, we recall that they represent extreme\ntypes of chronically disabled individuals aged 65 and over. Apart from an esti-\nmated 15% of healthy individuals who have no disabilities with probability one,\neach (partially disabled) person in the population can be described through a vec-\ntor of membership scores for the eight estimated profiles. Since the hyperparameter\nestimate ^\n= 0.103 is small, the posterior distribution of grades of membership\nis bathtub-shaped, which means that membership vectors are dominated by one\ncomponent for a majority of individuals. Even though we focus on the population\nparameters in this paper, it is possible to use MCMC output to examine posterior\ndistributions for each individual. One could also compute posterior estimates of\nvarious quantities of interest, such as the percentage of individuals in the sample\nthat have membership vectors dominated by one profile (with gk > 0.95, e.g.).\n9. Discussion. Models that allow for specification of continuous latent con-\nstructs are increasingly popular among researchers in the social, behavioral, and\nhealth sciences since many latent variables of interest can be thought of as hav-\ning fine gradations. When substantive theory justifies distinct latent categories as\nwell as continuous latent variables, approaches that describe heterogeneity of indi-\nviduals with respect to those discrete categories often focus on class membership\nprobabilities. To give a few examples, Foody et al. (1992) emphasize the utility of\nposterior probabilities of class membership in the area of remote sensing; Muthen\nand Shedden (1999) model the class membership probability as a function of co-\nvariates in a study of alcohol dependence; Roeder, Lynch and Nagin (1999) address\na similar issue by modeling uncertainty in latent class assignments in a criminol-\nogy case study. The GoM model also addresses the issue of uncertainty in class\nmembership, but by using a different approach that directly incorporates degrees\nof membership as model parameters.\nStandard methods of estimating the GoM model described in Manton, Wood-\nbury and Tolley (1994) do not rely on the GoM representation as a discrete\nmixture model and have questionable properties [Haberman (1995)], including\ninstability of MLEs due to ridges in the likelihood function which are often\npresent. The Bayesian GoM estimation algorithm developed originally in Ero-\nsheva (2002, 2003), on which the present paper is largely based, leans heavily on\nthe structure provided by the latent class representation and has several advantages\nover likelihood-based estimation procedures for the GoM model. It is worth em-\nphasizing one more time that the developed latent class representation of the GoM\nmodel places identical probability structure on observable variables and, hence,\ncannot possibly be distinguished from the continuous mixture GoM model on the\nUnderstanding the latent class representation of the GoM model, and thus view-\ning it as a special instance of individual-level or mixed membership models, makes\nit easier to establish direct connections with models from other areas. For exam-\nple, although a clustering model with admixture developed for genetic data by\nPritchard, Stephens and Donnelly (2000) and the standard GoM model appear to\nbe quite different, they are both instances of the more general mixed-membership\nrepresentation. The generalization is flexible enough to accommodate models for\nother data structures such as text documents [Erosheva, Fienberg and Lafferty\nOur goal for the NLTCS analysis in this paper was to explore the population\ncharacteristics of disability patterns as measured by the 16 ADL and IADL vari-\nables. Incorporation of covariates in the GoM modeling would be an obvious next\nstep of great interest to social science researchers.\nThe preferred number of components identified by statistical criteria represents\nour best guess at the latent dimensionality in the NLTCS data under the GoM\nmixture model with a deterministically healthy compartment. Our choice of di-\nmensionality is based on a number of assumptions, some of which may be worth\nexploring further. In particular, the assumption of local independence for the full\nset of ADL and IADL variables may be questionable. One possible approach to\nrelax this assumption suggested by a reviewer is to focus on fitting the GoM mod-\nels separately for the set of ADL and for the set of IADL variables, producing two\nsets of correlated GoM scores. Such a split-GoM model may turn out to be more\nappealing to disability researchers and to produce gains in interpretability. We ex-\npect to consider this and other forms of model simplification as we work toward\nour ultimate goal of developing a longitudinal version of the GoM model.\n"
}