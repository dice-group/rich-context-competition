{
    "abstract": "Abstract\nAn overview is presented of the design and field procedures of the US National\nComorbidity Survey Replication Adolescent Supplement (NCS-A), a US face-\nto-face household survey of the prevalence and correlates of DSM-IV mental\ndisorders. The survey was based on a dual-frame design that included 904\nadolescent residents of the households that participated in the US National\nComorbidity Survey Replication (85.9% response rate) and 9244 adolescent\nstudents selected from a nationally representative sample of 320 schools (74.7%\nresponse rate). After expositing the logic of dual-frame designs, comparisons\nare presented of sample and population distributions on Census socio-\ndemographic variables and, in the school sample, school characteristics. These\ndocument only minor differences between the samples and the population.\nThe results of statistical analysis of the bias-efficiency trade-off in weight trim-\nming are then presented. These show that modest trimming meaningfully\nreduces mean squared error. Analysis of comparative sample efficiency shows\nthat the household sample is more efficient than the school sample, leading to\nthe household sample getting a higher weight relative to its size in the consoli-\ndated sample relative to the school sample. Taken together, these results show\nthat the NCS-A is an efficient sample of the target population with good\nrepresentativeness on a range of socio-demographic and geographic variables.\nCopyright \u00a9 2009 John Wiley & Sons, Ltd.\nNCS-A design and field procedures Kessler et al.\n",
    "reduced_content": "International Journal of Methods in Psychiatric Research\nPublished online in Wiley InterScience\nDesign and field procedures in the US\nNational Comorbidity Survey\nReplication Adolescent Supplement\n1 Department of Health Care Policy, Harvard Medical School, Boston, MA, USA\n2 Division of Developmental Translational Research, National Institute of Mental Health\n3 Center for Developmental Epidemiology, Department of Psychiatry and Behavioral Sciences, Duke\nUniversity Medical School\n4 Survey Research Center, Institute for Social Research, University of Michigan\n5 Section on Developmental Genetic Epidemiology, Intramural Research Branch, National Institute of\nMental Health\nKey words\npsychiatric epidemiology, child-\nadolescent mental disorder,\nNational Comorbidity Survey\nCorrespondence\nR.C. Kessler, Department of\nHealth Care Policy, Harvard\nEmail: Kessler@hcp.med.\nharvard.edu\n Introduction\nThis paper presents an overview of the design and field\nprocedures of the National Comorbidity Survey Replica-\ntion Adolescent Supplement (NCS-A), a national survey\nof DSM-IV mental disorders among adolescents (ages\n13\u00ad17) in the US. The survey was fielded between\nNational Comorbidity Survey Replication (NCS-R;\nKessler and Merikangas, 2004), a national household\nsurvey of adults. The NCS-A was carried out at the request\nof the National Institute of Mental Health (NIMH) to\nmeet a request from Congress to provide national data on\nthe prevalence and correlates of mental disorders among\nUS youth. Based on the limited budget, it was decided that\na survey of children, which would require parents and\nteachers to be the main respondents, was infeasible, but\nthat adolescents could be surveyed with a small amount\nof supplemental information obtained from self-admin-\nistered parent questionnaires. This was the study design\nused in the NCS-A. An overview of the rationale for the\nstudy is presented elsewhere (Merikangas et al., 2009).\nIn order to keep the study within budget, we had to use\nthesameinterviewersastheNCS-R.Giventheheavytrain-\ning burden on these interviewers, it was decided to use a\nmodificationoftheNCS-Rinterviewschedulewithadoles-\ncents rather than the instrument developed in an earlier\nprogram of NIMH-funded methodological research\n(Lahey et al., 1996). The NCS-A collaborators at Yale and\nNIMHtooktheleadinmakingtheseinstrumentmodifica-\ntions.AstheNCS-RwascarriedoutentirelyinEnglish,the\nNCS-A, too, was limited to English-speaking adolescents.\nThe number of adolescents residing in NCS-R house-\nholds was too small to generate the target sample of 10000\nrespondents. The sample was consequently supplemented\nby adding a school-based sample. This had lower costs\nthan household screening (Johnston et al., 2007). The\nfinal sample, then, was based on a dual-frame design\n(Groves and Lepkowski, 1985; Lepkowski and Groves,\n1986) in which one sample was recruited from the NCS-R\nhouseholds and the other from a representative sample of\nschools in the same communities as the NCS-R house-\nholds. All schools (public and private, schools for gifted\nchildren, therapeutic schools, etc.) were included in their\ntrue population proportions. A stratified probability\nsample of students was selected from each school to\nparticipate in the survey.\nSurvey mode\nThe NCS-A interview was administered face-to-face to\nadolescents in their homes using laptop computer-assisted\npersonal interviews (CAPI) by professional survey inter-\nviewers from the Survey Research Center (SRC) of the\nInstitute for Social Research at the University of\nMichigan. The decision to use CAPI rather than paper-\nand-pencil (PAPI) interviews was based on the fact that\nthe interview schedule had many complex skips that\ncreate opportunities for interviewer error. These errors\nare avoided in CAPI. CAPI is also cost-effective when the\nsample size is as large as in the NCS-A, as the costs of\nprogramming are less than the labor needed to keypunch\nPAPI responses. Parents were asked to complete paper-\nand-pencil self-administered questionnaires (PSAQ)\nwhile their children were being interviewed. In the\nschool sample, Principals and Mental Health Coordina-\ntors were asked to complete a self-administered question-\nnaire (SAQ) describing the school and its mental health\nresources.\nAs the NCS-A asked a number of embarrassing ques-\ntions, audio computer-assisted self-administered inter-\nviewing (A-CASI) might have been used instead of CAPI.\nA-CASI allows respondents to enter answers into a laptop\nwithout the interviewer knowing their answers by using\ndigital audio recordings and headsets connected to the\nlaptop to administer the survey questions. Considerable\nevidence shows that A-CASI can lead to significantly\nhigher reports of some illegal and embarrassing behav-\niors, although the evidence is more mixed for responses\nto questions about emotional problems (Tourangeau and\ndecision not to use A-CASI was based on the fact that it\nwas not used in the NCS-R, which would have made it\ndifficult to use it in the NCS-A. The decision not to use\nA-CASI in the NCS-R, in turn, was based on a concern\nabout non-comparability of responses for purposes of\ntrending with the baseline NCS.\nThe decision to use SAQ rather than interviewer\nadministered surveys to collect parent data was based\nlargely on financial constraints. As the vast majority of\nthe PSAQ data were collected while interviewers were in\nthe homes of respondents completing the adolescent\ninterviews, the marginal costs of the PSAQ data was quite\nlow. Trade-offs were that the PSAQ response rate was\nlower than if parents had been interviewed and that the\namount and subtlety of data collected from parents were\nlimited by the use of SAQ. But these were consequences\nthat were unavoidable based on financial constraints.\nIn the case of the SAQ data collected from school\nPrincipals and Mental Health Coordinators, the number\nof respondents was small enough that the increased cost\nof face-to-face data collection was not an issue, but the\nSAQ was found to be logistically the most efficient way to\nKessler et al. NCS-A design and field procedures\ncollect these data because of the difficulty finding enough\ntime for the Principals and Mental Health Coordinators\nto complete interviews. In cases where completed SAQ\ninformation could not be obtained, respondents were\noffered the opportunity to provide the information in a\ntelephone interview or in-person interview.\nFieldwork organization and procedures\nAs noted earlier, the NCS-A fieldwork was carried out by\nthe same professional SRC national field interview staff\nthat carried out the NCS-R. There were 197 interviewers\nsupervised by a team of 18 experienced regional supervi-\nsors. A study manager located at the central SRC facility\nin Michigan oversaw the work of the supervisors and their\nstaff. After sample selection (see later), each interviewer\nreceived a folder for each target household. An advance\nletter was sent to the household a few days before the\ninitial interviewer contact attempt explaining the study\nand providing an 800 number for questions prior to the\ninterviewer visiting their household. This mailing also\nincluded a brief brochure that posed and answered the\nquestions often asked by survey respondents (e.g. How\ndid you select my child? Will all answers be confidential?\nWhat will be done with the answers?).\nUpon making in-person contact, the interviewer\nanswered questions before obtaining written informed\nconsent from the parent and written informed assent\nfromtheadolescent.Inthehouseholdsample,onerandom\nadolescent was selected when more than one resided in\nthe household using a computer-based method in which\nthe names of all resident adolescents in the household\nwere entered into the computer and a routine pro-\ngrammed into the computer selected the random respon-\ndent. In the school sample, the adolescent was identified\nby the school roster. If more than one adolescent in a\nhousehold was selected in the school sample, which occa-\nsionally happened by chance, both were invited to par-\nticipate. Only after the parent provided signed informed\nconsent was any contact made with the adolescent. Inter-\nviews were never conducted with a non-emancipated ado-\nlescent unless at least one parent or guardian was present\nin the home during the interview. However, no parent\nconsent or parent questionnaire was requested in the\nsmall number of cases where an emancipated minor was\ninterviewed. Adolescents were given $50 as a token of\nappreciation for participating in the survey interview,\nwhile parents were given $50 for completing the SAQ.\nSchool Principals and Mental Health Coordinators were\nalso given $50 each to complete the SAQ describing the\nschool and its mental health resources.\nThe Human Subjects Committees of both Harvard\nMedical School (HMS) and the University of Michigan\napproved these recruitment, consent, and field\nprocedures.\nInterviewer training and field quality control\nEach professional SRC interviewer is required to complete\na two-day General Interviewer Training (GIT) course\nbefore working on any SRC survey. In addition, experi-\nenced interviewers have to complete GIT refresher course\nat the beginning of every new survey in which they work.\nEach NCS-A interviewer additionally received a five-day\ntraining specific to the NCS-A. Several steps were taken to\nensure quality of fieldwork. Sample households were\nselected centrally to avoid interviewers recruiting respon-\ndents from preferred neighborhoods. The computerized\nComposite International Diagnostic Inverview (CIDI)\nhad a built-in clock to record speed of data entry, making it\ndifficult for interviewers to shorten interviews by skipping\nsectionsorfillinginsectionsquickly.Supervisorsreviewed\neach interview within 24 hours of completion to check for\na wide range of errors. Supervisors contacted a random\n10% of interviewed households to confirm address, enu-\nmeration, random selection procedures, interview length,\nand a random sample of question responses. Completed\nCAPI interviews were sent electronically to supervisors\nevery night for this purpose. In cases where problems were\ndetected, interviewers were instructed to re-contact the\nrespondent to obtain the missing data.\nThe sample design\nHousehold sample selection procedures\nAs noted earlier, the NCS-A household survey was con-\nducted as a supplement to the NCS-R. The NCS-R house-\nholds that included adolescents were included in the\nNCS-A. The school sample was recruited from the same\nsample of counties as the NCS-R. A comprehensive gov-\nernment list of schools was used for selection. The house-\nhold sample also included adolescents who were not\ncurrently enrolled in school. Selection of NCS-R house-\nholds is described in detail elsewhere (Kessler et al., 2004)\nand will not be repeated here other than to note that the\nhouseholds were based on a three-stage clustered area\nprobability sampling design that was representative of\nhouseholds in the continental US.\nSchool sample selection procedures\nThe school sample was selected using the same methods\nas other SRC school-based surveys (Johnston et al., 2007).\nNCS-A design and field procedures Kessler et al.\nAlthough school-based samples miss adolescents who\nhave dropped out of school, approximately 96.6% of US\nadolescents in the age range 13\u00ad17 are students (see\nhttp://www.census.org), which means that the under-\ncoverage involves only 3.4% of the population in the\ntarget age range. In addition, the NCS-R household\nsample included non-students, which provided some\ninformation about how they differ from students.\nHowever, the number of non-students was so small in the\nhousehold sample (n = 25) that no precise inferences\ncould be made about this segment of the population. The\nanalysis consequently focused on students both in the\nhousehold sample and in the school sample. This exclu-\nsion is important to keep in mind when considering\nrelatively uncommon disorders that might be highly con-\ncentrated among non-students, such as bipolar disorder,\nwhere even the exclusion of a mere 3.4% of the population\nmight lead to meaningful under-estimation of\nprevalence.\nIn the school sample, a representative sample of middle\nschools, junior high schools, and high schools was selected\nwith probabilities proportional to the size of the student\nbody in the classes relevant to the target sample (i.e., ages\n13\u00ad17), in each of the counties or county clusters that\nmade up the primary sampling units (PSUs) of the nation-\nally representative NCS-R sample. The schools were\nselected from a master file of all licensed schools in each\nPSU. All accredited schools were eligible, including private\nand residential schools. In some cases where there were\nseveral small schools in a geographic area, those schools\nwere combined to form a cluster that was treated as a\nsingle school for purposes of sampling.\nRecruitment began by contacting school districts with\nletters that described the purpose of the study. With the\ndistrict's approval, individual school Principals were con-\ntacted and asked to provide rosters from which to contact\nstudent families for study participation. Schools were\nprovided $200 as a token of appreciation for this\ncooperation. Within each school, a random sample of\n40\u00ad50 eligible students was selected for sampling. This\nwas done using a systematic selection procedure imple-\nmented by the survey firm staff member who obtained\naccess to the school roster. This procedure began with a\nrandom start and a systematic selection of every nth\nstudent in the roster beginning at the random start, where\nboth the random start and the number n are controlled\nby a computer program and is used by the survey firm\nstaff member to build the sample. Toward the end of the\nrecruitment period when more schools were needed to\ncomplete the study, school payment was increased to\nA total of 320 schools participated in the survey.\nSample selection began with a target sample of 289 schools\ninitially contacted for participation, of which only 81\nagreed. The primary reason given for refusal was reluc-\ntance to release student information for research studies.\nSome schools even had policies against giving out student\ninformation. Districts that required formal research pro-\nposals usually granted our request eventually, but some-\ntimes with the stipulation that they would only release\nstudent information if they first had parental written\nconsent. Schools of the latter typed were generally rejected\nbased on the fact that active initial consent has been\nshown in previous research to result in a very low response\nrate (Johnston et al., 2007). In cases where there were no\nreplacement schools readily available, though, this\nrequirement was accepted because there was no choice.\nThis occurred in roughly 15% of schools. As shown later,\nthe response rate was dramatically lower in this sub-\nsample, which are referred to later as blinded schools\nbecause the survey team was blinded to the identities\nof the sample students until after signed consent was\nobtained by the school Principals.\nBased on the low initial school-level response rate and\noften protracted time frame of recruitment, multiple\nreplacement schools were recruited for some refusal\nschools. Replacement schools were selected using stan-\ndard procedures to match the initial refusal schools in\nterms of school size, geographic area, and demographic\ncharacteristics (Kish, 1987). The fact that the sample\nreflects this expansion of recruitment. In cases where\nmultiple replacement schools were included in the sample\nfor one original school, the total number of interviews\ntargeted in the replacement schools added up to the\nnumber targeted for the original school.\nA question can be raised whether the high level of\nreplacement of schools led to bias in estimates. As the\nhousehold sample included respondents who were stu-\ndents in schools that refused to participate in the survey,\nthis question can be investigated empirically. As reported\nelsewhere, this analysis shows that the use of replacement\nschools did not introduce bias into estimates of either\ndisorder prevalence or treatment, the two classes of out-\ncomes included in the comparative analysis of students\nfrom refusal schools and replacement schools (Kessler\nSample disposition\nThe NCS-A sample disposition is reported in Table 1. The\noverall adolescent response rate was 75.6%, for a total of\nKessler et al. NCS-A design and field procedures\n10148 completed interviews. This is made up of response\n332) in the blinded school sample. Non-response was\nlargely due to refusal (21.3%), which in the household\nand unblinded school samples came largely from parents\nThe refusals in the blinded school sample, in comparison,\ncame almost entirely (98.1%) from parents failing to\nreturn the signed consent postcard.\nThe much higher refusal rate in the blinded school\nsample than the other samples was due to the fact that in\nblinded schools active written parental consent, in the\nform of a signed return postcard in response to a letter\nmailed by the school Principal, was required before the\nschool would release the names and addresses of sample\nadolescents to the research team. Some 74.9% of parents\nin blinded schools failed to return these postcards, while\nanother 1.5% of cases were omitted because of refusal on\nthe part of either the parent (0.9%) or the adolescent\n(0.6%) to participate after a parent had signed the\ninformed consent postcard. As in the blinded school\nsample, the majority of refusals in both the household\ncame from parents rather than adolescents.\nConsistent with parents being less cooperative than\nadolescents, the response rate to the parent SAQ was con-\nsiderably lower than in the adolescent survey: 63.0% com-\npared to 75.6%. The parent SAQ response rate could not\nbe higher than the adolescent response rate by design, as\nparent SAQs were collected only for adolescents who\ncompleted interviews. The conditional parent response\nrate given adolescent response did not differ substantially\nWeighting\nAs noted earlier in the paper, the most recent Census data\nare students. It would consequently have been expected\nthat about 31 non-student respondents would be in the\nhousehold sample (i.e. 3.4% of 904). The actual number\nwas 25. This is too few to support extrapolation to the\npopulation of the roughly half million non-student ado-\nlescents in the US. The non-student respondents were\nconsequently excluded from the bulk of the analyses,\nwhich concentrated on the 10123 respondents who were\nstudents. Weighting focused on the student population.\nAs the sample design involved a dual-frame approach, a\ndistinct weighting scheme was used to make each sample\nrepresentative of adolescents in the US household popula-\ntion on the cross-classification of a wide range of socio-\ndemographic and geographic variables. The two weighted\nsamples were then merged for purposes of analysis.\nTable 1 NCS-A sample disposition\nHousehold Unblinded school Blinded school Total\nPercentage n Percentage n Percentage n Percentage n\nI. Adolescents\nII. Parents\na Twenty-five of the household survey respondents were not students. The remaining 879 are students.\nb Fifteen of the parents who completed a questionnaire eight full questionnaire, seven short-form questionnaire were the\nparents of adolescents who were not students.\nNCS-A design and field procedures Kessler et al.\nThe household sample\nThe household sample weighting was the simpler of the\ntwo in that weights had already been developed for the\nNCS-R household sample. The NCS-R weights are\ndescribed elsewhere (Kessler et al., 2004) and will not be\ndiscussed here. The first step was to add these weights to\nthe adolescent data and adjust them for differential prob-\nability of selection of adolescents as a function of number\nof other adolescents in the household. These doubly-\nweighted data were then compared with nationally\nrepresentative Census data on basic socio-demographic\ncharacteristics for purposes of post-stratification. Two\ndata files were used for this purpose. The first was the\n2000 Census Public Use Microdata Sample (PUMS;\nhttp://www.census.gov/support/pumsdata.html) of a 5%\nsample of the entire US population. Data were extracted\nfrom the PUMS for adolescents who were students at the\ntime of the Census. The second was a small area geo-code\ndata file prepared by a commercial firm that aggregated\n2000 Census data to the level of the Block Group (BG) for\nresources/us-census-2000.html). These BG-level data\nwere linked to the data record of each NCS-A respondent,\nwhile the national distributions for the population on\nthese same BG-level variables were generated by\nweighting the BG-level data by the population of eligible\nadolescents in each BG.\nA wide range of variables available in the NCS-A as\nwell as in the PUMS or the BG-level data file was selected\nto post-stratify the NCS-A data. (Details available on\nrequest.) In addition, some information was available\nabout variables not in the Census files available for the\nNCS-A household sample, as the NCS-R was completed\nin the households of all NCS-A respondents and\nnon-respondents. In particular, comparisons and\nweighting were made for discrepancies between the\nDSM-IV/CIDI disorders reported by the adult NCS-R\nrespondents in the households of NCS-A respondents\nand non-respondents.\nThe post-stratification weight was created by using an\nexponential weighting function to make the distributions\nof post-stratification variables in the adjusted weighted\nsample agree with the distributions in the external data-\nsets. Specifically, the weight for case k was of the form\nk k k\n* exp( ) ,\n= \nwhere Wk\n* is the adjusted weight, Wk\nis the weight before\nadjustment, xk\nis the vector of characteristics associated\nwith case k (derived either from the survey data or from\nthe BGD) including a one for the intercept, and  is a\nvector of coefficients calculated to satisfy the condition\nW\nk k\n =\n* ,\nwhere X is the vector of population distributions of the\npost-stratification variables selected from the PUMS and\nBPS datasets. This procedure is a version of raking cali-\nbration, commonly used to adjust surveys to match census\ndata (Deville et al., 1993), but generalized in this case to\nallow for adjustment using continuous as well as categori-\ncal variables. A program written in the R programming\nlanguage was used to estimate  and to create these cali-\nbrated weights. The weights resulted in the distributions\nof the post-stratification variables in the weighted sample\nbeing identical to those in the population datasets, while\nmaintaining the associations among these variables\nfound in the sample.\nSome sense of the extent to which post-stratification\naffected variable distributions can be seen by comparing\nthe distributions of selected post-stratification variables\nin the sample before versus after weighting. (Table 2) For\nthe most part, the ratios of proportions based on final (F)\nweights, which equal the actual population proportions\nfound in the databases used for post-stratification, to the\ncorresponding proportions without post-stratification\nweighting (U) were in the range 0.8\u00ad1.2. This means that\nproportions typically changed by less than 20% of their\nbase. There were some exceptions, though, as illustrated\nby the fact that the proportion of the population who\ndefined themselves as neither being Non-Hispanic White,\nNon-Hispanic Black, or Hispanic is only 61% as high in\nthe population (5.0%) as in the unweighted sample before\npost-stratification (8.2%).\nThe school sample\nWeighting for the school sample was based on weights\nthat controlled for three sets of variables. The first set was\nextracted from the Quality Education Data (QED) data-\nbase, a commercially-produced database of the character-\nistics of all primary and secondary schools in the US\n(http://www.qeddata.com), controlling to population\ntotals of these variables (weighted by school enrollment)\nadjusted for discrepancies between the schools included\nin the sample and the population of all schools in the US.\nA wide range of school characteristics were examined that\nincluded such variables as size, grades covered, type of\nschool (e.g. public versus private, special needs school,\nK-8 school, junior high school, high school), average size\nof classroom, average student/teacher ratio, and presence\nKessler et al. NCS-A design and field procedures\nTable 2 Unweighted and weighted distributions of selected NCS-A post-stratification variables among adolescent\nstudent respondents in the NCS-A household sample n = 879\nUnweighted (U) Weighted with final post-\nstratification weights (F)\nCoefficientsa\nPercentage Standard error Percentage Standard error  F/Ub\nSex\nAge\nRace/ethnicity\nFamily income BG\nUrbanicity\n12-Month DSM-IV/CIDI Diagnosis of NCS-R Participant\na Coefficients are from the exponential log-linear raking model.\nb The ratio of the unweighted value to the value in the final weight.\nc Any mood disorder consists of DSM-IV/CIDI diagnoses of bipolar disorder, major depressive disorder, or dysthymic\ndisorder.\nd Any anxiety disorder consists of DSM-IV/CIDI diagnoses of generalized anxiety disorder, panic disorder, social phobia,\nor specific phobia.\ne Any impulse-control disorder consists of a DSM-IV/CIDI diagnosis of IED only Part I diagnoses from the NCS-R could\nbe assessed here.\nversus absence of various school programs. The other two\nsets of variables were the same PUMS and BG-level data-\nsets used in the household sample. The same statistical\napproach to weighting was used as in the household\nsample. The within-household probability of selection\nweights used in the household sample, though, were not\nneeded in the school sample, as schools and students\nwithin schools were selected with probabilities propor-\ntional to the size of the eligible student body.\nAs with the household sample, post-stratification did\nnot have dramatic effects on distributions of the post-\nstratification variables in the school sample. (Detailed\nNCS-A design and field procedures Kessler et al.\nresults available on request.) For the most part, relative\nproportions based on final (F) weights compared to\nmeans that proportions typically changed by less than\n25% of their base. For example, the proportion of adoles-\ncents who are non-Hispanic White was estimated to be\n55.5% before post-stratification compared to the actual\npopulation distribution of 65.6%, a relative increase of\nstratification. This general pattern of relatively modest\nadjustments in proportions held for the vast majority\nof the post-stratification variables included in the\nanalysis.\nWeight trimming\nWhen weights vary greatly relative to the mean, estimates\ntend to have large standard errors. This, in turn, leads to\ninefficiency in estimation. It is possible to deal with this\nproblem by trimming extreme weights. There is a trade-\noff in doing this, though, as weight trimming can lead to\nbias in estimates. If the reduction in variance created due\nto added efficiency exceeds the increase in variance due\nto bias, the trimming is helpful overall. Weighting is\nunhelpful, in comparison, if the opposite occurs (i.e.\nthe increase in bias is greater than the decrease in\nimprecision).\nIt is possible to study this trade-off between bias and\nefficiency empirically in order to select an optimal weight\ntrimming scheme by calculating the mean squared error\n(MSE) of estimates of substantive importance. This was\ndone by evaluating the effects of weight trimming on 10\nprevalence estimates: lifetime and 12-month prevalence\nestimates of any DSM-IV/CIDI mood, anxiety, external-\nizing, substance use, and any disorder. As described in\ndetail elsewhere (Kessler et al., 2009b), the DSM-IV\ndiagnoses generated in the NCS-A combine parent and\nadolescent reports and have good concordance with inde-\npendent diagnoses based on semi-structured research\ndiagnostic interviews with parents and adolescents by\nblinded clinical interviewers in an NCA-S clinical reap-\npraisal study. In order to evaluate the effects of weight\ntrimming on prevalence estimates based on the CIDI\ninterviews, MSE for variable Y at trimming point p was\ndefined as\nMSE Var( ),\np p\nwhere BYp\nis the bias of the prevalence estimate at that\ntrimming point and Var(Yp\n) is the variance of Y at trim-\nming point p. An unbiased estimator of B2\nYp\nis\n^ ^ ) ^ ^\np p p\n( Var( ),\nwhere ^\nis an unbiased estimator of bias and V\u00e2r(^\n) is\nthe estimated variance of ^\n. This means that and unbi-\nased estimator for Equation 3 can be rewritten as\nMSE ( Var( ) Var( ).\n^ ^ ) ^ ^ ^ ^\np p p\nEach of the three elements in Equation 5 can be esti-\nmated empirically for any value of p in comparison to an\nuntrimmed estimate (which is assumed to be unbiased),\nmaking it possible to calculate MSE across a range of\ntrimming points to determine the trimming point that\nminimizes MSE for any given variable Y. The first term,\n(^\n)2, can be estimated directly as (Yp\nrepresents the weighted prevalence estimate of Y based on\nthe untrimmed data and Yp\nis the weighted prevalence\nestimate based on data trimmed at trimming point p. The\nother two elements in Equation 5 can be estimated using\npseudo-replication (Zaslavsky et al., 2001). In the present\ncase, this was done by generating 84 separate estimates\nfor Yp\nat each value of p for each of the two samples. The\nnumber 84 is based on the fact that the NCS-R sample\ndesign has 42 geographic strata (made up of PSUs or, in\nthe case of non-self-representing PSUs, pairs of PSUs)\neach with two sampling-error calculation units (SECUs;\nconstituting sub-samples within self-representing PSUs\nand individual PSUs within strata that are made up\nof multiple non-self-representing PSUs), for a total of\n84 stratum-SECU combinations. The separate estimates\nwere obtained by sequentially modifying the sample and\nthen generating an estimate based on that modified\nsample. The modification consisted of removing all cases\nfrom one SECU and then weighting the cases in the\nremaining SECU in the same stratum to have a sum of\nweights equal to the original sum of weights in that\nstratum. If Yp\nis defined as the weighted estimate of Y at\ntrimming point p in the total sample and Yp(sn)\nis defined\nas the weighted estimate at the same trimming point\nin the sample that deletes SECU n (n = 1, 2) of stratum s\n) can be estimated as\nVar( ) SUM\n^ [( ) ( ) ]/\ns s\np s p p p p\n= - + -\nVar(BYp\n) was estimated in the same fashion by replacing\nYp(sn)\nin Equation 4 with\n^ ^\n( ) ( ) ( ) ( )\nYp sn p sn sn p Yp sn p\n= - = -\nand replacing with\nThis method was used to evaluate the effects of trim-\nming between 1% and 10% of respondents at each tail of\nKessler et al. NCS-A design and field procedures\nthe weight distribution in each of the two samples. Trim-\nming consisted of assigning the weight at the trimming\npoint to all cases with more extreme weights on that tail\nof the weight distribution. The weighting analysis\ndescribed in Equation 1 and 2 was replicated anew for\neach combination of trimming points on the two tails so\nas to obtain an accurate post-stratification of the weighted\nsample to the population. Prevalence estimates and their\ndesign-based standard errors, which were estimated using\nthe Taylor series method (Wolter, 1985), were then calcu-\nlated for each of the 10 variables used in the analysis of\nbias-efficiency trade-off. Inspection of empirical varia-\ntion in MSE with changes in trimming rules was used to\nselect final trimming rules that were used to generate the\nresults in Table 2.\nIn both samples, MSE was not strongly affected by\ntrimming. Final trimming rules were consequently\nchosen that trimmed the minimum proportion of cases\nwhile approximating the minimum average MSE across\nall possibilities considered. In the household sample, no\nweight trimming was performed for low weights but the\nhighest 2.5% of weights were trimmed. This reduced the\ncoefficient of variation of weights (the ratio of the stan-\ndard deviation of weights to the mean weight) by about\n8%. This was achieved with a roughly 2% increase in\nMSE due to bias, for a total reduction in MSE of approxi-\nmately 6%. In the school sample, the bottom 2.9% and\nupper 0.1% of weights were trimmed, reducing the co-\nefficient of variation of weights by about 9%. This was\nachieved with a nearly 4% increase in MSE due to bias,\nfor a total reduction in MSE of approximately 5%.\nWeighting the parent sample\nThe weights described so far were developed for the full\nsamples. Weights were similarly calculated for the sub-\nsamples of cases with parent data to make possible analy-\nses requiring these responses. To make these samples\nnationally representative with respect to the weighting\nvariables, the weighting analyses described earlier was\nreplicated by treating the total sample as the `population'\nand the sub-sample of cases with parent SAQ data as the\n`sample.'Thepost-stratificationcontrolvariables included\nall those used in the full-sample analyses in addition to\nthe lifetime and 12-month prevalence estimates in the\ntotal sample of DSM-IV/CIDI mood, anxiety, impulse-\ncontrol, and substance disorders. By controlling for the\npresence of diagnoses adjustments were made for possible\ntendencies of parents to be either more or less likely to\nrespond to the SAQ when their children had certain types\nof diagnoses. At the same time the national representa-\ntiveness of the full sample with respect to demographic\nand school characteristics was retained. This re-weight-\ning was carried separately in the household and school\nsamples and, within each of these samples, in the sub-\nsamples with full SAQ data and either full or partial SAQ\ndata. The final trimmed weights from the total sample\nwere included as base weights in these analyses and no\nfurther trimming was done when the post-stratification\nweights were applied to the data.\nCombining the weighted household and\nschool samples\nThe research team plans to carry out substantive analyses\nof the NCS-A data largely in a consolidated sample that\ncombines the household and school samples. Some deci-\nsion about relative weighting is needed to do this combin-\ning. The obvious approach is to transform the weights in\neach sample to sum to the number of respondents in the\nsample and then combine these two weighted data files\ninto a single file. However, this approach implicitly\nassumes that the two samples have the same efficiency.\nThis assumption turns out to be incorrect, as shown by\nthe fact that the H/S ratio of design-based variance esti-\nmates of various descriptive measures in the household\nsample (H) relative to the school sample (S) is generally\nlower than the roughly 10.5:1 ratio of the two sample\nhousehold sample is more efficient for this set of estimates\nthan the NCS-A school sample (Table 3). The reason for\nthis is that the NCS-A household sample has less cluster-\ning than the school sample because the number of ado-\nlescent student respondents in the household sample (n =\n879) is smaller than the number of area segments (n =\n1001). In the case of the school sample, in comparison,\nthe number of adolescent respondents (n = 9244) is nearly\n30 times larger than the number of schools (n = 320),\nwhich means that there is considerable clustering at the\nsegment level.\nBased on these results, the approach taken to combine\nthe household and school samples into a single larger\nconsolidation sample gave higher weight to the household\nsample in recognition of the greater efficiency of the\nhousehold sample than the school component. This\napproach is based on the goal of combining the two\nsamples into a consolidated dual-frame sample that mini-\nmizes the overall MSE of estimates, which is achieved\nwhen the two samples are weighted inversely proportional\nto their MSEs (Lepkowski and Groves, 1986). Based on\nthe results reported in Table 3, this was done by assuming\nthat the variance of estimates average six times higher in\nNCS-A design and field procedures Kessler et al.\nTable 3 Ratios of design-based variance estimates of\nselected descriptive statistics in the household sample H\nrelative to the school sample S\nVariance ratios\nMean Trimmed\nmeana\nMedian\nI. DSM-IV/CIDI disorder prevalence estimatesb\nII. Predictive effects of socio-demographic variables on\ndisorder prevalencec\na Mean among observations in the 25th\u00ad75th percentile\nrange on the distribution of variance ratios.\nb Lifetime, 12-month, and 30-day prevalence estimates\nof any DSM-IV/CIDI mood disorder, anxiety disorder,\nimpulse-control disorder, substance disorder, and any\ndisorder.\nc Based on multivariate logistic regression equations to\npredict each of the 15 outcomes in Part I of the table.\nthe household sample than the school sample, which\nmeans that we constructed the consolidated sample so\nthat the sum of weights in the school sample was six times\nthat of the sum in the household sample. Combined\nsamples were created using this same weighting approach\nfor the PSAQ student sample and the short-form PSAQ\nsample.\nAnalysis with combined and separate samples\nAlthough the bulk of NCS-A analyses will be carried out\nwith the consolidated dataset, we also plan to carry out\nsensitivity analyses of critical results in the separate\nhousehold and school sub-samples because a criticism\ncould be raised that the school sample does not represent\nthe population as well as the household sample based on\nthe fact that the majority of the schools originally\nselected to participate in the NCS-A school sample did\nnot participate and had to be replaced. The household\nsample, in comparison, had a high adolescent response\nrate (85.9%). It would be comforting to find that substan-\ntive results found in the combined sample could be\nreplicated in the household sample as well as in the\nschool sample.\nDesign effects\nAlthough the effects of weighting and clustering can be\ndescribed in a number of ways, a particularly convenient\napproach is to calculate a statistic known as the design\neffect (DE; Kish, 1965) for a number of variables of inter-\nest. The DE is the square of the ratio of the design-based\nstandard error of a descriptive statistic divided by the\nsimple random sample standard error. The design-based\nstandard error can be calculated using a number of\nmethods (Wolter, 1985), each of which takes into consid-\neration information about the clustering and weighting\nof the data. The DE can be interpreted as the approximate\nproportional increase in the sample size that would be\nrequired to increase the precision of the design-based\nestimate to the precision of an estimate based on a simple\nrandom sample of the same size. DEs due to clustering\nare usually a good deal larger in estimating prevalence\nand other first-order statistics than more complex statis-\ntics, as the number of respondents having the same char-\nacteristics in the same SECU of a single stratum becomes\nsmallerandsmallerasthestatisticsbecomemorecomplex.\nThis leads to a reduction in the effects of clustering in the\nestimation of DE. DEs due to weighting are also usually\nsomewhat smaller for multivariate than bivariate descrip-\ntive statistics because DEs are due not only to the variance\nof the weights but also to the strength of the association\nbetween the weights and the substantive variables under\nconsideration.\nBecause means typically have higher DEs than other\nstatistics, evaluations of DEs typically focus on the esti-\nmation of means. However, we also examined associa-\ntions of three socio-demographic variables (age, sex, and\na dichotomy for non-Hispanic White race-ethnicity\nversus all others) with the disorder clusters. The latter\nincluded 30-day, 12-month, and lifetime prevalence of\nany DSM-IV/CIDI anxiety disorder, mood disorder,\nimpulse-control disorder, substances disorder, and any\ndisorder (five classes of disorder in each of three time\nframes). The DEs for prevalence are in the range 1.4\u00ad1.6\nin the household sample, 3.1\u00ad4.6 in the school sample,\nand 3.3\u00ad4.5 in the combined sample (Table 4). The DEs\nfor the associations of socio-demographic variables with\nthe disorders in the household sample are similar to those\nfor the prevalence estimates (1.4\u00ad1.7), while those in the\nschool sample are lower than for the prevalence estimates\n(2.9\u00ad3.5). The same is true for the DEs for the associations\nin the combined sample (2.4\u00ad2.9). The DEs are consis-\ntently lower for estimates involving 30-day disorders than\n12-month or lifetime disorders because less common out-\ncomes generally have lower DEs because multiple cases of\nKessler et al. NCS-A design and field procedures\nTable 4 Design effectsa for prevalence estimates of\nDSM-IV/CIDI disorder clustersb and for associationsc\nbetween socio-demographic variables and these clusters\nin the NCS-A household sample, school sample, and\ncombined sample\nHousehold School Combined\nPrevalence estimates of DSM-IV/CIDI disordersb\nSocio-demographic associationsc\na Design effects are the squares of the ratios of the stand-\nard errors of design-based estimates and estimates based\non the assumption of simple random sampling. See the\ntext for a more detailed discussion of the substantive\ninterpretation of design effects.\nb The five DSM-IV/CIDI disorder clusters considered in\neach of three time frames 30-day prevalence, 12-month\nprevalence, and lifetime prevalence are any anxiety dis-\norder, any mood disorder, any impulse-control disorder,\nany substance disorder, and any disorder.\nc Associations were estimated in logistic regression equa-\ntions that used information about respondent age, sex,\nand race-ethnicity non-Hispanic White versus all others to\npredict each of the five outcomes in each of the three time\nframes.\nthese outcomes seldom occur in a single SECU, leading\nto low clustering. Because of this fact, we can expect the\nDEs associated with the prevalence and correlates of indi-\nvidual disorders to be lower than those reported here for\ndisorders clusters.\nIt is important to recognize that the above calculations\ndid not take into consideration the fact that post-stratifi-\ncation weighting improves the extent to which the sample\nis representative of the population with respect to post-\nstratification variables compared to a simple random\nsample. As a result, design effects are over-estimated to\nan unknown degree in the results reported in Table 4.\nThis bias could be corrected by using a pseudo-replica-\ntion simulation approach to estimate DE and building in\nthe post-stratification to each replicate. When we use\npseudo-replication to estimate design effects, as we do\nfor highly non-linear statistics where the linearization\nassumption of the Taylor series method might be violated,\nwe use the jackknife repeated replications (JRR) method\nof pseudo-replication (Kish and Frankel, 1974). As\ndescribed in more detail elsewhere (Kessler et al., 2004),\nwe work with 76 JRR pseudo-samples in the NCS-R and\nNCS-A. This means that we estimate coefficients of inter-\nest 76 separate times, once in each pseudo-sample, and\nthen use information about the distribution of the co-\nefficient across the pseudo-samples to estimate design\neffects. The positive effects of post-stratification could be\nbuilt into this procedure by developing post-stratification\nweights for each pseudo-sample, which would decrease\nvariation across the pseudo-samples to some degree and\nreduce the empirical estimates of design effects appropri-\nately. We did not do this, though, based on the fact that\nit would be labor-intensive to develop 76 separate post-\nstratification weighting schemes and our past experience\nhas been that this exercise only has modest effects in\ndecreasing estimates of design effects.\nModel-based versus design-based estimation\nThe weights described earlier were developed in order to\nsupport a program of substantive data analysis based on\n`design-based' estimation of descriptive and inferential\nstatistics; that is, estimation that attempts to make the\nsample representative of the population with respect to\nweighting variables and to make standard errors of survey\nestimates accurate by using information about the sample\ndesign (i.e. clustering and weighting) to adjust for dis-\ncrepancies between the sample and the population in\nestimating descriptive statistics and to adjust for discrep-\nancies between the sample design and a simple random\nsample in estimating inferential statistics (Wolter, 1985).\nThe alternative to design-based estimation is `model-\nbased' estimation, in which inferences are made by build-\ning a statistical model that attempts to include all variables\nneeded to adjust for discrepancies between the sample\nand the population, including controls for weights and\nsample clusters (DuMouchel and Duncan, 1983).\nIf clusters or weights are judged based on appropriate\nanalyses not to contribute meaningfully to the prediction\nof substantive outcomes and not to have meaningful\ncorrelations with substantive predictors in model-based\nanalyses, these design variables can be deleted as controls\nin the prediction equations, leading to an increase in the\nprecision of estimates and to substantially better preci-\nsion than in design-based analyses (Gelman, 2007).\nMeaningful interactions between substantive predictors\nand variables that define either clusters or weights can\nbe included in prediction equations. However, the\nNCS-A design and field procedures Kessler et al.\ninterpretation of these coefficients becomes very complex\nwhen many such interactions exist, in which case design-\nbased estimation becomes more attractive.\nIt has been our experience in the past that many\ncomplex interactions exist between substantive predic-\ntors of mental disorders and design variables (i.e. clusters\nand weights) in community epidemiological surveys. As\na result, we have based the bulk of our substantive analy-\nses of design-based rather than model-based methods.\nHowever, these experiences have largely been based on\nsurveys of adults. To investigate this possibility in the\nNCS-A, we carried out preliminary analyses of associa-\ntions of NCS-A clusters (strata and SECUs) and weights\nas predictors of the same 10 DSM-IV/CIDI classes of\nmental disorders as considered in the analysis of weight\ntrimming. We also examined these design variables as\nmodifiers of the predictive effects of several basic socio-\ndemographic predictors of these disorders, including age,\nsex, race-ethnicity, and parental education (Table 5). The\nc2 values of main predictive effects show that the clusters\n(83 dummy predictor variables for strata-SECUs) are sig-\nnificant predictors of all 10 outcomes, while weights are\nnot. Weights are involved, though, as significant modifi-\ners of the associations between socio-demographics and\nthe associations of the four socio-demographic variables\nwith the 10 outcomes). This is much more than the 5%\nwe would expect on the basis of chance alone. Significant\ninteractions of socio-demographics with clusters are even\nmore common, occurring in 60% of the cases examined\n(24/40). These results strongly suggest that substantial\ncomplexities would arise in attempting to use model-\nbased methods to estimate substantive associations with\nthe NCS-A data.\nOptimizing the design for a fixed budget\nWe have discussed budget constraints several times earlier\nas providing a rationale for various design decisions. It is\nworth noting in this regard that survey methodologists\nhave developed formal procedures for optimizing survey\ndesigns for a fixed budget (Kish, 1987). These procedures,\nthough, require prior information to be available on the\naccuracy of data collected from alternative sources (in\nour case, adolescents, parents, and possibly even teach-\ners), using various procedures (in our case, self-report\nquestionnaires, fully-structured diagnostic interviews,\nand semi-structured clinical interviews), the associations\namong these reports, and the relative costs of collecting\ndata of each sort (Groves, 1989). We did not have access\nto such data in designing the NCS-A. In addition, we had\nthe constraint that the sample of adolescents had to be\nIt is possible, though, to carry out an analysis of design\noptimization post hoc in an effort to guide future research-\ners. We did this for the adult NCS-R survey and found\nthat the optimal design to estimate the prevalence of\nclinical diagnoses (that is, diagnoses based on the SCID\nclinical reappraisal interviews rather than on the CIDI)\nwould have reduced the sample of CIDI interviews from\nof SCID clinical reappraisal interviews to about 2000\n(Kessler et al., 2004). It is noteworthy that the optimal\nNCS-A was not to eliminate CIDI interviews entirely and\nto carry out only SCID interviews. This is because the\nCIDI was found to contain information that predicted\nSCID diagnoses strongly at a cost considerably less than\nthe cost of administering a SCID interview.\nWe are constrained in carrying out a similar post hoc\nanalysis of design optimization in the NCS-A because we\nhave no information about the implications of the most\nobvious design change: carrying out either face-to-face or\ntelephone interviews with parents that assessed all the\nDSM-IV disorders considered in the survey rather than\nusing self-administered parent questionnaires to assess\nonly a subset of these diagnoses. It might be that the\noptimal fixed-cost design would have been one that\nreduced the sample size below (perhaps substantially so)\nthe target of 10000 and included interviews with parents.\nIt is also possible that optimal allocation of resources to\nminimize mean-squared error of K-SADS diagnoses\nwould have resulted in a decrease in the number of\nrespondents (both parents and youth) administered fully-\nstructured CIDI interviews and increased the number\nthat received semi-structured K-SADS clinical reappraisal\ninterviews. It would be valuable for formal analyses of\nthese alternatives to be undertaken using available data\nfrom existing surveys where all these elements are in\nplace. We suspect that this exercise will show that the\noptimal design for estimating prevalence based on clini-\ncal assessments and estimating correlates of clinical diag-\nnoses would be one that included interviews with parents\nand a somewhat lower ratio of CIDI to K-SADS interviews\nthan in the NCS-A.\nOverview\nThis paper presented an overview of the NCS-A survey\ndesign and field procedures. The design allowed us to\ngather data from a national sample of adolescents and\nschools weighted to be representative of the population\non a wide range of socio-demographic, school, and\nKessler et al. NCS-A design and field procedures\nTable 5 Chi-square values of the main effects and interactions of design effects and socio-demographic variables in predicting lifetime and 12-month disorder\nLifetime disorders Twelve-month disorders\nMoodb Anxiety Impulse-controlb Substance Anyb Moodb Anxiety Impulse-controlb Substance Anyb df\nI. Main effects of clusters and weights\nII. Main effects of demographics\nParent\neducationc\nIII. Interactions involving weights\nIV. Interactions involving clusters\na There are n = 10123 observations with weights and design effects. Each effect is looked at through a bivariate model.\nb These disorders use information parent SAQs and consequently are limited to the 6483 cases with completed PSAQs\nc Parent education is defined as the maximum number of years of education of either parent. Categories are: 0\u00ad11 years, 12 years, 13\u00ad15 years, 16+ years\nd Due to sparse data, some models were run with a forward regression logistic model that stepped in two-way interactions included at an entry criterion of\np = 0.95 i.e. even very small coefficients were entered. The number of degrees of freedom in these models is lower than in the saturated model.\n*Significant at the 0.05 level.\nNCS-A design and field procedures Kessler et al.\ngeographic characteristics. Although less desirable than\ninterviewer-administered survey data, the parent SAQ\ndata were obtained very cost-effectively and provide valu-\nable collateral information about family history, develop-\nmental milestones, and externalizing disorders of the\nadolescent respondents. The SAQ data provided by\nPrincipals and Mental Health Coordinators, further-\nmore, provide information that might prove to be valu-\nable in expanding our understanding of the ways in which\nschool characteristics influence detection and response\nto adolescent mental disorders. Innovative methods of\npost-stratification, weight trimming, and combination\nof the household and school samples improve the\nrepresentativeness and efficiency of the consolidated\nsample.\nAn important limitation of the NCS-A is the relatively\nlow response rate of schools in the school sample and of\nindividual respondents in the blinded school sub-sample.\nThe response rate of adolescents in the household sample\nwas considerably higher. Because of this between-sample\ndifference, we will carry out sensitivity analyses sepa-\nrately in the household and school samples. Consistency\nof results across the two samples will be taken as an\nindication of robustness of findings.\nDespite the limitation imposed by the low response\nrate of schools, the data on comparisons of sample and\npopulation characteristics at the level of the individual\nwith Census socio-demographic characteristics and at the\nlevel of the school with administrative databases are very\nencouraging regarding the representativeness of the\nsample. The rich substantive information contained in\nthe NCS-A will allow many analyses to be carried out to\nincrease our understanding of the health and well-being\nof adolescents in the US.\n"
}