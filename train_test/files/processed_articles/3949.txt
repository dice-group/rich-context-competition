{
    "abstract": "Abstract\nWe demonstrate an expanded procedure for assessing drug-label comprehension. Innovations include a pretest of\ndrug preconceptions, verbal ability and label attentiveness measures, a label-scanning task, a free-recall test, category-\nclustering measures, and preconception-change scores. In total, 55 female and 39 male undergraduates read a facsimile\nDrug Facts Label for aspirin, a Cohesive-Prose Label, or a Scrambled-Prose Label. The Drug Facts Label outperformed\nthe Scrambled-Prose Label, but not the Cohesive-Prose Label, in scanning effectiveness. The Drug Facts Label was no\nbetter than the Cohesive-Prose Label or the Scrambled-Prose Label in promoting attentiveness, recall and organization\nof drug facts, or misconception refutation. Discussion focuses on the need for refutational labels based on a sequence-\nof-events text schema.\n",
    "reduced_content": "Health Psychology Open\nReprints and permissions:\nsagepub.com/journalsPermissions.nav\njournals.sagepub.com/home/hpo\nCreative Commons Non Commercial CC BY-NC: This article is distributed under the terms of the Creative Commons\nAttribution-NonCommercial 4.0 License (http://www.creativecommons.org/licenses/by-nc/4.0/) which permits non-commercial use,\nreproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open\nAccess pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).\nIntroduction\nThe burden that a nonprescription drug label bears is to\ninform consumers how to self-medicate safely and effectively\nwithout the guidance of a physician or pharmacist (Soller,\n(FDA, 1999) made a formal effort to lighten that burden by\nstandardizing the content, order, and format of all nonpre-\nscription drug labels with the now-familiar Drug Facts Label\n(DFL). The FDA continued this effort by requiring pharma-\nceutical drug manufacturers to conduct label comprehension\nstudies for all nonprescription drugs. In their Guidance to\nIndustry (FDA, 2010), the FDAsuggests that questions about\nthe primary communication objectives of a proposed label be\nposed to potential consumers in one-to-one interviews using\nan \"open-label\" procedure. Respondents are\n... told before the study starts that they can refer to the label\nduring questioning. Questions can begin with the statement\n\"according to the label,\" however, subjects should not be overly\nprompted to look at the label during questioning. (FDA, 2010: 9)\nThe primary objective of this study is to demonstrate\nan expanded label comprehension procedure that\naddresses critical deficiencies in the current open-label\nprocedure.\nA study designed by Raymond et al. (2002) with guid-\nance from the FDA offers a rare published example of the\nopen-label procedure. Raymond et al. assessed label com-\nprehension of prototype DFL panels on a two-pill package\nof a nonprescription emergency contraceptive (Plan B\nTwo-Step) and the six-panel patient insert inside the pack-\nage. The text on the outside of the package conformed to\nDFL standards; the text insert inside the package provided\nDoes the Drug Facts Label for\nnonprescription drugs meet its\ndesign objectives? A new procedure\nfor assessing label effectiveness\nMichael P Ryan and Reagan N Costello-White\n Keywords\nbeliefs, cognitive processing, communication, drugs, memory, methodology\nThe University of Texas at San Antonio, USA\nCorresponding author:\nMichael P Ryan, Department of Psychology, The University of Texas at\nEmail: Michael.Ryan@utsa.edu\nReport of empirical study\n2 Health Psychology Open \nfurther information in a question\u00adanswer format (e.g. \"Who\nshould not use Plan B?\"). Raymond et al. made use of the\n11 primary communication objectives of the drug to\ndevelop 30 interviewer questions for assessing the commu-\nnication effectiveness of the proposed labeling. In individ-\nual interviews, eligible respondents first briefly examined\nthe external DFL panels as if considering their purchase.\nWith the package out of sight, respondents then had to\nexplain the purpose of the drug. The interviewer next asked\nrespondents five more questions (e.g. \"According to the\nlabel, should Plan B be used as regular birth control?\"),\nallowing them to consult the package label as necessary.\nAfterward, respondents were asked to open the package\nand review the six-panel package insert as if they were\nabout to use the product. Finally, respondents answered 24\nmore questions (e.g. \"Awoman had unprotected sex a week\nago and then used Plan B to prevent pregnancy. Was this a\ncorrect use of Plan B?\"), referring to the package labeling\nor the package insert as necessary.\nRaymond et al. adhered carefully to the FDA's (2010)\nGuidance for the conduct of a label comprehension study.\nIn addition, they note that their \"study design and question-\nnaire were heavily influenced by the Food and Drug\nAdministration's comments on early drafts of the protocol\"\nand well-conducted open-label study. However, we believe\nthat there are significant deficiencies in the open-label pro-\ntocol itself. Our aim in this study is to identify potential\nimprovements in the protocol that can increase the quality\nof the data obtained from label comprehension studies.\nWe identify here seven deficiencies in the open-label\nprotocol that may limit its utility for assessing the compre-\nhension of a set of drug facts. First, there is no pretest of\nrespondents' prior knowledge of contraceptive drugs.\nSecond, there is no measure of verbal ability. Third, there is\nno measure of the care taken by respondents in attending to\nthe text of the DFL or the package insert. Fourth, there is no\nassessment of the ease with which information could be\nlocated on the label in response to interviewer questions.\nFifth, there is no measure of respondents' ability to retrieve\nimportant label information from long-term memory. Sixth,\nthere is no formal evaluation of the subjective features of the\nlabel (e.g. Perceived Organization or Authoritativeness) as a\nmedication guide. And seventh, there is no posttest of\nrespondents' knowledge and beliefs to determine whether\nthe label had confirmed or corrected preconceptions\nrespondents may have had about the drug. We consider\nthese deficiencies of the open-label procedure in the follow-\ning section. We then describe in our \"Methods\" section the\nprocedure we have developed to remedy these deficiencies.\nDeficiencies in the label comprehension protocol\nAssessing medication-specific beliefs.Text comprehension\ndepends on the reader's prior knowledge of the text topic as\nnumber of studies have demonstrated that clear and well-\nwritten science passages can fail to modify a reader's mis-\nconceptions about the topic--even when the text refutes\nthose misconceptions (see Tippett, 2010). Therefore, it is\nimperative that a label comprehension study begin with an\nassessment of the preconceptions that consumers have\nabout the drug in question. This assessment should not be\nlimited to the primary communication objectives of the\nlabel. With respect to an emergency contraceptive pill, for\nexample, some misconceptions about the appropriate use of\nthe product may arise from na\u00efve beliefs about the nature of\nthe reproductive process. Morgan et al. (2002) use a \"men-\ntal models\" approach to identify procedures for eliciting\nvalid and invalid preconceptions that consumers may bring\nto their reading of health-protective communications. Rat-\ning-scale assessments of these beliefs offer a quantitative\nmeasure that can serve as a pretest measure or a covariate\nmeasure.\nAssessing verbal ability. Because medical information seems\nto pose a challenge to many consumers, label comprehen-\nsion studies often include a measure of medical literacy.\nOne popular measure is the Rapid Estimate of Adult Liter-\nacy in Medicine (REALM: Davis et al., 1993). The REALM\nassesses health literacy by asking patients to pronounce 66\ncommon medical terms. Rather than attempting to assess\ngeneral medical literacy, however, it may be more useful to\nassess the specific knowledge a consumer has about the\ndrug under consideration. The information obtained from a\npretest such as we describe above serves that purpose.\nAlthough a drug-specific pretest assesses the \"health\" com-\nponent of health literacy, it does not assess the \"literacy\"\ncomponent. Wide-range vocabulary measures offer a more\nuseful index of general verbal ability. The six-minute,\n24-item Extended Range Vocabulary Test (ERVT: Ekstrom\nrange of ability levels.\nLabel attentiveness.With few exceptions (e.g. Bix et al.,\n2009), label comprehension studies do not verify that\nrespondents have attended carefully to the text of the label.\nInstead, respondents read the label as though deciding\nwhether to purchase the drug or how to use the drug. In the\nabsence of any external check on a respondent's attentiveness\nto the label text, there are likely to be large differences among\nrespondents in what they read and what they do not read. The\nopen-label task itself compounds the problem: a respondent is\nfree to scan the label for an answer if recall fails. In order to\ncontrol statistically for differences in reading styles and moti-\nvation, a measure of label attentiveness is necessary. Ryan\n(2011) used the tactic of inserting obvious typographical\nerrors throughout a simulated analgesic label, asking partici-\npants to circle all errors they found.\nRyan and Costello-White 3\nLabel-scanning.Brass and Weintraub (2003) characterize\nthe open-label task as \"one designed to demonstrate the\nability of consumers to extract relevant information from\nthe proposed label\" (p. 407). Ease of scanning can be\nassessed by timing how long it takes a respondent to locate\ntarget information on a label, but that simple measure fails\nto take into account the possibility that a respondent may\noften be recalling the targeted information rather than find-\ning it on the label. A better measure involves giving a\nrespondent a randomized list of target words or phrases to\nbe located and marked on the label. If these targets are\ndrawn from throughout the label text, a count of the number\nof target phrases found in a fixed amount of time provides\na more valid measure of scanning-ease.\nDelayed free recall. Because some time may elapse between a\nrespondent's first reading of a drug label and the subsequent\nuse of the drug, it is important to assess the amount and accu-\nracy of the label information that a consumer can retrieve from\nlong-term memory after an initial reading. A consumer may\nnot re-read the label when the time comes to use the drug, rely-\ning instead on his or her recollection of what the label had said.\nAlthough specific circumstances might dictate another meas-\nure, a free-recall task following a distraction task (\"recall\nwhatever you can from the label as it comes to mind\") has four\nvirtues. First, a several-minute distraction task prior to the\nrecall effort ensures that a respondent is retrieving information\nfrom long-term memory rather than from short-term memory.\nSecond, a free-recall task provides a measure of recall that\ndoes not depend on question comprehension in the way that\nmultiple-choice or true\u00adfalse questions do. Third, what con-\nsumers recall and do not recall provides useful information\nabout their attention strategies. Finally, adjacent items in a\nfree-recall protocol will frequently belong to whatever subjec-\ntive category an individual has used to organize label informa-\ntion in long-term memory (Friendly, 1977). Such \"category\nclustering\" provides invaluable information about the subjec-\ntive organization of drug-label information.\nPerceived label characteristics. Label comprehension studies\noften rely on consumer perceptions in evaluating drug\nproduct labels (e.g. preferences for different label formats).\nSelf-reports and subjective ratings are no substitute for\nbehavioral assessment (e.g. label-scanning speed or free\nrecall of drug facts). Nonetheless, a drug product may fail\nin its mission if it does not have a positive impact on key\nconsumer perceptions. For example, consumers are likely\nto read a label with greater care if they perceive it to be well\nized rating scales provide an efficient way to collect infor-\nmation about consumer perceptions that are likely to\nincrease their willingness to attend to label directives.\nRe-assessing medication-specific beliefs.A posttest using rat-\ning-scale assessments of consumers' preconceptions about\na medication provides a useful index of the effectiveness of\na label in confirming and correcting drug preconceptions\n(Ryan, 2011). One aspect of \"knowledge updating\" is the\ndegree to which readers use label information to strengthen\npretest beliefs that accord with that information. A second\naspect of knowledge updating is the degree to which read-\ners use label information to weaken pretest beliefs that con-\ntradict that information. The two measures reflect different\nways in which readers modify their beliefs to accord with\nthe authoritative text of the label.\nA demonstration study\nIn order to provide a detailed illustration of our label com-\nprehension procedure, we examined the degree to which\nthe DFL (FDA, 1999) for aspirin achieves its design objec-\ntives. We discuss below the four distinguishable objectives\nidentified at different points in the FDA's 1999 Final Rule.\nObjective 1: Enhancing the appeal of nonprescription drug\nlabels. The DFL was designed to increase reading motiva-\ntion and reading confidence by reducing the cognitive\ndemands of reading drug facts information. The simplified\nwording of drug facts and the use of a highly legible visual\nformat were intended to reduce those cognitive demands\nObjective 2:Increasing the ease of finding information on a non-\nprescription drug label.The organization of the DFL was\ndesigned to help consumers quickly locate and read impor-\ntant drug information in order to permit fast and effective\nproduct comparisons. An ordered set of standard headings\n(Active Ingredients, Purposes, Uses, Warnings, Directions,\nOther Information, Inactive Information, and Questions) is\nused on the DFL to organize label information to facilitate\nObjective 3: Improving the comprehension and recall of drug\nfacts information.The layout, format, and headings of the\nDFL were designed to improve consumers' ability to read,\nunderstand, and recall label information. The DFL format\nwas thought to offer \"a more structured, organized, and\ncompact presentation\" that would reduce memory demands\nin promoting a level of comprehension and recall sufficient\nfor the safe and effective use of a nonprescription drug\nObjective 4: Providing a model for the organization of drug\nfacts information. The nature and ordering of headings in\nthe DFL were designed to develop in consumers a deci-\nsion-making process for selecting and using nonprescrip-\ntion drugs. The standardized ordering of headings in the\nDFL was meant to help consumers learn and use a deci-\nsion-making schema for organizing drug facts informa-\n4 Health Psychology Open \nLabel readability and cohesion\nThe DFL was designed to achieve its objectives through the\norganization, layout, and simplification of critical drug\ninformation. An implicit assumption is that a highly reada-\nble prose version of those facts would not serve the purpose\nas well. We could find no reports of the relative effective-\nness of prose versions of drug-label information. Therefore,\nwe seek in this study to use our modified label comprehen-\nsion procedure to test the hypothesis the DFL is more effec-\ntive than highly readable prose in achieving the FDA's four\ndesign objectives.\nWe defined a highly readable prose version of drug facts\ninformation as one that is both readable and cohesive.\nReadability as it is conventionally measured assesses word\ndifficulty and sentence complexity by computing, respec-\ntively, the average number of word strings in a sentence and\nthe average length of word strings in a text. Different reada-\nbility formulae combine these two values in different ways to\nobtain an estimate of reading level (Benjamin, 2012). The\nFDA(2010) recommends that a DFLbe written to a readabil-\nity standard of \"no higher than an 8th grade reading level\" (p.\n5). The Flesch\u00adKincaid Reading Level for our aspirin Drug\nFacts Label (DFL) facsimile (see Appendix 1), for example,\nis just at the 7th grade reading level with a value of 7.2. In\ncontrast, cohesiveness is a measure of the degree to which\nthe sentences in a text can be readily linked to each other.\nCohesiveness can be roughly estimated as the percentage of\nsentences in a text that include a word-concept from a prior\nsentence. Britton and G\u00fclg\u00f6z (1991) have demonstrated that\nreading cohesive text results in the recall of more text propo-\nsitions per unit reading time than text not so interconnected.\nCohesive text is also likely to produce in the reader a mental\nrepresentation of the relationships among key text concepts\nthat more closely resemble the mental representation of the\ntext author than do less cohesive texts (Britton and G\u00fclg\u00f6z,\nlevels of text cohesion in colorectal cancer screening infor-\nmation are associated with decreased reading time and\nincreased comprehension performance. In addition, Smith et\nal. (2011) found small but nonsignificant effects of text cohe-\nsiveness on the comprehension of research and clinical infor-\nmation about diabetes mellitus effects.\nIn order to test the hypothesis that the DFL is superior to\nhighly readable prose, we first created a prose equivalent of\nthe DFL for aspirin by expressing the drug facts on that label\nin simple sentence form. For example, \"Active Ingredient\nmg aspirin NSAID\" was re-\nwritten as \"The active ingredient in each regular-strength\ntablet is aspirin. Aspirin is a nonsteroidal anti-inflammatory\nmg of aspirin in each tablet.\"\nBulleted items were expressed as full sentences. For exam-\nple, \"Uses:  headache  muscle pain  toothache ...\" was\nre-written as \"You can use aspirin to relieve headache. You\ncan use aspirin to relieve muscle pain. You can use aspirin to\nrelieve toothache pain ....\" The headings used on the DFL\nfor aspirin were used as paragraph headings in our Cohesive-\nProse Label. We ensured that the text of this label was highly\ncohesive by including a word from a prior sentence in each\nnew sentence (see Appendix 2). We also created a scram-\nbled-prose version of the aspirin drug facts (seeAppendix 3)\nas a comparison label that included all of the drug facts in\nsentence form, but had little cohesion. Morrow et al. (1996)\nmade use of a similar logic in comparing the drug facts\nrecall of those who read an organized-prose label for a fic-\ntional drug with the recall of those who read a scrambled-\nsentences label for the same drug. Our SPL contained the\nsame sentences as the organized-prose label, but arranged\nthem in one of two random orders. No paragraph headings\nwere included in this scrambled-prose equivalent of the\ndrug facts for aspirin.\nExperimental design and hypotheses.Each participant read\nonly one of the three facsimile labels we prepared; all label\nassessment tasks were administered to every participant.\nLabel condition (DFL, CPL, or SPL) is our only between-\nsubjects treatment variable. The subject variable Verbal\nAbility is used as a covariate in all of our analyses, and\nadjusted means are reported whenever that covariate was\nsignificantly correlated with a dependent measure. We use\nthroughout a mixed-model analysis of covariance with\nLabel Condition serving as a between-subjects variable,\nVerbal Ability serving as a covariate, and one or more task\nmeasures serving as within-subjects variables.\nWe used the SPL to create a content-control condition in\nwhich participants would be able to read the complete set of\naspirin drug facts in the absence of any organizational\nstructure. We hypothesized that a reading of either the Drug\nFacts Label or the Cohesive-Prose Label would allow par-\nticipants to perform significantly better on all of our design-\nobjective measures than would a reading of the\nScrambled-Prose Label. The question of primary interest,\nhowever, is whether the layout and format of the DFL are a\nmore effective way to organize drug facts information than\nis a cohesive-prose presentation of that information. If that\nlayout and format are uniquely suited to the task of label\ncomprehension then a reading of the Drug Facts Label\nshould allow participants to perform significantly better on\nall of our design-objective measures than would a reading\nof the Cohesive-Prose Label. We test that hypothesis by\nexamining measures of (a) the rated appeal of a drug label,\n(b) the ease of finding information on a drug label, (c) the\ncomprehension and recall of drug facts, and (d) the organi-\nzation of drug facts information in memory.\nMethods\nParticipants\nIn total, 55 female and 39 male undergraduates between\nthe ages of 18 and 25 participated in hour-long group ses-\nsions in order to satisfy a research requirement; all were\nRyan and Costello-White 5\nnative English speakers. Confirming our expectation that\naspirin is not commonly used by undergraduates (see\nEllen et al., 1998), only eight students reported having\nused aspirin in the 30\ndays prior to their participation in\nthe study. In contrast, 66 reported having used ibuprofen;\n51, acetaminophen; 22, naproxen. Participants reported\ntaking some care in reading label information for their\npreferred analgesics (7\n=\nSEM=0.39), but they were confident that they could use\naspirin safely and effectively (7\n=\nextremely confident:\n=\n0.18). The mean ERVT verbal ability\nscores ranging from 2 to 18. These scores did not vary\nsignificantly as a function of the label condition to which\nLabel facsimiles\nDrug Facts Label.Our DFL was a two-page, letter-sized\nsimulation of an aspirin label, with a cover page replicating\nthe Principle Display Panel for a brand name aspirin. We\nused the exact wording from the then-current aspirin label.\nThe order of information and headings mirrored that DFL\norder (i.e. Active Ingredient, Uses, Warnings, etc.). Bar-\nlines, hairlines, indenting, bulleting, and white-space\nmatched those of the actual label. We increased font size to\nmake the DFL more legible, using 16-point, 14-point, and\n12-point Arial font for headings, subheadings, and text.\nThe use of boldface and italics also matched the DFL.\nCohesive-Prose and Scrambled-Prose Labels. Our CPL was a\nthree-page, letter-sized prose version of the DFL made by\nexpanding each telegraphic DFL phrase into a complete\nsentence. The sentence for any bulleted item included an\nexplicit cohesive link to its heading (e.g. the sentence \"You\ncan use aspirin to reduce menstrual pain\" was included in\nits appropriate position in the Uses paragraph; each bul-\nleted use followed as a separate sentence). Additional cohe-\nsive links were added as necessary to ensure that each\nsentence repeated a word from the previous sentence or\nfrom the governing heading. These explicit lexical links aid\nthe reader by eliminating the need to link adjacent sen-\ntences by recalling or re-reading earlier sentences or by\nmaking language- or knowledge-based inferences (cf. Brit-\nmandated headings and subheadings appeared as indented\nparagraph headings in bold, italicized font. All headings\nand text were in 12-point Arial font. We created our SPL by\neliminating all paragraph headings from our CPL and then\npreparing two random orderings of those CPL sentences to\ncounterbalance any order effects. We created an artificial\nparagraph structure with sequences of indented sentence\nstrings that paralleled the length and ordering of paragraphs\nin the CPL.\nAssessing text cohesion. The DFL, CPL, and SPL had com-\nparable Flesch\u00adKincaid reading grade levels of 7.4, 7.5,\nand 7.8, respectively.As would be expected, the word count\ntively, than the count for the DFL at 613. We computed\ncohesion values for the CPL and the SPL using the follow-\ning logic. The CPL is comprised of 94 sentences (counting\nparagraph headings as sentences). The total number of CPL\nsentence pairs is then 93 minus the 17 pairs composed of\nthe last sentence on one paragraph and the first sentence of\nthe next--for a final count of 76 CPL pairs that could be\nlexically linked. We then divided 67--the number of adja-\ncent CPL sentence pairs that were directly linked with a\nshared word or phrase--by 76 to obtain a lexical cohesion\nvalue of 88percent. Similarly, the total number of SPL sen-\ntence pairs that could be lexically linked is then 78 minus\nthe 14 paragraph-transition pairs--for a final count of 64.\nWe found only 12 sentence pairs in the SPL that were\ndirectly linked with a shared word, so the value of our lexi-\ncal cohesion index was 19percent.\nCalculating a cohesion index for the DFL is problematic\nbecause it is not true prose. We made two assumptions in\norder to make an estimate. Because each drug fact in the\nDFL had given rise to a separate sentence in the CPL and\neach DFL heading had given rise to a separate paragraph,\nwe again estimated the possible number of lexical links as\n76. We obtained an indirect and very liberal estimate of the\nnumber of direct lexical links in the DFL by counting the\nnumber of bulleted items and subtracting that value from\n76. By this logic, each bullet reflects the absence of a cohe-\nsive link and calls for a concept in the bulleted heading to\nbe reinstated by a reader (cf. Kieras, 1978). Given a bullet\ncount of 40, we estimated the number of direct cohesive\nlinks in the DFL as 36. Dividing that estimate by the total\nnumber of idea pairs, we obtained a lexical cohesion index\npercent for the DFL. By our estimate, therefore, the\ncohesiveness value of the DFL is about half that of the\nLabel attentiveness.We needed a measure of label attentive-\nness to control statistically for individual differences in read-\ning style and motivation in our analyses. Following Ryan\n(2011), we inoculated our DFL, CPL, and SPL texts with\nobvious spelling errors (e.g. pan rather than pain or doctar\nrather than doctor). Although the spelling errors are shown\nonly for our Drug Facts Label facsimile in Appendix 1, the\nsame spelling errors were included in the Cohesive-Prose\nLabel and the Scrambled-Prose Label actually used by par-\nticipants in those two label conditions. The spelling errors in\nall three facsimile labels were distributed at roughly equal\nintervals throughout the label texts. No error occurred in any\nword that was central to the meaning of an aspirin drug fact.\nThe DFL, the CPL, and the SPL texts contained the same 26\nerrors. We told participants that there were at least 20 spelling\nerrors to be found and circled as they read their label. In\n6 Health Psychology Open \naddition, we emphasized that it was important that they pay\ncareful attention to all of the information in the label so that\nthey could perform as well as possible on the recall and com-\nprehension tests that would follow their reading of the label.\nWe verified that our attentiveness task was a nonreactive one\nby examining the correlation between attentiveness scores\nand the subsequent recall of drug facts from the label. Any\nshallow processing induced by the error-detection task should\nimpair recall, resulting in a negative correlation between the\ntwo measures; in contrast, any deep processing induced by\nthe error-detection task would facilitate recall, resulting in a\npositive correlation (cf. Craik and Lockhart, 1972). In fact,\nthe overall correlation between error detection and subse-\ndemonstrating that the task neither impaired nor facilitated\ndrug facts recall.\nOutcome measures\nObjective 1: Enhancing the appeal of nonprescription drug\nlabels.After completing the label-scanning task, partici-\npants rated five subjective characteristics of our labels--the\nlabels were not available for inspection as they made these\nratings. Four sets of items were rated with a 7-point scale\n(1=very much disagree; 7=very much agree). Three items\ncontributed to a Perceived Readability subscale (\"The Drug\nFacts were very clearly written and extremely easy to\nunderstand.\"), Cronbach's \n=\n.73. Four items contributed\nto a Perceived Cognitive Load subscale (\"It was hard to put\nall of the information together\"), \n=\n.76. Four items con-\ntributed to a Perceived Organization subscale (\"The label\ninformation was very well organized\"), =.81. Three items\ncontributed to a Perceived Authoritativeness subscale\n(\"The label information is authoritative with directions that\nshould be carefully followed\"), =.83. Finally, four items\ncontributed to a Perceived Recallability subscale. Here, we\nasked for perceived efficacy ratings (1\n=\nnot at all confi-\ndent; 7=extremely confident) for the recall of drug facts (\"I\ncan list from memory all of the reasons one should not use\nthis drug without first consulting a doctor\"), =.80.\nObjective 2:Increasing the ease of finding information on a nonpre-\nscription drug label.We constructed 23 sentence-completion\nitems (e.g. \"Vomiting blood is a sign of _________ bleeding\")\nto probe for information from throughout the text of each\nlabel. None of these items involved drug facts from which we\nhad drawn the aspirin claims described below. Two different\norderings of these items were prepared with the constraint that\neach missing target word was on a different page than the pre-\nvious target word. In order to prevent participants from simply\nrecalling the information when they could, participants had to\nlocate and circle each target word on a clean copy of their aspi-\nrin label. They also recorded that word or phrase on the\nresponse form. We defined \"scanning efficiency\" as the num-\nber of target words correctly circled in 5minutes.\nObjective 3a: Improving the comprehension of drug facts.We\nused 30 aspirin drug facts from throughout the DFL to con-\nstruct aspirin claims that were plausibly true or false. Fifteen\nof these claims were paraphrases of facts directly stated on\nthe label (e.g. \"You should drink a full glass of water each\ntime you take aspirin\"). We refer to this set of aspirin claims\nas Label-Congruent (LC) claims because each such claim is\nexplicitly confirmed in each version of the aspirin drug facts\n(e.g. \"drink a full glass of water with each dose\"). The\nremaining 15 aspirin claims were incorrect paraphrases of\ndrug facts directly stated on the label (e.g. \"Aspirin should be\nkept in the refrigerator in order to maintain its potency\"). We\nrefer to this second set of aspirin claims as Label-Discrepant\n(LD) claims because each such claim is directly contradicted\nin each version of the aspirin drug facts (e.g. \"store at room\ntemperature\"). We created two different orderings of the 30\nclaims, with each block of six claims including three LC and\nthree LD claims. In order to encourage participants to rely on\ntheir intuitions in rating the perceived validity of each claim,\nwe ask them to use a 6-point Likert scale with anchor-point\nlabels that emphasized intuitive validity (1\n=\ndefinitely feels\nfalse; 6=definitely feels true).\nObjective 3b: Improving the recall of drug facts.As their last\ntask in the study, participants had 5minutes to write down as\nmany facts as they could recall from the aspirin information\nthey had read. We encouraged them to write down any label-\nrelated information as it occurred to them--without trying to\nrecall the drug facts in order and without worrying about\nwhether they were completely correct or not. We asked them\nto write down enough information about each recalled drug\nfact to allow us to score the recalled item as true or false.\nWhen we coded recall, we used gist scoring to give full credit\nto any fact correctly recalled from the text. We gave partial\ncredit to any fact that referenced specific information from\nthe label even if it was incorrect, distorted, or vague. This\nscoring scheme allowed us to use a strict or lenient standard\nfor recall in our analyses. Using a strict standard, we counted\nonly drug fact reports that had received full credit; using a\nlenient standard, we added to our full-credit count any facts\nthat had received partial credit. In order to determine whether\nour recall measure was biased by the post-label ratings of\naspirin claims or by the label-scanning task, we also coded\nrecall reports for any of a new set of 30 aspirin drug facts that\nwere not included among the aspirin claims or among the\ntargets of the scanning probes.\nObjective 4: Providing a model for the organization of drug facts\ninformation. One virtue of a free-recall measure of memory\nis that the order in which information is recalled can reveal\nhow that information is organized in memory (Friendly,\n1977). If the DFL imposes a \"decision-making\" category\nstructure upon consumers' organization of drug facts infor-\nmation, then drug facts presented under the same DFL head-\ning would likely be adjacent to each other in our participants'\nRyan and Costello-White 7\nfree-recall protocols. We tested this hypothesis by classify-\ning every label-specific item reported in each recall protocol\nusing a seven-category schema defined by the headings in\nthe DFL. We included only the major categories of aspirin\ndrug facts in the DFL schema: (a) Uses, (b) Reye's Syn-\ndrome, (c) Allergy Alert, (d) Stomach Bleeding, (e) Ask\nDoctor Before Use, (f) Stop Use If, and (g) Directions. We\ncoded all information recalled by our participants, including\nany incorrect, distorted, or vague information traceable to\nspecific label phrases. We also classified all label-specific\nitems reported on our recall form using a variation of the\nthree-category \"na\u00efve medication schema\" Morrow et al.\n(1996) identified for short prescription drug labels. We\nmodified those schema categories to make them more suit-\nable for classifying the kinds of drug facts found on nonpre-\nscription drug labels: (a) Purpose, (b) Warnings, and (c)\nDirections. This dual-coding system allowed us to examine\nwhether the organization of aspirin drug facts in memory is\ngoverned by the authorized medication schema embodied in\nthe DFL or by a pre-existing na\u00efve medication schema. We\nused the adjusted ratio of clustering (ARC: Roenker et al.,\n1971) to measure the degree to which the formal DFL\nschema was more successful than Morrow's na\u00efve medica-\ntion schema in accounting for the order in which drug facts\nwere recalled.\nProcedure\nAfter providing informed consent, participants received a\nfolder from which they removed and replaced forms as\ndirected by the experimenter. Because reading the DFL\nrequired about 4\nminutes and reading the CPL and SPL\nminutes, separate group sessions were conducted\nfor each label condition. Although the additional reading\ntime accorded the two prose labels might have advantaged\nparticipants in those conditions, we show in our analyses\nthat reading time per se is not critical: the CPL and SPL\ngroups differ in important ways even though participants\nspent the same amount of time reading each label.\nWe asked our participants to rate the 30 aspirin claims\nbefore they actually read their facsimile label. We told them\nto read each claim as carefully as necessary to be certain of\nits meaning and then to take no more than 2 or 3seconds to\ncircle a number indicating how true it seemed. We explained\nthat we wanted them to base their ratings on their \"gut feel-\nings\" rather than relying on anything they might have heard\nor read about aspirin. We also informed them that their rat-\nings would be more reliable if they made \"snap judgments\"\nafter they had taken the time to understand each claim. Our\nassumption in providing these instructions was that any\npreconceptions they had would be rooted in their enduring\nintuitions rather than in their conscious and deliberate anal-\nysis of the claims. We paced them through the claims at a\nseconds per claim to allow a careful reading of\neach claim prior to rating its intuitive validity.\nWe then asked our participants to read their aspirin label as\ncarefully as possible, circling any inserted spelling errors as\nthey found them. After participants had read their labels, they\nminutes to complete the 24-item ERVT. Immediately\nafterward, we asked them to complete the aspirin claims form\nas a posttest. We again emphasized the importance of rating\ntheir \"gut feeling\" about the truth of a claim after reading it\ncarefully. We also cautioned participants not to try to recall\ntheir pretest ratings or specific label information as they made\ntheir judgments. We told them that making spontaneous, non-\nreflective judgments would improve the likelihood that their\ntruth ratings would accurately reflect their enduring intuitions\nin future days or weeks. As on the pretest, we gave them\n10seconds to read and rate each claim.\nNext, we guided participants through the 5-minute scan-\nning task. Afterward, they evaluated the label they had read\nby completing the 18-item label-evaluation form. The label\nwas not available to them as they made these ratings.\nFinally, 3\nminutes after completing the scanning task, our\nparticipants had 5minutes to recall as many aspirin facts as\nthey could, recording each fact on a different line on the\nresponse form. We strongly encouraged them to write down\nany idea as it occurred, even if they were not certain that it\nhad appeared on the label. After completing this task, each\nparticipant received a debriefing form and had the opportu-\nnity to ask questions about the study.\nResults\nPreliminary analyses showed that error-detection scores\nwere not a significant covariate in any analysis. Therefore,\nwe treat our attentiveness scores as an additional outcome\nmeasure. We omitted from all analyses data from 12 partici-\npants who did not carry out the label-scanning task as\ninstructed.\nAspirin-specific preconceptions. Verbal ability was not a sig-\nnificant covariate in the analyses of truth ratings for LC\nlabel information, participants rated LC claims as signifi-\n=\n=\nclaims is well above 3.50 (the mathematical midpoint of\nthat our participants were generally certain that our LC\nclaims were valid. The mean rating of 3.60 for the 15 LD\nclaims is just above that scale midpoint, t(81)=2.02,\np\n<\n.05, suggesting that our participants were generally\nuncertain about whether our LD claims were valid or\ninvalid.\nLabel attentiveness. Verbal ability did not influence how\nmany of the 26 inserted spelling errors our participants\n8 Health Psychology Open \n=\n.09. The number of inserted errors circled by\nferroni comparisons showed that the label version effect\nwas due to a lower error-detection rate in the DFL condition\nas compared to the CPL condition, p<.05. This result may\nreflect the difficulty of detecting spelling errors in the DFL's\ntelegraphic text.\nObjective 1: Enhancing the appeal of\nnonprescription drug labels\nWe used a multivariate analysis of variance to analyze the\nmean ratings on the five label-evaluation scales. Verbal abil-\nity did not affect any of the five scale ratings, Wilk's =0.95,\n<\n1.00. The overall effect of label version on sub-\nscale scores was significant, Wilk's \n=\n=\n.31. Follow-up univariate tests\nshowed that label version significantly affected ratings of\n=\n.12, and Perceived Authoritative-\nlabel version did not affect ratings of Perceived Readability,\nAs can be seen in Figure 1, the DFL was rated signifi-\ncantly more organized than the SPL, DM\np\n<\nBoth the DFL and the CPL also had significantly lower cog-\nnitive-load ratings than the SPL, DM\naddition, the DFL and the CPL were both judged as signifi-\ncantly more authoritative than the SPL, DM\nSEDiff\nrespectively. Bonferroni-adjusted comparisons at .05 level\nshowed that the DFL and the CPL did not differ in Perceived\nOrganization, Cognitive Load, or Authoritativeness ratings.\nObjective 2: Increasing the ease of finding\ninformation on a nonprescription drug label\nScanning ease was measured as the number of target drug-\nfacts phrases found and circled on a facsimile label within a\nfixed amount of time. These scores were adjusted for verbal\nability effects because that covariate had a significant effect\nOf the 23 label targets, those reading the DFL found and\n=\ninterval; those reading the CPL found and circled 9.97\n(SEM=0.68). Scanning success was significantly greater for\nthose reading the DFL than for those reading the SPL,\nDM\nwere also significantly more successful than those reading\nthe SPL, DM\nBonferroni comparison showed that those reading the DFL\ndid not locate significantly more targets than those reading\nObjective 3a: Improve the comprehension of\ndrug facts information\nBecause pretest ratings of LC and LD claims did not differ\nsignificantly across label conditions, we subtracted the ini-\ntial rating of each claim from its final rating to obtain an\nindex of the degree to which reading the label appropriately\nupdated claim ratings. A positive value of this knowledge-\nupdating index for LC claims reflects confirmatory updat-\ning; a negative value of the index for LD claims reflects\ncorrective updating.\nParticipant-by-participant knowledge updating. We entered\nclaim type (LC and LD) as a repeated-measures variable\nand label version (DFL, CPL, or SPL) as a between-\nsubjects variable. We did not adjust this index for verbal\nability because it was not a significant covariate in this\neach label condition are shown in Figure 2. Label ver-\nsion had no main effect on updating scores, F(2,\n=\n0.13, nor did it interact with claim\nedge-updating index was significantly greater for LC\n=\nhave changed as a result of reading the aspirin drug\nFigure 1. Ratings of label perceptions for Drug Facts Label (DFL),\nCohesive-Prose Label (CPL), and Scrambled-Prose Label (SPL).\nRyan and Costello-White 9\nfacts, we also tested whether the two indices were sig-\nnificantly different from the no-change value of 0.\nWhile the knowledge-updating index for ratings of LC\np\n<\n.001, the updating index for ratings of LD claims\nClaim-by-claim knowledge updating. We also conducted a claim-\nby-claim analysis. The mean updating indices for each of the\n15 LC claims and the 15 LD claims were treated as two levels\nof a between-claims factor, with label version treated as three\nlevels of a within-claims factor. There was no main effect of\n<\n.10, and no label ver-\np\n>\n.20. The effect of claim type on the knowledge-updating\n=\n.36. As was the case in the individual-subject\nanalysis, a significant increase in the updating index was found\n=\nHere too, the updating index for ratings of LC claims was sig-\nfor ratings of LD claims was not, t(80)<1.00. As can be seen\nin Figure 2, the knowledge-updating effect sizes are nearly\nidentical for both the individual-subject and the individual-\nclaim analyses. In both analyses, ratings for LD claims were\nunchanged by any of the three labels.\nObjective 3b: Improving the recall of drug facts\nIn our scoring of participants' free-recall responses, we\ngave full credit to any response that correctly paraphrased\nlabel information (e.g. \"you should see a doctor if you have\ntrouble hearing\"). We gave partial credit to any response\nthat included specific information from the label--even if it\nwas incorrect (e.g. \"don't take more than 3 drinks a day\"),\ndistorted (e.g. \"you should not take aspirin if you have\nReye's syndrome\"), or vague (e.g. \"stomach ulcers or\nbleeding problems\"). This scoring scheme allowed us to\nuse a strict or lenient standard for recall in our analyses.\nUsing a strict standard, we counted only drug facts reports\nthat had received full credit. Using a lenient standard, we\nadded to our full-credit count any fact that had received\npartial credit. The DFL, CPL, and SPL did not differ sig-\nnificantly in their ERVT-adjusted recall scores using either\n78)<1.00. We report lenient recall scores as Total Recall in\nFigure 3 because we wanted a sensitive measure of the\nimpact of the label on memory. Our reasoning was that any\nitem of information that bore the imprint of specific word-\ning in the label text demonstrated the impact of the label on\nmemory--even if it was not strictly correct. This lenient\nstandard also ensured that we had a large enough pool of\nresponses to use in our category-clustering analyses.\nA further analysis showed that label version did not dif-\nferentially affect the amount of Purpose, Directions, or\nWarnings drug-facts recall. These three categories reflect\nthose in the na\u00efve medication schema identified by Morrow\net al. (1996). Here too, verbal ability was a significant\nNeither label version, F(2, 78)\n<\n=\nThe significant main effect of drug-fact category, F(2,\nences among the categories in the frequency with which\nthey appear among the drug facts on the aspirin label. The\nrelative differences in the ERVT-adjusted means in each\ncategory approximate the relative frequencies of each kind\nof fact in the label itself. Figure 3 displays the ERVT-\nadjusted recall scores for each category of label content.\nWe also conducted an analysis of the free-recall data in\nwhich we counted only correctly recalled aspirin facts that\nFigure 2. Knowledge updating values for Label-Congruent (LC)\nand Label-Discrepant (LD) beliefs by participants (P) and by\nindividual claims (C).\nFigure 3. Total number of aspirin drug facts recalled from\neach label and breakdown by number of purpose, warnings, and\ndirections drug facts.\n10 Health Psychology Open \nhad not been among those we included in our set of aspirin\nclaims nor in our set of label-scanning targets. This scoring\nprocedure allowed us to assess whether either task had biased\nour measure of recall performance. However, we still found\nthat the labels did not differ in their recall effectiveness, F(2,\n<\n1.00. Recall of this restricted set of 30 drug facts was\n=\nObjective 4: Providing a model for the\norganization of drug facts information\nUsing the order in which each participant had recorded\naspirin drug facts on the response sheet, we counted the\nnumber of pairs of adjacent items that belonged to the\nsame schema category. We did separate counts for the DFL\nseven-category schema and Morrow's three-category\nschema. Roenker et al.'s (1971) ARC index computes the\nratio of same-heading pairs observed to the total number of\npossible pairs; it also corrects for the number of same-\nheading pairs that would occur by chance. In addition, it\nincludes a k value that corrects for individual differences\nin the number of categories from which two of more items\nare reported. For coding using Morrow et al.'s na\u00efve medi-\ncation schema, our participants' k values were 2 or 3; for\ncoding using the authorized DFL schema, their k values\nwere 2, 3, or 4. Computed ARC values can range from\n(Roenker et al., 1971). We followed the common practice\nof replacing all negative ARC values with a zero to indi-\ncate that a given recall protocol involved only a chance\nlevel of category clustering. An ARC score of .30 repre-\nsents a moderate degree of clustering, but the best use of\nthe index is to determine which of two or more classifica-\ntion schemes is associated with the highest ARC score. For\nticipants, respectively, recalled enough aspirin information\nto permit the computation of an ARC score for both sche-\nmas and the use of a repeated-measures analysis.\nWe analyzed the two ARC scores for each participant as\na within-subjects medication-schema factor and label ver-\nsion as a between-subjects factor, including verbal ability\nas a covariate. Verbal ability significantly influenced ARC\nlabel version did not, F(2, 64)\n<\n=\n.11, but the medication\nOverall, the degree of category clustering was almost twice\nas high for Morrow et al.'s na\u00efve medication schema\nsons showed the ARC values for Morrow et al.'s na\u00efve\nschema to be significantly greater than those for the\nauthorized schema for each version of the aspirin drug\nfacts, ps<.05 (see Figure 4 for mean ARC values for each\nlabel version and each category scheme). However, it is\nalso the case the ARC values for the authorized medication\nschema are significantly greater than zero for the DFL, the\nThe pattern of results suggests that both medication sche-\nmas play a significant role in organizing aspirin informa-\ntion in memory, but the na\u00efve medication schema is the\nmore influential.\nDiscussion\nSummary of findings\nThe Drug Facts Label performs and fails to perform\nmuch as its Cohesive-Prose counterpart on every meas-\nure we used. Participants rated aspirin drug facts as sig-\nnificantly more organized, less cognitively demanding,\nand more authoritative when presented in a Drug Facts\nLabel or in a Cohesive-Prose Label than in a Scrambled-\nProse Label. Perceptions of readability and recallability\ndid not differ across the three label conditions. Label-\nscanning performance was significantly and comparably\nbetter for both the DFL and the CPL as compared to the\nSPL. Unexpectedly, the free recall of drug facts was no\ngreater for the DFL than for our CPL or our SPL. Morrow\net al.'s (1996) categories of Purpose, Warnings, and\nDirections accounted for the organization of drug facts\nin recall to a significantly greater extent than did the\nseven major headings of the DFL in all three label condi-\ntions, but this effect did not vary as a function of label\ncondition. Most importantly, all three labels were equally\neffective in promoting the confirmatory updating of LC\nclaims. In contrast, all three labels were equally ineffec-\ntive in promoting the corrective updating of LD claims.\nFigure 4. Degree to which drug facts are clustered in recall\nby drug-facts-label categories and and by Morrow's na\u00efve-\nmedication-schema categories.\nRyan and Costello-White 11\nInterpretation\nWe interpret our findings by evaluating the degree to which\nthe DFL meets its design objectives (FDA, 1999).\nObjective 1: Enhancing the appeal of nonprescription drug\nlabels. Participants reading the DFL for aspirin did perceive\nthe reading process to be less demanding cognitively than\nreading the SPL. They also perceived the text to be more\norganized and the information to be more authoritative than\ndid those reading the SPL. However, the CPL was equally\nsuperior to the SPL on those three dimensions. In contrast,\nparticipants did not judge the aspirin information on the DFL\nor the CPL to be significantly more understandable or more\nmemorable than that on the SPL. We believe that this latter\nfinding reflects the challenge participants face in monitoring\ncomprehension or predicting recall. Perceptions of compre-\nhension were not correlated with either confirmatory updat-\ning, Pearson's r(80)\n=\n\u00ad.15, or corrective updating,\nr(80)=+.00, respectively, nor were perceptions of recallabil-\nity correlated with lenient gist recall, r(80)=+.18. In sum-\nmary,theDFLmeetstheobjectiveofmotivatinglabel-reading\nefforts by reducing Perceived Cognitive Load, increasing\nPerceived Organization, and increasing Perceived Authorita-\ntiveness. However, it is no more effective in doing so than\nthe CPL (see Figure 1).\nObjective 2:Increasing the ease of finding information on a non-\nprescription drug label.Those scanning the DFL for target\nwords or phrases found significantly more in a 5-minute\nperiod than did those scanning the SPL. However, those\nscanning the CPL found as many targets as those scanning\nthe DFL. Kools et al. (2008) varied the number of headings\nincluded in three different versions of a five-page health\neducation text and asked their undergraduate participants to\nsearch for 10 information targets in the text. They found\nthat all versions of the text that included headings were\nsearched more quickly than a control text version that had\nno headings. Our CPL used as paragraph headings the same\nheadings as the DFL, and our SPL had no headings.\nAlthough the DFL does achieve the objective of helping\nreaders quickly locate information, the scanning advantage\nof the DFL over the SPL may arise simply from the use of\nheadings rather than from any other feature of the label.\nObjective 3: Improving the comprehension and recall of drug\nfacts information.Our comprehension measure focuses on\nthe degree to which reading a set of drug facts modifies\none's preconceptions about aspirin--increasing truth val-\nues for facts confirmed by a label and decreasing values for\nfacts refuted by a label. Neither the DFL nor the CPL pro-\nduced significantly greater confirmational change or refu-\ntational change than did the SPL (see Figure 2). We used\nrecall as a surrogate measure of a reader's ability to apply\nlabel information because drug facts that are not recalled\ncannot influence the safe and effective use of a nonpre-\nscription drug. Neither the DFL nor the CPL produced sig-\nnificantly more recall on any of our four indices than did\nthe SPL (see Figure 3). These findings indicate that the\nDFL may not fully achieve its comprehension and applica-\ntion objectives.\nObjective 4: Providing a model for the organization of drug facts\ninformation.Our analysis of category clustering indicates\nthat neither the DFL nor the CPL has any greater effect on\nthe mental organization of drug facts than does the SPL.\nAlthough DFL categories significantly influenced recall\nclustering for all three labels, a simpler na\u00efve schema using\nonly the categories of Purpose, Warnings, and Directions\n(Morrow et al., 1996) was significantly more effective in\naccounting for the order in which drug facts were recalled\n(see Figure 4). These findings strongly suggest that the\nDFL does not achieve its objective of influencing the way\nin which consumers organize drug facts information.\nLimitations\nOur data indicate that the DFL was no more effective than\nits cohesive-prose equivalent in achieving any of its design\nobjectives. Our findings are limited in the following ways.\nCohesiveness manipulation. Although we were able to estab-\nlish a high degree of lexical cohesiveness in our cohesive-\nprose version of the drug facts, free recall was no greater\nthan in the scrambled-prose version. We believe the failure\nof our cohesiveness manipulation is due to the specialized\nnature of the drug-label discourse itself. Text comprehen-\nsion research has shown that causal connections are partic-\nularly effective in improving the comprehension and recall\nof narrative texts (cf. Trabasso and Van den Broek, 1985).\nBecause our CPL, like the SPL and the DFL, is simply a\ncategorized listing of aspirin drug facts, the cohesive links\nwe created established lexical links between adjacent sen-\ntence pairs rather than the causal links that Britton and G\u00fcl-\ng\u00f6z created for their narrative text. The recall of drug facts\ninformation in both the DFL and our CPL might be\nimproved by inserting causal links that explicitly organize\nthe drug facts as steps in a decision-making process.\nChoice of nonprescription drug.Our findings are limited to\nthe DFL for aspirin. Because aspirin is not commonly used\nby undergraduates (Ellen et al., 1998), they are unlikely to\nhave read the label and will be biased largely by their pre-\nconceptions about the drug rather than by their actual expe-\nrience in using the drug. Because the aspirin drug facts are\nFDA-approved and appear on all product labels for aspirin,\nour facsimile label is authoritative in a way that a fictional\ndrug label (cf. Morrow et al., 1996) would not be. The fact\nthat our young adult college students are not likely to be\nfamiliar with aspirin as an analgesic nor with the DFL for\n12 Health Psychology Open \naspirin does not threaten the internal validity of our study,\nbut it does mean that the effects we report here may be qual-\nitatively different for other more commonly used nonpre-\nscription analgesics or for other classes of nonprescription\ndrugs (e.g. antacids, antihistamines, and anti-diarrheals).\nNature of the label-processing task. Our label-reading task is\nnot designed to simulate the label inspection process that\noccurs when a consumer is comparing one product with\nanother in the same class at the point-of-purchase or when a\nconsumer subsequently self-medicates with that drug. In\nboth situations, the reading process is likely to be less sys-\ntematic and thoughtful than the task we posed our partici-\npants. Prior to reading their assigned label, our participants\nwere asked to rate the perceived truth of 30 different claims\nabout the information to be found on an aspirin drug label.\nThey were then told that they would have a chance to read\nthe actual drug facts for aspirin before rating these claims a\nsecond time and recalling what they could from the label.\nThe label-reading instructions they were given encouraged\nparticipants to read all of the label information very care-\nfully.As a check on the care they took in inspecting the label\ninformation, we asked them to circle any of the typographi-\ncal errors we had inserted into the drug facts text. In sum-\nmary, we have every reason to believe that our participants\nread the aspirin drug facts much more closely than the aver-\nage consumer would in making his or her drug purchase or\nin referring to the label for guidance in using the drug for\nsymptomatic relief. Our intention was to ensure that partici-\npants performed as well as possible on our dependent meas-\nures. For that reason, we believe that under everyday reading\nconditions, consumers would not perform nearly as well as\nour participants on the tasks we posed them. Future studies\nare needed to determine the generality of our findings across\na range of more ecologically valid conditions.\nParticpant sample.We must also limit our conclusions\nabout label comprehension to young adult college students.\nDifferent consumer populations might vary in their precon-\nceptions about aspirin, their familiarity with the DFL, and\ntheir general knowledge of nonprescription drugs. In addi-\ntion, our procedure focuses on a knowledge-updating\nmeasure of comprehension. This measure is a critical one\nfor assessing label effectiveness, but there are many other\nways to define and measure comprehension (White, 2011).\nClearly, conceptual replications of our findings using other\ndependent measures should be conducted.\nCarry-over effects. Given the number of tasks in our procedure,\nit is possible that carry-over effects bias some of our measures.\nThe drug-facts recall task, for example, was preceded not only\nby the label-reading task but also by the intervening vocabulary\ntest, the post-label aspirin belief ratings, the label-scanning\ntask, and label-evaluation ratings. The vocabulary test does not\nshare any content with the DFL, and the label-evaluation\nratings were based on participants' recollection of the label,\nrather than on a re-inspection of the label. However, the aspirin\nbelief statements may have reminded participants of specific\ndrug facts on the label, and the label-scanning task necessarily\ninvolved a selective inspection of the label. We corrected for\npotential contamination effects by scoring recall protocols only\nfor drug facts that were not included in the aspirin beliefs scale\nand not included among the label-scanning targets. Scores on\nthis ancillary measure showed the same effect as the other\nmeasures of recall. In addition, any contamination effects on\ndrug facts recall would have affected each label condition in the\nsame way. It is also possible that pre-label belief ratings influ-\nenced the reading of the DFLs and the post-label belief ratings.\nOnce again, any contamination effects would have been con-\nstant across the three label conditions.\nImplications\nAlthough further refinements of our procedure may be neces-\nsary, two important insights about label comprehension\nemerge in this study. First, the impact of consumers'domain-\nspecific drug preconceptions and their domain-general medi-\ncation schemas on the label comprehension process deserves\nmuch more examination. Second, nonprescription drug labels\nmay require major modifications in order to ensure that they\ncorrect consumers' drug preconceptions and to facilitate the\ndevelopment of valid medication schemas.\nPrior-knowledge effects. In this study, we define label compre-\nhension as the degree to which consumers can use a nonpre-\nscription drug label to modify their knowledge of a drug so\nthat they can use that drug safely and effectively. This defini-\ntion assumes that consumers have their own preconcep-\ntions--however vague and ill informed--about how they\ncan make best use of a given drug to treat the symptoms that\nconcern them. Our definition also assumes that label com-\nprehension is a mental representation that arises from the\ninteraction of readers' preconceptions about a drug with the\ntext of the drug label (cf. Jungermann et al., 1988; Morris\nand Aikin, 2001). We use changes in truth ratings for a set of\naspirin drug-facts claims to measure the degree to which a\nlabel is effective in modifying drug-specific preconceptions\nabout aspirin. Existing measures of health literacy (Davis\nBecause such measures seek to assess a consumer's general\nhealth and medical literacy, they provide no specific infor-\nmation about consumers' knowledge of a given drug. Meas-\nures of verbal ability or text readability are useful for\ndetermining how challenging a given consumer will find a\ngiven drug label, but they too provide no information about\nconsumers' knowledge of a given drug. Measures of the\nrecall of label information provide an index of what drug\nfacts were read and encoded, but in and of themselves, they\noffer no information about how consumers understand the\ndrug facts they recall.\nRyan and Costello-White 13\nFurthermore, our category-clustering analyses indicate that\nparticipants appeared to be using Morrow et al.'s (1996) na\u00efve\nmedication schema--Purpose, Warnings, and Directions--\nrather than the schema dictated by the major headings of the\nDFL--Uses, Reye's Syndrome, Allergy Alert, Stomach\nBleeding,Ask Doctor Before Use, Stop Use If, and Directions.\nfor nonprescription analgesics, for example, may serve as a\ntemplate to guide a consumer's reading of the DFL for a new\nanalgesic. However, the categories of \"Ask Doctor Before Use\n...\" and \"Stop Use If ...\" call for very different consumer\nactions, and those who classify them only under the broad cat-\negory of \"Warnings\" may fail to make distinctions that are\ncritical for the safe use of aspirin. Further research on the role\nplayed by na\u00efve medication schemas in the processing and\napplication of drug facts information is clearly necessary.\nLabel redesign.Our findings also have implications for the\ndesign and development of drug warning labels. Although the\nFDA promulgates Primary Communication Objectives for\neach nonprescription drug, it is notable in the present context\nthat the FDA sets forth no Primary Refutation Objectives.\nMorgan et al. (2002) have identified detailed procedures for\neliciting misconceptions that individuals may have about the\nsafe and effective use of a nonprescription drug. Conceptually\nbased misconceptions are not easily changed, but refutation\ntexts have been shown to be effective in producing those\nVan Den Broek and Kendeou, 2008). In general, refutation\ntexts identify a misconception, label it as incorrect, and explain\nwhy it is incorrect. Modifying the DFL to make it serve as a\nrefutation text for significant misconceptions about nonpre-\nscription drugs would require a dramatic change in the product\nlabels for those drugs. However, a label that fails to correct\nsignificant misconceptions about the safe and effective use of\na drug most certainly should be viewed as a defective label.\nThe need for refutational nonprescription drug labels calls for\na fundamental reconsideration of the primary communication\nobjectives of a drug label: those objectives should include\nideas to be dispelled as well as ideas to be instilled.\nIn addition to developing drug labels that are more effec-\ntive in refuting misconceptions, it is also important to mod-\nify the text structure of those labels so that they more\nexplicitly reflect the \"decision-making process\" originally\nuates could pick out and label a set of four short sequence-\nof-events passages from among sets of four other kinds of\ntext passages. Their study indicates that young adults will\nnot likely be able to discern the decision-making sequence\nimplicit in a Drug Facts Label. However, if the headings of\nthe DFL are explicitly identified as steps in a process, and\nthe causal links among those steps are clearly stated (see\nKendou, Smith and O'Brien, 2013), consumers may be bet-\nter able to build a mental model of how to use\nnonprescription drugs safely and effectively (cf. Bostrom et\n"
}