{
    "abstract": "Abstract\nHere I propose procedural replication as a method for diagnosing errors and omissions and identifying research artifacts\nin published studies. The goal of procedural replication is not to make substantive contributions so much as improve\nresearch practice, or how scientists go about doing science. This is accomplished by generating checklists of lessons\nlearned that scholars can use to assess the reliability of new or existing studies, guide editorial reviews, and make\nscientific knowledge production more reliable. I demonstrate the method by implementing a procedural replication of\nMichael Ross's controversial finding that democracy has no effect on child mortality. I find this null finding is an artifact\nof the way five-year averages were computed and the static nature of the preferred model. I demonstrate, using causal\ndiagrams, how concerns about listwise deletion and selection bias affecting previous studies may have been overstated.\nI also provide a checklist with lessons learned.\n",
    "reduced_content": "Research and Politics\nrap.sagepub.com\nCreative Commons NonCommercial-NoDerivs CC-BY-NC-ND: This article is distributed under the terms of the Creative\nCommons Attribution-NonCommercial-NoDerivs 3.0 License (http://www.creativecommons.org/licenses/by-nc-nd/3.0/) which\npermits non-commercial use, reproduction and distribution of the work as published without adaptation or alteration, without further permission\nprovided the original work is attributed as specified on the SAGE and Open Access pages (http://www.uk.sagepub.com/aboutus/openaccess.htm).\nIntroduction\nThe impact of regime type on welfare outcomes is a topic\nof great importance. Against the prevailing consensus, a\nrecent study finds \"little evidence that the rise of democ-\nracy contributed to the fall in infant and child mortality\n872).1 According to the study, the negative association\nbetween democracy and infant and child mortality reported\nin previous studies disappears once corrections are made\nfor additive, time-invariant, unobserved heterogeneity;\ncommon time trends; and selection bias from listwise dele-\ntion. Here, I report results from a procedural replication of\nthis finding. I show this null result is an artifact of a highly\nrestrictive dynamic specification. I also find that concerns\nabout selection bias in previous studies may have been\noverstated. Finally, I document sources of errors and omis-\nsions in a checklist that scholars can use to assess the reli-\nability of new or existing studies, guide editorial reviews,\nand make scientific knowledge production more reliable.\nRoss's (2006) null finding has wide ranging theoretical,\npolicy, and practical implications. It questions core theories of\nrepresentation, electoral accountability, and redistribution\ncy's constructive and direct roles in the conceptualization and\nsatisfaction of needs (Sen, 2000). It also provides evidence\nagainst the desirability of political conditionality in foreign aid\ning down the perceived accomplishments of democracy, it can\nalso influence the very process of democratization via problem\ndefinition (Rochefort and Cobb, 1993), preference formation\n(Druckman and Lupia, 2000), and political persuasion (Cobb\nand Kuklinski, 1997).As a testament to this importance, Ross's\nReplication studies remain highly controversial. One rea-\nson for this is that social scientists disagree on what constitutes\na replication study, how they are done, and for what purpose\nadamant that replication studies should make a substantive \u00ad\nas opposed to procedural \u00ad contribution. In this view\nreplications are completely uninteresting unless accompanied\nDemocracy is good for the poor: A\nFernando Martel Garc\u00eda\n Keywords\nprocedural replication, experimental artifact, procedural errors, checklists, scientific standards, causal inference,\nobservational studies, democracy, infant mortality\nManager, Cambridge Social Science Decision Lab Inc. Washington, DC, USA\nCorresponding author:\nFernando Martel Garc\u00eda, Manager, Cambridge Social Science Decision Lab\nResearch Article\n2 Research and Politics \nby a new discovery. Yet from the point of view of research\npractice, or the study of how scientists do science, a primary\ngoal of replication studies is to identify research artifacts, diag-\nnose sources of errors and omissions, and document lessons\nlearned through checklists, guidelines, and assessment scales.3\nIt is a mistake to think all replication studies should make\na substantive contribution. First, such replication studies often\nstruggle with the question of where the replication ends, and\na new study begins.After all, most scientific studies are noth-\ning but replication studies with extensions and new findings\n(King, 2006: 1). Second, replication studies that aim to make\na substantive contribution often relegate the details of the rep-\nlication \u00ad what went wrong and lessons learned \u00ad to a foot-\nnote, thus forsaking an opportunity to inform and improve\nresearch practice. Third, these studies often focus on conten-\ntious solutions rather than on diagnosing errors and omis-\nsions, yet diagnosis is central to prevention and remediation.\nFor example, procedural checklists can help bring problem-\natic areas to the attention of researchers and reviewers, whilst\navoiding contentious debates about specific solutions that are\nbest resolved in the context of specific applications.\nHere I introduce procedural replication, a formal\nmethod to diagnose errors and omissions, identify research\nartifacts, and contribute new (or improved) checklists that\nscholars can use to inform future research, streamline edi-\ntorial reviews, and improve research practice. The replica-\ntion proceeds in two steps. First, I conduct a pure replication\nto infer the exact procedures and technologies, or scientific\nstandard, used in producing the original study outputs.\nSecond, I undertake a critical evaluation of the inferred\nstandard, including a checklist to prevent future errors and\nomissions. The focus of the evaluation step is on \"what to\nlook out for,\" not what an ideal study would do; and on\nproblematic areas rather than contentious solutions.\nStandard replication studies aim to make substantive con-\ntributions by changing data, model specifications, estima-\ntors or inference procedures. By contrast, procedural\nreplications aim to improve research practice and the reli-\nability of scientific knowledge production by reporting\nsources of errors and omissions.\nThis case-study in research practice proceeds as follows.\nThe section titled \"Data\" describes the data in the replica-\ntion file. \"Pure replication\" presents results from a pure\nreplication, including inferences about the scientific stand-\nard used in the original study. \"Diagnosing errors and omis-\nsions in the inferred scientific standard\" demonstrates how\na minor change to the way quinquennial averages are com-\nputed is enough to reverse the null finding, and how con-\ncerns about selection bias from listwise deletion may be\noverblown. The article ends with \"Conclusion.\"\nData\nIn response to a request for replication materials for Ross's\n(2006) study \"Is democracy good for the poor?\" the author\nkindly provided the following: (1) a raw annual frequency\ndata set; (2) a quinquennial frequency data set used in the\nanalysis (the dependent variable is only available every five\nto 10 years so all annual data are collapsed to quinquennial\nfrequency); and (3) five quinquennial frequency multiply\nimputed data sets. The estimation results using the quin-\nquennial frequency data and the multiply imputed data\nwere sourced from the published manuscript. The original\ncomputer code, random seed for multiple imputation, and\nother elements of the procedures used to generate the esti-\nmates could not be obtained. Even so, judging from infor-\nmation in the published paper and replication file I infer\nthat the principal software platforms used were Stata, R (R\nexact version of each could not be determined.\nPure replication\nThe objective of a pure replication is to infer the exact pro-\ncedures and technologies used in the original article and to\ndocument potential errors and omissions. These are then\ndiagnosed further at the evaluation stage (see \"Diagnosing\nerrors...\"). The pure replication was done in three steps.\nFirst, I reproduced the quinquennial frequency estimation\ndata from the raw annual data using the exact same proce-\ndures reported in the original article. Next, I tried to repro-\nduce the listwise deleted estimation results. Finally, I did\nthe same with multiply imputed data and results. I report\nthe findings from each step below.\nReplicating the estimation dataset\nFirst,theavailablereplicationdataareincomplete.Collapsing\nthe raw annual data into quinquennia by computing five-year\naverages I was unable to replicate the key measure of\ndemocracy \u00ad the polity variable \u00ad in the quinquennial estima-\ntion data set.4 In addition, the adult HIV prevalence and dem-\nocratic years variables were both missing from the annual\ndataset, so I could not replicate their quinquennial averages\nin the estimation dataset. All other variables in the original\nquinquennial frequency dataset could be replicated from the\nannual data with the exception of real GDP (gross domestic\nproduct) per capita, where I found minor differences for the\nUK, Greece, Ireland and Thailand between the quinquennial\ndata in the replication file, and the corresponding five-year\naverages I computed from the annual data.\nSecond, the original study computes quinquennial data\nusing a forward average. As shown in \"Diagnosing\nerrors...\" this can severely dampen the estimated effect of\ndemocracy on child and infant mortality. For example,\nmortality data for the 1970 quinquennium refers to mortal-\nity in the year 1970. These data are regressed on the Polity\ndata for the 1965 quinquennium. However, the latter is\nwhich is centered in 1967, and not the centered average for\nto a three year than a five year lag.\nMartel Garc\u00eda 3\nThird, the original study's criteria for defining the pop-\nulation of interest \u00ad sovereign countries having a popula-\nstudy uses an artificially balanced panel of 169 countries\nThis panel excludes extinct countries (like the USSR) and\nincludes extrapolations for non-sovereign country years\n(like Ukraine prior to 1989). As a result, the original study\nsample contains 14% more annual \"observations\" than\nPrzeworski et al.'s (2000) unbalanced panel of sovereign\ncountry years, which, by recording history as it happened,\navoids extrapolations and includes deceased entities. As\nshown in \"Diagnosing errors...,\" the extra observations in\nartificially balanced panels can inadvertently deflate stand-\nard errors.5\nFourth, the original study did not use the available\ndata efficiently or consistently. With two exceptions, all\nannual data prior to 1970 were discarded before comput-\ning the quinquennial averages and their lagged values.6\nConsequently all lagged values for the 1970 quinquennia,\ndata are available for these years. Some of these observa-\ntions were then imputed manually before multiple impu-\ntation (see Table 2).\nUsing the quinquennial data in the replication file, I was\nable to replicate exactly the listwise deleted results reported\nI found both the R2 and dependent variable are misreported.\nThe reported R2 measures the overall as opposed to the\nwithin-country variation.7 Furthermore, the dependent vari-\nable used in Tables 3 and 4 of the original study is not\nthe World Bank's under-five mortality rate, which has the\nmost missing cells.\nReplicating the multiply imputed estimates\nI could not replicate exactly the multiply imputed data and\nestimates because the replication file does not include a\nrandom seed for the imputations. Even so, I found missing\ndata were imputed inconsistently. For example, quinquen-\nnial averages were computed ignoring missing observa-\ntions (a form of imputation); lagged values of the dependent\nvariable in the first period were manually imputed using the\nactual observation in that period; and the key independent\nvariable, polity, was never included in the imputation\nmodel.8 Moreover, the imputation software available at the\ntime ignored time dependency (King et al., 2001).\nDiagnosing errors and omissions in the\ninferred scientific standard\nThe pure replication in the previous section helped me par-\ntially infer the combination of technological inputs and pro-\ncedures (or scientific standard) used in the original study.\nHere, I diagnose potential errors and omissions. The objec-\ntive is to learn from mistakes, assess their impact, and pro-\npose preventive measures, not to make a substantive\ncontribution about regime type and human welfare by\nchanging data sources, model specification, estimators, or\ninferential procedures.\nRelaxing the dynamic specification in the\nobserved dataset\nThe original study's preferred two-way fixed effect model\nspecification includes only one lag of polity, and no interac-\ntions with time. Combined with the forward quinquennial\naverages, this imposes severe dynamic restrictions.\nVariable Obs. Missing % Mean Std. Dev. Min. Max.\nLagged variables\nthe quinquennial datum for 1970 is the arithmetic average of the log annual data for the years 1970\u00ad1974 inclusive). These averages are computed\nignoring missing values. Over 30% of mortality data from various sources are observed as missing in the quinquennial data. The equivalent figure for\nthe annual data is 80%. Lagged variables are lagged one quinquennium.\nWB: World Bank; GDP: gross domestic product\n4 Research and Politics \nAs formulated, the original study asks not whether democ-\nracy has an effect \u00ad any effect \u00ad on infant and child mortal-\nity, but whether it has a constant additive effect in the first\nthree years after a transition. Few social scientists would\nexpect democracy to have a substantive impact in such a\nshort period, yet the original study provides no theoretical\njustifications for this choice. This is all the more puzzling\nconsidering that most econometric textbooks highlight the\nflexibility of panel data in characterizing dynamic effects\nFor example, in the preferred two-way fixed effects\nmodel specification the outcome for 1975 is given by yi\n=  i\n + i\n, where polity is lagged\none quinquennia, and the penultimate term is a vector of\nlagged covariates and time dummies. First, the quinquennial\nlag is computed as Polity Polity\ni i t\nt\n, ,\n{ , , }\n.\n=\n\n\na three-year than a five-year lag. Second, because the pre-\nferred model specification includes only one lag but no\ninteractions with time, it rules out \u00ad by assumption \u00ad any\ndynamic adjustment, long-run effects, and changes to the\nrate of mortality decline. That is, the model assumes democ-\nracy only has a constant additive effect on mortality in the\nfirst three years or so after a transition, and not thereafter.\nThis is an extremely restrictive assumption.\nThe dynamic restrictions are so severe that even a\nminor relaxation, like computing centered quinquennial\naverages (which allow for a slightly longer lagged effect),\nis enough to reverse the null findings in the original study.\nTo show this separate from the multiple imputation I rep-\nlicated the listwise deleted estimation results in Table 3 of\nthe original study, replacing the forward quinquennial\ndata in the original estimation with centered quinquennia.\nI also used Przeworski et al.'s (2000) unbalanced panel of\nsovereign country years.9 Using the exact same two-way\nfixed effect specification in the published table \u00ad the\nstudy's preferred specification \u00ad I obtained a point esti-\ncally significant, and about twice as large as the published\nof 10 points in the polity variable implies a 5% average\ndecline in child mortality after five years (95% CI: \u00ad9.4 to\nTo check that this was not a result of using a different\npopulation, I replaced Przeworski et al.'s (2000) unbal-\nanced panel of sovereign country years with the original\nstudy's artificially balanced panel. The result is an almost\ndynamic specification further, by adding an extra lag of\npolity or an interaction with a linear time trend, also yielded\npractically and statistically significant results. These results\nunderscore the importance of omitted dynamics in generat-\ning the original study's null result.\nRelaxing the dynamic specification in the\nmultiply imputed dataset\nThe original study claims previous significant findings may\nhave been biased by missing data. Specifically, listwise\ndeletion drops rich autocracies with enviable records in\nreducing mortality from the sample, thus biasing the esti-\nmated effect in favor of democracies. Assuming this bias is\nremoved by multiply imputing the missing data and con-\ntrolling for two-way fixed effects, the original article\nshowed democracy has a negligible effect on mortality. In\nwhat follows I show the claim about selection bias has\nweak theoretical support. The null result in the original\nstudy is an artifact of the extremely restrictive dynamic\nTable 2. Summary statistics for Ross's quinquennial data set, 1970.\nVariable Obs. Missing % Mean Std. Dev. Min. Max.\nLagged variables \nData for the first quinquennia (1970\u00ad1974) are missing for most regressors. The annual data set was truncated in 1970 before computing the lagged\nquinquennial averages, with two exceptions. First, the quinquennial lag of polity was calculated before truncation. Second, the dependent variable\nin 1970 and its lagged value are exactly identical because the former was used to manually impute the latter. For the other variables, truncating the\nannual data before calculating the lags discards one-eighth of the cells, including UNICEF data on child and infant mortality for 1965.\nWB: World Bank; GDP: gross domestic product\nMartel Garc\u00eda 5\nspecification, not the result of correcting selection bias in\nprevious studies.\nFirst, the selection bias argument does not withstand\ntheoretical scrutiny. The fact that rich autocracies with\nenviable declines in infant and child mortality are listwise\ndeleted from the estimation sample tells us nothing about\nthe effect of democracy on mortality. For all we know, their\ndeclines could have been faster (or slower) had they been\ndemocracies. Therefore the bias, if it exists, could go either\nway. Besides, if selection is on the basis of income and\nregime type, as the original study claims, then controlling\nfor these variables, like most previous studies do, should\nhelp alleviate the bias. For example, suppose autocratic\nregimes above a certain income threshold all drop out from\nthe sample. If the effect of democracy increases with\nincome, then the sample estimate will underestimate the\npopulation effect. But the estimate will remain unbiased for\nthe countries in the sample, which in this case includes\nmost of the world. Figure 1 illustrates this logic using a\nSecond, the selection bias argument does not withstand\nempirical scrutiny. For example, using centered quinquen-\nnia, and a multiple imputation software better suited for\ntime dependence, I found democracy has a practical and\nstatistically significant effect on infant and child mortality,\nas reported in Table 3.11 These results are very different\nLog under-five mortality LDV LDV LDV FE LDV LDV FE\n***Significantly different from zero at 99% confidence. Only noted for key independent variables.\n**Significantly different from zero at 95% confidence. Only noted for key independent variables.\n*Significantly different from zero at 90% confidence. Only noted for key independent variables.\nThese estimates were computed using a stricter definition of sovereign country years (Przeworski et al., 2000), centered quinquennial averages, and\nthe software package Amelia II for multiple imputation (see main text for further details). Both polity and democratic years are now highly statisti-\ncally significant in all specifications except the last. By contrast, in the original study they are insignificant across all specifications. All regressors,\nexcept period dummies, are lagged one quinquennia. The LDV specification uses panel corrected standard errors, assuming a panel-specific AR(1)\nautocorrelation structure. The static fixed effects (FE) specification uses robust standard errors (although, in theory, these are not needed (Greene,\nLDV: Lagged dependent variable; NT: Number of countries (N), Number of time periods (T), where NT= N x T; AR: Auto-regressive.\n6 Research and Politics \nfrom the corresponding estimates in Table 4 of the original\npolity or democratic years is significant. By contrast, the\ncorresponding estimates reported in Table 3 are all practi-\ncally and statistically significant, with the exception of\ndemocratic years in the last column.\nTo further check the robustness of this results I repli-\ntable reports the coefficients on polity when different mul-\ntiply imputed measures of infant and child mortality are\nused. I repeated the replication twice. Once using\nPrzeworski et al.'s (2000) unbalanced panel of sovereign\ncountry years and centered quinquennia (top panel, Table\n4), and again using the artificially balanced panel of sover-\neign country years and forward quinquennia from the origi-\nnal study (bottom panel, Table 4).\nFirst, using the original study's preferred two-way fixed\neffect model I found polity is significant at the 10% level or\nless whenever I used the centered quinquennia data (top\npanel, last column of Table 4). However, using the forward\nquinquennia I found all estimated coefficients are insignifi-\ncant, and about half the size (bottom panel, last column).\nTable 4. Procedural replication of Ross's Table 5 showing\nthe coefficients on polity across alternate multiply imputed\nmeasures of infant and child mortality.\nLDV LDV and period\ndummies\nFE and period\ndummies\nACLP population of sovereign country years, centered quinquennial\naverages\nRoss population of sovereign country years, forward quinquennial\naverages\n***Significantly different from zero at 99% confidence.\n**Significantly different from zero at 95% confidence.\n*Significantly different from zero at 90% confidence.\nThe top panel reports estimates using Przeworski et al.'s (2000) more\nrestrictive definition of sovereign country years, centered quinquen-\nnial averages (so the quinquennial data for 1970 is the average of years\n(see main text). The bottom panel reports the same estimates using\nthe original study's population of sovereign country years, forward\nquinquennial averages (so the quinquennial data for 1970 is the average\nsions (see main text).\nFE: fixed effects; CMR: child mortality rate; WB: World Bank; WHO:\nWorld Health Organization; IMR: infant mortality rate\nCLP: Przeworsky et al's (2000) dataset; LDV: Lagged dependent variable;\nNT: Number of countries (N), Number of time periods (T), where\nNT= N x T.\nSource: Reproduced from Ross M (2006) Is democracy good for the\nU\nt\nt\nR\nFigure 1. Simplified causal diagram illustrating the causes of the\noutcome of interest, the missingness, and the selection through\nlistwise deletion. The graphical model assumes mortality is\ncaused by last period's regime type (polityt-1\n), income (GPDt-1\n),\nand other unobserved causes (Ut\n). For simplicity I assume GDPt-1\nis the only variable with missing data. The missingness indicator\nR\nGDP\nequals one whenever GDP is missing, and is zero\notherwise. Selection into the listwise deleted sample is on the\nbasis of missingness. Thus, Select equals one if an observation\nis included in the listwise deleted sample (i.e. R\nGDP\nis zero otherwise (i.e. R\nGDP\n= 1). Conditioning the analysis on\nSelect = 1, a descendant of collider R\nGDP\n, opens a backdoor\npath from polityt-1\nto IMRt\nvia the missingness indicator and\nincome variables. However, conditioning on income blocks this\nand other backdoor paths. If so the population experimental\ndistribution that would have been observed had polityt-1\nbeen\nrandomized can be estimated \u00ad within income strata \u00ad using the\npassively observed distribution (formally P (IMRt\n|do (polityt-1\n),\n, Select)  P(IMRt\n|polityt-1\n), where the operator\ndo (.) captures the notion of experimental manipulation).\nFrom here, we can estimate the overall population effect if the\ndistribution of income in the selected sample overlaps with the\npopulation distribution and if the population weights for the\nstrata are known. Otherwise we can only estimate the effect\nwithin the selected sample.\nGDP: gross domestic product; IMR: infant mortality rate\nMartel Garc\u00eda 7\nSecond, using the lagged dependent variable specifica-\ntions I found most point estimates are similar and signifi-\ncant, even when forward quinquennia are used (first two\ncolumns of Table 4). This is because the lagged dependent\nvariable specification, though still very simple, allows for\nshort- and long-run effects. However, I found standard\nerrors are higher when using Przeworski et al.'s (2000)\nstricter definition of sovereign country years (top panel)\ncompared to the original study's criteria (bottom panel).\nThe reason for this difference is that the stricter criteria\nyield 957 observations, as opposed to the original study's\n1183 observations. The latter treats observations for coun-\ntries like Ukraine prior to 1989 as missing rather than unde-\nfined. Multiply imputing these data may exaggerate the\namount of information in the dataset, thus underestimating\nuncertainty.\nI summarize the lessons from the pure replication in the\nsection \"Pure replication\" and the diagnosis and criticism\nin \"Diagnosing errors...\" in a checklist (see Table 5). Such\na checklist can be used prospectively to help design more\neffective studies on the impact of regime type on human\nwelfare. It can also be used retrospectively to assess the\nquality of existing studies and as a quality control in the\npeer review process.\nConclusion\nRoss's (2006) controversial and widely cited finding that\ndemocracy has no effect on child mortality is of momen-\ntous significance. If true it has wide ranging theoretical,\npolicy, and practical implications. I replicated this study\nusing a procedural replication and found reasons to chal-\nlenge it.\nI found Ross's (2006) original null result is an artifact of\nan extremely restrictive dynamic specification. The pre-\nferred static fixed effect model specification, combined\nwith forward quinquennial averages, assumes democracy\nonly has an additive effect on child or infant mortality\nwithin the first three years or so after a transition \u00ad and not\nthereafter. Few social scientists expect democracy to have a\nsubstantive impact in such a short period. The restriction is\nso severe that even a small change in the dynamic specifi-\ncation, like using centered quinquennial averages that allow\nfor a five-year lag, is enough to detect practically and statis-\ntically significant effects. The lesson here is that scholars\nshould think carefully about dynamics when estimating the\neffect of democracy on mortality.\nI also found the original study's concern over listwise\ndeletion and selection bias may have been overstated. Ross\n(2006) claims previous significant findings are biased by\nmissing data. Specifically, listwise deletion drops rich autoc-\nracies with excellent records in reducing mortality from the\nsample, thereby biasing the estimated effect in favor of\ndemocracies. However, the theoretical arguments and empir-\nical evidence presented here demonstrate that selection bias\nmay not have been such a problem after all. What is driving\nthe null result is the extremely restrictive dynamic specifica-\ntion, not the presumed correction for selection bias in previ-\nous studies. I also found a more sound definition of the\npopulation of interest yields better measures of uncertainty.\nFinally, I showed how causal diagrams can be used to ana-\nlyze selection bias and listwise deletion succinctly.\nHere I have demonstrated the use of procedural replica-\ntion. The objective of procedural replication is to diagnose\nsources of errors and omissions, identify research artifacts,\nand propose preventive measures including checklists to\nTable 5. DEMOCHECK: A procedural checklist for studying the impact of democracy on human welfare.\nItem Check\nProcedures\nCarefully consider the dynamic nature of the effect you are trying to estimate, and whether a static fixed effect\nspecification makes theoretical sense, is consistent with the data, and is robust.\n\nDescribe the population of interest, including the cross-sectional and time-wise criteria used for selection of\ncountry-year units into the study, and be explicit about how you plan to deal with extinct countries, new countries,\nmergers, and splits. Consider using Przeworski et al.'s (2000) unbalanced panel of sovereign country years.\n\nConsider using a casual diagram to communicate easily and transparently the assumed causal structure generating the\noutcome, the missing data, and the sample selection.\n\nExercise care in aggregating panel data to lower frequencies, and consider how that may affect the dynamic\ninterpretation of the estimates. Centered averages are often easier to interpret.\n\nForm lags before truncating the data to a shorter period. \nExamine the time-wise and cross-sectional patterns of missingness. \nUse a random seed, like a verifiable public lottery number, for multiple imputations and include it in the replication file. \nUse the within estimator, rather than the least square dummy variable estimator, in fixed effect models to get a\nmore meaningful R2.\n\nSoftware technologies\nReport the software used and its release version in the main article or replication file. \nConsider using a multiple imputation software, like Amelia II, for data sets with time dependence. \n8 Research and Politics \ninform future research, streamline editorial reviews, and\nimprove cumulative research about the impact of regime\ntype on human welfare. In pursuing this objective I deliber-\nately avoided questioning the basic research design, choice\nof measures, model specifications, estimators, inferential\ntechniques and other assumptions.12 Advocating alternative\nchoices and assumptions, and testing them, is the remit of\nstandard scientific studies, not procedural replications.\nIndeed, it is a mistake to think all replication studies must\nmake a substantive contribution. The point of any conse-\nquential scientific endeavor is not just to present novel\nfindings, but to actually answer existing questions reliably.\nProcedural replication focuses squarely on improving our\nanswers to existing questions and so the method ought to be\nas relevant as the questions are consequential.\n"
}