{
    "abstract": "Abstract\nDigital social analytics is a subset of Big Data methods that is used to understand the social environment in which people\nand organizations have to act. This paper presents an analysis of eight projects that are experimenting with the use of\nthese methods for various purposes. It shows that two specific technological features influence the work with such\nmethods in all the cases. The first concerns the need to distribute choices about the structure of data to third-party\nactors and the second concerns the need to balance machine intelligence and human intuition when automating the\nanalysis. These features set specific conditions for knowledge production, and the paper identifies two opposite\napproaches for engaging with each of these conditions. These features and approaches are finally combined into a\ntwo-dimensional affordance space that illustrates how there is flexibility in the way project leaders interact with the\nfeatures of the data environment. It thereby also shows how digital social analytics come to have different affordances for\ndifferent projects.\n",
    "reduced_content": "Original Research Article\nBetween technical features and analytic\ncapabilities: Charting a relational\naffordance space for digital social analytics\nAnders Koed Madsen\n Keywords\nDigital social analytics, Big Data, affordances, information infrastructures, Gibson, Bowker\nIntroduction\nWhen Google used hyperlinks to determine the rele-\nvance of web pages at the end of the 1990s, they did\nnot just redefine the practice of search (Brin and Page,\n1998). Their success made a compelling case for the\nargument that digital traces could be used as empirical\nindications of social phenomena. The methodological\nidea of repurposing digital traces as social data has,\nsince then, spread beyond the field of search. Inside\nGoogle it has inspired the Flu Trends project that has\nboth been hailed as a prime example of the powers of\nBig Data (Anderson, 2008) and criticized as an example\nof Big Data hubris (Lazer et al., 2014). Outside Google\nit has led to visions of how digital traces and Big Data\ncan optimize decisions in, for instance, consultancy\nfirms (McKinsey Global Institute, 2011) and develop-\nmental organizations (World Economic Forum, 2012).\nGoogle's success has spawned an interest in a specific\nsubset of methods that this paper will term digital social\nanalytics (DSA). The methods falling under this head-\ning are here defined as repurposing digital traces from\nthe web in order to establish new empirical sensitivities\ntoward social phenomena. The fact that social analysts\nacross different organizational sectors find themselves\nconfronted by an unprecedented proliferation of web-\nbased data has simply motivated a shift toward the\ndigital in the methods they use to understand\nthe social environment in which they are working\nThis uptake of DSA is of sociological interest\nbecause empirical tools and techniques shape our\nrepresentations of the world--and our actions within\nit. This is evident when we look at the way statistical\nreasoning has had effects on urban planning\nAalborg University Copenhagen, Denmark\nCorresponding author:\nAnders Koed Madsen, Aalborg University Copenhagen, A.C. Meyers\nEmail: akma@learning.aau.dk\nBig Data & Society\nbds.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License (http://\nwww.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (http://www.uk.sagepub.com/aboutus/\nopenaccess.htm)\n(Scott, 1998), how rankings have changed university\nmanagement (Espeland and Sauder, 2007), and how\nsurveys (Glynn et al., 2004) and censuses (Ruppert,\n2011) have been used to operationalize ``the public''\nas an object of analysis. This paper assumes that similar\nstories will be told when it comes to the techniques\nassociated with DSA. In the words of Latour (1990),\nsuch techniques will produce inscriptions that define\n``what it is to see, and what there is to see.'' Or, as\nformulated by Boland and O'Leary (1991), because\n``inscribing and organizing are interdependent.''\nThis paper presents an inquiry into the emerging use\nof DSA on the basis of two empirical sources. One is\ninterviews with eight project leaders working with this\nempirical method across different organizational con-\ntexts. The other is analysis of the documentation of\ntheir respective projects. The paper will proceed as\nfollows. The ``Technological affordances and distribu-\nted information infrastructures'' section will introduce\nJames Gibson's (1986) concept of affordances and\nGeoffery Bowker's concept of information infrastruc-\ntures (2010) to formulate two research questions that\nwill guide the paper. ``Method and research design'' will\noutline the methodological strategy for answering these\nquestions on the basis of interviews and documents.\n``Identifying characteristic features of the digital data\nenvironment'' will answer the first research question by\npinpointing features of digital data that enable different\nmodes of seeing than previous analog methods.\n``Variations in strategies for interacting with distribu-\ntion and automatization'' will answer the second\nresearch question by identifying variations in the way\nthe project leaders devise solutions to produce social\nknowledge with the conditions set by the features.\nFinally, ``DSA: A method in a relational affordance\nspace'' will combine the identified features and\napproaches into a relational ``affordance space'' that\nillustrates how DSA come to have different affordances\nfor different projects.\nTechnological affordances and\ndistributed information infrastructures\nJames Gibson's theory of affordances concerns the\nway we see the world around us. It was formulated\nas an intervention into the mid-20th century debate\nabout perception and Gibson refused the prevailing\nempiricist understanding of perception. Instead of\nunderstanding vision as the causal result of external\nstimulus that affects a passive brain through the sense\norgans, he conceptualized it as the result of a con-\nstant and active interaction between the perceiver and\nthe environment. The concept of affordances is the\ncore of this argument, and Gibson defined it as\nfollows:\nThe affordances of the environment is what it offers the\nanimal [. . .] The verb to afford is found in the dictionary\nbut the noun affordance is not. I have made it up.\nI mean by it something that refers to both the environ-\nment and the animal in a way that no existing term\nThe first sentence of this quote emphasizes that in\norder to understand vision one must understand the\nentities that surround a perceiving agent. Gibson con-\nceptualized the environment as being full of objects,\npersons, and mediums that create specific types of\ninformation to be picked up. He saw the environment\nas having a set of features that enable certain percep-\ntions and actions. Gibson therefore took the environ-\nment to provide a certain scope of resources for seeing\nthe world. The first research question of the paper\ntransfers this ontology of perception to DSA, when it\nasks the following: ``Does the environment of digital\ntraces have characteristic features that enable or cir-\ncumvent specific modes of seeing across projects that\nare working with DSA for very different reasons?''\nThe answer to this question gets us some of the way\ntoward understanding the affordances of DSA.\nHowever, if we are to remain faithful to Gibson's\ntheoretical framework, it cannot stand alone. It is evi-\ndent from Gibson's quote above that the work of pin-\npointing the enabling and constraining features of the\nenvironment only tells half the story. The second part\nof the quote emphasizes that affordances is a noun that\nrefers to the perceiving agent as well as to the environ-\nment. It is not a verb that can be attached to entities in\nthe environment. This relational approach is stressed\neven more clearly in the following:\n[. . .] an affordance is neither an objective property nor a\nsubjective property; or it is both if you like. An affor-\ndance cuts across the dichotomy of subjective-objective\nand helps us understand its inadequacy. It is equally a\nfact of the environment and a fact of behavior.\nThe features of the environment only frame the possi-\nbility of agentic action in relation to an object\n(Hutchby, 2001). They set certain conditions for experi-\nence, but they do not determine it. The perceiving agent\nwill always have a unique set of capabilities that makes\nhim or her interact with these features in a specific way.\nAs put by Braund (2008), experience is the result of\nreciprocal movements in a perceiver\u00adenvironment\nsystem. Affordance is relative to the action capabilities\nof a particular perceiving actor at a particular situation.\nIt is a distributed and relational phenomenon.\nThe second research question, therefore, leaves the\nfocus on features for a focus on differences in the way\n2 Big Data & Society\nthey are interacted with by different project leaders.\nHowever, the specific wording of this question builds\non Geoffrey Bowker's writings on information infra-\nstructures, which he defines as ``pervasive enabling\nresources in network form'' (Bowker et al., 2010). To\nBowker, such networks are not just tubes and wires\nwith certain technical features. Rather, they are distrib-\nuted across a broad range of social and technical actors.\nIn fact, Bowker argues that one of the core questions to\nask of information infrastructures is whether they dis-\ntribute central tasks (such as creating meta-data or\nensuring trust) to social or technical actors:\nIn building cyberinfrastructure, the key question is not\nwhether a problem is a ``social'' problem or a ``technical''\none.Thatisputtingitthe wrong way around. The question\nis whether we choose, for any given problem, a primarily\nsocial or a technical solution, or some combination. It is\nthe distribution of solutions that is of concern as the object\nof study and as a series of elements that supportinfrastruc-\nture in different ways at different moments.\nThis way of thinking is not foreign to Gibson's\nthoughts about experience as the result of a constant\ninteraction between the situated capabilities of a per-\nceiver and the features of the environment. He was also\ninterested in how solutions to seeing were distributed\nacross different actors. It is this combination between\nthe works of Gibson and Bowker that is the foundation\nfor the following formulation of the second research\nquestion: ``Do the different projects vary in the way\nthey distribute solutions to social and technical actors\nwhen handling the features set by the digital data\nenvironment?''\nThe combined answers to these questions lay the\nfoundation for conclusions about the affordances of\nDSA. More specifically, the last section of the paper\ncharts a relational affordance space in which DSA\nprojects move. This space serves as an analytic contri-\nbution to recent sociological discussions about the\npractical epistemologies of the digital (Bowker, 2014;\nSavage and Burrows, 2009). It provides a foundation\nfrom which to understand DSA projects and thereby\nalso how knowledge about the social may--or may\nnot--be changing with the uptake of this new\nmethodology.\nMethod and research design\nThe empirical sources for answering the research ques-\ntions are twofold. One source is interviews with eight\nproject leaders that are using DSA for purposes that\nvary from the detection of cultural tensions around\nbrands to the detection of innovation paths around\nemerging technologies. The second source is qualitative\nanalyses of specific documents that these interviewees\nsuggested as relevant readings in order to understand\ntheir work. Each project leader will be taken as a case\nwhose approach to DSA can be understood through\nthese two sources of data. An overview of the data\ncan be found in Table 1.\nThe interviewees were chosen on the basis of a most\ndifferent case study design that is well suited to answer\nthe first research question. By studying projects that use\nDSA for a variation of purposes, it becomes possible to\ndetect features of the data environment that enable and\nconstrain modes of seeing in similar ways across differ-\nent projects (Flyvbjerg, 2004). The selection of inter-\nviewees was decided through a purposive sampling\ntechnique, where the guiding principle is to ``think of\nthe person or place or situation that has the largest\npotential for advancing your understanding and look\nthere'' (Palys, 2008). More specifically, the cases were\nchosen through a combination of criterion sampling,\nexpert sampling, and maximum variation sampling.\nThe criterion set for cases to be included in the study\nwas that the project leader had to be experienced in\nusing DSA in his or her organization. Besides that he\nor she had to be a deep enough expert to answer ques-\ntions about features of the data environment that he or\nshe was working within. Finally, the cases were chosen\nso as to ensure maximum variation in the kind of prob-\nlems the project leaders worked with and the type of\norganizations they were located in.\nThe interviews were carried out between October\nthrough Skype. They lasted between 45 min and 1 h\nand the semistructured interview guides were to a\nlarge extent based on the documents suggested by the\ninterviewees. The transcribed interviews and the docu-\nments were coded and analyzed in NVivo through a\ntwo-step process. The first step was to code the empir-\nical material for features of the data environment that\nappeared as enabling or constraining. The aim of this\nanalytic step was to identify features that were visible\nacross the otherwise different cases. The second step\nwas to recode the chunks of data concerning the iden-\ntified features with the aim of identifying the scope of\nvariation in the solutions for working within the con-\nditions set by these features. This analysis led to the\ndevelopment of continuums of analytic ideal types\nthat distribute solutions to technical and social actors\nin opposite ways.\nIdentifying characteristic features of the\ndigital data environment\nThe first step of the analysis resulted in the identifica-\ntion of two features of the data environment that\nTable 1. Overview of cases and empirical data.\nName of project leader and\norganizational affiliation\nThe project in which ``digital social ana-\nlytics'' is used Interview data imported into NVivo Document data imported into NVivoa\nAna Andjelic Digital strategist\nand marketing consultant\nDetecting the value creation and cultural\ntensions around brands\nThirty-five minute interview (D1) Two years of blogposts by Ana Andjelic on the blog\n``I [love] marketing'' (D2)\nJohn Kelly Cofounder and chief\nscientist at Morningside\nAnalytics\nDetecting political communities that share\nsources of information and opinion\nOne hour interview (MA1) Three academic papers: Pride of Place\n(MA2) Mapping Iran's Online Public\n(MA3) Mapping the Arabic Blogosphere\nAlan Porter Foresight analyst at\nSearch Technology Inc.\nUnderstanding innovation paths around\nemerging technologies and evaluating\nthe transdisciplinary reach of research\nfields\nForty-five minute interview (STI1) Three academic papers: Forecasting Innovation\nPathways (STI2) A Forward Diversity Index\n(STI3) Assessing the Human and Social\nDynamics Program (STI4)\nChris Pallaris Senior consultant\nat I-Intelligence\nSpotting signals of change that can support\ngovernment policy and business strategy\nOne hour interview (I1) One academic paper: OSINT--Knowledge,\nActivity and Organization (I2) One keynote\npresentation: The Four Architectures of\nCompetitive Intelligence (I3)\nVincent Lepine\n\u00b4y Sociologist at\nMIT's Mapping Controversies\nprogram\nMapping the dynamics of sociotechnical\ncontroversies\nOne hour interview (MC1) None\nGuilhem Fouetillou CEO and\ncofounder at Linkfluence\nCharting product-related conversations\ntaking place in social web communities\nOne hour interview (L1) None\nAnonymized Founder and con-\nsultant at Information Service\nBureau\nCapturing information that can aid the\nquality of military intelligence\nForty-five minute interview (R1) One keynote presentation [Anonymized] (R2)\nRobert Kirkpatrick Director of\nthe visualization branch ``Global\nPulse'' at the United Nations\nSpotting early signals of crisis-related\nstress and other indications of devel-\nopmental concern\nOne hour interview (UN1) Three project white papers: Twitter and\nPerceptions of Crisis-related Stress\n(UN2) Using Social Media and Conversations\nto Add Depth to Unemployment Statistics\n(UN3) Streams of Media Issues: Monitoring\nWorld Food Security (UN4) One statement\nfrom the UN Secretary-General (UN5)\naThe documents can be obtained by contacting the author, and their references are listed in the `Documents used as empirical data to supplement the interviews' section.\n4 Big Data & Society\ninfluence the work with DSA across the cases. One is\nthe distributed character of the data structures on the\nweb and the other is the necessity of automatization\nwhen working with fast paced data sets. Each feature\nset specific conditions for the way data can be captured\nand processed and they will be discussed in turn.\nDistributed character of data structures\non the web\nTo structure data is here defined as the practice of\nsegmenting it on the basis of a set of predefined speci-\nfications or classifications. Sociologists of knowledge\nhave for a long time emphasized the importance of\nsuch structures in the organization of knowledge\n(Bowker and Star, 1999) and this importance is not\ndiminished when it comes to DSA. However, it has\nbeen suggested that the digital data environment is\nfull of unstructured data (Mayer-Scho\n\u00a8 nberger and\nCukier, 2013). For instance, it has been suggested\nthat data coming from platforms such as Twitter lack\nstructure in the sense that they are not products of\nclearly defined interactions (Shaw, 2013). Bowker\nlenged this idea with the argument that no data is\never raw or unstructured.\nThis paper follows Bowker and Gitelman in inter-\npreting all digital data as always-already structured.\nFor instance, a tweet comes with a 140 character limit\nthat influences mode of expression and it has specific\nmetadata that shapes the way it can be analyzed. This\ndoes not mean that data in different DSA projects have\nthe equal when it comes to structure. The analysis of\nthe eight cases will show that the practice of structuring\nhas distinct dynamics in different sources of data.\nHowever, DSA projects share a common fate when it\ncomes to the structuring of data. All of them work in an\nenvironment where both data and its structure are\nrepurposed from secondhand sources on the web.\nThis distribution stands in contrast to methods such\nas surveys (Agresti and Finlay, 1997) and focus\ngroups (Morgan, 1996) where the structure of the\ndata can be more or less controlled or moderated\nfrom the initial formulation of questions to the final\nanalysis.\nThis feature of distribution is evident when looking\nat Table 2. Despite working with different problems in\ndifferent organizations, each of the project leaders has\nto rely on data that is prestructured by channels and\nplatforms that own and control interesting data. John\nKelly from Morningside Analytics touches upon this\nfeature of the data environment, when he compares\nthe media content he bases his analyses on with the\ncontent that can be obtained from well-described\nsources such as newspapers: ``Data is networktized\n[. . .] Now you got huge scale network structured and\neverybody in the world can in principle participate. So\nit's a different game that requires a different approach\n(MA1).'' Kelly presents the fact that data are network-\ntized as both an enabling and constraining feature in his\nattempt to visualize political communities. It is\nenabling in the sense that it makes it possible to repre-\nsent what he describes as the ``non-famous and\nnon-powerful individuals'' (MA1). However, it is con-\nstraining because it marks the end of an era where, in\nthe words of Kelly, ``people had some sort of charac-\nterization of the channel'' (MA1) they drew their data\nfrom. His argument is that it is harder to pinpoint what\nkind of data source a social media platform is than do\nthe same thing with an established channel like Fox\nTable 2. The distribution of data formats in the projects.\nProject leader Mentioned data sources Data formats and their role in the project\nAna Andjelic Twitter\nGoogle Trends\nRetweets as indications of information relevance\nSearch queries as markers of interest\nJohn Kelly Wikipedia\nBlogs\nLinks and linkshorteners as markers of associations\nAlan Porter Web of Science\nLexus-Nexus\nDatabase categories as markers of entity types (field-structured data)\nChris Pallaris Twitter\nGoogle\n140 character tweets as mood indicators\nTime stamps as an indicator of actuality\nVincent Lepine\n\u00b4y Google Links as associations\nGuilhem Fouetillou Blogs\nTwitter\nBlogrolls as associations\nTime stamps as an indicator of actuality 140 character tweets as mood\nindicators\nAnonymized Twitter\nGoogle Custom Search\nAuthor information as marker of identity\nSource ranking as marker of relevance\nRobert Kirkpatrick Twitter 140 character tweets as mood indicators\nNews. Chris Pallaris from the consultancy firm I-intel-\nligence links this constraint to the distribution of con-\ntrol over data sources: ``You know you cannot control\nthe information, okay, that is the first thing [. . .] the\ninfrastructure with which the generated information is\nno longer in anybody's control (I1)''. John Kelly and\nChris Pallaris point to a characteristic of DSA that is\nnicely captured by Noortje Marres' (2012) concept of the\n``redistribution of methods.'' The production and struc-\nturing of the data are shaped by a distributed set of\nactors with mixed interests when one works with DSA.\nThis means that access to relevant digital data often\ncomes at the cost of losing control and transparency\ninto the way it is structured. This redistribution is also\nan issue when Guilhem Fouetillou's company,\nLinkfluence, captures data from social media platforms:\nWe really try to understand how the infrastructure\nimpacts the way that people are interacting and it is\nreally something important for us and each time there\nis a new social media place that appears we try to\nunderstand how it moves the [. . .] existing landscape,\nand what are the new rules of this space. (L1)\nThe infrastructure sets the rules for data production\nand Fouetillou gives an example of how important it\nis for his company to understand the moving infrastruc-\ntures around, for instance, the practice of linking in the\nblogosphere. As it stands now, this infrastructure\nenables people to leave generic links at the blog level.\nHowever, as Fouetillou formulates it, it is ``not good to\nsay, I like this article but it doesn't mean that I like this\nblog, you know'' (L1). The important point is that the\nconditions for data production and structure are set by\na third-party actor. Fouetillou is in a situation where he\nrelies on the link but has no control over the conditions\nfor leaving these data.\nThe same goes for all the project leaders that are using\ntweets as the basis for their projects. A methodological\nchallenge mentioned by Ana Andjelic, for instance, is\nthat ``Twitter creates a lot of complexity in the way the\nre-tweeting system is set up'' (D1). Similarly, Chris\nPallaris argues that the structure of 140 characters\nleaves ``no space to really give to provide a depth of\nfeeling'' (I1). Even Alan Porter, who works with a\nmore structured database like Factiva, reports trouble\nwhen repurposing its categories to understand dynamics\nof technological innovation: ``[Factiva is a] very nasty\ndatabase [. . .] the more we work with these subject cate-\ngories, the more we have an `uh, oh' feeling'' (STI1).\nThese methodological quarrels indicate the existence\nof so-called blue team dynamics that must be dealt with\nwhen working with DSA. Such dynamics arise with\nsecondhand data. They refer to situations where a\ndata provider modifies a data infrastructure for reasons\nthat are unrelated to a specific analytic project--but\nnonetheless come to influence it (Lazer et al., 2014).\nSuch dynamics have recently troubled the poster child\nof DSA--Google Flu Trends. Google's model overes-\nhave been that changes in Google's drop-down menu\nmade it suggest flu-related search words to its users\n(Lazer et al., 2014). This example of blue team\ndynamics exemplifies that web-based data are always\nprestructured and regularly restructured.\nBut the troubles with prestructured data may not be\nconfined to blue team dynamics. The anonymized mili-\ntary intelligence analyst, for instance, speculates that\nsources like Twitter and Google may deliberately be cen-\nsoring and cleaning the data they make available through\ntheir APIs. When speaking about the results from\nGoogle's custom search engine, he, for instance,\nexpresses the ``feeling that The New York Times is\npaying to be there'' (R1). Similarly, he argues that the\ninvisibility of Wikileaks on Twitter ignites the ``feeling\nthat it was simply censored by Twitter'' (R1).\nSuch deliberate attempts at gaining information are\nknown as red team dynamics (Lazer et al., 2014) and there\nis often no way to know whether such dynamics are at\nplay in web-based data. This means that the lack of con-\ntrol of data structures is supplemented with a great deal\nof black boxing when it comes to the sources for doing\nDSA. These features of the data environment are of\nimmense importance to the epistemological characteris-\ntics of DSA because they set conditions for the modes of\nseeing the methods enables. Andlejic also explicates the\nfact that DSA requires the analyst to rely on a distributed\nset of tools, when she reflects on the practice of working\nwith web-based data as a digital strategist:\nThere is a script in every tool that sets out how you are\ngoing to use it [. . .] I think about it when I do not have\nInternet access how I think differently [. . .] My writing\nprocess is assemblaged of [. . .] different sources, tools\nand different others. (D1)\nThe necessity of automatization\nThe second feature of the digital data environment that\nis mentioned across the cases concerns the need to rely\non some degree of automatization in the processing of\ndata. Automatization is here taken to be the choice of\nusing computational technology to allow a process to\ntake place in a spontaneous manner that does not\nrequire input from a human analyst. By being spontan-\neous, automatization is supportive of the kind of real-\ntime analysis that is often referred to as one of the\nunique qualities of DSA (Mayer-Scho\n\u00a8 nberger and\n6 Big Data & Society\nThe possibility of working with real-time data is also\nsomething that is mentioned as a unique advantage of\nDSA across the cases. This temporal characteristic of\ndigital data is especially pertinent in the UN's attempt\nat using tweets to provide early warnings of food-\nrelated crises in developing countries. In fact, project\nleader Robert Kirkpatrick points to the possibility of\nreal-time awareness as the main advantage of DSA\nwhen compared to the method of household surveys:\nWe define real time as basically information that is a\ncurrent enough reflection of reality to be used to\nrespond in ways to alter the outcome [. . .] In a world\nof constant change, adaptation requires real time infor-\nmation [. . .] The entire landscape is dynamic in ways\nthat can be either harmful or helpful. We need to adapt\nto our programming as we go to that moving target.\nKirkpatrick grounds the difference between survey ana-\nlysis and DSA in their abilities to handle fast-paced\ndata. This temporal focus leads to a focus on automa-\ntization because no human being can process large\namounts of data at the same speed as a computer.\nWithout a certain degree of automatization, it would\nnot be possible to create representations of the social\nthat ``adapt to the moving target.'' In short, the shared\ninterest in fast data translates into a shared interest in\nsome degree of automatization and algorithmic data\nprocessing across the cases. Just as scientific visualiza-\ntions are conditioned upon their subjects becoming\nmathematized (Lynch and Woolgar, 1990), it can be\nargued that the pace of digital data requires DSA to\nbe somewhat automatized.\nHowever, all of the project leaders translate this con-\ndition into a need for finding a balance between the\nstrengths of machines and humans. Despite having\ndifferent ways of approaching this balance, they seem\nto agree with Guilhem Fouetillou when he states that\n``it is really difficult to have good results with purely\nautomated approaches'' (L1). They are all on par with\nBowker when he argues that it is the decision whether\nto think of an information problem having a technical\nor social solution that is the decisive infrastructural\nchoice. We have already seen Ana Andjelic hinting at\nthis with her description of her own thinking as an\nassemblage of different social and technical sources.\nThe following quote illustrates that she connects this\nfeature of DSA to a need for striking a balance between\nthe technical and the human: ``If you think about the\nassemblage of technical and human you cannot reduce\nthe humans to one dimension and the technical to\nanother dimension. Its like design \u00ad its how you con-\nnect them'' (D1). John Kelly expresses a similar point\nwhen he argues that ``you try to leverage what humans\nand computers do. I don't think of them as extracting\ndifferent features'' (MA1). In fact, all of the\ninterviewees implicitly refuse an otherwise popular\nidea--namely that automated pattern recognition rep-\nresents ``the end of theory'' (Anderson, 2008). In their\npractical work with web-based data, they all experience\nthe need for human classification at some point in the\nprocess. As we will see below, they disagree on the right\nbalance, but they all subscribe to a classic argument in\nthe sociology of knowledge, namely, that data visual-\nizations are constructed by combinations of automated\nmachines and people using concepts and styles of prac-\nDistribution and automatization as features that\nenable and constrain\nThis leads us to a positive answer to the first research\nquestion. The data environment that DSA operates\nwithin does indeed have characteristic features that\ncreate possibilities and constraints across the cases.\nFirst, it contains data that are structured by a\ndistributed set of actors and thereafter repurposed by\nthe analysts. This feature enables the analyst to liberate\nhim or herself from one specific logic of data produc-\ntion and include a broader set of voices in the\ndepictions of the social. On the other hand, this feature\nalso comes with important constraints in relation to\ntransparency and control over data.\nSecond, the environment of digital data contains\ndata that comes at a pace that requires an integration\nof automated algorithms into the information infra-\nstructure. This feature enables a real-time sensitivity\nthat is widely appropriated across the cases. However,\nit also circumvents a mode of seeing where human intu-\nition can be relied upon to interpret the complete set of\ndata. Much data in DSA will never be encountered by a\nhuman being before it shapes the depiction of the\nsocial. This creates a problem of how to balance tech-\nnical and human aspects of the infrastructure.\nIt is the combination of these features which makes\nDSA a unique method of social analysis that will create\na different mode of seeing than popular methods such\nas field ethnography and survey statistics. Whereas eth-\nnography works in a data environment that contains\nmessy and distributed data, it does not need to delegate\npart of its analytic work to automated algorithms. To\nthe contrary, whereas survey statistics are dependent on\na mathematization of their data subjects, they are\ndeductive in the sense that they control the structures\nof the data when the survey is formulated. It is the\ncombination of the two features that makes the data\nenvironment around DSA distinct. However, the\ndescription of these features is not enough to under-\nstand the affordances of DSA. Both Gibson and\nBowker emphasize the need to look at the capabilities\nof the perceiving agent and the way they interact with\nthese features. This is the topic of the second research\nquestion, to which we will now turn.\nVariations in strategies for interacting\nwith distribution and automatization\nThis section will describe variations in the way the fea-\ntures are dealt with across the cases. The interviews and\ndocuments will be used to construct two ideal-type\napproaches for interacting with these features. These\nideal types represent ends of a continuum that projects\nof DSA can move between. By ideal type it is meant\nthat the approaches are not tied to a single case but\nrather synthesized from related ways of thinking\nabout how to engage with the conditions set by the\nfeatures across the cases. Each project may slide back\nand forth on the continuums depending on the context\nthe project finds itself within.\nApproaches for engaging with distributed data\nFigure 1 depicts a continuum with two opposite\napproaches for engaging with the distribution of data\nstructures. One ideal type is conceptualized structured\nchanneling. It represents a suggestion to give high pri-\nority to deriving structure from communication chan-\nnels that are deemed valid and reliable. The\nidentification of a relevant channel to repurpose data\nfrom is a core methodological act and what counts as a\nrelevant channel naturally varies from project to pro-\nject. However, the approach of structured channeling\nprioritizes channels that have specialized competencies\nin organizing data from specific groups that communi-\ncate about specific issues through specific genres.\nA case that exemplifies this way of engaging with\ndistributed data structures is Alan Porter's choice of\nworking with the database Web of Science (WOS)\nwhen depicting the transdisciplinary scope of research\nprojects. This depiction is part of a project that evalu-\nates whether the U.S. National Science Foundation\nsucceeds in funding research that crosses disciplinary\nand organizational boundaries, and it is shown in\nFigure 2. Porter is partly motivating the choice of rely-\ning on the data structures in WOS through a reference\nto its editorial judgment and robustness:\nOur methods depend on the WOS Subject Categories.\n[The use of subject categories] as the unit of classifica-\ntion means that an article's journal, not its content,\ndetermines its categorization. Assignment of journals\nto SCs is based on a combination of citation patterns\nand editorial judgment at the Institute for Scientific\nInformation (ISI) \u00ad it is not unambiguous [but] quite\nrobust. (STI3)\nThe WOS subject categories are robust because they are\nstructured by scientifically competent people who seg-\nment scientific papers into data chunks such as author\naffiliations, citation scores, publication dates, and jour-\nnal types. Each of these classifications is discrete\nenough to be distinguished from each other by a com-\nputer and they are recognizable in the context in which\nthe project is going to have an impact (STI3; STI4). The\nchoice of relying on WOS categories ensures that the\nprocess of data structuring is distributed to a channel\nthat has a recognized institutionalized expertise in the\nrelevant scientific fields. If a paper is classified as\nbelonging to a specific category in WOS it is because\nan editor with professional judgment has placed it\nthere. This does not ensure that the structures are per-\nfect, but they are argued to be sufficiently stable, well\ndefined, and transparent to risk the loss of control\ninvolved in distributing decisions about them to a\nthird-party actor (STI3; STI4).\nStructured channeling is a solution to the challenges\nof secondhand data that are visible across many of the\ncases. Another project led by Alan Porter, for instance,\nuses the data structures in Thompson Reuters Derwent\nWorld Patent Index as the basis for depicting innov-\nation pathways around emerging technologies (STI2).\nSimilarly, a UN project done by Robert Kirkpatrick's\nlab uses the structure of press releases in Dow Jones'\nbusiness tool, Factiva, as the basis for mapping the\ninfluence of different food security issues (UN4). The\nrationale behind enrolling such recognized databases is\nnicely summarized by the anonymized military intelli-\ngence analyst who states that if one wants to know\nwhat, for instance, the medical profession think about\na specific issue one must first look for ``whatever\nStructured\nchanneling\nDistributed data formats\nAdaptive\nTracking\nFigure 1. Illustration of the feature of data distribution (red\nbox) and the continuum between two ideal-type approaches\n(blue boxes) to engage with this feature when working with\n``digital social analytics.''\n8 Big Data & Society\nchannel there is where medics discuss these things''\n(R1). This quote indicates that medics are the best\nsources of information about the medical profession\nand that an important methodological job is to locate\nspecialized channels where medics communicate. A cen-\ntral assumption behind the approach of ``structured\nchanneling'' is accordingly that the analysts working\nwith DSA should prioritize structured data from chan-\nnels with an institutionalized expertise and a clear and\ntransparent process for segmenting data.\nThe analytic ideal type at the opposite end of the\ncontinuum in Figure 2 is conceptualized as adaptive\ntracking. It differs from structured channeling because\nit is not looking to identify specific channels as provid-\ning the most relevant data structures. It is rather a solu-\ntion to the challenges of distribution that takes the\ndemise of authoritative channels as one of the key bene-\nfits of web-based data. John Kelly exemplifies this when\ndiscussing the blog-links used by Morningside\nAnalytics to identify political clusters:\nA corporation, a newspaper, the federal government, a\ncelebrity, your grandmother, the Sierra Club, and the\npizza place on the corner can all have a blog, or even\njust a regular old website. And they can link to each\nother if they choose. This unification of channel for\ncommunication across all levels of social scale is\ncritical, because the previous segregation has been so\nfoundational to social life in the widest sense [. . .]\nInternet communications technologies are eliminating\nthe channel-segregation that previously reinforced the\nindependence (or mutual deafness) of classes of actors\n[. . .]. (MA2)\nLinks on a blog are here argued to break the need to\nrely on channel-specific data structures such as the ones\nobtained from institutionalized channels like WOS.\nWhereas classifications like journal types and data\nstructures like citations are ordered by field profes-\nsionals, this is not the case with digital traces like the\nlink, the like, and the retweet. Blogs, Facebook, and\nTwitter are not designed for communication between\npeople with predefined expertise that communicate in\nspecialized genres. As put by Ana Andlejic, they are\nrather interfaces that ``function more as a media plat-\nform than as a publisher with editorial control'' (D2).\nThe lack of such control is here posited as a positive\ntrait of digital data. If we return to the project of\ndepicting transdisciplinarity, it would, accordingly, be\na priority for proponents of adaptive tracking to build\ndepictions without having to rely on data structures\nfrom within the discipline of science. Using platforms\nrather than channels would ensure that a research idea\nFigure 2. Visualization depicting the interdisciplinary reach of scientific disciplines in order to evaluate whether the U.S. National\nScience Foundation is succeeding in funding research that crosses disciplinary boundaries.\nwould not necessarily have to come in the form of a\npaper made by an identifiable author and its relevance\nwould not have to be judged on the basis of institution-\nally validated formats such as a citation.\nRobert Kirkpartick's emphasis on the need for the\nUN to adapt methods to hit moving targets is also con-\nnected to this way of thinking (UN1) \u00ad the reason being\nthat institutionalized channels are not very agile data\nsources. One of Kirkpatrick's projects is the construc-\ntion of the crisis monitor depicted in Figure 3. This\nmonitor is built to give early warnings of food-related\ncrises in Indonesia and the USA on the basis of tweets,\nwhich is a type of data that has quite specific character-\nistics. It has a maximum of 140 characters, it can be left\non mobile phones, and it is captured through Twitter's\napplication programme interface (API) where it is\naccompanied by a set of metadata in JSON language.\nThis combination means that it provides a quicker and a\nmore heterogeneous set of data than institutionalized\nchannels such as the survey team in the UN.\nThe monitor contains three visualizations. To the\nleft we see the words most frequently tweeted, in the\nmiddle we see the semiautomated networks that indi-\ncate how these words cooccur with predefined key\nwords, and to the right we see a ``topic wheel'' that\nuses automated color codes to indicate the severeness\nof specific issues (UN2). These visual elements exem-\nplify Kirkpatrick's ambition to ground DSA in real-\ntime data. He prioritizes data that are structured in\nsuch a way that they can be used in everyday commu-\nnication. This pace is ensured by lowering requirements\non the stability, reliability, and validity of data. For\ninstance, tweets may change its number of characters\nand the API may change the metadata it makes avail-\nable. Despite these shortcomings, Twitter is still the\nfavored data source in Kirkpatrick's crisis monitor as\nwell as in projects led by Ana Andjelic, Chris Pallaris,\nand Guilhem Fouetillou. This choice reflects the idea\nthat DSA must be based on a data foundation that is as\nchanging and unreliable as the platforms that people\nuse. Or, as put by Ana Andlejic when discussing noise\nin data: ``Complexity in the environment of tools\nshould be aligned with complexity in human behavior.\nYou do not need to simplify'' (D1).\nThe approaches of structured channeling and adap-\ntive tracking represent opposite ways of engaging with\nthe feature of distribution. As two ends of an analytic\ncontinuum they pinpoint a central trade-off that con-\ncerns the need to balance an interest in transparent,\nstructured, and trustworthy data with an interest in\ndata structures that are adaptive and agile. With the\nwords of Bowker, this trade-off also implies a decision\non how an infrastructural solution is distributed\nbetween social and technical elements. In the approach\nof structured channeling, the solution is to a large\nextent distributed to a professional that ensures the\ntransparency and topical relevance of the data. To the\ncontrary, in adaptive tracking the solution is more\nbroadly distributed. The data structures that shape\nthe analysis are provided by a platform on which\nboth a crowd of humans and technical gatekeepers\nplay a role.\nApproaches for engaging with automatization\nFigure 4 depicts a continuum with two opposite\napproaches for handling the need to balance the role\nof humans and machines when automating data ana-\nlysis. One ideal type is conceptualized as following\nbecause it suggests to leverage the power of algorithms\nFigure 3. Visualization depicting meaning structures around the topic of food in order to detect negative emotions and early signals\nof crisis.\n10 Big Data & Society\nto recognize surprising patterns in data without being\ndistracted by cultural preconceptions. Despite being\n``blind'' in their processing of data, the approach rests\non the assumption that algorithms can guide analysts to\ninnovative analytic concepts and categorizations. This\nway of thinking, for instance, underpins John Kelly's\nproject of visualizing political clusters in the blogo-\nsphere. Figure 5 shows an example of his work with\nso-called attention clusters in the Arabic blogosphere.\nThe nodes represent blogs, their size is based on in-\nlinks, their position is based on nearness to their neigh-\nbors, and their color is based on their history of links to\nother sources.\nKelly explicates the following approach when he\nexplains how his way of visualizing political commu-\nnities is different from his competitors:\nSome people would go in and color the nodes on the\nbasis of some pre-existing typology. They got the\ncategories that they think are relevant in their minds\nand they go in and they assign everything to a category.\nI sort of wanted the data to tell me what kind of cate-\ngories that were in it. I did not want to go in with\npresuppostitions [. . .]. (MA1)\nFigure 5. Visualization depicting ``attention clusters'' in the Arabic blogosphere in order to understand the influence of blogs on\npolitical discourse.\nFollowing\nTraining\nThe necessity for\nautomatization\nFigure 4. Illustration of the condition of automatization\n(red box) and the continuum between two ideal-type approaches\n(blue boxes) to handle this condition in the process of technical\ncommensuration.\nThis is why Kelly colors the nodes on the basis of\ncomputer-detected similarities in link history rather\nthan preestablished distinctions between, for instance,\nliberal and conservative bloggers. For instance, the\nyellow nodes represent a group of bloggers that are con-\nnected for other reasons than linguistics, nationality, or\npolitical observation. The choice of following the way\nthe algorithm colors on the basis of a long history of\nlinking is what enables this subset of the blogosphere\nto be visible. This mode of seeing political communities\nis enabling different interpretations of the political dis-\ncussions about the Middle East than a map based on\nexpert categories. Automatization is used to avoid the\ndrawbacks involved in relying too heavily on a priori\nhuman intuition. This is a kind of use that is also pro-\nmoted by Guilhem Fouetillou in his mapping of prod-\nucts (L1). Similarly, Ana Andjelic supports this inductive\nform of analysis because it enables analysts to see ``[. . .]\nsomething that [they] have previously missed'' (D2).\nThe analytic ideal type at the opposite end of the\ncontinuum is conceptualized as training because it\nbuilds on the idea that ``it is imperative that the analyst\n`train the algorithm' (UN2). It is an alternative to fol-\nlowing because it suggests guiding the automated algo-\nrithm to reflect categories that are recognizable in the\ncontext in which they are going to have an impact. The\ntag clouds in the monitor in Figure 4 reflect this\napproach. They are built by training algorithms to\ndetect predefined emotional cues around predefined\ncrisis categories such as ``food.'' Tweets that fitted the\nintuition of the analysts about what belongs to these\ncues and categories were used to train the algorithms.\nThe goal was to ensure that the visualization was\n``aligned with project objectives'' (UN2). The approach\nof training is, in that sense, a way of emphasizing the\nimportance of having a human decision that points the\n``[. . .] processing capacity at particular problems'' (I1).\nThe approaches of following and training represent\ntwo opposite ways of engaging with the need for\nautomatization. They pinpoint a central trade-off\nbetween the need for DSA to reflect distinctions that\nresonate with the world and the need to challenge dom-\ninating distinctions on the basis of emergent categories.\nBoth approaches are conditioned upon the need to\nenroll algorithms in the organization of information\nbut the way they preprogram these algorithms is quite\ndifferent. The approach of training uses expert guid-\nance to program software on the basis of predefined\nsemantic classifications that are relevant for the social\ndynamics analyzed. This is different in the approach of\nfollowing where the preprogrammed elements are\ngrounded in theories about the mathematical properties\nof the social world.\nThe continuum between following and training is\nalso providing insights into variations in the way\ninfrastructural solutions can be distributed between\ntechnical and social elements in DSA projects. For\ninstance, training semantic software to look for the\noccurrence of specific words that an expert has sug-\ngested is prioritizing a social solution. To the contrary,\nfollowing the algorithm and letting it guide you to\nwords that occur next to each other is prioritizing a\ntechnical solution. All of the cases slide somewhere\nbetween the extremes of the continuum in Figure 4.\nA good example is Alan Porter's depiction of transdis-\nciplinarity in Figure 3, which is a hybrid between an\ninitial expert categorization in WOS and an algorithm\nrunning an inductive analysis to identify the clusters\n(STI3; STI4). This mode of coloring exemplifies the\nneed for striking a balance between machine intelli-\ngence and human categorization. A balance that\nBowker (2014) has recently argued to be central in\nthe context of Big Data.\nDSA: A method in a relational\naffordance space\nThe analysis so far has shown that the data environ-\nment surrounding DSA has specific features that set\ncertain conditions for the production of social insights.\nIt has also shown that these conditions are engaged\nwithin different ways across the projects. Following\nGibson, we can say that the affordances of DSA are\nshaped by reciprocal movements in this perceiver\u00ad\nenvironment system. Put differently, each project work-\ning with DSA will find itself in a situation where the\nfeatures of the environment and the capabilities of the\nproject leader need to be aligned. In line with Bowker,\nthe analysis has shown how this alignment will be an\noutcome of a negation about the degree to which solu-\ntions should be distributed to technical or social actors.\nThe solution to this negotiation will ultimately place\nDSA projects at a certain position in the two-dimen-\nsional space in Figure 6, which integrates the con-\ntinuums in Figures 1 and 4.\nFigure 6 can be interpreted as depicting a flexible\naffordance space within which any DSA project can\nalign the features of the environment with the capabil-\nities of the analyst. Following Gibson, it can be argued\nthat these capabilities will ultimately be shaped by the\nsituation and context in which a given project is carried\nout. The position of a project on the affordance space is\ntherefore influenced by the situation the project leader\nfinds him or herself within. This point becomes clear\nwhen looking at the reasons for positioning UN's\nTwitter-based crisis monitor in top center in the affor-\ndance space above.\nFirst, the project is located in the top of the coord-\ninate system because it prioritizes the adaptiveness of\ndigital data over their transparency. However, it is\n12 Big Data & Society\nimportant this prioritization of an agile infrastructure\nfits the strategic mission of the Secretary-General, who\nlaunched the Global Pulse Lab by stating that the\nworld is increasingly ``volatile and interconnected\n[because] the impacts of [a] crisis [are] flowing across\nborders at unprecedented velocity'' (UN5). This argu-\nment entails that tools like surveys and census data are\ntoo slow to detect signals of emerging crises in due time\nto react upon them. An example of such a signal is a\nmother who takes her kid out of school. Within the UN\nthis is considered to be an ``early signal'' of economic\nproblems and one argument for experimenting with\nDSA is that this mother will communicate about her\nchoice through a traceable media device a long time\nbefore a traditional survey can capture it (UN1). It is\nsuch possibilities that make the Secretary-General con-\nclude that ``traditional 20th century tools for tracking\n[. . .] development simply cannot keep up'' (UN5).\nWhen the features of the digital data environment\nand the capabilities of an analyst in a specific context\ninfluence each other we have what Gibson would refer\nto as a reciprocal movement in the perceiver\u00adenviron-\nment system. In the case of Global Pulse, this move-\nment makes a specific DSA solution possible. For\ninstance, it is feasible for Kirkpatrick to distribute the\nsolution to the challenges of distribution toward the\nTwitter infrastructure. The organizational discourse\naround the Global Pulse is favorable for prioritizing\nspeed over transparency and control. However, the\nproject is at the same time positioned in the middle of\nthe horizontal axis because there is a need to ensure\nthat the final visualizations are recognizable across dif-\nferent branches of the UN. Bureaucratic organizations\nneed data that are recognizable across organizational\nsilos and this is hard to ensure if one is distributing the\nsolution of classification challenges to an automated\nalgorithm. Training ensures recognizability! Or, as\nRobert Kirkpatrick puts it: ``[. . .] It is not just about\ngetting the data; it is also [. . .] about the organizational\ncapacity to facture a snapshot of these types of infor-\nmation in the context of their on-going policy develop-\nment planning'' (UN1).\nThese movements in the perceiver\u00adenvironment\nsystem determine the kind of affordances DSA has\nfor Kirkpatrick. This also indicates why the affordances\nof DSA should not be understood as an attribute of\ndigital technologies. Affordances is not a verb--it is a\nnoun. It is a relational entity emerging in an interplay\nbetween environmental features and capabilities for\nseeing that are tied to a specific problem in a specific\ncontext. Similar conclusions can be drawn from a look\ninto the two other projects positioned in Figure 6. Alan\nPorter's visualization of the transdisciplinarity of scien-\ntific disciplined is produced as an input to an official\ngovernmental funding program. In order to fulfill such\na role, it needs to be perceived as valid across different\nFigure 6. Two-dimensional space within which projects of ``digital social analytics'' can locate themselves.\nstakeholders. The pace of the visualizations is less\nimportant. This leads to a specific alignment between\nfeatures and capabilities when it comes to handling the\ndistributed character of digital data. The solution is\ndistributed to professional social actors because trans-\nparency in the data is of higher priority than speed.\nFinally, John Kelly's project on the structures of polit-\nical communities was funded by research money and\nwas carried out in a private consultancy company.\nThis context gives Kelly the capability to experiment\nwith technical solutions to the challenges of both dis-\ntribution and automatization. All these ways of settling\nmovements in the perceiver\u00adenvironment system will\nlead to distinct affordances and thereby also of different\nsocial implications of the use of DSA in response to\nparticular problems.\nConclusion\nWith a departure in Gibson's concept of affordances\nand Bowker's concept of information infrastructures,\nthis paper has analyzed eight projects that are using\nDSA to depict and understand a diverse set of social\ndynamics. Through interviews and document analyses,\nthe paper initially identified two features of the digital\ndata environment that set specific conditions for know-\nledge production across the projects. One was the need\nto distribute the work of structuring data to third-party\nactors and the other was the need to find a proper level\nof trust in automated techniques when dealing with fast\npaced data.\nThe second part of the analysis identified ideal-type\napproaches for engaging with these features across the\ncases. First, it was shown that the distribution of data\ncan be handled either by prioritizing structured channel-\ning of institutionalized data from transparent sources or\nby prioritizing adaptive tracking of data formats from\nplatforms that integrate many actors and that are agile\nenough to change the rules for data generation when\nthe world changes. Second, it was shown that the need\nfor automatization can be handled in two ways. The\nfirst is to prioritize an inductive empirical strategy\nwhere one is following algorithmic pattern detection.\nThe second is to prioritize a training of the algorithm\nthat make it return categories that resonate with\nalready existing beliefs.\nThese ideal-type approaches were finally combined\ninto a two-dimensional space where DSA projects can\nbe positioned according to the way they interact with\nthe features of the data environment. It was suggested\nto think of this space as a flexible affordance space\nbecause the affordances of DSA can only be under-\nstood through a theoretical focus on the interplay\nbetween features of the digital data environment and\nthe analyst's capabilities for working with specific\nmodes of seeing in the situation and context he or she\nworks within. This interplay can, with the words of\nGibson, be seen as movements in the perceiver\u00adenvir-\nonment system and it was argued that the affordances\nof DSA will be determined by the way the different\nsociotechnical actors in such movements can be aligned\nin a specific situation.\nDocuments used as empirical data to\nsupplement the interviews\nAvailable at: http://anaandjelic.typepad.com/ (accessed\nEtling B, Kelly J, Faris R, et al. (2009) Mapping\nthe Arabic blogosphere: Politics, culture, and dissent.\nHarvard University, USA: Berkman Center Research\nPublication. Available at: http://cyber.law.harvard.\nedu/publications/2009/Mapping_the_Arabic_\nissues--Monitoring world food security. Available at:\nhttp://www.unglobalpulse.org/projects/news-awareness-and-\nemergent-information-monitoring-system-food-security\nGlobal Pulse (2011) Twitter and perceptions of crisis\nrelated stress. Available at: http://www.unglobalpulse.\norg/projects/twitter-and-perceptions-crisis-related-\nGlobal Pulse (2011) Using social media and online\nconversations to add depth to unemployment statistics.\nAvailable at: http://www.unglobalpulse.org/projects/\ncan-social-media-mining-add-depth-unemployment-\nKelly J (2008) Pride of place: Mainstream media and\nthe networked public sphere. Harvard University, USA:\nBerkman Center Research Publication. Available at:\nhttp://cyber.law.harvard.edu/sites/cyber.law.harvard.\nKelly J and Bruce E (2008) Mapping Iran's online\npublic: Politics and culture in the Persian\nblogosphere. Berkman Center Research Publication.\nAvailable at: http://cyber.law.harvard.edu/publica-\ntions/2008/Mapping_Irans_Online_Public/ (accessed\nKi-Moon B (2011) Secretary-General's remarks at\nGeneral Assembly Briefing on the Global Pulse\nInitiative. Available at: http://www.un.org/sg/\nPallaris C (2009) OSINT as knowledge, activity and\norganization--Trends, challenges and recommenda-\ntions. Available at: http://www.eurosint.eu/system/\nfiles/docs/osint-knowledge-activity-organization.pdf\n14 Big Data & Society\nPallaris C (2012) The four architectures of competi-\ntive intelligence. In: Presentation at 360 Degree Indian\nInstitute of Technology, 1\u00ad16.\nPorter A and Garner J (2011) Assessing the human\nand social dynamics program exceptional cross-discipli-\nnarity. In: Paper presented at Atlanta Conference on\nScience and Innovation Policy, Atlanta, 1\u00ad9\nPorter A and Stephen C (2011) A forward diversity\nPorter A., et al. (forthcoming) Forecasting innov-\nation pathways: The case of nano-enhanced solar\ncells. In: Technological forecasting and social change.\nElsevier.\nDeclaration of conflicting interest\nThe author declares that there is no conflict of interest.\nFunding\nThis research received no specific grant from any funding\nagency in the public, commercial, or not-for-profit sectors.\nReferences\nAdkins L and Lury C (2009) Introduction: What is the empir-\nAgresti A and Finlay B (1997) Statistical Methods for the\nSocial Sciences. Essex, UK: Pearson.\nAnderson C (2008) The end of theory: The data deluge makes\nthe scientific method obsolete. Wired Magazine, July 16.\nBoland RJ Jr and O'Leary T (1991) Technologies of inscrib-\ning and organizing: Emerging research agendas.\nAccounting, Management and Information Technologies 1:\nBowker G (2014) Big data, big questions--The theory/data\nBowker G, Baker K, Millerand F, et al. (2010) Toward infor-\nmation infrastructure studies: Ways of knowing in a net-\nworked environment. In: Husinger J (ed.) International\nHandbook of Internet Research. Essex, UK: Springer,\nBowker G and Star SL (1999) Sorting Things Out.\nClassification and Its Consequences. Cambridge, MA:\nMIT Press.\nBraund MJ (2008) The structures of perception: An ecological\nBrin S and Larry P (1998) The anatomy of a large-scale\nhypertextual Web search engine. Computer Networks and\nBurri R and Dumit J (2007) Social studies of scientific ima-\nging and visualization. In: Hackett E, et al. (eds) The\nHandbook of Science and Technology Studies, 3rd ed.\nEspeland WN and Sauder M (2007) Rankings and reactivity:\nHow public measures recreate social worlds1. American\nFlyvbjerg B (2004) Five misunderstandings about case-study\nGane N (2011) Measure, value and the current crises of soci-\nGibson JJ (1986) The Ecological Approach to Visual\nPerception. Hillsdale, NJ: Psychology Press.\nGitelman L (ed.) (2013) Raw Data Is an Oxymoron.\nCambridge, MA: MIT Press.\nGlynn C, Herbst S, O'Keefe G, et al. (2004) Public Opinion,\n2nd ed. Colorado, USA: Westview Press.\nHutchby I (2001) Technologies, texts and affordances.\nLatour B (1990) Visualisation and cognition: Thinking with\neyes and hands. In: Lynch M and Woolgar S (eds)\nRepresentation in Scientific Practice. Cambridge, MA:\nMIT Press.\nLazer D, Kennedy R, King G, et al. (2014) The parable of\nGoogle Flu: Traps in big data analysis. Science 343:\nLynch M and Steve W (1990) Representation in Scientific\nPractice. Cambridge, MA: MIT Press.\nMcKinsey Global Institute (2011) Big data: The next frontier\nfor innovation, competition, and productivity.\nAvailable at: http://www.mckinsey.com/insights/mgi/\nresearch/technology_and_innovation/big_data_the_next_\nMarres N (2012) The redistribution of methods: On interven-\ntion in digital social research, broadly conceived. The\nMayer-Scho\n\u00a8 nberger V and Cukier K (2013) Big Data \u00ad A\nRevolution That Will Transform How We Live, Think and\nWork. London, UK: John Murray Publishers.\nMorgan DL (1996) Focus groups. Annual Review of Sociology\nPalys T (2008) Purposive sampling. In: Given L (ed.) The\nSage Encyclopedia of Qualitative Research Methods. vol.\nRuppert E (2011) Population objects: Interpassive subjects.\nSavage M and Burrows R (2009) Some further reflections on\nthe coming crisis of empirical sociology. Sociology 43:\nScott JC (1998) Seeing Like a State: How Certain Schemes to\nImprove the Human Condition Have Failed. Binghamton,\nNY: Yale University Press.\nShaw M (2013) What kinds of data are there in Big Data?,\nt5/Discover-Performance-Blog/What-kinds-of-data-are-\nUN Global Pulse (2011, December) Twitter and perceptions of\ncrisis related stress: Methodological white paper.\nWorld Economic Forum (2012) Big Data, big impact: New\npossibilities for international development. Available at:\nhttp://www3.weforum.org/docs/WEF_TC_MFS_\nBigDataBigImpact_Briefing_2012.pdf (accessed 1 August"
}