{
    "abstract": "Abstract\nSafe movement through the environment requires us to monitor our surroundings for moving\nobjects or people. However, identification of moving objects in the scene is complicated by self-\nmovement, which adds motion across the retina. To identify world-relative object movement, the\nbrain thus has to `compensate for' or `parse out' the components of retinal motion that are due to\nself-movement. We have previously demonstrated that retinal cues arising from central vision\ncontribute to solving this problem. Here, we investigate the contribution of peripheral vision,\ncommonly thought to provide strong cues to self-movement. Stationary participants viewed a\nlarge field of view display, with radial flow patterns presented in the periphery, and judged the\ntrajectory of a centrally presented probe. Across two experiments, we demonstrate and quantify\nthe contribution of peripheral optic flow to flow parsing during forward and backward movement.\n",
    "reduced_content": "Article\nPeripheral Visual Cues\nContribute to the Perception\nof Object Movement During\nSelf-Movement\nCassandra Rogers and Simon K. Rushton\nSchool of Psychology, Cardiff University, Cardiff, UK\nPaul A. Warren\nDivision of Neuroscience and Experimental Psychology, School\nof Biological Sciences, Faculty of Biology, Medicine and Health,\nUniversity of Manchester, Manchester Academic Health Science Centre,\nManchester, UK\n Keywords\nflow-parsing, flow-parsing, optic flow, peripheral vision, scene perception, motion, self-movement,\nobject movement\nIntroduction\nThe ability to detect and estimate the movement of objects in the surrounding environment is\nvital. Without this ability, dangerous activities such as crossing the road would be very\ndifficult. For a stationary observer, the visual detection of a moving object in an otherwise\nstationary scene is straightforward; moving objects in the world are indicated by motion in\nthe image that is formed on the retina (retinal motion; Figure 1(a)). However, during self-\nCorresponding author:\nSimon K. Rushton, School of Psychology, Cardiff University, Tower Building, 70 Park Place, Cardiff CF10 3AT, UK.\nEmail: rushtonsk@cardiff.ac.uk\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License\n(http://www.creativecommons.org/licenses/by/4.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sage-\npub.com/en-us/nam/open-access-at-sage).\ni-Perception\njournals.sagepub.com/home/ipe\nmovement, this task becomes more complex; objects that are stationary in the scene can be\nmoving within the retinal image (Figure 1(b)) and the physical trajectories of objects that are\nmoving in the scene are obscured (Figure 1(c)). Thus, during self-movement, the brain must\ndecompose a complex pattern of retinal motion (Figure 1(c), insert) to separate components\nof retinal motion that are due to objects moving in the scene from components of retinal\nmotion due to self-movement.\nA general class of compensation solutions for this problem rests upon the brain generating\na prediction of the sensory signals that should be expected from self-movement and then\ncomparing this prediction to the actual incoming sensory data (von Holst & Mittlestadt,\n1954). In practice, this process can be thought of as subtracting the predicted from the\nexperienced sensory consequences of the movement. Given an accurate prediction, any\nremaining signal after the subtraction must then be due to the motion of other objects in\nthe scene.\nTo be able to generate a prediction of expected sensory input, it is clear that information\nabout current self-movement is required. This could come from either retinal (visual) or\nextra-retinal (non-visual) sources or a combination of both. Early investigations of this\nproblem focused on extra-retinal information about self-movement (von Holst &\nabout self-movement plays an important role in judgements of object movement. More recent\nwork by Wexler (van Boxtel, Wexler, & Droulez, 2003; Wexler, Lamouret, & Droulez, 2001;\nMacNeilage, Zhang, DeAngelis, & Angelaki, 2012) and Glennerster (Tcheang, Gilson, &\nGlennerster, 2005) has extended our understanding of these extra-retinal processes.\nFigure 1. Retinal motion associated with stationary objects (dark grey) and a moving object (light grey) in\nthe scene, whilst stationary (a) or during rightward self-movement (b and c). (Adapted from Warren,\n2 i-Perception\nOver the last decade, research has begun to focus on how retinal information might also be\nused to enable compensation for the consequences of self-movement (Calabro, Soto-Faraco\nobserver moves, a characteristic, global, structured pattern of retinal motion arises which\ncontains information about self-movement (Gibson, 1950). It should be possible to use such\ninformation to underpin a compensation solution.\nThe flow parsing hypothesis (Rushton & Warren, 2005) suggests that the brain uses\nincoming retinal motion to generate a direct prediction of current self-movement and then\ndoes something akin to a global subtraction (or filtering) of the (predicted) optic flow across\nthe visual field. Considerable data have now been provided which is compatible with the use\nof such a visually based process (Rushton & Warren 2005; Rushton et al., 2007; Warren &\nRoyden & Holloway, 2014). For example, Warren and Rushton (2009) show that when the\nleft hemifield of an expanding radial optic flow stimulus is presented together with a probe\nobject in the right hemifield, the perceived probe trajectory is biased. The direction of the bias\nis consistent with subtraction of the (absent) right hemifield of optic flow. Furthermore, the\nbias increases in size as the probe moves further into the empty hemifield--a difficult result to\nexplain with an alternative account given that it suggests more interaction between two\nstimuli as they move further apart. However, this surprising result is predicted by flow\nparsing; motion in a radial flow field generally increases in magnitude with eccentricity,\nmeaning the component to be subtracted (and hence the effect on the probe) should also\nincrease with eccentricity. Recent work has also focused on developing models of the neural\nprocesses underlying flow parsing (e.g., Layton & Fajen, 2016; Royden & Holloway 2014;\nWork on flow parsing to date has presented optic flow stimuli in central vision. However,\nperipheral vision is also known to make powerful contributions to both the perception of self-\nmovement (Brandt, Dichgans, and Koenig, 1973; Berthoz, Pavard, & Young, 1975; Habak,\nCasanova, & Faubert, 2002; Lepecq, Jouen, & Dubon, 1993) and its control (Lee & Aronson,\nFurthermore, peripheral flow has a potential role in resolving some of the ambiguities in\nvisual information present in central vision. For example, assuming noise in the coding of\nmotion signals, the retinal flow associated with lateral translation is similar to that generated\nduring a horizontal gaze rotation. There is no similar ambiguity with peripheral flow because\ngaze rotation and lateral translation generate quite different patterns of retinal motion.\nLateral translation produces a radial flow pattern on either side of the observer, a\ncontracting field on one side and an expanding field on the other, whereas gaze rotation\nproduces laminar flow on both sides. Here, we assess the contribution of peripheral visual\ninformation to flow parsing during simulated forward and backward movement. Although\nforward movement is likely to be more common in everyday activity, we also included a\nbackward self-movement condition for comparison.\nSeveral different definitions of what constitutes peripheral vision and what constitutes\ncentral vision have been used previously. For example, Osaka (1994, as cited in Berencsi,\nIshihara, & Imanaka, 2005) assessed the distribution of cones and rods across the retina and\nRogers et al. 3\ndefined the central 2 to 4 of vision as `central' with everything beyond classed as peripheral\nvision. Trevarthen (1968) classified peripheral vision as beyond the central 4 to 5 of vision.\nHowever, the majority of experimental studies consider central vision to cover a much larger\nportion of the retina, typically extending up to 15 from fixation (a 30 region in the centre of\nof our research, we used the latter definition and defined central vision as up to 15 from\nfixation.\nOverview of Experiments\nIn two experiments, we assessed the impact of optic flow presented in the periphery on the\nperceived trajectory of a target probe in central vision. In Experiment 1, we manipulated the\neccentricity of the peripheral visual flow and found evidence for an effect on target trajectory\n(and hence a peripheral contribution to flow parsing) for flow stimuli up to 41 from fixation.\nThe contribution of peripheral vision to flow parsing was found to decrease approximately\nlinearly as a function of retinal eccentricity. In Experiment 2, we examined how information\nfrom different locations across the peripheral retina is combined. Our data suggest that the\ninformation from the most central part of the peripheral retina makes the primary\ncontribution to the combined effect.\nExperiment 1\nFlow parsing involves the subtraction of global components of motion. If a global\ncomponent of motion is subtracted then every object in the visual field should be affected.\nTo recap, Warren and Rushton (2009) looked for evidence of the subtraction process by\nprobing empty locations within the visual stimulus. In a key condition, they placed the probe\ndot opposite a hemifield of radial flow that had a focus of expansion at the point of fixation.\nThey found that the perceived trajectory of the probe dot was influenced by the presence of\nthe flow (and the change showed a dependence on the position of the relative to the focus of\nexpansion). The difference between physical and perceived trajectory was consistent with a\nglobal flow subtraction process.\nWarren and Rushton (2009) demonstrated the contribution of central vision to the parsing\nprocess. Here, we created a variant of Warren and Rushton (2009) to investigate if peripheral\nvision contributes, and if so, which parts of the periphery contribute. Expanding or\ncontracting radial flow was presented at different eccentricities whilst a horizontally\nmoving target appeared either above or below a central fixation point, as depicted in\nIf peripheral vision contributes to the flow parsing process, then the perceived trajectory of\nthe target dot will be biased inwards in the presence of expanding radial flow (see Figure 2) or\noutwards in the case of contracting radial flow. By varying the eccentricity of the radial flow,\nwe can assess the extent to which the effects of peripheral flow persist.\nAll targets moved across the screen from left to right, perceived trajectories are expressed\nin terms of a positive or a negative trajectory bias, where positive is anticlockwise (ACW; i.e.,\nFigure 2(c), the target below fixation shows an ACW bias which would be coded as a positive\nrelative tilt, and the target above fixation shows a clockwise [CW] bias, coded as a negative\nrelative tilt). We summarise the results using the difference in relative tilt between the two\ntarget positions (see Supplementary Materials for detailed results at each flow eccentricity).\nWe will look for evidence of a change in the relative tilt difference as a function of flow\neccentricity. To do this, we conducted a two-factor ANOVA for each eccentricity condition\n4 i-Perception\nwith direction of radial flow (forwards or backwards) and target position (above or below) as\nfactors. A significant contribution at each eccentricity would be indicated by a statistical\ninteraction between target position and the direction of radial motion.\nMethods\nParticipants. Six postgraduate students (1 male) with an age range of 22 to 26 took part in the\nstudy and were nai\u00a8ve as to the experimental hypotheses. Participants were recruited from the\nSchool of Psychology, Cardiff University, and had normal or corrected-to-normal vision.\nWhere vision was corrected, participants were asked to wear contact lenses. This additional\nrestriction was put in place because the frames of a participant's glasses might have obscured\n(at least partially) the peripheral stimuli used in the experiments.\nAll recruitment and experimental procedures reported herein adhered to the Declaration\nof Helsinki and were approved by the Ethics Committee of the School of Psychology, Cardiff\nUniversity.\nApparatus. Computer-generated visual stimuli were presented on a large nonpolarising back\nprojection screen using a ChristieT Digital Systems Projector (model DS\u00fe26). The spatial\nsize was 127 cm \u00c2 96 cm. When viewed at a distance of 40 cm, the projection area subtended\nAll experiments were coded in Pascal and OpenGL using Lazarus (an open source IDE),\nSDL v1.2 (https://www.libsdl.org) and the JEDI-SDL libraries (http://www.delphi-jedi.org).\nStimuli were rendered on a computer running Windows XP with a NVIDIA Quadro NVS\n420 Graphics card with four DVI outputs (driving two projectors and two peripheral\nmonitors). All stimuli were drawn in red and presented on a black background unless\nFigure 2. Schematic illustration of flow parsing with peripheral motion. Expanding flow condition depicted.\n(a) The retinal motion associated with forward self-movement, both possible target locations are indicated.\nThe target moves across the screen left to right in a horizontal path. (b) Once a (radial) pattern of optic flow\nhas been identified, a global subtraction process subtracts an expanding radial component of motion across\nthe whole visual field (equivalent to adding a contracting radial component as illustrated here). (c) The\nperceived target trajectory once self-movement components have been parsed from retinal motion. The\nperceived target trajectory is biased inwards in this example and it would be biased outwards with\ncontracting flow.\nRogers et al. 5\notherwise stated. A red filter was placed in front of the projector to improve the contrast of\nthe display. Anti-aliasing was set to 2 \u00c2 multisample antialiasing in order to ensure smooth\nmotion of the stimuli at such a close viewing distance. For trajectory judgements, participants\nused a physical `jog-wheel' (a rotating dial) to orient an on-screen response line to match the\ntrajectory they perceived.\nStimuli. Radial flow was presented on the projection screen and simulated forward or\nbackward translation. The flow stimulus consisted of 3,500 red limited lifetime dots\n(1 second lifetime, 0.6 diameter). Dot motion was appropriate for an observer translating\neither forward or backward at a rate of 30 cm/s (a slow walking pace) through a volume of\noffscreen or had been present for more than 1 s, it was redrawn at a new on-screen location at\nthe end of the volume, ahead of the observer. Dots were presented in an annulus (peripheral\nband). Dot lifetime was staggered so that dots disappeared and reappeared asynchronously.\nApproximately 600 dots were visible at any one time.\nwidth (w, see Figure 3(b)) was 14 at a radius of 23. The annulus width increased with\nannulus radius, it was M-scaled for eccentricity using the method described by Rousselet,\nHusk, Bennett, and Sekuler (2005; see Supplementary Materials).\nA central fixation dot was presented at the centre of the flow stimulus together with a small\n(0.3) circular red target probe placed either above or below fixation at 4 eccentricity. Target\nmotion was predominantly horizontal and rightwards (although see below) at 0.6/s. All\ntargets appeared to the left hand side of the midline and translated rightward along the\nspecified trajectory. The target passed through the vertical midline of the screen half way\nalong its travelled path.\nDesign. Three independent variables were manipulated: the direction of simulated self-\nmovement (2 levels: expanding or contracting flow), the position of the target (2 levels:\n\u00c04/\u00fe4 from fixation) and the eccentricity of the peripheral flow (measured by the inner\nTo avoid potential response biases, rather than repeatedly presenting the same trajectory,\nthe target had a fixed initial position and the trajectory varied within a range above and\nbelow horizontal. This manipulation prevented the observer from knowing whether perceived\nupwards motion was physical or due to flow parsing on any given trial. In each condition,\nthere were nine physical target trajectories (spanning the range \u00c6 32 from horizontal in 8\nsteps), resulting in a total of 180 trials (2 \u00c2 2 \u00c2 5 \u00c2 9), which were all completed in a single\nexperimental session of approximately 45 min. The order of the trials was randomised and all\neccentricity conditions were interleaved.\nThe dependent variable was relative tilt, which was calculated as the difference between the\non-screen trajectory and perceived trajectory reported by the observer. A within-subjects\ndesign was used and data collection for each participant was completed in a single\nexperimental session.\nProcedure. Observers were seated on a static height-adjustable chair, in a dark room with their\neyes level with the fixation point and approximately 40 cm viewing distance from the centre of\nthe projection screen. It was not feasible to provide participants with a chin rest at this\nviewing distance but participants (who had all taken part in previous psychophysical\nexperiments) were instructed to keep as still as possible during the experiment.\n6 i-Perception\nThe timeline of each trial, depicted in Figure 4, was as follows: A fixation dot was\npresented. Participants maintained fixation on the central dot throughout each trial. After\n0.75 s, peripheral flow appeared which simulated forward or backward translation at a speed\nof 30 cm/s. Following a variable 1 to 1.2 s delay, the target was presented above or below\nfixation and moved at constant speed of 0.6/s (1 cm/s) for a 2-s duration. Immediately after\nthe probe disappeared, a short 2D response line ($3 in length) which rotated about the point\nat which the target initially appeared was presented with a randomised initial line orientation\non each trial. Participants rotated the line using a rotating dial or `jog-wheel' in order to\nindicate the perceived trajectory of the target. Participants were told that if they did not\nperceive the target to move along a straight path, then they should set the response line to\nmatch the mean linear trajectory of the target. Once the participant had set the on-screen line,\nthey clicked a button on the jog-wheel to move on to the next trial. By delaying their click,\nobservers could opt to take a break before continuing. Four enforced breaks of 15 s duration\nwere imposed at regular intervals during the experiment.\nFigure 3. (a) Plan view of display devices for peripheral stimuli for Experiments 1 and 2. In Experiment 1,\nonly the projection screen was used and the observer was seated, with a viewing distance of 40 cm. In\nExperiment 2, both the projection screen and the side screens were used and the viewing distance was 95 cm.\nThe observer is seated with head in chinrest (green diamond) looking straight ahead. In Experiment 2, the\nNear peripheral stimulus (expanding or contracting radial flow) was presented on the projection screen and\nthe Far peripheral stimulus (moving bars) was presented on peripheral monitors, each positioned with the\nnearest edge 45 from the (dashed) line of sight. (b) Schematic diagrams of stimuli used in experiments.\nExperiment 1 and Experiment S1 (control, see Supplementary Materials) used only the central projection\nscreen to present flow, while Experiment 2 used the central projection screen and two peripheral monitors\nto present flow stimuli. Experiment 1 dashed line (r) shows inner annulus radius and solid line (w) indicates\nflow width.\nRogers et al. 7\nAnalysis. To equate relative tilts across the different target trajectories, a simple\ntransformation was applied to the raw data1 (see Warren & Rushton, 2007, for further\ndetails):\ni\u00bc tan\u00c01\u00f0sin\u00f0p\n\u00c0R\u00de=sinp\u00de\nwhere the P and R subscripts refer to perceived and real on-screen trajectory angles. In the\nresults that follow, i\nis referred to as the relative tilt.\nTo present appropriate within-subject error bars in figures, the data were normalised\naccording to the method described in Cousineau (2005). Variance due to individual\ndifferences was removed from the dataset by subtracting each participant's average relative\ntilt from the same participant's relative tilt in each experimental condition. Using the adjusted\ndataset, the standard error was then calculated for each condition.\nUnder this experimental design, flow parsing predicts that changing either the target\nposition or flow movement direction should lead to reversals in the sign of the relative tilt\nin an unbiased observer. The combination of the two effects means that we should find a\nstatistical interaction between target position and flow direction. Accordingly, we conducted\na 2 \u00c2 2 repeated measures ANOVA at each flow eccentricity and looked for a simple\ninteraction between the flow direction and target position as a marker of flow parsing\n(rather than insisting on a sign change). The presence of an interaction provides statistical\nsupport for a contribution to flow parsing at the eccentricity considered. Since a directional\ninteraction was predicted, probability values from the ANOVA interaction term were\nadjusted (p/2; Wuensch, 2006), because the error term for the interaction in an ANOVA\ndoes not assume a directional effect. Note that the test for an interaction is robust in the case\nof observers who have a systematic tendency to perceive, or report, a trajectory inaccurately.\nIn addition to looking for evidence of flow parsing at each flow eccentricity, we looked to\nsee if the magnitude of the flow parsing effect (relative tilt) increased (or decreased) as a\nTime\nFixation dot\nFlow onset\nFlow only\nResponse line\nResponse phase\nTarget duration\nFixation dot\nTarget onset\nITI\nFigure 4. Timeline for Experiment 1. Both possible target locations are indicated but only one target was\npresented on each trial. The response line appeared in the same location as the target.\n8 i-Perception\nfunction of the eccentricity of the radial flow. We conducted this analysis on the difference of\nthe relative tilt between the above and below target positions, which essentially provides an\nindex of the magnitude of the flow parsing effects observed across the two probe positions\nand has the added advantage of doubling the size of the effect. A 5 (flow eccentricity) \u00c2 2\n(flow direction) within-subjects ANOVA was then performed. If flow parsing effects\ndecreased as a function of flow eccentricity, then we would expect to see an interaction\nbetween these two factors.\nResults and Discussion\nWe found that the presence of expanding or contracting visual flow in peripheral vision\nbiased the perceived trajectory of a central target. At each tested flow eccentricity and\ntarget position, perceived target trajectory was biased in the direction opposite to the\nflow--indicative of global subtraction and in line with a peripheral contribution to flow\nparsing.\nFor targets located below fixation (\u00c04), target trajectory was ACW during expanding flow\nand CW during contracting flow. When the target was located above fixation (\u00fe4), we\nobserved the opposite pattern with expanding flow biasing target trajectory in a CW\ndirection and contracting flow resulting in an ACW bias. This pattern of results indicates\na contribution of peripheral flow to a flow parsing mechanism and was statistically significant\n(interaction, all p < .01) at each flow eccentricity (Figure 5; see Supplementary Materials for\nfull statistical results).\nThere was also a significant interaction between flow eccentricity and flow direction,\nof the flow and the eccentricity of the flow. This interaction which is evident in Figure 6\nindicates that relative tilt difference decreases with increasing flow eccentricity.\nWe also found that relative tilt effects were larger in the expanding flow conditions\n(Figure 6). The magnitude of the difference in relative tilt between the two target positions\nThe marked difference between expanding and contracting flow is evident in this figure. This\ndifference might indicate a response bias, and the similar gradient of the two lines is\ncompatible with this. However, asymmetries between expanding and contracting flow have\nbeen reported before (e.g., Edwards & Ibbotson, 2007, showed faster onset and larger\nmagnitude of vection in response to contracting flow than expanding flow but there is\nsome debate in this area and other studies have demonstrated a greater response to\nexpanding flow, i.e., Reinhardt-Rutland, 1982). The differences observed in this experiment\nbetween expanding and contracting flow might be due to broader differences in the neural\nprocessing of expanding and contracting motion. As forward self-movement is typically\nfaster than backward self-movement, there may well be differences in the speed tuning of\nneurons in relation to these two directions of motion. The second control experiment\n(Experiment S2) provides some data on the sensitivity to motion between forward and\nbackward self-movement using the present flow stimuli. The results of S2 did not indicate\nany differences in sensitivity.\nExperiment 2\nThe results of Experiment 1 show that peripheral flow contributes to flow parsing but that the\ncontribution decreases as the eccentricity of flow increases. However, we were only able to\nexplore the contribution over a limited range of eccentricities. In Experiment 2, we explore\nRogers et al. 9\nfurther into the periphery and examine how information from different parts of the peripheral\nretina is combined. To do this, we defined near (15\u00ad45 from fixation) and far (45\u00ad135 from\nfixation) peripheral regions. To stimulate far periphery, we placed monitors to either side of the\nparticipant's head. This setup was inspired by the peripheral vection experiments in Lepecq\net al. (1993) which used moving striped vertical bar stimuli presented on similarly arranged\nscreens. This experimental setup was reported to create a compelling sense of vection and\ntherefore should provide a strong visual cue to self-movement in this experiment.\nFigure 5. For each flow eccentricity: Relative tilt in degrees, shown in the vertical axis, as a function of flow\ndirection (expanding flow--blue squares, Contracting flow--red triangles) and target position for above and\nbelow target locations, shown on the horizontal axis. Error bars show within-subjects SE.\nTarget movement parameters and the relative tilt measure of perceived target trajectory\nwere the same as in Experiment 1. As in Experiment 1, the contribution of peripheral motion\nto flow parsing would be indicated by a significant interaction between flow direction and\ntarget position.\nMethods\nParticipants. Five undergraduate students (2 male) with an age range of 18 to 21 were recruited\nusing an online participant panel and received course credit. The same eligibility restrictions\nand ethical procedures as for Experiment 1 were applied. All participants were nai\u00a8ve to the\nexperimental hypotheses.\nApparatus. The central projection screen apparatus was the same as that used in\nExperiment 1, but we used an increased viewing distance of 95 cm. At this distance, the\nprojected image size was 67.5 \u00c2 53.6 and there were 21 pixels/degree. In addition, two\n1900 (aspect ratio 5:4) BENQ LCD monitors (model number: Q9T4) with a resolution of\n1280 \u00c2 1050 were placed either side of the observer's head, in a portrait orientation (see\nFigure 3(a)). The monitors faced each other and were separated by a total distance of\n43 cm with the chinrest for observers centred between the two monitors. Thus, each\nmonitor was approximately 15 cm from the observer's nearest eye. Each monitor\nsubtended approximately 90 horizontally and 100 vertically. For an observer seated with\ntheir head in the chin rest and looking straight ahead, the front edge of each peripheral\ndisplay (monitor screen) was 45 from the (cyclopean) line of sight (see Figure 3). The\nmonitors at the side of the head were covered with a red lighting gel to increase the\ncontrast of the stimuli and reduce ambient light which might have otherwise increased the\nsaliency of the edges of the monitors. Note that the arrangement of the apparatus meant that\nthere were gaps between the vertical edges of the central and peripheral screens.\nRelative tilt difference in degrees\nInner radius of flow in degrees\nFigure 6. Relative tilt difference in degrees (i.e., the difference between relative tilts when the probe was\npositioned above and below the fixation point) as a function of flow direction (expanding flow--blue squares,\ncontracting flow--red triangles) and flow eccentricity, shown on the horizontal axis. Error bars show within-\nsubjects SE.\nStimuli. As depicted in Figure 3 (right hand side), three peripheral flow conditions (Near, Far\nand Combined) were employed. The Near peripheral flow was generated using the same\nmethod as reported for Experiment 1 and had an inner radius (r) of 40 cm (22.8) and an\nouter radius of 50 cm (27.8) which was a similar eccentricity to inner edge of the least\nperipheral stimuli presented in Experiment 1 (inner radius [r] of 23). Far peripheral flow\nwas presented on monitors either side of the head. Stripes were used in the periphery\nsimilar to Lepecq et al.'s (1993) stimuli and because pilot testing demonstrated this stimulus\ngave a more compelling sense of self-movement than the limited lifetime dots that were used in\ncentral vision. Vertical stripes were positioned at a virtual distance of 50 cm from the\nobserver's nose on two parallel planes, either side of the head and orthogonal to the fronto-\nparallel plane and moved parallel to the line of sight away from the central projection screen.\nThe Combined flow condition presented the Near and Far peripheral stimuli simultaneously.\nAs before, the target was a small circular dot (diameter: 0.12) positioned either above or\nbelow fixation at an eccentricity of 4 from fixation and moved rightwards at a speed of\n0.6/s. The diameter of the flow dots, target size, fixation dot size and target position were all\nscaled in accordance with the increased viewing distance (95 cm vs. 40 cm).\nDesign. We manipulated three variables in this experiment: target position (\u00c04/\u00fe4), flow\ndirection (expanding/contracting) and peripheral region (Near/Far/Combined). For each of\nthe 12 resulting conditions, the nine tilt trajectories we employed in the previous experiment\nwere presented twice. Near, Far and Combined conditions were presented in separate blocks\nconsisting of 72 trials each. As before, we measured the relative tilt in degrees. All\nparticipants saw all conditions and the order of peripheral conditions was counterbalanced\nacross participants. Each participant completed the three peripheral conditions in a single\nexperimental session lasting approximately 45 min.\nProcedure. Participants were seated with their head in a chinrest and instructed to maintain\nfixation on the dot in the centre of the screen during stimulus presentation. The trial\nprocedure timings were identical to Experiment 1 (see Figure 4) and the Near, Far or\nCombined peripheral flow conditions were presented in separate experimental blocks.\nA 15-s enforced break was included halfway through each block. Because there were more\ntrials in Experiment 2 than Experiment 1, in order to reduce eyestrain and minimise fatigue,\nthe ceiling lights were turned on and participants had a short ($2 min) break between each\nperipheral condition (Near/Far/Combined).\nAnalysis. As before, to assess whether peripheral flow contributes to flow parsing, we\nconducted a 2 (expanding/contracting flow) \u00c2 2 (\u00c04/\u00fe4 target position) repeated measures\nANOVA on the data from each peripheral condition.\nTo investigate how information from Near and Far periphery is combined, we compared\nthe magnitude of the effect in the Combined condition to the sum of the magnitude of Near\nand Far effects. Specifically, we conducted a regression analysis to evaluate how well the\nCombined condition data could be predicted from the linear sum of near and far data.\nResults and Discussion\nThe results corroborated the findings of Experiment 1, they showed a peripheral contribution to\nflow parsing when flow was presented in near peripheral vision (Figure 7, left panel). The\ninteraction between flow direction and target position was highly significant, F(1, 4) \u00bc\nrelative tilt observed was much lower than in the Near condition. Additionally, the effect of\nFlow direction and target position upon relative tilt was less pronounced, but a significant\n(Figure 7, right panel) looked rather similar to the Near condition and once again a significant\nFor each flow direction (expanding or contracting), a linear regression analyses was\nconducted to test the extent to which the relative tilt data in the Combined condition\ncould be predicted by the linear sum (Near \u00fe Far) data. For the expanding flow\ncondition, statistical testing showed the linear sum model accounted for 97% of the\nContracting flow, the linear sum model accounted for only 34% of the variance in the\nresults suggest that the contribution of far peripheral flow to flow parsing is limited. There\nis some indication that the linear sum model can account for the data in the expanding but\nnot the contracting flow conditions. Rather than suggesting that the brain does not combine\ninformation over the retina, it is likely that the result in the Contracting condition is due to\nthe small magnitude of the effect of far peripheral flow on perceived probe trajectory.\nContribution of Far periphery\nGiven the linear relationship between eccentricity and the magnitude of the flow parsing\neffect in Experiment 1, we can attempt to predict the amount of relative tilt that is\nexpected for the Far peripheral condition. Before doing so, however, we note an important\ncaveat: Image speed depends on both distance from the observer and self-movement speed.\nThe ability to factor out the effect of distance depends on the quality of the distance cues\navailable. Distance cues are typically plentiful in central vision but drop off in peripheral\nvision. Consequently, for the far peripheral stimuli, the magnitude of any flow parsing is\nprobably based on raw image speed alone. Had we placed the virtual bars closer, the image\nspeed would have been higher; had we placed them further, then the image speeds would have\nbeen lower. Therefore, the magnitude of the flow parsing effect we observe with far periphery\nalone is relatively arbitrary. With that caveat clearly stated, we looked at the observed\nmagnitude of the flow parsing effect in far periphery and the magnitude predicted from an\nextrapolation of the results observed for central and near peripheral regions in Experiment 1.\nFigure 7. Relative tilt as a function of target position for each peripheral condition (solid lines--expanding\nflow, broken lines--contracting flow). Error bars show within-subjects SE.\nThe nearest edge of the far peripheral stimulus was 45 from fixation and the flow was\npresented only on the left and right of the head. We fitted a regression model to the data from\nExperiment 1 and used the model to predict relative tilt difference for a case where flow was\npresented at 45 eccentricity. The composite data and predictions are shown in Figure 8.\nThe prediction on the basis of the data from Experiment 1 for flow presented at 45\neccentricity is broadly in line with the data collected from the Far condition of\nExperiment 2. In the following section, we consider some additional factors that could\nimpact on the flow parsing effects observed.\nFurther Influences on the Magnitude of the Flow-Parsing Effect, Supplemental\nExperiments\nIn further supplementary experiments, we investigated the effect of further stimulus\nparameters. In Supplementary Experiment S1, we investigated whether reducing the area of\nthe flow, specifically whether presenting flow only in two quadrants (as in Experiment 2),\nimpacted upon the magnitude of flow parsing. The results of the experiment indicated that\nthe presence of flow stimuli on only the left and right quadrants did lead to a reduction in\nrelative tilt difference compared with when stimuli were presented in all four quadrants of the\nvisual field. Specifically, we found that the relative tilt for expanding flow reduced by 34% and\nfor contracting flow by 49%. Nonetheless, even with the removal of half of the area of the\nvisual field (the above and below quadrants), the overall pattern of results was similar in this\nsupplementary experiment.\nIn supplementary Experiment S2, we investigated the impact of stimulus type and peripheral\nposition between Experiments 1 and 2 (near peripheral dots vs. far peripheral stripes), whether\nthe two stimuli provided equally good motion signals. We did this by comparing speed\ndiscrimination thresholds. We found no effects of stimulus type on speed discrimination.\nIn sum, across Experiments 1 and 2, we find that peripheral flow does contribute to flow\nparsing but the contribution decreases with eccentricity. This reduction appears to follow a\nlinear function. We find no compelling evidence that flow presented beyond 40 eccentricity\nmakes a significant contribution to flow parsing.\n(Far)\nRelave lt difference in degrees\nInner radius of flow in degrees\nFigure 8. Composite data from all conditions of Experiment 1 and Far condition from Experiment 2. Solid\nand dashed lines show the predicted relative tilt difference for flow at 45 eccentricity on the basis of\nExperiment 1.\nDiscussion\nWe set out to investigate whether optic flow presented in the periphery could contribute to\nthe flow parsing process during simulated forward and backward movements of the observer.\nThe experiments reported here demonstrate that peripheral visual flow can contribute to flow\nparsing. When self-movement information is presented in peripheral vision, it leads to a\nsystematic effect on perceived object trajectory in line with the flow parsing account.\nExperiment 1 showed that the magnitude of the effect on perceived object trajectory\ndecreases as peripheral flow becomes more eccentric. Experiment 2 compared the\ncontributions of flow in the Near and Far periphery and how these contributions might be\ncombined. The results extended the findings of the first experiment, and again showed that\nthe contribution of peripheral flow to flow parsing decreases with increasing retinal\neccentricity. We examined how flow from different portions of the periphery was\ncombined. We found some evidence for combination across regions; however, the fact that\nwe found greatly reduced effects when flow was in far periphery makes it hard to draw a\nstrong conclusion from these data.\nIn our experiments, we ask observers to maintain fixation at the focus of the flow field.\nStudies have shown that this is the location that observers typically fixate (Land & Lee, 1994;\nLappe, Bu\n\u00a8 scher, & Hoffmann, 1999). Because observers are looking at the focus of the flow\nfield, retinal eccentricity and eccentricity defined relative to the focus of the flow field are\nequivalent. Consequently, we cannot distinguish between the two. If an observer fixates a\npoint away from the focus, the difference between eccentricity relative to the fovea and\neccentricity relative to the flow field becomes important. Research has shown that ability\nto judge direction of heading is relatively independent of the eccentricity of the focus of\nexpansion (Crowell & Banks, 1993). Therefore, we would expect little difference in the\nflow-parsing process. However, further experimental work is needed to confirm this\nprediction.\nWe now consider potential explanations for the decreased contribution to flow parsing of\nperipheral retina. Flow parsing relies on an accurate estimate of self-movement direction. In\naddition, retinal image speed is a function of both the speed at which the observer is\ntranslating and the distance of the scene objects from the observer so the availability of\nthese cues is important for flow parsing. In central vision, the availability of binocularly\noverlapping visual fields and high acuity allow for precise estimates of the distance that is\nnecessary for accurate estimation of observer translation speed. As the eccentricity increases,\nraw image speed persists but the available information about distance decreases,\nso consequently, the precision of estimates of self-movement speed will also decrease. The\ndecrease in the precision of estimates of self-movement direction or self-movement speed\nshould lead to the down-weighting of flow with eccentricity in the flow parsing process.\nThe research reported here provides a foundation for exploring the potential contribution\nof peripheral vision to flow parsing for other forms of self-movement. The case of lateral self-\nmovement will be of particular interest as the peripheral flow structure unambiguously\nspecifies that the observer is undergoing lateral translation. This differs from central vision\nwhere the flow due to lateral translation is difficult to distinguish from the flow due to a gaze\nrotation around the vertical axis. Therefore, in the case of lateral translation, we would\nexpect a clear contribution of peripheral vision to flow parsing.\nIn summary, the experiments reported here show a clear contribution of peripheral visual\nmotion to the flow parsing process and further bolsters the evidence that this mechanism\nrelies upon global optic flow fields.\nAuthor Note\nData and code is available from the ReShare research data repository, https://dx.doi.org/10.5255/\nAuthor contribution\nCassandra Rogers, Simon K. Rushton and Paul A. Warren jointly conceived the study, interpreted the\ndata and wrote and edited the manuscript. Cassandra Rogers programmed the experimental visual\nstimuli, collected the psychophysical data and performed the statistical analysis.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or\npublication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or\npublication of this article: This research was funded by the Economic and Social Research Council.\nSupplementary material\nSupplementary material is available for this article online.\nNote\n1. Although this transformation is appropriate before combination of the different target trajectories, note\nthat repeating the statistical analyses undertaken on the raw data does not change the conclusions.\nReferences\nAngelaki, D. E., Gu, Y., & DeAngelis, G. C. (2011). Visual and vestibular cue integration for heading\nBardy, B. G., Warren, W. H., & Kay, B. A. (1999). The role of central and peripheral vision in postural\nBerthoz, A., Pavard, B., & Young, L. (1975). Perception of linear horizontal self-motion induced by\nperipheral vision (linearvection) basic characteristics and visual-vestibular interactions.\nBrandt, T., Dichgans, J., & Koenig, E. (1973). Differential effects of central versus peripheral vision on\negocentric and exocentric motion perception. Experimental Brain Research, 16, 476\u00ad491.\nCalabro, F., Soto-Faraco, S., & Vaina, L. (2011). Acoustic facilitation of object movement\ndetection during self-motion. Proceedings of the Royal Society B: Biological Sciences, 278,\nCalabro, F., & Vaina, L.-M. (2011). Detection of object motion during self-motion: psychophysics and\nCousineau, D. (2005). Confidence intervals in within-subject designs: A simpler solution to Loftus and\nMasson's method. Tutorials in Quantitative Methods for Psychology, 1, 42\u00ad45.\nCrowell, J. A., & Banks, M. S. (1993). Perceiving heading with different retinal regions and types of\nEdwards, M., & Ibbotson, M. R. (2007). Relative sensitivities to large-field optic-flow patterns varying\nEriksson, L., & von Hofsten, C. (2005). Effects of visual flow display of flight maneuvers on perceived\nspatial orientation. Human Factors: The Journal of the Human Factors and Ergonomics Society, 47,\nFajen, B. R., & Matthis, J. S. (2011). Direct perception of action-scaled affordances: The shrinking gap\nproblem. Journal of Experimental Psychology: Human Perception and Performance.\nFajen, B. R., & Matthis, J. S. (2013). Visual and non-visual contributions to the perception of object\nFajen, B. R., Parade, M. S., & Matthis, J. S. (2013). Humans perceive object motion in world\ncoordinates during obstacle avoidance. Journal of Vision, 13, 25.\nFoulkes, A. J., Rushton, S. K., & Warren, P. A. (2013a). Flow parsing and heading perception show\nsimilar dependence on quality and quantity of optic flow. Frontiers in Behavioural Neuroscience, 7,\nFoulkes, A. J., Rushton, S. K., & Warren, P. A. (2013b). Heading recovery from optic flow: comparing\nperformance of humans and computational models. Frontiers Behavioural Neuroscience, 7, 1\u00ad20.\nGibson, J. J. (1950). The perception of the visual world. Boston, MA: Houghton Mifflin.\nGogel, W. C. (1990). A theory of phenomenal geometry and its applications. Perception &\nHabak, C., Casanova, C., & Faubert, J. (2002). Central and peripheral interactions in the perception of\nLayton, O. W., & Fajen, B. R. (2016). A neural model of MST and MT explains perceived object\nLappe, M., Pekel, M., & Hoffmann, K.-P. (1998). Optokinetic eye movements elicited by radial optic\nLappe, M., Pekel, M., & Hoffmann, K.-P. (1999). Properties of saccades during optokinetic responses\nto radial optic flow in monkeys. In W. Becker, H. Deubel, & T. Mergner (Eds.), Current oculomotor\nresearch: Physiological and psychological aspects (pp. 45\u00ad52). New York, NY: Plenum.\nLee, D. N., & Aronson, E. (1974). Visual proprioceptive control of standing in human infants.\nLepecq, J.-C., Jouen, F., & Dubon, D. (1993). The effect of linear vection on manual aiming at\nmemorized directions of stationary targets. Perception, 22, 49\u00ad60.\nMatsumiya, K., & Ando, H. (2009). World-centered perception of 3D object motion during visually\nguided self-motion. Journal of Vision, 9, 15.\nMourant, R. R., Rockwell, T. H., & Rackoff, N. J. (1969). Driver's eye movements and visual\nMacNeilage, P. R., Zhang, Z., DeAngelis, G. C., & Angelaki, D. E. (2012). Vestibular facilitation of\nNiemann, T., Lappe, M., Bu\n\u00a8 scher, A., & Hoffmann, K.-P. (1999). Ocular responses to radial optic flow\nPaulus, W., Straube, A., & Brandt, T. (1984). Visual stabilization of posture physiological stimulus\nReinhardt-Rutland, A. (1982). Asymmetry in forward and backward vection. Perceptual and Motor\nRousselet, G. A., Husk, J. S., Bennett, P. J., & Sekuler, A. B. (2005). Spatial scaling factors explain\nRoyden, C. S., & Connors, E. M. (2010). The detection of moving objects by moving observers. Vision\nRoyden, C. S., Crowell, J. A., & Banks, M. S. (1994). Estimating heading during eye movements. Vision\nRoyden, C. S., & Holloway, M. A. (2014). Detecting moving objects in an optic flow field using\ndirection-and speed-tuned operators. Vision Research, 98, 14\u00ad25.\nRoyden, C. S., & Moore, K. D. (2012). Use of speed cues in the detection of moving objects by moving\nRoyden, C. S., Sannicandro, S. E., & Webber, L. M. (2015). Detection of moving objects using motion-\nand stereo-tuned operators. Journal of Vision, 15, 21.\nRushton, S. K., Bradshaw, M. F., & Warren, P. A. (2007). The pop out of scene-relative object\nRushton, S. K., & Warren, P. A. (2005). Moving observers, relative retinal motion and the detection of\nStoffregen, T. A. (1985). Flow structure versus retinal location in the optical control of stance. Journal\nof Experimental Psychology: Human Perception and Performance, 11, 554.\nTcheang, L., Gilson, S. J., & Glennerster, A. (2005). Systematic distortions of perceptual stability\nTrevarthen, C. B. (1968). Two mechanisms of vision in primates. Psychologische Forschung, 31,\nvan Boxtel, J. J., Wexler, M., & Droulez, J. (2003). Perception of plane orientation from self-generated\nand passively observed optic flow. Journal of Vision, 3, 1.\nWallach, H. (1987). Perceiving a stable environment when one moves. Annual Review of Psychology, 38,\nWarren, P. A., & Rushton, S. K. (2007). Perception of object trajectory: Parsing retinal motion into self\nand object movement components. Journal of Vision, 7, 2.\nWarren, P. A., & Rushton, S. K. (2008). Evidence for flow-parsing in radial flow displays. Vision\nWarren, P. A., & Rushton, S. K. (2009). Optic flow processing for the assessment of object movement\nWarren, P. A., Rushton, S. K., & Foulkes, A. J. (2012). Does optic flow parsing depend on prior\nestimation of heading? Journal of Vision, 12, 8.\nWexler, M., Lamouret, I., & Droulez, J. (2001). The stationarity hypothesis: An allocentric criterion in\nWexler, M., Panerai, F., Lamouret, I., & Droulez, J. (2001). Self-motion and the perception of\nWuensch, K. L. (2006). Half-tailed tests in ANOVA. Retrieved from http://core.ecu.edu/psyc/\nwuenschk/StatHelp/StatHelp.htm.\nAuthor Biographies\nCassandra Rogers gained a BS in psychology (2008), MS in social\nUniversity and then began working as a Project Officer at the same\ninstitution, within the Quality Assurance division. In 2015, she began\nworking as a Senior Research Associate within Institutional Research\n(IR) at New Jersey Institute of Technology in the US. In 2016, she was\npromoted to Assistant Director of IR and Planning and focuses on the\nanalysis of institutional data. She maintains an interest in many\naspects of visual perception, including motion perception, peripheral\nvision, colour perception, and visual illusions.\nSimon K. Rushton has worked in academia and industry on both sides\nof the Atlantic. He is currently a Professor in the School of\nPsychology at Cardiff University. Simon's primary research interest\nis in perception during locomotion. Specifically, he is interested in two\nproblems: (i) what visual information do we use to guide walking, and\n(ii) how do we perceive the world while we are moving?\nPaul A. Warren studied mathematics as an undergraduate and in 2000\nobtained a PhD in vision science from the University of Sheffield.\nAfter postdoctoral positions at New York University and The\nUniversity of Glasgow, he spent 2 years working in industry,\nreturning to academia in 2007 as a research fellow at Cardiff\nUniversity. Since 2009 he has held a faculty position at The\nUniversity of Manchester. His primary research interest is visual\nperception, with particular emphasis on motion perception and\noptic flow processing. He also studies human judgement and\ndecision making."
}