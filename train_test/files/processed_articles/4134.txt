{
    "abstract": "Abstract\nEarly investigation led the Evaluative Study of Action Research (ESAR) team to conclude that the complexity of a global,\nlarge scale study (evaluation of more than 100 highly diverse action research [AR] projects) called for an overarching\nresearch evaluation framework that differed from traditional frameworks. This article details the flexible, rigorous, Evaluative\nAction Research (EvAR) framework developed to meet the complex demands of the diverse AR projects and the intent to\nconduct high engagement research evaluation. The EvAR fulfilled multiple overarching needs to: authentically collaborate,\nengage, and enhance ownership from the ESAR team and the AR project participants and boundary partners evaluated;\nbe informed in decision making via strong reference support; be responsive and flexible yet meet accountability demands\nto track, demonstrate, and measure process, outcomes, and impacts of projects; use mixed-method data collection to\nenhance rigor of findings; and utilize a highly reflective and reflexive approach to the evaluation. Many of the latter needs\nalign with underpinning principles and values in AR itself; that is, it is collaborative, consultative, democratic, reflective,\nreflexive, dialogical, and improvement oriented. Rationale for the framework is provided alongside full details of phases and\nimplementation elements using the ESAR as an example. Throughout the article, features are highlighted that distinguish this\nnew EvAR framework from others. The advantages of adopting a flexible framework, which aims to enhance engagement of\nthose evaluated, are highly relevant to contexts beyond AR if ownership of evaluation outcomes is a goal.\n",
    "reduced_content": "sgo.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of\nthe work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nArticle\nIntroduction\nThis article describes the establishment and application of a\nnew research evaluation framework: the Evaluative Action\nResearch (EvAR) framework which was employed in the\nEvaluative Study of Action Research (ESAR). We use italics\nthroughout the article to illustrate the way in which the EvAR\nframework phases and elements were applied and tested on\nthe ESAR as an example.\nWe begin with an overview of the EvAR framework which\nour seven-strong team of international researchers developed\nto provide detail and clarity for the way we would conduct the\nESAR. This beginning section of the article introduces the six\nphases and multiple elements of the EvAR framework as well\nas its visual representation. The six phases are as follows: (a)\npreparation, (b) reconnaissance, (c) implementation, (d)\nreview of achievement, (e) reporting on achievements/recom-\nmendations and knowledge mobilization, and (f) continued\naction for improvement. In the overview, we include two of\nthe features of the EvAR which have been given limited\nemphasis in other evaluative frameworks. First is the critical\nimportance of establishing protocols for an evaluative research\nteam working together. Second, little mention is made in other\nevaluative frameworks of the importance of conducting an ini-\ntial deep review of the literature to ensure the evaluative\nframework matches the context to be evaluated. The\n\"Overview: The Evaluative Framework\" section concludes\nwith discussion of the way the EvAR aligns with the underpin-\nnings and values of action research (AR).\nSix sections follow, where each phase of the framework is\ndetailed using ESAR as an illustration (shown in italics).\nParticular emphasis is placed on the following elements\nwithin the implementation phase: setting purposes, benefits,\nindicator establishment, participants/boundary partner\nengagement, methods utilized, and analysis of data.\nIn the \"Conclusion\" section, we emphasize the impor-\ntance of the process of a review and reflective stance when\n1Royal Roads University, Victoria, British Columbia, Canada\nCorresponding Author:\nEileen Piggot-Irvine, School of Leadership Studies, Royal Roads University,\nEmail: Eileen.Piggotirvine@RoyalRoads.ca\nDeveloping a Framework for Research\nEvaluation in Complex Contexts Such as\nAction Research\nEileen Piggot-Irvine1 and Deborah Zornes1\n Keywords\nresearch impact evaluation framework, action research, process, impact, output, impact evaluation\n2 SAGE Open\nusing a research evaluation framework and provide a sum-\nmary of the team's reflections throughout the ESAR project\nas an example. Such a stance is seldom featured in traditional\nevaluative frameworks though it is a strong component of\nAR. Extensive knowledge mobilization is discussed next in\nthe conclusion. Finally, we sum up the effectiveness of the\nEvAR as an evaluative framework developed for the ESAR\nproject.\nOverview: The Evaluative Framework\nIn this overview, we provide an outline of the EvAR frame-\nwork phases and elements. We want to clarify that our devel-\nopment of the framework did not occur until some months\nafter the ESAR instigation. It was only after the team had\nsomewhat intuitively engaged in what we describe as Phases\n1 and 2 that we realized we were creating an evaluative\nframework which differed from many others we explored.\nSuch a distinctive framework was essential for our work in\nevaluating more than 100 complex AR projects globally in\nthe ESAR. A different framework was also needed to fit our\nequally complex international research team who wished to\nuphold the principles and values associated with AR itself in\nthe evaluative research.\nThe EvAR (Figure 1) begins with the crucial initial step of\na research team creating clarity around the way they will\nwork together. This preparation phase (Phase 1) includes\nestablishment of some form of agreement and protocols cov-\nering principles and values. We found little emphasis of this\nstep in other framework outlines.\nThe reconnaissance phase (Phase 2) is also rarely men-\ntioned in evaluative frameworks. In this phase, two steps are\nincluded which are associated with becoming informed prior\nto implementing a research evaluation. First, we recommend\na probing literature review be conducted prior to initiating\nevaluative research to gain foundational understanding of the\ncomplexity of research evaluation frameworks. This is fol-\nlowed by an investigation of the context such a framework\nwill be used for. We offer that such an exploration is critical\nto becoming sufficiently informed to move to the second step\nof selecting and justifying an appropriate framework and\nconstituting elements.\nThe implementation phase (Phase 3) of the EvAR incorpo-\nrates process elements. Phase 3 begins with setting purposes,\nidentifying the benefits of the study, articulating objectives\nand research questions, and establishing indicators for evalu-\nation. The importance of determining the appropriate partici-\npants in a study is outlined, as is stakeholder (also noted as\nboundary partners in this article) engagement. Next, elements\ncovering the methodology and methods selected and data\nanalysis used are noted. We do not offer a prescriptive\napproach in the EvAR framework but rather allow for delib-\nerate flexibility and considerable choice of tools.\nFollowing the articulation of constituting elements, Phase\n4, the review of achievement phase is discussed. In this\nphase, the focus is on gathering data regarding the effective-\nness of the research evaluation process with meta-reflection\nand reflexivity as guiding approaches.\nThe review of achievement phase is followed by the\nreporting achievements, recommendations, and knowledge\nmobilization phase (Phase 5). We believe that, ideally, report-\ning out and knowledge mobilization could occur throughout\nthe entire application of the framework in much the same\nway that AR itself often includes iterative reporting to\nenhance ownership and further input on findings.\nThe continuation arrow shown in Figure 1 for the EvAR\nindicates that ongoing action is likely to result from Phases 4\nand 5. The sixth and final phase of the framework, the con-\ntinued action for improvement phase (Phase 6), encourages\nthe evaluative researchers to be responsive to emergent needs\nfor further improvement in their evaluation.\nThe EvAR, as its name suggests, follows an AR philoso-\nphy and process. In summary, we developed an AR-based\nevaluative framework that could be utilized to evaluate AR\nin our ESAR in what could be described as a meta-AR\napproach to \"function as an umbrella process, a meta-meth-\nodology, under which a variety of flexible methods can be\nassimilated\" (Dick et al., 2015, p. 38). Meta implies that an\nAR model is used at a higher level; in the case of the EvAR,\nit is AR on AR. We note strongly, however, that the EvAR\ncould be adopted as an evaluative research framework for\nmany other types of research.\nThe framework has all the hallmarks of AR including\ncombined data collection (systematic research and inquiry)\nand change (action) phases (Davison, Martinsons, & Kock,\nscends disciplinary, institutional, and international boundar-\nies with a central focus on research with (and alongside)\nboundary partners (all stakeholders) and communities\nin AR and the EvAR is associated with enhancing the capac-\nity of groups and organizations to own and sustain change.\nAs Greenwood and Levin (2007) indicated, \"AR is a set of\nself-consciously collaborative and democratic strategies for\ngenerating knowledge and designing action in which trained\nexperts in social and other forms of research and local stake-\nholders work together\" (p. 1). The change orientation along-\nside the underpinning collaborative and democratic values\nand strategies sets AR, and EvAR, apart from most tradi-\ntional forms of research and evaluation. We strongly believed\nthat any evaluative framework which was low in collabora-\ntive, participative, democratic and transformative intent\nwould likely be rejected by those involved in the AR projects\nwe wanted to investigate, and most importantly that such a\nframework would likely lead to low ownership of findings\nby those involved in the projects.\nThe EvAR, like AR, also includes an emphasis on open-\nness to unpredictability and flexibility (Coghlan & Brannick,\nPiggot-Irvine and Zornes 3\nbroader thinking about complexity where order and predict-\nability are limited (Kurtz & Snowden, 2003).\nSuch openness matched our needs for the ESAR because\nwe wanted to be responsive to increasing demands to track,\ndemonstrate, and measure the impacts and outcomes of\nMackean, Casebeer, & Lindstrom, 2014), but we also wanted\nflexibility in our framework sufficient to deal with the highly\ndiverse 100 plus AR projects to be evaluated.\nFlexibility is also linked to the EvAR pragmatic orienta-\ntion to method employment that had previously been\ndesigned by one of the team (Piggot-Irvine, 2012b).\nGreenwood (2014) defined such a pragmatic approach in AR\nas that which\nwill use theory and methods from any corner of the sciences,\nsocial sciences and humanities if they offer some hope of helping\na collaborating group move forward. If numbers are needed,\nstatistical social science, surveys and other formal techniques\ncan and will be used. (p. 647)\nFigure 1. Evaluative AR framework.\nNote. AR = action research.\n4 SAGE Open\nIt is also pragmatic in Metcalfe's (2008) terms in that\nfindings can be created which are meaningful and help those\naffected to construct understanding and design actions rele-\nvant to their community.\nThe framework, in keeping with AR, has a cyclic, itera-\ntive, depiction that sometimes has spin-off (McNiff, 1988),\nor slightly divergent, cycles. This cyclical orientation (itera-\ntive planning, acting, reflecting, and evaluating within larger\ncycles or phases) is supported by multiple authors (e.g.,\nThe EvAR is also associated with further underpinning\nprinciples that are not so typical of AR, with some indicating\nenhanced expectations of rigor. The latter include focusing\non research that evaluates precursors, processes, outcomes\nand impacts; establishing clarity of this focus via evaluation\nindicators that are both bibliometric and nonbibliometric;\nand considering complexity by seeking to understand mean-\ning (largely through Ql data) as well as searching for causal-\nity (through Qn data). To avoid repetition, we note that each\nof these principles is covered later in discussion of the indi-\nvidual elements of the framework.\nEach phase of the EvAR is detailed in the subsequent sec-\ntions of this article, using the ESAR as an example (illus-\ntrated in italics).\nPhase 1: Preparation\nThe inclusion of a preparatory phase as we describe it has not\nbeen mentioned in traditional evaluative research frame-\nworks we explored. The following outline of Phase 1 there-\nfore exclusively describes the employment of the phase in\nthe ESAR project as an example.\nIn our initial work together in the ESAR as seven interna-\ntionally dispersed researchers with varying levels of under-\nstanding and experience of either or both AR or evaluation,\nwe decided that we could not progress without establishing\nconsensus about commonality of values, principles, and pro-\ntocols for working as a cohesive, highly collaborative team.\nSuch an important element is widely valued in AR itself, and\nwas a priority for the ESAR team because, as noted in Rowe,\nGraf, Agger-Gupta, Piggot-Irvine, and Harris (2013), \"the\ngrounding of a change initiative in early stage elements of\nthoughtful inquiry, collaboration, dialogue and reflection\noften mitigates resistance and enhances progress on imple-\nmenting a change agenda\" (p. 4).\nThe team spent two days on this preparatory phase and\nthe resulting documents developed have continued to provide\nreference points throughout our work together. Without\nextensively reporting on the content of the documents, we\nnote briefly that working together authentically in collabora-\ntion with each other and with all boundary partners domi-\nnated our protocols. The approach to collaboration drew\nstrongly upon the six preconditions for collaboration out-\nlined in Piggot-Irvine (2012a) as \"trust; shared goals;\nshared language; a desire to participate; openness and lis-\ntening; and passion for the process\" (p. 2). We also noted the\nfollowing advantages of collaboration as stated in Piggot-\n. . . the advantages to the participants of collaboration in action\nresearch are cited as many and various (D'Arcy, 1994; Kemmis &\nit can allow for public testing of private assumptions and\nreflections; that is, it helps to avoid self-limiting reflection (Sch\u00f6n,\n1983).Collaborationcanalsoenhanceownershipandcommitment\nto change and it can leverage the change to a level frequently\nunattainable through individual reflection alone. (p. 25)\nAs a research team, we felt that just collaborating, as a\nprinciple, would be insufficient and that the collaboration\nand democratic values of AR needed to be linked to dialogue\nif trust was to be an outcome. Dialogue is associated with\nopen, nondefensive (Argyris, 2003) interactions where bilat-\neral (considering two sides) and multilateral (considering\nmultiple sides) conversation dominates. Dialogue is charac-\nterized by two essential components. The first is the offering\nof openness about perspectives by those collaborating,\nalongside provision of evidence and reasoning behind those\nperspectives (an advocacy approach). The second compo-\nnent is that of receiving, checking, and understanding of oth-\ners' perspectives without prejudgment, or assumptions (an\ninquiry approach), so that mutual understanding can be\nreached. Preskill and Torres (1999) summed up the dialogue\norientation resulting from this advocacy and inquiry balance\nin suggesting: \"individuals seek to inquire, share meanings,\nunderstand complex issues, and uncover assumptions\"\nwhich facilitates \"learning processes of reflection, asking\nquestions, and identifying and clarifying values, beliefs,\nassumptions and knowledge\" (p. 53).\nOnce the ESAR team had created a shared understanding\nof the values and protocols for working together, we were\nready to dig deeply into the literature associated with our\nframework development task in the reconnaissance phase.\nPhase 2: Reconnaissance\nAs suggested in our introduction, we propose that consid-\nerable investigation of evaluative frameworks and existing\nknowledge of the context which a framework will be used\nwithin could precede construction of any research evalua-\ntion framework. In this statement, there is a premise that\nwe believe a conceptual framework is necessary despite\nthe existence of advantages and disadvantages. Baxter and\nJack (2008), for example, suggested that one advantage of\na framework lies in its ability to serve as an anchor for a\nstudy. They also noted, however, that framework construc-\ntion may be constraining and limit an inductive approach.\nIn our experience, such reconnaissance investigation there-\nfore can help to clarify why and how any research evalua-\ntion might occur.\nPiggot-Irvine and Zornes 5\nWe propose a reconnaissance phase in the framework\nwhich includes literature reviews on the two foundational\ntopics of (a) research evaluation frameworks themselves and\n(b) the context of the specific evaluation research to be con-\nducted to enhance the possibility of a framework-context\nmatch. The following discussion outlines the two founda-\ntional topics with illustration via the ESAR.\nFoundational Topic 1: Exploring Frameworks\nAvast range of research evaluation frameworks exist, includ-\ning the Research Excellence Framework (Parker & van\nTeijlingen, 2012); STAR METRICS, which aims to \"assess\nand understand the performance of research and researchers,\nlargely for accountability purposes, using data mining and\nother novel low burden methods\" (Guthrie, Wamae,\nDiepeveen, Wooding, & Grant, 2013, p. 2); Excellence in\nResearch for Australia (ERA); Canadian Academy of Health\nScience Payback Framework; National Institutes of Health\nResearch (NIHR) Dashboard; Productive Interactions;\nEvaluation Agency for Research and Higher Education\n(AERES) framework; Congressionally Directed Medical\nResearch Program (CDMRP); Performance-Based Research\nFund (PBRF); and Standard Evaluation Protocol (SEP).\nMany of the traditional frameworks we explored focused\nlargely on measuring impact through a process of external\npeer review and frequently emphasized the use of quantifi-\nable bibliometric indicators. A recent trend is toward frame-\nworks incorporating both bibliometric and nonbibliometric\nindicators. The Payback framework is an example of the lat-\nter and is used extensively in health research internationally\nDonovan & Hanney, 2011). The Payback framework incor-\nporates both academic outputs and wider societal benefits to\nassess outcomes (knowledge production such as journal arti-\ncles, etc.), target future research, build capacity, inform poli-\ncies and project development, create health and health sector\nbenefits such as better health and health equity, and enhance\nbroader economic benefits (Buxton & Hanney, 1996).\nFrameworks incorporating both bibliometric and nonbib-\nliometric indicators often fall under the cluster of SIAMPI\n(Social Impact Assessment Methods for research and fund-\ning instruments through the study of Productive Interactions\nbetween science and society) and have \"a central theme of\ncapturing `productive interactions' between researchers and\nstakeholders\" (Penfield, Baker, Scoble, & Wykes, 2014, p.\n24). The focus is on understanding how research interactions\nlead to social impact. The Australian Research Quality\nFramework (RQF), for example, uses a case study approach\nto demonstrate and justify public expenditure on research\nand asks researchers to provide \"evidence of economic, soci-\netal, environmental, and cultural impact of their research\"\nimplemented, it was adapted for the United Kingdom\nResearch Evaluation Framework (REF), which continued\nwith the case study approach, adding significance, depth,\nspread, and reach as further nonbibliometric criteria for\nassessment. Here, depth and spread refer to \"the degree to\nwhich the research has influenced or caused change, whereas\nspread refers to the extent to which the change has occurred\nIn general, as Guthrie et al. (2013) offered, trade-offs are\nassociated with any framework construction decisions in\nevaluation of research. Trade-offs are summarized as\nfollows:\n\u00b7 Quantitative approaches (those which produce numerical\noutputs) tend to produce longitudinal data, can be applied\nrelative to fixed baselines reducing the need for judgment\nand interpretation, and are relatively transparent, but they\nhave a high initial burden (significant work may be required\nat the outset to develop and implement the approach);\n\u00b7 Formative approaches (which focus on learning and\nimprovement rather than assessing the current status) tend\nto be comprehensive, evaluating across a range of areas, and\nflexible, but they do not produce comparisons between\ninstitutions;\n\u00b7 Approaches which have a high central burden (requiring\nsignificant work on the part of the body organizing the\nevaluation process) tend not to be suitable for frequent use;\n\u00b7 Approaches which have been more fully implemented tend\nto have a high level of central ownership (by either the body\norganizing the evaluation, or some other body providing\noversight of the process); and\n\u00b7 Frameworks that place a high burden on participants require\nthose participants to have a high level of expertise (or should\nprovide capacity building and training to achieve this).\nOverall, individual frameworks have specific strengths\nand limitations, and each should be weighed up in choosing\na framework. Penfield et al. (2014) suggested the following\nlimitations that we considered associated with:\n\u00b7 time lag--outcomes and impacts can take years to\nmaterialize and it may be very difficult, if not impossible to\ntrace them back to the project/research;\n\u00b7 developmental nature of the impact--impact changes and\ndevelops over time and can be temporary or long lasting;\n\u00b7 attribution--over time, it becomes more and more difficult\nto tie outcomes, and especially impacts, directly back to the\nresearch and the research findings;\n\u00b7 complementary assets--over time, as various factors and\ninputs influence the outcomes, it becomes difficult to\nattribute the outcome back to the original research and\nfindings);\n\u00b7 knowledge creep--typically, new data, discoveries and\ninformation become accepted and absorbed over a long\nperiod of time; and\n\u00b7 gathering evidence--in many cases, the requirement to\ncollate evidence retrospectively may be difficult as\nmeasures, baselines and evidence itself has not been\ncollected and may not be available. (adapted from\n6 SAGE Open\nDespite a less inductive orientation indicated with using a\nframework, we decided that we needed an evaluation frame-\nwork to guide the complex ESAR and we embarked upon an\nexploration of the varied frameworks we have described in\nthis section. Initially, we sought to find a framework which\nwas a good fit for our planned study, or find aspects of mul-\ntiple frameworks that might help guide us.\nWe considered that both bibliometric and nonbibliomet-\nric indicators were relevant in our research evaluation. We\nalso decided to adopt considerations from Guthrie et al.\n(2013) including that the framework might promote learn-\ning and development and quality improvement, that is, it\ncould have analysis and accountability purposes; be an\niterative process; draw out wider social, economic, and\npolicy impacts; minimize administration burden; hold\ntransparency with rules and processes; include team-based\nresearch; apply collaborative (including cross-disciplin-\nary, cross-institution) research; support capacity building\nand development of next generation researchers; and be\nhelpful if it gathered longitudinal data to support quality\nimprovement.\nFoundational Topic 2: Investigating the AR\nContext\nIn the reconnaissance phase, we consider that a probing lit-\nerature review could also cover exploration of the context in\nwhichtheresearchevaluationwillbeconducted.Furthermore,\nsuch review could include examination of the extent to which\nthe context has previously been evaluated.\nIn the ESAR, our literature review of the AR context con-\nfirmed our knowledge that AR is frequently seen as a popu-\nlar developmental research methodology with combined\ndata collection (research) and change (action) elements\n(Piggot-Irvine et al., 2011). Earlier in the \"Overview: The\nEvaluative Framework\" section of this article, we have\nsummarized many of the other principles of AR including\nits pragmatic, responsive, iterative, and flexibly applied\naction-orientation with a core element of systematic\nresearch and inquiry processes; ability to transcend disci-\nplinary, institutional, and international boundaries; and\nfocus on research which is inclusive of boundary partners\nto democratically enhance the capacity of groups and orga-\nnizations to sustain change, develop resilience, and thrive.\nWe have also reported on the degree of unpredictability,\ncontextual and cultural specificity of AR, and such charac-\nteristics have a consequence of nongeneralizable findings\nwith subsequent implementation that is also highly\nvariable.\nThe principles of AR summarized in our probing litera-\nture review of the evaluation context led us to conclude\nthat the complexity of the large scale ESAR we\nwere planning called for an overarching framework which\ndiffered from any of the traditional research evaluation\nframeworks we examined. We had dual overarching needs\nbecause we wanted to be responsive to increasing demands\nto track, demonstrate, and measure the impacts and out-\ncomes of research but we also wanted flexibility in our\nframework. The framework needed to be pragmatic and\nflexible enough to deal with the context and practice\ndiversity of the 100 plus AR projects to be evaluated but\nalso needed to match the responsive, collaborative, demo-\ncratic, and dialogical underpinnings and values associ-\nated with AR itself if we were to gain ownership, respect,\nand credibility from action researchers. We believed that\nany evaluative framework which was low in collaborative,\nparticipative, democratic, and transformative intent could\nbe rejected by those involved in the AR projects we wanted\nto evaluate, and most importantly that it could likely lead\nto low ownership of findings by those involved in the\nprojects.\nEstablishing a rationale for the ESAR framework was\nrelatively easy because our literature review revealed a gap\nin terms of evaluation of AR. The touted high ideals of AR\nshown in the literature review, alongside its variable inter-\npretation and implementation, almost set up the approach\nfor substantial critique with it referred to as \"muddled sci-\np. 16), with reporting as \"little more than picturesque jour-\nneys of self-indulgent descriptions\" (Macpherson & Brooker,\nthat change associated with AR was hard to measure and\nthere was often poor theory development. As a team, we con-\ncluded that such critique prevails because little evaluative\ndata exist to demonstrate whether the ideals espoused for AR\nare widely realized. The paucity of evaluative data was\nstrongly expressed by Piggot-Irvine and Bartlett (2008) who\nstated there was a great deal of literature discussing or iden-\ntifying what constitutes good AR, but very little evaluation of\nAR outcomes or impact. A strong rationale for the ESAR was\nable to be articulated in our framework and our next task in\nframework construction was to establish clear direction for\nimplementation via purpose, objectives, and research\nquestions.\nPhase 3: Implementation\nThe implementation phase of the EvAR is the most inten-\nsively covered in this article. It is during this phase that\npurposes and benefits (justification) for the choice of a spe-\ncific research evaluation can be outlined. Furthermore, at\nthis phase, detail of the constituting elements describing\nhow the research evaluation will be conducted is noted (as\nsummarized in Figure 2) in the framework. This section of\nthe article covers description of the constituting elements of\nthe EvAR alongside illustration with application to the\nPiggot-Irvine and Zornes 7\nPurpose, Objectives, and Research Questions\nGuthrie et al. (2013) noted that the \"design of a framework\nshould depend on the purpose of the evaluation\" (p. ix).\nThese authors described the purposes of research evaluation\nas (with our interpretation):\n\u00b7\n\u00b7 advocacy (demonstrating benefits, enhancing under-\nstanding of the research process among policymakers\nand the public, and making a case for change/\nimprovement);\n\u00b7\n\u00b7 accountability (showing efficiency of use of resources\nwithin research);\n\u00b7\n\u00b7 analysis and learning (demonstrating how and why\nresearch is effective, and how it can be better sup-\nported); and/or\n\u00b7\n\u00b7 allocation (determining where and how best to allo-\ncate resources in the future).\nSuch purposes, in turn, are linked to whether an evalua-\ntion intent is formative (ongoing and learning, developmen-\ntal) or summative (endpoint and accountability oriented) as\nsummarized in Piggot-Irvine and Bartlett (2008). Guthrie\net al. (2013) stressed that purposes have to be clear from the\noutset because many other framework decisions are linked to\nthose purposes.\nFurthermore, Aberatne (2010) and more specifically\nDurlak and DuPre (2008) have made a solid case for the\nneed to understand purposes and process implementation in\nevaluating outcomes. For example, Durlak and DuPre\n(2008), in their own research, asked, \"1) Does implementa-\ntion affect outcomes?; and 2) What factors affect implemen-\nIn the ESAR project, Guthrie et al.'s (2013) primary pur-\nposes of advocacy, and analysis and learning predominated.\nAdvocacy was strong because we wanted to demonstrate\nbenefits, effective processes, and improvement impacts of\nAR. Analysis and learning also dominated as purposes due to\nour intent to showcase how and why AR led to different types\nof impacts. Both purposes have formative intent, but because\nwe wanted to evaluate the efficiency of resource use within\nAR projects we studied, there was also a secondary account-\nability (summative) purpose.\nPurpose decisions led to clarification of the overall\nobjective for the ESAR as to explore, via an examination\nof process and outcomes of approximately 100 AR proj-\nects implemented in varied contexts globally; whether and\nhow the often touted espousals of individual, community,\norganizational, and/or societal impact of AR are actually\nrealized; and to advance knowledge and understanding of\nthe elements of AR enhancing outputs, outcomes, and\nimpact.\nFurther focus in the ESAR was articulated through the\nclarification of the key research question:\nResearch Question 1: In what ways can AR be validated\nas a contributor to meaningful individual, community,\norganizational, and societal change?\nThe overall objective and question shows that the ESAR\nhad a focus on both process and outcomes. Findings were\nalso intended to provide clarity about validity claims for\nAR as an approach to change. In addition, more general\noutcomes associated with advancing knowledge were\nhoped for from the ESAR. These outcomes included build-\ning on current research from Piggot-Irvine and Bartlett\n(2008) on evaluation of AR, establishing evaluative indi-\ncators for AR, and creating a publicly accessible AR\nrepository as a directory for AR project reports and\nresearch findings.\nEstablishing Benefits\nIntended benefits of any study should be strongly articulated\nin a research evaluation framework (de Jong, van\nArensbergen, Daemen, van der Meulen, & van den Besselaar,\nSpaapen, Dijstelbloem, & Wamelink, 2007; Spaapen & van\nDrooge, 2011). Such benefits can be articulated as justifica-\ntion for a research evaluation study.\nKey benefits of the ESAR included that it was conducted\nin multicontextual, nonacademic, communities (e.g., health,\nsport, development aid, education, agriculture, environ-\nmental, management, and leadership, to name but a few),\nFigure 2. Constituting elements in the EvAR framework.\nNote. EvAR = Evaluative Action Research.\n8 SAGE Open\nand findings of the ESAR study were to be of interest to a\nvariety of disciplines (sometimes transdisciplinary), aca-\ndemic fields, and research areas such as philosophy, sociol-\nogy, science, arts, and so on. A further benefit was reported\nas enhanced AR credibility. We believed that the current\nperception of limited impact of AR was substantially due to\nthe minimal examination of outputs, outcomes, and impact.\nIn our framework, we recorded that the ESAR findings\ncould not only address this limitation but also add recom-\nmendations on processes that enhance effective outcomes\nfor action researchers. If outcomes, outputs, and impact\nwere validated, there could be reduction of criticism of low\ncredibility of AR. We stated in our \"Establishing Benefits\"\nsection of the EvAR framework that, at the least, recom-\nmendations for improved AR process/practice could be\nestablished to demonstrate how AR might be designed to\ngenuinely create thinking and behavior leading to improve-\nments in economic, social, cultural, and intellectual\nwell-being.\nIndicator Establishment\nGuthrie et al. (2013) emphasized that a framework \"requires\ncareful selection of units of aggregation for the collection,\nanalysis and reporting of data\" (p. x). Units of aggregation\nare most often referred to as indicators. Indicators can be\ndiscussed from varying perspectives, including scope (meth-\nods, dimensions of indicators) and establishment (extent of\ncollaboration in development, etc.).\nIn terms of scope, Penfield et al. (2014) offered specifi-\ncally that in data collection methods there should be a focus\non metrics, narratives, surveys, and citations (within and out-\nside of academia) as indicators for evaluating the success of\nresearch. A broader, dimensions oriented, emphasis proposed\nby Wickson and Carew (2014) included that indicators should\nfocus on whether a project/research is/was socially relevant\nand solutions oriented, sustainability and future scanning,\ndiverse and deliberative, reflexive and responsive, rigorous\nand robust, creative and elegant, and honest and accountable.\nJahn and Keil (2015) noted similar dimensions focusing on\nthe quality of the research problem (considering different spa-\ntial, temporal, and social scales), research process (level of\nintegration and epistemic, social organization, and communi-\ncative levels), and research results (maintaining the viability\nof society, and the attention to current and future issues of\njustice).\nThere has, however, been growing "
}