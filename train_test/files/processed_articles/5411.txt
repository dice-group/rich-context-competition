{
    "abstract": "Abstract\nThe Snowden revelations about National Security Agency surveillance, starting in 2013, along with the ambiguous\ncomplicity of internet companies and the international controversies that followed provide a perfect segue into con-\ntemporary conundrums of surveillance and Big Data. Attention has shifted from late C20th information technologies and\nnetworks to a C21st focus on data, currently crystallized in ``Big Data.'' Big Data intensifies certain surveillance trends\nassociated with information technology and networks, and is thus implicated in fresh but fluid configurations. This is\nconsidered in three main ways: One, the capacities of Big Data (including metadata) intensify surveillance by expanding\ninterconnected datasets and analytical tools. Existing dynamics of influence, risk-management, and control increase their\nspeed and scope through new techniques, especially predictive analytics. Two, while Big Data appears to be about size,\nqualitative change in surveillance practices is also perceptible, accenting consequences. Important trends persist \u00ad the\ncontrol motif, faith in technology, public-private synergies, and user-involvement \u00ad but the future-orientation increasingly\nsevers surveillance from history and memory and the quest for pattern-discovery is used to justify unprecedented access\nto data. Three, the ethical turn becomes more urgent as a mode of critique. Modernity's predilection for certain\ndefinitions of privacy betrays the subjects of surveillance who, so far from conforming to the abstract, disembodied\nimage of both computing and legal practices, are engaged and embodied users-in-relation whose activities both fuel and\nforeclose surveillance.\n",
    "reduced_content": "Original Research Article\nSurveillance, Snowden, and Big Data:\nCapacities, consequences, critique\nDavid Lyon\n Keywords\nSurveillance, privacy, Big Data, control, ethics, Snowden\nIntroduction: Snowden disclosures and\nBig Data\nThe Snowden revelations about National Security\nAgency (NSA) surveillance, starting in June 2013,\nalong with the ambiguous complicity of internet com-\npanies and the international controversies that fol-\nlowed illustrate perfectly the ways that Big Data\nhas a supportive relationship with surveillance.\nWords such as ``bulk data'' and ``dragnet'' and\n``mass surveillance'' more than hint that processes\nreferred to as ``Big Data'' are in play, producing\nexpanded and intensified surveillance. The rapid and\nwidespread adoption of what are called Big Data\npractices signal profound changes for individuals,\nfor the dynamics of both public and private sector\norganizations, for the relation of citizen to state, and\nfor society at large.\nHowever, for a fuller understanding of Snowden's\nrevelations and Big Data surveillance several matters\nhave to be unpacked, not least the questions of the\nsocio-technical character of Big Data, how several of\nthe Snowden revelations demonstrate dependence on\nBig Data techniques and which have a highly significant\nimpact for understanding the character of surveillance\ntoday. Of course, some of what Snowden has revealed\ninvolves targeting but the main focus here is on Big\nData techniques. Beyond this, it is vital to consider\nwhat is meant by the controversial key concepts,\nQueen's University, Ontario, Canada\nCorresponding author:\nDavid Lyon, Queen's University, University Avenue, Kingston, ON,\nEmail: lyond@queensu.ca\nBig Data & Society\nbds.sagepub.com\nCreative Commons CC-BY-NC: This article is distributed under the terms of the Creative Commons Attribution-NonCommercial\n3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use, reproduction and distribution\nof the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages (http://www.uk.\nsagepub.com/aboutus/openaccess.htm).\n``Big Data and surveillance.'' What follows is a pro-\nvocative introduction to some key issues raised by the\nsocial and political realities of this conceptual conjunc-\ntion, prompted by the Snowden revelations.\nBig Data, first, may be best thought of as ``the cap-\nacity to search, aggregate and cross-reference large data\ncourse a range of ideas, practices, metaphors, software,\nand techniques bundled together in those two decep-\ntively straightforward-sounding words. For one thing,\nBig Data practices occur in a variety of contexts\n(Meyer-Scho\nmistake is to imagine that similar kinds of ends and\npossibilities of success are in view whatever the context.\nConsumer marketing, health care, urban policing, and\nanti-terrorism \u00ad to take four popular potential and\nactual application sites for Big Data \u00ad are not the\nsame and practices that may in some respects be accept-\nable in one (say, marketing) may erode rights and deny\nhuman dignity in another (say, anti-terrorism) (Mosco,\nthat is, they are not the same in each area.\nThe second crucial concept is surveillance, that can\nbe understood as any systematic, routine, and focused\nattention to personal details for a given purpose (such\nas management, influence, or entitlement; see Lyon,\nsome tightening for the present purpose. Our task here\nis to examine how far Big Data intensifies certain sur-\nveillance trends associated with information technolo-\ngies and networks (see Bennett et al., 2014), and is thus\nimplicated emerging configurations of power and influ-\nence. Of course, as political-economic and socio-tech-\nnological circumstances change, so surveillance also\nundergoes alteration, sometimes transformation.\nClassically, studies of surveillance suggest that a shift\nin emphasis from discipline to control (Deleuze, 1992;\nHaggerty and Ericson 2000) has been a key trend asso-\nciated with the increasing use of networked electronic\ntechnologies that permit surveillance of mobile popula-\ntions rather than only those confined to relatively cir-\ncumscribed spaces, and depend on aggregating\nincreasingly fragmented data. Surveillance practices\nhave been moving steadily from targeted scrutiny of\n``populations'' and individuals to mass monitoring in\nsearch of what Oscar Gandy calls ``actionable intelli-\nfies this.\nTwo main questions are addressed here: One, in\nwhat ways and to what extent do the Snowden disclos-\nures indicate that Big Data practices are becoming\nincreasingly important to surveillance? Queries about\nBig Data practices in relation to surveillance and\npublic concern about the activities of the NSA predate\nSnowden, of course (Andrejevic and Gates, 2014).\nBut Snowden's revelations have brought them into\nthe public eye as never before. Two, if Big Data is\ngaining ground in this area, then how far does this indi-\ncate changes in the politics and practices of surveil-\nlance? Are new trends, or the augmentation of older\nones, visible here? We shall explore these questions in\nrespect to the capacities of Big Data and their social-\npolitical consequences before commenting on the kinds\nof critique that may be appropriate for assessing and\nresponding to these developments.\nThe Snowden disclosures\nThe first item revealed by Edward Snowden on 6 June\n2013 and published in The Guardian (UK) was that the\nNSA, using an order from the Foreign Intelligence\nSurveillance Court (FISC), had required the telecom-\nmunications giant Verizon to hand over metadata from\nmillions of American's phone calls to the Federal\nBureau of Investigation and the NSA (Greenwald,\n2013). Verizon itself was forbidden to disclose to the\npublic either the order or the request for customer\nrecords.\nThe next day, articles in the Washington Post and\nThe Guardian detailed how the PRISM program\nseemed to give the NSA direct access to the servers of\nsome of the biggest technology companies, including\nApple, Facebook, Google, Microsoft, Skype, Yahoo,\nand YouTube. Encryption and privacy controls were\ncircumvented with the help of the companies\n(Gellman and Poitras, 2013). In the UK, the Tempora\nprogram appeared to be even more like a dragnet as it\ngave similar access to GCHQ (General\nCommunications Headquarters; the UK partner of\nthe NSA in the ``Five Eyes''). Together, their cable\nand network tapping abilities are called ``Upstream''\nand can intercept any internet traffic. The database\nthat allows the information to be extracted in real\ntime is called ``XKeyscore'' (Lanchester, 2013). The\nrevelations have continued and Snowden himself\nhas said (in early 2014) that some of the most striking\ndisclosures are yet to come.\nThe surveillance practices revealed by Snowden\nshow clearly if not completely that governments \u00ad\nespecially American, British, Canadian, and possibly\nother agencies \u00ad engage in astonishingly large scale\nmonitoring of populations, and also how they do it.\nOn the one hand, the NSA engages contractors to\nshare the burden of their work and also gathers and\nmines user data collected by other corporations, espe-\ncially telephone, internet, and web companies. And on\nthe other, this kind of surveillance also means that the\nNSA and similar agencies watch for cookies and log-in\ninformation. They thus use data derived from the use of\ndevices such as cell phones or geo-locating social media\n2 Big Data & Society\nsites. What users unknowingly disclose on those plat-\nforms \u00ad such as Facebook or Twitter \u00ad or when using\ntheir phones, is usable data for ``national security'' and\npolicing purposes. But more importantly from a Big\nData perspective, metadata (see the discussion below)\nrelating to users is gleaned without their knowledge\nfrom the simple use of these machines. There are thus\nat least three significant actors in this drama, govern-\nment agencies, private corporations and, albeit unwit-\ntingly, ordinary users.\nWhat holds these groups together, in a sense, is the\nsoftware, the algorithms, the codes that allow users'\ndata to be systematically extracted or disclosed, ana-\nlyzed, and turned into what the data collectors and\nothers, such as the NSA, hope will be actionable\ndata. In other words, it is the (big) data practices that\ndifferent kinds of operations have in common. As\n`` . . . NSA targets the communications of everyone . . . ''\nthen `` . . . filters, analyzes, measures them and stores\nthem for periods of time simply because it's the easiest,\nmost efficient and most valuable way of achieving these\nends'' (Greenwald et al., 2013). The NSA thus depends\non codes, the algorithms, plus the witting or unwitting\ncooperation of both telephone and internet corpor-\nations in order to do surveillance. Individual users\nmay play a part, too, but their role is hardly one of\nconscious actors in the drama. This already goes\nbeyond what many once imagined was direct and spe-\ncifically targeted relationships by state agencies of indi-\nviduals, to mass surveillance, dependent on a close\nliaison with corporate bodies and on the self-recording\ndevices used in everyday communications and\ntransactions.\nThe gathering of national intelligence in the U.S. is a\nmammoth undertaking, worth over US$70 billion per\nyear (FAS, 2014) and involving extensive links with\nuniversities, internet companies, social media, and out-\nside contractors \u00ad such as Booz Allen Hamilton that\nemployed Edward Snowden and from which Snowden\nillegally conducted his removal of sensitive data. If\nnothing else, the economic value of these operations\nindicates how much emphasis is placed on data process-\ning by government agencies and in turn by global cor-\nporations. But what kinds of data are sucked up so\nvoraciously by these organizations with such sophisti-\ncated processing power?\nThe word that has perhaps appeared most in relation\nto the Snowden revelations is ``metadata.'' This term\nrefers \u00ad rather imprecisely \u00ad to the ``data about data''\nsuch as the IP address, the identity of the contact, the\nlocation of calls or messages, and the duration of the\ncontact. However, metadata takes many forms, well\nbeyond communications. For example, automatic\nlicense plate recognition systems or word-processing\nprograms also generate metadata (Newell, forthcom-\ning). While specific cases of monitoring the content of\nphone calls and examining text messages exist as well,\nthe extremely large-scale collection and analysis of\nmetadata characterizes many of the disclosures about\nthe kinds of activities with which the NSA is engaged.\nWhen the Snowden revelations began in June 2013,\ngovernments and agencies were quick to dismiss them\nby downplaying the significance of metadata.\nIn the U.S., the collection of metadata was permitted\ndata program'' but it is unclear how far similar such\nprograms extend to other countries such as Canada or\nthe UK. However, it was revealed in 2014 that the\nCanada Border Services Agency made 19,000 requests\nfor subscriber data in one year but this and other\nrelated Canadian agencies are under no statutory\nrequirement to say how often such requests are made\nor for how much data (Freeze, 2014). More specifically,\na program that featured in the news media as Canada's\nCSEC (Communications Security Establishment of\nCanada) collecting data from airport Wifi systems\nwas actually a general means of identifying travel pat-\nterns and geographic locations using ID data (that is,\nmetadata) in conjunction with a database of IP\naddresses supplied by the company Quova over a\ntwo-week period in January 2014. What this shows is\nhow data are analyzed, rather than just the fact of its\ncollection (Schneier, 2014). Such data may be used, for\ninstance, to set up an alarm when a ``suspect'' enters a\nparticular hotel, or to check on someone \u00ad a kidnapper,\nmaybe \u00ad who may have repeatedly visited a particular\nlocation. But it takes little imagination to think of other\npotential uses for such datasets.\nThis is why security critic Bruce Schneier cuts\nthrough the obfuscations to state unequivocally that\n``metadata is surveillance.''1 As he also observes,\nwhile the mass media accounts focus on what surveil-\nlance data are being collected, the most significant ques-\ntion is how the NSA analyzes those data. On the one\nhand, the nearly five billion cell phone records collected\nby the NSA each day by tapping into cables that con-\nnect mobile networks globally can reveal personal data\nabout where users are located, anywhere in the world.\nThe NSA can attempt to track individuals to private\nhomes and can also retrace earlier journeys, whenever\nthe phone is on, because phones transmit location data\nwhether or not they are in use. On the other hand, the\nNSA also analyzes patterns of behavior to reveal more\npersonal information and relationships between differ-\nent users (Gellman and Soltani, 2013). The latter is\nmore subtle, but in the Big Data world, more\nsignificant.\nThese pattern-seeking processes are the ones where\nBig Data practices really come into their own.\nFor example, the NSA program, known as\n``Co-Traveler,'' uses highly sophisticated mathematical\ntechniques to map cell phone users' relationships,\nsuperimposing them on others to find significant inter-\nsections and correlations. Co-Traveler is meant to\nsearch for the associates of foreign intelligence targets,\nalthough domestic users' data are also garnered ``inci-\ndentally'' and the foreign sweeps are so broad that they\nare bound in include Americans on a mass scale. This is\nthe searching, aggregating, and cross-referencing pro-\ncess referred to above, that characterizes some of the\ntechnical aspects of Big Data.\nSeveral key surveillance trends (see Bennett et al.,\n2014) are augmented by the advent of Big Data. Just\ntwo are mentioned here. One is that contemporary sur-\nveillance expands exponentially \u00ad it renders ordinary\neveryday lives increasingly transparent to large organ-\nizations. The corollary, however, is that organizations\nengaged in surveillance are increasingly invisible to\nthose whose data are garnered and used. This ``para-\ndox'' is deepened by the advent of Big Data (Richards\nand King, 2013). A second trend is that the expanding\nsecuritization of daily life prompts the use of extended\nsurveillance, from neighborhoods and travel arrange-\nments to large sporting and entertainment events. The\nquest of ``national security'' breeds Big Data, particu-\nlarly through efforts to preempt security breaches by a\nform of anticipatory surveillance described, somewhat\nvaguely, by the Department of Homeland Security as\n``connecting the dots.''\nOf course, the surveillance implications of the use of\nBig Data \u00ad such as using metadata \u00ad are just one dimen-\nsion of new ways of structuring information in a digital\nage. The present task is not to catalogue potentially\nbeneficial aspects of Big Data but rather to focus atten-\ntion on what sorts of surveillance issues are raised \u00ad\nespecially ones that prompt civil liberties or privacy\nquestions \u00ad in new ways by this re-structuring of\ninformation.\nBig Data surveillance\nThe Big Data/surveillance link was recognized by US\nfor a ``comprehensive review of Big Data and privacy''\nfollowing the Snowden leaks (White House, 2014). It\nwas further acknowledged when the US proposed new\nrules governing bulk data collection by the NSA of the\nphone calling habits of Americans (Savage, 2013). The\nonce-secret bulk phone records problem was what had\nmost alarmed privacy advocates when the Snowden\nleaks began in 2013 and now the president proposed\nthat it should be curtailed, along the lines of a dated\nEuropean data retention directive. But the media rhet-\noric surrounding this suggests a fairly conventional\nunderstanding of surveillance that does not fully\ngrasp the Big Data aspects of the bulk phone records.\nSurveillance constantly undergoes change and is cur-\nrently being reconfigured in several respects, some of\nwhich alter its character. In particular, different kinds\nof data are now being captured and used in new ways,\nwhich prompts some to distinguish between surveil-\nlance as targeted practices over against fresh form of\ndataveillance (van Dijck, 2014). Not only are data cap-\ntured differently, they are also processed, combined,\nand analyzed in new ways. Social media that appeared\non the scene at roughly the same time as responses to 9/\n11 boosted the ``surveillance state,'' are now the source\nof much data, used not only for commercial but also for\n``security'' purposes. The buzzword is ``datafication,''\nwhich points to the ways that for many businesses,\nthe information infrastructure is their heart\n(Bertolucci, 2013). Ordinary users' social activities are\nsucked up as data, quantified and classified, making\npossible real-time tracking and monitoring.\nIt goes beyond this, however. With Big Data prac-\ntices, for example, personal data \u00ad now including iden-\ntifiable metadata \u00ad are not collected for certain limited,\nspecified, and transparent purposes, which are the goals\nof data protection and privacy advocates. Rather, Big\nData reverses prior policing or intelligence activities\nthat would conventionally have targeted suspects or\npersons of interest and then sought data about them.\nNow bulk data are obtained and data are aggregated\nfrom different sources before determining the full range\nof their actual and potential uses and mobilizing algo-\nrithms and analytics not only to understand a past\nsequence of events but also to predict and intervene\nbefore behaviors, events, and processes are set in\ntrain. Both corporate and government aspects of this\nraise questions for analysis and critique.\nPreemptive approaches in security and policing, that\ndepend on prediction, have been growing steadily since\nare a bureaucratic incentive to over-collect data, espe-\ncially in security and law enforcement. Perhaps even\nmore important to cost-cutting government depart-\nments, the falling cost of processing power is a strong\ninducement to use new data analytics in a number of\nfields (Bankston and Soltani, 2014). It is not hard to\nfind extravagant promises that real-time data analytics\nwill transform aspects of retail, manufacturing, health\ncare, and public sector organizations. But despite the\ndetermined and well-informed activities of data protec-\ntion and privacy advocates over a number of years and\nin several countries, any countervailing focus on the\ncontribution Big Data may make to reducing demo-\ncratic freedoms, reconfiguring privacy and indeed, rede-\nfining the role of information in contemporary life, is\nstill muted and marginalized.\n4 Big Data & Society\nThus stated, the problem is that basic alterations in\nsurveillance and legal expectation are occurring in a\ncontext that celebrates rather than carefully assesses\nBig Data. The differences between Big Data applica-\ntions are crucial here. For example, Ian Kerr and\nJessica Earle (2013) distinguish helpfully between\nthree kinds of prediction: consequential, where one\naim is to help clients or users to choose what is likely\nto be beneficial to them, preferential, illustrated by mar-\nketers trying to second guess our desires from our\nbrowsing behavior, and preemptive, where is a deliber-\nate intention to reduce someone's range of options. In\nthe context of law and justice, the latter raises funda-\nmental issues of privacy and due process. Where legal\nsystems are based on an after the fact system of penal-\nties or punishments, the turn to one based on future-\noriented preventative measures is of huge import, not\nleast for those rendered unable to understand or con-\ntribute meaningfully to the process.\nThis is why the Snowden revelations offer a unique\nopportunity to grapple with Big Data surveillance in a\nsystematic way. Of course, this phenomenon did not\nappear overnight, fully formed. It represents the con-\nfluence of many streams and is itself better thought of\nas a fluid form that constantly changes its character\nthan as a relatively solid set of surveillance relations\nthat positions and governs the subject in a disciplinary\nfashion. Introducing the language of surveillance to Big\nData discussions challenges the practices often\ndescribed in epistemologically nai\u00a8ve and politically dis-\ningenuous ways. But equally, examining how Big Data\npractices are affecting the character of contemporary\nsurveillance obliges students of surveillance to recon-\nsider what is happening, particularly across different\nsurveillance domains.\nCapacities\nThe term ``Big Data'' suggests that size is its key fea-\nture. Massive quantities of data about people and their\nactivities are indeed generated by Big Data practices\nand many corporate and government bodies wish to\ncapitalize on what is understood as the Big Data\nboom. As with many other single aspects of this phe-\nnomenon, however, the idea of size both yields import-\nant clues and, on its own, can mislead. While the\ncapacities of Big Data practices (including the use of\nmetadata) intensify surveillance by expanding intercon-\nnected datasets and analytical tools, this tells only a\npart of the story.\nDrawing on a number of sources, Rob Kitchin\nargues that Big Data has several crucially important\ncharacteristics: huge volume, consisting of terabytes\nor petabytes of data; high velocity, being created in or\nnear real time; extensive variety, both structured and\nunstructured; exhaustive in scope, striving to capture\nentire populations of systems; fine-grained resolution,\naiming at maximum detail, while being indexical in\nidentification; relational, with common fields that\nenable the conjoining of different data-sets; flexible,\nwith traits of extensionality (easily adding new fields)\nand scalability (the potential to expand rapidly)\nData sources may be thought of under three main\nheadings each of which may be applied in surveillance\ncontexts: directed, automated, and volunteered\n(Kitchin, 2014, forthcoming). In the first, a human\noperator obtains the data, obvious examples being\nCCTV systems or police seeking, say, vehicle ownership\nrecords. In the second, the data are gathered without a\nhuman operator intervening; traces are recorded rou-\ntinely from transactions with banks or consumer out-\nlets and communications, using cellphones above all. In\nthe third, data are in a weak sense ``volunteered'' by the\nuser who gives out information on social media sites\nand the like. Of course, social media users do not neces-\nsarily think of their activities in terms of volunteering\ndata to third parties (Trottier, 2012) but this is an\naccurate way of understanding surveillance data gath-\nering in this context.\nClearly, one of the surveillance trends amplified by\nBig Data practices is the increased integration of gov-\nernment and commercial surveillance. Big Data may\nalso be thought of in terms of its promised economic\nrewards. As Bruce Schneier observes, the term Big Data\ncould be viewed as placing today's data operations in\nthe same kind of category as ``Big Pharma'' or ``Big\nOil'' (Schneier, 2012), where the corporate strategy\nbehind the new practice is the decisively significant\nfactor and when ``big'' refers to the economic worth\nof the data commodity. This dimension is very import-\nant to any analysis, as Viktor Mayer-Scho\n\u00a8 nberger and\nKenneth Cukier (2012) show. They argue that the ``Big\nData revolution'' is based in part on new data manage-\nment techniques that permit analysis beyond ``rows and\ntables'' to dispensing with ``hierarchies and homogen-\neity'' but also on internet companies collecting vast\ntroves of data and having ``a burning financial incentive\nto make use of them'' such that they became leading\nusers of the latest processing technologies, sometimes\nsuperseding others that had decades more experience\nUnderstood thus, the capacities of Big Data surveil-\nlance take on some new meanings. The enthusiasm for\ncommercial uses of Big Data is shared by those in the\nsecurity field, thus stimulating further integration of\nthese activities. In a Big Data context, the same data\nare increasingly used for different purposes. This is\nmore than a change of context that might alter how\ndata subjects might construe their privacy or how\nlegal limits on secondary use might be stretched.\nRather, the same commercial data may be given new\nmeanings in the security realm, combined, and con-\nnected in novel ways. Thus the capacities of Big Data\nmay also be seen to allow new forms of inferential rea-\nsoning that Louise Amoore calls ``data derivatives''\n(2011). This is of critical importance in the security-\nsurveillance context because such associations and\nlinks, however trivial and improbable, may be given\nnew meanings that are cut off from the values that\nonce made sense of them and the identifiable subjects\nwhose activities generated them in the first place.\nConsequences\nAs with the capacities of Big Data, given the current\nvolatility of the field it is hard to tell exactly what the\nconsequences of widespread adoption of Big Data will\nbe for surveillance. Important trends will probably per-\nsist, including the quest for control through surveil-\nlance, an almost nai\u00a8ve faith in technology that\ninhibits the search for low-tech or no-tech alternatives,\npublic-private synergies that benefit government, cor-\nporation \u00ad and sometimes citizens \u00ad and the involve-\nment of internet users in surveillance processes as\n``prosumers.'' At the same time, the reinforced future-\norientation is likely to exacerbate the severance of sur-\nveillance from history and memory and the assiduous\nquest for pattern-discovery will justify unprecedented\naccess to data. It is likely that existing dynamics of\ninfluence, risk-management, and control will increase\ntheir speed and scope through new techniques, espe-\ncially predictive analytics, but what specific trends will\nbe accentuated as Big Data practices expand?\nThere are three key ways in which commitment to\nBig Data practices seem to be shifting the emphasis of\nsurveillance and this is clear in the Snowden disclos-\nures. They are stated here and discussed below. First,\ngiven that Big Data involves the amplified use of algo-\nrithms for analytics, an increasing reliance on software\nfor surveillance and a concomitant reliance on what\nmight be called a ``human-algorithm'' relationship\nthat shapes the ways that human subjects are treated\nby surveillance systems. Such automation tends to\ndiminish opportunities for discretion within systems.\nSecond, Big Data practices increasingly tilt surveillance\noperations to focus on the future more than on the\npresent and the past. In the context of neo-liberal gov-\nernance, this anticipation is likely to place more weight\non surveillance for managing consequences rather than\nresearch on understanding causes of social problems\nsuch as crime and disorder. The third area is adaptation,\nthe propensity for analytics to be treated as if methods\ncan be transferred successfully and with little risk from\none field to another. The enthusiasm for Big Data\n``solutions'' may lead to the inappropriate transfer of\ntechniques from one field to another.\nAutomation\nThe combination of readily available software and its\nrelatively low price is an incentive to choose technical\nsolutions over more labor-intensive ones in surveillance\npractices as in other fields (see Bankston and Soltani,\n2014 on how this affects police location tracking). This\nmeans that automated surveillance will become an\nincreasing possibility. At the same time, greater data\nstorage capacity means that larger and larger amounts\nof data are collected before their use has been ascer-\ntained (Savage and Burrows, 2007), the consequences\nof which are unknown as yet. What we do know, how-\never, is that who makes decisions about algorithms and\ndatasets will have the capacity to make a difference in\nthese emerging scenarios (Glennon, 2014).\nThe automation of surveillance must also be seen as\nan aspect of the way that surveillance occurs as a rou-\ntine management procedure. Evelyn Ruppert rightly\nwarns against panoptic panics regarding government\nsurveillance that suggest sinister state attempts to\nkeep close watch on all citizens. The automating of\nsurveillance is part of the kinds of cost-cutting and effi-\nciency exercises that have dominated the public admin-\nistration for decades. So far from there being an ``all-\nknowing state, what we have instead is a plethora of\npartial projects and initiatives that are seeking to har-\nness ICTs in the service of better knowing and govern-\nAnd if the process is not panoptic then it is not dir-\nectly disciplinary either. The ``modulating'' controls\ndescribed briefly but evocatively by Gilles Deleuze\n(1992) are more in view here than direct concern with\ndiscipline or with the behavior of individuals. Ruppert\nargues that databases work with an ontology of sub-\njects that creates profiles \u00ad data bodies or data doubles\n\u00ad based on their activities, connections, performances,\ntransactions, and movements that relate to govern-\nment. These data ``make up'' the people in the system\npurview, in ways that are constantly shifting, fluctuat-\ning. In this way, a neo-liberal logic of control fits neatly\nwith the ways that individuals are ``made up'' by data.\nIf the role of ``data doubles'' in determining the life-\nchances and choices of individuals was a major concern\nof an earlier phase of surveillance studies (see e.g. Lyon,\n2001) then its Big Data magnification will likely inten-\nsify such concerns, both analytically and in terms of\ncritique and political contestation. ``Data doubles''\nbecomes a double-entendre.\nThe kind of ``soft biopower'' (Cheney-Lippold, 2011:\n166) associated with Big Data is at work in marketing\nas in parallel ways to those ``harder'' forms found in\n6 Big Data & Society\n``national security.'' Marketing moved from demo-\ngraphic (Gandy, 1993) to more psychographic cate-\ngories in the 1990s and then as marketing went\nonline, was able to use search histories to create further\nconsumer clustering, superimposed on the former cate-\ngories. Algorithms are used increasingly to target par-\nticular kinds of consumers in relation more to real-time\nweb use than to the older categories of census and post-\ncode. This contributes to cybernetic-type control, where\nwhat is assumed to be normal and correct behavior is\nembedded in circuits of consumer (or employment,\nhealth, or education) practices. This is also significant\nfor what Snowden has revealed, as we shall see.\nThis argument also suggests the need for a shift in\nfocus from some accounts that refer more directly to\norganizations and individuals, to ones that acknow-\nledge \u00ad as privacy advocates and others have argued\nfor some time \u00ad that online subjects are also difficult\nto define, are not really amenable to the kinds of indi-\nvidualist characterizations common in some ``privacy''\ndiscourses and are hard to connect with the kinds of\nactors that might be called upon to raise questions\nabout Big Data surveillance in the political realm.\nThere exists, of course, a recognition of privacy in\nhuman rights codes and constitutional documents but\nkeeping these in view is a constant challenge.\nThe Deleuzian approach appears to fit the surveil-\nlance-analysis bill in some ways, because it acknow-\nledges the shift from just the ``state'' to other\nsurveillance agencies, from ``individuals'' to ``divi-\nduals'' and from discipline to control. As Mattelart\nand Vitalis observe, a Deleuzian approach also high-\nlights the mobile and invisible nature of much surveil-\nlance and the ways that it depends on the involuntary\nparticipation of individuals \u00ad metadata again \u00ad and the\npurpose of anticipating behavior (Mattelart and Vitalis,\n2014) that is overwhelmingly evident in the Snowden\ndisclosures. At the same time, a Deleuzian approach is\nmisleading if one imagines that the world of top-down\ngovernment-based surveillance is a thing of the past.\nSuch practices now appropriate data from the ``rhi-\nzomic'' forms of surveillance described by Deleuze.\nSurveillance in the era of Big Data, then, does not\nfocus only on the body or on a population but on def-\ninitions to which we may contribute as part of our daily\nonline interactions. It ``makes up'' the data double,\nDeleuze's ``dividual'' and that entity then acts back\non those with whom the data are associated, informing\nus who we are, what we should desire or hope for,\nincluding who we should become. The algorithms grip\nus even as they follow us, producing ever more infor-\nmation to try to make the user data more effective.\nUsers discover, one might say, that the price of our\nfreedom in both political and consumer contexts is\nour shaping or conditioning by algorithms.\nAnticipation\nThe political-economic and socio-technical responses to\n9/11 helped to change the ``tense'' of surveillance in\nsome significant ways (Genosko and Thompson,\nniques have increasingly turned towards attempts to\npredict and preempt future developments but the antici-\npatory approach was racheted up some further notches\nas early forms of data analytics were brought into play.\nThe frequently advertised notion of ``connecting the\ndots'' was predicated exactly on what might be called\nanticipatory analytics, where the aim of amassing and\nmining data was ``knowledge discovery,'' of finding\npatterns in data that would point a suspicious finger\ntowards persons and groups whose associations or\ncommunications added up to a ``person of interest''\nprofile. In other words, not merely what they might\nbe but what they might become, was a significant\nfactor in assigning riskiness from which it was a short\nstep to suspicion (Kerr and Earle, 2013).\nBig Data builds on these already existing modes of\nanticipatory surveillance in an attempt to create new\nknowledge using the statistical power of large numbers\nto help grasp the fragmented details of individual lives.\nThe anticipatory approach is common across the range\nof Big Data applications. Google Now, for example,\nuses just this method to draw on a vast concatenation\nof relatable data in order to alert specific users to things\nthat may have great import for them, from warning\nthem about delayed flights to offering early diagnoses\nof flu (Regalado, 2013). Everyone collects and trans-\nmits much data, especially using smart phones, but\nalso through using any digital device. However, what\nLazar calls ``Big Data hubris'' appears when it is\nassumed that Big Data \u00ad in this case, based on user\nsearches for information about flu \u00ad can substitute for\nrather than supplement conventional modes of analysis.\nAs it happens, the conventional forms of analysis still\nseem to have a high degree of validity compared with\ncrowd-sourced methods (Butler, 2013). If this is true of\nepidemiology how much more care should be taken\nwith risk analysis relating to (another rather elastic con-\ncept) ``terrorism.'' In this case, as opposed to that of flu,\nthere is no regular presentation of accurate, identifiable,\nand actionable intelligence. The term itself is politi-\ncized, it is well-nigh impossible to distinguish between\na violent and non-violent activist, and with so few facts,\ncorrecting for false positives and negatives is both rick-\nety and risky.\nThe situation is exacerbated by the fact that antici-\npatory approaches are less concerned with the overall\npicture of a given individual as with ``premediating and\npinpointing potential dangers'' (de Goede, 2014). The\nproblem is that profiles may be built and inferences\nmade about individuals with privacy regulations and\ndata protection in place. The conventional links\nbetween data and the individual have become tenuous\nbe associated with Deleuze's ``dividual''? Much filtering\nand analysis is done, as noted above, before identifiable\nindividuals come in sight. She further suggests that the\nharms are therefore to the `` . . . associational life, to the\npotentiality of futures that are as yet unknowable'' and\nto the very possibility of making a political claim (111).\nScience-Technology-and-Society approaches are\nimportant for indicating the importance of an onto-\nlogical approach to the making-up of data subjects\nbut this by no means should condone complacency\nabout the ways that subject positions are still imbri-\ncated with neo-liberal notions of, for example,\n``deserving poor'' that still characterize some welfare\nsystem use of Big Data practices (Maki, 2011) or the\nprofiling of ``bad guys'' (why do intelligence and poli-\ncing agencies persist in using such terms?) in anti-ter-\nrorism units. As other studies have indicated, such\ninvidious categories not only persist but are also ampli-\nfied as greater reliance is placed on automated (see e.g.\nmethods. One has to ask, what do the increasing\nflows of those data between different kinds of organiza-\ntions mean for the reproduction of social distinctions \u00ad\nclass, gender, ethnicity \u00ad and for public accountability\nof data processing bodies?\nBig Data practices also encourage the use of auto-\nmated decision-making and thus downplay the role of\ndiscretion (see also Ruppert). Seen in classic liberal-\nlegal terms, automated decisions can easily deprive\nindividuals of their liberty and property, that trigger\nin the US the safeguards of the Due Process Clauses\nof the Fifth and Fourteenth Amendments. For exam-\nple, computers can terminate individuals' Medicaid\nbenefits, impairing a statutorily-granted property inter-\nest (see Citron, 2008). Innocent individuals may be\ndesignated as dead-beat parents, resulting in lost prop-\nerty, revoked driver's and professional licenses, and\ninjury to their reputations. The US federal govern-\nment's ``No Fly'' data matching program labels some\nindividuals as potential terrorists, resulting in the post-\nponement or denial of air travel, both significant\nimpairments of liberty rights. Automation, suggests\nDanielle Citron, will be a driving force in the retreat\nfrom the discretionary model of administrative law.\nNonetheless, due process does mean that citizens or\nconsumers can push back against such automation\nwhen it precludes or limits understanding or responding\nto suspicions, charges, or cut benefits. However, such\nan assumption depends on those citizens and con-\nsumers knowing what is happening, which Big Data\napproaches make very difficult if not impossible.\nAdaptation\nWe noted earlier that many Big Data practices are\ncommon across different platforms. In this section,\nhowever, we indicate that what might under some cir-\ncumstances be acceptable for Google may be highly\nunacceptable where the NSA is concerned. Google,\nafter all, holds the contents of much of the visible inter-\nnet in its data centers and this includes satellite images,\nground level photos of the built environment in a geo-\nspatial database indexed to individuals and organiza-\ntions. The electronic activities of hundreds of millions\nof people, including emails and search requests are also\nknown to Google.\nAs Sean Gallagher (2013) observes, what the NSA\ndoes is essentially similar, capturing call metadata and\ngaining access to information like that of Google\nthrough systems like Tempora and possibly PRISM.\nBut the additional factor is that the NSA, using the\nForeign Intelligence Surveillance Act, can follow up\n``exceptions'' with warrants to check on persons of\ninterest. This has been possible for some time, a fact\nfirst exposed by former AT&T employee Mark Klein in\n2005, when he showed how AT&T helped the NSA to\ngain access to its own systems through a splitter that\nfed into the Intelligence Traffic Analyzer. It was also\nshown in 2006 that the NSA used its phone call data-\nbase for social network analysis and, according to\ninformation from Snowden in 2013, call data collection\nof US to foreign numbers is still occurring.\nCuriously, solving just such problems of data storage\nand analysis have been key to the operations of Google\nand Yahoo!, which prompted the NSA to improve on\nGoogle's BigTable systems with a program called\nAccumulo, that has multiple levels of security access.\nIt can also generate near real-time reports from data\npatterns, such as words or addresses from a range of IP\naddresses, right across the internet. Through what are\ncalled ``iterators,'' emergent patterns are constantly\nreported back to the NSA so that it can ``visualize''\nlinks between entities based on relationships and attri-\nbutes. In this way it resembles Facebook's social graph,\nwhich is a global mapping system of users and how they\nare related to each other; it is the largest social network\ndataset in the world. PRISM offers online NSA access\nto cloud providers, primarily seeking metadata, which\ncompletes the circle. The NSA's new data center in\nUtah with its huge data-storage capabilities will\nenable the expansion of PRISM-type real-time internet\nsurveillance (although being classified, the precise\npurposes are unpublished).\nOne question for privacy advocates and others is\nwhether or not these surveillance operations are legal:\nthey contend that such programs violate laws designed\nto protect the liberty and privacy of citizens.\n8 Big Data & Society\nThe assurances given, in the US and other countries,\nthat citizens are not targeted by these systems, have\nfailed to reassure citizens and privacy advocates. It is\nalso clear that some data are ``incidentally'' collected on\nthe whereabouts of domestic cellphones. Such data may\nbe used to map users' relationships, as noted earlier in\nrelation to CoTraveler (see Gellman and Soltani, 2013).\nIt is crucial to distinguish between different kinds of\nconsequences. As noted above, marketing uses of Big\nData analytics cannot simply be extended to\nanti-terrorist pre-emption. Marketers will be satisfied\nwith results that are accurate only in a relatively small\nproportion of cases, just because the cluster around\nthat group will also be profitable, albeit to a lesser\nextent. The economic harms to individuals from such\ninaccuracy, though potentially serious, are seldom con-\nsidered by marketers (see e.g. Gandy, 2013; Turow,\n2012) and are in some contexts fairly inconsequential\n(Amazon suggesting some books in which readers have\nno interest, for example). But the attempt to find ter-\nrorist ``needles'' in Big Data ``haystacks'' is fraught\nwith palpable problems. Such ``needles'' are, generally\nspeaking, clever, determined, and imaginative in their\nattempts to evade detection. The needle-and-haystack\nargument carries with it a high probability of false posi-\ntives, which do matter immediately and intensely\nbecause the likelihood is high of harm to specific\npersons.\nCritique\nThe question of Big Data, understood in relation to the\nSnowden disclosures, has generated unprecedented\npublic interest in surveillance in many countries\naround the world. While technical and legal responses\nhave been made and while at the level of civil society\nmuch activity is evident, particularly demanding\naccountability \u00ad and, where appropriate, abolition of\nsome programs \u00ad from the NSA and its cognate agen-\ncies, less progress has been made on what might be\ncalled a broad ethical front. Yet the questions raised\nare profound ones for which there are no ready answers\nand thus, I suggest that an ethical turn becomes more\nurgent as a mode of critique. This is so at several levels,\nbut particularly in the kinds of ways that Snowden him-\nself indicates through his repeated questions about\n``what kind of society do we want?''\nWe began with the question of capacity which is\nreflected in the popular metaphors used about Big\nData, notably the handily alliterating ``data deluge.''\nThe metaphors associated with Big Data are revealing\nfor the hopes and fears associated with Big Data. As\nDeborah Lupton (2013) has observed, many are asso-\nciated with liquidity. Unlike the metaphors first\nadopted for computer technologies, that invoke a\n``natural'' world of the web, cloud, bug, virus, mouse,\nand spider, Big Data tropes ``relate to streams, flows,\nleaks, rivers, oceans, waves'' but also to floods or tsu-\nnamis that may seem to threaten to swamp or drown\nus. They are potentially uncontained, out-of-control.\nBut there is more to the liquidity issue than metaphors\nsuch as the data deluge.\nUnder the heading ``liquid surveillance'' I discussed\nwith Zygmunt Bauman the ways in which data flow\nincreasingly freely within and between containers and\nin particular the ways that digital surveillance has a\nseemingly symbiotic relationship with the kind of\nliquidity visible in contemporary social, political, and\neconomic arrangements, that are often short-term, fis-\nsiparous (Bauman and Lyon, 2013). They also query\nthe kinds of ``blockages and resistances, the solidities\nthat may impede the fluid circulation of data'' (Lupton,\n2013) that tend to be omitted from the free-flow-of-data\naccounts. The liquidity of surveillance is as signifi-\ncant in the social and political realm as at the level of\ndata-flows.\nOne theme of Liquid Surveillance is the need for\nproperly ethical practices. Big Data is currently domi-\nnated by commercial and governmental criteria and\nthese are often met with technical demands (for better\nencryption for example) or legal demands (for legisla-\ntion relevant to today's technologies). Privacy advo-\ncates and internet activists also try to promote new\npolitical approaches to emergent tendencies such as\nBig Data. But a key reason why those commercial\nand governmental criteria are so imbricated with Big\nData is the strong affinity between the two, particularly\nin relation to surveillance. Big Data represents a con-\nfluence of commercial and governmental interests; its\npolitical economy resonates with neo-liberalism.\nNational security is a business goal as much as a polit-\nical one and there is a revolving door between the two\nin the world of surveillance practices (Ball and Snider,\nProperly ethical practices are at a relative disadvan-\ntage for several other reasons as well. Not many ethi-\ncists spend time thinking about the complexities of the\ninternet, social media, or Big Data and many of those\nat the forefront of the Big Data field seem to have little\ntime for ethics except as a minor, residual concern (see\nNarayanan and Vallor, 2014). The imperatives for Big\nData approaches come from a belief in the immense\npower of technology \u00ad can Google really track and pre-\ndict the spread of flu faster than centers for disease\nalong with the capacity to analyze vast quantities of\ndata at steadily shrinking unit costs. But just as in the\nGoogle flu example, questions must be asked about\nhow good are the surveillance data and the modes of\nanalysis?\nHow data are generated and framed always has deci-\nsive effects on the final outcomes of analysis. As Lisa\nGitelman reminds us, ``raw data is an oxymoron''\n(2013); data have always been ``cooked'' as Geoff\nBowker says in the conclusion of Gitelman's book.\nTerms such as metadata, so crucial to Big Data surveil-\nlance, lack clear definition, even though it can generally\nbe distinguished from data such as the content of phone\ncalls or emails. Yet those ill-defined metadata are used,\nconstantly, by security and intelligence agencies, and the\npatterns revealed by the algorithms used to filter them\nrelate back to the purposes that shape the data in the first\nplace and forward to those affected by the designation of\ngroups that may contain persons of interest.\nThe range of ethical issues relating to Big Data sur-\nveillance is considerable, but from what has been dis-\ncussed in the foregoing, may be clustered as privacy,\nsocial sorting, and preemption.\nGiven the reliance on western liberal legal traditions\nit is hardly surprising that public debate generally com-\nmences around the question of privacy. Understood as\na human right, it underlies aspects of democratic polity,\nsuch as freedom of expression. Often understood in the\npost-Snowden era as relating to control of communica-\ntions about oneself, it is clearly a threatened value if not\n\u00ad according to some \u00ad a forlorn hope. Following the\nabove argument, though, it is vital that an ethics of Big\nData practices be found that deals with the problem of\nthe increasing gap between data and individuals\nthe preeminent mobilizing concept for opposition to\ninappropriate, disproportionate or illegal surveillance,\nthe efforts of those who propose technical limits such as\nencryption or de-identification or who would re-infuse\nthe concept with content appropriate to a Big Data\nworld are certainly welcome.\nAs far as social sorting is concerned, this is a concept\nthat alerts us to several related practices that produce\nuneven and unequal outcomes when the supposedly\nneutral and illuminating techniques of Big Data \u00ad\nespecially predictive profiling \u00ad are applied to perceived\nsocial and political problems. This connects surveil-\nlance both with modern bureaucratic practices and\nalso, under the sign of security, with insurance logics\nthat see security as procurable through intelligence\ngathering, identification, and tracking (Lyon, 2007;\nZedner, 2009). Its outcomes \u00ad amplified in Big Data\ncontexts \u00ad are above all the growth of categorical sus-\npicion (the parallel in consumer surveillance, is what I\nterm ``categorical seduction'' Lyon, 2007). This in turn\nencourages a consequentialism that departs from earlier\nnotions of proportionate punishment to deterrence\nand incapacitation. Together with a ``penal populism''\nthat calls for public protection, reinforced by media-\nenhanced perceptions of risk, time-honored\ncommitments to the presumption of innocence, or\nproof beyond reasonable doubt are eroded (Zedner,\nThirdly, an emphasis on preemption takes the actu-\narial logic one stage further, connecting with what was\nsaid above about how Big Data fosters an anticipatory,\nfuture tense approach to surveillance. Again this is not\na new development in surveillance. Risk-management\nin particular has encouraged such anticipatory govern-\nance for several decades. But the availability of Big\nData techniques encourages an intensified future-orien-\ntation in practice. So the possibility that, because of\ncertain data fragments, the data-body may be thought\nto have a propensity to certain behaviors that are not\nyet evident, leads to some action. The data have effects;\nthey are, as Rita Raley says, ``performative.'' Following\nHaggerty and Ericson's (2000) Deleuzian discussion of\nthe surveillant assemblage, Raley points out that,\nthe composition of flecks and bits of data into a profile\nof a terror suspect, the re-grounding of abstract data in\nthe targeting of an actual life, will have the effect of\nproducing that life, that body, as a terror suspect.\nConclusion\nThe main question addressed in this article is in two\nparts: One, in what ways and to what extent do the\nSnowden disclosures indicate that Big Data practices\nare becoming increasingly important to surveillance?\nThe answer, clearly, is yes, they are. Many of the\nmajor Snowden revelations, especially those in which\nmetadata feature prominently, indicate a reliance upon\nBig Data practices. The second question, following on\nfrom the first, is how far does this indicate changes in the\npolitics and practices of surveillance? Are new trends, or\nthe augmentation of older ones, visible here? Again, the\nevidence discussed here suggests strongly that Big Data\npractices are skewing surveillance even more towards a\nreliance on technological ``solutions,'' and that this\nboth privileges organizations, large and small, whether\npublic or private, reinforces the shift in emphasis\ntowards control rather than discipline and relies increas-\ningly on predictive analytics to anticipate and preempt.\nThese questions were explored in respect to the capa-\ncities of Big Data, their social-political consequences\nand the kinds of critique that may be appropriate for\nassessing and responding to these developments. For\nthe first, I argue that ``size'' is not directly the issue\nbut rather that, taken together, the loose cluster of\nattributes of ``Big Data'' make a difference in ways\nthat are hard to generalize. Big Data practices echo\nseveral key surveillance trends but in several respects\n10 Big Data & Society\nthey point to realities that have perhaps been under-\nestimated. One is that, within surveillance studies\nthere has been a general tendency to analyze multiple\nforms of surveillance that are not directly linked with\nstate-based, top-down surveillance of the kind epito-\nmized in George Orwell's Nineteen-Eighty-Four. If\nthis was understood by some to mean that more gen-\neralized \u00ad or, following Gilles Deleuze, ``rhizomic'' \u00ad\nsurveillance spells less state surveillance activity, the\nSnowden revelations are rapidly dispelling that illusion.\nHowever, those revelations, which as I show above,\nindicate an increasing dependence on Big Data prac-\ntices, also lay bare in ways that were known only\nhazily before just how far security and intelligence\nagencies depend on data obtained from the commercial\nrealm. These are consequences that cry out for careful\nconsideration. In a sense, this means that Orwell's bleak\nvision of what tendencies in post-war liberal democratic\npolities could lead to authoritarian surveillance regimes\nwere not mistaken so much as standing in need of com-\nplementary analyses, such as that of his contemporary,\nAldous Huxley, in Brave New World. Big Data prac-\ntices in consumer surveillance are (now literally!)\nco-travelers with those of state surveillance and\ntogether produce the kinds of outcomes around which\nethical debates should now revolve. Indeed, not only\nare they ``co-travelers,'' they also cooperate extensively,\nthe one taking methods from the other, with, as dis-\ncussed above, potentially pernicious results as the ``suc-\ncessful'' methods in one area are applied in ways\ndeleterious of human rights in another. Sadly, little\ntime seems to be spent on such matters in typical com-\nputing studies departments in today's universities,\nwhere all too often notions like privacy and civil liber-\nties are regarded as a nuisance that slows research\ndevelopment (Narayanan and Vallor, 2014).\nIt is these matters in particular that attract critique,\nespecially in relation to anticipatory and preemptive\napproaches common to Big Data mindsets and activ-\nities and amplifying what is a long-term surveillance\ntrend. These fit neatly, of course, with currently inten-\nsifying political styles of neo-liberalism that, with\nregard to ``national security,'' are seen in a list towards\nactuarialism and a consequentialist concern with mana-\nging disorder and crime rather than seeking its causes\nand attempting to eradicate them (Agamben, 2013). Let\nme give two examples. Critically, certain time-honored\nlegal protections such as a presumption of innocence or\nproof beyond reasonable doubt are being eroded within\na number of western societies precisely due to the\ndeveloping reliance on big-data-led beliefs that suspects\ncan be isolated by category and algorithm. Even if one-\ntime ``suspects'' have their names cleared by judicial\nprocess, the fact that Big Data practices exemplified\nin the collect-it-all slogan include retaining data\nindefinitely, it can be hard for persons with a\n``record'' ever to make a fresh start. Data in the\nCanadian Police Information Centre, for example,\nremain there permanently. And when police include\nmental health problems in their records these can lead\nto denial of entry to Canadians trying to cross the\nborder into the US. Attempted suicide calls, for exam-\nple, have been uploaded to international databases with\nSnowden's revelations have done good service in\nshowing how far state-based surveillance extends but\nalso how much it depends on Big Data practices that\nimplicate corporate bodies and connect directly with\neveryday practices of ordinary internet and cellphone\nusers. Ethically, he frequently, and wisely, asks what\nkind of society we want to live in. Is it one marked\nby fear and mutual suspicion, where data are collected\npromiscuously and kept forever, in systems that never\nforget, making forgiveness obsolete and creating much\nto fear even though you have nothing to hide? Is it one\nwhere vulnerability is amplified, democracy diminished\nand where ordinary people are more exposed to organ-\nizations that are themselves more opaque? These are\nquestions that Big Data surveillance obliges us to\nconfront.\n"
}