{
    "abstract": "Abstract\nAs part of their core mission, public health agencies attend to a wide range of disease and health threats, including those\nthat require routine, acute, and emergency responses. While each incident is unique, the number and type of response\nactivities are finite; therefore, through comparative analysis, we can learn about commonalities in the response patterns that\ncould improve predictions and expectations regarding the resources and capabilities required to respond to future acute\nevents. In this study, we interviewed representatives from more than 120 local health departments regarding their recent\nexperiences with real-world acute public health incidents, such as infectious disease outbreaks, severe weather events,\nchemical spills, and bioterrorism threats. We collected highly structured data on key aspects of the incident and the public\nhealth response, particularly focusing on the public health activities initiated and community partners engaged in the\nresponse efforts. As a result, we are able to make comparisons across event types, create response profiles, and identify\nfunctional and structural response patterns that have import for future public health preparedness and response. Our study\ncontributes to clarifying the complexity of public health response systems and our analysis reveals the ways in which these\nsystems are adaptive to the character of the threat, resulting in differential activation of functions and partners based on the\ntype of incident. Continued and rigorous examination of the experiences of health departments throughout the nation will\nrefine our very understanding of what the public health response system is, will enable the identification of organizational\nand event inputs to performance, and will allow for the construction of rich, relevant, and practical models of response\noperations that can be employed to strengthen public health systems.\nCitation: Hunter JC, Yang JE, Crawley AW, Biesiadecki L, Arago\n\u00b4n TJ (2013) Public Health Response Systems In-Action: Learning from Local Health Departments'\nEditor: Vittoria Colizza, Inserm & Universite Pierre et Marie Curie, France\nCopyright: \u00df 2013 Hunter et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits\nunrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nFunding: This study was supported by a Preparedness and Emergency Response Research Center (PERRC) grant from the Centers for Disease Control and\nPrevention, under FOA RFA-TP-08-001, to the University of California at Berkeley (grant number 5P01TP000295). Its contents are solely the responsibility of the\nauthors and do not necessarily represent the official views of the Centers for Disease Control & Prevention. The funders had no role in study design, data\ncollection and analysis, decision to publish, or preparation of the manuscript.\nCompeting Interests: The authors have declared that no competing interests exist.\n* E-mail: jhunter@berkeley.edu\n",
    "reduced_content": "Public Health Response Systems In-Action: Learning from\nLocal Health Departments' Experiences with Acute and\nEmergency Incidents\nJennifer C. Hunter1*, Jane E. Yang1, Adam W. Crawley2, Laura Biesiadecki3, Toma\n\u00b4s J. Arago\n1 Center for Infectious Diseases and Emergency Readiness, School of Public Health, University of California, Berkeley, California, United States of America, 2 San Mateo\nCounty Health System, Division of Public Health, Policy and Planning, San Mateo, California, United States of America, 3 National Association of County and City Health\nOfficials, Washington, District of Columbia, United States of America, 4 San Francisco Department of Public Health, San Francisco, California, United States of America\n Introduction\nAs part of their core mission, public health agencies attend to a\nwide range of disease and health threats, including those that\nrequire routine, acute, and emergency responses. In recent years,\nthe 2001 anthrax attacks, the emergence of Severe Acute\nRespiratory Syndrome (SARS), the extraordinary destruction\ncaused by Hurricanes Katrina and Sandy, and the pandemic\nfrom the novel H1N1 influenza virus have provided vivid\nexamples of how natural and man-made phenomena can wreak\nhavoc on the health and well-being of a community. Public health\nagencies have received increased attention and visibility following\nthese events, which have been met with public investments in\npreparedness, as well as heightened expectations of the public\nhealth system's ability to prevent, detect, and contain health\nthreats to communities [1,2].\nAs expectations have expanded, the need to strengthen public\nhealth systems' capacity and capabilities to respond to any hazard\nhas been at the center of many policy discussions [1,2]. However,\nthe evidence base for how to achieve this priority has lagged\nbehind. There is still little agreement on how to measure, let alone\nimprove, public health response performance [3,4]. A number of\nchallenges have been cited as barriers to research advancement in\nthis field, including: the infrequent nature of large-scale public\nhealth emergencies [3,5\u00ad7], the heterogeneity of emergency events\nand of public health delivery structures [3,6], the challenges with\naccess to incident leadership during real-world emergencies [7],\nthe limited ability for standardized surveys to measure complex\nagency and system processes [6], and the difficulty of identifying a\ncomparison group or constructing a counterfactual of what might\nhave occurred if particular public health interventions had not\ntaken place [8,9]. As a result, outside of statistical modeling,\nresearchers have often been limited in their use of statistical\nmethods to test hypotheses, reach generalizable conclusions, and\nisolate factors that are likely to have the greatest impact on\nresponse capacity [8,10]. Additionally, because catastrophic events\nare infrequent, the majority of the measurement literature in this\nfield has focused on preparedness rather than on response -- on\nidentifying and measuring the inputs to preparedness rather than\nthe variations in response performance. What is known about\npublic health emergency response is largely derived from\nsimulated emergencies (e.g. exercises or drills), with a primary\nfocus on bioterrorism or pandemic influenza [3]. By relying on an\nevidence base that draws from a narrow set of threats, we run the\nrisk of overemphasizing the capabilities and resources required for\nthose incidents while neglecting those that may be essential in\nother scenarios [11]. Furthermore, simulated emergencies intro-\nduce artificialities that do not reflect real-world response situations\nThis study attempts to overcome these limitations and to inform\nagency preparation and performance by implementing a novel\napproach. First, we concentrate on characterizing responses to\nreal-world events rather than preparedness and response efforts for\nhypothetical scenarios. Second, we broaden the case material to\ninclude acute public health events, not just disasters. And third, we\ncompare response features across incidents rather than identifying\nlessons learned from single isolated incidents. The methodological\nbasis for this approach is that while each event is unique, the\nnumber and type of response activities are finite; therefore,\nthrough comparative analysis, we can learn about commonalities\nin the response patterns that could improve understanding of the\nresources and capabilities required to respond to future acute\nevents.\nThe purpose of this study was twofold: (1) to test this novel\napproach, and (2) to describe public health agency response\npatterns to a diversity of acute events. For this study, we collected\nhighly-structured data on more than 120 real-world acute\nincidents, representing the broadest examination of events that\nhave stressed the local public health system in the United States.\nBy pooling data across diverse incident contexts and types, we\nincrease the number of opportunities for learning [13\u00ad15]. This\nstudy serves as a starting point for the development of evidence-\nbased forecasts of public health system response behavior that will\nhelp shape researchers' and practitioners' expectations for public\nhealth activity during urgent events and identify situations in\nwhich a governmental public health response has deviated from\nthese expectations. Such deviations or ``surprises'' can provide\nopportunities to improve and update our understanding of\nresponse performance by pointing either to a lack of sophistication\nin our predictive models, adaptive response behaviors or\npromising practices that could be applied in other situations to\nbeneficial effect, or unnecessary variation associated with ineffi-\nciencies that may affect the health of a community or the\nreputation of public health agencies.\nAdopting the maxim that ``all emergencies are local,'' we\nfocused this research on describing the public health response\nsystems from the perspective of the local health department. We\nexamine three domains through structured interviews with public\nhealth authorities involved in response efforts, including: (1) key\ncharacteristics of the acute event context, (2) the number and type\nof public response activities initiated using the CDC Public Health\nPreparedness (PHEP) Capabilities as an organizing framework,\nand (3) the number and type of organizations contributing to the\npublic health response activities. The domains selected for this\ninvestigation were informed by a study of the organization and\ndelivery of local public health services during normal operations\nby Mays et al. (2009), which employed similar measures in the\nexpectation that they could reasonably be expected to influence\nperformance and outcomes [16,17]. We view these response\nmeasures as intermediate outcomes between an exposure (i.e. the\nurgent event) and the final outcomes of interest (e.g. illnesses,\ndisabilities, deaths) [12].\nMethods\nStudy design\nThis research uses a mixed-methods approach. Quantitative\nand qualitative data on urgent event and response characteristics\nwere collected through structured telephone-based interviews with\nhealth department representatives using a retrospective cross-\nsectional design.\nStudy population\nSelection criteria and sampling design. The National\nAssociation of City and County Health Officials' (NACCHO)\n2010 National Profile of Local Health Departments (Profile of\nLHDs) was used to identify a sampling frame of 856 local health\ndepartments that serve a population of at least 50,000 individuals\n[18]. A total of 354 local health departments were recruited for\nparticipation, including: (a) all 171 local health departments that\nhad responded to a Profile of LHD survey question indicating that\ntheir agency had responded to an ``all-hazards emergency''\n169 local health departments from the remaining sampling frame,\nusing a probability-proportional-to-size sampling strategy; and (c)\na convenience sample of 14 local health departments included in\nthe pilot phase, with whom the researchers either had a personal\nconnection or had learned about their involvement in incidents\nthrough an online disease outbreak alerting system, HealthMa-\nTo be eligible for participation, recruited health departments\nhad to self-report that their agency had responded to an ``urgent''\nevent in recent history, defined as an event ``whose scale, timing,\nor unpredictability overwhelmed or threatened to overwhelm\nroutine capacity'' [20]. Simulated emergencies and events related\nto the 2009 H1N1 influenza pandemic were excluded. Addition-\nally, the representative(s) volunteering to participate in an\ninterview had to indicate that they were generally knowledgeable\nabout the overall public health response to the selected event.\nRecruitment. Study recruitment and data collection proceed-\nIn the initial rounds of recruitment, study invitations were emailed\nto preparedness coordinators and health officers for selected\nLHDs. Through follow-up phone calls with these health depart-\nment representatives, we learned that personnel in different\nfunctional roles, specifically communicable disease control staff or\nepidemiologists, would be the best informed about the overall\nresponse to an infectious disease event. As a result, after\napproximately one-quarter of our sample had been recruited, we\nshifted our outreach strategy and targeted either (1) the\npreparedness coordinator, or (2) the communicable disease\ndirector or epidemiologist, in an effort to identify a range of\ninfectious and non-infectious disease events. Each round of\nrecruitment lasted six weeks, during which, individuals were sent\nthe initial email invitation and study description, a reminder\npostcard by mail, three email reminders, and a telephone or\nvoicemail follow-up. Individuals were also informed that they\ncould forward the invitation to another person within the health\ndepartment who might be better positioned to participate, and\nthat multiple people could participate in a single interview.\nAs an incentive for participation, all participants were offered a\ncustomized report that would summarize their interview and\nprovide a comparison to other de-identified health department(s)\nthat had participated and discussed a similar event. Participants\nwere also entered into a raffle for the chance to receive monetary\nprizes in the form of public health preparedness books.\nLocal Public Health Systems and Urgent Events\nMeasurements and Instrument\nInstrument. Interviews were conducted by phone using a\nstructured interview tool, which included questions related to the\nthree primary research domains, including: (1) key characteristics\nof the acute event context, (2) the number and type of public\nresponse activities initiated using the CDC Public Health\nPreparedness (PHEP) Capabilities as an organizing framework,\nand (3) the number and type of organizations contributing to the\npublic health response activities. The questions and response\noptions were iteratively developed and refined through testing with\nover 100 case studies reported in the peer-reviewed literature and\nfurther revised after pilot-testing with four local health depart-\nments.\nThree interviewers (two primary and one backup) were\nextensively trained on the intent of each question in the\ninstrument, administration protocols, and response coding. Any\nquestions regarding the interpretation and coding of interview\nresponses were discussed throughout the data collection period.\nAfter all of the interviews had been completed, each of the two\nprimary interviewers reviewed the others' completed data\ncollection tools to ensure that coding decisions were consistently\napplied.\nMeasures. Event characteristics. Each event was character-\nized with respect to a number of contextual features, which were\nselected with the goal of building a common operational picture\nthat could allow for meaningful comparison across disparate\nincidents. We hypothesized that public health systems are adaptive\nto the nature of the event and therefore would expect to observe\ndifferential activation (in both number and type) of the response\nfunctions and partners based on the type of incident. In contrast, a\nnon-adaptive response system would engage similar functions and\npartners regardless of incident type. Accordingly, our predictor\nvariable was the type of event. Each incident was assigned to one\nof six specific event type categories, as defined by the CDC\nEmergency Preparedness and Response website, including:\ninfectious disease outbreaks and incidents, natural disaster or severe weather\nevents, bioterrorism events, mass casualty events, chemical emergency events, or\nradiation emergency events [21]. For the purposes of conducting certain\nanalyses within this investigation, these categories were further\ncollapsed into two groups: infectious disease events, including\nbioterrorism and infectious disease outbreak events, and non-\ninfectious disease events, comprising the remaining event types.\nFor all events, regardless of type, the following event details\nwere summarized: the duration of the public health response, the\nnumber of individuals directly contacted to investigate illness or\nexposure, the number of probable or confirmed cases, the number\nof severe cases (requiring hospitalization or resulting in death), and\nthe number of persons receiving medical countermeasures as part\nof the public health response. Additionally, for each event, we\nrecorded additional information data related to the scope of the\nevent, such as the geographic locations affected, types of\npopulations and community services affected by the event, and\nhow frequently the health department responds to a similar event\non the same scale as the one they selected for the interview.\nPublic health response activities. We used the CDC\nPublic Health Preparedness Capabilities (PHEP Capabilities)\nframework and definitions as the basis for characterizing the\npublic health activities carried out in response to the hazard [22].\nThe response activities are the first of our two primary outcome\nvariables. The Capabilities framework identifies and defines 15\ntypes of services that public health systems might be expected to\ndeliver during emergencies. We deviated from this framework for\nthe purpose of data collection in three key ways. First, we added\nfour categories that emerged as important public health response\nactivities through previous related work and pilot-testing but that\nare not emphasized in the PHEP Capabilities document. These\ncategories included: environmental investigations, evacuation,\nconsulting subject matter experts, and assessing medical and\npublic health response capacity. Second, we eliminated the\n``preparedness'' category from the list of public health response\nactivities included in the interview since pilot-testing proved it was\na confusing concept in the context of a specific response effort.\nFinally, we collected ``other'' activities that participants felt were\nimportant aspects of the response that had not otherwise been\ncaptured in the interview. Interviewers described each of the 19\nresponse activity categories (14 original PHEP Capabilities, four\nadditional categories, and an ``other public health response\nactivity'' category) and asked participants to indicate whether\nany related activities were initiated during the response to their\nselected event. Additionally, participants were asked to identify\nwhich of the response activities were ``absolutely necessary to the\noverall response.'' A summary score was calculated by summing\nthe total number of public health response activities initiated\nduring an event (between 0 and 19 activities).\nRole of public health in the overall response. In order to\ncharacterize the role of public health agencies in the event\nresponse, participants were asked to specify whether public health\nserved in the lead role, joint-lead role with another responding\nagency, or supporting role.\nOrganizational response partners. The second outcome\nof interest is the public health response system, which we define as\nall entities who contributed to public health response activities for\na given event. For each of the public health activities initiated\nduring a response, participants were asked to identify the\norganizations and agencies that contributed to that activity,\nincluding their own organization. A list of 41 organization types\nwas developed once all interviews were completed based on\nparticipants' qualitative responses. The categorization of organi-\nzations was based on the descriptions of the public health system in\nthe literature and expert opinion, using organizational function as\nthe basis for classification [16,23\u00ad25]. Three measures were\ndeveloped from these data. The first measure, ``any involvement'',\nis a dichotomous variable that indicates whether entities from each\nof the 41 organizational categories contributed to any of the 19\npublic health response activities. The second measure, ``relative\ncontribution'', is a weighted measure that summarizes, for each\nevent, the number of response activities for which an organization\ntype contributed, compared to the total number of response\nactivities performed during that event. Therefore, for each event in\nwhich a specific organization type had any involvement, the\n``Relative Involvement'' for an organization type was calculated\nas:\nRelative contribution (organization) ~\nNumber of activities contributed by organization\nTotal number of activities performed during event\nAdditionally, a summary measure of the total number of\norganizational categories mentioned in the interviews was\ncalculated (between 0 and 41 organizations).\nAlternate explanatory variables. Because we expected that\nfactors such as community context and local health department\ncapacity also influenced the character of the public health response\nsystem, we also conducted an exploratory analysis to assess this\nLocal Public Health Systems and Urgent Events\nLHDs, we assessed whether the number of response activities and\npartners varies by key characteristics of the health department,\nincluding: the population size served by a health department,\nhealth department expenditures, and number of full-time equiv-\nalent (FTE) staff [18]. Additionally, we examined whether the\nresponse activities and response partners vary based on the nexus\nof public health authority, which can be at the state or the local\nlevel.\nStatistical issues\nData recorded on paper-based interview tools were entered\nelectronically into the web-based program, Qualtrics, using double\ndata entry; the data were managed and analyzed using Stata 12\n(StataCorp LP, College Station, TX) and merged with organiza-\ntional data from the Profile of LHDs [18]. Distributions of event\ncharacteristics, response activities, and response partners were\ncalculated and event-specific profiles were developed. For event\nand response measures, the differences between infectious disease\nand non-infectious disease events were assessed using t tests or chi-\nsquare tests, as appropriate, log-transforming data as necessary. A\nmultiple linear regression model was employed to assess the\nassociation between organizational factors and response outcomes.\nBased on our power analyses and primary research question, we\ndecided to recruit at least 120 health departments. With this\nsample size, we expected to have power of 80 percent to detect\nsignificant differences of 25 percentage points or more between\ninfectious disease and non-infectious disease events for the\noutcome response measures of interest.\nEthics Statement\nThe protocols for this study were reviewed and approved by the\nCommittee for the Protection of Human Subjects at the University\nof California, Berkeley, which determined that our research\nactivities qualified for exempt status. Participants' provided verbal\ninformed consent to participate and to have the research interview\naudiorecorded, which was documented in the written record by\nthe interviewer. This consent process is consistent with our\nInstitutional Review Board's requirements for research with\nexempt status and with our approved research protocols. At this\ntime, interview data are not available in a public repository.\nResults\nSample demographics\nOf the 354 recruited local health departments, participants from\n123 health departments completed an interview, resulting in a\n35% response rate. The 231 non-participating local health\ndepartments included agencies that: were not eligible because\nthey did not have an urgent event that met study criteria (9% of\nnon-participants), enrolled in the study but were lost to follow-up\nduring the course of data collection (9%), declined to participate\n(12%), and provided no response to study recruitment requests\nParticipants represented health departments in 38 of the 48 US\nstates targeted for recruitment, with a diversity of community and\npublic health agency characteristics (see Figure 2 and Table 1).\nThese agencies served populations from 50,000 to several million\nresidents, reported annual expenditures ranging from $1 to more\nthan $500 per capita, and had staffing levels between 10 and more\nthan 1,000 Full-Time Equivalents. Nearly three-quarters of\nparticipants represented health agencies that operate as units\ndecentralized from state health agencies (i.e. locally governed),\nwith responsibility for a geographic jurisdiction defined by county\nboundaries. Overall, compared to non-participants, participating\nagencies were significantly more likely to serve a larger population,\nhave more expenditure per capita, and have more FTEs (for all\nInformant and interview characteristics\nInterviews involved between 1 and 5 health department staff,\nsuch as preparedness and response coordinators or directors (63%\nof interviews), communicable disease staff, including directors,\nepidemiologists, and nurses (38% of interviews), health officers or\ndirectors (16%), and environmental health staff (10%) (see Table\nInterviews lasted nearly one hour, ranging from 27 minutes to\n120 minutes. On average, interviews focusing on infectious disease\nevents were significantly shorter than those focusing on non-\ninfectious disease events (p,0.05).\nEvent Characteristics\nEvent details. The types of events included in our study\nprimarily involved infectious disease investigations and severe\nweather or natural disasters, with each constituting approximately\n40 percent of the total. Our event set also includes incidents\ninvolving chemical exposures, misuse of prescription or illegal\ndrugs, suspected or confirmed exposure to biological agents,\nradiation, mass casualties, technological emergencies (such as\nwater or power outages), complex events (involving multiple\ncauses), and anticipated mass-gatherings. Details on the types and\nfrequencies of events are provided in Table 2.\nWhen informants were asked how frequently their health\ndepartment responds to a similar event on the same scale as the\nincident they selected for the interview, more than half indicated\nthat this was the only event of its kind in recent history (29% of\nevents) or that something similar happens once every few years\n(29%). Other events occurred with a greater frequency, from one\nto two times per year (28%) to three or more times per year (13%).\nOther context and indicators of event severity. The\ncharacteristics of the events included in our study vary widely (see\nTable 3). For example, the shortest response duration was\napproximately five hours, in the event of a white powder incident,\nwhile the longest response lasted multiple years in the event of the\nDeepwater Horizon oil spill. The number of individuals within the\ncommunity contacted by health departments and their partners to\nassess illness or exposure ranged from 0 to 11,000 individuals,\nresulting in the identification of a mean of 37 confirmed or\nprobable cases per event. Overall, a mean of three cases resulted in\nhospitalization or death. A t-test comparison of the log-\ntransformed variables, duration of response and number of probable or\nconfirmed cases, revealed that infectious disease events involved\nsignificantly more cases (p,0.05) than did non-infectious disease\nevents.\nAll severe weather and natural disaster events directly or\nindirectly resulted in the disruption of community infrastructure or\nservices, including water, sewage, electricity, telecommunications,\nroads or transportation, as well as the direct delivery of public\nhealth and medical services. On average, four types of services\nwere disrupted in these severe weather events. With the exception\nof technological emergencies, other types of events rarely involved\nan interruption of community services other than those provided\ndirectly by public health, which were postponed or cancelled due\nto staff diversions for response activities in nearly a quarter of these\nevents.\nPublic Health Response Activities\nIn response to the urgent events included in our study, the\nnumber and type of public health activities initiated by response\nLocal Public Health Systems and Urgent Events\nsystems varied considerably (Figure 3). Of the 19 activity\ncategories, urgent event response efforts involved between 3 and\n18 types of activities, with a mean of ten activities per event. The\nresponse activities most commonly initiated were those related to:\ninformation sharing and management (100% of events), public\nhealth surveillance and epidemiology (98%), emergency public\ninformation and warning (89%), non-pharmaceutical interventions\n(88%), environmental or product investigation (82%), consulting\nsubject matter experts (79%), public health laboratory testing\n(74%), and emergency operations management (65%).\nActivity profiles for each of the six event categories (Figure 3)\nprovide a summary of the frequency and distribution of response\nmeasures by event type. Response efforts for non-infectious disease\nevents included a significantly greater number of response\nactivities than infectious disease events, with a mean of 13\ncompared with 9 response activities, respectively. Only one type of\nactivity, dispensing medical countermeasures, including vaccina-\ntion and post-exposure prophylaxis, was more likely to occur\nduring infectious disease events (p,0.05). In contrast, 11 different\ntypes of activities were significantly more common in non-\ninfectious disease events, as shown in Figure 3 with asterisks,\n(p,0.05). Because severe weather and natural disaster events\nconstituted a majority of the non-infectious disease events, we\nconducted a sensitivity analysis to assess the robustness of the\nresults. After excluding severe weather and natural disaster events,\nwe found that infectious disease and non-infectious disease events\ndid not differ significantly with respect to the number of response\nactivities, and that the only differences in type of activity that\npersisted were: dispensing of medical countermeasures, which was\nstill more common in infectious disease events; emergency\noperations management, volunteer management, and mass care\nand sheltering remained more common in the non-infectious\ndisease events (p,0.05). Additionally, after excluding severe\nweather and natural disaster events, two new activities appeared\nto be more common to infectious disease events, including\nepidemiology/surveillance and laboratory testing (p,0.05).\nParticipants identified ``other'' public health activities that were\ncarried out in the response to their event but were not captured by\nour pre-defined activity categories, including those related to:\nrestoring community confidence after an event (e.g. community\nmeetings, counseling individuals), enabling individuals to follow\ndisease prevention and health promotion activities (e.g. obtaining\nfood stamps after food disposal orders, providing financial\nassistance if ill or infected persons were excluded from work due\nto risk of disease transmission, providing housing for individuals\nremoved from their homes), contributing to resource coordinating\ncenters to help affected persons access needed health services and\npermits (e.g., food permits) from multiple agencies after an event,\nand assessing legal compliance and breaches of protocols.\nEssential Response Activities. Our measure of essential\nresponse activities, shown as horizontal gray bars in Figure 3,\nprovides a summary of activities that were perceived as ``absolutely\nFigure 1. Recruitment Flow Diagram. This flow diagram summarizes the sampling and recruitment steps that resulted in the study population of\n123 local health departments. Reasons for non-participation are provided, where possible.\nLocal Public Health Systems and Urgent Events\nnecessary'' to the overall response. For the urgent events in our\nstudy, activities most commonly reported to be essential were:\nepidemiology and surveillance for infectious disease events;\nenvironmental health and mass care and sheltering for severe\nweather events; environmental investigations and information\nmanagement for chemical events; information management for\nevents involving biological agents; public information and\nwarning for radiation events, and ``other'' for mass casualty\nevents, including patient transport and coordinating family\nassistance centers.\nPublic Health Response System\nOf the urgent events included in our study, we found that public\nhealth response systems were comprised of 3 to 25 types of\norganizations, with a mean of 10 organizations (Figure 4). The\ntypes of organizations mentioned as contributors in more than half\nof the urgent event responses in our study included: local public\nhealth agencies, including environmental health (98% of events);\nstate public health agencies (92%); healthcare providers (78%);\nmembers of the general public, including cases, contacts and\nfamily members of cases, and other individuals (70%); first\nresponders, including emergency medical services, hazardous\nmaterials, and fire (58%); and law enforcement and public safety\nOverall, infectious and non-infectious disease events differed\nwith respect to the numbers and types of public health system\npartners. The response systems for non-infectious disease events\nwere comprised of significantly greater numbers of organization\ncategories, with a mean of 13 versus 7 organization types\nrespectively (p,0.05). We identified three organization types that\nwere significantly more common in infectious disease events and\n17 organization types that were more common in non-infectious\ndisease events, shown in Figure 4 (legend). Because the non-\ninfectious disease category is dominated by severe weather and\nnatural disaster events, we also conducted a sensitivity analysis to\nassess the robustness of our findings after excluding this type of\nevent. We found that the difference in the number of response\npartners between infectious disease and non-infectious disease\nevents remained significant after excluding severe weather events\n(p,0.05). However, only half of the previously observed differ-\nences in the types of response partners remained, including:\ngeneral public, first responders, law enforcement, emergency\nmanagement, American Red Cross, critical infrastructure, and\nlaboratories (p,0.05). Additionally, after excluding severe weather\nand natural disaster events, two new differences in response\npartners appeared: involvement of ports of entry entities were\nmore common in non-infectious disease events and involvement of\nstate public health was common in infectious disease events\nFor each incident, we also calculated the relative contribution or the\nproportion of initiated response activities to which a participating\nagency contributed. The vast majority of partner organizations\ncontributed to a very limited proportion of the overall response\nactivities. For example, volunteer organizations were primarily\ninvolved in mass care and sheltering or volunteer management\nactivities, whereas the involvement of environmental or agricul-\ntural entities was mostly limited to environmental investigation\nand information sharing. Of forty-one organization types, only five\ncontributed to more than ten percent of the response activities\ninitiated during a response, including: local public health agencies,\nwhich contributed to a mean of 79 percent of response activities,\nstate public health agencies (38% of response activities), healthcare\nproviders (21%), first responders (14%), emergency management\nagencies (13%), and law enforcement agencies (11%).\nRole of public health in the response system. Informants\nfelt that public health played a ``lead role in the overall response''\nto half of the events in this study, a joint-role in approximately\none-third of events, and a supporting role in the remaining events.\nFigure 2. Geographic distribution of participating agencies, by U.S. state. This map shows the distribution of participating agencies across\nthe United States. States with a greater number of participating local health departments (LHDs) are shaded a darker blue. States with the greatest\nnumber of participating health departments included California (12 LHDs), Ohio (8 LHDs), North Carolina (8 LHDs), Texas (7 LHDs), Florida (7 LHDs),\nand New Jersey (7 LHDs). Image developed using data from the National Weather Service and the SPMAP module for STATA 12 (College Station, TX:\nLocal Public Health Systems and Urgent Events\nTable 2. List of events.\nEvent Type # of Events Event detail (# of events)\nInfectious disease event 51 Norovirus (9), Pertussis (7), Salmonellosis (6), Shiga toxin-producing Escherichia coli (STEC) (4), Tuberculosis (3),\nHepatitis A (2), Measles (2), Meningococcal disease (2), Mumps (2), Bacillus cereus (1), Botulism (1),\nCampylobacteriosis and Guillian Barre Syndrome (1), Coliform bacteria (1), Cryptosporidiosis (1), Cyclosporiasis\n(1), Hantavirus pulmonary syndrome (1), Legionellosis (1), Lyme disease (1), Novel influenza A virus infections (1),\nRabies-Animal (1), Shigellosis (1), Unknown Etiologic Agent (1), Varicella (Chicken pox) (1)\nSevere weather/Natural\ndisaster\n45 Hurricane/Tropical Storm (16), Severe winter weather (7), Tornado (7), Flooding (5), Fire (5), Severe rain or wind\nstorm/derecho (5)\nChemical or drug event 10 Designer drugs (Bath Salts/White Rush, Blueberry Spice) (2), Hydrogen Sulfide, Natural Gas, Mercaptans (1),\nDiesel Fuel And Lubricating Oil (1), Hydrogen Sulfide/Methane Gas (1), Pulverized Limestone (1), Deepwater\nHorizon - Crude Oil, tarballs (1), Isocyanate (1), Liquid Mercury (1), Lead, Arsenic (1)\nEvent involving a biological\nagent (suspected or\nconfirmed)\n6 White Powder Incident (Anthrax Suspected, Ruled Out) (3), Anthrax (Confirmed, From Natural Source) (1),\nBiowatch Actionable Result (Agent Not Named, Confidential) (1), Ricin (1)\nMass casualty event 2 Explosion (1), Plane crash (1)\nTechnological emergency 2 Mechanical failure at water treatment plant (1), Transformer fire (1)\nAnticipated event 2 Planned mass gathering (1), Displaced persons from natural disaster/severe weather (1)\nComplex event 1 Displaced persons from natural disaster/severe weather & infectious disease outbreak (cholera) (1)\nThis table summarizes the total number of events within each event type. The number of events for each sub-category (e.g. number of urgent events involving the\ndisease pertussis) is shown in parentheses.\nTable 1. Characteristics of Participating Local Health Departments and Participants.\nContinuous Variables mean median min max Signif National mean1\nCategorical Variables n % of Participants % of LHDs Nationwide1\nGoverning authority\nGeographic area served by agency\nTypes of Services directly provided by agency\nPosition or title of participant(s)2\nHealth Officer/Deputy 7 6\nTable 1 provides a descriptive summary of participants, including characteristics of the public health agency and agency representatives.\n1For local health departments serving a population of 50,000 individuals or more.\n2Participants could identify more than one position or title.\nLocal Public Health Systems and Urgent Events\nHowever, the public health role varied tremendously by the type\nof event, whereby public health was considered to play the lead\nrole in 100% of the radiation and complex emergency events, 94%\nof infectious disease events, 33% of incidents involving a\nbioterrorism agent, 30% of chemical events, 9% of severe weather\nor natural disaster events, and none of the technological\nemergencies or anticipated events.\nCommunity and Public Health Agency Characteristics\nParticipants from health departments in which governmental\nauthority is centralized at the state level, or where authority is\nshared between state and local entities, were significantly more\nlikely to choose non-infectious disease events as the subject for the\ninterview, compared to health departments that are decentralized\nfrom the state health department (p,0.05).\nTo assess the effect of agency characteristics on the response\nstructure and function, multiple linear regression models were\nused to assess the relationship between the community and agency\nmeasures (predictor variables: size of the population served by a\nLHD, number of FTEs, and annual per capita expenditures) and\nresponse measures (outcome variables: number of organizations\ninvolved in the public health system response, number of response\nactivities initiated during the response) controlling for the type of\nevent (infectious disease versus non-infectious disease). Each of the\nsix models included a single predictor and outcome variable,\ncontrolling for the type of event. We used the natural logarithm of\neach predictor variable and employed robust standard errors in\nthe statistical models to minimize the effects of outliers and\nheteroskedasticity. Controlling for the type of event, only the\nmodels including the number of full time staff were significantly\ncorrelated with the number of response activities (F = 37.88,\nshowing a negative association. This correlation indicates an\ninverse correlation between the number of public health depart-\nment staff and the number of organizations and the number of\ndifferent types of activities activated during an event.\nResponse reporting and dissemination\nEighty percent of participants indicated that their health\ndepartment developed a report describing their response efforts.\nApproximately two-thirds of these health departments developed\nafter-action reports, which were disseminated internally (66% of\nAARs), to contributing agencies (46%), or to the state health\ndepartment (37%). In only 11 instances was a summary report\nwidely disseminated, either in the peer-reviewed literature (4% of\nall events), in the Morbidity and Mortality Weekly Report (3%), or\nthrough the Department of Homeland Security Lessons Learned\nand Information Sharing web portal (LLIS, 2%).\nDiscussion\nThis is the first study to systematically describe and analytically\ncompare the response operations of local health departments and\ntheir community partners among such a large range of acute\nincidents. Public health representatives described their experiences\nresponding to more than 120 incidents involving unusual clusters\nof illness, unexpected exposures to hazardous substances, or the\nsudden loss of infrastructure. Regardless of the character of the\nevent, nearly every informant portrayed a situation that compelled\nhis or her public health agency to work with a network of other\norganizations to take rapid action in an effort to mitigate, control,\nor prevent expected adverse health consequences, often in highly\nstressful and politically charged environments with demanding\nexpectations for performance.\nTypically, these local public health agencies are faced with\nrestricted opportunities for learning from real-world urgent events.\nOne reason is the infrequency with which these events occur for\nany given community. More than half of the health departments\nthat we surveyed described an event that happens once every few\nyears or an event that was the only one of its kind in recent history.\nA second reason is a lack of access to others' experiences. Our\nfindings show that less than ten percent of urgent public health\nincidents were summarized and disseminated to the outside world,\nlikely due to a range of factors including time constraints and\nconcerns over legal or political repercussions. Moreover, when\nincident summaries are actually shared, reports are so varied in\nstructure and level of completeness that making comparisons\nacross events and drawing parallels to one's own experiences is\nvery challenging [13]. Opportunities for learning from events\nfaced by other health departments are further constrained by\nbudget cuts, travel restrictions, and a funding environment that\nmakes it difficult to justify activities that do not meet specific grant\nrequirements [26]. As a consequence, for many types of events,\nhealth departments are limited in their own direct experiences and\nhave almost no access to descriptions of the experiences of others.\nThis environment stands in stark contrast to other organizations\nthat are expected to perform reliably in high stress environments,\nsuch Naval aircraft carriers, where extensive field experience\nresults in finely tuned expectations for behavior, or air traffic\ncontrol systems, where the study and dissemination of lessons\nlearned from near-miss incidents serves as a cornerstone for\nlearning and improvement [27,28]. Above all, this research\nTable 3. Event Characteristics.\nEvent Characteristics # of events mean sd min median max Signif.\nNumber of individuals contacted to\ninvestigated illness or exposure\nNumber of severe cases (number of\nhospitalizations or deaths)\nThis table summarizes key event characteristics, including: duration of response time, number of individuals contacted to investigate illness or injury, number of\nprobable or confirmed cases, number of severe cases, and number of individuals who received prophylaxis.\n*Differences between infectious disease and non-infectious disease events significant at p , 0.05.\n**Differences between infectious disease (excluding events involving a bioterrorism agent) and non-infectious disease events significant at p , 0.05.\nLocal Public Health Systems and Urgent Events\nFigure 3. Response activity profiles, by event type. This figure shows the profile of response activities for each of six different types of events,\ndisplayed as separate bar charts. For a given event type, the blue vertical bars show the proportion of events that involved each of the 19 defined\nresponse activities. The horizontal gray bars provide the percent of events for which that activity was perceived to be ``essential.'' For example, within\nLocal Public Health Systems and Urgent Events\ndemonstrates that it is possible to identify meaningful insights from\na large set of real world events \u00ad insights that might not be evident\nfrom an examination of single isolated incidents \u00ad and that these\nlessons may have relevance in other public health settings and\ncontexts.\nComplexity of public health response system\nOur study contributes to clarifying the complexity of the public\nhealth response system, extending and expanding upon current\npublic health response systems are adaptive to the nature of the\nthreat. Our study response profiles reveal differential activation -\nin both number and type - of functions and partners based on the\ntype of incident. For example, we found that the public health\nresponse to severe weather events involved a much larger and\nmore diverse set of organization systems when compared to\ninfectious disease events. Within the field of public organization\ntheory, these non-infectious disease systems would be expected to\nelicit a number of predictable challenges to effective communica-\ntion and coordination [30,31]. With a more explicit recognition of\nthese complex systems, researchers and practitioners may be able\nto better able to predict associated challenges, their consequences,\nand strategies for avoiding critical failure points during urgent\nevents. Second, our study system profiles also provide an\nindication of the frequency and circumstances with which\nparticular organizations might become involved in public health\nresponse activities \u00ad information that is of the greatest importance\nwhen developing and fostering relationships with potential\npartners in the community. We found that some entities are likely\nto take part in a public health response of any nature, including\npublic health agencies, healthcare providers, and members of the\ngeneral public, whereas many other organizations are either\ninfrequently involved in public health responses or typically have a\nrole only under specific event circumstances. The American Red\ninfectious disease events (top box), 100% of events involved epidemiology and surveillance (Activity A), and in 82% of events this activity was felt to\nbe essential. The activities are ordered by five functional domains: investigation, disease control and prevention, information and incident\nmanagement, surge management, and community resilience. Technological emergencies, complex events, and anticipated events are excluded from\nthis figure due to small sample size.\nFigure 4. Public health response system profiles, by event type. Figure 4a shows the public health response system profile for each of six\ndifferent types of events, displayed as separate bar charts, key provided in Figure 4b. For a given event type, the green vertical bars show the\nproportion of events that involved each of the 41 defined response partners. For example, within infectious disease events (top box), 98% of events\ninvolved local public health agencies (Organization Type A). The types of organizations are ordered based on the overall frequency with which they\nwere mentioned, most frequent to least frequent, from left to right. A gray dotted line, at the 50% marker, is included in each bar chart to highlight\nthose organizations involved in more than half of events of that type.\nLocal Public Health Systems and Urgent Events\nCross provides a good example of an organization that was almost\nuniversally active in our severe weather and mass casualty events,\nbut rarely took part in infectious disease or bioterrorism events.\nFurthermore, the partner agencies described in our study, with few\nexceptions, lent their expertise or resources to a very limited\nproportion to the overall public health response activities. One\ninterpretation of this finding is that only a fraction of response\nefforts will be salient to those organizations. Alternatively, this\ncould suggest opportunities for expanded roles of organizations in\nresponse efforts. Lastly, we found that the role of public health\nvaried tremendously by type of event. Public health departments\nwere ten times more likely to serve in a lead role for infectious\ndisease events compared to events involving severe weather.\nRecognizing these response patterns can have an impact on\nplanning and exercising with partner agencies, particularly with\nrespect to setting expectations and developing a mutual under-\nstanding about the roles and responsibilities of public health\nagencies in various situations, an issue that has repeatedly been\nrecognized as an area needing improvement [3,32].\nWhen looking at health department characteristics, our findings\nsuggest an inverse correlation between the number of full-time\nstaff at a health department and the number of response\norganizations and activities activated during an event, after\ncontrolling for event type. While it might be expected that\norganizations with greater capacity would require less outside\nassistance, resulting in fewer organizations in the overall response\nsystem, it is somewhat surprising that we also observe a similar\nrelationship with the number of response activities. One possible\nexplanation is that health departments with fewer staff are\nrequired to work with a greater number of external organizations,\nand as a result, those organizations engage in a broader set of\nactivities than a smaller response system.\nUsing conceptual models of response to improve\npreparedness\nOur study response profiles suggest a few predictable configu-\nrations common to public health response efforts. For example,\nwhile far from comprehensive or validated, our data identified\nthree conceptual models of response. In the first model of\nresponse, most typical of infectious disease events, public health\nagencies serve in the lead role to the overall response; response\nactivities and partners are more limited in number and type; the\nnumber of cases define event severity; and the epidemiology and\nsurveillance function is considered most essential to the response.\nIn the second model of response, most typical of severe weather\nand natural disasters, public health agencies serve in a joint or\nsupporting role to the overall response; response activities and\npartners are more numerous and diverse; disruption to community\ninfrastructure defines event severity; and environmental health\nand mass sheltering and care activities are considered most\nessential to the response. In the last model of response, typical of\nevents involving chemical exposure or biological agents, public\nhealth agencies serve in a joint or supporting role to the overall\nresponse; response activities are moderate in number; response\nsystems involve atypical partners; number of persons exposed\ndefines event severity; and information and incident management\nactivities are considered most essential to the response. An\napproach that uses ``prototypical'' models for response, such as\nthis, could provide the basis for a new avenue of planning that\nbuilds on the strengths of those currently used. Like planning\nbased on single scenarios (e.g. aerosolized anthrax), response\nmodels are grounded in concrete real-world incidents, making it\neasier to conceptualize the likely functional and structural aspects\nof a response. This allows for the development of detailed response\nprotocols, which can be used to guide the training of staff and\npurchase of resources needed to test, implement, and improve\nthese plans [11]. At the same time, the conceptual models are\ngeneral enough that insights and skills gained from planning for\none threat can be expected to be applicable, although not\nidentical, to other hazards with a similar profile, increasing the\nefficiency of planning.\nExtension of CDC preparedness capabilities\nWe used a capabilities-based approach as an organizing\nframework for conceptualizing public health response activities.\nThis planning model, based on an assumption that preparedness\ncan be achieved by directing resources towards building, testing,\nand improving defined priority areas, is at the core of the CDC\n``preparedness capabilities'' that were used to characterize the\nresponse activities described by our informants. Consequently, our\nresults complement the PHEP Capabilities by highlighting the\ncircumstances in which related activities or functions might have\nparticular relevance in practice. Not surprisingly, our study finds\nthat certain types of events were much more likely to elicit\nresponse activities related to particular capabilities, and that the\nfrequencies with which capability-related activities were performed\ndid not necessarily equate with how ``essential'' that capability was\nto the overall event. For example, the epidemiology and\nsurveillance capability was almost universally activated. However,\nit was more likely to be considered ``essential'' for certain types of\nincidents, particularly infectious disease events. Linking our results\nto the CDC PHEP Capabilities framework may be of particular\nvalue to preparedness planners, for example, by guiding the\nselection of exercise scenarios that would be most likely to trigger\nactivities related to the capabilities they seek to assess or improve.\nIn addition to the original PHEP Capabilities, we also asked\nparticipants about four additional categories of activities that were\nidentified through our previous research and pilot testing as (1)\nimportant and (2) of a different character than the PHEP\nCapabilities. These activities included: environmental or product\ninvestigation, consulting subject matter experts, assessing public\nhealth or medical capacity, and evacuation. While each of these\nproved to have relevance in certain contexts, environmental and\nproduct investigations stand out because informants mentioned\nthese activities with such frequency, and considered these activities\nas essential in more than one-third of infectious disease, chemical,\nand severe weather incidents.\nCurrently, environmental investigations are folded into the\n``epidemiology and surveillance'' capability; however, the resourc-\nes, staffing, and partners required for these activities are quite\ndistinct from those required for epidemiology and surveillance. We\nbelieve that under-specification of important response functions\ncan have serious consequences, particularly in an era of scarce\nresources, in which health departments are often only able to\ndirect their efforts to a limited number of preparedness improve-\nments. Environmental investigations and other noted activities\nmight be considered in future versions of the PHEP Capabilities or\nother discussions about what it means for communities to be\nprepared. Our informants also identified a variety of ``other''\npublic health activities carried out in the response to their events,\nthat they felt were distinct from the PHEP Capabilities, and may\nalso merit further attention.\nGiven the current fiscal and political environment, which\nincreasingly demands accountability from the public sector, our\nfindings may prove to be particularly informative. In the absence\nof strong empirical evidence, policy makers have relied on expert\nopinion and a very limited research base to guide the development\nof preparedness standards, guidance, and performance measures\nLocal Public Health Systems and Urgent Events\n[6]. Our research demonstrates that the available literature is not\nrepresentative of the urgent events that health departments face,\nand that the available descriptions of the public health system in-\naction do not reflect actual complexity. Our study strengthens this\nlimited evidence base and we hope increases accountability and\nimproves guidance, policy, and best practices in preparedness and\nresponse.\nStrengths\nOur study benefits from three major strengths, including active\nevent finding, a broad definition of urgent events, and the use of\nin-depth interviews as a data collection method. As a result, we\nwere able to gain access to a number and diversity of urgent events\nthat would not have otherwise been available. In fact, fewer than\nten percent of the events included in this investigation were\npublished in the peer-reviewed literature or other professional\ninformation-sharing web portals, confirming that the publicly\navailable literature describes a very limited proportion of events\nexperienced by LHDs. For example, only two percent of events\nwere reported to the Department of Homeland Security's Lesson\nLearned and Information Sharing (LLIS) web portal database,\nwhich is believed to contain a fairly comprehensive set of response\nsummaries.\nSecond, our study adopted of a broad definition of urgent\nevents, thereby expanding the available case material on public\nhealth responses. By pooling data across incidents with different\ncontexts, we had a sufficient number to examine patterns,\nhighlight commonalities and differences across events with\ndifferent contexts, and generate hypotheses for future study.\nThird, because this is a fairly new field of research, the use of in-\ndepth interviews for data collection was invaluable, as this method\nprovided participants the opportunity to ask for clarification on\nquestions and for interviewers to ask follow-up questions and to\nhear how health department representatives describe their\nresponse. These qualitative data, while not highlighted in our\nfindings, influenced the insights we drew from the data. This study\nwas also strengthened by the availability of organizational data,\nprovided by the 2010 Profile of LHDs, which provided a sampling\nframe of local health departments, allowing us to better\nunderstand the representativeness of our sample and interpret\nour findings, and affording us the opportunity to examine how\ncharacteristics of a health department influence our outcomes of\ninterest [18]. Finally, our approach also draws strength from the\napplication of a systems-based and functions-based approach, both\nseen as essential features of high-quality research in this field [3].\nBy using the CDC PHEP Capabilities as a framework for\nconceptualizing public health activities, we hope to be able to\ncontribute to the scientific literature in a way that is standardized,\nand thus allows for comparison with future research.\nLimitations and Next Steps\nWhile our results describe the responses to a wide range of\nincidents, our method of event-finding did not draw from a sample\nthat is statistically representative of all health departments or\nurgent public health incidents across the United States. Repre-\nsentativeness was not a cornerstone of our sampling goal; however,\nin order to appropriately interpret the findings of this study, we\nbelieve that it is important to recognize the ways in which our\nfindings are not representative. First, while we were able to achieve\nthe desired number of events for comparison, we had a fairly low\noverall response rate (35%). Based on the reasons for not\nparticipating provided by a subset of our non-participants, a\nsignificant proportion of health departments in this group may not\nhave experienced an incident that met our study criteria.\nTherefore, we believe that the true response rate of eligible LHDs\nwas considerably higher. Nonetheless, we recognize that partici-\npating agencies systematically differed from those who did not\nparticipate: they were significantly more likely to serve a larger\npopulation, have higher public health expenditures per capita, and\nhave more full-time staff. Non-participants health departments'\ncapacity or inclination to participate may be related to a specific\nresponse profile that is underrepresented in our results. Second, we\nallowed participants to select a single event, which is one of many\nfrom which they could have potentially chosen. We do not claim\nto know anything about the events that were not selected;\ntherefore, it is not possible to know how representative our set of\nevents really is. We do know that the distribution of event types in\nour sample is similar to that found in other research [18].\nFurthermore, certain types of events occur more frequently in our\ndataset, such as norovirus outbreaks and hurricanes. As a result,\neach event profile is disproportionately influenced by these more\nfrequent events. Lastly, health departments that served a\npopulation of fewer than 50,000 individuals were excluded from\nour sampling strategy. The response system attributes of these\nhealth departments, which often have very limited staffing,\nwarrant additional study.\nAnother limitation of this study is that we recorded only\nwhether certain activities were initiated and which partners were\ninvolved in a response. We did not attempt to characterize the\nquality or appropriateness of those partners or activities. Addi-\ntionally, we do not provide information on the organizational,\ninter-personal, leadership, training, or historical factors that likely\ninfluenced whether responding agencies considered response\nmeasures to be appropriate and actionable.\nConclusion\nIn this study, we collect highly structured data on more than 120\nreal-world acute public health incidents. This is the first study to\nsystematically describe and analytically compare the response\noperations of local health departments and their community\npartners during such a large range of acute incidents. As a result,\nwe are able to make comparisons across events and to identify\nfunctional and structural response patterns that have relevance to\npublic health practitioners and researchers. As an extension of this\nwork, we recommend that future studies examine the types of\nevents that were less commonly reported in our sample, including\nmass casualty and chemical events, and suggest continued use of\nstandardized data gathering to ensure that future guidance, policy,\nand research is grounded in the best evidence learned through\nreal-world events.\n"
}