{
    "abstract": "Abstract\nAlgorithms and data-driven technologies are increasingly being embraced by a variety of different sectors and institutions.\nThis paper examines how algorithms and data-driven technologies, enacted by an organization like Facebook, can induce\nsimilarity across an industry. Using theories from organizational sociology and neoinstitutionalism, this paper traces the\nbureaucratic roots of Big Data and algorithms to examine the institutional dependencies that emerge and are mediated\nthrough data-driven and algorithmic logics. This type of analysis sheds light on how organizational contexts are\nembedded into algorithms, which can then become embedded within other organizational and individual practices. By\ninvestigating technical practices as organizational and bureaucratic, discussions about accountability and decision-making\ncan be reframed.\n",
    "reduced_content": "Original Research Article\nIsomorphism through algorithms:\nInstitutional dependencies in the case of\nFacebook\nRobyn Caplan1 and danah boyd2\n Keywords\nAlgorithms, accountability, Facebook, institutional theory, isomorphism, bureaucracy\nThis article is a part of special theme on Algorithms in Culture. To see a full list of all articles in this special theme,\nplease click here: http://journals.sagepub.com/page/bds/collections/algorithms-in-culture.\nConcerns about the impact of data-driven interme-\ndiaries on the news media industry have been growing\nsteadily over the last several years (Saurwein et al.,\n2015). Major social media and information companies\nlike Facebook, Google, and Twitter play a central role\nin what news and information people consume\n(Gottfried and Shearer, 2016). The popularity of these\nsystems--and the scale with which they impact both\nviewership and finances--has forced many news\nmedia producers to alter how they produce and dissem-\ninate content for their audiences. In short, long-stand-\ning news outlets must construct their content with\nalgorithmic and data-centric intermediaries in mind.\nFurthermore, a whole host of new digital-first outlets\nsuch as BuzzFeed and Breitbart have emerged to capit-\nalize on the way in which this ecosystem is architected.\nThe news industry has long been interwoven with\nother industries and institutions--most notably, adver-\ntising and government. At various points in history,\nnews media has been reconfigured by shifts in those\necosystems. From the rise of ``penny press'' to the\ndynamics of government-driven propaganda, journal-\nism has had to change depending on the broader land-\nsocial media, and algorithmic and data-driven systems\nhave altered many aspects of the news and information\nlandscape. Through the use of algorithms that rely on\nsignals from both the content and interactions of con-\nsumers, these technologies help curate what news and\ninformation is presented to whom. Furthermore, by\nproviding services that allow everyday people to\nactively serve as content distributors, their systems\n1Data & Society Research Institute, USA; School of Communication and\nInformation, Rutgers University, USA\n2Microsoft Research, USA; Data & Society Research Institute, USA\nCorresponding author:\nRobyn Caplan, Data & Society Research Institute, 36 West 20th Street,\nEmail: Robyn@datasociety.net\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License (http://\nwww.creativecommons.org/licenses/by/4.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-\nat-sage).\nBig Data & Society\njournals.sagepub.com/home/bds\nhelp distribute some content more widely than others.\nTraditional news enterprises, dependent on attention\nand clicks over digital advertising (often delivered by\nprogrammatic advertising networks owned by\nFacebook and Google), are forced to respond to these\nshifts. As a result, these platforms have upended the\norganizational practices of news-producing platforms,\naltering how both the newsroom and individual jour-\nThis paper underscores how efforts to increase\naccountability within algorithmically-mediated fields\nneed to consider the organizational values and institu-\ntionalized mechanisms embedded within algorithms\nthat have been driving organizational change across\nthe news media industry. Part of the challenge for algo-\nrithmic accountability work is to understand how algo-\nrithms and data-driven technologies are both situated\nwithin larger macro-social trends, such as the increased\nprivatization of public services in the current era of\ncapitalism as well as changes in ownership structures\nof industries, and also influence a wide-range of actors\nand organizations that have become dependent on\nalgorithmic and data-driven intermediaries. We draw\non concepts from institutional theory, such as iso-\nmorphism, to understand how algorithms structure dis-\nparate businesses and aims into an organizational field,\nleading them to change their goals and adopt new prac-\nprovides an analysis of how the media industry has\nshifted through its dependence on powerful algorithmic\nintermediaries, such as Facebook. In doing so, we\nexamine both how technology has shaped media indus-\ntries as well as how these systems have conferred value\nand legitimacy to specific individuals and organiza-\ntions. Using DiMaggio and Powell's (1983) theory of\nisomorphic change, we highlight how Facebook and its\nalgorithmic and data-driven practices have become an\ninstitutionalized organization within this domain,\nstructuring the media system as an organizational\nfield. In this sense, algorithms and data-centric technol-\nogies, like bureaucracy, act as a mechanism of legitim-\nation in the process of institutionalization, reflecting\nbroader macro-structural social processes, inducing a\nprocess of isomorphism, or homogenization, among\ndependent organizations (DiMaggio and Powell, 1983;\nMeyer and Rowan, 1977). We argue that algorithmic\nand data-driven technologies can be ``de-mythified''\nand viewed more akin to bureaucratic or administrative\nmechanisms than intelligent systems.\nViewing algorithmic systems as akin to bureaucratic\nor centralized administrative instruments can help re-\norient technology companies that have eluded classifi-\ncations, back into their regulatory domains. The fact\nthat social media and information technologies are not\nautomatically labeled as part of the news business has\nled to confusion about their role and responsibilities\nwithin the news media ecosystem. Ambiguity has\nstemmed from the emergence of algorithmic and data-\ndriven platforms, built by people who typically lack\ndomain-specific expertise, entering into wide spectrum\nof sectors and industries, such as transportation, public\nhealth, criminal justice, or media. Often, technology\ncompanies position themselves as ``platforms,'' which\nboth serves to highlight their intermediary role and\nallow them to position themselves as ``neutral'' in\nways that would make them more immune from more\ntop-down regulation or from complaints by users\nwithin the United States (Gillespie, 2010). Julie Cohen\n(2016) argues that this has created problems for a regu-\nlatory environment developed during industrialism that\nis dependent on ``well-defined industries'' with specifi-\ncations for what would ``trigger regulatory oversight''\n(p. 4). Information technology companies have come to\nmediate more and more of everyday life, without a clear\nunderstanding of how the incentives or goals of the\norganizations developing technologies can affect\ndiverse sectors or industries. Despite the ubiquity of\ndigital and information technologies now, the language\nof technology--in this case data and algorithms--is\noften used to make a company's activities distinct\nfrom previously regulated institutions. At the same\ntime, the presence of these technologies also serves to\nhomogenize the sector's practices and incentives.\nThe process of homogenization is not unique to\nalgorithms and data. Twentieth century organizational\nand neo-institutional scholarship focused on a different\nset of mechanisms--namely, bureaucracy--that also\ninduced similar changes across sectors and industries.\nScholars have previously highlighted this automation\nof bureaucratic processes through software. For exam-\nple, James Beninger's (1986) The Control Revolution\nfocuses on these dynamics long before the totalizing\neffects of Big Data and algorithmic intermediation\nhad even begun to take shape. More recently, popular\narticles in publications like Slate and Real Life Mag\nmake connections between Big Data and algorithms\nand their bureaucratic administrative predecessors\nto introduce accountability into bureaucratic systems,\nthere is good reason to examine sociotechnical organ-\nization practices through the lens of bureaucracy to\nopen up ways of rethinking accountability in this\nenvironment.\nSome who still consider social media platforms as\nfocused on personal experiences rather than news may\nthink an analysis of Facebook's effect on the news\nmedia an odd choice for an analogy of algorithmic sys-\ntems as centralized bureaucratic institutions. Yet, con-\nversations around algorithmic accountability often\ncenter on Facebook and Google in ways that reveal\n2 Big Data & Society\nthe entanglement of social media, news media, and\nalgorithms (Napoli, 2015). Rooted in sociology and\npolitical science, DiMaggio and Powell's (1983)\ntheory of isomorphism provides a novel perspective\nfor debates about algorithms and culture, providing a\ndifferent vantage point for understanding the relation-\nships between organizations embedded within algorith-\nmic logic.\nData-driven algorithms homogenize\nAlthough algorithmic processes are shaping sociotech-\nnical systems more than ever before, the notion of an\n``algorithm'' still lacks analytic stability and coherence\n(Seaver, 2017). Many scholars and computer scientists\ntake as their starting point the definition provided by\nDonald Knuth (1968), who argued that the word ``algo-\nrithm'' refers to a ``finite set of rules which gives a\nsequence of operations for solving a specific type of\nproblem,'' (p. 27). Meanwhile, there has been a growing\nunderstanding within the burgeoning field of ``algo-\nrithm studies'' that algorithms are a powerful ``rationa-\nlizing force'' within the network society (Pasquale,\nlooking to other past methods of ``rationalization'' of\nsocieties to understand how to both frame an analysis\nof algorithms, as well as decrease its importance as the\nobject of analysis in algorithm studies. Algorithms that\nserve to rationalize industries, also work to homogenize\nor make an industry more uniform and similar.\nInstitutional and neoinstitutional definitions of algo-\nrithms examine at the role algorithms have begun to\nplay as mediators of macropolitical processes. Philip\nnoted the usefulness of neoinstitutional theory for re-\nlocating algorithms within these complex social, polit-\nical, and economic relationships. Both Napoli's argu-\nment of ``algorithms-as-institutions'' and Ananny's\nconcept of ``algorithmic assemblages'' seek to under-\nstand how algorithms come to mediate supra-organiza-\ntional processes, and automate them to directly\n``structure user behaviors.'' What is needed to expand\non both Napoli and Ananny's theories is a way to\nunderstand how algorithms, as mechanisms of institu-\ntionalization, lead to broader system-wide changes\namong organizations and individuals structured\nthrough algorithms.\nIn the 1980s, James Beninger warned that the mech-\nanisms of algorithms, which define individuals and\nactions into discrete categories (inputted as variable\ntypes) are underpinned by a belief in the value of\nsuch processes of rationalization to organize societies,\nthat ``control can be increased not only by increasing\nthe capability to process information, but also by\ndecreasing the amount of information to be processed''\nprocess, categorize, and classify individuals and organ-\nizations should be viewed as extensions of bureaucratic\ntools such as forms, that have been associated with the\nstate in the past. This comparison, however, has fallen\nby the wayside in contemporary studies of algorithms.\nIt is difficult to understand why, as much of the con-\ntemporary information technology industry has\nfocused on the digitization of records and practices\nthat were previously done offline. For instance, early\nsoftware development focused on business applications\nlike Microsoft Office and Lotus 1-2-3, which were\ndesigned to enable bureaucratic aims like the collection\nand storage of records about actors (and relationships\nbetween actors), events, and processes. Algorithmic and\ninformation systems have in many ways served to\nre-mediate the record-keeping function and standard-\nization of bureaucratic mechanisms. In the process,\nhowever, privately-owned software companies that\nhave undertaken this work have fundamentally\ntransformed business and government, as well as\nconsumer technologies, reconfiguring most sectors\ninto data-driven bureaucracies where algorithms promise\nefficiency and optimization.\nDespite the obvious link between bureaucratic\nmodes of information production and online modes\nof data production using algorithmic models, there\nare some key differences in the current information\nenvironment which may have obscured this relation-\nship. Firstly, bureaucratic modes of information pro-\nduction and management have often been associated\nwith the state and more centralized and hierarchical\ninformation organizational contexts. Bureaucracy, for\nWeber, is a mechanism used by the state to induce\nrationality within complex political and economic\nenvironments. The critiques we make of the character-\nistics of bureaucracy now in the twenty-first cen-\ntury--that it is too hierarchical, too rigid, and\nrequires workers to be specialized--was seen by\nWeber as precisely the instruments that could be used\nby the state to create fairer, more just, and more equit-\nable treatment of citizens within societies (Du Gay,\naccording to Du Gay's reading of Weber, was to be\n``impersonal, expert, and procedural'' through a com-\nmitment and subordination to the bureaucratic hier-\noften deployed with an expressed interest in limiting\nthe subjectivity of decision-making systems (Beninger,\nthis is done as a way to make algorithmic systems\nappear more objective than their human counterparts,\neven when humans directly play a role in the creation,\ntraining, and deployment of algorithmic systems.\nCaplan and boyd 3\nViewing algorithmic systems as an extension of\nbureaucratic mechanisms can both serve to temper\nanxieties about the role algorithms are playing in\nre-structuring industries, and highlight potential\navenues for critique. Algorithms, like bureaucracies in\nthe past, have been positioned as the necessary antidote\nto subjective decision-making processes within large-\nscale and complex systems that are coordinating\nbetween many individuals, industries, and organiza-\ntions, simultaneously. Companies that have emerged\nto digitize records and automate the delivery of infor-\nmation and services to users, using proprietary algo-\nrithms, have been able to enter into new industries\nand spaces under the guise of internet exceptionalism\n(Wu, 2010). In the process, the bureaucratic mechan-\nisms that came to frustrate so many individuals have\nbeen closed down and hidden behind not only the\n``black box'' of algorithms, but a mythology that sug-\ngests that the work done by algorithms is fundamen-\ntally different from that done by offline administrative\nmechanisms in the past (Pasquale, 2015). Viewing algo-\nrithms in this way also highlights how they can work to\norganize, homogenize, and synthesize industries, such\nas the news media industry, through processes of ``iso-\nmorphism'' studied by DiMaggio and Powell (1983),\nwithin the context of bureaucracy.\nAlgorithms as administrative\nmechanisms\nAs technology companies have come to support state-\nbased processes like predictive policing and algorithmic\nadministrative power has transferred from the state to\nprivate enterprise, particularly as the technology indus-\ntry has advanced (Owen, 2015). Over the last two dec-\nades, the buzzwords disrupt and disruption have,\naccording to Taylor Owen, come to stand in ``for a\nform of libertarianism deeply rooted in the technology\nsector, a sweeping ideology that goes beyond the pre-\ncept that technology can engage social problems to the\nbelief that free market technology--entrepreneurial-\nism--should be left unhindered by the state'' (Owen,\n2015). During waves of hype surrounding automation\nand ``Big Data,'' the mythology surrounding these tech-\nnologies implies it is more legitimate than existing insti-\ntutions, with more accurate claims to objectivity (boyd\nand Crawford, 2012). Yet, the adoption of particular\ntechnological practices and vocabulary often serves\nmore as a signal of ``legitimacy'' than an attempt to\nimprove productivity and performance of an industry\n(DiMaggio and Powell, 1983; Meyer and Rowan,\n1977). This has been seen in the adoption of algorithmic\nand data-driven processes across a wide spectrum of\nsectors and institutions, despite evidence that\ndemonstrates that these processes are subject to similar\nbiases and concerns as previous bureaucratically driven\ninstitutions. Though this process of institutional de-\nlegitimization can find its roots in many histories, the\nnarrative of technology as that which could disrupt\nexisting institutional structures can be traced to the\nideologies embraced by many of early proponents of\nthe internet.\nThis is where the theories of neoinstitutional scho-\nlars, such as DiMaggio and Powell (1983) and Meyer\nand Rowan (1977), are especially useful for analyzing\nhow these industry-wide changes can occur. For Weber,\nbureaucracy rationalized society by trapping people\ninto a structured order, or an ``iron cage.'' DiMaggio\nand Powell (1983) revisit the concept of his ``iron cage''\nof bureaucracy, seeking to make sense of the existence\nof a system that persists and continues to structure\nsocial life, despite its removal from the context in\nwhich that iron cage emerged (and despite it no\nlonger being an efficient way to structure society). The\nconcept of an ``iron cage'' is fruitful for considering the\nimpact of algorithms, whose formalized logics often\ncontradict the rhetoric of personalization, choice, and\nfreedom.\nAlgorithms and Big Data function in a similar\nway--in a world where surveillance is the norm,\nmerely existing in the world means you are structured\ninto the technologies and systems of data collection,\nproduction, and analysis that structure most of social\nlife today. For DiMaggio and Powell, the iron cage of\nbureaucracy persisted 80 years after Weber was writing,\nnot because bureaucracy increased competition or\nmade the state more efficient or just or equal, but\nbecause it served as a mechanism of rationalization\nand structuration. In effect, bureaucracy demanded\nlegibility of every actor or organization that interacts\nwith the state within the terms the state defined.\nDiMaggio and Powell (1983) look to these mechan-\nisms of structuration to explain how organizations and\nindividuals become more similar or ``homogenous''\n(p. 147). They use a concept, ``isomorphism,'' to\nprovide a way to understand system-wide changes in\nan industry, sector, or ``organizational field'' that\nforces ``one unit in a population to resemble other\nunits that face the same set of environmental condi-\nis helpful for understanding how both the mechanisms\nand the rhetoric of algorithms have become embedded\nwithin the structure of social life, despite rampant\ncritiques about their capacity to accurately represent\nreality, increase efficiency, or remain free from bias.\nThese theories provide an orientation to examine\nhow organizations become more similar through\ndependence of one organization on another organiza-\ntion, using predictors such as ``the greater the\n4 Big Data & Society\ndependence of an organization on another organiza-\ntion, the more similar it will become to that organiza-\ntion in structure, climate, and behavioral focus''\nPowell offer three frames or forces with which one\ncan analyze these changes--coercive, mimetic, and nor-\nmative--though these forces can hardly be considered\nas separate. In analyzing news media industry in\nresponse to algorithms and Big Data, what becomes\nrelevant is how these frames of analysis can help iden-\ntify new forms of legitimation within organizations,\nprofessionals, and audiences that can work to tease\nout what or whose values are being prioritized through\nthe current media ecosystem, that are then structured\nthrough algorithms. The increasing dominance of the\nalgorithmic form is thus analogous to the role played\nby bureaucracy in neo-institutionalist work in soci-\nology, where bureaucracy is as much a carrier of legit-\nimation, as it is the outcome of more macro-structural\nsocial processes.\nAlgorithmic isomorphism: Re-orienting\nthe organizational field of news media\nThe news media industry provides an interesting case\nstudy to study the increasing dominance of the algo-\nrithmic form at competing levels of organizational con-\ntexts (the technology company versus the news media\ncompany) and individual practices (engineering versus\njournalism). Technology companies that produce\nsearch engines, social media, aggregators, and recom-\nmendation engines are currently operating as interme-\ndiaries in spaces where news media content is both\nproduced and distributed. Though platforms have\nrepeatedly tried to distance themselves from traditional\nclassifications of sectors (Napoli and Caplan, 2017),\ntheories of isomorphism can work to re-situate these\ntechnologies back into their domains. DiMaggio and\nPowell's theory of institutional isomorphism provides\none mechanism to re-orient these companies into the\norganizational field of media. This lens reveals the dis-\nconnect between (1) the values and assumptions being\nembedded into the technology that shapes the media\nindustry and (2) the (often problematic) values that\nhave dominated journalism historically. This has been\nmade more complicated as platform companies\nengaged in the prioritization and filtering of news\nmedia content, like Facebook and Google, have repeat-\nedly sought to differentiate themselves from traditional\nmedia companies (Napoli and Caplan, 2017).\nThe power and centrality of Facebook's News Feed\nalgorithm, in particular, is important. According to\nDiMaggio and Powell's predictors of isomorphic\nchange (or more homogeneous and similar), the more\ndependent an industry becomes on one organization\nwho is exerting a dominant administrative function\n(in this case, Facebook's News Feed algorithm), the\nmore that organization will be able to exert change\non other organizations that rely upon them\nre-defining the concept of relevance or ``value'' of infor-\nmation and news media, Facebook increasingly writes\nthe rules, or code, that defines which content succeeds\nor fails in no small part because Facebook is now play-\ning an outsized role in how people access news content\n(Gottfried and Shearer, 2016). Furthermore, by altering\nthe economics of journalism through the reconfigur-\nation of attention and advertising, Facebook drives\nnews media organizations to incorporate metrics such\nas click-rate, likes, and shares.\nNews media and the news feed\nIn their analysis of the bureaucratic state, DiMaggio\nand Powell describe coercive forces that stem from pol-\nitical influence and what they refer to as ``the problem\nthe context of information intermediaries, Lawrence\nLessig (1999) takes a similar approach through his\nadage ``code is law,'' which emphasizes the degree to\nwhich code and hardware serve to structure and regu-\nlate certain activities and outcomes within computa-\ntional systems.\nFacebook itself has used its News Feed algorithm,\nand changes being made to it, to exert powerful coer-\ncive pressures on organizations operating within its\nwalls. Evidence that news media organizations are sub-\nject to the informal and formal pressures Facebook's\nplatform places upon them can be seen in their relative\nsuccess following changes to Facebook's News Feed\nalgorithm. Publishers that had early success in News\nFeed effectively subsumed their own organizational\npractices to the logic of Facebook's algorithms.\nOutlets like BuzzFeed, EliteDaily, and UpWorthy were\nearly winners in the Facebook ecosystem, using tactics\nlike engineering headlines to include emotional direct-\nives for readers (to click or like and share) and creating\ndigestible and relatable content that could be easily\nAugust 2013, Facebook engineer Lars Backstrom\nauthored a ``News Feed FYI'' for the corporate blog,\nexplaining why sites engaging in ``clickbait'' practices\nwere prioritized by Facebook's algorithms. At that\ntime, Facebook's algorithms prioritized stories with\nmany likes and comments, and re-prioritized content\nto the top of a user's feed that had significant engage-\nment (Backstrom, 2013). The impact on the organiza-\ntions willing to play by these rules was significant. In\nOctober 2013, Facebook announced that referral traffic\nto media sites from Facebook had grown by over 170%\nCaplan and boyd 5\nfrom the previous year. Publishers that engaged with\nthis system saw even more significant growth, with\nBuzzFeed reporting referral traffic increases of 855%\nduring this period that many of the dependencies\nbetween Facebook and news publishers were strength-\nened. SimpleReach, a content measurement and distri-\nbution company, announced in 2013 that Facebook\nwas driving ``more traffic than any other social\nnetwork,'' surpassing other social media sites popular\nat the time, such as Twitter and StumbleUpon\nFacebook's central position within this emerging\norganizational field led to repeated changes within the\nmedia industry as organizations adapted to Facebook's\nalgorithms, and as Facebook changed its algorithms to\nadapt to these organizations. In their effort to combat\nthe dominance that news media organizations engaging\nin `click-bait' were having over their network,\nFacebook released another change to the News Feed\nin late 2013 to identify ``high-quality'' news content\n(Meyer, 2013). ``High-quality'' was defined by\nFacebook as whether users continued to interact with\nan article after-the-fact, which meant that some pub-\nlishers saw older articles begin to re-emerge on the net-\nwork, with traffic driven to this older content. In\nAugust 2014, Facebook released another change to\nthe News Feed to address ``Click-Baiting Headlines,''\nfurther defining their concept of quality news sources.\nIn this version, Facebook used variables like ``how long\npeople spend reading an article away from Facebook''\nas a way to calculate how users determine content that\nis valuable to them (El-Arini and Tang, 2014).\nFacebook warned publishers relying on click-baiting\nheadlines, that their referral traffic may decrease.\nOutlets like Eli Pariser's UpWorthy were particularly\naffected by this change, with a decrease of 46% of refer-\nral traffic over two months (McArdle, 2014). Pariser\nresponded to the change by re-evaluating the metrics\nby which UpWorthy calculated its own success, to be\nmore in line with Facebook's own goals. Pariser is\nquoted as saying he was shifting his organization\ntowards ``Facebook's focus on engaged time'' (Kafka,\n2014). This shifting of goals in response to Facebook is\nperhaps indicative of the less explicit forms of coercive\nisomorphism described by DiMaggio and Powell\n(1983), in which organizations are driven to conform\nto gain support from the organizations upon which\nthey are now dependent (p. 151).\nchanges Facebook made to its News Feed had effects\non news media organizations. As status updates and\npersonal sharing among users began to decline over\n2015, Facebook began to invest more of their resources\nin products geared towards news media distribution\n(Efrati, 2016). This included a new emphasis on\n``native videos'' embedded directly in the News Feed,\nwhich was communicated out to news publishers dir-\nectly by Facebook (Oremus, 2016). It also included the\nlaunch of Instant Articles in May 2015, a platform\ndeveloped exclusively for the hosting of content from\nrecognized news media publishers to reduce load time\nfor users clicking on news media stories (Reckhow,\n2015). This new platform was also the first step in a\nrevenue-sharing model between Facebook and news\npublishers, albeit limited--they offered that publishers\ncould sell ads in their articles and ``keep the revenue'' or\nuse Facebook's Audience Network, the site's own tar-\ngeted advertising product, already used by many\nbrands and publishers (e.g. The Huffington Post) for\naudience measurement and targeted ad delivery\n(D'Onfro, 2016). One report, by Digiday, said pub-\nlishers using Instant Articles saw a drop in referral traf-\nfic over the last quarter of 2015, though the author\nnotes that few publishers were willing to speak about\ndeclines in traffic on the record (Moses, 2016). During\nanother tweaking of its algorithm in June 2016,\nFacebook's algorithm re-prioritized friends and family\nover publishers, and news media organizations again\nsaw significant declines in referral traffic (Mosseri,\n2016). This corresponded (though there is no docu-\nmented causal link) to an uptick in a spread of misin-\nformation (commonly referred to as ``fake news'') over\nthe Facebook network over the same period\nThough Facebook has in many cases claimed that its\nalgorithms merely neutrally reflect the aggregate activ-\nre-framing of the News Feed's prioritization of content\nchallenges this claim. This pattern of changing the algo-\nrithm to meet their own organizational incentives also\nhighlights how accountability proposals that focus pri-\nmarily on gaining access to algorithms or data will fall\nshort, given that changes can be made to the News Feed\nalgorithm quickly and with widespread effects on indus-\ntry practices. Of course, not all news organizations were\nas responsive to the changes made to the News Feed\nalgorithm. Understanding the broader contexts\nthrough which some companies adapted to changes\nmade to the algorithm, when others did not, would be\na worthwhile area of future investigation.\n`Innovation' through imitation\nChanges stemming from coercive forces, especially\nwhen frequent, lead to an environment of uncertainty\nthat prompts dependent organizations to learn from\nother dependent organizations that have successfully\nconformed to the structuring mechanisms. This process\nof ``mimesis,'' or imitating models for success, is\n6 Big Data & Society\nargue will induce similarity across an organizational\nfield. In this sense, the dominant organization's incen-\ntives or goals become embedded across an industry\nthrough the borrowing of practices that lead to success\nover the network. In the case of Facebook, this was\nseen in the adoption of data-driven metrics and ana-\nlytics into newsrooms, as well as the growth of a new set\nof intermediaries that were fed directly by the\nFacebook API, whose role it was to analyze and com-\nmunicate Facebook metrics back to publishers.\nDuring the early era of the News Feed, relationships\nbetween Facebook and media organizations were far\nfrom static or one-directional. Rather, an ecosystem\nof social media analytics businesses, using the\nFacebook API, acted as intermediaries between\nFacebook and the news media industry which was\ngrowing dependent on the social media platform to\nreach audiences. Throughout 2013, a number of tools\nand products were rolled out for media organizations in\norder to bring in data or content from Facebook users\ndirectly into their newsroom. In September 2013,\nFacebook rolled out tools for publishers and ``media\npartners'' including BuzzFeed, CNN, NBC's Today\nShow, BSkyB, and Slate to integrate ``public posts of\nreal-time activity about any given topic,'' in the form of\nKeyword Insights API, and the Public Feed API\n(Osofsky, 2016). The development of these products,\nas well as other partnerships, quickly lead to an add-\nitional ecosystem of businesses who used Facebook's\npublic API and served as an intermediary between\nFacebook and media organizations. Facebook lists\nthese ``media solutions'' partnerships on their site,\nwhich includes CrowdTangle, a social media analytics\ncompany that was bought by Facebook in November\nAs Facebook and other online intermediaries began\nto take on a larger role in the distribution of journalism\nand other news media content, the media industry con-\ntinued to shift in respond to this algorithmic and data-\ndriven environment. While some content providers,\nsuch as BuzzFeed and The Huffington Post, emerged\nout of these new algorithmic markets producing con-\ntent directly for Facebook and other social media net-\nworks (Herrman, 2016), other news agencies, including\nThe New York Times, had to quickly grapple with how\nto incorporate metrics and analytics into their news-\nroom cultures (Sobel Fitts, 2015). These pressures\nwere greater for some organizations who saw falling\nreadership on both their website, and on mobile, as\nthey competed with other digital content producers\nmore able to quickly adapt to the algorithmic and\ndata-driven ecosystem.\nThe news industry was responding to the impact that\nnew digital technologies were having on their industry,\nincorporating the organizational incentives of these\ntechnologies (how Facebook was structuring value of\nan article) into the structure of their organizations,\nas well as into the system of incentives that were\nbeing used to drive coverage among journalists.\nThe New York Times addressed this issue of ``disrup-\ntion'' of the existing media industry by new technology\nplayers directly within their report, in a section titled\n``What is Disruption?'' (The New York Times, 2014:\n16). Featured in the report were media businesses that\nhad adopted metrics and analytics into their coverage\n(such as BuzzFeed, ESPN, and Quartz) and who were\nexpanding their digital offerings rapidly by using\n``social search and community-building tools and stra-\ntegies'' (p. 24). Other media organizations sought to\nsimilarly adapt their business models, highlighting the\nrole that data-driven and algorithmic processes can\ntake in compelling news media organizations to take\non the characteristics of social media platforms--an\nexample being Tribune Publishing rebranding itself as\nthe tech company ``tronc'' which purports to use\nmachine learning to better serve audience interests\n(Napoli and Caplan, 2017). As DiMaggio and Powell\nargue, modeling of one organization's practices by\nanother is ``a response to uncertainty'' through the\nborrowing of practices that may enhance legitimacy\nor possibility for success, or to demonstrate to others\nthat they are working to change their practices to be\nin-line with those of the dominant organization\nmany of the practices that we now associate with\n``innovation,'' such as the adoption of Big Data meth-\nods by the Tribune, is actually due to an uncertain\nenvironment which induces one organization to copy\nthe practices of another.\nInfluence (breadth) versus reputation (depth)\nThe third source of isomorphic change described by\nDiMaggio and Powell occurs at the individual level\nduring processes of professionalization of a workforce,\nwhich they refer to as ``normative pressures'' (p. 152).\nThere are many reports that the work of journalism has\nchanged significantly in response to digital media, how-\never, to what extent this is due to Facebook in particu-\nlar is not known. At the same time, broader trends--the\nrise of citizen journalism, journalists adapting data-\ndriven metrics into communicating the value of their\nwork, and the incorporation of computational skills\ninto journalistic work--need to be considered alongside\nthe emergence of Facebook and other data-driven\nintermediaries to assess how algorithms have changed\nthe journalist-audience relationship (Anderson, 2011).\nAdditional factors for consideration include algorith-\nmic methods of surfacing news content (through the\nCaplan and boyd 7\nTrending Topics module on Facebook) and the produc-\ntion of news content through automated methods\nAs Anderson (2011) and other scholars (Tandoc,\nnoted, as online metrics and data-driven processes\ngained an increased status in the news media ecosystem,\nnews media organizations began to adapt, using these\nmetrics to learn more about what their audiences search\nfor online and what topics can drive revenue. As a\nresult, they began to choose their ``subjects solely on\nthese computer-generated metrics'' (Anderson, 2011:\n536). Anderson stressed that media companies began\nto embrace an ``algorithmic understanding of demo-\ncratic processes,'' viewing the process of news delivery\nas one in which data and algorithms are used to assess\nindividual user wants and needs, relying on a model of\n``individual consumer choice'' that becomes equated\nJournalists themselves were reporting pressures\nwithin newsrooms to adapt to the new digital ecosys-\ntem, as systems of incentives that valued views and\nclicks began to dominate. Though media companies\nhave always used audience measurement to guide\nreporting, Petre (2015) argues that the ``tracking cap-\nabilities of the internet, as well as the ability to store\nand parse massive amounts of data, mean that audience\nmetrics have grown far more sophisticated in recent\nyears.'' Analytics companies contribute to the ecosys-\ntem of data-driven journalism, impacting the profes-\nsional practices of journalists within newsrooms.\nReports by Nieman Lab (2014) have detailed the\nmanner by which journalistic and editorial practices\nbegan to shift in response to the emergence of web met-\nrics, leading to the rise of a ``culture of the click,'' with\nweb metrics often used as a management tool, particu-\nlarly when websites rely on ``traffic-based financial\nincentives'' (Christin, 2014). Metrics influence journal-\nistic practices even when only editors--and not journal-\nists--have access to the data (Sobel, 2015). Even when\nboundaries between journalists and metrics exist, jour-\nnalists still seek out ways to numerically compare their\nA focus on numeracy and digital data shapes every\naspect of how journalists are expected to do their work.\nFor example, journalists are increasingly encouraged to\ndevelop technical skills, become skilled at using social\nmedia, and learn to code (Broussard, 2015). The pres-\nsure to learn digital skills appears to have affected jour-\nnalism training as early as the 1990s, with roots\nstemming even earlier to the digitization of some news-\nto the current ecosystem in which intermediaries play a\nmore central role are calls for journalists to engage in\n``journalism-as-a-process'' which stresses to journalists\nthat newsmaking is an ongoing process and a collab-\norative venture between journalists and audiences.\nMeyer (2013) found that, because of social media, audi-\nences expected journalists to write stories they could\n``relate'' to, mirroring expectations from the personal-\nization of content that occurs over algorithmic and\ndata-driven networks, such as Facebook.\nCoercive, mimetic, and normative pressures, influ-\nenced through algorithmic prioritization of content\ndetermined through metrics, can thus have important\nimplications for the production of content. As social\nmedia and search engines have centralized the produc-\ntion and distribution of content, news media content in\nparticular, they have also shifted how publishers and\njournalists determine not only what is important to\ncover, but how the value of this coverage is communi-\ncated to a wide range of actors communicating value\nthrough metrics. These actors include publishers com-\nmunicating the reach of their stories and site, journal-\nists communicating their value to potential employers,\nand the communication of value (and cost) to adver-\ntisers, using these same services to place and distribute\nadvertisements to consumers. Due to their centrality\nwithin this network of interrelated actors, however,\npower to drastically alter these relationships has\nbecome centralized within opaque proprietary compa-\nnies like Facebook, which can work define, and re-\ndefine the rules structuring these relationships with no\naccountability nor oversight.\nAlgorithms as\nadministration--Implications\nfor oversight\nArguments both in favor of and against incorporating\nalgorithmic decision-making tend to over-emphasize\nthe role algorithms specifically play in the construction\nof reality. Instead, algorithms should be viewed more as\nadministrative mechanisms that organize relationships\nbetween organizations and individuals. As part of this\norganizational structure, not only are algorithmic sys-\ntems working to automate the administrative mechan-\nisms of a dominant organization, but they are also\nproviding a common language or structure that serves\na legitimizing function that affects other organizations\nand individuals within that field. This is both positive\nand negative for increasing oversight into this process\nof structuration. Using neoinstitutional theory, it is\npossible to trace a network of organizational dependen-\ncies and relationships that we cannot see through the\ncode alone.\nThrough the administrative function of algorithms,\norganizational incentives become deeply embedded\nwithin many layers of an organizational field, making\nthe encoded algorithmic models almost invisible and\n8 Big Data & Society\nless amenable to change. Within the area of media\npolicy, tracing this map of interdependencies, in terms\nof both sociotechnical and economic dependencies,\nbegs us to question how one changes system-wide\nincentives and organizational structures that become\nembedded at multiple levels. It also begs the question\nof how, or according to what principles, we begin to\nassess the constraints, limitations, and goals of the\ndominant organization as their commitments become\nembedded into algorithmic or computational mechan-\nisms. As part of this re-definition of values and criteria,\nneoinstitutional scholars Meyer and Rowan (1977)\nstress the need to include mechanisms that would not\nnecessarily be subsumed within this dominant formal\nstructure (p. 356). In other words, one approach\nFacebook could take would be to develop a mechanism\nby which news content is excluded from the same\nmetric-ization of clicks and likes as other content on\nFacebook. In this way, Facebook could ``decouple''\nits valuation of news from its organizational logics.\nWhat makes algorithms so seemingly necessary and\npowerful is the sheer amount of data they parse and sort\nthrough--far beyond what individuals are capable of\nprocessing on their own. And yet, evidence increasingly\nsuggest that algorithms are no less immune to the biases\nand inefficiencies of the humans that created them,\nwithin the domains or sectors within which they are\nsituated (Kroll et al., 2017). Consistently, technology\nremains embedded within the specific historical social,\npolitical, and economic contexts--and existing systemic\nsocial injustices--in the domains and sectors in which\nthey are deployed, despite their owner's hopes for their\nUnderstanding algorithms as an extension of the\nconcept of bureaucracy, in terms of both their organiz-\ning and legitimizing functions, is one step towards\nunderstanding how organizations have become more\nhomogenous in the era of algorithms and data-driven\nprocesses. In their analysis about the similar function\nbureaucracy played centralizing the power of the state,\nDiMaggio and Powell provide one set of mechan-\nisms--predictors of isomorphic change--that is useful\nfor conceptualizing how organizational contexts\nbecome embedded within other dependent organiza-\ntions, through the administrative processes of data\nand algorithms. This work is useful for re-orienting dis-\ncussions about how to assess the values driving the\nshaping of an organizational field, such as the news\nmedia industry.\nWhere the analogy between algorithms and bureau-\ncracy falls short can also illuminate broader concerns\nabout introducing accountability mechanisms within\nalgorithmic systems. Bureaucracies were implemented\nby human beings and tend to have humans at most\nends of the bureaucratic process. Within these more\nalgorithmically-driven systems, humans are part and\nparcel of how individuals, behaviors, and content\nbecome classified and embedded within algorithmic-\nsystems (e.g. the use of journalists to train the\nFacebook Trending Topics algorithm (Nunez, 2016)).\nHowever, automation and algorithms may take over\nmany processes, leading to fewer points of access for\nindividuals to question or critique how they have been\nclassified into the system (Eubanks, 2018).\nAdditionally, the human element of bureaucratic sys-\ntems may in some way reduce the complexity of the\nbureaucratic systems. If humans are responsible for car-\nrying out mechanisms of bureaucracy, to some degree,\nthey must understand how the bureaucracy works.\nWithin algorithmic bureaucracies, code often serves to\nmediate these relationships, as well as the relationships\nbetween data collected through the platform, reducing\nthe number of people capable of understanding the\ncomplexities of the whole system, as well as opportu-\nnities for critiquing process or whistleblowing.\nThe news media industry has been irrevocably\nshifted in the era of data and algorithms. In many\nways, these mechanisms brought about positive\nchanges to an industry that has long been hegemonic,\ntop-down, and controlled by powerful corporate inter-\nests that were allowed to consolidate in the late 1990s\nafter changes to the Telecommunications Act (Croteau\nand Hoynes, 2006). While algorithms are only a small\npart of what is inducing change across the news indus-\ntry, the Facebook example shows that power rests not\nin an algorithm's capacity to induce a new logic into an\nindustry, but in its function as an administrative mech-\nanism that is embedded with the values and cultural\nand economic environment of their creators. In this\nprocess, algorithms shape all other organizations and\nindividuals operating within a given landscape.\nIn studying the role data and algorithms have in\nreproducing the structure of social life, there has been\na significant emphasis placed on gaining access to the\nspecific technologies themselves. Efforts to increase the\ntransparency or auditability of algorithms and data rest\non the assumption that gaining access to code, or even\nthe data used to train machine learning models, can pro-\nvide us insight into what goes wrong when there are\nbiases or inefficiencies within systems (Diakopoulos,\ntheory shows that, to the extent that one organization\nis able to control the behaviors, actions, or incentives of\nother organizations through changing the structure of\ntheir system unilaterally, the ripple effects go far\nbeyond the code itself. More research is needed to under-\nstand how the interplay between organizations in the\nnews ecosystem are influencing each other and being\nimplemented through code. Increasing oversight or\naccountability into how an industry has been shaped\nCaplan and boyd 9\nby a dominant organization is incredibly complex, and\nentails a system-wide analysis of how organizational\nincentives, built into algorithms, both operate as a con-\nstraint across a field, and are themselves constrained by\nlarger macro-sociological trends.\n"
}