{
    "abstract": "Abstract\nWe considered whether optic flow generated by 3D relief of a foreground surface might influence\nvisually-mediated self-motion perception (vection). We generated background motion consistent\nwith self-rotation, and a foreground object with bumpy relief was either rotated with the observer\n(ego-centric) or fixed in world coordinates (world-centric). We found that vection strength ratings\nwere greater in conditions with world-centric retinal motion of the foreground object, despite\ngenerating flow that was opposite to background motion. This effect was explained by observer\njudgments of the axis self-rotation in depth; whereas ego-centric flow generated experiences of\nmore on-axis self-rotation, world-centric flow generated experiences of centrifugal rotation\naround the foreground object. These data suggest that foreground object motion can increase\nthe perception of self-motion generated by optic flow, even when they reduce net retinal motion\ncoherence and promote conditions for multisensory conflict. This finding supports the view that\nself-motion perception depends on mid-level representations of whole-scene motion.\n",
    "reduced_content": "Short Report\nA New Angle on\nObject-Background\nEffects in Vection\nJuno Kim and Michael T. T. Tran\nSchool of Optometry and Vision Science, University of New South Wales,\nSydney, NSW, Australia\n Keywords\nself-motion perception, vection, diffuse, specular, reflectance, vision\nThe primary visual stimulus for self-motion perception is ``optic flow,'' which is generated\nby the light reflected by the surfaces of objects that move relative to the observer (Gibson,\n1950). The idea that this motion is ``relative'' implies that it is generated by either object or\nobserver. The only way for the brain to differentiate between these different causes is through\nthe visual processing of some constraints that might be diagnostic of one type of motion over\nthe other. In some situations, the visual motion is entirely consistent with physical self-\nmotion, and the perceptual result is the experience of compelling illusions of self-motion\nwhen completely stationary, known as ``vection.''\nThe power of vection illusions has attracted extensive research, culminating in the strong\nassertion that vection critically depends on motion of some inferred background in the scene\nCorresponding author:\nJuno Kim, School of Optometry and Vision Science, University of New South Wales, Sydney, NSW 2052, Australia.\nEmail: juno.kim@unsw.edu.au\ni-Perception\nipe.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (http://www.\nus.sagepub.com/aboutus/openaccess.htm).\nwas enhanced by stationary objects presented in the foreground, but inhibited when the same\nobjects were situated (perceptually) behind the moving background. Ohmi et al. (1987)\nobtained similar findings, and Ohmi and Howard (1988) extended the effect to linear\nvection in depth generated by looming optic flow; a stationary pattern facilitated vection\nwhen perceived in the foreground, but suppressed vection when perceived behind the looming\noptic flow pattern. Kitazaki and Sato (2003) found that two transparent motions simulating\nupward/downward linear motion generated a perceived direction of self-motion that was\nopposite to the direction of the flow component perceived as farther in depth. Seno et al.\n(2009) proposed these effects support the hypothesis that vection is driven by motion\nperceived in the background and not the foreground.\nContrary to the view that vection is determined solely by perceived background motion,\nevidence suggests that the perceived foreground can also influence vection. Nakamura and\nShimojo (1999) presented observers with two large transparent linear motions separated in\ndepth by disparity. They found that not only did the background motion enhance linear\nvection, but this vection was further increased in strength when slow foreground motion\noccurred in the opposite direction.\nAre there any plausible generative constraints on image motion(s) that might allow\nforeground properties of the environment to enhance vection? Observer motion relative to\na curved stationary foreground object is one ecologically valid way to generate opposing\ndirections of foreground and background motion that might increase vection. We put this to\nthe test using realistic real-time rendering in a virtual environment viewed through a stereo\nhead-mounted display (see Methods section). Realistic computer graphics was used to ensure\nthe vivid appearance of a continuous foreground surface. This also ensured that all the\nforeshortening cues available in real-life viewing situations were present in the display. We\nused global illumination mapping to immerse our 16 observers inside the Uffizi Gallery of\nFlorence Italy for up to 15 min. This provided a nice break from reality for hard working\nundergraduate observers who were nai\u00a8ve to the purposes of the current experimental\nprotocol approved by the Human Research Ethics Advisory Panel at the University of\nNew South Wales.\nThe observer's point of view was simulated a short distance in front of the bumpy object in\nfront of them at the center of the scene (Figure 1). There were two independent variables:\nfixation type and type of object motion, both with two levels; Fixation was either with free\nviewing or with central fixation of a red spot situated just in front of the surface at no closer\nthan 12.5% of its maximum radius. For object motion conditions, the surrounding scene\nalways rotated around the observer, simulating en bloc yaw rotation of the whole body.\nWhereas in two of the conditions, the central object rotated in the same direction as the\nscene (world-centric), the other two conditions maintained the object's stationary orientation,\nholding constant the retinal image it generated (ego-centric). Note how in world-centric\nconditions the motion of the object's foreground relief is right to left--the opposite of that\ngenerated by motion of the background (Figure 1(b)).\nFigure 2(a) shows the results of observer estimates on their perceived axis of rotation during\n10s viewing trials of each simulation condition. A value of zero corresponds to on-center axis\nrotations, like spinning on a swivel chair. A value of 1 corresponds to off-center axis rotations,\nwhere the axis of rotation is situated at the center of the bumpy object, like being spun in a\ncentrifuge. A two-way ANOVA (analysis of variance) showed no significant main effect of\nfixation type, F(1, 15) \u00bc 3.22, p \u00bc .093. However, there was a significant main effect of relief\nThese results show that foreground relief motion has a profound effect on the perceived\naxis of rotation; compared with more on-center yaw rotation experienced during ego-centric\nrelief motion, observers perceive more centrifugal self-motion when viewing world-centric\nrelief motion. When prompted for feedback after their participation, observers reported\nFigure 1. The arrangement of the simulated environment. (a) Schematic showing the organization of the\nbackground scene and foreground object relative to the observer. (b) Overview of simulated rotations of\nobject and scene. Dashed arrows show direction of simulated physical rotation. Solid gray arrow shows the\npath of an observer's perceived centrifugal orbit (rotation and translation) in the world-relief conditions.\nNote diagrams not to scale.\nFigure 2. Perceptual estimates of self-motion. (a) Mean location of perceived axis of rotation in depth (d)\nfor conditions with (red) or without fixation (blue) during presentation of ego-centric and world-centric\nrelief. Larger values correspond to increasingly centrifugal rotation, whereas lower values correspond to\nincreasingly on-center axis rotation. (b) Mean vection strength ratings for the same simulation and viewing\nconditions. Error bars show standard errors of the mean.\nKim and Tran 3\nexperiences of self-rotation in ego-centric conditions, as though they were spinning on a\nswivel chair. They reported experiences of centrifugal motion in world-centric conditions,\nas though they were being flung around the 3D object situated in front of them.\nDo these differences in the path of self-motion influence vection strength? Figure 2(b) shows\nmean vection strength ratings following 30s viewing of the same simulations. A two-way\nANOVA found no main effect of fixation, F(1, 15)\u00bc 0.18, p\u00bc .68. There was a main effect of\nvection and perceived axis of rotation data together point to the possibility that vection might\ndepend on the inferred distance of axis of rotation; perceiving more centrifugal self-motion leads\nto stronger experiences of vection, compared with the perception of on-axis self-rotation. If this\nnotion is at the very least supported by the significant differences above, then we should find an\nobserver-wise relationship between vection and perceived axis of rotation.\nTo test this idea, we performed a correlation between the normalized estimates of vection\nstrength and perceived axis of rotation. Data across fixation conditions were averaged for\neach observer. Figure 3 plots normalized vection strength as a function of normalized\nperceived axis of rotation in depth. Each data point corresponds to the average across\nconditions with and without fixation. In support of the view that vection is influenced by\nperceived axis of self-rotation, there was a significant correlation between vection strength\nsuggests that approximately 31% of the variability in vection strength estimates is explainable\nby variations in the perceived axis of self-rotation.\nFigure 3. Normalized vection strength estimates plotted as a function of perceived axis of (self-)rotation in\ndepth. Line of best fit superimposed. Values for perceived axis location in depth range from 0.0 (observer-\ncentred) to 1.0 (object-centred). Note the positive relationship between vection strength and perceived\ndistance of the axis of rotation in depth (r \u00bc \u00fe0.56).\nThese findings extend those of a previous study by Nakamura and Shimojo (1999) who\nfound that vection generated by background motion could be increased by adding slow\nforeground motion in the opposite direction. Our data replicate this finding in circular\nvection induced by simulated self-rotation and further suggest this effect can be explained\nby differences in the perceived axis of rotation.\nSeno et al. (2009) showed that vection is generated by motion perceived as the\nbackground, leading to their support for ``the object and background hypothesis in\nvection.'' However, we placed a foreground object in all our conditions, so the light field\nwould have generated experiences of background motion unambiguously across conditions.\nAlso, the perceived distance of the foreground object did not vary significantly between\nexperiences of world-centred and object-centred motion due to the available disparity cues.\nHence, the effects we observe are consistent with vection depending not on background\nmotion per se, but on dynamic properties of perceived scene layout.\nTo informally verify that the direction of foreground motion relative to the background\nwas critical for vection effects observed here, we presented displays with inverted object\nrotation to three of the observers. All reported that vection generated by these inverse-\nrotation displays was weaker than that generated by the world-centric rotation condition.\nObservers indicated after viewing these displays that the condition with the inversely rotating\nobject appeared unnatural or even plain ``weird'' (quoting one observer), as though the object\nwas moving independently. This suggests that vection strength depends on the precise\nconfiguration of foreground\u00adbackground motions in the display, and not merely the\nmotion of the foreground object per se. It is possible that this decline in vection might be\ndriven by a decline in the realistic appearance of the display (Riecke, Schulte-Pelkum,\nAvraamides, Heyde, & Bu\n\u00a8 lthoff, 2006) or the inability to compute a valid interpretation of\nThe pattern of data we obtained is also consistent with the view that vection is not\nimpaired by sensory conflicts. Contrary to Zacharias and Young (1981) who proposed that\nvection should be optimized when sensory conflict is minimized, we find greater vection in\nconditions of apparent off-axis self-rotation expected to apply centrifugal forces to the head.\nThis expected stimulation should increase greater activity of otolithic vestibular receptors,\ncompared with perceiving on-center rotation. However, the resulting sensory conflict\nincreased vection strength in our stationary observers, rather than impairing it. This\nfinding supports other research showing that vection is increased by viewpoint jitter, which\nis expected to generate greater otolithic stimulation and sensory conflicts (Palmisano et al.,\nObserver reports of the perceived axis of rotation varied significantly across conditions\nwith or without relative object rotation. This variation in their inferred axis of self-rotation\naccounted for nearly one-third of the variation in normalized vection strength ratings.\nAlthough engagement of eye movements can influence vection strength (Kim & Palmisano,\n2010), it is possible that there may have been little engagement of eye movements in free\nviewing conditions, as we found little difference compared with fixation conditions. Hence,\nany potential influence of retinal motion on this effect is yet to be identified.\nTogether, the results of the current study support the view that the strength of vection and\nperceived path of traversal depends on mid-level interpretations of foreground object motion\nin the context of background motion. The novel findings with the perceived axis of rotation\ncould be extended in future research to investigate the role of different forms of perceptual\nscene decomposition on the experience of self-motion in real-world contexts.\nKim and Tran 5\nMethods\nObservers\nSixteen adult observers with normal or corrected-to-normal visual acuity participated in the\nstudy. Observer recruitment and participation in the study adhered to ethical principles of the\nHuman Research Ethics Advisory panel (HREA) for biomedical research at the University of\nNew South Wales and the Declaration of Helsinki.\nStimulus Generation and Display\nThe scene was a background illumination map, the Uffizi light field, used commonly in\ngraphical lighting simulations (Debevec, 2002). This background was simulated at infinity.\nThe foreground object was a bumpy spheroid generated by perturbing the 10,250 vertices of a\ngeodesic sphere using cloud-noise as a height map. The graphical simulation was generated\nby custom software written in C/C\u00fe\u00fe with embedded calls to the OpenGL Shading\nLanguage. The object occupied approximately \u00c615 of the central visual field, and it was\nsimulated at a distance of 2 m from the observer.\nThe display of scene content was administered using the Oculus Rift Development Kit 2.\nThe simulation made calls to the Rift's development library to present stereo images of the\nworld with disparity to each eye. Hence, each frame in time was rendered twice, once for the\nleft and once for the right eye's view, achieving approximately 60 fps for each eye. The light\nfield was rotated around the object and observer in yaw at approximately 0.125 Hz across all\nconditions. The display had an approximate horizontal field of view of 110 (80 vertical)\nwith 18 pixels per degree visual angle, comparatively better than the Oculus Rift DK 1 (Kim,\nChung, Nakamura, Palmisano, & Khuu, 2015).\nProcedure\nThere were four conditions in a 2 \u00c2 2 design: fixation condition (fixation or no fixation) and\nobject motion (ego-centric or world-centric). Ego-centric rotation was where the image of the\nobject did not change across conditions, consistent with an observer rotating on a swivel\nchair while inspecting an object they hold in front of them. World-centric rotation was where\nthe image of the object changed to be consistent with the observer walking at a constant\nradial distance around a completely stationary object.\nObservers were exposed to randomized presentations of each display condition for a\nperiod of time, after which time, they used a rating bar to set either their report of the\nvection strength or the apparent location of the axis of self-rotation between the object\nand themselves. The same rating bar was used to indicate responses over a 0 to 1 range.\nIn vection strength rating conditions, two repeat trials were presented, each for a total of 30 s\nduration. In conditions where the axis of rotation was estimated, presentations were limited\nto 10 s and one repeat trial per condition.\nResponses were recorded and averaged into mean scores from each observer in each\ncondition. A two-way repeated-measures ANOVA was performed to test for any main or\ninteraction effects. Correlation was used to test for relationships between normalized vection\nstrength and perceived axis of rotation. Vection strengths were normalized for each observer\nin this correlational analysis to eliminate variability introduced by differences in the\npsychophysical range of vection experiences across observers (Normalized score \u00bc raw/SD).\n"
}