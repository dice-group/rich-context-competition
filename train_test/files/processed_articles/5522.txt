{
    "abstract": "Abstract\nIn this article, we studied perception of a particular case of light fields that is characterized by a\ndifference in its consistent structure between parts of a scene. In architectural lighting design, such\na consistent structure in a part of a light field is called a light zone. First, we explored whether\nhuman observers are sensitive to light zones, that is, zones determined primarily by light flow\ndifferences, for a natural-looking scene. We found that observers were able to distinguish the light\nconditions between the zones. The results suggested an effect of light zones' orientation.\nTherefore, in Experiment 2, we systematically examined how the orientation of light zones\n(left-right or front-back) with respect to a viewer influences light inferences in symmetric\nscenes. We found that observers are quite sensitive to the difference in the light flow of the\nlight zones. In addition, we found that participants showed idiosyncratic behavior, especially for\nfront-back-oriented light zones. Our findings show that observers are sensitive to differences in\nlight field structure between two parts of a scene, which we call visual light zones.\n",
    "reduced_content": "Article\nVisual Light Zones\nTatiana Kartashova and Huib de Ridder\nPerceptual Intelligence Lab, Delft University of Technology,\nthe Netherlands\nSusan F. te Pas\nExperimental Psychology, Utrecht University, the Netherlands\nSylvia C. Pont\nPerceptual Intelligence Lab, Delft University of Technology,\nthe Netherlands\n Keywords\nlight, light field, light zones, visual perception, illumination, light properties\nIntroduction\nCan one make visual estimations of something that can not be seen? Yes, human observers\nare sensitive to the light field in empty space (Koenderink, Pont, van Doorn, Kappers, &\nfit the intensity, direction, and diffuseness of light on a matte white sphere to a scene basing\nCorresponding author:\nTatiana Kartashova, Perceptual Intelligence Lab, Delft University of Technology, Landbergstraat 15, 2628 CE Delft,\nthe Netherlands.\nEmail: kartashovata@gmail.com\nCreative Commons CC BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License\n(http://www.creativecommons.org/licenses/by/4.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/\nopen-access-at-sage).\ni-Perception\njournals.sagepub.com/home/ipe\non appearance of objects in that scene. This sensitivity was named the visual light field\n(Koenderink et al., 2007). Moreover, observers can robustly estimate these light properties\nthroughout an empty space (Kartashova, Sekulovksi, de Ridder, te Pas, & Pont, 2016), and\ntheir inferences agree with homogeneous, converging, or diverging superpatterns (van Doorn,\nKoenderink, Todd, & Wagemans, 2012). The human ability to infer light in (empty!) space is\nan interesting scientific topic in itself and also relates to questions about interdependency of\nlight, shape, and material perceptions. In this article, we further explore visual light fields\nby investigating inferences on spatially varying superpatterns, created by variation in\nillumination over scenes.\nLight fields (Gershun, 1939; Mury, Pont, & Koenderink, 2007) in natural scenes can contain\nuniform, convergent, divergent, rotational, and deformation patterns (Mury, 2009). A uniform\npattern is formed by perfectly collimated light (having parallel light rays), for example, direct\nsunlight. Convergent and divergent patterns are formed by light that focuses in a point or\nspreads out from a point, respectively. A rotational pattern is formed by light that cycles\naround a point. Finally, a deformation pattern has a complex flow structure, for example, a\nsaddle. Van Doorn et al. (2012) showed that observers group local shading patterns into global\nsuperpatterns that appear to be illuminated in some unitary fashion. They found that observers\ncan perceive uniform, convergent, and divergent patterns but that they are blind to rotational\nand deformation patterns. The question we address here is whether observers are able to\nperceive such global superpatterns if a single scene contains two of such patterns.\nIn the architecture field, such patterns or consistent structures within complex light fields\nwere named light zones by Madsen (2007). She introduced the concept of light zones,\nprovided several practical examples and defined them as ``(spatial) groupings of the\nlighting variables (intensity, direction, distribution and colour), which are significant to the\nspace and form-giving characteristics of light.'' We note that light zones or the zone system\nwere also introduced in photography by Adams (1948); yet, those zones concern luminance\nranges of photographed scenes used for determining optimal film exposure. This is of course\nclosely related to lightness perception and spatial grouping on the basis of intensity, which\nwas already intensely studied (see later). We here study light zones in Madsen's (2007) sense\nof spatially segmented parts of a scene that can be grouped on the basis of the structure of the\nlight flow, or, in van Doorn et al.'s words, ``global super-patterns that appear to\nbe illuminated in some unitary fashion.'' As van Doorn et al., we consider primarily\nthe directional properties of the light field structure, the light flow, for this segmentation.\nMoreover, we restrict our light zones to flow structures that are uniform/divergent/\nconvergent. Please note that the superpatterns that van Doorn et al. studied were defined\nin a plane but that they can be easily extrapolated to three-dimensional spaces especially for\nthese simple structures.\nAlthough under different names, the concept of light zones can be found in a number of\nperceptual studies. The first prominent example is Gilchrist's (1977) experiment on the\nperceived lightness of a patch, which depended on its perceived position. Stimuli consisted\nof two empty spaces, a dark one in the front and a bright one in the back, which were\nconnected with a door opening. When a patch was thought to be in the brightly lit back\nspace (one light zone), its matched lightness was much lower than when it appeared to be in\nthe dim front space (another light zone). Snyder, Doerschner, and Maloney (2005) changed\nthe apparent depth of a probe sphere by manipulating retinal disparity. The sphere could\nappear to be placed either in a far bright room or in a close dark room, along the observer's\nline of sight. Hence, retinal disparity moved the probe between different light zones. This\nmanipulation affected the perceived lightness of the probe. Schirillo (2013) discussed this and\nother examples in which the lightness and chromaticity of patches were judged in depth\nplanes with different illuminations. He concluded that human observers are able to infer\nthe light in empty space (between illuminated objects). This was tested and confirmed in\nKoenderink et al.'s (2007) visual light field study. Toscani, Gegenfurtner, and Doerschner\n(2017) studied the difference in perception of illumination in #thedress scene between\nobservers who see the dress white and gold and those who see it blue and black. The light\nwas probed in front of the dress and in the background. It was found that in the background,\nthere were no differences in chromaticity settings between different perceivers. However,\nin the foreground, the white-perceivers made bluer settings than blue-perceivers, making\nthe chromatic difference between the front and back of the scene more pronounced.\nThe foreground and background in this case represent two zones with different\nilluminations. The question remains whether observers are able to spatially segment parts\nof a scene on the basis of the structure of the light flow, that is, the directional properties of\nthe light.\nThe study presented in this article was inspired by an experiment using 17th century Dutch\npaintings (Kartashova, de Ridder, te Pas, Schoemaker, & Pont, 2015), results of which\nshowed a relation between settings consistency and the complexity of light fields in painted\nscenes. In that experiment, we tested the perception of light on objects and in empty space.\nObservers were asked to infer light either on volumetric objects cutouts from images of six\npainted scenes, or in empty space in positions of those cutout objects in the scenes. The\nconsistency of observers' settings varied greatly between paintings. Four paintings contained\nseemingly consistently structured light fields (uniform or diverging), or a single light zone.\nFor those paintings, the observers' settings were rather consistent between conditions\n(comparing settings for the cutout object with those for the probe in the painting) and\nwithin a scene. However, for the other two paintings, the observers' inferences varied\ngreatly. One of those paintings showed an interior and exterior through a window\nopening, and the other an interior and back room through a door, thus, both paintings\nseemed to present two spaces with different light qualities--including its directional\nproperties. The most likely explanation of the inconsistencies in the observers' settings was\nthe presence of two light zones in both paintings. The observers seemed to interpret the\nborder between the zones idiosyncratically; some inferred two different illuminations in\nthe two parts of the scene, while others made settings as if there was only one light zone.\nIt was an interesting finding; yet, we could not compare the settings of observers to the\nveridical values in those scenes because they were painted hundreds of years ago.\nOur goal in the current study is to investigate the perception of light properties in scenes\nwith two light (direction) zones. We performed two experiments. The first experiment (see\nExperiment 1 section) had an explorative nature and was done to test whether we could\nrepeat the finding of our former study and to analyze how it is related to the physical light\nfield. We built a model of a natural scene and illuminated it with two configurations of light\nsources, both creating two light zones. The two configurations were designed to have different\norientations with respect to the viewing direction. The visual light field was measured over a\ngrid of points, analyzed, visualized, and compared with the physical light field. In the second\nexperiment (see Experiment 2 section), we focused on the specific question whether the\norientation of the light zones (in the picture plane vs. in depth) influences the light\ninferences. In Experiment 2, we used less probes per scene to allow probing more\nillumination configurations, and we used a controlled environment. Finally, we discuss the\nobtained results and propose further directions for research on light zones perception (see\nDiscussion and Conclusion section).\nKartashova et al. 3\nExperiment 1\nThe aim of the first experiment was to investigate whether human observers are able to\ndistinguish differences in light properties between physical light zones that were designed\nto have prominent differences in light directions. We created a scene with two illumination\nconditions. One condition produced different light zones in the left and in the right part of the\nscene; another condition created different light zones in the front and in the back parts of\nthe scene. We obtained visual light fields for both illumination conditions by sampling the\nobservers' light inferences over a grid of positions (for method, see Kartashova et al., 2016).\nMethods\nStimuli. We created a model of a scene resembling a living room and illuminated it using two\nsets of light sources (see Figure 1). In both illumination conditions, the light sources were\nplaced such that approximately half of the scene was in one light zone and approximately half\nin another. The main difference between the light zones was the light direction. In the first\ncondition, the illumination direction differed between the left and right sides of the scene,\ncreating a left-right (LR) light zones condition. The left side of the scene was illuminated\nfrom top-left, with the lamps on the ceiling of the room, and the right part from top-right\nwith the sun shining through the window. The second, front-back (FB) condition had the\nfront part illuminated from the top-front, via lamps above the viewer (not visible in\nthe image), and the back part was illuminated from the left with the light coming through\nthe door in the back of the room. The light of the lamps was simulated by small spherical\nlight sources producing diverging light. The sun- and skylight was simulated by small\nluminous planes. We rendered images of 1,200 \u00c2 900 pixels size with the following settings:\nlinear gamma, mental ray renderer (built-in software for rendering of images and light\nmeasurements), minimum 1 sample per pixel, maximum 128 samples per pixel.\nSetup. To measure the visual light field in the scenes, we used a light probing approach\n(Kartashova et al., 2016; Koenderink et al., 2007). During the actual measurements,\na white matte sphere on a black monopod was superimposed on an image of the scene.\nObservers could control the direction of the light on the sphere via mouse movements and\nthe intensities of the directed and ambient lights using keyboard buttons. From the observers'\nFigure 1. Scenes of Experiment 1. Left is the left-right (LR) condition, and right is the front-back (FB)\ncondition.\nsettings, we also extracted the diffuseness of the light, parameterized as 1 minus the ratio\nbetween the directed and ambient intensities (Xia, Pont, & Heynderickx, 2016b). The\ndiffuseness can range from fully collimated light (e.g., sunlight) to fully diffuse or Ganzfeld\nillumination (e.g., light in the mist on a snowy field).\nTo define the positions and sizes of the sphere and pole, we created a grid of spheres\nstanding on poles in the model, five spheres in width, five in depth, and three in height. The\ngrid was positioned in the scene such that for both illumination conditions, the vertical\nmiddle planes of the grid were on the borders between the light zones (see Figures 2\nand 4). The grid was also adjusted such that the poles were always standing on\nnonoccluded objects to clearly define the spheres positions. For Figure 4, the probes were\nrendered in the scenes.\npixels, Retina Display, luminance range from 0.4 cd/m2 to 330.8 cd/m2). The experiment\nsequence and controls were developed using the Psychtoolbox library (Brainard, 1997;\nPelli, 1997). The light in the room was switched off to avoid illumination interference on\nthe screen. The viewing distance of the observers was fixed at 27 cm from the screen with a\nchin rest to keep the viewing angle the same as that of the virtual camera used for rendering.\nThe images and probe were presented in grayscale because we wanted primarily to test the\ninfluence of the distribution of light. The images, probe, and screen were calibrated linearly.\nProcedure. At each trial of the experiment, observers were asked to set the illumination on the\nprobe to make it appear as if it belongs to the scene. The experiment consisted of two blocks\nfor the two conditions: LR and FB. Half of the observers started with the LR scene and half\nwith the FB scene to balance the order. In each condition, observers made one setting for\neach grid position and two additional settings for probes corresponding to the red spheres\nin Figure 2. Having three repetitions in these points allowed us to compare the spread of the\nsettings within observers across light zones and illumination conditions.\nBefore the experiment, we explained the procedure, task, and probe controls to the\nobservers. We did not explain the concept of light zones to the observers. To explain the\ntask, we showed a scene resembling a different room that was not used in the experiment,\nwith spheres rendered in it. Then, we performed three trials for training the use of the\ncontrols, after which the two parts of the experiment were conducted.\nParticipants. Ten observers participated in this experiment. The participants were naive\nwith respect to the setup and purpose of this experiment. All participants had normal or\nFigure 2. Schematic representation of the measurements positions. The positions of repeated\nmeasurements are marked with red. The viewing plane orientation is denoted as a green line.\nKartashova et al. 5\ncorrected-to-normal vision. They all gave written, informed consent. All experiments were\ndone in agreement with the Declaration of Helsinki, Dutch Law, local ethical guidelines, and\napproved by the TUDelft Human Research Ethics Committee.\nIn-scene light measurements. In addition to the psychophysical measurements, we also\nperformed measurements of the light in the modeled scene. For this purpose, we used the\nLighting Analysis Assistant tool of the Autodesk 3ds Max system, which allows virtual\nilluminance measuring. We created a grid of virtual cubic illuminance meters (six\nilluminance meters on a cube, which allows to measure a first-order approximation to the\nlight field, see Xia, Pont, & Heynderickx, 2016a; Xia et al., 2016b) using a script. We set the\nmeasurement cubes to be in the same positions as the probes. The script placed all six meters\nin the same position, with the sensors facing the positive and negative directions of each\naxis (see details in Kartashova, de Ridder, te Pas, & Pont, 2018). Then, for each cube,\nwe extracted from the resulting six luminance measurements the intensity, diffuseness, and\ndirection of the light using Cuttle's (2003, 2013) formulas and interpolated them to obtain a\nrepresentation of the mathematical first-order structure of the ``physical'' light field in the\nscene (Kartashova et al., 2016). Alternative could be estimating the properties from for\ninstance local spherical panoramic images. They are easy to use in rendered scenes, yet\nwould require a spherical harmonics decomposition to compute the properties. Xia, Pont,\nand Heynderickx (2016a, 2016b) showed that the cubic approach forms a computationally\neasier approach. Moreover, it can easily be used in real scenes too.\nWe visualized the light fields as light tubes (see Figure 3). A tube is aligned to the light\nvectors along its length. A tube's path is calculated via interpolation methods (see\nKartashova et al., 2016; Mury, Pont, & Koenderink, 2009 for the details). The thickness\nof a tube is inversely proportional to the light intensity. The physical light field in the LR\ncondition contains curved tubes. This happens because in the middle of the measured volume,\nthere is a space that is occluded from all direct light sources, where light arrives mostly\nthrough scattering from the floor. Therefore, it is dim (the tubes are rather thick), and the\nFigure 3. The mathematical first-order structure of the physical light fields for the stimuli used in\nExperiment 1. Left is the LR (left-right) orientation, and right is the FB (front-back) orientation.\nlight vector is directed downward (to the floor, a secondary light source). It is clear that the\nlight direction in the left side of the measured volume is very different from the middle and\nthe right side of the volume. There is less curvature in the light field topology for the FB\ncondition because there is almost no space occluded from the direct light sources. As a result,\nthere is a clear division between the light zones, one being in the volume of the light from the\ndoor, and the other in the volume of the light from the lamps.\nResults\nFrom the observers' settings on the spheres, we obtained psychophysical measurements of the\ndirection, intensities (directed and ambient), and diffuseness of light in the two illumination\nconditions. The diffuseness D was calculated in accordance to the following formulas (Cuttle,\nE x\n\u00f0 \u00de \u00bc Ex\u00fe \u00c0 Ex\u00c0 \u00f01\u00de\nEvector \u00bc\np\n\u00f0x\u00de\n\u00f0 y\u00de\n\u00f0z\u00de\n$Ex \u00bc\nEx\u00fe\n\u00fe Ex\u00c0\n\u00c0 Ex vector\nEsymmetric \u00bc\n$Ex\n\u00fe $Ey\n\u00fe $Ez\nEscalar \u00bc Evector=4 \u00fe Esymmetric \u00f05\u00de\nD \u00bc 1 \u00c0 Evector=Escalar\nHere, E\u00fe\nand E\u00c0\nare the illuminance measurements on opposite sides of the cube; E(x)\n,\nE(y)\n, and E(z)\nare the light vector components on each axis; Evector\nis the light vector\nmagnitude; Esymmetric\nis the symmetric illuminance; and Escalar\nis the mean illuminance in\na point. For the observers' settings, directed and ambient light were taken as the magnitudes\nof Evector\nand Esymmetric\n, respectively, after correction for the clipping of intensities on the\nprobe. The diffuseness D ranges from 0 (fully collimated light) to 1 (fully diffuse light).\nTo analyze the results quantitatively, we grouped the settings according to the positions of\nthe probes. The grid was ``sliced'' into planes parallel to the border between the light zones\n(see Figure 4). In the LR condition, the probes were grouped parallel to the viewing direction\nand in the FB condition parallel to the picture plane. Thus, each of the five groups of data\npoints contained the directional settings of all observers (including the repetitions) on all\nprobes of a slice.\nFigure 5 shows the distribution of the directional settings on spheres, with the mean\ndirection represented by a red dot and one standard deviation by red ellipses, for each\nplane and both conditions. The ellipses' short and long axes were determined by projecting\nthe data on a plane and calculating standard deviations of the resulting bivariate\ndistributions. It is clear that the settings on the two left spheres in Figure 5 (left light zone\nfor LR, and back light zone for FB) are dramatically different from the settings on the two\nright spheres (right light zone for LR, and front light zone for FB). The angular differences\nbetween the means of the different light zones are large: from 82 to 111 for LR and from 49\nto 61 for FB. In contrast, the differences for planes in the same light zones are small: 24 and\n12 for LR, and 4 and 8 for FB. This suggests that observers were on average able to\ndistinguish the light zones. However, the data show quite some variation, and therefore we\nnow analyze individual results in detail.\nKartashova et al. 7\nHaving the observers' settings for a grid of points allowed us to reconstruct the visual light\nfields via interpolation (Kartashova et al., 2016; Mury et al., 2009); see Figure 6 for three\nrepresentative cases per condition. Generally, in the LR condition, there is an apparent\ndistinction between the light zones with the border slightly varying from one observer to\nanother, but roughly in the middle of the measured volume (see Figure 6, top row). For none\nof the observers, we found curved light tubes in the center of the scene, as in the physical light\nFigure 5. Distribution of settings per slice. The first row shows the results for the LR (left-right) condition,\nthe second row for the FB (front-back) condition. Each sphere represents all the directional settings of all\nobservers on all the spheres of a corresponding slice. The red dots represent the mean directions; the red\nellipses represent one standard deviation.\nFigure 4. Slicing of the resulting settings. Left is the LR (left-right) condition sliced parallel to the viewing\ndirection, and right is the FB (front-back) condition sliced across the viewing direction.\nfield (see Figure 3). This confirms our previous finding that human observers ignore subtle\nvariations in physical light fields (Kartashova et al., 2016). The visual light fields in the FB\ncondition differed from one observer to another (see Figure 6, bottom row). In the left\nvisualization, the tubes in the back of the room seem to flow to the door, whereas the\ntubes in the rest of the room point to the lamps in front; in the second figure, all the tubes\npoint to the lamps; and in the third, most of the tubes point to the door.\nWe analyzed the spreads of the data between and within observers (see Figure 7). As a\nmeasure of the spread of the directional settings, we took the dispersion 1/R, where R was the\nlength of the vector summation of the settings represented as unit vectors divided by the\nnumber of measurements (Leong & Carlile, 1998). R has the highest value (namely 1) when\nall the vectors point in the same direction, it decreases with increasing spread, and it is\nsmallest (namely 0) for data that are uniformly spread over all directions. So, 1/R ranges\nfrom 1 to infinity. The motivation of using such method is that the data have a spherical\nnature, and therefore, such a spherical analysis is better suited than splitting the data into two\nangles. For the interobserver spread of the directional settings, represented in the first column\nand row of Figure 7, we calculated the dispersion 1/R for all settings of all observers on all\nspheres of a slice, including the repetitions (thus, the same data as we grouped in Figure 5\nfor calculating means and ellipses). For the LR light condition (left half of the graph), the\ndispersion peaks on the middle plane and otherwise is relatively low. The dispersions in the\nFB condition (right half of the graph) seem more uniform across the slices than in the LR\ncondition and on average higher. We did not calculate the significance of the differences\nbetween the data for the slices because we did not have a tool at hand for the analysis of\nsuch spherical data. The dispersion between repetitions (within observers) was calculated\nusing the repeated settings data for five probes. The five probes were selected from the\nnine repetition probes such that two of the probes lay in one light zone, two in the other\nFigure 6. Pairs of visual light fields of three representative observers. The first row represents results for\nthe LR (left-right) condition, the second row for the FB (front-back) condition. The green line denotes the\npicture plane. Yellow spheres represent the lamps. Black lines show the positions of the window and the\ndoor. The visualizations of the LR conditions have a rather clear border between the light zones, whereas for\nthe FB conditions, the visual light fields vary idiosyncratically.\nKartashova et al. 9\nlight zone, and one in the center of the grid. The dispersions between repetitions showed a\nsimilar pattern as those between observers. Moreover, the values of 1/R between repetitions\nor within observers seemed, overall, somewhat smaller than between observers.\nTo compare the intensity settings, we calculated the scalar illuminance (see Equation 5).\nFor diffuseness, we used the normalized diffuseness formula of Xia (Cuttle, 2003; Xia et al.,\n2016a; see Equation 6). We took the standard deviation as a measure of the spread of the\nintensity and diffuseness (see Figure 7). We found that the spreads for the intensities (ranging\nbetween 0.10 and 0.25, and we did not find significant differences for these data. Moreover,\nagain the values between repetitions or within observers seemed overall somewhat smaller\nthan between observers.\nSummarizing the results, the observers were able to distinguish the illumination differences\nbetween the light zones. In addition, we found trends in the data, indicating that there might\nbe idiosyncratic differences as well as differences between the light conditions: In the LR\ncondition, the results seemed to be consistent, except the plane between the light zones,\nwhereas in the FB condition, the spread values seemed on average higher than in the LR\ncondition. The question remains whether these differences between the conditions were\ngenuine or that they were evoked by other stimulus properties. The positions of light\nsources were different between the conditions, with respect to the scene geometry.\nSpecifically, in the LR condition, the light sources were on two opposite sides of the scene,\nand in the FB condition on two perpendicular sides. In addition, in the LR condition, the\nobservers could see the lamps and not in the FB condition. Finally, the scene was not\nsymmetric.\nFigure 7. Spreads of settings between observers in the first row and between repetitions in the second\nrow. The first column concerns the spread in the directional settings, the second column in the intensity\nsettings, and the third column in the diffuseness settings. For the bar charts between observers, each bar\nrepresents the spread between all observers' settings in one slice of the grid. For the bar charts between\nrepetitions, each bar represents an average of the spreads between observers' repetitions for each probe.\nLR \u00bc left-right; FB \u00bc front-back.\nWe performed a second experiment to study if the trends in the findings were indeed\ncaused by the light zones' orientations. In Experiment 2, we eliminated all the listed\ninterfering differences between conditions.\nExperiment 2\nThe goal of this experiment was to systematically investigate light perception for LR and FB\norientations of light zones. A rotationally symmetric scene was illuminated with three\nconfigurations of light sources, creating physical light zones. Viewing each illumination\ncondition from two perpendicular directions allowed us to test LR and FB orientations of\nthe light zones while keeping the actual light and geometry in the scene constant.\nMethods\nStimuli. The constructed scene contained a set of simple shapes that were placed and adjusted\nsuch that the scene was geometrically symmetric with respect to 90 rotations (see Figures 8\nand 9). The objects of the scene were chosen to induce a variety of light cues: shading,\nshadows, highlights, and interreflections. All objects were white, and most of the objects,\nexcept four spinners, were matte. The spinners were glossy. The ground plane was midgray,\nand the background was black. The scene was created and rendered in the same software as\nin Experiment 1.\nFor each illumination condition, the light sources were positioned at a 45 elevation with\nrespect to the center of the scene and the ground plane. For the first three conditions, we\nilluminated the scene with two identical small spherical light sources (see Figures 8 and 9).\nThe conditions were viewed from two directions, such that from one viewpoint the light zones\nwere on the left and on the right side of the scene (1LR, 2LR, and 3LR), and from the other\nviewpoint in the front and in the back of the scene (1FB, 2FB, and 3FB). We modulated the\npositions of the light sources and shades to create light zones differing in average light\ndirection. Conditions 1 and 2 both have identical positions of the light sources at opposite\nsides of the scene (see Figure 8, first row). In Condition 1, the shades partially occluded the\nlight so that the light source illuminated only the closer half of the scene. In Condition 2, the\nshades completely occluded the light on half of the scene. The placing and orientation of\nshades in these two conditions create light zones with complementary directions. As a result,\nin 1LR, the scene is illuminated from the left and the right (similarly to LR condition of\nExperiment 1), whereas in 2LR from the front and back. Condition 3 was selected to test a\ncondition that is similar to the FB condition of Experiment 1. In this condition, we used the\ncombination of the shades used in Conditions 1 and 2. The fourth condition contained a\nsingle light source, identical to the sources of previous conditions, creating a quite\nhomogeneous single light zone. This single light zone condition was created to have\nbaseline settings for each light direction. It was viewed from each side of the scene (front,\nright, back, and left). Thus, altogether, we created 10 test images, 6 with two light zones and\n4 with a single light zone (see Figure 9).\nSetup and procedure. The setup in Experiment 2 was the same as in Experiment 1. Each test\nimage contained five probes, one in each quadrant of the scene and one in the center\n(see Figure 10)--but during the experiment, only one probe was shown per trial. Five\nprobes do not suffice to model the global light field but allowed us to include more\nscenes in the experiment and systematically test the effects of light directions and viewing\ndirections. The adjustments were repeated three times for each probe and each test image.\nKartashova et al. 11\nThus, 10 test images \u00c2 5 probes \u00c2 3 repetitions constituted 150 trials, of which we randomized\nthe order of presentation.\nBefore the experiment, we explained the procedure, task, and probe controls to the\nobservers. We did not explain the concept light zones to the observers. To explain the\ntask, we showed two illuminations of the scene, which were not used in the experiment,\nwith spheres rendered in it. Then, we performed three trials for training the use of the\ncontrols and the experiment trials.\nFigure 8. Schematic representation of the tested conditions and views. Each image represents the top view\nof the scene and light sources (the distances to light sources and shades are not proportional). Red rectangles\nrepresent the cameras, labeled according to the resulting scene image. Yellow and blue circles represent the\nlight sources. Black bars show the shades, which partially occluded the light, so that the light source\nilluminated only the closest half of the scene. Black rectangles show the shades that completely occluded the\nlight on a half of the scene. Yellow and blue arrows show the approximate light orientation (as a vector,\npointing toward the source) in the zones of corresponding colors.\nAs in Experiment 1, we also conducted ``physical'' light measurements in the scene at the\npositions of the probes for each illumination condition.\nParticipants. Ten observers (different observers than who participated in Experiment 1)\nparticipated in this experiment. The participants were naive with respect to the setup and\npurpose of this experiment. All participants had normal or corrected-to-normal vision. They\nall gave written, informed consent. All experiments were done in agreement with the\nDeclaration of Helsinki, Dutch Law, local ethical guidelines, and approved by the\nTUDelft Human Research Ethics Committee.\nResults\nThe results of Experiment 2 consisted of observers' repeated settings on the five probes for the\n10 test images, 6 of which were pairs of light zones conditions, and the remaining 4\nconsidered the single light source condition. We made several comparisons of the results\nfor the direction settings. We arranged the results for each test image in three groups, with\nthe first group representing the settings on the two probes of the first light zone (L for LR and\nF for FB), the second group of the single middle probe, and the third group of the two probes\nFigure 9. Test images. The first two rows contain the conditions with two light zones. The first row shows\nthe LR orientations, the second row the FB orientations. The third row shows the single light zone condition\nfrom the left, front, and back (the right is not shown here because that is exactly mirrored to the left case).\nKartashova et al. 13\nof the second light zone (R for LR and B for FB). For the single light source condition, the\ndata were grouped into left, middle probe, and right parts of the scene with regard to the\nviewing direction.\nWe parameterized the directional variability via the dispersion 1/R as described in\nExperiment 1. Figure 11 shows that the dispersions are overall quite low and that they are\nsignificantly lower between repetitions than between observers (paired t test: t \u00bc 3.04,\np \u00bc .002 < .05). There are clear peaks for the B zones of 1FB and 2FB, both between\nobservers and between repetitions. The peaks are even higher than on the middle sphere,\nwhere high dispersion could be expected because this probe is on the border between the light\nzones.\nFigure 10. White spheres illustrating the positions of probes (for 2LR (left-right), with veridical probe\nilluminations). Each scene contained five probes, four in each quadrant of the scene and one in the center of\nthe scene. Only one probe was shown at a time. A probe did not produce a shadow in the trials.\nFigure 11. Inter- and intraobservers' variability of the directions of the settings (parameterized via the\ndispersion).\nFor comparison with the physical light directions for each probe, we calculated the mean\nangular differences between the veridical and the observers' inferred light directions. These\ndeviations from veridical again showed peaks for the B zones of 1FB and 2FB. We tested if\ndeviations from the veridical values for back light zones are significantly different from\ndeviations from the veridical values for front light zones. We made paired t tests of these\nt \u00bc 4.46, p \u00bc .000013). The large deviation from veridical that we find for the middle sphere of\nCondition 1 (middle bar of 1LR and 1FB in the Figure 12) is due to the physical light\ndirection being from below (light vector pointing down), while the observers inferred it to\nbe from above.\nWe also analyzed the distributions of the directional settings. Because all the light sources\nwere positioned on the same height (specifically, making a 45 angle between light source,\nmiddle of the scene and the scene floor plane), the differences in their positions could be\nspecified in the XY-plane/a top view. Figure 13 shows the circular histograms of the settings\nfor the data of all test images, with the data grouped in three clusters as above. The red lines\nin the centers of the circles show the veridical light directions (red dots instead of lines mean\nthat the veridical light vector points straight up or straight down). First, it is evident that the\nmajority of the settings are close to the veridical directions. Thus, observers were well able to\ndistinguish the light zones. If we take a closer look, we can see that for the back light zone of\n1FB and 2FB, there is a number of settings in the direction opposite to the veridical, whereas\nthis is not the case for the LR conditions. It appears from the plots that observers often made\nsettings on the probe in the back light zone opposite to the actual illumination in that light\nzone, but in accordance to the illumination in the front light zone. In addition, for these\nimages, the middle probe settings appear the same as those of the front probe, which is not\nthe case for the LR conditions.\nAs we explained in the Methods section, the two test images of the same light condition\ndiffered only in the direction of view. Thus, if the settings would depend only on light\ncondition and not on viewing direction, the settings for the LR and FB cases should\nbe the same up to a 90 rotation. For example, the settings in the L light zone of 1LR\nshould be the same as in the F light zone of 1FB, after a 90 correction. We tested the\nsignificance of the differences between pairs of directional settings (top view, as presented\nin Figure 13) after 90 corrections. To this aim, we used Watson's U2 test (code by Me\n\u00b4 gevand\nFigure 12. Deviations with respect to the veridical average light direction (light vector) as a function of\ncondition.\nKartashova et al. 15\n[https://github.com/pierremegevand/watsons_u2] based on equations by Zar, 1999) for\ncircular distributions. First, we compared the settings between the couples of light zones\nunder the same illumination (see Table 1). For example, L of 1LR versus F of 1FB, and\nL of 2LR versus B of 2FB. We found (see Table 1) that the front light zones of all FB\nconditions were not significantly different from the corresponding zones of the\nLR conditions, except for light Condition 2. However, the back light zones of all FB\nconditions were significantly different from the corresponding zones of the LR conditions.\nFor the single light source condition, the settings were compared for the pairs 4L versus\n4R and 4F versus 4B. We compared the pairs after flipping. The settings of 4L did not differ\nsignificantly from the (mirrored) settings of 4R. There was a significant difference between\nsettings 4F and (mirrored) settings for 4B.\nFigure 13. Top view circular histograms of direction settings. Settings are grouped such that the left\nhistogram of a test image shows the settings made on the two probes in the left or front light zone (for LR or\nFB, respectively), the middle histogram shows the settings on the middle sphere, and the right histogram\nshows the settings made on the two probes in the right or back light zone (for LR or FB, respectively). The\nred lines in the centers of the circles show the veridical light directions (red dots instead of lines mean that\nveridical light vector points straight up or straight down). The green line represents the picture plane.\nDiscussion and Conclusion\nWe investigated whether human observers can distinguish light zones that are determined by\na difference in overall light direction. In the first experiment, we measured and analyzed\nvisual light fields for two illumination conditions. In the second experiment, we created\nhighly controlled stimuli to systematically investigate the influence of light zones'\norientations. Specifically, we tested illumination perception in LR and FB orientations of\nlight zones.\nThe distributions, spreads, and visualizations of the first experiment's settings show that\nobservers were able to distinguish the illumination differences between the light zones. This\nsensitivity we call visual light zones. There seemed to be a trend, suggesting that interobserver\nspreads were larger than intraobserver spreads, especially for the FB condition. The results of\nthe second experiment confirmed the existence of visual light zones. In Experiment 2, we\nagain found that interobserver spreads were larger than intraobserver spreads, indicating\nidiosyncratic behavior. In addition, we found a difference between LR and FB orientations\nof light zones. In particular, the observers often made the settings in the back light zone of the\nFB conditions in accordance to the illumination in the front light zone of those conditions.\nOne of the reasons of the differences in the settings between the light zones' orientations\nmight be the visibility of light cues, for example, shadows, shading, and highlights (Boyaci,\nDoerschner, & Maloney, 2006; Koenderink, van Doorn, Kappers, te Pas, & Pont, 2003;\nLopez-Moreno, Sundstedt, Sangorrin, & Gutierrez, 2010; O'Shea, Agrawala, & Banks,\nIn the LR orientation, each light zone took half of the picture plane, and therefore, it was\nlikely that in both light zones, the cues were approximately equally well visible. In the FB\ncondition, light cues in the back part might be less obvious than those in the front because of\nocclusions and perspective/scaling. Boyaci et al. (2006) and Xia et al. (2017) demonstrated\nhow in the presence of less (articulated) cues the veridicality of participants' settings declined.\nThere are still many unanswered questions about light zones. One of the concerns is how\nthe grouping of such patterns happens. Illuminance flow patterns (Pont, van Doorn, Wijntjes,\n& Koenderink, 2015) are a probable candidate as a cue for direction-based zones. The exact\nmechanisms are subject of further studies. In addition, it needs to be studied how intensity,\ndirection, diffuseness, and color interact in the perception of light zones. Furthermore,\ngrouping light zones can be done at different scales of analysis. This scale (the dimensions\nof the light zones with respect to the scene) determines the relative size and the number of\nlight zones in natural (usually complex) light fields. It defines, for instance, whether relatively\nsmall parts of a scene are determined to be a separate light zone or part of a larger one. In\nKoenderink et al.'s (2007) visual light field study, we find an interesting example. They tested\na position in their spotlight condition where the probe was in a relatively small shadow\nTable 1. Summary and p Values of the Light Zones Comparisons.\nComparison of\nsettings between\nlight zones\nFront vs. (rotated)\ncorresponding zone\nBack vs. (rotated)\ncorresponding zone\nLight 1 .067 (nonsignificant difference) <.001 (significant difference)\nLight 3 .433 (nonsignificant difference) <.001 (significant difference)\nSingle light source settings: 4R and (mirrored) 4L: p \u00bc.117 (not significantly different); 4F and (mirrored) 4B: p <.001\n(significantly different).\nKartashova et al. 17\nvolume that was cast by one of the objects (penguins). Only one of eight observers inferred\nthe probe to be in the shadow, but others adjusted the illumination on the probe as if it was in\nthe spotlight. It might well be the case that visual light zones concern a rather coarse-scale\nanalysis that neglects such fine-scale light variations. Further studies are needed to fully\nunderstand these mechanisms.\nOur findings might help to understand the structure of the visual light field, which can\ncontribute to several applied areas. In computer graphics, volume zoning was introduced for\nthe case of participating media, for example, dust or fog (Rushmeier & Torrance, 1987). We\nbelieve that research on light zones could be useful for automated creation of light probes\n(Chajdas, Weis, & Westermann, 2011). It would be also interesting to test the veridicality of\nperception of light on objects moving through light zones, extending the existing studies of\nlightness estimations of an object moving though differently illuminated areas (Toscani,\nZdravkovic\n\u00b4 , 2008). Would observers notice it if a\nchange of illumination on a moving object does not match the variations of the light in a\nspace through which it is moving? How (in)sensitive are we to such changes? Can we simplify\nimplementations by modeling complex natural light fields in a segmented model containing\nonly a few zones with simple uniform/divergent/convergent light flows? Light zones are\nregularly used in architecture and light design. Madsen (2007) coined the concept and\nprovided a number of practical architectural examples. There is a continuing interest in\nthe topic from researchers in the field of architecture and lighting (Lindh, 2013; Trisha &\nImran, 2014). We sharpened the definition of light zones and provided an approach for\nmeasuring and evaluating their perception. Finally, our results confirmed the existence of\nvisual light zones.\n"
}