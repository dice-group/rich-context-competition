{
    "abstract": "Abstract\nThe Universiti Sains Malaysia Emotional Quotient Inventory (USMEQ-i) is a Malay-language emotional intelligence (EI)\ninventory that was based on a mixed-model approach of EI. It was specifically developed and validated for use among medical\ncourse applicants. However, evidence to support its use among medical students is inadequate. This study aims to provide\nfurther construct validity evidence for the USMEQ-i among medical students through confirmatory factor analysis (CFA).\nA cross-sectional study was carried out on a sample of 479 medical students in Universiti Sains Malaysia (USM). After a\npreliminary analysis, data from only 317 respondents were found suitable for inclusion in CFA. CFA was performed using the\nmaximum likelihood estimation method with bootstrapping due to the nonnormality of items at the multivariate level. The\nresults of the analysis support the two-factor model of the EI component and the one-factor model of the faking component.\nHowever, the USMEQ-i should be administered with caution until further cross-validation studies are conducted among\nstudents in other medical schools in Malaysia.\n",
    "reduced_content": "sgo.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of\nthe work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nArticle\nIntroduction\nEmotional intelligence (EI) is defined as the ability to per-\nceive, express, understand, motivate, control, and regulate\nMayer, 1996). Previous studies have shown that EI is a deter-\nminant of success in various occupational settings (Gazzard,\nEI predicts social relationships, family relationships, work\nperformance, academic performance, physical health, and\npsychological well-being (Mayer, Roberts, & Barsade,\nIn the medical education context, studies have found that\nhigh EI is positively associated with doctor\u00adpatient relation-\nships, interpersonal skills, communication skills, teamwork,\nempathy, organizational commitment abilities, stress man-\nagement, and examination performance on specific areas\nsuch as clinical, diagnostic, and prognostic abilities (Arora\netal., 2010). In addition, results from a prospective study\nindicated an association between preadmission EI and the\npsychological health of medical students during first-year\nmedical training (Yusoff, Esa, MatPa, Mey, & Aziz, 2013).\nGrewal and Davidson (2008) reported that the doctor's EI is\npositively associated with the patient's trust, which in turn\nresults in a better doctor\u00adpatient relationship and treatment\ncompliance, as well as improved patient satisfaction with the\ndoctor and hospital. They also found a significant association\nbetween the health care team's EI and the team's effective-\nness. In short, EI plays important roles that are closely related\nto medical doctors' competency.\nThere are three theoretical approaches to EI: the specific-\nability approach, the integrative-model approach, and the\nmixed-model approach (Mayer etal., 2008). The specific-\nability approach focuses on specific skills that are considered\nfundamental to EI. Examples of inventories based on this\napproach include the Diagnostic Analysis of Nonverbal\nAccuracy 2, the Japanese and Caucasian Brief Affect\nRecognition Test, and the Levels of Emotional Awareness\nScale. The integrative-model approach combines a number\nof relevant abilities to obtain an overall sense of EI. Examples\n1Universiti Sains Malaysia, Kubang Kerian, Kelantan, Malaysia\nCorresponding Author:\nWan Nor Arifin, Unit of Biostatistics and Research Methodology, School\nof Medical Sciences, Universiti Sains Malaysia, 16150 Kubang Kerian,\nKelantan, Malaysia.\nEmail: wnarifin@usm.my\nConfirmatory Factor Analysis of the\nUniversiti Sains Malaysia Emotional\nQuotient Inventory Among Medical\nStudents in Malaysia\nWan Nor Arifin1 and Muhamad Saiful Bahri Yusoff1\n Keywords\nconfirmatory factor analysis, emotional intelligence, faking, medical students, mixed-model approach\n2 SAGE Open\nof inventories based on this approach include the Emotion\nKnowledge Test, the Mayer\u00adSalovey\u00adCaruso Emotional\nIntelligence Scale, and the Multibranch Emotional\nIntelligence Scale. The mixed-model approach uses a broad\ndefinition of EI, which includes noncognitive capability,\ncompetency, or skill; emotionally and socially intelligent\nconduct; and personality dispositions. The approach encom-\npasses diverse psychological traits, abilities, styles, and other\ncharacteristics of EI. The Emotional Quotient Inventory\n(EQ-i), Self-Report Emotional Intelligence Test (SREIT),\nand Multidimensional Emotional Intelligence Assessment\n(MEIA) are examples of inventories based on this approach.\nThe Universiti Sains Malaysia Emotional Quotient\nInventory (USMEQ-i) is a Malay-language EI inventory that\nwas based on the mixed-model approach. It was developed\nto measure EI among medical course applicants in Malaysia\n(Yusoff, Rahim, & Esa, 2010). The USMEQ-i also under-\nwent a validation process by means of exploratory factor\nanalysis (EFA; Yusoff etal., 2011) and confirmatory factor\nanalysis (CFA; Arifin, Yusoff, & Naing, 2012). In a prelimi-\nnary validation study among medical students, Yusoff (2012)\nreported that the USMEQ-i has good test\u00adretest and internal\nconsistency reliabilities. However, this evidence is still inad-\nequate to support the construct validity of the USMEQ-i\namong students. Stronger evidence of its validity can be pro-\nvided by CFA.\nCFA is superior to EFA and simple reliability analysis\n(test\u00adretest and internal consistency reliabilities) in many\nrespects. CFA is a type of structural equation modeling\n(SEM) that is concerned with measurement models (Brown,\n2006). It is advantageous to use CFA to verify the relation-\nships between items and their respective factors because it\nallows the fixing of these relationships in the measurement\nmodel and provides ways to assess the fit of the proposed\ntheoretical model to the collected data (Brown, 2006;\nStevens, 2009). Thus, CFA is considered an indispensable\ntool for validation in social and behavioral sciences (Brown,\nGiven the advantage of CFA, this study aims to provide\nfurther evidence for the construct validity of the USMEQ-i\namong medical students through an evaluation of its mea-\nsurement model validity by CFA.\nMethod\nStudy Population\nA cross-sectional study was carried out among medical stu-\ndents of the School of Medical Sciences at the Universiti\nSains Malaysia (USM) from March to May 2011. In the\nschool, study years are divided into three phases: Phase I\n(first and second years), Phase II (third and fourth years), and\nPhase III (fifth year). The first-, third-, and fifth-year medical\nstudents in 2011 were taken as a sampling frame because they\nwere considered representative of each phase. Second- and\nfourth-year medical students were intentionally excluded\nbecause those years have been found to be a stressful period\nfor students (Yusoff, Rahim, & Yaacob, 2010). Thus, data\nfrom these students might not reflect a stable mental state\namong the students.\nSample Size and Sampling Method\nA total of 460 students were required for a CFA of 46 items\nin the inventory, following Bentler and Chou's (1987) sug-\ngestion for a minimum subjects-to-item ratio of 10:1. The\nrequired sample size was inflated to 512 students to factor in\na 10% drop-out rate. Stratified random sampling was applied,\nwith the phases and students' gender as the stratification\nvariables (Table 1). These strata were chosen because the\nstratum-specific proportions varied between student intakes\nover the years.\nMeasurement Tool\nA preliminary version of the USMEQ-i was used in this\nstudy. This version was construct validated by EFA (Yusoff\netal., 2011), as opposed to the final version of the USMEQ-i\nthat was construct validated by CFAin a study byArifin etal.\n(2012). In view of the possibility that the remaining items as\nvalidated among medical students might differ from the\nremaining items as validated among medical course appli-\ncants after CFA, the preliminary version with a larger pool of\nitems was deemed preferable in this validation study.\nThe inventory has two distinct components: the EI com-\nponent and the faking component. The EI component con-\nsists of 39 items that are clustered under seven factors:\ncontrol, maturity, conscientiousness, awareness, commit-\nment, fortitude, and expression. Alternatively, based on the\nconfirmatory study, the items could be clustered under two\nfactors: personal competence and social competence (Arifin\net\nal., 2012). The faking component is a unidimensional\ncomponent that is meant to measure the tendency of respon-\ndents to overrate themselves (Yusoff, Rahim, & Esa, 2010).\nTable 1. Strata Size and Required Sample Size.\nPhase gender\nPercentage of\nall phases\nSample size\nrequired per strata\nPhase I\nPhase II\nPhase III\nArifin and Yusoff 3\nIt consists of seven items that are clustered under the faking\nindex. Each item in the inventory was rated on a 5-point\nLikert-type scale (0 = not like me, 1 = a bit like me, 2 = quite\nlike me, 3 = a lot like me, and 4 = totally like me). All the\nitems have factor loadings of more than 0.3, and the\nCronbach's alpha values for the factors range from .603 to\nAn overview of the factors and items under the EI and\nfaking components is presented in Table 2. Detailed descrip-\ntions of each factor and a list of items are included in the\nonline manual of the inventory (see the link provided in the\nAuthors' Note). The seven-factor model (EI-VII) and two-\nfactor model (EI-II) of the EI component and the one-factor\nmodel (FI) of the faking component were evaluated for mea-\nsurement model validity.\nData Collection Procedures\nUSMEQ-i forms were administered to all first-, third-, and\nfifth-year medical students in examination halls after they\ncompleted all end-of-phase examinations. Informed consent\nwas obtained from the students prior to the collection of forms.\nData Management and Preliminary Analysis\nData management and preliminary analysis were done using\nIBM SPSS Statistics version 20 and SPSS Amos version 19.\nFor the purpose of statistical analysis, the ordinal\nresponses of the USMEQ-i were treated as continuous data.\nThe use of maximum likelihood (ML) estimation for ordinal\ndata is reasonable if the number of ordinal categories exceeds\n3 (Byrne, 2010; Rhemtulla, Brosseau-Liard, & Savalei,\nThe multivariate normality of the items was assessed at\nthe univariate, bivariate, and multivariate levels (Kline,\n2011). The univariate normality of each item was assessed\nvisually by inspecting a histogram with normality curve,\nbox-and-whisker plot, and Q\u00adQ plot, and statistically by the\nKolmogorov\u00adSmirnov and Shapiro\u00adWilk tests of normality\nand skewness and kurtosis to their standard error ratios (ratio\n< 3 for normality). The bivariate normality was assessed\nthrough an evaluation of the linearity and homoscedasticity\nof residuals of bivariate correlations for a number of selected\npairs of items (Kline, 2011). The multivariate normality of\nthe items was assessed by component, visually by plotting\nthe chi-square versus the Mahalanobis distance plot\n(Burdenski, 2000) and statistically by Mardia's normalized\nestimate of multivariate kurtosis in the form of critical ratio\nof kurtosis in Amos. Critical ratio of kurtosis < 5.0 indicates\nmultivariate normality (Bentler, 2006). Multivariate outliers\nwere identified through an evaluation of the Mahalanobis\ndistance and its respective p1 and p2 values in Amos.\nA multivariate collinearity assessment allows the identifica-\ntion of redundant items among a group of variables. Tolerance <\n0.10 or variance inflation factor (VIF) > 10 indicates the multi-\nvariate collinearity of the affected item (Kline, 2011). These\nvalues were obtained from a multiple linear regression analysis\nin SPSS by assigning a dummy variable (ID was used) as the\ndependent variable and the items as the independent variables.\nCFA\nCFA was performed in Amos to evaluate the measurement\nmodel validity of the proposed EI-VII, EI-II, and FI models.\nThe validity was evaluated through an assessment of model\nfit indices and other evidence of construct validity of the pro-\nposed and revised measurement models. The marker indica-\ntor approach was used to scale the factors to their respective\nitems, as the approach is preferred whenever bootstrapping is\nused (Arbuckle, 2010). Items with the largest unit of discrim-\nination were chosen as marker indicators, and their factor\nloadings were fixed to 1.0.\nTable 2. Model Factors and Items.\nModels Factors Number of items Items\nEmotional\nintelligence (EI-\nEmotional\nintelligence (EI-II)\nNote. EI-VII = seven-factor model of emotional intelligence component; EI-II = two-factor model of emotional intelligence component; Q = question\nnumber; FQ = faking question number.\n4 SAGE Open\nFollowing Brown's (2006) recommendation, the follow-\ning categories of fit indices were considered in this study:\nabsolute fit (chi-square goodness-of-fit [2], standardized\nroot mean square residual [SRMR]), parsimony-corrected fit\n(root mean square error of approximation [RMSEA]), and\ncomparative fit (Tucker\u00adLewis fit index [TLI], comparative\nfit index [CFI]). The following cutoff values were used to\nRMSEAand its upper 90% confidence limit  0.08, RMSEA's\nFor model-to-model comparison of nonnested models, the\nAkaike information criterion (AIC) and expected cross-\nvalidation index (ECVI) were used. Models with the lowest\nAIC and ECVI values were judged to fit the data better in\ncomparison with other tested models (Brown, 2006;\nFurther assessment of construct validity involved an\nassessment of the main components of construct validity,\nnamely, convergent validity and discriminant validity.\nConvergent validity was evaluated through an assessment of\nitem factor loadings and their statistical significance, fol-\nlowed by an assessment of the factors' average variance\nextracted (AVE) and construct reliabilities (CRs). Convergent\nvalidity was indicated by an item factor loading  0.5 and\nwere calculated according to the following equations given\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n=\n= =\n\n \n\n\ni\ni\nn\ni\ni\nn\ni\ni\nn\n+ e\n,\nAVE\n=\n+\n=\n= =\n\n \n\n\ni\ni\nn\ni\ni\nn\ni\ni\nn\ne\n,\nwhere \ni\nis the factor loading for item i under a particular\nconstruct, and e\ni\nis the error variance for the item.\nter estimates of the CR values and confidence intervals in the\ncontext of SEM, as demonstrated by Fan (2003) in the Amos\nsoftware environment. The procedure was performed as\nfollows:\n1. A latent reliability variable (RV) was created for each\nfactor.\n2. Directional paths were added from the items to the\nrespective RVs.\n3. The regression weights for these additional paths\nwere all set to 1.\n4. The square of the correlation coefficient between a\nparticular factor and its RV is the composite reliabil-\nity coefficient for that factor.\nNext, discriminant validity was evaluated by comparing\nfactor AVE values with shared variances (SVs) between the\nfactors, which are the squared correlations between any two\nfactors. The factors were considered discriminant when the\nAVE values were greater than the SV values (Fornell &\nModel revisions were done based on assessments of fac-\ntor loadings, standardized residuals (SRs), and modification\nindices (MIs), while maintaining the congenericity of the\nmeasurement model within the theoretical framework. Items\nwith factor loadings < 0.5 were considered for removal (Hair\net\nal., 2009). The researchers also considered items with\nloadings that had bootstrapped lower 95% confidence inter-\nvals below this cutoff value for removal. Items with SR >\n2.58 were considered problematic items, which were further\nevaluated before removal (Brown, 2006). In this study, MI\nvalues were only used to identify potential cross-loading\nitems (Hair etal., 2009) without setting any particular cutoff\nvalues, as the decision based on SR values was given more\nimportance.\nEthical Approval\nEthical approval to conduct this study was obtained from the\nUSM Research Ethics Committee (Human). The USM\nResearch Ethics Committee required informed consent forms\nand approved the collection of data only as required by the\nanalysis, as the USMEQ-i forms also included other personal\ninformation.\nResults\nPreliminary Analysis\nA total of 576 medical students from the first, third, and fifth\nyears gave their consent to participate in the study. A sample\nof 479 students was then obtained from this list of students\nthrough stratified random sampling. The sample size was\nsmaller than the target sample size, as the male strata of\nPhases I and II were underrepresented due to the small par-\nticipation rate within the strata.\nDuring the initial data screening process, 160 respondents\nwere dropped: one respondent for wrong entry, 38 respon-\ndents for not responding to all items, 36 respondents for not\nresponding to more than five items consecutively (e.g., miss-\ning responses from Q1 to Q6), and 85 respondents for having\na predictable pattern of responses (e.g., repetitive responses\nlast two conditions as dishonest responses, hence justifying\nArifin and Yusoff 5\ntheir removal from the sample. After the screening process,\n319 respondents remained in the sample.\nIn this remaining sample (n = 319), there were 11 respon-\ndents with one missing response, four respondents with two\nmissing responses, and one respondent with three missing\nresponses, for an overall rate of missing values of 0.15%.\nThe missingness mechanism was determined as missing at\nrandom based on a significant Little's (1988) test, 2 (df) =\nThe missing values were imputed with the prior knowl-\nedge imputation method (Tabachnick & Fidell, 2007). The\nmissing responses for these 16 respondents were imputed\nwith a value of 2, which is the middle value on the Likert-\ntype scale, representing the \"quite like me\" option. The deci-\nsion was made after a discussion with the inventory developer\n(M. S. B. Yusoff, personal communication, October 15,\n2012). The developer considered the middle value as accu-\nrately representing the missing response. Other options of\nimputation were not considered in this study given the negli-\ngible percentage of missing values; most imputation meth-\nods will give similar results with a minimum bias in estimates\nat this percentage of missingness regardless of the mecha-\nAll items except Q11 were not normally distributed at the\nunivariate level. At the bivariate level, seven items from the\nEI component were randomly selected to form 21 bivariate\ncorrelations, all of which were not normally distributed.\nSeven items from the faking component formed 21 bivariate\ncorrelations. Similarly, all the correlations were not normally\ndistributed. At the multivariate level, items from both com-\nponents were not normally distributed (EI component: multi-\nfaking component: multivariate kurtosis = 33.39, critical\nratio of kurtosis = 26.56). Upon close inspection of 30 multi-\nvariate outliers from both components, two more respon-\ndents were excluded for having a predictable pattern of\nresponses, as described earlier. However, no improvement in\nmultivariate normality was noted after excluding these two\nrespondents. None of the items had multivariate collinearity\nbased on tolerance and VIF.\nAfter this preliminary analysis, only 317 (66%) respon-\ndents out of 479 from the initial sample were included in the\nCFA. The demographic characteristics of the respondents\nand dropped cases are presented in Table 3.\nCFA\nIn Amos, the main estimation method used is ML, which is\ndependent on the multivariate normality assumption. As the\nitems were not normally distributed at the multivariate level,\navailable options in Amos for non\u00admultivariate normal data\nare the unweighted least squares (ULS), asymptotically dis-\ntribution free (ADF), and bootstrapped ML estimation meth-\nULS is not asymptotically efficient; thus, chi-square test and\nother fit indices that rely on chi-square cannot be obtained.\nOn the contrary, ADF requires a very large sample size that\n2010). Thus, the ML estimation method with bootstrapping\nwas used to obtain an accurate estimation of standard errors\n(Byrne, 2010) as reflected in p values and confidence inter-\nvals. Bootstrap samples were set at 250, as recommended by\nNevitt and Hancock (2001). The bias-corrected confidence\ninterval was set at the 95% confidence level. In addition, the\nBollen\u00adStine bootstrap p was used as an appropriate alterna-\ntive to the 2 p whenever the bootstrapping method was used\nindicative of model fit.\nEI component. EI-VII was specified as a reflective measure-\nment model that consisted of seven first-order latent factors,\n39 items (Table 1), and 21 interfactor correlations. The anal-\nysis of EI-VII indicated that the solution was not admissible\ndue to a nonpositive definite covariance matrix. The model\nwas not revised in view of the study among applicants (Ari-\nfin etal., 2012), in which EI-VII also faced a similar issue.\nNext, EI-II was specified as a reflective measurement\nmodel that consisted of two first-order latent factors, 39 items\n(Table 1), and a correlation between social competence and\npersonal competence. EI-II had poor model fit as indicated by\nall fit indices except SRMR. To obtain a good-fitting model,\nEI-II was revised iteratively as described below.\nfactor loadings of less than 0.5 were removed from personal\ncompetence. This was followed by the removal of an addi-\nTable 3. Demographic Characteristics of Respondents and\nDropped Cases.\nVariables\nRespondents\nDropped cases\nn (%) n (%)\nGender\nRace\nPhase\naMedian (interquartile range). Age was not normally distributed.\n6 SAGE Open\nexcept Q7 (factor loading = 0.596), which was retained\nbecause the value was very close to 0.6. The researchers set a\nhigher cutoff value of 0.6 for personal competence, consider-\ning the large number of items (34) and the researchers' aim to\nreduce the number of items under this factor. In addition, the\nfactor loadings of all the items had a lower 95% confidence\ninterval below 0.5, signifying the need to remove the items.As\nfor social competence, only Q29 was removed from the factor\nat this stage due to low factor loading (0.398).\nAfter these 20 items were removed, Q28 was noted to\ncross-load on personal competence based on an MI value of\n15.30. Judging from the item content, Q28 appeared to fit the\ndefinition of personal competence; thus, it was relocated to\nthat factor, leaving social competence with only three items.\nfactor loadings had a lower 95% confidence interval of less\n3.67). At this point, the model still did not have a satisfying\nfit based on the fit indices (Bollen\u00adStine bootstrap p = .032,\nrespectively), were considered for removal, although the SRs\nwere lower than the 2.58 cutoff point. Q22 itself was not con-\nsidered for removal as it belonged to social competence,\nwhich was left with only three items. The researchers tried to\nkeep three or more items per factor to maintain a reasonable\nnumber of representative items. Q36 was removed, which\nresulted in the best improvement to the model (Bollen\u00adStine\ncompared with the removal of the other two items. However,\nTLI and CFI values were still not satisfactory (TLI = 0.939,\nloading had a lower 95% confidence interval of less than 0.5.\nOverall, 25 items were removed from both factors. The\nresulting model was a two-factor model (revised; EI-IIr) con-\nsisting of three items under social competence and 11 items\nunder personal competence (Figure 1). The model fit well, as\nindicated by the fit indices, and showed model improvement\nas indicated by the reduction in AIC and ECVI values. Fit\nindices for EI-VII, EI-II, and EI-IIr are presented in Table 4.\nThe convergent validity of EI-IIr was indicated by high\nfactor loadings (Table 5), acceptable AVE values, and high\nCR values (Table 6). The discriminant validity of the model\nwas also indicated by the AVE values, all of which exceeded\nthe respective SV values (Table 6).\nFaking component.FI was specified as a unidimensional\nreflective measurement model consisting of seven items\n(Table 1). FI had poor model fit, as indicated by the RMSEA\nand Bollen\u00adStine bootstrap. FI was revised to obtain a good-\nwere removed due to relatively low factor loadings. This\nrevision resulted in a unidimensional model (FIr) consisting\nof four items (Figure 2); the model fit well based on most of\nthe fit indices except RMSEA and showed a remarkable\nreduction in AIC and ECVI values. Fit indices for both FI\nand FIr are presented in Table 4. FIr had good convergent\nvalidity, as indicated by the high factor loadings (Table 5),\nacceptable AVE value, and high CR value (Table 6).\nDiscussion\nEI Component\nThe proposed two-factor model of EI fit well after an extensive\none item was relocated to another factor. The extent of the revi-\nsion is comparable with the revision done in the confirmatory\nstudy of a sample of medical course applicants, in which 26 out\nstudy by Arifin et\nal. (2012), the extensive removal of items\ncould be attributed to the carrying over of several items with low\nfactor loadings from the EFAstage. The remaining items by fac-\ntor in the current study are different from those retained in the\nstudy among applicants (Arifin etal., 2012). This finding signi-\nfies the use of different sets of items in the EI component of the\nUSMEQ-i for medical students and medical course applicants.\nThe two-factor model is consistent with Goleman's (1998)\nemotional competence framework, which was based on the\nmixed-model approach of EI. In the framework, emotional com-\npetence is divided into personal competence and social compe-\ntence. Essentially, personal competence deals with managing\noneself, whereas social competence deals with handling relation-\nships with others (Goleman, 1998). The validity of the model\nalso confirms the results from the confirmatory study of the\nUSMEQ-i among medical course applicants (Arifin etal., 2012).\nThe Emotional and Social Competency Inventory, which was\nbased on a similar approach to EI, also includes personal and\nsocial factors (Boyatzis, 2007). In contrast, the model is not con-\nsistent with models from other inventories that were based on a\nsimilar approach, namely, the one-factor model of the EQ-i\n(Petrides & Furnham, 2001), the one-factor model of the SREIT\n(Petrides & Furnham, 2000), and the three-factor model of the\nMEIA(Tett & Fox, 2006), all of which were validated by CFA.\nFaking Component\nThe proposed unidimensional model of the faking compo-\nnent fit well after the removal of three out of seven items\n(43%). This could also be attributed to the carrying over of\nitems with relatively low factor loadings from the EFA stage\nThe unidimensionality of the faking component in the cur-\nrent study is comparable with that in the study among appli-\ncants (Arifin etal., 2012). However, the studies differ in the\nremaining items after CFA; this signifies the use of different\nsets of items for students and applicants. Confirmatory valida-\ntion studies of other inventories measuring the faking concept\nArifin and Yusoff 7\nhave also shown its unidimensionality.ACFAof the Marlowe\u00ad\nCrowne Social Desirability Scale (MCSDS) indicated the uni-\ndimensionality of the short forms of MCSDS (Fischer & Fick,\nDeception Scales, was also found to be unidimensional\n(Lanyon & Carle, 2007) after a minor revision.\nLimitations and Future Research\nIn the current study, the USMEQ-i was validated among medi-\ncal students in the USM Medical School. The inventory may\nalso be valid among medical students from other medical\nschoolsinMalaysia,asthesettingsarealmostsimilar.However,\nthe USMEQ-i should be administered with caution until cross-\nvalidation studies are conducted in other medical schools.\nBecause a large number of items were removed during the\nmodel revisions, a revalidation study is needed on a new\nsample of medical students. Hair etal. (2009) recommended\nthe collection of a new sample upon removal of more than\n20% of the items. A low cutoff value of 0.3 for item factor\nloading was set during the EFA stage of USMEQ-i validation\n(Yusoff etal., 2011), which resulted in a number of poor\nquality items in the preliminary version used in this study. In\nview of the findings of the current study and those of Arifin\nmore practical (Hair etal., 2009) to ensure that only good\nitems are carried over to the CFA stage of validation.\nThe evidence of construct validity of the USMEQ-i in this\nstudy was only provided by CFA. Matthews, Zeidner, and\nRoberts (2007) pointed out that evidence of the convergent\nFigure 1. Two-factor model of emotional intelligence component (revised).\nTable 4. Fit Indices of EI and FI Measurement Models.\nModels 2 (df), p\nBollen\u00adStine\nbootstrap p SRMR RMSEA (90% CI), CFit p TLI CFI AIC ECVI\nEI-VII Solution was not admissible\nNote. The revised models are highlighted in bold. EI = emotional intelligence; FI = one-factor model of faking component; SRMR = standardized root mean square residual;\nRMSEA = root mean square error of approximation; CI = confidence interval; CFit = close fit; TLI = Tucker\u00adLewis fit index; CFI = comparative fit index; AIC = Akaike\ninformation criterion; ECVI = expected cross-validation index; EI-VII = seven-factor model of emotional intelligence component; EI-II = two-factor model of emotional\nintelligence component; EI-IIr = two-factor model of emotional intelligence component (revised); FIr = one-factor model of faking component (revised).\n8 SAGE Open\nvalidity of an EI inventory is commonly established in rela-\ntion to other available EI inventories. However, there is no\nother EI inventory in the Malay language, making it impos-\nsible to provide evidence of convergent validity.\n"
}