{
    "abstract": "Abstract\nWolfe (2016) responds to my article (Kristja\n\u00b4nsson, 2015), arguing among other things, that the\ndifferences in slope by response method in my data reflect speed accuracy trade-offs. But when\nreaction times and errors are combined in one score (inverse efficiency) to sidestep speed\naccuracy trade-offs, slope differences still remain. The problem that slopes, which are thought\nto measure search speed, differ by response type therefore remains.\n",
    "reduced_content": "Reply\nThe Slopes Remain the Same:\nA\n\u00b4 rni Kristja\n\u00b4nsson\nFaculty of Psychology, University of Iceland, Reykjavik, Iceland; Institute\nof Cognitive Neuroscience, University College London, Reyjavik, Iceland\n Keywords\nattention, parallel processing, visual search\nRecently, I argued that the distinction between preattentive and attentive processing that is\noften made in visual search studies, based on whether slopes of set size and response time\n(RT) are positive or flat, has outstayed it's welcome and may even sometimes hamper\nprogress (Kristja\nWolfe (2016) responded, arguing that wholesale abandonment of slopes would be unwise\ngiven their usefulness. That is a worthy cause, especially had slopes been in any danger. I did\nnot actually argue against the use of slopes but simply highlighted the theoretical baggage\nthey tend to carry in the visual search literature. Slopes are obviously a useful tool and can,\nfor example, be used to measure the rate at which items are processed. Whether they do so in\nvisual search is debatable, however, and the assumption that they actually do, and are\ntherefore the true measures of search speed, may yield questionable conclusions.\nWolfe (2016) echoes my warnings about thinking of slopes as measures of actual cognitive\nmechanisms and processing levels or types. Slopes are not simple metrics of whether a search\nis ``parallel'' or ``serial.'' This assumption is nevertheless often made in the literature. So\nWolfe and I agree that slopes are interpretable and useful but disagree on whether they have\noutstayed their welcome in the visual search literature.\nWolfe claims that the most challenging data for the use of slopes as measures of search rate\nare changes in slope when only the task is changed (present/absent vs. go/no-go). If slopes are\na measure of search speed, they should not be affected by response type, which was\nnevertheless the case in Kristja\n\u00b4 nsson (2015). Wolfe argues that error rates increase with set\nCorresponding author:\nA\n\u00b4 rni Kristja\n\u00b4nsson, Institute of Cognitive Neuroscience, University College London, Reyjavik IS107, Iceland.\nEmail: ak@hi.is\ni-Perception\nipe.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sage-\npub.com/en-us/nam/open-access-at-sage).\nsize in the critical conditions that I report, and that this data involve a ``classic speed accuracy\ntrade-off [SAT].'' Wolfe is right that there is evidence of SATs in the data but the important\nquestion is whether SATs account for all the differences in slope by response method reported\nin Kristja\nThere is no single agreed upon way of assessing whether SATs account for condition\ndifferences, and a definitive way may not exist (Bruyer & Brysbaert, 2011). But any such\nassessment must almost certainly involve some convolution of RTs and error rates. Inverse\nefficiency scores (IES; Townsend & Ashby, 1978) have been used to combine RTs and error\nrates in one score to compensate for differences in error rates (e.g., Bruyer & Brysbaert, 2011;\nVandierendonck, 2016). IES involve multiplying mean RT by error rates yielding a single\nscore (IES \u00bc Mean RT/1 \u00c0 Mean error rate). Slopes of IES and set size can then be\nmeasured. If there are still slope differences between response conditions in Kristja\n\u00b4 nsson\n(2015), then the problem for the RT by set size methodology remains.\nTable 1 shows the results of applying IES scores to RTs and error rates in Kristja\n\u00b4 nsson\n(2015) and also to data from Wang, Kristja\n\u00b4 nsson, and Nakayama (2005) where a similar\nslope difference by response method was reported. The IES transform does not affect the\npatterns in the results in any fundamental way. For easy conjunction search, there are still\ncondition differences of 5 ms per added item to the set size. This means that the search is 5 ms\nslower per added item for the more traditional present/absent task than the Go No-Go task.\nThis is also the case for easy conjunction search from Wang et al. (2005). The slope\ndifferences for the difficult conjunction search are, however, smaller than in the original\ndata. In sum, SATs do not easily account for slope differences by response method\nsuggesting that slopes are not straightforward measures of search rate.\nThere are also notable intercept differences. Intercept differences are often ignored in\nvisual search studies, based on the assumption that they involve a separate processing\nstage from the actual search (Sternberg, 1969), which also relies on the questionable\nassumption that slopes are the true measure of search. In any case, outright dismissal of\nintercept differences as irrelevant to visual search is unhelpful, but further speculation is\nbeyond the current scope.\nIn the end, I do not think that Wolfe and I disagree on very much. And we agree that task-\nbased differences in slope are a challenge to the RT \u00c2 Set size methodology. We may disagree\non whether SATs account for the task-based slope differences, but I think that the current\nanalysis makes clear that they cannot easily be dismissed as SATs.\nThere are likely other ways of assessing SATs, but it is hard to see that they would involve\nanything else than taking both error rates and RTs in to account as inverse efficiency scores\ndo, although weights assigned to each could be varied.\nTable 1. Slope and Intercepts for Inverse Efficiency scores (in ms) from Kristja\nEasy conjunction search Hard conjunction search Feature search Wang et al. (2005)\nResponse Intercept Slope Intercept Slope Intercept Slope Intercept Slope\nNote. PA \u00bc present/absent task; GNG \u00bc Go No-Go task.\nThis issue deserves more detailed analysis. Inverse efficiency scores are not uncontroversial\nand carry a number of assumptions (Bruyer & Brysbaert, 2011; Vandierendonck, 2016).\nRecent studies highlight the usefulness of analyzing RT distributions (Antoniades et al.,\n\u00b4 nsson & Jo\nHorowitz, Torralba, & Wolfe, 2011; Wolfe, Palmer, & Horowitz, 2010). Testing whether\nRT distributions differ by response method could shed further light on the issue.\nCurrently, my coworkers and I are collecting large data sets with varied response methods\nthat will enable such detailed analyses.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or\npublication of this article.\nFunding\nThe author(s) received no financial support for the research, authorship, and/or publication of this\narticle.\nReferences\nAntoniades, C., Ettinger, U., Gaymard, B., Gilchrist, I., Kristja\n\u00b4 nsson, A\n\u00b4 ., Kennard, C., . . . Carpenter,\nR. H. S. (2013). An internationally standardised antisaccade protocol for clinical use. Vision\nBruyer, R., & Brysbaert, M. (2011). Combining speed and accuracy in cognitive psychology: Is the\ninverse efficiency score (IES) a better dependent variable than the mean reaction time (RT) and the\npercentage of errors (PE)? Psychologica Belgica, 51, 5\u00ad13.\nBurnham, B. R., Cilento, J. J., & Hanley, B. (2015). Intertrial priming of pop-out search influences the\nshift, skew, and dispersion of response time distributions. Attention, Perception, & Psychophysics, 77,\nKristja\n\u00b4 nsson, A\n\u00b4 . (2015). Reconsidering visual search. i-Perception, 6.\nKristja\n\u00b4 nsson, A\n\u00b4 ., & Jo\n\u00b4 hannesson, O\n\u00b4 . I. (2014). How priming in visual search affects response\ntime distributions: Analyses with ex-Gaussian fits. Attention, Perception & Psychophysics, 76,\nPalmer, E. M., Horowitz, T. S., Torralba, A., & Wolfe, J. M. (2011). What are the shapes of response\ntime distributions in visual search? Journal of Experimental Psychology: Human Perception and\nSternberg, S. (1969). The discovery of processing stages: Extensions of Donders' method. Acta\nTownsend, J. T., & Ashby, F. G. (1978). Methods of modeling capacity in simple processing systems.\nIn J. Castellan & F. Restle (Eds.), Cognitive theory (Vol. 3, pp. 199\u00ad239). New York, NY: LEA.\nVandierendonck, A. (2016). A comparison of methods to combine speed and accuracy measures of\nperformance: A rejoinder on the binning procedure. Behavior Research Methods. Advance online\npublication.\nWang, D., Kristja\n\u00b4 nsson, A\n\u00b4 ., & Nakayama, K. (2005). Efficient visual search without top-down or\nWolfe, J. M., Palmer, E. M., & Horowitz, T. S. (2010). Reaction time distributions constrain models of\nWolfe, J. M. (2016). Visual search revived: The slopes are not that slippery: A reply to Kristjansson\nKristja\nAuthor Biography\nA\n\u00b4 rni Kristja\n\u00b4 nsson received his PhD in Cognition, Brain and\nBehavior from Harvard University in 2002 under the\nsupervision of Prof. Ken Nakayama. He was awarded a Human\nFrontiers Science Program grant for Postdoctoral studies at the\nInstitute of Cognitive Neuroscience, University College London,\nworking with Prof. Jon Driver. He is now Professor of\nNeuroscience at the University of Iceland. His research is\nfunded by the European Research Council, the Icelandic\nResearch Council (Ranni\u00b4s) and the Research fund at the\nUniversity of Iceland."
}