{
    "abstract": "Abstract\nThe central topic of this paper is a mobile phone application, `InformaCam', which turns metadata from a surveillance risk\ninto a method for the production of public proof. InformaCam allows one to manage and delete metadata from images\nand videos in order to diminish surveillance risks related to online tracking. Furthermore, it structures and stores the\nmetadata in such a way that the documentary material becomes better accommodated to evidentiary settings, if needed.\nIn this paper I propose InformaCam should be interpreted as a `forensic device'. By using the conceptualization of\nforensics and work on socio-technical devices the paper discusses how InformaCam, through a range of interventions,\nrearranges metadata into a technology of evidence. InformaCam explicitly recognizes mobile phones as context aware,\nuses their sensors, and structures metadata in order to facilitate data analysis after images are captured. Through these\nmodifications it invents a form of `sensory data forensics'. By treating data in this particular way, surveillance resistance\ndoes more than seeking awareness. It becomes engaged with investigatory practices. Considering the extent by which\nstates conduct metadata surveillance, the project can be seen as a timely response to the unequal distribution of power\nover data.\n",
    "reduced_content": "Original Research Article\nForensic devices for activism: Metadata\ntracking and public proof\nLonneke van der Velden\n Keywords\nForensics, metadata, surveillance, activism, mobile devices, apps\nIntroduction\nIncreased access to digital technologies and distribution\nnetworks has enhanced the potential for citizen jour-\nnalism to monitor and report human rights abuses\n(Center for Research Libraries, 2012). However, the\nwidespread use of these technologies, and that of\nmobile devices in particular, has also raised a new set\nof concerns. Firstly, these concerns relate to fears about\nsurveillance and security (WITNESS, 2011). Secondly,\ndigital reporting also raises the issue of authentication\nbecause digital material is highly vulnerable to manipu-\nfurther complicated by the volume of images and video\nthat is captured and uploaded, which leads to a third\nissue: a `fire hose' that needs to be sorted through,\nevaluated and maintained (Center for Research\nLibraries, 2012). The credibility of digital reporting is\nnot only an issue for activists but for (international\ncriminal) courts as well (The Human Rights Center at\nthe Human Rights Electronic Evidence Study by the\nprofusion of digital documentation has created new\nchallenges of managing and authenticating vast\namounts of evidence, from a multitude of sources,\nmany of them unidentified.' Against the backdrop of\nthese concerns citizen journalists and human rights\nactivists and organisations are faced with the question\nof how to investigate and document an event using\ndigital technologies whilst at the same time avoiding\nthe risks of traceability that might endanger the citizen\njournalist. This paper discusses the ways in which the\nInformaCam project tries to deal with these issues.\nFaculty of Media Studies, University of Amsterdam, Amsterdam, The\nNetherlands\nCorresponding author:\nLonneke van der Velden, Faculty of Media Studies, University of\nAmsterdam, Turfdraagsterpad 9 1012 XT, Amsterdam, The Netherlands.\nEmail: L.C.vanderVelden@uva.nl\nBig Data & Society\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons Attribution-\nNonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use, reproduction\nand distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nInformaCam is a mobile phone application for\nmanaging metadata embedded in photo and video\nfiles. It is aimed at resolving two, sometimes paradox-\nical, dimensions involved in documenting conflicts: the\nneed to document violence, and the need to protect\noneself from online surveillance. In one of the first art-\nicles in this journal, Couldry and Powell argue that\n`emerging cultures of data collection deserve to be\nexamined in a way that foregrounds the agency and\nreflexivity of individual actors as well as the variable\nways in which power and participation are constructed\nand enacted' (2014: 1). The InformaCam project is such\nan example of how actors engage with data collection\nand analysis for the very specific purpose of investiga-\ntion and evidence production.\nTo highlight this investigatory dimension that is part\nof anti-surveillance activism, InformaCam is intro-\nduced as a `forensic device'. First of all, it is important\nto stress that the term `forensic device' stems from a\nparticular reading of the term forensics, not as a discip-\nlinary practice of the forensic sciences, but as the `pro-\nduction of public proof'. According to Weizman et al.:\n`Etymologically, ``forensics'' is derived from a Latin\nterm meaning ``before the forum'' and refers to the\npractice and skill of making propositions through\nobjects before professional and political gatherings or\nproposed by Weizman et al. the focus shifts from sci-\nentific practices, which serve legal procedures, to the\nskills and the (spatial) settings of evidence production\nbeyond the disciplinary institutions of the law only.\nSecondly, the term `device' refers to a particular form\nof action. A device, according to Callon and Muniesa\n(2005), is a way of arranging things to make something\nwork. In other words, a device establishes what in\nActor Network Theory (ANT) is called a `translation'\nCallon and Muniesa, 2005) by looking at how connec-\ntions are being made between elements from diverse\nfields; in my case, these are connections between (meta)-\ndata and requirements from the domain of law. The\nmaterial for this case study consists of the (online) pub-\nlications about the app and personal interviews with\ndevelopers of InformaCam. By not only looking at\nthe application itself, but by tracing the project back\nto the philosophy of and writings of the developers, I\nshow how InformaCam is an assemblage in which tech-\nnical practices are tied to the domain of the law in such\na way that something innovative emerges. In the case of\nInformaCam, what is made to work is a particular form\nof producing evidence with respect to digital images,\nthrough a range of interventions. In his work on protest\nsites, Andrew Barry has shown how activists re-orga-\nnise public space for the demonstration of facts (Barry,\nhow the developers of InformaCam set the conditions\nfor metadata to gain evidentiary capacity. As I will\nargue, InformaCam translates metadata from a poten-\ntial surveillance risk into a method for the production\nof public proof, and in that way, it acts as a `forensic\ndevice'. Looking at InformaCam in this way allows one\nto make explicit that activism in the context of surveil-\nlance not only focuses on awareness raising and protec-\ntion measures, but has an investigatory dimension as\nwell. Moreover, it shows how the metadata are not\nready made, nor do they speak for themselves, but\nthey are constructed in such a way that they gain\nagency, that is, evidentiary capabilities.\nIn the following paragraphs, I will first explain the\nbasic idea behind InformaCam. Then I will provide\nsome background to the use of the term forensic\ndevice. After that I will describe the metadata cate-\ngories deployed in the project and the interventions\nmade by the developers. Concluding, I will state that\nwhereas metadata are initially seen as a risk, the\nInformaCam project re-articulates this risky subject\nmatter as material that can be used for evidence\nproduction.\nWhat is InformaCam?\nInformaCam is developed by The Guardian Project\n(not to be confused with the newspaper The\nGuardian). The Guardian Project is an open source\nsoftware company that helps mobile device users to\nprotect their communication from intrusion and moni-\ntoring. One of the developers describes the twofold\ngoals of the company as follows: `to give users control\nover how much data they provide as they pass media\nalong the pipeline, and to increase awareness and visi-\nbility of the various issues that converge around their\nproject is to provide people with useful tools that can\nbe used by non-specialists. As stated on their website:\nThe Guardian Project aims to create easy to use apps,\nopen-source software libraries and operating system\nmodifications, and customized mobile devices that can\nbe used and deployed around the world, by any person\nlooking to protect their communications and personal\ndata from unjust intrusion and monitoring. (The\nFor the InformaCam project, the developers of The\nGuardian Project teamed up with WITNESS, a video\nadvocacy group in the context of human rights activism.\nThe organisation supports people to use video `safely,\nethically and effectively' (WITNESS, 2015). The project\nwas supported by the International Bar Association\n2 Big Data & Society\n(IBA). The IBA was established in 1947 and connects\nassociations (International Bar Association, 2015).\nInformaCam is designed to support people in mana-\nging metadata that come with making images and\nvideos. In a general sense, metadata can be defined as\n`data about data'. Metadata can be defined in a very\nspecified sense as well, depending on the setting in\nwhich they play a role. In the digital context, the sim-\nplest description would be data about the context in\nwhich a file was produced, edited or stored. Metadata\ncan be distinguished on different levels, such as `system\nmetadata, file system metadata, application metadata,\ndocument metadata, email metadata, business meta-\ndata, geographical metadata and many more'\nrelevant for this article is `application metadata', data\nthat are embedded in the file which `describes and\nmoves with the file when it is moved or copied'\nMetadata can pose a surveillance risk. When an\nimage is created with a mobile phone, the image is\nstored with an extra layer of information that can\ninclude things such as the model of the phone and\nGPS data. When posting images or videos online one\nalso uploads the metadata embedded in the file along\nwith it, creating an online `record', thus enabling those\nwith the right tools or expertise to extract the metadata\nand gain certain information about the creation of the\nfile. This can prove highly risky for the producers of\ndocumentary material in oppressive or security-\nobsessed regimes, because they can potentially be\ntracked down. (For example by connecting different\nimages made by the same device that is owned by a\njournalist known by name or by using the GPS data\nto determine the location of a person on a picture.)2\nInformaCam is part of a larger project, SecureCam,\nin which InformaCam's predecessor, the anti-\nsurveillance app ObscuraCam, allows users to remove\nidentifying metadata. ObscuraCam can strip metadata\nand obscure faces. If somebody wishes to share an\nimage, ObscuraCam diminishes the chance that the\nproducer of the image, or the persons depicted in the\nimage, can be identified or located (The Guardian\nProject, 2013b). Technically speaking, InformaCam is\nbased upon similar principles, but it makes an add-\nitional and opposite move: metadata are not obscured\nbut deliberately captured and safely stored in case one\nwants to make this information public in the future.\nInformaCam enhances mobile devices with a `witness\nmode', that is, an extra functionality that uses the\nsensors of the mobile device in order to make the regis-\ntration of contextual metadata available to, and man-\nageable for, the user. When activated, the app registers\n`sensory and atmospheric data throughout the session'\n(The Guardian Project, 2012). This includes data types\nsuch as: current timestamp, user's public (PGP) key,\nImage Regions created in the image/video, current\nlatitude and longitude, all cell IDs that are visible, alti-\ntude, compass bearing, WIFI-networks (The Guardian\nProject, 2012; personal communication).3 After having\nmade an image or video, one could add specific meta-\ndata about the setting in which the image was taken as\nwell, as for instance, information about the content and\nthe producer of the footage. The contextual metadata\nand the annotations can be valuable for authenticating\nthe image.\nThe application therefore provides the possibility of\nmaking two versions of the documentation: one version\nis produced without the identifiable metadata and\nanother is safely stored with all the metadata. The\ndata-poor version (Figure 1) can be distributed to any\nnetwork of choice, whether that is YouTube, friends'\nnetworks or (citizen) journalists. The data-rich\nversion (Figure 2) can be sent to a trusted party,\nFigure 1. Screenshot of the interface: a data-poor version for\nsharing. Image provided by The Guardian Project.\nvan der Velden 3\nwhich could be for example one's own e-mail address, a\nfriend, or a support organisation such as WITNESS.\nThis happens automatically through an encrypted\nchannel via Tor.4\nThe layer of metadata and the images can be disen-\ntangled when posted online, but they are stored\ntogether if one ever needs them in court or for other\nevidentiary purposes. In this way, InformaCam has\nmerged two of the problems mentioned at the start of\nthis paper, that of mobile tracking and that of digital\nauthentication. (The third problem, the one of sorting\nthrough a large volume of images, will be addressed\nlater in the paper.) The developers have produced a\ntool that allows users to take control over the circula-\ntion of data by intermediating between two different\nsettings that have different requirements, the risky\nenvironment of public space and the evidentiary setting\nof public proof. In other words, the tool allows two\ndifferent ways of `making data public'. It is the\nsecond setting that I will focus on now. For it is here\nthat the app enters the world of forensics.\nForensics as the production of public\nproof\nForensics is usually understood as `forensic science'. It\nrefers to the scientific practices, methods and tech-\nniques that are related to the investigation of crime.5\nThe forensic sciences are those sciences that investigate,\non behalf of the court, the principal investigator, or on\nbehalf of the defence (depending on the legal system),\nspecific material assumed to be related to a criminal\noffence. The forensic sciences can offer potential evi-\ndence for a decision that is subsequently to be made\nby the court. Forensics are hence associated with\nhighly specialized laboratory work conducted by\nexperts that make material, which is relatively invisible\nfor `untrained eyes', visible for the public in court\n(Jasanoff, 1998b). However, studies into how scientific\nand technologically mediated data become witnessed\nfacts tell us that the objects of the forensic sciences\nnever speak for themselves. Scientific and technologic-\nally mediated data are in need of particular translations\nto become convincing in the courtroom when data are\npresented in front of the judge and jury (Jasanoff,\nAlthough studies into science and law have shown\nthat the forensic sciences do not operate isolated from\npublics or social practices (M'charek, 2008; Toom,\n2010), forensics can be understood in an even broader\nsense. This interpretation of forensics goes back to the\netymological understanding of the term. The Latin\nword `forensis' refers to `the art of the forum'\n(Forensic Architecture, 2015), and can also be trans-\nlated as `public speaking'. Weizman explains how the\nmeaning of forensics has shifted over time:\nThe Roman forum to which forensics pertained was a\nmultidimensional space of politics, law, and economy,\nbut the word has since undergone a strong linguistic\ndrift: the forum gradually came to refer exclusively to\nthe court of law, and forensics to the use of medicine\nand science within it. This telescoping of the term\nmeant that a critical dimension of the practice of foren-\nsics was lost in the process of its moderniza-\ntion--namely its potential as a political practice.\nWeizman et al. (2010) speak in terms of `forensic archi-\ntecture'. This reading takes the practices and settings of\nevidence giving as a central point of departure \u00ad and\nnot the scientific or legal institutions. From this per-\nspective, forensics refers to a relational practice in\nwhich evidence giving can be organised and so it\nwidens up the range of actors and sites in which foren-\nsics can arguably take place. Forensics can therefore be\nreframed, as suggested by Latour (2012) in a response\nFigure 2. Screenshot of the interface: a data-rich version for\nstorage. Image provided by The Guardian Project.\n4 Big Data & Society\nto the Forensic Architecture project, as the production\nof public proof.\nAs the practice of forensics centres around a piece of\nmaterial, the concept also invites one to take questions\nconcerning the relevance of this material very seriously.\nTo explain this point better I draw on the work by Susan\nSchuppli on forensic media (forthcoming). Schuppli\nshows how technical objects can contain `trace-\nevidence': inscriptions of (violent) events. Her examples\ninclude documentary material that is degraded by radi-\nation (Chernobyl documentary by Shevchenko in 1986),\nfilm material that has been copied and edited (the `Loshi\nvideo' depicting a massacre in Kosovo in 1999; for an\nanalysis see Schuppli, 2014), and video footage that has\nmetadata embedded (an anonymous execution video\nshot in Sri Lanka in 2009). In her framing, the object\nbecomes `informed material', a term inspired by the\nphilosopher of science Isabelle Stengers, and it denotes\nthe way `their internal composition is enriched by infor-\nmation' (Schuppli, 2013). Such material can depict\nevents not only in representative terms, but the mater-\nials themselves become enriched as well through the\ninscriptions along the way. Schuppli shows the different\nways in which matter that has archived traces of events\narticulates itself as a witness of these events. Her con-\ncern is with how matter that is `informed' takes on the\nrole of a witness, that is, how matter can speak and\ntestify. She uses the concept of `material witness' as an\noperative concept to describe the process by which that\nhappens. This term is rooted in legal jargon (from the\nUS context). When a witness becomes `material' to a\ncase it means it holds crucial information (Leonardi,\n2010). In Schuppli's case studies, the question about\nthe material witness becomes one that is concerned\nwith the inscriptions being made along the trajectory\nof material becoming a piece of relevant evidence.\nThese inscriptions can be accidental influences, but\nthey can also be legal formats with which materials\nneed to comply in order to gain credibility in court.\nWhat I take from the reading of `forensics' as pro-\nposed by Weizman et al. is the displacement of forensic\npractices, which allows one to grasp the participation of\nactors other than scientists and lawyers in the investi-\ngation of affairs. Schuppli's work directs attention to\nhow material, including digital material, changes along\na trajectory and how that requires us to rethink pro-\ncedures of evidence giving. InformaCam is concerned\nwith practices of archiving trace evidence and with\nthe issue of how to make documentary material rele-\nvant through particular inscriptions. However,\nInformaCam is also an experimental application: it is,\nat the time of writing, `in the making'. That also means\nthat it does not (yet) deal with passed events that it can\ndocument. In fact, it is the organisation of public proof\nin future that the application directs itself towards. It is\nalso the organisation of public proof about which\nANT-scholars have produced fruitful studies.\nDevices for arranging the production of\npublic proof\nClassic examples of ways to organise public proof are\nlegal trials and scientific demonstrations (Jasanoff,\nThese are endeavours, or `devices' as in social-material\narrangements, constructed to prove particular states of\naffairs. These devices require solidity because they build\non rules or protocols that stay more or less the same\nand which allow a replication of testing and decision\nthinking about public proofs, and therefore relevant to\nthis case study, is Andrew Barry's understanding of the\n`demonstration' (1999). Barry starts with drawing an\nanalogy between scientific demonstrations and political\ndemonstrations. The scientific demonstration has\nalways been an important object of study in science\nstudies. These studies have shown that scientific dem-\nonstrations heavily depend on the participation of wit-\nnesses and controlled behaviour, and thus, on a\nShapin and Schaffer, 1985). According to Barry, polit-\nical demonstrations share a family resemblance with\nscientific demonstrations because they require a similar\nreorganisation of public space. In Barry's understand-\ning, `to conduct a political demonstration can be a\nmatter of making visible a phenomenon to be witnessed\nOne of Barry's examples is an extra-parliamentary\naction: an occupation in a forest against potential road\nconstructions. The site of the occupation, the land-\nscape, was not just the background for the protest.\nAs a `setting' it became part of the protest itself because\nit exposed a potential truth claimed by the protesters. It\nshowed `the fact that humans, land were mutually\nonmental destruction. In this way, the activists crafted\na space in which there emerged something to point to.\nAs can be taken from the title of Barry's piece, `site' and\n`sight' become interconnected. Barry describes at length\nthe style of conflict resolution between the activists, the\nliterature they produced and the material and social\ndiscipline needed to organise the camp. He also\ndescribes how the protest involved an `art of demon-\nstration' and a careful orchestration of how (electronic)\nmedia participate in the way the demonstration is\nwitnessed.\nIn sum, Barry shows that devices for public proof\ncan also be displaced from the formal arenas of public\nproof giving. At the same time he describes that,\nalthough these settings might be less protocolised,\nvan der Velden 5\nspaces for public proof giving still need a lot of work to\nbe established. Barry's take on the matter provides\nuseful pointers for analysing InformaCam. The\nInformaCam project is, in an experimental way,\ninvolved with a range of interventions through which\nit tries to establish such spaces and connections. Thus,\nin line with more `formal devices' such as the trial and\nthe experiment, InformaCam can also be seen as a\ndevice that is engaged with creating the conditions for\nthe production of public proof. As InformaCam is\nexperimental, it provides insights into how a forensic\ndevice is being set up.\nEnriching and ordering metadata\nAs will be explained in more detail, the InformaCam\nproject turns metadata from a risky matter of surveil-\nlance into something that is expected to have evidential\nvalue. Metadata can have evidential value because\n`[m]etadata refers to data about the data that is\nstored within a source of digital evidence' (Raghavan,\nof evidence can tell something about itself through its\nmetadata because contextual information is captured\nwithin the (digital) object itself. However, as mentioned\nearlier, data often need narrative techniques to become\nwitnessed as facts. Framed in more philosophical terms,\nfollowing Schuppli (forthcoming), capturing data by\nwhich material becomes `informed' is not always suffi-\ncient to turn it into a `witness': the material has to be\nable to articulate its relevance to a case. Similarly,\nInformaCam does more than merely `capturing' data.\nThe specific way by which data are captured and orga-\nnised is crucial for turning it into a witnessing machine.\nThe following paragraph describes in more detail\nthrough which categories the InformaCam project\norganises code and why. It also shows how software\ndevelopers draw together concepts about digital net-\nworks, law and ethical perspectives, into the same\nproject.\nThe lead developer of the project, Harlo Holmes,\nreflects upon The Guardian Project's app development\nin her master's thesis. She describes how EXIF data\ncontain various specified fields and allow for free com-\nments. EXIF stands for `Exchangeable image file\nformat' and is the standard used for specifying and\nannotating image files by digital cameras. She argues\nthat a large amount of the EXIF data fields are filled up\nwith intellectual property data. Referring to\nManovich's concept of `cultural transcoding', a concept\nthat addresses the translation of cultural formats into\nThe EXIF specification's treatment of the copyright tag\nis a remarkable example of the process of `cultural\ntranscoding' posited by Lev Manovich. In the specifi-\ncation, the EXIF tag descriptions are usually no more\nthan 3 lines in length; the copyright section, however,\nIt is this insight, that metadata are formatted in relation\nto an intellectual property regime, that for Holmes\nopens up the question about possible alignments with\nother regimes \u00ad such as that of human rights. If EXIF\nmetadata take part in a particular material legal cul-\nture, why wouldn't this be extended to other domains\nof legal culture as well? Holmes refers as well to the\nanthropological research of Gabriella Coleman on\nhow software developers approach code and intellec-\ntual property law. Coleman has shown how the soft-\nware community has contributed to a form of\noriginally defined by Robert Cover in 1983, refers to\n`the collective construction of new legal meanings and\nartefacts that diverge from statist or dominant inter-\nsituates The Guardian Project's app development in\nthis context. She states: `This interaction with justice\nthrough technology can be viewed as a form of digitally\nview `technological laws' undergo similar processes of\nre-appropriation:\nObscura openly challenges the law of the smartphone\nby overriding its unencrypted media database and by\nallowing users to rein control over the embedded EXIF\ndata. To interact with the app encourages direct expos-\nure to the new laws of images, allowing users to actively\nparticipate in the politics newly embedded into the\nOne can now begin to sense how Holmes and her co-\ndevelopers creatively appropriate the role of metadata\nby reaching out to formats that are directed at eviden-\ntiary settings. In making this move, the developers\nrelate to the human rights arena specifically.\nThe interaction between human rights and software\nis of central concern to the Project Director of\nWITNESS (which is the NGO that collaborates on\nInformaCam), Sam Gregory. Gregory (2012) presents\nsome of his ideas in a publication that discusses alter-\nnative ways of making human rights visible. One exam-\nple is a proposal for a new kind of licensing system, one\nthat `recognizes intentionality'. His proposal is to give a\ntwist to digital material, but one that is different from\ncopyright or Creative Commons licenses that deal with\nintellectual property rights and the possibility for\nremixing. His type of license would embed a proposed\nhuman rights use into the metadata. His second exam-\nple relates to rethinking witnessing in the digital age `in\n6 Big Data & Society\nline with the primary principle that every human being\nis possessed of ``inherent dignity'' \u00ad a concept that runs\nAn important concern in this context is the avoidance\nof re-victimization of victims on film through the wide-\nspread circulation of media. Gregory continues to\nargue that this comes with an ethical obligation for\nthe one who is witnessing to do so carefully with respect\nfor the victim: `Contemporary thinking on testimony,\nwitnessing and trauma also places a heavy emphasis on\nthe responsibility of the witness to abuse to represent it\nresponsibly and with ethical integrity \u00ad to be, so to\nwants to contribute to ethical forms of witnessing by\ntranslating professional notions of informed consent\n(inspired by medical practices, social science and inter-\nnational human rights and humanitarian law) into the\nInformaCam is an implementation of some of the\nideas mentioned above. This is done by what one\ncould call `enriching metadata': InformaCam structures\nhow metadata are embedded in the image. An (early)\nblog post on the project mentions four metadata cate-\ngories: Data, Consent, Intent, Genealogy.7 The cat-\negory `Data' sounds very general, but it represents the\ndata that `captures the moment of capture'. As\nexplained by The Guardian Project's website: `This cat-\negory includes all standard metadata (timestamp,\nacquired sensory data, location and movement data)\nthat have been collected during the lifetime of the\nimage, from the moment it was opened to the instant\nit was saved' (The Guardian Project, 2012).\nInformaCam does not capture traffic but only publicly\nvisible identifiers. `Consent' resonates most explicitly\nwith human rights culture. A user of the application\ncan add free text to images indicating whether the sub-\nject has given consent to be filmed. As touched upon\nearlier, the approach of WITNESS is to translate ideas\nof consent into technical devices, by for example tools\ngiving `prompts on consent during those filming/upload\ntion thereof. `Intent' is more experimental and is dir-\nected to the circulation of digital material. It indicates\n`information about the media's creator and the permis-\nsions for sharing' (The Guardian Project, 2012), and\ncould therefore be considered as a materialisation of\nwhat Gregory (2012) proposed: `a licensing system\nthat recognizes intentionality'. This `tag of intent' will\nsay something about what kind of `use' the producer\nenvisions with a particular digital object and is an\nattempt to create `human rights media' as a particular\npiece of media and bring that into circulation (Gregory,\n2013, personal communication). `Genealogy' refers to\nthe main indicator of the chain of custody (or `data\nintegrity', which means that data should be left in tact\nuntil it reaches the court). This is addressed through a\ndigital hash embedded into the file on the moment the\nimage was made to indicate its original state.8\nBesides these main categories, the developers make\nuse of an ordering device entitled J3M (JSON\nEvidentiary Mobile Media Metadata), which is\ndescribed as `a format that can be used to easily\ndescribe the origins, context, and content of any\nimage or video taken with a mobile device' (j3m.info,\n2013). This is to be understood as a way of structuring\nmetadata. The aim of J3M is to:\n[m]aintain a trusted record of a media object's chain-of-\ncustody (. . .); Express the context surrounding the\nmedia object's capture (. . .); Embed extra user input\nfrom forms or surveys into the media object as signed\nmetadata (. . .); Provide metrics for analyzing the con-\ntent of the media object to mathematically determine\nthat it was created by the device indicated in its meta-\nFigure 3 is an example of what this would look like in\ncode. Technical specifications are given on the website\nof the Guardian Project including a java library to help\ndevelopers to use J3M.\nThe above mentioned categories and J3M show a\nfirst insight into how the people involved with\nInformaCam actively shape metadata. They do so in\na way that would help forms of narration firstly with\nrespect to the context of the event, secondly with\nrespect to the content of the material, the relation\nbetween the producer of the image and the people\ndepicted, and, finally, his or her relation with the digital\nobject itself. It is an example of an emerging culture of\nFigure 3. Screenshot of metadata ordered through J3M. Image\nprovided by The Guardian Project.\nvan der Velden 7\ndata collection in which actors on the ground exercise\ntheir agency by constructing and curating data for par-\nticular purposes (Couldry and Powell, 2014).\nOrganising conditions of public proof\nAt the time of writing, InformaCam just released its\nbeta-implementation. Therefore, real life experiences\nof how InformaCam is put into use are not yet avail-\nable. However, InformaCam allows for organising the\nsettings for the production of public proof in multiple\nways. I discuss three of these ways below.\nA first intervention has already been discussed,\nwhich consists of tying images to regimes of evidence.\nAs highlighted in the previous paragraph, the cate-\ngories of InformaCam show how the project developers\npull in different kind of formats into the application.\nThe chain of custody, an important issue for investiga-\ntory purposes in legal settings, is accommodated with a\ndigital hash that J3M embeds in the file. In addition,\nnotions of ethical witnessing from the human rights\narena are redesigned as an awareness prompt. In this\nway, in Holmes' words, the developers are `ingraining'\ncategories borrowed from legal and human rights dis-\ncourse into the metadata (Holmes, 2013, personal com-\nmunication). It is interesting to see how these\ninscriptions organise the capturing of data before the\nimages are even being made. This has its analogy in\nother legal practices. In his work on the workings of\nlaw (2010), Latour explains how, in the context of the\nFrench Council of State, some (governmental) docu-\nments are prepared for legal use before being used in\na legal setting. They are, in other words, already `pro-\nfiled' before making it to the court. Files, according to\nation of law, he argues, cannot be understood without\nthese preparations. Similarly, software developers are\nundertaking preparatory work to `ripen up' digital\ndata for legal use.\nWhether this material will make it in the end to the\ninternational human rights courts is most difficult to\nforesee. In the context of this discussion, it is import-\nant to take note of the different legal systems with\nrespect to the admission and evaluation of evidence\nial system in the United States exist specified legal\nrequirements with respect to scientific evidence (the\nDaubert Criteria).9 It has been claimed that these\nadmissibility rules, together with the litigation struc-\nture in the United States, provide opportunities for the\ncritical evaluation of science and technology, espe-\ncially when compared to inquisitorial systems found\nin many continental countries (Jasanoff, 1998a; Van\nKoppen, 2007). In inquisitorial systems, the prosecu-\ntor is responsible for the `dossier work' and the\nadmissibility of scientific and technological data is\nless subject to public discussion in the courts.\nInternational human rights courts consist of a mixture\nof legal systems, but tend to follow civil (continental)\nlaw in relation to the admission of evidence. This\nimplies that the threshold for the admissibility of evi-\ndence is low. With respect to electronic evidence the\ninternational tribunals require no particular standards\nand in terms of admissibility trial chambers are rela-\ntively free in their assessment (O'Neill et al., 2011).\nThe rules for (electronic) documentary evidence there-\nfore vary from court to court and the development of\nstandards proceeds very slowly (Center for Research\nlished for national and local courts than for inter-\nnational courts and tribunals' (Center for Research\nhuman rights O'Neill et al. state that `procedural\nrules at international courts and tribunals offer little\nguidance on what must be shown to authenticate new\nin which metadata have played a role is still rather\nlimited, and hence there is little case law to draw con-\nclusions from about what to expect in the near future.\nA request by the International Criminal Court\nProsecutor for a protocol for `born-electronic evi-\ndence' was denied by the Chamber (O'Neill et al.,\n(p. 42), the authentication of e-evidence can play an\nimportant role in opening up investigations into\nhuman rights violations. Despite the lack of existing\nstandards, there is a realization that they might\ndevelop in the years to come. According to the\nauthors of the same review, the potential future devel-\nopment of restrictive demands concerning e-evidence,\nwhich might be inspired by the more extensively docu-\nmented (commercial) US litigation context, could be\ndangerous for international human rights proceedings,\nsince the burden placed on people bringing in evidence\nmay preclude those without access to equipment of\nsufficiently high standards. That is the reason why\nInformaCam is a significant project: whereas require-\nments for metadata in the legal domain of inter-\nnational human rights procedures are not yet\ndefined, the developers of the project are already\nworking towards developing a specific socio-technolo-\ngical standard of which they hope it will also become\naccessible for activists.\nIn this context it is important to know that The\nGuardian project will soon launch the InformaCam\nIBA launched a spin-off called `Eyewitness for Atrocities\nApp'. This app is built on the open source implementa-\ntion that was made in collaboration with the Guardian\nProject. That means that the concepts behind the project\n8 Big Data & Society\nare now being brought into practice. Next to offering\nthe tools, the developers of InformaCam do also try to\nfind ways to familiarize courts with their techniques.\nAccording to Sam Gregory, they are looking for what\nthey call `demonstration projects' that can help demon-\nstrate the evidentiary value and applicability of J3M\ndata and the InformaCam project (Gregory, 2013, per-\nsonal communication). At the same time they are aware\nof the dangers of putting a very heavy weight on people\nbringing in evidence whilst not everybody has access to\nthe right equipment to secure such standards: `We're\nalso cautious though not to create a situation where\nthere is an insistence on extra metadata for proof since\nwe know that there will be many contexts where valuable\nevidence is missing this' (Gregory, 2013, personal\ncommunication).\nA second intervention is related to the insight that\nmobile devices have capabilities that can organise forms\nof witnessing on the ground. Through Bluetooth the\napp can detect other devices that have InformaCam\nactivated nearby. In this way the app can show that\nmultiple devices were present at the same place at the\nsame time, or that people have made similar documen-\ntation at the same time with regard to the same event\n(Holmes, 2013, personal communication). One poten-\ntial user group is the Georgia Legal Services Program\nthat helps migrant workers (Making Cameras Count,\n2013). It happens that bosses deny that people came to\nwork, leaving workers without payment. It is for such\nsituations that InformaCam could mobilize self-\ntracking: through the simultaneous use of Bluetooth\ndetection, people would be able to try to prove their\npresence, or at least that of their phones. Therefore, the\napplication does not only aim to produce images of\nevents, it would also put oneself, or one's collective,\non the map. So one way in which InformaCam invites\nmaterial to become more `informed' is by capturing\n(collective) presence. It captures not only contextual\nmetadata that refers to location, device number, etc.,\nbut it enacts a collective body of witnesses. Figure 4 is\nan example of how the presence of devices can be\nmapped through Bluetooth.\nWith a third intervention, the J3M-library makes a\nparticular form of forensic data analysis possible.\nAccording to Harlo Holmes, it is not the app itself\nthat she expects to do all the work: it is the openly\navailable library that opens up the perspective to dis-\ntribute J3M to other applications and platforms such as\nGregory adds that the distribution of J3M into the\npublic domain aims to open up research possibilities\nthrough J3M itself. The library is inscribed into the\nfiles and subsequently read out again. So the device\nworks by structuring data in such a way that material\ncan be pulled together after capturing it. According to\nGregory, multiple J3Msources embedded in\nInformaCam material can be used for timeline mapping\nand comparison between multiple angles. It could\nenhance constructing a chain of explanation of what\nhappened in an event (2013, personal communication).\nThere are already several projects that map events on\nthe basis of (EXIF) metadata online. See for instance\n`The Rashomon Project', an open-source online toolkit\nthat assembles and analyses videos and photos from\n`contested events'. Their aim is to enhance a nuanced\nunderstanding by providing multi-perspective timelines\nFigure 4. Map that visualises cell towers, WIFI, Bluetooth and movement. Image provided by The Guardian Project.\nvan der Velden 9\nand interactive viewing features (The Rashomon\nProject, 2015). The approach of the InformaCam devel-\nopers is therefore an example of how actors `on the\nground' challenge `conventional data collection'\nthe InformaCam System Architecture. From the left to\nthe right it shows the app, the two versions of the docu-\nmentary material that the app produces, the methods\nfor verification, and lastly, the analysis dimension in the\nproject (`J3MScan Advanced Search and Analysis').\nA forensic device for activism\nInformaCam takes part in an emerging trend of pro-\njects that aim to enhance the verification of online\ninformation. There exist websites for tracking users'\nlocation footprint on the basis of GPS data, tools\nfor revealing EXIF data attached to images, and tools\nfor showing whether images have been altered. (See, for\ninstance, the website of the Verification Handbook for\nan overview (Silverman, 2014).) On the other side of the\nspectrum there are plenty of tools that help users to\nprotect their identity, to browse anonymously or to\nsecurely encrypt their data. (See for instance, http://\nprism-break.org.) According to the developers,\nInformaCam is, as far as they know, the only app\nthat combines this many capabilities (`enhanced meta-\ndata through sensors, cryptographic verification/hash-\ning/signing, secure storage and transmission') and that\nis offered as a free and open source app that runs on\ninexpensive smartphones (Freitas, 2013, personal\ncommunication).\nMoreover, InformaCam is prefigurative to legal\nstandards. As mentioned earlier in the paper,\nAndrew Barry has shown how activists can be\ninvolved in carefully modifying and constructing\nspaces that allow proof to emerge, and how they\ncan invent new forms of demonstration. The actors\ninvolved with the InformaCam project do a similar\nthing with respect to networked technologies. They\nactively engage with how data can be handled by\nmaking InformaCam intervene in different parts in\nthe trajectory of an image. By transcribing law into\ncode before the event, controlling how data is cap-\ntured on the ground, and by the enhancing research\ncapabilities for post-event analysis, the InformaCam\nproject invents a form of what we could call `sensory\ndata forensics'. Mobile phones, sensory data, users'\ninteraction with technology, legal formats and code\nare tuned in such a way that together they allow for\nthe production of public proof, and hence operate as a\nforensic `device' in the ANT sense of the word. It also\nindicates a medium-specific collaborative practice to\nwitnessing, which can be better understood when\ntaking into consideration that particular software\ncommunities have particular approaches to code\nInformaCam are not waiting until jurisprudence\ncatches up with new evidentiary modes, but are\nalready intervening through the media landscape.\nFigure 5. InformaCam System Architecture. Image provided by WITNESS and The Guardian Project.\n10 Big Data & Society\nThere seems to be a paradox to the idea that images\nshould remain `in tact' to retain the chain of custody\non the one hand and the practice of adding data-points\nto structure images for analysis on the other hand.\nBut as we can read in the work of Kelly Gates, this\nparadox characterizes the practice of video forensics\nby forensic experts as well. Looking at the disciplinary\npractice of video forensics in particular, Gates describes\nhow in preparing CCTV video material, forensic inves-\ntigators use narrative techniques such as annotating,\nzooming and composing timelines, sometimes with the\nuse of sophisticated software. Metadata can also be\nattached to images to enhance search and retrieval\ncritically points out, the practice of video forensics\npoints to a new conceptualization of (computational)\nobjectivity:\nHere I want to suggest that the use of digital imaging\ntechnologies to make visible what is invisible and invest\nimages with indexicality points to a new conceptualiza-\ntion of objectivity. This way of thinking about object-\nivity holds that neutral, scientific results can be\nachieved through the application of computational\nforms of analysis \u00ad automated, algorithmic techniques\nJust like forensic investigators, the developers of\nInformaCam invest images with indexicality to condi-\ntion computational analysis. Whether projects such as\nInformaCam, just like forensic state investigators, also\nparticipate in the establishment of what Gates calls a\nan interesting topic for future research. Especially\nbecause the developers don't hide the fact that the com-\nputational analysis of data requires an extensive prep-\naration including choices, concepts and ethics.\nConcluding remarks\nThe InformaCam project signals an innovative way of\nthinking about surveillance risks: surveillance risk is\nnot just something to be `informed of' or to be avoided;\nit is something that can be hacked in order to become\nan empirical object. The project has re-articulated\nwhat used to be a problem into its working material.\nFor the people involved in the InformaCam project,\nthe circulation of data is a problem but at the same\ntime it is material that can be analysed and used for\nother things.\nInformaCam shows in what direction activism in the\ncontext of surveillance can develop. It seems to do away\nwith the gaze as a central organising principle. Instead\nof being primarily concerned with what can be seen (on\nan image), the project shows how attention shifts to the\n`art of looking', which is concerned with how to organ-\nise which data counts (including one's own position,\nlocation, etc.). In short, it becomes engaged with inves-\ntigatory practices through code. It is what Thomas\nKeenan (inspired by the use of the concept by the pho-\ntographer Sekula) calls `counter-forensics'. This con-\ncept refers not to countering forensic investigations,\nbut to the tactical adoption of forensics in the context\nThis investigatory dimension raises a few critical ques-\ntions: Doesn't the project become too much of a surveil-\nlance project itself? Doesn't it perform analytic work in\nservice of authorities that attempt to monitor people? Do\npeople who use this tool, by collectively mapping events\nand their devices, endanger themselves? When asked\nabout this, Harlo Holmes admitted this constitutes a\npotential risk, but she also argued that many states\nhave access to this kind of data already (as\nInformaCam captures only public data) and many\npeople are not aware of it yet. She regarded using\nInformaCam as taking a step forward in terms of the\n`equality of arms' (Holmes, 2013, personal communica-\ntion). Recent developments have underlined the invasive-\nness of state surveillance. The National Security Agency\n(NSA)-disclosures by Edward Snowden in 2013\n(Greenwald, 2014) have shown that the NSA uses many\ntechniques for metadata analysis. This includes pro-\ngrammes such as `HAPPYFOOT' for collecting mobile\nphone location data and `Co-Traveler Analytics', which\ndetects devices being present together at particular loca-\ntions (Soltani and Gellman, 2013). Tools such as\nInformaCam, therefore, can be seen as a timely response\nto the unequal distribution of power over data.\n"
}