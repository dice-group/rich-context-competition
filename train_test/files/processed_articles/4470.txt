{
    "abstract": "Abstract\nDigital technologies in combination with `big' data and predictive analytics are having a significant\nimpact upon professional practices at individual, organisational, national and international levels.\nThe interplay of code, algorithms and big data are increasingly pervasive in the governing,\nleadership and practices of different professional groups. They are reshaping the relationships\nbetween professional grouping and between professionals and their clients/users/students.\nNew forms of accountability and responsibility are emerging as a result of these trends, raising\nimportant questions about culpability and decision-making in professional practice. However,\nto date, despite the introduction of many professional codes on the use of digital data and\nsocial media, these issues have received limited examination in research addressing professional\neducation. This article aims to explore some of these trends, how they are manifested in different\nprofessions and what might be the educational implications. Our argument is that new digital\ntechnologies are reconfiguring professional practice and responsibility, but that the education of\nprofessionals has yet to adequately reflect these changes.\n",
    "reduced_content": "European Educational Research Journal\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\neerj.sagepub.com\nExploring the impact of digital\ntechnologies on professional\nresponsibilities and education\nTara Fenwick\nSchool of Education, University of Stirling, UK\nRichard Edwards\nSchool of Education, University of Stirling, UK\n Keywords\nProfessional responsibility, accountability, professional education, digital technologies, analytics,\nalgorithms, big data\nIntroduction\nDigital technologies in combination with `big' data and predictive analytics are having a signifi-\ncant impact upon professional practices at individual, organisational, national and international\nlevels. These technologies and their associated analytics are proliferating across professional\nCorresponding author:\nTara Fenwick, School of Education, University of Stirling, Stirling FK15 0HD, UK.\nEmail: tara.fenwick@stir.ac.uk\nArticle\npractices from medicine, law and education to urban planning and policing. They collect data\nthrough continuous sensing. They access massive data sets, such as administrative and health\nrecords, and link these with all sorts of unstructured data combed in real time from human digital\nactivity. They work through algorithms to analyse this data on a huge scale for patterns, then cal-\nculate these patterns to identify problems and suggest solutions. Increasingly these technologies\nare being used to predict and plan, to recommend and, at times, to even make automated decisions.\nThis interplay of code, algorithms and big data is increasingly pervasive in the governing, leader-\nship and practices of different professions. It is also reshaping the relationships between profes-\nsional grouping and between professionals and their clients/users/students.\nThese trends raise important questions about responsibility: the contribution of the skilled pro-\nfessional in these reconfigured practices, the role and position of professional judgement, and how\nresponsibility and accountability are to be delineated with so many technological actors integrated\ninto professional services. Digital technologies are part of the emerging knowledge infrastructures\nof daily life, the `robust networks of people, artefacts, and institutions that generate, share and\nmaintain specific knowledge about the human and natural worlds' (Edwards, 2010: 17). They rep-\nresent a significant part of professional futures. Yet, despite some research on the effects of digital\ndata and the coded governing of contemporary life in educational systems (e.g. Fenwick et al.,\ntions of digital technologies for professional practice, responsibility and education.\nThis article seeks to explore the issues arising with the emergence of digital technologies, pre-\ndictive analytics and big data in professional work, with particular interest in questions of respon-\nsibility. What are the implications of digital analytics for practitioners' responsibility and\naccountability in their everyday work, as well as for the disciplinary knowledge underpinning their\npractice? What new capacities might be needed, and what dilemmas might be anticipated? How\ncould we be educating professionals for forms of practice and decision-making that are increas-\ningly `code-threaded'? At the very least, what critical dialogues might we engage student profes-\nsionals in regarding digital analytics in their practice? These are significant questions for\nprofessional educators as well as for the broader social science communities in a period of rapidly\nchanging circumstances. This article will touch upon these questions rather than address each fully,\nas our intention here is to suggest an agenda for research and professional education that requires\nfar more attention than can be achieved within the context of a single article (cf. Fenwick, 2016).\nThe article is, therefore, not intended to be a comprehensive literature review or a report of\nempirical data, but an exploratory essay drawing selectively on literature in professionalism and\nprofessional work, ethics, education and software studies. The argument is presented in four parts.\nFirst, we will outline some contested conceptions of professional responsibility and their ethical\nassumptions and practical implications. We will explore also some forms of calculation and distri-\nbutions of accountability and professional responsibility associated with these trends and tensions\nwithin them. Second, we outline some of the work emerging that explores the work of algorithms,\nbig data and analytics and their significance for social practices. Third, we explore selected ways\nin which digital technologies interplay with professional practice, in domains as diverse as polic-\ning, health and architecture. Finally, we will outline what we take to be some of the key educational\nimplications arising from the discussion. While it may be rather easy to identify dystopian trends in\ncritical evaluations of digital technologies, the position we take is one of creating useful future\ndirections. These are likely to require a reconfiguration of professional practices, perhaps involv-\ning a reframing and refocusing of the specific dimension brought to sociotechnical, sociomaterial\nassemblages of practice by expert human practitioners. We are mindful of the lurking dystopias,\nwhile seeking ways to interlink the benefits of digital analytics with the significant issues that pro-\nfessional groups and services seek to address. Our intention is to raise questions about the framing\nof future practice and research in relation to professional responsibility and education, deliberately\nadopting a broad approach to reflect the multi-professional and multi-disciplinary spaces within\nwhich these issues are being researched and discussed.\nProfessional responsibilities and accountabilities\nWhile the notion of the professional is heavily contested, for the purposes of this article we may\nunderstand professions as `the knowledge-based category of service occupations which usually\nfollow a period of tertiary education and vocational training and experience ... [and are] exten-\nsively engaged in dealing with risk' (Evetts, 2013: 781). Within the professions, responsibility is\noften treated as a defining set of obligations for the nature of professionalism itself: obligations to\nthe client's interests as well as the needs of society broadly (Freidson, 2001). Much of the literature\non the topic is characterised by normative moral declarations of what professionals ought to do,\nand what comprises professionals' responsible practice in particular fields. Prescriptions abound\nfor codes of behavior as well as for methods to educate professionals to perform these codes. These\nprescriptions may be stoked by complaints and public concern about professionals' perceived irre-\nsponsible practice and the failure to regulate practices appropriately.\nConceptual discussions of professional responsibility are wide ranging, from causal (who\ncaused the problem) to consequential responsibility (who takes the blame); and from attributed\n(who is held accountable) to distributed responsibility (how accountability is apportioned among\nagents). Moral responsibility invokes notions of both obligation and moral decision-making.\nObligation calls forth a sense of duty to care for self and others extending beyond one's own self-\ninterest, and an accountability to others for one's actions. In this sense, questions of professional\nresponsibility have tended to focus on the actions and decisions of individuals, although questions\nabout collective and organisational responsibility have become more common. The others to whom\nprofessionals are responsible can be interpreted broadly: other human beings, other collectives,\nsuch as community or national interests, authorities, tradition, animals or non-sentient beings of\nthe natural universe, concepts or ideals. Moral decision-making to acknowledge and act upon one's\nprofessional responsibilities incites questions about the conception of the `good', the attendant\ncriteria or principles that should guide action, and the extent of one's freedom to decide. Within all\nof this, as Gibbs (2000) points out, some view a distinction between responsibility as felt and\nresponsibility as acted.\nIn the field of ethics, critical debates have long swirled around the questions: who is responsible\nto whom, for what, and to what extent? Responsibility has been developed within a tradition of\nrational philosophy as a question primarily of ethical decision-making, invoking issues of univer-\nsal laws and the problem of the contingent particular situation, as well as bonds and obligations that\ninhere in an individual, conceived as autonomous, intentional and capable of acting independently\nof others. However, Levinas (1981) and educational philosophers who have taken up his concep-\ntion of the ethical subject (e.g. Biesta, 2006) have begun from a basic critique of the assumptions\nembedded in this rational tradition. Levinas counters the view that individuals act and reason as\nautonomous agents, and stresses the intersubjective relationships that enmesh human beings with\none another beyond their conscious intention or rational application of moral principles. He also\nargues that ethical responsibility is moved not by rational decision-making but is enacted within\nmoments of connection, participation with others that calls forth response.\nThese considerations shift the issue of responsibility from notions of individual felt duty to the\nactive responding to others, broadly conceived, within complex webs of connection. A focus on\nresponse turns attention away from defining what is the good, and what ethical laws should guide\naction, towards questions about how response is excited, by whom or what, what forms it takes and\nwhat are its consequences. Thus, responsibility is not necessarily a simply rational construct, but can\nbe a phenomenal and relational dynamic. The meanings of professional responsibility are tangled\nwith issues of ethics, where some seek a clear moral delineation of `good'practice through codes of\nethics and conduct to be followed, while others focus more on the responsiveness to circumstances.\nThe latter entails a more (philosophically) pragmatic approach to issues of professional responsibil-\nity than a simple principled approach, that is, the rational application of ethical `laws' and `rules'.\nThere is growing research pointing to the pragmatic pluralism of professionals'obligations, and\nthe tensions and conflicts in responsibility that they must negotiate. This web of commitments\noften necessitates what May (1996) has called `legitimate compromises'. Professionals balance\nobligations to their employing organisations and their rules of practice, to broad social needs served\nby their profession, to the profession itself and the standards and regulatory codes governing its\npractices, to individuals for whom the professional adopts a responsibility, and to personal alle-\ngiances influencing a sense of the `right thing to do'. Robinson (2009: 18) argues that these func-\ntion as three different kinds of engagement in professional responsibility. One is a plural\nengagement, working through critical dialogue to navigate the responsibility of different roles.\nAnother is a relational engagement, `maintaining close awareness of the other'. A third is creative\nengagement, `looking for a collaborative and negotiated response'. These may occur singularly,\nsequentially or even simultaneously.\nAccording to empirical research, professionals' negotiations of these differing, and sometimes\nconflicting, responsibilities are becoming exacerbated by particular tensions between the claims\nof increased efficiency and accountability, and the best interests of clients, students and patients\nnurses and teachers appear to manage these tensions by juggling simultaneously the discourses of\neconomy and ecology in practice. Colley et al. (2007) suggest that professionals must often\nchoose to act in ways `unbecoming' according to formal regulations, which are themselves risky.\nThese tensions signal the uneasy relations between professional responsibility and accountabil-\nity. Responsibility may be described as the needs to which professionals are expected to respond,\nand in what ways, while accountability is more about how professionals are expected to justify the\nways they perform those responsibilities. Many commentators such as Solbrekke and Sugrue\n(2010, 2014) are concerned about the increasing attention given by employers and government to\nprofessionals' accountability in ways that can distort core commitments of responsibility.\nAccountability in professional practice takes various forms: fiscal accountability, legal accounta-\nbility (compliance with explicit regulations), bureaucratic outcomes-oriented accountability (duty\nto the organisation's mission), community accountability (duty to care) and professional account-\nability (duty to a profession's discipline and ethics).\nThese forms and effects of accountability are all made visible through systems of measurement.\nThese measurements require a conversion of living events and their often unpredictable ambiguity\ninto representations of particular scales, into data. In the process, qualitative judgements can be trans-\nlated into measured technical data. These data are rendered in forms such that they can be scrutinised\nand assessed according to often conflicting accountability demands by various stakeholder interests\nranging among professionals, government departments, employers and the general public.As Robson\n(1992: 700) explains, accounts essentially make living events visible; they provide a basis for calcula-\ntion. These calculations afford a means for acting upon individuals and institutions to produce new\nprocesses. Over time, accountabilities have become increasingly calculated through the interlacing of\nalgorithms and data and the analytics and visualisations of the practice they generate.\nIn relation to accountabilities, Callon and Law (2005) describe the linking and manipulation of\ndata as an act of counting and judgement that typically follows a three-stage process. First, relevant\nentities are categorised, detached and displayed in a single frame. Second, these entities are manip-\nulated and transformed to show (or create) relations between them. Finally, a result is extracted\nsuch as a new entity, a ranking, or a decision. Calculation does not reside in human subjects and\nbecome projected through their efforts as acts of agency, but rather is enacted in `material arrange-\nments, systems of measurement and methods of displacement \u00ad or their absence' (Callon and Law\n2005: 715). Increasingly this work is done through digital technologies.\nCallon and Law (2005) reconfigure the concept of calculation in two ways that are helpful for\nunderstanding accountability. First, they offer the term `qualculation'to capture the ways that arith-\nmetic and qualitative accounts are melded in acts of calculation. Things have to be valued in par-\nticular ways, they must qualify for calculation, which involves qualitative processes. Acts of\nqualculation involve all sorts of ways to manipulate entities within a single frame, only some of\nwhich are arithmetic. Thus, rather than big data being technicist and reductionist, that is, ignoring\nissues of quality, in conceptualising them as practices of qualculation, we can trace the meshing\nand translation of values into the socio-technical practices of data collection and analysis. Second,\ncalculation and non-calculation are mutually constitutive: they are interrelated, rather than existing\nin separate spaces. All calculation comes about with and against non-calculation, and vice versa. In\nother words, in making certain things visible, certain things are made invisible. The most important\nboundary is not between the acts of counting and the acts of judgement, but between arrangements\nthat allow qualculation, and other arrangements that make it impossible. In the context of digital\ntechnologies and big data, this entails the capacity for the values in professional codes to be trans-\nlated into the binary logic of lines of code.\nIn our discussion, this points to the ways in which digital technologies are not simply technical\nsolutions to enhancing the quality, efficiency and effectiveness of practices, but can also be power-\nful value-embedded socio-technical interventions in the attempted shapings of practices, account-\nabilities and responsibilities. What is made visible and invisible is the result of work and does not\nexist a priori to its enactment. They are neither determining nor determined, as qualculations are\nnot simply internalised but become part of the web of relations through which professional practice\nis enacted, in the process contributing to different enactments of responsibility.\nSolbrekke and Sugrue (2014) suggest that responsibility and accountability are two logics used\nin assessing professional work, both of which are concerned with the quality of practice. However,\nwhile the first is framed around professionals' own judgement, the second focuses on profession-\nals' compliance with externally determined indicators of performance. Thus, `best practice'\nbecomes performed and defined differently within each of these logics. On the one hand, the logic\nof accountability frames practice through economic concerns for standardised, measurable priori-\nties and rationales, and economic processes of external audit and counting. On the other hand, the\nlogic of responsibility frames practice within a language of values and integrity, contextual nuance\nand relationship, and processes of situated judgement and negotiated standards. For Solbrekke and\nSugrue, this logic of responsibility elicits more proactive activity, while that of accountability\nprompts more reactive behaviour. There is a dynamic interplay between these logics with their\napproaches and priorities affecting one another.\nWe witness well-developed research on professional responsibility and accountabilities. What\nhappens to these then when digital technologies are introduced into both the practice of profession-\nals and their accountabilities, when qualculation takes hold? What professional decision-making is\ninformed by digital technologies or supplanted by them? How are responsibilities and accountabil-\nities being delegated and distributed by and to digital technologies? What possibilities and risks\nemerge through these developments? We explore such questions in the next section.\nDigital technologies, big data and analytics\nSo ubiquitously and insidiously are digital technologies permeating all aspects of life that some\nclaim we now live and work in `code/space' (Kitchin and Dodge, 2011). It is difficult to separate\nhow we think from the logic of the software through which we form and represent our thoughts.\nNor can we disentangle our actions from the materials with which we work, generated through\nautomated analysis of massive information sets to which we contribute continuously. Digital tech-\nnologies and people are becoming interdependent, constituting one another, with emergent effects;\nthey do not just mediate existing social forms, but are integral to practice.\nto the wide-reaching and accelerating consequences of these forces, claiming that professionals,\nprofessional educators, researchers, policy-makers and the public are just beginning to realise the\nenormous challenges being posed by digital technologies, software code and standardised data. Yet\nprofessional education curricula and pedagogy seems to be standing aside from these transforma-\ntions, often continuing to develop practitioners' knowledge and skills without much attention even\nto the new educational materials appearing on learning analytics (Buckingham Shum 2015). Where\ndigital technologies are part of professional education, they tend to be treated as tools: useful to\nmaster, but clearly subordinate to the knowledgeable professional. Yet the industries that are mar-\nketing these digital technologies, and the practitioners, policy-makers and consumers eyeing their\npotential, are already moving towards a future that could quickly marginalise or even exclude\nprofessional intervention in many arenas. For some, this is part of the democratising of knowledge\nand expertise and a challenge to professional deference. For others, it represents the denial of\nhuman expertise and expert judgement.\nThe development of digital technologies is linked to the use of big data. Big data is a widely\nused, if problematic, term that refers to various types of data sets collected in massive volume at\nhigh velocity that tend to be exhaustive in scope, use very fine-grained resolution, and combine\nwide-ranging types and contexts of data (Kitchin, 2013). What marks their increased role in profes-\nsional practice are their digital forms and the capacity for them to be searched, sorted and analysed\ndigitally by the algorithms of software code (Halford et al., 2012). The results are ever-expanding\nmasses of data and database formats that can be manipulated to produce measures of performance,\nanalytics to predict behaviours and actions, and capacity for automated decision-making. In a\nrecent report for the UK's Economic and Social Research Council, Ruppert and her team (2015)\nargue that it is these new social practices that need investigation. Rather than focusing on the oft-\ncited big data characteristics of volume, velocity and variety, these authors direct our attention to\nthe specific novel socio-technical practices through which data is born, given meaning, then exer-\ncised in all sorts of ways (searched, cleaned, mashed, curated, staged, traced, shared, re-purposed,\netc.). These exercises enact data in ways that order, change, reproduce and govern social life.\nThis is an argument also made by Mackenzie (2015) in his examination of some of the practices\nof prediction through machine learning. He suggests that `the production of prediction is not auto-\nmatic, although it is being automated. But as machine learning is generalized, the forms of value\nthat circulate in the form of commodities alter. Prediction changes the social reality of value forms'\n(Mackenzie, 2015: 444). Thus, while these digital analytics are producing possibilities for `evi-\ndence-informed' policy and practice in ways unimagined in previous eras, Ruppert et al. (2015)\nsuggest that we think about big data itself as having social lives. We tend to overlook these social-\ntechnical lives, which raises new vulnerabilities, risks and problems in how they become enacted.\nIt is here that research on the development of knowledge infrastructures and ontology building\nbegins to give insights into such lives (e.g. Edwards et al., 2013). It is also the case that some of\nthese lives are imagined and marketed rather than practised and experienced.\nKitchen (2014) identifies that big data are collected through at least three ways. First,\nthrough intentional surveillance operated by humans, such as assessment records of students or\npatient record information accumulated through a range of measures, tests, electromagnetic\nscans and biotechnical feedback. This produces what Kitchen calls `directed data'. A second\nmeans is through embedded sensors in objects, environmental measuring instruments, click-\nstreams measuring students' and staffs' digital activity, scanners that read objects, and machines\nthat record their own uses as well as the items passing through them, such as diagnostic\nmachines. These sensors and scanners produce `automated data'. A third way is through gather-\ning `volunteered data', which we ourselves post on the web or social media. This data often is\nprocessed not by human actors, but by algorithms in software code. However, humans and\ntechnologies are not so easily separated: they participate together in practices of generating,\nmanipulating and curating data. Through processes of tagging, classification, calculation and\ngeneralisation, knowledge is being enacted, along with identities, categories and relationships.\nThese elements are being represented through what Manovich (2013) calls media hybridisation\nand the `deep mix' of media platforms, logics and techniques. Ever new data formats, new\ninterfaces and new ways of creating media are emerging from this deep media hybridising. This\nis why Manovich claims that software is `taking command'.\nIn effect, digital technologies, data manipulated by algorithms, alongside the explosion of soft-\nware code mediating much of our analytics, knowledge, communication and decision-making, are\norganising new standards of decision-making and governing. In the process, Berry (2011) argues\nthat different forms of delegation, aggregation and quantification are being enacted. While his\nanalyses focus on social life more broadly, it is their implications for professional practices that are\nof interest here.\nDigital technologies, professional practices and responsibilities\nIncreasing amounts of research in the professions is exploring the issues raised by the introduction\nof digital technologies and the use of big data and analytics. In medicine, for example, electronic\npatient records (EPRs) are being implemented in hospitals across most developed countries. Critics\nsuch as Greenhalgh et al. (2014) have shown empirically how the software of these EPRs not only\nlimit the categories for diagnosis and description of patients to pre-given databases, even reducing\ndiagnostics to pull-down menus, but also turn expert practitioners into data entry workers. In other\nwords, argue these researchers, such data systems are fundamentally changing clinical work in\nways that were not fully considered before implementation. Meanwhile in the rapidly growing area\nof mhealth (mobile technologies for health care), new technologies such as the RemotoscopeTM\napp, designed to work with anyone's mobile phone to diagnose ear infection at home, are moving\nrapidly from prototype to market. Such products are likely to increase convenience and responsive-\nness of service. But are algorithmically calculated, data-driven diagnostics as reliable and consist-\nent as services performed by human professionals?Available studies are careful in their conclusions.\nFor example, in researching a new algorithm running on mobile technology for managing chil-\ndren's illness in sub-Saharan Africa, Shao et al. (2015) found that it resulted in better identification\nof children with viral infections and an 80% drop in unnecessary prescription of antibiotics \u00ad\noverall, better clinical outcomes than standard practice. However, success depended on the deploy-\nment of the technology by professional clinicians specifically trained to follow its protocols strictly.\nHigher education is another sector that is employing algorithmic analytics to address a host of\nissues. For instance, analytics can be used to determine which students may pose a retention prob-\nlem as the basis for targeted assistance. Students can be assigned a dropout prediction score, which\nis shared with staff who can then monitor student activity and provide resources to keep them\nenrolled (Harris 2014). Educators are becoming interested also in the possibility of improving\nstudent attainment through predictive analytics that match teachers and students, reshuffle student\nwork groups and `recommend', like Amazon, resources and classes to individual students. To help\npredict students' employment paths and suggest suitable curricula, these analytics also are being\nlinked with projected labour skills demands, demographics, aptitude tests and markers of students'\nonline engagement (time spent viewing pages, content highlighted, etc.).\nThis all appears valuable as part of educational interventions, but relies on the validity and reli-\nability of the analytics embedded in the qualculations. Questions are raised when the analysis and\neducational prescription are delegated solely to the decisions made by digital technologies. Any\nstudent data will contain complex mixes of culture, class, sexuality, etc. that, however good the\ndigital technology and analytics, often cannot be registered or can be manipulated or gamed.\nLaurillard (2012) shows that much student data is collected as by-products from other interactions.\nWhile useful, it needs additional interpretation from professional educators. Here is an opportunity,\nLaurillard argues, for educators to collaborate with technology specialists to capture data that will\naddress issues of most educational concern, and to use it to improve specific educational practices.\nIn other words, the production of prediction and the qualculations themselves need re-translation\nthrough professional decision-making in the enactment of practice.\nIn education more broadly, Williamson (2015) draws attention to new phases in the calculation\nand classification of complex matters of learning, pedagogy and context. Educational governance\nin the UK increasingly is being actively displaced to technical centres such as Education DataLab,\nwhich deploys analytics to manipulate masses of data from the National Pupil Database in order to\ngenerate `actionable policy insights'. In particular, Williamson focuses concern on the incorpora-\ntion of citizens and the persuasive, almost seductive, authoritative power of data visualisation\nbeing employed by these technologies. His example is Learning Curve produced by Pearson\nPublishing:\nThe user of the Learning Curve is solicited to perform independent analyses by tweaking variables,\nadjusting statistical weightings, and generating new visualisations. As a result, the user is solicited not\nquite as the consumer figure of school comparison websites cited earlier, but more as a `prosumer' who\ndoes not only consume content but also produces it. ... These logics of `prosumption' elide distinctions\nbetween popular and expert knowledge practices. (Williamson, 2015: 15)\nIn this way, what becomes enacted through digital technologies as governing knowledge in educa-\ntion is presented benignly as co-created fun, scripting its users' involvement and obscuring its\nactual functions in ways that they are not encouraged to examine.\nA comparable range of digital technologies and visualisations are being implemented also to\nsupport `predictive policing'. For example, Motorola's Real-Time Crime Centre Starter Kit links\nwide-ranging data from sources such as sensors, alarms, multiple video systems and computer-\naided dispatch with software analytics. Motorola's representative explains that the technology\n`allows agencies to implement predictive policing tactics and leverage existing technology to pro-\nvide relevant and timely intelligence to improve closure rates, help stop a crime in action and\nproactively identify potential incidents before they occur' (Cipriano, 2014). These sorts of tech-\nnologies increasingly build in public involvement so that citizens can monitor activity in their\nneighbourhoods and feed it into the software for analysis to generate predictions and recommended\nactions. The power of such predictions is one of the questions raised by Mackenzie (2015), as the\ngeneralisations might be said more accurately to produce anticipations over which human judge-\nment still needs to be maintained rather than precise predictions. It is in the collapsing of anticipa-\ntions into predictions that professional responsibility is delegated to digital technologies.\nIn the context of architects and other professionals working with built environments, Jaradat\net al. (2013) document how dramatically professional roles are changing as large integrated data\nsystems are used increasingly to design, construct and maintain buildings. The client is becom-\ning increasingly `professionalised', new conflicts are appearing across professional groups, and\nnew kinds of professional accountabilities are emerging. For example, workflow approvals are\noften delegated to digital mechanisms, while professionals running the projects may bypass the\nfuss and unwieldy structures of uploading the required documents and continue to rely on phone\ncalls and emails to negotiate fast-changing details between engineers, contractors and architects.\nNew specialists dealing with document control and integration are becoming part of the building\ndesign and delivery processes, who may exercise different standards of judgement in assessing\nwork quality than the design professionals. The proliferation of different design professionals \u00ad\narchitects, servicing engineers and so forth \u00ad all mediated by digital technologies, create new\nissues of standardisation and transfer of the digital data and potential for conflict and work\narounds in the practices of qualculation. The handover of digital data can create frustration at a\nsystem's inflexibility, or the errors and misinterpretations that can occur with multiple users\ninteracting with the same data at once.\nDigital technologies are not necessarily digital in the ways that professionals need to be. They\ntend to work from simplistic premises: that problems are technical, comprise knowable, measura-\nble parameters, and can be solved through technical calculation. They rely on practices that enable\nqualculations through a binary logic of generalisation and either/or. Barocas et al. (2013) also show\nthat algorithms reflect what they term `a profound deference to precedent', acting on the past to\nmake decisions regarding the future. Digital technologies work through identifying past patterns\nand cycles of anticipation, which can be self-reinforcing and reproductive, augmenting path\ndependency and entrenching existing practices. They can act as filter bubbles, simply reinforcing\npast patterns of behaviour (Pariser, 2011). Complexities of responsibilities and values, ambiguities\nand tensions, culture and politics and even the context in which data are collected are not necessar-\nily taken into account.\nMany warn that the growth and unexamined nature of these sorts of analytics, as they permeate\nprofessional practice, are creating particular forms of rationality, and potentially new epistemo-\nlogical orders (Kallinikos, 2010; Kitchin, 2014). There are new ethical as well as legal issues when\nprofessional responsibility becomes delegated to algorithms (Barocas et al., 2013; Ruppert et al.,\n2015). `Smart' machines such as diagnostic technologies and robotics are powerful augmenters of\npractice but, as Marcus and Davis (2014) argue in the case of health care, they should supplement,\nnot replace, professional judgements: only human professionals can listen to patients with nuanced\nunderstanding of complexities. Digital technologies do not attune or intuit, and, to date, they are\nnot considered conscious agents that can bear responsibility for decisions.\nBearing this in mind, it is sobering to read about technological developments that are allowing\nincreased delegation of professional decision-making to digital analytics. In human resource man-\nagement for instance, Sullivan (2013) reports that Google is using big data and algorithm-based\ndecisions in its practices: `people analytics' for the twenty-first century. A hiring algorithm is used\nto predict which employees are most likely to succeed after recruitment, both to shorten the total\ninterview time and to ensure that the selection panels do not `miss' top talent: this is `scientific'\nrecruitment. One algorithm targets `diversity problems', analysing root causes of `weak diversity'\nand suggesting solutions. Another algorithm predicts which employees are likely to become a\n`retention problem', alerting management so that pre-emptive action can be taken. These `forward-\nlooking' predictive models use technology-driven processes to identify and address `people man-\nagement' problems and opportunities.\nIn the law profession, Susskind (2013) has tracked the ways technology-driven processes have\nproliferated in legal services, with a corresponding rise of technology-driven entrepreneurs: legal\nknowledge engineers, legal data technologists, risk managers and project managers. Online personal\nlegal services are increasingly common, just as e-services have become more prevalent in many\nprofessions, using software that analyses problems and presents solutions. These `democratising'\ndevelopments have been debated for some time in law journals, where the benefits of affordability\nand convenience are weighed against the concerns about risk, quality, trust and accountability (Cho,\n2006; Figueras, 2013). Susskind predicts a radical reconfiguration of the profession of law, deliv-\nered through diverse internet-based global legal businesses, online document production, virtual\ncourts and online dispute resolution. Segrist (2015) goes further, to argue that big data and predictive\nanalytics are actually changing the responsibility of an attorney.\nAs these sorts of examples show, across professional work in health care, education and many\nother areas, new digital technologies are reframing practices in different ways. Predictive analytics\nare used to assess conditions and prescribe remedies for students or patients or clients, to produce\nclient and professional service records that can be integrated with other data to make decisions, and\nto plan and even automate service provision in areas such as health, social care, education and\npolicing. Some of this is for great benefit, as better and more quickly generated data can assist\nimproved decision-making to enhance practices. However, what we and others are suggesting is\nthat aspects of these trends have implications for professional accountability and responsibility that\nrequire further exploration. The coded objects, infrastructures, processes and assemblages of digi-\ntal technologies participating in reconfiguring professional practices are not simply tools to enhance\npractice, but pose questions as to the nature of future professional work and the values embedded\nin and evidenced by such work.\nHow then should we think about professional responsibility when algorithms are embedded in\nthe production of predictions? How do we understand the professional as a responsible actor when\ncapability is delegated and distributed? What does it mean for professionals to work responsibly\nwith big data sets of varying quality and with reductionist algorithms? What responsibilities do and\nshould professionals have within different regimes of coded accountability and governing? What\npractices of qualculation enhance the value of professional work? Professionalism and profes-\nsional discretion and responsibility are important aspects of professional education. Perhaps we\nneed to rethink how it is enacted in particular digital assemblages, working through particular\ndigitised problems. Then we might reimagine ways for professionals to learn strategies of respon-\nsibility in these different contexts even as their own position is reconfigured in the production of\nthese assemblages.\nEducational implications\nThis article has drawn attention to a number of issues for professional responsibility posed by new\ndigital technologies and analytics that we argue deserve more attention by educators and educa-\ntional researchers. While our purpose is not to provide detailed pedagogical recommendations for\nthese particular issues, even if such recommendations were available in current literature, we do\nwish to suggest educational approaches that might be implied by the foregoing discussion. These\nmay not be new or original suggestions, but we offer them in the spirit of inspiring further thinking,\npractice developments and research around educating professionals for responsibility in work con-\ntexts increasingly reconfigured by new digital technologies, analytics and big data.\nCritically examine new digital analytics being introduced in particular fields and\nhow they influence knowledge and practice\nAs we have indicated in this article, empirical studies are appearing showing the impact of new\ndigital technologies and analytics in different fields of professional work, and what benefits as well\nas problems are occasioned. Students in the professional arenas should be introduced to these.\nThey also might interview experienced practitioners about how these resources are actually being\nused, or examine promotional material for these products. Students can examine and discuss all\nthese critically from the perspective of implications for professional responsibility. What happens\nin practice? To what extent are particular digital analytics foreclosing nuances and complexity that\nare important to professional analysis and problem-solving? What issues of trust, risk and quality\nare raised? What do the practices of qualculation and the production of prediction entail and with\nwhat implications for knowledge, practice and responsibility?\nThe object is to educate new professionals to develop a critical attunement that can see past the\npersuasive apparent `precision' of solutions produced by digital technologies, qualculation and\npredictive analytics, and to question their limitations as well as identify their possibilities. More\nbroadly perhaps, the aim is to prompt students' sense of responsibility to engage with these tech-\nnologies as part of the assemblages of practice, and not just to accept them as black boxes that only\ncomputer specialists can understand.\nLearn more about the effects of computational processes\nStudents in all professions could be encouraged to learn more about computational processes that\nproduce certain forms of knowledge and the logic that structures thinking. `Learning to code' has\nbecome an arena of debate in education more broadly, with some claiming that the challenge for\ncurriculum is to teach students either `to program or be programmed' (Naughton, 2012). The argu-\nment is that it is possible \u00ad even urgent \u00ad to make visible the hidden work of software code by\ndeveloping enhanced computer skills in all students.\nIn much professional education, however, learning to code is not practical: expertise relies on\nspecialism and each professional domain has its own arena of discrete capability. It is also the case\nthat learning to code is considered by some as an inadequate response to the work of digital tech-\nnologies. The developing field of software studies and the work from which we have drawn for this\narticle indicates a far more intricate interplay in coding processes of technical and professional\nissues with sociological, ethical, political and computational questions (e.g. Berry, 2011; Edwards\nto appreciate.\nFor professional practice, it is the capability of the team harnessing different expertise that is\ncentral. However, students within professional education could discuss the effects of digital tech-\nnologies. Who generates the technologies and their outputs? Who should be able to understand the\ncode and big data, and at what level? How are issues of values and ethics translated into lines of\ncode and with what implications? Students also could look more closely at how algorithms built\ninto common software such as Facebook shape the way that they express and represent themselves,\ninteract with others, form preferences, make decisions and become drawn into particular social\ngroups and patterns. As students move into professional work, they could become more attuned to\nmaking the computational work decipherable and more visible in relation to their practices.\nLearn to collaborate with designers\nIn general, as writers cited here such as Laurillard (2012) have argued, it makes more sense for\nprofessionals and student professionals to learn to collaborate with computer scientists than to\ntry to become computer scientists. This is something that our own colleagues have begun to do,\nin our case through a series of workshops involving social scientists, professional educators,\npractising and student professionals, and computer scientists (Code Acts, n.d.). Halford (2015)\nconvenes projects linking social and computer scientists, and argues this is the most important\narea for educational attention. She claims that most disciplines still remain aloof from engaging\nwith computational experts, for all sorts of understandable reasons, including the vast differ-\nences in language, logics, purposes and approaches. This is despite the proliferation of expertise\nand resources among people, the internet and social media (MacKenzie 2015). However, Halford\nargues that until public service professionals learn to collaborate with computer scientists, digi-\ntal technologies may well continue to be designed within the vacuums of technological innova-\ntion for its own sake rather than for the complex contexts of social worlds and responsibilities,\ncontributing to the reductionism that then becomes a focus of critique. Furthermore, collabora-\ntion with coders helps professionals understand the possibilities as well as limitations of qualcu-\nlations, semantic webs and big data, and address explicitly issues of responsibility and\naccountability within these changing knowledge infrastructures. For the computer scientists,\nalthough co-production has been a frequent aspiration in the development of digital technolo-\ngies, the capacity for professionals to have a clear understanding of what is required and how it\ncan be produced and developed is also critical. This requires very different forms of cross-disci-\nplinary curriculum and cross-professional working to those that mostly exist now.\nLearn the issues and capacities needed to integrate new data analytics and\ntechnologies effectively into responsible practice\nExamples cited in this article, such as the inevitable proliferation of online (professional) services\nand machine diagnostics, suggest that professionals need to be pragmatic as well as critical about\nthese new technologies. In other words, practitioners need to decide when and how to embrace\nthem. Embracing means neither accepting and using new technologies without question, nor stand-\ning aside and allowing `smart' machines to get on with it. As with the example of new mobile-\nbased algorithms for health care, the responsible use of these technologies relies upon trained\nprofessionals.\nFurthermore, as the example provided by Jaradat et al. (2013) showed, the new forms of big data\nbeing introduced into professional work demand new systems for transferring data between clients,\noperators and various groups of practitioners. The recommendation from Jaradat et al. (2013) is that\nprofessionals need to understand the potential points for error or misinterpretation at various inter-\nfaces in this data integration, as different forms of data and different purposes for interpreting it must\nbe reconciled. Professionals also need to assume accountability themselves for examining these\npoints in order to better manage data flows and critically examine the issues in meanings, metrics\nand ethics that arise. In order to do this, professionals who may not ordinarily work directly with\ndata systems need to understand more about data itself and how these systems work, the translations\nof qualculation and production of predictions, and how to link with other professionals and institu-\ntions to integrate practices responsibly using this data across professional roles.\nExplicitly debate the implications of new digital technologies for professional\nresponsibilities and accountabilities\nThese questions about the potential expansion of professional responsibility to critically interfere\nwith and more actively engage with digital technologies and analytics raises the broader issue of\nprofessionalism and accountability in this realm. How should we think about professional respon-\nsibility when algorithms produce predictions and make decisions? How do we understand the\nprofessional as a responsible agent when capability is distributed? What does it mean for profes-\nsionals to work responsibly with `dirty' big data sets and generalising algorithms? What forms of\nresponsiveness are appropriate to the messiness of practices enmeshed within the binary code of\nsoftware? Professionalism is an important aspect of professional education: we need to rethink\nhow it is enacted through its entanglement with digital technologies. Then we might encourage\nnew professionals to reimagine principles and pragmatics of responsibility, to develop purposes\nand learn strategies for using digital technologies thoughtfully and responsibly in these brave new\nworlds. Their promise might be of more accurate, consistent and clear analytics to reduce complex-\nity and improve decision-making. However, while the complexity, responsibilities and accounta-\nbilities may be reconfigured, we would question if they are simply reduced. Digital analytics and\ntechnologies are increasingly powerful and sophisticated actors in professional practices that are,\nas in the industrial revolution of the nineteenth century, transforming work knowledge, divisions\nof labour and work identities. However, they also bring opportunities for different forms of profes-\nsionalism. They do not negate professional responsibilities and accountabilities, providing simple\ntechnical solutions to complex social issues. They do highlight the need for a more informed debate\nin professional education surrounding digital technologies and professional responsibility, one to\nwhich we hope this article is a small contribution.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication\nof this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or publica-\ntion of this article: This article is developed from work within the ESRC-funded seminar series Code Acts in\nEducation http://codeactsineducation.wordpress.com/about/ (grant reference: ES/L001160/1).\nReferences\nBarocas S, Hood S and Ziewitz M (2013) Governing algorithms: A provocation piece. Paper prepared for the\nGoverning Algorithms conference, New York University, May 16\u00ad17.\nBerry D (2011) The Philosophy of Software: Code and Mediation in the Digital Age. Basingstoke: Palgrave\nMacmillan.\nBiesta G (2006) Beyond Learning: Democratic Education for a Human Future. Boulder: Paradigm Publishers.\nBuckingham Shum S (2015) Learning analytics: On silver bullets and white rabbits. Medium (9 Feb.).\nAvailable at: https://medium.com/@sbskmi/learning-analytics-on-silver-bullets-and-white-rabbits-\nCallon M and Law J (2005) On qualculation, agency, and otherness. Environment and Planning D: Society\nCho V (2006) A study of the roles of trust and risk in information oriented online legal services using an\nCipriano M (2014) Crime centre kit boosts predictive policing capabilities. GCN: Technology, Tools and\nTactics for Public Sector IT, 28 March. Available at: http://gcn.com/articles/2014/03/28/predictive-\npolicing-starter-kit.aspx?admgarea=TC_BigData&m=2.\nCode Acts (n.d.) Code acts in education: Learning through code/learning to code. Economic and Social\nResearch Council-funded seminar series and blog, University of Stirling 2014\u00ad15. Available at: https://\ncodeactsineducation.wordpress.com/about/.\nColley H, James D and Diment H (2007) Unbecoming teachers: Towards a more dynamic notion of profes-\nEdwards P (2010) A Vast Machine: Computer Models, Climate Data, and the Politics Of Global Warming.\nCambridge, MA: MIT Press.\nEdwards P, Jackson S, Chalmers M, et al. (2013) Knowledge Infrastructures: Intellectual Frameworks and\nResearch Challenges. Ann Arbor, MI: Deep Blue.\nFenwick T (2016) Professionalism and Professional Responsibility: A Sociomaterial Examination. London:\nRoutledge.\nFenwick T, Manguez E and Ozga J (eds) (2014) Governing Knowledge: Comparison, Knowledge-based\nTechnologies and Expertise in the Regulation of Education. London: Routledge.\nFigueras I (2013) The LegalZoom identity crisis: Legal form provider or lawyer in sheep's clothing? Case\nFreidson F (2001) Professionalism: The Third Logic. Cambridge: Polity Press.\nGibbs R (2000) Why Ethics? Signs of Responsibility. Princeton, NJ: Princeton University Press.\nGreenhalgh T, Stones R and Swinglehurst T (2014) Choose and book: A sociological analysis of `resistance'\nHalford S (2015) Decoding code: A critical politics of the semantic web as an opportunity for inter-profes-\nsional learning. Presentation to Code Acts in Education ESRC seminar series, University of Stirling,\nFebruary.\nHalford S, Pope C and Weal M (2012) Digital futures? Sociological challenges and opportunities in the emer-\nHarris C (2014) Big data means big results in higher education. Tech Page One, 13 May. Available at: http://\ntechpageone.co.uk/en/technology/big-data-means-big-results-in-higher-education/.\nJaradat S, Whyte J and Luck R (2013) Professionalism in digitally mediated project work. Building Research\nKallinikos J (2010) Governing Through Technology: Information Artefacts and Social Practice. London:\nPalgrave.\nKitchin R (2014) The Data Revolution: Big Data, Open Data, Data Infrastructures and Their Consequences.\nLondon: Sage.\nKitchin R and Dodge M (2011) Code/Space: Software and Everyday Life. Cambridge, MA: MIT Press.\nLaurillard D (2012) Teaching as a Design Science: Building Pedagogical Patterns for Learning and\nTechnology. London: Routledge.\nLawn M (ed.) (2013) The Rise of Data in Education Systems: Collection, Visualisation and Use. Oxford:\nSymposium.\nLevinas E (1981) Otherwise Than Being Or Beyond Essence. The Hague: Martinus Nijhoff.\nMacKenzie A (2015) The production of prediction: What does machine learning want? European Journal of\nManovich L (2013) Software Takes Command: Extending the Language of New Media. London: Bloomsbury\nAcademic.\nMarcus G and Davis, E (2014) Eight (no, nine!) problems with big data. New York Times, 7 April, A23.\nAvailable at: http://www.nytimes.com/2014/04/07/opinion/eight-no-nine-problems-with-big-data.\nhtml?_r=2.\nMay L (1996) The Socially Responsive Self. Social Theory and Professional Ethics. Chicago: University of\nChicago Press.\nNaughton J (2012) From Gutenberg to Zuckerberg: What You Really Need to Know About the Internet.\nLondon: Quercus.\nPariser E (2011) The Filter Bubble: What the Internet is Hiding From You. London: Viking.\nRobinson S (2009) The nature of responsibility in a professional setting. Journal of Business Ethics 88: 11\u00ad19.\nRobson K (1992) Accounting numbers as `inscription': Action at a distance and the development of account-\nRuppert E, Harvey P, Lury C, et al. (2015) Socialising Big Data: From Concept to Practice. CRESC Working\nPaper Series, Working Paper No. 138, the University of Manchester and Open University. Available at:\nhttp://www2.warwick.ac.uk/fac/cross_fac/cim/research/socialising-big-data/sbd_wp_2015.pdf.\nSegrist P (2015) How the rise of big data and predictive analytics are changing the attorney's duty of compe-\nShao AF, Rambaud-Althaus C, Samaka J, et al. (2015) New algorithm for managing childhood illness using\nmobile technology (ALMANACH): A controlled non-inferiority study on clinical outcome and antibi-\nSolbrekke T (2008) Professional responsibility as legitimate compromises: From communities of education\nSolbrekke T and Sugrue C (2010) Professional responsibility: Retrospect and prospect. In: T Solbrekke and\nC Sugrue (eds) Professional Responsibility: New Horizons of Practice? London: Routledge, 11\u00ad28.\nSolbrekke T D and Sugrue C (2014) Professional accreditation of initial teacher education programmes:\nTeacher educators' strategies \u00ad between `accountability' and `responsibility'. Teaching and Teacher\nStronach I, Corbin B, McNamara O, et al. (2002) Towards an uncertain politics of professionalism: Teacher\nSullivan J (2013) How Google is using people analytics to completely reinvent HR. TLNT: The Business of\nto-completely-reinvent-hr/.\nSusskind R (2013) Tomorrow's Lawyers: An Introduction to Your Future. Oxford: Oxford University Press.\nWilliamson B (2015) Digital education governance: Data visualisation, predictive analytics and `real-time'\nAuthor biographies\nTara Fenwick is Professor of Professional Education and Director of ProPEL (research in professional prac-\ntice, education and learning) at the School of Education, University of Stirling. Her most recent books include\nProfessional Responsibility and Professionalism: A Sociomaterial Examination (Routledge forthcoming) and\nReconceptualising Professional Learning (with M. Nerland, Routledge 2014).\nRichard Edwards is Professor of Education at the School of Education, University of Stirling, who has pub-\nlished extensively in educational theory, globalization and lifelong learning. His current research focuses on\nchanging knowledge infrastructures, informal learning, citizen science, and the effects of digitization."
}