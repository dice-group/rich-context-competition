{
    "abstract": "Abstract\nThe Partnership Questionnaire (PFB) is used favorably in the German language area to measure partnership quality. The goal of\nthe present study is to re-analyze the subscales of the PFB (Conflict Behavior, Tenderness, Communication) via the Rasch model.\nPolytomous and dichotomous Rasch models were calculated in a population sample (N = 1,123) and a student-based cross-\nvalidation sample (N = 250) for the three subscales of the PFB. Final models were chosen based on several fit criteria. Good\nto very good model fit was obtained with symmetrical (Conflict Behavior) or nonsymmetrical (Tenderness, Communication)\ndichotomously collapsed categories. After adapting the instruction and dichotomizing the categories, the PFB can be used as\na checklist (PFB-checklist). An additional cross-validation is needed to substantiate the obtained results.\n",
    "reduced_content": "sgo.sagepub.com\nCreative Commons CC BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access page (http://www.uk.sagepub.com/aboutus/openaccess.htm).\nArticle\nA considerable amount of research has focused on under-\nstanding what factors predict partnership satisfaction and\ndissolution (for reviews, see Amato, 2010; Bradbury,\nFincham, & Beach, 2000; Hahlweg, Baucom, Grawe-Gerber,\n& Snyder, 2009). A happy relationship influences general\nlife satisfaction, health, and well-being positively in many\nways (Holt-Lunstad, Birmingham, & Jones, 2008; Kiecolt-\nGlaser & Newton, 2001). On the contrary, a disharmonic\nrelationship influences the life situation of both partners neg-\natively, especially concerning physical and psychological\nhealth (e.g., Kiecolt-Glaser & Newton, 2001; Whisman,\n2007, for a review). Furthermore, relationship distress can\nimpact treatment response for a variety of individual disor-\n& Clements, 2012). Accordingly, relationship distress, its\nantecedents, and consequences have been an active area of\nThe Partnership Questionnaire (PFB) developed by\ncommonly used in Europe as a measure of relationship or\nmarriage quality, that is, the subjective evaluation of one's\nrelationship/marriage, and has been translated into nine lan-\nguages (English, Dutch, Afrikaans, French, Italian, South\nAfrica English, Spanish, Chinese, Maleyish). In addition, a\nshort form of the PFB, the PFB-K, has recently been devel-\noped and evaluated (Kliem, K\u00f6rger, et al., 2012). Other\ninstruments commonly used to gather information about\nrelationship quality include the Marital Adjustment Test\n(MAT; Locke & Wallace, 1959), the Dyadic Adjustment\nScale (DAS; Spanier, 1976), and the Marital Satisfaction\nInventory (MSI; Snyder, 1981). Partnership quality, as mea-\nsured via the PFB, can be seen as comparable with the other\nmentioned instruments. For example, the PFB total score\ncorrelates highly with the sum scores of the DAS (Spanier,\nRigozzi, Charvoz, & Bodenmann, 2006). Although the MAT,\nDAS, MSI, as well as other psychometric instruments have\nbeen re-analyzed using item-response-theory, and despite\nthat relationship distress is an important problem in German-\nspeaking countries (DESTATIS, 2010), no study up to date\nhas evaluated whether the PFB, which is favorably used in\nGerman-speaking countries, conforms to the assumptions of\nItem Response Theory (IRT) (e.g., Funk & Rogge, 2007;\nBut why is it important to evaluate clinical instruments\nvia IRT? IRT has several potential advantages over classical\ntest theory, for example, by potentially giving invariant esti-\nmates and providing advanced reliability information. First,\n1Criminological Research Institute of Lower Saxony, Germany\n2Technical University of Braunschweig, Germany\n3Zittau/G\u00f6rlitz University of applied sciences\n4University of Leipzig, Germany\nCorresponding Author:\nS\u00f6ren Kliem, Criminological Research Institute of Lower Saxony\nEmail: Soeren.Kliem@kfn.de\nA Rasch Re-Analysis of the Partnership\nQuestionnaire\nS\u00f6ren Kliem1, Johannes Beller2, Christoph Kr\u00f6ger2,\nYve St\u00f6bel-Richter3, Kurt Hahlweg2, and Elmar Br\u00e4hler4\n Keywords\nPartnership Questionnaire (PFB), relationship satisfaction, Rasch model, item response theory, family psychology\n2 SAGE Open\nvia IRT, one can obtain so-called invariant item and latent\ntrait estimates. In classical test theory, the item means are\ndependent on the sample. If a researcher samples very satis-\nfied participants, means on items assessing dissatisfaction\nwill be lower than if he had sampled dissatisfied participants.\nWithin sampling error, the estimates of a fitting IRT model\nshould be the same (within a linear transformation;\nEmbretson, 1996). Second, by using IRT models more pre-\ncise measurements can be obtained. For example, via the\nRasch model, it is possible to obtain detailed information\nregarding the precision of measurement (or reliability) of the\nscales. Whereas in classical test theory, only global measures\nof reliability are available, the Rasch model provides the\nresearcher with the possibility to calculate precision of mea-\nsurement statistics depending on the position on the latent\ncontinuum (see, for example, Embretson & Reise, 2000).\nThis possibility is especially useful to decide which purpose\nthe instrument might be used for. One could argue, for exam-\nple, that a screening instrument should be able to discrimi-\nnate extreme from nonextreme values on the latent continuum\n(maximum reliability in very high parts of the latent contin-\nuum) because it should adequately identify the at-risk popu-\nlation. An instrument used for the evaluation of therapy\ninterventions, on the other hand, should detect changes most\nreliably in the middle and upper part of the latent continuum,\nbecause it should adequately reflect changes in the burden of\npatients. In addition, by analyzing the precision of measure-\nment for specific items, one can determine which items best\ndiscriminate on what position on the latent trait. This infor-\nmation could be beneficially used for constructing short\nscales. For example, using this information, one could strate-\ngically select items to capture the whole latent dimension as\nefficiently as possible or concentrate on specific parts when\ndeveloping questionnaires for specific populations. Without\nspecific reliability measures, one cannot obtain this impor-\ntant information (for a comprehensive introduction into IRT\nsee, for example, Embretson & Reise, 2000). Thus, it seems\nimportant to analyze clinical instruments via IRT.\nThe goal of the present study is to evaluate whether the\nwidely used PFB, which was constructed by means of\nClassical Test Theory, could conform to the requirements of\nthe Rasch model. Finding that the PFB conforms to the\nRasch model would have important implications regarding,\nfor example, the preciseness of the measurement of partner-\nship quality and could thus be important in practical and\ntheoretical applications. However, to the knowledge of the\nauthors, this analysis has not been conducted before.\nAlthough other recent studies have evaluated relationship\ndistress measures with IRT, these studies have all been con-\nducted in the United States with English versions and are not\nnecessarily translatable to other cultures and languages\nFunk & Rogge, 2007). However, statistics show that rela-\ntionship distress represents a widespread phenomenon in\nGerman-speaking countries as well (DESTATIS, 2010). As\nthe PFB is the most commonly used measure of partnership\nsatisfaction in German-speaking countries, an evaluation of\nthe PFB is needed. To fill this gap, we examine whether the\nPFB is Rasch scalable in a representative sample for the\nGerman population. Toward this end, we first determine an\noptimal response format for the PFB. Using this response\nformat, we examine whether the Rasch model fits the PFB.\nLast, we cross-validate all results via a German student-\nbased sample.\nMethod\nMeasures\nPFB. The PFB consists of the three subscales Conflict Behav-\nior, behavior shown during a conflict that does not further\nthe solution of the conflict (e.g., \"When we quarrel he or she\nkeeps taunting me\"); Tenderness, all activities that include\nphysical contact (e.g., \"He or she caresses me tenderly\"); and\nCommunication, communicative activities that are done by\nboth partners and show their closeness (e.g., \"We talk to each\nother for at least half an hour every day\"). Each subscale\ncontains 10 items with a four-point response format\n(never/very seldom, seldom, often, very often). A value of 0\nto 3 points can be matched to each item, depending on the\nselected answer. Furthermore, a so-called \"Happiness-item\"\n(\"How happy would you consider your relationship?\") based\non the rating scale from 0 (very unhappy) to 5 (very happy)\nby Terman, Buttenwieser, Ferguson, Johnson, and Wilson\n(1938) is added to the PFB similar to other widely used mari-\ntal distress scales (e.g., DAS; Spanier, 1976). Using a sample\nrepresentative for the population of Germany (Hinz et al.,\n2001), good to very good reliability coefficients were con-\nfirmed for the three subscales (Conflict Behavior:  = .88;\nTenderness:  = .91; Communication:  = .85; Total Scale: \n= .93). In addition, the factorial validity of the PFB has been\nconfirmed via exploratory and confirmatory factor analyses\n(see, for example, Kliem, Kr\u00f6ger, St\u00f6bel-Richter, Hahlweg,\nParticipants\nPopulation sample. In the year 1999, an independent polling\nand 50 years on behalf of the University of Leipzig. Partici-\npants were chosen from households, which were selected\nfollowing a random-route procedure based on the constitu-\nencies of the federal elections. Following this, one partici-\npant was chosen randomly from each of the selected\nhouseholds and interviewed at home. The response rate\namong those contacted was approximately 68% (for further\ndetails, see Hinz et al., 2001). The data collection was done\nin accordance with German procedures for human subject\nparticipation and data privacy laws (e.g., voluntary partici-\npation and deletion of identifying information). For the\nKliem et al. 3\npresent study, people who were currently in a relationship\n(N = 1,344) and who had completed the PFB were eligible\nfor analysis (N = 1,123 participants). Of all the participants,\ntheir own. The participant's mean age was 36.7 years (stan-\ndard deviation [SD] = 8.3 years). The average duration of\nthe current relationships was 12.8 years (SD = 8.4 years).\nThe following total score means and SDs of the PFB for the\nsubscales were found in the population sample: Communi-\nConflict Behavior: M = 23.4, SD = 5.2. Furthermore, good\nto very good reliability coefficients could be confirmed for\nall subscales: Communication:  = .85; Tenderness:  = .90;\nConflict Behavior:  = .88. The average satisfaction with the\nrelationship was estimated through the \"Happiness-item,\"\nresulting in an average value of 4.8 (SD = 1.1), which cor-\nresponds to a happy relationship.\nStudent-based sample.Data for the cross-validation sample\nwere obtained in an annual seminar about test construction\nfor students of psychology at the Technical University of\nBraunschweig. The collection of data took place as an assign-\nment in the seminar, with approximately 50 to 70 students\ncompleting the PFB themselves as well as collecting data\nfrom two additional people. A collection of data for the PFB\nis available from seminars taking place in the summer semes-\nsurveyed; 277 participants reported being in a relationship\nand were eligible for the present study. Out of those, n = 250\npeople had filled out the PFB completely. Of all the partici-\nchild of their own. The participant's mean age in the student-\ning total values for each subscale were found in the\ncross-validation sample: Communication: M = 20.8, SD =\n21.9, SD = 6.2. Similar to the population sample, reliability\ncoefficients in the cross-validation sample ranged from good\nto very good: Communication:  = .85; Tenderness:  = .90;\nConflict Behavior:  = .90. The average satisfaction with the\nrelationship was 5.09 (SD = 1.0), which indicates a happy\nrelationship.\nStatistical Analysis\nSeveral different Rasch models with varying response for-\nmats were calculated. First, a Rasch model with the original\nresponse categories never/very seldom, seldom, often, and\nvery often was calculated. To examine whether the potential\nmisfit of the previously calculated Rasch model might be due\nto the response format, we examined whether a dichotomous\nresponse format might better fit the response patterns of par-\nticipants and might thus provide additional psychometric\nquality for relationship measurement. Thus, in addition to the\nRasch model with the original response categories, three\ndichotomous Rasch models were calculated (\"Collapsing\ndichotomization of the categories was symmetrical\n([never/very seldom, seldom] vs. [often, very often]) or asym-\nmetrical ([never/very seldom] vs. [seldom, often, very often]\nand [never/very seldom, seldom, often] vs. [very often]).\nThen, inter alia,Akaike's information criterion (AIC;Akaike,\n1973) and area under curves (AUCs) were determined via\nreceiver operating characteristics (ROC) analysis. AIC is an\ninformation criterion that quantifies the relative fit of the\nmodel to the data, with smaller AIC values denoting better\nfit. AUC is also a measure of model fit (Mair, Reise, &\nBentler, 2008). However, calculating AUCs is only possible\nfor the dichotomous Rasch model. AUC values between .7\nand .8 denote acceptable fit, values between .8 and .9 denote\ngood fit, and values above .9 denote very good model fit\n(Hosmer & Lemeshow, 2000). The final model with either\nthe original or a dichotomous response format was selected\nbased on several fit criteria (Lopez, 1996; for an example,\nAfter the selection of an optimal response format, depar-\ntures from the Rasch model could principally either occur\ndue to the persons (e.g., younger participants value sexual\naspects higher in a relationship than older participants) or\nbecause of the items (e.g., the items measure different con-\nstructs). Thus, the applicability of the Rasch model for the\nPFB was checked via the conditional likelihood-ratio tests,\nwhich test for misfit because of person heterogeneity, and the\nMartin-L\u00f6f test, which tests for misfit due to item heteroge-\ntests split the whole sample in subgroups according to a spe-\ncific split criterion. Generally speaking, it is then tested\nwhether characteristics of the persons (likelihood-ratio test)\nor the items (Martin-L\u00f6f test) are comparable across the sub-\ngroups, which should be the case if the Rasch model fits.\nRegarding the conditional likelihood-ratio test raw score,\nrandom split, sex, and age were used as split criteria for the\nsubgroups. Regarding the Martin-L\u00f6f tests, raw score and\nrandom split were chosen as split criteria. If significant\ndepartures from the model assumptions were found, some of\nthe items might not be scalable according to the Rasch model.\nThus, to identify the items that evoked the misfit, Wald tests\nwere additionally calculated. Because of the large sample\nsize, even negligible small departures from the model\nassumptions might evoke significant model misfit. Thus,\ngraphical model tests were conducted as well to take the\neffect size of the violations into account. Items were removed\nif Wald tests and the graphical model tests consistently iden-\ntified items as misfitting. If an instrument conforms to the\nRasch model and the correlation between the raw scores and\nthe person parameters is high enough, the individual items\nmight be collectively averaged and analyzed via the usual\nmethods of statistical inference (see, for example, Bond &\nFox, 2001). Contrary to everyday practice, these actions can-\nnot be justified by classical test theory.\n4 SAGE Open\nStatistical power plays a special role in Rasch analysis\nbecause a test cannot validate model fit. Thus, it might only\nshow departures from model fit (model fit is the null hypoth-\nesis). Even if the sample size in this study might be regarded\nas large, the literature still lacks a grounded concept of power\ncalculation in Rasch analysis. In this study, a conservative\nalpha of 5% is chosen, because an alpha of, for example,\n10% would increase the risk of a Type 2 error disproportion-\nately. To correct for multiple tests of model fit, the obtained\np values will be corrected via the Bonferroni procedure and\nwill be denoted as p*.\nItem difficulties based on the Rasch model. To analyze the item\ndifficulties, we calculated person-item maps. These person-\nitem maps display the item location parameters together with\nthe person parameters on the same scale. Difficult items, in\nwhich participants have to have a high person parameter to\nhave a probable chance to solve the item, are found on the\nright. Thus, via the person-item maps, it is possible to also\ngauge the reliability of the scale in relation to the latent\nposition.\nReliability based on the Rasch model.In Rasch analysis, the\nreliability of measurement depends on the position of the\nlatent continuum one considers. We will therefore calculate\nthe reliability of measurement with asymptotic 95% confi-\ndence intervals for all relevant raw scores (1, . . .,10). High\nreliability corresponds to a small confidence interval around\nthe sum score. In addition, Andrich's (1988) reliability\n(RelAndrich's\n), a global Rasch reliability measure, was calcu-\nlated, which is interpreted the same as Cronbach's alpha.\nHere, the variance of the weighted person parameters is cal-\nculated in relation to the expected standard errors of predic-\ntion of all person parameters.\nAll analyses were conducted with the freely available sta-\ntistics software R (Version 2.13.0, R Development Core\nTeam, 2011). The eRm Package (Extended Rasch modeling),\nwas used to calculate the Rasch models.\nResults\nComparison of the Categorization Variants\nTo fully explore the potential Rasch scalability of the PFB,\nwe first compared several categorization variants. Table 1\ncontains the fit criteria for the different categorization\nvariants.\nThe results for the polytomous Rasch model suggest\nsevere model departures for all three subscales. In case of the\nsubscale Conflict Behavior, very good model fit was obtained\nfor two dichotomizations. Whereas the AUC favors a sym-\nmetrical dichotomization ([never/very seldom, seldom] vs.\n[often, very often]), the AIC suggests a nonsymmetrical\ndichotomization as the best-fitting model ([never/very sel-\ndom, seldom, often] vs. [very often]). The reason for this dis-\nagreement might be the so-called \"variance-bias-dilemma,\"\nthat is, the phenomenon that observed variance in the data\ncannot easily be distinguished from bias because of ill-fitting\nmodels (Rosenberg et al., 2003). Consequently, the AIC may\nnot be able to distinguish between ill-fitting models with low\nvariance (e.g., a falsely collapsed scale where most partici-\npants have a specific value like \"happy\") and good fitting\nmodels with high variance (e.g., a correctly collapsed scale\nin which the participants are evenly distributed between cat-\negories). Thus, the nonsymmetrical dichotomization might\nhave been favored by theAIC because of a lack of substantial\nvariance in the data. Figures 1 to 3 depict the raw-score box-\nplots after the different dichotomizations and seconds the\nsuspicion of the occurrence of the variance-bias dilemma.\nBecause a psychometric instrument with minimal variance,\nas indicated in Figure 1, may lack the diagnostic ability\nneeded to fulfill its purpose, we chose the symmetrical\ndichotomization as the final model for the Conflict Behavior\nsubscale.\nTable 1. Comparison of the Different Rasch Model Conceptualizations Via Model Tests and Fit Indices.\nModel\nCommunication:\nSignificant model\ntests\nCommunication:\nAUC\nCommunication:\nAIC\nConflict\nBehavior:\nSignificant\nmodel tests\nConflict\nBehavior:\nAUC\nConflict\nBehavior:\nAIC\nTenderness:\nSignificant\nmodel tests\nTenderness:\nAUC\nTenderness:\nAIC\nPolytomous\nRasch model\n3 Cannot be\ncalculated\ncalculated\ncalculated\nBalanced\ndichotomization\nUnbalanced\ndichotomization\nUnbalanced\ndichotomization\nNote. AUC = area under curve; AIC = Akaike's information criterion.\nKliem et al. 5\nRegarding the subscale Tenderness, the model fit criteria\nindicated good model fit for a nonsymmetrical dichotomiza-\ntion ([never/very seldom, seldom, often] vs. [very often]).\nAlthough the AIC suggested a symmetrical dichotomization\nagain, the boxplots depicted in Figure 2 indicate the occur-\nrence of the aforementioned variance-bias dilemma, so that\nthe nonsymmetrical dichotomization was chosen as the final\nmodel.\nIn case of the subscale Communication, contradictory\nresults emerged as well. Whereas the AIC suggested a non-\nsymmetrical dichotomization in ([never/very seldom] vs.\n[seldom, often, very often]), the boxplots depicted in Figure 3\nindicate an occurrence of the variance-bias dilemma. Thus,\nthe dichotomization ([never/very seldom, seldom, often] vs.\n[very often]) was preferred, and dichotomous categorization\nvariants were preferred over the regular response scale of the\nPFB for all three subscales.\nRasch Model Fit\nTo examine the model fit of the previously selected dichoto-\nmous Rasch models, we calculated several fit criteria\nFigure 1. Comparison of the boxplots depicting the sum scores of the scale Conflict Behavior of the PFB regarding a symmetric (left)\nand a nonsymmetric dichotomization (right; [never/very seldom, seldom, often] vs. [very often]) of the response formats.\nNote. PFB = Partnership Questionnaire.\nFigure 3. Comparison of the boxplots depicting the sum scores of the scale Communication of the PFB regarding a nonsymmetric\ndichotomization (left; [never/very seldom, seldom, often] vs. [very often]) and a second nonsymmetric dichotomization (right; [never/very\nseldom] vs. [seldom, often, very often]) of the response formats.\nNote. PFB = Partnership Questionnaire.\nFigure 2. Comparison of the boxplots depicting the sum scores of the scale Tenderness of the PFB regarding a nonsymmetric\ndichotomization (left; [never/very seldom, seldom, often] vs. [very often]) and a second nonsymmetric dichotomization (right; [never/very\nseldom] vs. [seldom, often, very often]) of the response formats.\nNote. PFB = Partnership Questionnaire.\n6 SAGE Open\nTable 2. Wald Tests for the Scale Communication.\nItem\nMedian-split Random-split Sex Age\nz p* z p* z p* z p*\nWhen he or she talks about his or her work, he or she wants to hear\nmy opinion\nHe or she makes an effort to be attentive to my wishes and fulfills them\nwhen the opportunity arises\nWhen he or she has clearly treated me wrongly, he or she later\napologizes to me\nWe usually spend at least half an hour talking to each other in the\nevening\nNote: p* = alpha-adjusted significance level.\nregarding the three subscales of the PFB. Regarding person\nhomogeneity for the subscale Communication, no significant\ndepartures from model assumptions emerged for the split cri-\n= .090). The likelihood-ratio test concerning the split crite-\n.017). Concerning the item homogeneity, the Martin-L\u00f6f\ntests indicated one significant departure from model assump-\np* < .001) but no further violation of model assumptions for\nfurther investigate the adequacy of the subscale, Wald tests\nwere computed (Table 2). Only Item 29 was significant (\"He\nor she tells me, that he or she likes me\"). The graphical model\ntest also suggested the exclusion of this item (see Figure 4).\nAfter eliminating Item 29, the cross-validation sample\nshowed no significant model departures regarding person\ncollapsed Communication scale of the PFB conformed to the\nassumptions of the Rasch model.\nThe subscale Conflict Behavior conformed to the Rasch\nmodel. No test was significant regarding person homogene-\nit was not possible to calculate a median split of the raw\nscore because of the response patterns. Tests for item homo-\ngeneity led to no reason for concern (raw score: 2 = 25.84,\n.757). The Wald tests and graphical model tests indicated no\nmodel misfit. The results in the cross-validation sample for\nmodel violation. Thus, the collapsed Conflict Behavior scale\nof the PFB conformed to the assumptions of the Rasch model\nwithout further modification.\nFor the subscale Tenderness, the model tests indicated\nmodel conformity in the representative sample (raw score: 2\n9, p* = .999). Testing item homogeneity via the Martin-L\u00f6f\ntests indicated no model violation either (raw score: 2 =\np* = .271). The Wald tests resulted in no significant model\ndepartures on item level. The graphical model tests con-\nfirmed the results of the Wald tests. The results of the cross-\nvalidation sample seconded the results of our main sample;\nno significant departures from model fit were found regard-\ning person homogeneity (raw score: 2 = 19.7, df = 9, p* =\nscale of the PFB conformed to the assumptions of the Rasch\nmodel without further modification.\nItem Difficulties Based on the Rasch Model\nTo examine the reliability of the PFB in the general popula-\ntion sample across the latent dimension, we inter alia calcu-\nlated person-item maps, which show the distribution of the\nKliem et al. 7\nitem parameters together with the distribution of the person\nparameters. Figure 5 shows the person-item maps for the\nthree subscales of the PFB. In general, it is desired that the\ndifficulties of the items (lower part of Figure 5) span approx-\nimately the same positions on the latent trait as the person\nparameters (upper part of Figure 5). Regarding the subscale\nCommunication, Item 19 (\"When he or she has clearly\ntreated me wrongly, he or she later apologizes to me\") had\nthe highest and Item 10 the lowest item difficulty (\"We make\nplans together for the future\"). Of all participants, 290\n(25.8%) answered all items of the Communication scale with\noften or very often; only 20 (1.7%) participants answered all\nitems with very seldom or seldom.\nWith respect to the subscale Tenderness, Item 27 had the\nhighest (\"He or she talks to me about his or her sexual\ndesires\") and Item 23 (\"He or she hugs me\") the lowest item\nparameter. Three hundred fifty persons (31.2%) responded to\nthe items of the scale Tenderness with often or very often, 42\npersons (3.7%) with very seldom or seldom.\nThe analysis of the subscale Conflict Behavior showed\nthat Item 1 (\"He or she keeps bringing up mistakes that I have\nmade in the past\"), marginally followed by Item 18 (\"He or\nFigure 4. Graphical model tests for the subscale Communication.\nNote. PFB = Partnership Questionnaire.\nFigure 5. Person-item maps for the three subscales of the PFB.\nNote. PFB = Partnership Questionnaire.\n8 SAGE Open\nFigure 6. Reliability of the dichotomized Similarity scale of the PFB, depending on the position of the latent trait.\nNote. The error bars represent the standard error of the latent dimension estimate. PFB = Partnership Questionnaire.\nshe makes derogatory remarks about my opinions\"), had the\nhighest difficulty and Item 22 (\"He or she blames me when\nsomething goes wrong\") the lowest item parameter. Only 5\npersons (0.4%) answered all items of the subscale with often\nor very often; 611 persons (54.4%) rated the items with very\nseldom or seldom (the scale is coded negatively). Thus, the\nitem difficulties mapped very well to the general population\nsample, although the items of every subscale seemed to con-\ncentrate in the middle part of the latent continuum.\nThe reliability of the sum scores depending on the posi-\ntion of the latent trait is depicted in Figures 6 to 8. Figures 6\nto 8 show which range of the latent continuum corresponds\nto the observed sum scores on the dichotomized Rasch scale.\nAs one can see in Figures 6 to 8, the latent constructs covary\nalmost linearly with the observed sum scores. The resulting\nhigh correlation of latent person parameters with observed\nsum scores (Communication: r = .97, Tenderness: r = .98,\nConflict Behavior: r = .96) indicates that the scale quality\nmight be judged as interval or metric, in the sense that\ndifferences in the latent dimension correspond to differences\nin the observed sum scores. All scales show the highest reli-\nability (i.e., the standard errors around the estimates are\nsmallest) in the middle part of the latent continuum. For\nexample, an observed sum score of 5 on the similarity scale\nmight correspond to a latent score of roughly -0.5 to +1, but\nan observed score of 8 might correspond to +1 to +3.5 on the\nlatent dimension. Thus, measuring similarity in the extremes\nnearly doubles the uncertainty of the estimate. Regarding the\noverall reliability, the Rasch reliability coefficients indicated\na good to very good reliability of all three scales\n(Communication: RelAndrich's\n= .86; Tenderness: RelAndrich's\n=\n.89; Conflict Behavior: Rel\nAndrich's\nDiscussion\nThe present article re-analyzed the subscales of the PFB,\nreviewing their compliance with the requirements of the\nRasch model. An analysis on the basis of the 4-point\nFigure 7. Reliability of the dichotomized Tenderness scale of the PFB, depending on the position of the latent trait.\nNote. The error bars represent the standard error of the latent dimension estimate. PFB = Partnership Questionnaire.\nKliem et al. 9\nLikert-type scales (never/very seldom, seldom, often, very\noften) in a series of tests for different model fits showed devi-\nations from the requirements of the Rasch model. After\ndichotomizing the response categories for the subscales of\nthe PFB, results in accordance with the Rasch model were\nachieved. This study is to our knowledge the first IRT study\nof measures of relationship satisfaction to test whether the\nresponse categories, beneath an item selection, could be\nadjusted to achieve model fit. Consequently, we are among\nthe first to find that almost all items could be retained when\nthe response scales are dichotomized. Only one item (sub-\nscale Communication, Item 29) had to be eliminated (we\ndeleted rather than allocated Item 29 to be as close to the\noriginal PFB as possible). The elimination of Item 29, how-\never, is consistent with the results obtained by Hahlweg\n(1996) in the exploratory factor analysis of the PFB, which\nresulted in the highest factor loading (.70) for this item on the\nsubscale Tenderness.\nBased on these results, the items of the PFB could in the\nfuture be used as a checklist (PFB-checklist; cf. Elliott et al.,\nTo be able to use the PFB as a checklist, the original instruc-\ntions for the subscales Communication and Tenderness\n(Hahlweg, 1996), \"In the following you can see a list of\nbehaviors, which possibly occur in your relationship/mar-\nriage. ( . . . ). The numbers behind the statements have the\nfollowing meaning,\" have been changed to \"In the following\nyou can see a list of behaviors, which [VERY OFTEN] occur\nin your relationship/marriage.\" For the subscale Conflict\nBehavior, the instructions have been changed to \"In the fol-\nlowing you can see a list of behaviors, which [OFTEN] occur\nin your relationship/marriage.\" The response categories for\nthe items would then be \"no\" (= 0) or \"yes\" (= 1). Even\nthough the results of the present analysis have been cross-\nvalidated with a second independent sample, a further vali-\ndation should follow, thus ensuring that the results can also\nbe obtained with the presentation of the \"PFB-checklist.\"\nProvided the results can be replicated, the \"PFB-checklist\"\nwould be a psychometric instrument in accordance with the\nRasch model, applicable for the analysis of relationship qual-\nity (Embretson & Reise, 2000). Because the PFB-checklist\nhas been shown in a representative sample of the German\npopulation to be most reliable, that is, to best discriminate\nbetween persons, in the middle part of the latent trait con-\ntinuum, the instrument could be valuably used in nonclinical\nsamples, whereas the original PFB might be used in clinical\nsamples. One further case where the PFB-checklist may be\nused is when ease of use is of concern. Deciding between\ntwo instead of four answer categories might also be slightly\nfaster. For studies where the added ease of use might not be\nimportant, researchers could also collect the data in the origi-\nnal response format and dichotomize the data afterward.\nHowever, it should be cautioned that these two options might\nnot produce equal results. Future studies should empirically\nanalyze if there are any significant differences in adminis-\ntrating a dichotomized as opposed to a polytomous-and-\nthen-dichotomized PFB.\nDue to the high correlation between the total values of the\nPFB subscales and the related person parameters, the deter-\nmined total values can be seen as measurement values on\ninterval scale level without problems (cf. Rost, 2004). Future\nresearch should examine whether the conceptualization of\nother partnership measuring instruments (e.g., the DAS) as\ndichotomized checklists could benefit the psychometric\nquality of these instruments as well.\nThese findings are in accordance with previous studies\n(e.g., Funk & Rogge, 2007), which also showed that other\nmeasure of partnership quality might conform to IRT\nassumptions. Consistent with the literature, we found that\nmeasurement properties could be improved by slightly\nadapting the instrument. While Funk and Rogge (2007)\nselected items as a strategy to improve the preciseness of the\nmeasurements across the latent trait, we used a different\nstrategy and could obtain pleasing results by changing the\nFigure 8. Reliability of the dichotomized Conflict Behavior scale of the PFB, depending on the position of the latent trait.\nNote. The error bars represent the standard error of the latent dimension estimate. PFB = Partnership Questionnaire.\nresponse format of the instrument. One possible explanation\nfor this result might be that the participants could not differ-\nentiate well between the original response categories but\nmight be better judges of their partnership quality if only a\ndichotomous scale is provided. If proven replicable, these\nfindings suggest that other instruments of partnership quality\ncould also be made more efficient and precise by changing\nthe response format. These more precise instruments could\nthen be beneficially used to decrease the likeliness to find\nmethodological artifacts and to increase the likeliness to find\nreal antecedents and consequences of partnership quality.\nHowever, given that dichotomizing response scales might\nalso lead to a loss of information, these results must be sub-\nstantiated by further studies. Thus, focusing on the response\nformat of measures of partnership quality might be a fruitful\navenue for future research on the measurement of partner-\nship satisfaction.\nThe reason why the usual polytomous Likert-type scale in\nthe PFB does not allow a uniform separation between partici-\npants according to the measured constructs is still debatable.\nOne explanation could be the different subgroups created\nthrough the use of split criteria. Different semantic meanings\nfor each response category might exist within those sub-\ngroups (Low, 1988). For instance, the semantic meaning of\nthe term often, used to describe frequency in sexuality, might\ndiverge between older and younger or male and female par-\nticipants. However, all participants in the population sample\nseem to view the term very often related to sexuality as con-\ntrary to the remaining terms of frequency. In addition, mea-\nsuring partnership quality proved to be most efficient in the\nmiddle of the latent continuum. Consequently, individuals at\nthe extremes of the latent continuum were comparatively\nharder to discriminate. One possible methodological expla-\nnation for this phenomenon, which is regularly found in the\nliterature regarding the measurement of satisfaction in gen-\neral, is that classical test theory prefers items which discrimi-\nnate in the middle of the continuum, because these items can\ncorrelate most strongly with each other and thus tend to have\nthe highest item-scale correlations. However, this finding\ncould also point to a potential theoretical explanation, in that\nthe construct of relationship quality itself best discriminates\nhigh-quality from low-quality partnerships. Following this\nline of thought, there could potentially be other constructs\nthat might discriminate within the high-quality and low-\nquality groups. Last, this is an empirical question that must\nbe answered by future research. In addition, a mixed-Rasch\nanalysis could determine whether a good model fit might\nalso be obtained for different polytomous Rasch models in\nindependent subsamples.\nAlthough the primary sample was based on a representa-\ntive German community sample and some subpopulation\ndifferences were examined (age and gender), results may\nhave differed for subpopulations not tested (e.g., according\nto duration of the relationship, eastern or western Germany,\nchildren in the relationship). Similarly, the student sample\ncould have been biased in that some student dyads were\nincluded in the sample. Although the examination of the\nwidely used PFB adds to the growing literature on the valid-\nity of relationship distress measures internationally (Funk &\nRogge, 2007), the PFB should also be examined in other cul-\ntures and languages in which it is used. In addition, the utility\nand the validity of the suggested \"PFB-checklist\" with the\nRasch model should be reviewed using a representative pop-\nulation sample, as well as a sample of unhappy couples\nreceiving counseling or couple therapy, or in which one of\nthe partners receives treatment of a psychological disorder.\nIn addition, the benefits of using the PFB in a checklist\nformat as opposed to using the original scale and collapsing\nitems afterward might be questioned. In a general population\nsample, people may be comparatively happy as opposed to a\ntreatment-seeking sample, which might be the reason why\npeople either endorsed the maximal response option or not,\nwith the other options not providing a meaningful distinc-\ntion. If one were to use the checklist in a sample of treatment-\nseeking couples, one may expect that discriminating between\nlevels of dissatisfaction might be more important rendering\nthe full PFB scale the more indicated in treatment settings.\nThus, a PFB-checklist could be beneficially used to discrimi-\nnate happy\u00adunhappy relationships in a general population,\nbut polytomous scales may be indicated for treatment inter-\nvention research. Future studies should validate whether the\nPFB-checklist could also be beneficially used in clinical\nsamples.\nSumming up, to increase the effectiveness of the PFB, the\npresent study re-analyzed the subscales of the PFB (Conflict\nBehavior, Tenderness, Communication) via the Rasch model.\nWe found in both a population sample (N = 1,123) and a\nstudent-based cross-validation sample (N = 250) that col-\nlapsing the response format to a dichotomy substantially\nimproved the accuracy and effectiveness of the PFB, as\njudged by the fit of the Rasch model. Thus, after adapting the\ninstruction and dichotomizing the categories, the PFB could\nbe used as a checklist (PFB-checklist). Although our analysis\nshould be replicated and extended upon, for example, regard-\ning convergent and discriminant validity, the Rasch-based\nPFB-checklist could prove beneficial for measuring partner-\nship quality.\nAuthors' Note\nS\u00f6ren Kliem and Johannes Beller contributed equally to the\narticle.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect\nto the research, authorship, and/or publication of this article.\nFunding\nThe author(s) received no financial support for the research and/or\nauthorship of this article.\nReferences\nAkaike, H. (1973). Information theory and an extension of the max-\nimum likelihood principle. In B. N. Petrov & F. Csaki (Eds.),\nProceedings of the 2nd international symposium on Information\nAmato, P. R. (2010). Research on divorce: Continuing trends and new\nAndersen, E. B. (1973). A goodness of fit test for the Rasch model.\nAndrich, D. (1988). Rasch models for measurement. Beverly Hills,\nBeach, S. R. H. (2001). Marital therapy for co-occurring marital\ndiscord and depression. In S. R. H. Beach (Ed.), Marital and\nfamily processes in depression: A scientific foundation for\nPsychological Association.\nBond, T. G., & Fox, C. M. (2001). Applying the Rasch model:\nFundamental measurement in the human sciences. Mahwah,\nNJ: Lawrence Erlbaum.\nBradbury, T. N., Fincham, F. D., & Beach, S. R. (2000). Research\non the nature and determinants of marital satisfaction: A decade\nDESTATIS. (2010). Bev\u00f6lkerung. Eheschlie\u00dfungen, Geborene und\nGestorbene nach Kreisen 2009 [Population, marriage, birthrate\nand mortality rate of administrative districts 2009]. Wiesbaden,\nGermany: Statistisches Bundesamt. Available from http://\nwww.destatis.de\nElliott, R., Fox, C. M., Beltyukova, S. A., Stone, G. E., Gunderson,\nJ., & Zhang, X. (2006). Deconstructing therapy outcome mea-\nsurement with Rasch analysis of a measure of clinical distress:\nEmbretson, S.E. (1996). The new rules of measurement.\nEmbretson, S. E., & Reise, S. P. (2000). Item response theory for\npsychologists. Mahwah, NJ: Lawrence Erlbaum.\nFischer, G. H., & Molenaar, I. (1995). Rasch models--Foundations,\nrecent developments, and applications. Berlin, Germany:\nSpringer.\nFunk, J. L., & Rogge, R. D. (2007). Testing the ruler with item\nresponse theory: Increasing precision of measurement for\nrelationship satisfaction with the couples satisfaction index.\nHahlweg, K. (1996). Fragebogen zur Partnerschaftsdiagnostik\n(FPD) [Questionnaires to the Partnership Diagnostics].\nG\u00f6ttingen, Germany: Hogrefe.\nHahlweg, K., Baucom, D. H., Grawe-Gerber, M., & Snyder, D. K.\n(2009). Strengthening couples and families: Dissemination of\ninterventions for the treatment and prevention of couple dis-\ntress. In K. Hahlweg, M. Grawe-Gerber, & D. H. Baucom\n(Eds.), Enhancing couples: The shape of couple therapy to\ncome (pp. 3-30). G\u00f6ttingen, Germany: Hogrefe.\nHahlweg, K., Klann, N., & Hank, G. (1992). Zur Erfassung der\nEhequalit\u00e4t: Ein Vergleich der \"Dyadic Adjustment Scale\"\n(DAS) und des \"Partnerschaftsfragebogens\" (PFB) [Partnership\nHinz, A., St\u00f6bel-Richter, Y., & Br\u00e4hler, E. (2001). Der\nPartnerschaftsfragebogen (PFB): Normierung und soziode-\nmographische Einflussgr\u00f6\u00dfen auf die Partnerschaftsqualit\u00e4t\n[Partnership Questionnaire: Standardization and the impact of\nsociodemographic characteristics on the relationship quality].\nHolt-Lunstad, J., Birmingham, W., & Jones, B. Q. (2008). Is there\nsomething unique about marriage? The relative impact of mari-\ntal status, relationship quality, and network support on ambula-\ntory blood pressure and mental health. Annals of Behavioral\nHooley, J. M., & Teasdale, J. D. (1989). Predictors of relapse in\nunipolar depressives: Expressed emotion, marital distress,\nand perceived criticism. Journal of Abnormal Psychology, 98,\nHosmer, D. G., & Lemeshow, S. (2000). Applied logistic regres-\nsion. New York, NY: Wiley.\nKiecolt-Glaser, J. K., & Newton, T. L. (2001). Marriage and health:\nKliem, S., Job, A.-K., Kr\u00f6ger, C., Bodenmann, G., St\u00f6bel-Richter, Y.,\nHahlweg,K.,&Br\u00e4hler,E.(2012).EntwicklungundNormierung\neiner Kurzform des Partnerschaftsfragebogens (PFB-K) an einer\nrepr\u00e4sentativen deutschen Stichprobe [Development and stan-\ndardization of a short form of the Partnership Questionnaire\n(PFB-K) on a representative German sample]. Zeitschrift f\u00fcr\nKliem, S., Kr\u00f6ger, C., St\u00f6bel-Richter, Y., Hahlweg, K., & Br\u00e4hler, E.\n(2012). Die faktorielle Struktur des Partnerschaftsfragebogens\n[The factorial structure of the Partnership Questionnaire].\nZeitschrift f\u00fcr Klinische Psychologie und Psychotherapie, 41,\nLocke, H. J., & Wallace, K. M. (1959). Short marital-adjustment\nand prediction tests: Their reliability and validity. Marriage\nLopez, W. (1996). Communication validity and rating scales. Rasch\nLow, G. D. (1988). The semantics of questionnaire rating scales.\nMair, P., & Hatzinger, R. (2007a). CML based estimation of\nextended Rasch models with the eRm package in R. Psychology\nMair, P., & Hatzinger, R. (2007b). Extended Rasch modeling: The\neRm package for an application of IRT models in R. Journal of\nMair, P., Reise, S. P., & Bentler, P. M. (2008). IRT goodness-of-\nfit using approaches from logistic regression. Department of\nStatistics, University of California, Los Angeles. Retrieved\nO'Farrell, T. J., & Clements, K. (2012). Review of outcome\nresearch on marital and family therapy in treatment for\nalcoholism. Journal of Marital and Family Therapy, 38,\nR Development Core Team. (2011). R: A language and environ-\nment for statistical computing. Vienna, Austria: R Foundation\nfor Statistical Computing. Available from http://www.R-proj-\nect.org/\nRosenberg, P. S., Katki, H., Swanson, C. A., Brown, L. M.,\nWacholder, S., & Hoover, R. N. (2003). Quantifying epide-\nmiologic risk factors using non-parametric regression: Model\nselection remains the greatest challenge. Statistics in Medicine,\nRossier, J., Rigozzi, C., Charvoz, L., & Bodenmann, G. (2006).\nMarital satisfaction: Psychometric properties of the PFB and\ncomparison with the DAS. Swiss Journal of Psychology, 65,\nRost, J. (2004). Lehrbuch Testtheorie \u00ad Testkonstruktion [Textbook\ntest theory--Test construction]. Bern, Switzerland: Huber.\nSabourin, S., Valois, P., & Lussier, Y. (2005). Development and\nvalidation of a brief version of the Dyadic Adjustment Scale\nwith a nonparametric item analysis model. Psychological\nShadish, W. R., & Baldwin, S. A. (2003). Meta-analysis of MFT inter-\nShadish, W. R., & Baldwin, S. A. (2005). Effects of behavioral\nmarital therapy: A meta-analysis of randomized controlled\ntrials. Journal of Consulting and Clinical Psychology, 73,\nSnyder, D. K. (1981). Marital Satisfaction Inventory (MSI). Los\nAngeles, CA: Western Psychological Services.\nSnyder, D. K., Castellani, A. M., & Whisman, M. A. (2006).\nCurrent status and future directions in couple therapy. Annual\nSpanier, G. B. (1976). Measuring dyadic adjustment: New scales\nfor assessing the quality of marriage and similar dyads. Journal\nTerman, L. M., Buttenwieser, P., Ferguson, L. W., Johnson, W. B.,\n& Wilson, D. P. (1938). Psychological factors in marital hap-\npiness. New York, NY: McGraw-Hill.\nWhisman, M. A. (2007). Marital distress and DSM-IV psychiatric\ndisorders in a population-based national survey. Journal of\nAuthor Biographies\nS\u00f6ren Kliem is a research fellow at the Criminological Research\nInstitute of Lower Saxony. He is interested in family psychology,\npsychometrics, clinical epidemiology and clinical psychology.\nJohannes Beller is a research fellow at the Department of\nDevelopmental, Personality and Forensic Psychology at the\nTechnical University Brunswick. He is interested in the potential of\nadvanced statistical methods for psychology, youth delinquency\nand positive human development.\nChristoph Kr\u00f6ger is the director of the outpatient clinic at the\nTechnical University Brunswick, Department of Clinical\nPsychology, Psychotherapy and Assessment. He is internationally\nrecognized for sex and couple therapy.\nYve St\u00f6bel-Richter is full professor at the Zittau / G\u00f6rlitz University\nof applied sciences. She is internationally recognized for her work in\nfamily planning and decisions for and against having children.\nKurt Hahlweg is full professor at the Technical University\nBrunswick, Department of Clinical Psychology, Psychotherapy and\nAssessment and Niedersachsenprofessor 65+ for Clinical\nPsychology and Psychotherapy. He is internationally recognized\nfor his work in prevention research.\nElmra Br\u00e4hler is full professor at the University of Leipzig,\nDepartment of Medical Psychology and Sociology. He is interna-\ntionally recognized for his work in clinical epidemiology, clinical\npsychology and public health."
}