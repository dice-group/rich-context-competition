{
    "abstract": "Abstract. The visual system dissects the retinal image into millions of local analyses along\nnumerous visual dimensions. However, our perceptions of the world are not fragmentary, so\nfurther processes must be involved in stitching it all back together. Simply summing up the\nresponses would not work because this would convey an increase in image contrast with\nan increase in the number of mechanisms stimulated. Here, we consider a generic model of\nsignal combination and counter-suppression designed to address this problem. The model\nis derived and tested for simple stimulus pairings (e.g. A 1 B), but is readily extended\nover multiple analysers. The model can account for nonlinear contrast transduction, dilution\nmasking, and signal combination at threshold and above. It also predicts nonmonotonic\npsychometric functions where sensitivity to signal A in the presence of pedestal B first\ndeclines with increasing signal strength (paradoxically dropping below 50% correct in two-\ninterval forced choice), but then rises back up again, producing a contour that follows the\nwings and neck of a swan. We looked for and found these \"swan\" functions in four different\nstimulus dimensions (ocularity, space, orientation, and time), providing some support for\nour proposal.\n",
    "reduced_content": "a Pion publication\nDaniel H. Baker\nSchool of Life and Health Sciences, Aston University, Aston Triangle, Birmingham B4 7ET, UK;\ne-mail: d.h.baker1@aston.ac.uk\nTim S. Meese\nSchool of Life and Health Sciences, Aston University, Aston Triangle, Birmingham B4 7ET, UK;\ne-mail: t.s.meese@aston.ac.uk\nMark A. Georgeson\nSchool of Life and Health Sciences, Aston University, Aston Triangle, Birmingham, B4 7ET, UK;\ne-mail: m.a.georgeson@aston.ac.uk\n Keywords: dilution masking, suppression, summation, binocular, spatiotemporal vision, orientation.\n1 Introduction\nThe generic problem for spatial vision\nDuring the 1970s and 1980s, experiments with luminance-modulated stimuli revealed much about\nearly visual analysis (Graham, 1989, 2011). The model that emerged is one in which millions of visual\nanalysers decompose the retinal image into local measures along multiple image dimensions including\nspace, orientation, spatial frequency, colour, and motion. The purpose of this is obvious. The visual\nobjects that we are interested in contain smaller parts whose details contribute to the identification of\nthe object. Therefore, some form of image decomposition is necessary to analyse the parts and this is\nusually attributed to population coding within each of the feature dimensions.\nHowever, visual objects themselves do not appear fragmented, so something else is needed to\nlink the parts back together to build representations of higher order structures. Much of what we now\nknow about grouping and linking stems from early 20th-century observations by the Gestalt psycholo-\ngists, albeit now usually set in a contemporary psychophysical context (e.g. Dickinson & Badcock,\nsee Graham, 1989, 2011 for reviews). However, none of the above studies on feature integration con-\nsidered the implications in terms of luminance contrast (hereafter, simply contrast). This is curious,\nbecause contrast is the fundamental coding dimension of the primary visual cortex (V1). Perhaps the\nParadoxical psychometric functions (\"swan functions\") are\nexplained by dilution masking in four stimulus dimensions\n18 Baker D H, Meese T S, Georgeson M A\nreluctance to use image or target contrast as a dependent variable stems from the finding that contrast\nincrement detection does not improve when the size (area) of a grating patch is increased (Legge &\nFoley, 1980). This has been taken to imply that contrast integration (over area) does not take place\nabove threshold. For a given pattern or object, the preliminary analysers (basic mechanisms of V1)\npresumably contribute to feature integration in some manner, but a simple summing operation will\nnot suffice, because this would confound object contrast with the number of analysers involved (Hess,\nThis actually posed little concern for much of the work on spatial vision in the late 20th century,\nbecause most authors were content to end their story at the level of the preliminary analysers in V1\n(though see Olzak & Thomas, 1999, for an early example of a body of work that progressed this).\nHowever, more recent work (Foley, Varadharajan, Koh, & Farias, 2007; Manahilov, Simpson, & Mc-\noutputs of these mechanisms converge in a way capable of achieving contrast integration, and several\nfactors have been identified (Meese, 2010; Meese & Summers, 2007) that explain why this process\nwas often overlooked in the earlier textbook studies. Furthermore, the long-standing view that contrast\nintegration (over area) is abolished above detection threshold (Legge & Foley, 1980) is now quashed\n(Meese & Baker, 2011; Meese & Summers, 2007) and the principle of integration of the contrast re-\nsponse across multiple mechanisms has been firmly established.\nIn this paper, we present a general scheme that is able to achieve contrast integration over any di-\nmension of interest for which there are multiple analysers. The scheme involves a simple arrangement\nof summation and counter-suppression such that at threshold, the contrast sensitivity of the system\nbenefits by extending the stimulus along the relevant dimension, whereas above threshold, the contrast\nresponse is clamped by the gain control (Meese & Baker, 2011; Meese & Summers, 2007).\nA generic model of contrast integration: Signal combination and counter-suppression\nOur generic model is simply a development of standard models of contrast transduction (e.g. Legge &\nFoley, 1980) and contrast gain control (Foley, 1994). It shares the basic design of previous models that\nwere developed for specific stimulus dimensions, such as eye (Meese, Georgeson, & Baker, 2006),\narea (Meese & Summers, 2007), or both (Meese & Baker, 2011). Here, the model has been stripped\nback to the basic operations of summation and counter-suppression. It lacks the detail to provide\nquantitative fits to more complex data sets from previous studies, but it serves to illustrate the general\npoints of interest.\nWe use the term \"target\" to refer to the signal increment that the observer is trying to detect and the\nterm \"pedestal\" to refer to the uninformative contrast against which this judgement is being made. The\nterm \"mask\" is sometimes preferred over \"pedestal\" particularly when the mask and target differ along\none or more stimulus dimensions. However, our model involves summation across all of the relevant\ntarget and mask components and so contrast increments of the target are always detected against the\nbackground activity of the mask in the output mechanism (resp), regardless of any stimulus differ-\nences between the target and mask. Therefore, we find the term \"pedestal\" to be appropriate here, but\ntend to use the more general term \"mask\" with reference to related work by others.\nTo generalize across stimulus dimensions, we refer to pairs of stimulus component contrasts as\nA and B, expressed as percent contrast. In this study, these can derive from the left and right eyes, or\nadjacent locations in space, time, or orientation. We assume that different elementary mechanisms\nare responsive to A and B, and that the outputs of those mechanisms are combined to give a single\nresponse described by the equation\nresp ,\np p\nq q\n+\n=\n+ +\nwhere Z is a constant and the exponents p and q were set to typical values of 2.4 and 2, respectively\n(Legge & Foley, 1980). The model assumes late additive noise, added to the resp, and assumes that\nin a two-interval discrimination task the observer chooses the interval with the higher resp. The slope\nof the dipper function handle for contrast discrimination is set by the difference between p and q and\nthe position of the transition between the dipper region and handle is influenced by Z. For the simula-\ntions here, we set Z 5 2, but this value was not critical. Our analysis of the slope of the psychometric\nfunction is affected little if at all by the details of any of these parameters (within a normative range).\nresp\nDilution masking in four stimulus dimensions 19\nFor contrast discrimination with a single component (e.g. where the target and pedestal each con-\ntribute to the contrast in the A mechanism and B 5 0), the model reduces to the familiar Legge and\nFoley (1980) equation, which leads to dipper-shaped functions relating discrimination threshold to\npedestal contrast (blue curve in Figure 1a). Activating both component mechanisms equally (so that A\nand B each contain target plus pedestal contrasts) produces a similar dipper function, which is shifted\ndownwards and to the left (red curve in Figure 1a). This reveals a summation effect (the model is more\nsensitive to A 1 B than to A alone) at weak pedestal contrasts, but the dipper handles converge at high-\ner contrasts where the denominator terms dominate the saturation constant, Z. This behaviour is found\nWe now consider more complex stimulus arrangements. For convenience, when referring to target\nand pedestal components, we set pedestal components in bold (AB) and leave target components in plain\nfont (AB). When the pedestal consists of both components, but the target increment is in only one (A on\nAB), the dipper function (orange curve in Figure 1a) is a vertical translation of the AB on AB condition\n(red curve). This comparison across conditions reveals the effects of increasing the number of targets\n(from A to AB) whilst keeping the suppressive gain control from the pedestals constant (AB). The result is\nconsistent with our previous work that has found evidence for strong summation (greater than probability\nsummation) at all pedestal contrasts in both the binocular (Meese et al., 2006) and spatial (Meese & Sum-\nmers, 2007) dimensions, just as the model predicts. However, the reasons for such strong summation in\nthe model are not as obvious as they might seem. The modelling by Meese and Summers (2007) showed\nthat the benefit in the AB on AB condition derives from the effects of both signal summation (A 1 B), and\nthe detrimental effects of dilution masking in the A on AB condition against which it is compared. Dilution\nmasking is a specific form of masking (described in detail in the following section) that involves the inap-\npropriate combination of the B pedestal component with the A signal on the numerator of Equation (1).\nAnother configuration of interest is when target and pedestal are different components (A on B).\nFor binocular vision, this is dichoptic pedestal masking (pedestal in one eye, target in the other), where\nthe threshold elevation is so strong that the target contrast must equal or exceed that of the pedestal in\nhaviour predicted by Equation (1) and shown by the green curve in Figure 1(a). Note that the masking\nfunction is steeper and more severe than in the other three conditions. While investigating the model\npredictions for the A on B condition, we observed an unusual form to the psychometric function at high\npedestal contrasts. We describe this observation in the following section.\nA\nA\nA\nAB\nA\nB\nFigure 1. Predictions of the generic contrast integration model. (a) Dipper functions in four arrangements of\npedestal and target. Components are denoted as A and B, to represent separate locations along the dimension of\ninterest (space, time, eye, or orientation). Pedestal components are denoted in bold and target components in plain\nfont. (b) Psychometric functions at a high (32%) pedestal contrast for the same four arrangements. The dotted\nline in panel (a) indicates the pedestal contrast for which psychometric functions are shown in panel (b), and the\ndotted line in panel (b) indicates the threshold at 75% correct. The target contrast levels at which the dotted lines\nintersect with the model predictions are therefore equivalent across the two panels. Matlab code to produce this\nfigure is provided in Appendix B.\n20 Baker D H, Meese T S, Georgeson M A\nDilution masking, swan functions, and negative d\u00b4\nIn a typical contrast discrimination experiment, the pedestal is presented in each two-interval forced\nchoice (2IFC) task and drives the overall response of the generic model equation (Equation (1)) equally\nacross them. Adding a target to the pedestal increases the model response in the target interval. Because\nperformance (d9) is determined by the difference in responses between intervals scaled by the observer's\ninternal noise, performance improves as target contrast increases, and (the so-called) threshold is reached\nat some criterion level of performance (e.g. 75% correct). In the generic contrast integration model, this is\nprecisely what happens for the A on A and AB on AB conditions, and psychometric functions are the famil-\niar monotonic sigmoidal functions of target contrast, as shown by the red and blue curves in Figure 1(b).\nIn the A on B condition, however, the combined effects (in Equation (1)) of mandatory summation\nand suppression between the A and B mechanisms produce very different behaviour from above. The\nexistence of cross-mechanism suppressive effects becomes more readily apparent if Equation (1) is\nrewritten as follows:\nresp .\n=\n+ +\n+\n+ +\nA\np\nq\nq\nB\np\nq\nB\nq\nFor sufficiently high pedestal contrasts, the model response to the target (A) is very weak because of\nstrong suppression from the pedestal (B). This means that the target contrast must be high for it to be\ndetected. However, as the target contrast increases, it produces a substantial suppressive effect of its\nown and this diminishes the contribution that the pedestal (B) makes to the overall response of the\nmodel (note that the target (A) and pedestal (B) are summed before the decision stage). It turns out\nthat at intermediate target contrasts (a little below detection threshold), the detrimental (suppressive)\neffect of the target exceeds its positive contribution to the overall model response. This means that the\nmodel output is lower in the target interval than in the null interval. (This is a bit like turning up the\ndimmer switch for your lighting and finding that the light level decreases!) An observer selecting the\ninterval with the greater response (e.g. the higher perceived contrast) will choose the null interval and\nbe incorrect. This means that performance will drop below 50% correct in a 2IFC task, an example of\nnegative d-prime.1 At higher target contrasts, the nonlinear properties of the model mean that d-prime\nbecomes positive, and the rising part of the psychometric function is very steep, with small increases\nin target contrast producing substantial improvements in performance.\nThe green curve in Figure 1(b) illustrates this unusual behaviour, which leads to a nonmonotonic\npsychometric function that we refer to as a \"swan function\" (because it resembles the wings and neck\nof a swan) or sometimes a paradoxical psychometric function (because over the initial part of the func-\ntion, an increase in signal strength produces a drop in performance). More generally, we refer to the\nmasking process that underlies the swan functions (for A on B) as dilution masking. The terminology\nderives from the fact that the potency of the target is diluted by its inappropriate combination with a\npedestal that has been suppressed by the target. Meese and Summers (2007) identified this form of\nmasking in their work on the A on AB configuration. Dilution masking is distinct from conventional\nwithin-channel masking (Legge & Foley, 1980)--where the pedestal and target are unavoidably com-\nbined within the same initial mechanism--and cross-channel masking (Foley, 1994)--where the mask\nsuppresses the signal but is not combined with it.\nIn summary, the three hallmarks of A on B masking in our generic model are as follows:\n\u00b7 High thresholds\n\u00b7 Steep psychometric functions (the \"neck\" of the swan function)\n\u00b7 A region of negative d-prime in the psychometric function (the \"wings\" of the swan function).\nRecently, Foley (2011) reported a series of experiments that produced unusual, nonmonotonic psy-\nchometric functions that resemble the swan functions predicted by our model. In one such experiment,\na brief (100 ms) target was presented (temporally) in-between two high contrast maskers, each of 1000-\nms duration. The proportion of correctly identified targets decreased below chance performance (i.e.\n1Note that negative d-prime can also occur in single interval tasks when the variances differ between noise and\nsignal-plus-noise distributions (see Green & Swets, 1966, p. 63). However, this situation cannot explain any of\nthe data from our 2AFC experiments, because in 2AFC the variances of the probability distributions from the\nnull and target intervals combine (add) to generate the decision variable. This combined variance is thus the\nsame for the two alternatives: target-first or target-second.\nresp\nDilution masking in four stimulus dimensions 21\n<50% correct for 2IFC, implying negative d-prime) at medium target contrasts, and then increased above\nchance at higher contrasts, producing a highly unusual \"trough\" region in the psychometric function\n(see Foley, 2011, Figures 5 and 8). Encouraged by this finding, and our earlier observations of this phe-\nnomenon in the ocular dimension (Meese et al., 2005), we tested the predictions of the generic contrast\nintegration model experimentally across four stimulus dimensions (space, time, eye, and orientation) in\norder to examine the generality of the proposed model. To anticipate our results, we found evidence for\nall three of the properties above in each stimulus dimension (see Baker, Meese, & Georgeson, 2010, for\na preliminary report). This provides good support for the generic model of contrast integration and sug-\ngests a broader context in which to interpret Foley's (2011) findings.\nApparatus and stimuli\nAll experiments used a ViSaGe stimulus generator (Cambridge Research Systems, Ltd., Kent, UK)\ncontrolled by a PC. Stimuli were presented on a Nokia Multigraph 445X monitor, except for when eye\nof presentation was manipulated. These conditions used a Clinton Monoray monitor and ferro-electric\nshutter goggles (CRS, FE-01) that presented display frames alternately to the left and right eyes. Both\nmonitors ran at 120 Hz, so no flicker was seen even with frame alternation. The mean luminance of\nthe Nokia monitor was 60 cd/m2. Viewed through the goggles (which attenuate luminance by a factor\nof eight), the Clinton monitor had a mean luminance of 10 cd/m2. There were four experiments, inves-\ntigating different dimensions (space, time, eye, and orientation), for which stimuli are now described.\nWe use decibel (dB) units when presenting log contrast, defined as C\ndB\n(C\n%\n), where C\n%\nmax\nmin\n)/(L\nmax\nmin\n) is Michelson contrast in percent.\nIn each of the following four dimensions, we devised A and B component stimuli, where contrast\nsensitivity was (approximately) the same for A and B and where the A 1 B compound was continuous\nin the dimension of interest. We reasoned that this would encourage grouping by the Gestalt law of\ngood continuation in the relevant dimension.\nSpace\nWe used \"Swiss cheese\" stimuli, first introduced by Meese and Summers (2007). These consist of a\ncarrier grating (horizontal, 4 c/deg, 10\u00b0 wide), the contrast of which was modulated over space by a\nraised plaid envelope to produce \"check\" regions of high and low contrast (A or B components). The\nmodulator spatial frequency was such that there were four carrier cycles per modulator check, and the\nentire stimulus was windowed by a circular raised cosine envelope (8\u00b0 plateau, 1\u00b0 cosine ramp around\nthe boundary). The A and B components were derived by using positive and negative phases of the\nplaid modulator (see examples in Figure 3a). Summing A and B recreates the original unmodulated\ncarrier grating. The stimulus duration was 200 ms.\nTime\nSpatially, the AB target was a 1 c/deg horizontal sine-wave grating windowed by a raised cosine enve-\nlope (3\u00b0 plateau, 1\u00b0 cosine ramp around the boundary). An example is given in Figure 3(b). The total\nstimulus duration was 266.67 ms, with A and B component contrasts modulated by a 15 Hz raised\nsquare wave, which produced pulses of 33.33-ms duration (see the inset in Figure 3b). Odd-spaced\npulses formed the A stimulus, and even-spaced pulses the B stimulus. Viewed in isolation, each com-\nponent had on\u00adoff flicker, but their sum was a temporally unmodulated grating (i.e. it is the temporal\nequivalent of the spatial modulation described above).\nEye\nThe binocular AB eye stimulus was spatially identical to that used in the time condition, but was presented\ncontinuously for 200 ms. Monocular components A and B were shown to the left and right eyes, respec-\ntively. This was achieved using the shutter goggles, which have negligible crosstalk between the eyes.\nOrientation\nOur AB stimulus was an isotropic (circularly symmetric) difference of Gaussians (DoG) stimulus with a\ncentre frequency close to 1 c/deg. It was constructed to have zero mean luminance by using standard de-\nviations for the positive and negative Gaussian functions of 0.21\u00b0 and 0.31\u00b0, respectively, and amplitudes\nof unity and 0.44, respectively. To generate the A and B components, the DoG was orientation filtered in\n22 Baker D H, Meese T S, Georgeson M A\nthe Fourier domain as follows. The filter was a raised sine function of polar angle in Fourier space with\na period of 180\u00b0 of orientation. Positive and negative phases of angular modulation produced component\nstimuli with orthogonal orientations (\u00b145\u00b0), which resembled Gabor wavelets (see Figure 3d). Summing\nthe A and B components reconstructed the original isotropic DoG. (See the companion paper by Meese\n& Baker, 2013, for supporting diagram.) Stimulus duration was 200 ms. We abandoned initial attempts to\ndevise an analogous stimulus in the spatial frequency dimension because the complicating factor of the\ncontrast sensitivity function made it difficult to devise A and B stimuli for which sensitivity was similar.\nProcedure\nThe monitor was viewed from a chin-and-head rest, at a distance of 114 cm (Nokia) or 57 cm (Clinton).\nFor the \"eye\" experiment, the goggles were mounted in the head rest. We used a 2IFC paradigm (ISI of\n400 ms) and the method of constant stimuli for all experiments. Psychometric functions were measured\nat 11 target contrast levels, determined by pilot experiments, for a single pedestal contrast level (36 dB\nfor the \"eye\" experiment and 30 dB for the rest). Observers indicated which interval appeared to have\nthe greater contrast using a two-button mouse (for cross-reference, this is equivalent to Foley's (2011)\n\"normal\" response rule). There was no feedback to indicate response correctness, as this would mislead\nobservers if our hypothesis about a negative d-prime region of the psychometric function were correct.\nFor each of the four experiments, there were four combinations of the target and pedestal, A on\nA, AB on AB, A on AB, and A on B. Although this nomenclature always describes component \"A\" as\nthe target, in practice half of the trials were carried out with component \"B\" as the target, and the re-\nsults were pooled across the two arrangements. Trials from all four pedestal/target combinations were\ninterleaved. This was important, particularly in the \"time\" experiment, where we were concerned that\nobservers might have used flicker amplitude instead of luminance contrast as a cue to the target inter-\nval in the A on B condition (the target interval would always have the lower flicker amplitude). This\ncue was eliminated by interleaving the other three conditions, in particular the A on AB condition, for\nwhich the target interval had the greater flicker amplitude.\nSessions for each experiment were carried out in 10 blocks, each consisting of 20 trials per con-\ntrast level at each condition. This produced psychometric functions with 200 trials per level, and a total\nof 2,200 trials per function. We estimated the threshold (75% correct) and slope (equivalent Weibull )\nof each function using Probit analysis (Finney, 1971).\nObservers\nThree psychophysically experienced observers completed all conditions. One was the first author\n(DHB), the other two (ASB and LP) were volunteers who were unaware of the purpose of the experi-\nments. Observers had normal stereopsis and wore appropriate optical correction if necessary.\nModel simulations\nTo illustrate model behaviour for dipper functions (e.g. in Figures 1a andA2), we calculated thresholds\nby finding target contrasts that satisfied the following equation:\nd=\nresptarget\nrespnull ,\nwhere the \"resp\" terms are model outputs (e.g. from Equation (1) or the alternative models considered\nin Appendix A) in the null and target intervals, d' is the performance level at \"threshold\" (for 75% cor-\nrect, d' 5 0.95) and  is a deterministic representation of the observer's internal noise. For the simula-\ntions here 5 0.2. This value was not critical and merely influences overall sensitivity and the location\nof the transition between the dipper region and the dipper handle.\nModelpsychometricfunctions(e.g.inFigures1bandA1)wereproducedbyevaluatingEquation(3)\nfor a range of target contrasts and converting the resulting d'values to proportion correct according to\np = d\n,\n\nwhere  denotes the normal integral and p is proportion correct for a 2IFC task (see MacMillan &\nCreelman, 2005). We fitted the simulated psychometric functions using Probit analysis to produce\nthreshold and slope estimates to compare with our empirical results (e.g. grey crosses in Figure 2).\nresp resp\nDilution masking in four stimulus dimensions 23\nNote that the negative d' in the swan functions (see Section 1) derive from the fact that resp\nnull\nis larger\nthan resp\ntarget\n(Equation (3)) in that region. In turn, this causes Equation (4) to drop below 50% correct.\nWe first compare the threshold and slope values between the A on A and A on B conditions. In these\ntwo conditions, the pedestal contrast is the same: all that differs is the arrangement of pedestal and\ntarget across the dimension of interest. The results are shown in Figure 2 and are very different across\nthe two conditions. The A on A condition (open symbols) is characterized by moderate thresholds (<20\ndB) and shallow psychometric slopes (1 <  < 2) consistent with previous work on contrast discrimi-\nnation (e.g. Bird, Henning, & Wichmann, 2002; Meese et al., 2006), and similar to the A on AB and\nAB on AB conditions (not shown). The A on B condition (filled symbols in Figure 2) produced high\nthresholds (~30 dB) and steep psychometric functions ( > 3).\nBoth of these results are consistent with the predictions of the generic model of contrast integra-\ntion (grey crosses). In the model, slopes are shallow for A on A because the effective contrast trans-\nducer at high pedestal contrasts is equivalent to a power function with exponent p 2 q 5 0.4. For small\ncontrast increments (around the size of a contrast discrimination threshold), this function is effectively\nlinear (i.e. the local curvature of the C0.4 power law is approximately zero). Thus, it is often said that a\npedestal \"linearizes\" the contrast response to the target. This has the effect of reducing the psychomet-\nric slope to that for a linear system, which is  ~ 1.3 (e.g. Tyler & Chen, 2000). In the A on B condition,\nhowever, the slopes become steeper because of the effects of dilution masking described in Section 1.\nWe now consider psychometric functions for the A on B condition. These are shown for each of\nthe four stimulus dimensions and three observers in Figure 3. In each plot, the horizontal dotted line\nindicates chance performance for standard 2IFC (d' 5 0). Points falling below this line indicate nega-\ntive d-prime, highlighted by the shaded regions. Recall that each point on the psychometric function\nrepresents 200 trials, so their binomial errors are low (see error bars). Only the A on B condition pro-\nduced the negative d-prime effects--the other arrangements of target and pedestal produced conven-\ntional monotonic psychometric functions (not shown). We find evidence for nonmonotonic behaviour\nfor all three observers in the spatial dimension (Figure 3a), clear evidence for two observers in the time\ndimension (Figure 3b), and evidence for one observer in each of the eye (DHB, Figure 3c) and orienta-\ntion (LP, Figure 3d) dimensions. We consider possible explanations for these individual differences in\nB\nA\nA\nA\nFigure 2. Thresholds and slopes for two arrangements of target and pedestal. Open symbols are for the A on A\ncondition, and filled symbols for the A on B condition. Colour and symbol denote the stimulus type, with one\ndata point per observer for each condition. Slopes are equivalent Weibull  values, estimated from the fitted\ncumulative log-Gaussian psychometric function using the approximation  5 10.3/, where  is the Gaussian\nstandard deviation in dB. Note that the fitting procedure ignores values below the guess rate (50% correct) so the\nslope of the positive d-prime portion of the function is not affected by negative d-prime regions. The grey crosses\ngive the threshold and slope predictions for the generic contrast integration model.\n24 Baker D H, Meese T S, Georgeson M A\nSection 4. In summary though, examples of negative d-prime were found for all four stimulus dimen-\nsions, as predicted by the model.\nFinally, we estimated the level of summation across the A and B components by comparing thresh-\nolds in the A on AB condition with those in the AB on AB condition. Symbols in Figure 4 indicate sum-\nmation ratios (the threshold difference in dB, which equals 20 times the log of the ratio of thresholds in\nlinear units) for individual observers, for each of the four stimulus dimensions. The black bars are the\naverages, with error bars indicating \u00b11 SE. The mean level of summation on a pedestal lies between 3\nand 6 dB, consistent with previous findings for eye and space (Meese & Summers, 2007; Meese et al.,\n2006). The levels of summation are close to those predicted by the generic contrast integration model\n(grey horizontal line), which was not critically dependent on the values of its four parameters (Z, p,\nq, and ).\n4 Discussion\nWe tested several predictions of a generic contrast integration model of vision in each of four stimulus\ndimensions (space, time, eye, and orientation). As predicted, we found that detection thresholds and\nthe slopes of the psychometric function depended on whether the pedestal was the same as or differ-\nent from the target (Figure 2), indicating that our stimulus manipulations were successful in recruiting\nmultiple mechanisms (i.e. the A and B components excited different front-end mechanisms; see Ap-\npendix A for details). Furthermore, we found that the simultaneous excitation of these mechanisms im-\nA\nB\nA\nB\nLeft eye\nRight eye\n(a) (b)\n(d)\n(c)\nFigure 3. Psychometric functions for the A on B condition in each of four stimulus dimensions. Functions were\nsampled at 200 trials per target contrast level. There is evidence for nonmonotonicity and negative d-prime within\neach dimension.Above each plot are high contrast examples of the stimuli and icons indicating the arrangement of\nthe A and B stimuli. The dimensions were (a) space, (b) time, (c) eye, and (d) orientation. Error bars are binomial\nerrors.\nDilution masking in four stimulus dimensions 25\nproved performance, consistent with signal summation across them (Figure 4). Further still, when the\ntarget and pedestal were different (termed A on B) we found evidence for nonmonotonic psychometric\nfunctions with a clear region of negative d-prime in more than half of them. Because of the shape of\nthese functions, we refer to them as \"swan\" functions (Figure 3). This surprising behaviour is predicted\nby our generic contrast integration model as described in Section 1.\nIn what follows, we will discuss swan functions that have been found in other studies and pos-\nsible explanations for the individual differences in our results. We will consider and reject alternative\nmodels of our results in Appendix A.\nSwan functions in other studies\nAs mentioned in Section 1, Foley (2011) described psychometric functions that have a nonmonotonic\nshape similar to our swan functions under some of his conditions. Foley's stimulus arrangement that\nproduced this behaviour (a temporal \"mask\u00adtarget\u00admask\" sequence) is very similar to our \"time\"\ncondition described above (four repetitions of \"mask\u00adtarget\"), and so it is plausible that the processes\nunderlying the nonmonotonic effects might be the same across the two studies. However, our model\ninvolves summation of mask and target, but in Foley's model the signals are subtracted. We compare\nour model with Foley's and several others in Appendix A, and conclude that only our model can ac-\ncount for all of the findings in our study here.\nIn other work, swan functions have also been reported in the motion dimension. Serrano-Pedraza\nand Derrington (2010) judged perceived direction of motion for a 3 c/deg Gabor target moving at\n4 deg/sec, superimposed on a static 1 c/deg Gabor mask. When the stimulus was quite large (3.3\u00b0\nfull width at half-height [FWHH]), the psychometric function relating target contrast to proportion\nof correct direction judgements was steep and nonmonotonic, with a similar form to those in Figure\n3. The negative d-prime region was so severe (particularly for one observer) that for some contrasts\nevery trial was perceived incorrectly (e.g. 0% correct). When the stimulus was small (0.82\u00b0 FWHH),\npsychometric functions were shallower and had a monotonic sigmoidal shape.\nAre the results of Serrano-Pedraza and Derrington (2010) related to ours? The model they propose\ntakes the MAX response across noiseless and mutually suppressive mechanisms sensitive to differ-\nent spatial frequencies. The combination of subtractive suppression and a MAX operator produces\nappropriate nonmonotonic psychometric functions but does not predict the summation of A and B\nstimuli (Figure 4). This makes it inconsistent with our full set of results. Our own implementation of\na MAX-based model in Appendix A suffers the same fate. However, the MAX approach might well\nbe appropriate in Serrano-Pedraza and Derrington's (2010) motion paradigm where the existence of\na competitive opponent motion process is well established (e.g. the \"winner takes all\" in choosing\nbetween two potential motion directions). Consistent with this is their finding that detection of motion\nfor the individual components shows no summation of duration thresholds (their Figure 2B). Thus,\nalthough there are qualitative similarities between the swan functions here and those in the motion\ndimension, the details of their origins are quite possibly different.\nMore broadly, our findings may relate to other \"paradoxical\" contrast behaviours, such as those re-\nported by Stevenson and Cormack (2000). In their experiments, performance deteriorated when there\n\nFigure 4. Summation ratios in four stimulus dimensions (symbols) and model prediction (horizontal line).\nSymbols show results for each of the three observers, with the average shown by the black bars. In all cases,\nsummation is calculated as the dB threshold difference between the A on AB and AB on AB conditions. Error bars\nshow \u00b11 SE.\n26 Baker D H, Meese T S, Georgeson M A\nwas a contrast imbalance between the eyes (for stereopsis; see also Legge & Gu, 1989), or between\ntwo components in a vernier task, or adjacent frames of a motion stimulus. Both Legge and Gu (1989)\nand Kontsevich and Tyler (1994) proposed models for the stereo case, the latter being closely related\nto ours, involving mutual suppression followed by signal combination. Finally, the nonmonotonic\nbehaviour may be related to the well-known Fechner paradox in dichoptic brightness matching (e.g.\nPossible explanations for individual differences\nAlthough we found examples of negative d-prime in all four stimulus dimensions, the effects were\nnot uniform across observers. In particular, for eye and orientation, only one of our three observers\nproduced swan functions, though for the eye condition we have found them in three out of four other\nobservers outside of this study (unpublished observations; and Baker, 2008). Even where all observers\ndo show the effect (e.g. for space, Figure 3a), there is much more variation in the magnitude of the\nparadoxical trough region than in the threshold or slope values (Figure 2).\nWe consider three possible explanations for these individual differences, though others doubtless\nexist. The first is that the level of suppression between the A and B mechanisms might vary across\nobservers. This can be modelled in Equation (2) by including a multiplicative weight parameter on\neach of the cross-mechanism denominator terms. Reducing the level of suppression attenuates the\nnegative d-prime region, but it also reduces threshold and slope. Therefore, it cannot explain the data\nfor most of the observers and conditions in which the trough was absent, yet thresholds and slopes\nremained roughly homogeneous (Figure 2). However, it could perhaps explain the results for DHB in\nthe orientation condition.\nA second possibility is that observers might not select the interval that produces the greatest in-\nternal response. An alternative decision rule might be to respond to the stimulus that differs from an\ninternal representation of the null interval, consistent with choosing abs(d9). To a first approximation,\nthis would flip the negative d-prime region upside down, producing a hump above 50% correct, much\nlike using the \"reverse\" rule described by Foley (2011). There is some limited evidence for this for\nobserver ASB in the time, eye, and orientation conditions (Figure 3b\u00add), and observer LP in the eye\ncondition (Figure 3c). Of course, alternating between these two rules on different trials or sessions\nwould average out the trough and the hump leaving performance at chance (50% correct) in that part\nof the psychometric function, just as we found in some of our results.\nThe third explanation is that observers might have access to the individual component mech-\nanisms--i.e. mechanisms in which the A and B components are not summed. For example, for the\n\"Swiss cheese\" stimuli from the spatial dimension, the different spatial regions corresponding to the\nA and B components can be readily resolved when the stimulus is above threshold. However, it is less\nclear that this could happen in the other dimensions. In the binocular dimension, the consensus from\nthe literature is that observers cannot identify the eye to which a stimulus has been presented (i.e.\nutrocular discrimination is difficult or impossible; see Blake & Cormack, 1979). Arguably though,\nthis is not important: so long as observers are able to access the output of monocular mechanisms it\ndoes not matter whether those mechanisms are labelled for eye of origin. Regardless of the details, if\nobservers were able to access nonoverlapping component mechanisms, this would abolish both the\nthreshold elevation and negative d-prime effects caused by the pedestal. This is clearly not the case\nfor any of our observers, but one could construct a model in which a partial contribution from such\nmechanisms reduces one or both effects. However, our results do not provide sufficient constraint to\nattempt this here.\nThe generic integration model and population coding\nIn the experiments here, we have sampled the dimension of interest in just two places (the A and B\ncomponents). Nonetheless, we envisage extended integration where appropriate, and we have pre-\nsented evidence for this elsewhere (e.g. Baker & Meese, 2011). However, from one point of view, the\ngeneric model that we propose might appear puzzling: what is the point of integrating signal over a\nstimulus dimension if it is then to be suppressed by a similar integration over the same dimension? The\nfirst part of the answer is that the counter-suppression helps to maintain the invariance of contrast per-\nception with the variable extent of integration. In the case of binocular summation, we have referred\nto this as ocularity invariance (Meese et al., 2006). However, this operation appears to throw away the\nbenefit of performing integration in the first place. Meese and Baker (2011) offered a possible answer\nto this conundrum by proposing a population of integrators, where the suppressive integration region\nDilution masking in four stimulus dimensions 27\n(the gain control) extends over the maximum extent of the relevant dimension, but the extent of the\nexcitatory region varies across the mechanisms within the population. Thus, the general arrangement\nof suppression and counter-suppression that we propose is not as counterproductive as it might seem,\nbecause it provides the potential basis for a population code at a global (or object) level of analysis.\n5 Conclusions\nWe have found evidence for nonmonotonic psychometric functions (swan functions) in each of four\nstimulus dimensions. They occur only when the target and mask patterns stimulate different early\nvisual mechanisms--different eyes, different positions, different orientations, or at different times.\nThis unusual behaviour is predicted by our generic model of contrast integration, which involves\nsummation and counter-suppression across mechanisms within each stimulus dimension. It remains to\nbe seen whether this framework extends beyond the low-level stimulus dimensions we have tested to\nhigher level visual operations, such as object or face processing, or into other sensory modalities such\nas hearing and touch.\nReferences\nBaker, D. H. (2008). Interocular suppression and contrast gain control in human vision. Unpublished doctoral\nBaker, D. H., & Meese, T. S. (2007). Binocular interactions: Dichoptic masking is not a single process. Vision\nBaker, D. H., & Meese, T. S. (2011). Contrast integration over area is extensive: A three-stage model of spatial\nBaker, D. H., Meese, T. S., & Georgeson, M. A. (2007). Binocular interaction: Contrast matching\nand contrast discrimination are predicted by the same model. Spatial Vision, 20, 397\u00ad413.\nBaker, D. H., Meese, T. S., & Georgeson, M. A. (2010). \"Dilution masking\", negative d-prime and\nnonmonotonic psychometric functions for eyes, space and time. Perception, 39(S), 7.\nBird, C. M., Henning, G. B., & Wichmann, F. A. (2002). Contrast discrimination with sinusoidal gratings\nBlake, R., & Cormack, R. H. (1979). On utrocular discrimination. Perception & Psychophysics, 26, 53\u00ad68.\nCurtis, D. W., & Rule, S. J. (1980). Fechner's paradox reflects a nonmonotone relation between binocular\nDickinson, J. E., & Badcock, D. R. (2007). Selectivity for coherence in polar orientation in human form vision.\nField, D. J., Hayes, A., & Hess, R. F. (1993). Contour integration by the human visual system: Evidence for a\nFinney, D. J. (1971). Probit analysis. Cambridge: Cambridge University Press.\nFoley, J. M. (1994). Human luminance pattern-vision mechanisms: Masking experiments require a new model.\nFoley, J. M. (2011). Forward\u00adbackward masking of contrast patterns: The role of transients. Journal of Vision,\nFoley, J. M., Varadharajan, S., Koh, C. C., & Farias, M. C. Q. (2007). Detection of Gabor patterns of different\nGraham, N. V. (1989). Visual pattern analyzers. Oxford: Oxford University Press.\nGraham, N. V. (2011). Beyond multiple pattern analyzers modeled as linear filers (as classical V1 simple cells):\nGreen, D. M., & Swets, J. A. (1966). Signal detection theory and psychophysics. New York: Wiley.\nHess, R. F., Dakin, S. C., & Field, D. J. (1998). The role of \"contrast enhancement\" in the detection and\nJones, D. G., Anderson, N. D., & Murphy, K. M. (2003). Orientation discrimination in visual noise using global\nKontsevich, L. L., & Tyler, C. W. (1994). Analysis of stereothresholds for stimuli below 2.5 c/deg. Vision\n28 Baker D H, Meese T S, Georgeson M A\nLegge, G. E. (1979). Spatial frequency masking in human vision: Binocular interactions. Journal of the Optical\nLegge, G. E., & Foley, J. M. (1980). Contrast masking in human vision. Journal of the Optical Society of\nLevi, D. M., & Klein, S. A. (2000). Seeing circles: What limits shape perception? Vision Research, 40, 2329\u00ad\nMacMillan, N. A., & Creelman, C. D. (2005). Detection theory: A user's guide. New Jersey: Lawrence Erlbaum\nAssociates.\nMaehara, G., & Goryo, K. (2005). Binocular, monocular and dichoptic pattern masking. Optical Review, 12,\nManahilov, V., Simpson, W. A., & McCulloch, D. L. (2001). Spatial summation of peripheral Gabor patches.\nMeese, T. S. (2010). Spatially extensive summation of contrast energy is revealed by contrast detection of\nMeese, T. S., & Baker, D. H. (2011). Contrast summation across eye and space is revealed along the entire\nMeese, T. S., & Baker, D. H. (2013). A common rule for integration and suppression of luminance contrast\nMeese, T. S., Georgeson, M. A., & Baker, D. H. (2005). Interocular masking and summation indicate two stages\nMeese, T. S., Georgeson, M. A., & Baker, D. H. (2006). Binocular contrast vision at and above threshold.\nMeese, T. S., Hess, R. F., & Williams, C. B. (2005). Size matters, but not for everyone: Individual differences\nMorgan, M. J., & Hotopf, W. H. (1989). Perceived diagonals in grids and lattices. Vision Research, 29, 1005\u00ad\nMeese, T. S., & Summers, R. J. (2007). Area summation in human vision at and above detection threshold.\nMeese, T. S., & Summers, R. J. (2009). Neuronal convergence in early contrast vision: Binocular summation\nis followed by response nonlinearity and area summation. Journal of Vision, 9(4), 711\u00ad716.\nMotoyoshi, I., & Nishida, S. (2004). Cross-orientation summation in texture segregation. Vision Research, 44,\nMoulden, B. (1994). Collator units: Second-stage orientational filters. Ciba Foundation Symposium, 184,\nOlzak, L. A., & Thomas, J. P. (1999). Neural recoding in human pattern vision: Model and mechanisms. Vision\nParkes, L., Lund, J., Angelucci, A., Solomon, J. A., & Morgan, M. (2001). Compulsory averaging of crowded\nSassi, M., Vancleef, K., Machilsen, B., Panis, S., & Wagemans, J. (2010). Identification of everyday objects on\nSerrano-Pedraza, I., & Derrington, A. M. (2010). Antagonism between fine and coarse motion sensors depends\nStevenson, S. B., & Cormack, L. K. (2000). A contrast paradox in stereopsis, motion detection and vernier\nTyler, C. W., & Chen, C. C. (2000). Signal detection theory in the 2AFC paradigm: Attention, channel\nWatson, A. B., & Ahumada, A. J. (2005). A standard model for foveal detection of spatial contrast. Journal of\nWilson, H. R., & Wilkinson, F. (1998). Detection of global structure in Glass patterns: Implications for form\nDilution masking in four stimulus dimensions 29\nAppendix A: Alternative models\nHere, we consider several alternative functional models of our results. The pooled data across all\nobservers and experiments are shown in Figure A1(a), and the successful predictions of our generic\ncontrast integration model are shown in Figure A1(b) for comparison. We first show that other model\narrangements do not predict all aspects of our data. We then show that our generic model can predict\nA.1 Early summation\nAn alternative to pooling signals after exponentiation is to pool them before it. This is to assume that\nthe selectivity of the initial filtering mechanisms is sufficiently broad to respond to each of the A and\nB components. The model equation is given by\n( )\nresp ,\n( )\np\nq\n+\n=\n+ +\nwith all terms as described in the main body of the report. As shown in Figure A1(c), this model fails\nbadly for the A on B condition. This is because the linear summation between the two components\nmeans that the model is blind to which is the pedestal and the target. Thus, it predicts exactly the same\nbehaviour for A on B arrangement as it does for the A on A arrangement, and is inconsistent with the\nswan functions and high thresholds that we find empirically for A on B.\nA.2 A MAX operation instead of linear summation\nInstead of summing the two terms in Equation (2), we could select the most active mechanism:\nwith all terms as described in the main body of the report. This model does predict the nonmonotonic\ncharacter of the swan functions for A on B. In fact, the severity of the paradoxical region is even\ngreater than for the generic contrast integration model (compare the green functions in Figures A1d\nwith A1b). However, it fails to predict the correct ordering of the other contrast discrimination condi-\ntions, as follows. In the MAX model, the psychometric function for the A on AB condition (yellow)\nappears to the left of that for the AB on AB condition (red). This implies a negative summation effect,\nwhich occurs because suppression from the additional target in the AB on AB case outweighs the (non-\nexistent) benefit of including it.\nFor simplicity, the model calculations in Figure A1(d) were derived analytically. A stochastic\nversion of the MAX model with independent Gaussian noise added to each term in Equation (A2)\nbehaved in a very similar way, with the ordering of the conditions unchanged at high pedestal levels\n(not shown). This is in spite of the benefit from probability summation at threshold (e.g. Tyler & Chen,\n2000; Appendix A of Meese & Summers, 2007), which is hidden by the strong suppression from the\npedestals.\nA.3 Foley's subtractive model\nFoley (2011) proposed a model in which the mask contrast is subtracted from that of the target. A\nsimplified version, following our present conventions, can be written as\nwhere \"abs\" indicates the absolute (unsigned) value. Note that Foley's original model also included\nweight terms on both the numerator and denominator. We have omitted these here for simplicity, but\nincluding them makes little difference to the qualitative behaviour of the model (at least for the range\nof values considered by Foley, 2011). Figure A1(e) confirms that this arrangement predicts the swan\nfunction for the A on B condition considered by Foley (2011). However, the other three arrangements\nof mask and pedestal considered here are less well predicted. In particular, the AB on AB condition\nproduces a model response of zero, since the A and B terms cancel on the numerator of Equation (A3).\nThis could be fixed by including additional mechanisms (as proposed by Foley, 2011). However,\nresp\nresp\nresp\n30 Baker D H, Meese T S, Georgeson M A\nachieving the strong summation effects that we report will most likely require something similar to our\ngeneric model, which also predicts the nonmonotonic effects without the need for a subtractive term.\nGiven the similarity between our swan functions and those reported by Foley (2011; e.g. his\nFigure 5) it is clear that our model (Equation (1)) can at least provide a qualitative account of his\nresults. A precise quantitative fit would likely require additional free parameters (such as weights to\naccount for the different durations of mask and target) and is beyond the scope of this study.\nNotwithstanding the above, we should also point out that one of the useful properties of Foley's\n(2011) model is that it is well disposed to describing some interesting \"straddle\" adaptation effects\nreviewed by Graham (2011) (occasionally referred to as \"Buffy\" adaptation). It is beyond the scope of\nthis article to provide details of those experiments here, and it remains to be seen whether our generic\ncontrast integration model can be extended to account for those results as well.\nA.4 The generic contrast integration model predicts Foley's (2011) dipper functions\nExperiment 1 of Foley (2011) measured contrast discrimination (dipper) functions for a 100-ms target\n(and pedestal) interleaved between two 1,000-ms masks, with the same spatial properties. As the mask\ncontrast increased from zero, the dippers were shifted upwards and to the right such that the dipper\nhandles superimposed, similar to findings with other masks (e.g. cross-orientation masks, Foley, 1994;\ndichoptic pedestal masks, Baker, Meese, & Georgeson, 2007). The amount of facilitation (depth of the\ndip) also increased in the presence of a mask. In Figure A2, we show the predictions of the generic\nA\nA\nA\nAB\nA\nB\nFigure A1. Pooled data and predictions of four functional models for each of four arrangements of pedestal\nand target (legend). The data were combined across observers and experiments, with symbol size representing\nthe total number of trials at each contrast level (the largest symbols represent 2,400 trials each). See text for\ndescriptions of the four models.\nDilution masking in four stimulus dimensions 31\nFigure A2. Predictions for Foley's (2011) dipper functions. The diagonal translation of these functions with\nincreasing mask contrast mirrors the pattern found empirically (see Foley, 2011). Note that the dipper handles\nconverge at high pedestal contrasts, and that facilitation is strongest for high mask contrasts.\nCm\nCm\nCm\nCm\ncontrast integration model, when the target and pedestal are the A component, and the mask is the\nB component. It is clear that the diagonal translation of the dippers is also predicted by our model\n(Equation (1)). We also note that this pattern of dippers is similar to that we have reported previously,\nwhen target and pedestal are shown to one eye, and a fixed contrast mask is shown to the other eye\n32 Baker D H, Meese T S, Georgeson M A\nAppendix B: Matlab code to produce model diagrams\nAt the request of an anonymous reviewer, we have included Matlab code to produce the graphs in\nfunction appendixmodelcode\n% Generates predictions for the generic contrast integration model,\nas shown in Figure 1 of Meese & Baker (2013), iPerception\nclear; close all;\nnconds = 4;% there are four arrangements of target and pedestal\ncoloured curves\nK.P = 2.4; K.Q = 2; K.Z = 2; K.K = 0.2;% define model parameters in a\nstructure\n%\u00ad\u00ad\u00ad\u00ad\u00ad% Panel (a) - set up some vectors of pedestal contrasts and get\nmodel predictions for dipper functions\npedcontrastsC = 10.^(pedcontrastsdB/20); pedcontrastsC(1) = 0;\nrespArray = runmodels(K,pedcontrastsC, nconds);% call the function\nthat produces the predictions\n% set up a figure and make it look pretty\nticksy = ticksx;\naxis([minx maxx miny maxy]); axis square; set(gca, `XTick',ticksx,\n`YTick',ticksy);\nxlabel(`Pedestal contrast (dB)', `FontSize', 18); ylabel(`Threshold\n(dB)', `FontSize', 18);\n% plot the model predictions for dipper functions\nfor i \n= 1:nconds\nh = plot(pedcontrastsdB, respArray(i,:), `k-', `LineWidth', 2,\n`Color', colourvect(i,:));\n\nset(h,'LineWidth',4); % make the A on A condition thicker so you\ncan see it\n\nend\nend\nDilution masking in four stimulus dimensions 33\nlegend(`A on A', `AB on AB', `A on AB', `A on B', 2); % create a\nfigure legend\nplot([30 30], [miny maxy], `k:'); % add fiducial lines\n%--\u00ad--\u00ad\u00ad% Panel (b) - set up some matrices of pedestal and target\ncontrasts and get model predictions for psychometric functions\ntestdB = repmat(testdB, size(testdB,2),1); peddB = rot90(testdB,3);\nzeros(size(pedC));\n% calculate d-prime for each of the four conditions, see equation 3\nof paper\nd(1,:,:) = (model(K,pedC+testC,null)-model(K,pedC,null))./K.K;% A on A\nd(2,:,:) = (model(K,pedC+testC,pedC+testC)-model(K,pedC,pedC))./\nK.K;% AB on AB\nd(3,:,:) = (model(K,pedC+testC,pedC)-model(K,pedC,pedC))./K.K;% A\non AB\nd(4,:,:) = (model(K,testC,pedC)-model(K,null,pedC))./K.K;% A on B\npropcorrect = 0.5 .* (1+erf((d ./sqrt(2))./sqrt(2))); % convert\nmatrix of d-primes to proportion correct (equation 4 of paper)\n% spawn another axis and make it look pretty\naxis square; axis([minx maxx miny maxy]); set(gca, `XTick',ticksx,\n`YTick',ticksy);\nxlabel(`Target contrast (dB)', `FontSize', 18); ylabel(`Proportion\ncorrect', `FontSize', 18);\n% plot the model predictions for psychometric functions only at a\nfor i \n= 1:nconds\n\nh = plot(testdB(end-11,:), squeeze(propcorrect(i,end-11,:)),\n`k-', `LineWidth', 2, `Color', colourvect(i,:));\nset(h,'LineWidth',4); % make the A on A condition thicker so\nyou can see it\nend\nend\n`k:');% add fiducial lines\nreturn\n%------------------------------------------------------------------\nfunction respArray = runmodels(K, pedCarray, nconds)\n% basic function to accumulate thresholds for all the different\npedestal contrasts and conditions\nrespArray = zeros(nconds,length(pedCarray));% create matrix to\nstore results\nfor i = 1:nconds% loop through the conditions\nfor j = 1:length(pedCarray)% loop through the pedestal levels\nrespArray(i,j) = discriminate(K, pedCarray(j), i);% call the\n`discriminate' function to get a threshold\nend\nend\nrespArray = 20.* log10(respArray);% convert model thresholds to\ndecibels (dB)\nreturn\n%------------------------------------------------------------------\nfunction [Tc] = discriminate(K,ped,cond)\n34 Baker D H, Meese T S, Georgeson M A\n% This function is a basic staircase-like procedure for determining\ncontrast at threshold. The two loops increment and decrement the\ntarget contrast (Tc) by small amounts until threshold is reached\n(e.g. the response in the target interval exceeds that in the null\ninterval by some specified amount)\nswitch cond\ncase 1% A on A\n null = model(K, ped, 0);\ncase 2 % AB on AB\n null = model(K, ped, ped);\ncase 3 % A on AB\n null = model(K, ped, ped);\ncase 4% A on B\n null = model(K, 0, ped);\nend\nwhile (resp-null)<= K.K\nswitch cond\ncase 1 % A on A\n resp = model(K, ped+Tc, 0);\ncase 2 % AB on AB\n resp = model(K, ped+Tc, ped+Tc);\ncase 3% A on AB\n resp = model(K, ped+Tc, ped);\ncase 4% A on B\n resp = model(K, Tc, ped);\nend\nend\nwhile (resp-null) >= K.K\nswitch cond\ncase 1% A on A\n resp = model(K, ped+Tc, 0);\ncase 2% AB on AB\n resp = model(K, ped+Tc, ped+Tc);\ncase 3% A on AB\n resp = model(K, ped+Tc, ped);\ncase 4% A on B\n resp = model(K, Tc, ped);\nend\nend\nreturn\n%------------------------------------------------------------------\nfunction resp = model(K, A, B)\n% this is the generic contrast integration model, defined in equa-\ntion 1 of the paper\n\naa = A.^K.P./ (K.Z + A.^K.Q + B.^K.Q);% pass each component\ncontrast through a transducer\n\nbb = B.^K.P./ (K.Z + B.^K.Q + A.^K.Q);% featuring suppression\nfrom the other channel\nresp = aa + bb;% sum the responses from both channels together\nreturn\n%------------------------------------------------------------------\nCopyright 2013 D H Baker, T S Meese, M A Georgeson\nPublished under a Creative Commons Licence a Pion publication\nDilution masking in four stimulus dimensions 35\nTim S. Meese worked as a telecommunications engineer for five years before\nstudying Psychology and Computer Science at the University of Newcastle-\nUpon-Tyne, where he graduated in 1989. He did his PhD at the University of\nBristol and is now Professor of Vision Science at Aston University. His main\nresearch interests are in binocular and spatial vision and depth perception.\nHe has been on the executive committee of the Applied Vision Association\nfor more than 15 years and is now one of the chief editors of Perception and\ni-Perception.\nDaniel H. Baker studied Psychology at the University of Nottingham from\nat Aston University under the supervision of Tim Meese. Daniel held a post-\ndoctoral position at the University of Southampton (2007\u00ad09), and is currently\na research fellow at Aston University. His main research interests are spatial\nvision, binocular vision (including binocular rivalry), and motion perception.\nFor more information visit http://www1.aston.ac.uk/lhs/staff/az-index/daniel-\nbaker/.\nMark A. Georgeson studied Mathematics and Experimental Psychology at\nCambridge University, then worked for his DPhil on spatial vision at Sussex\nUniversity. He has held academic posts at Bristol, Birmingham, and Aston\nUniversities, and published about 80 research papers on visual psychophys-\nics and computational modelling. The work aims to understand how spatial\nvision, motion perception, and binocular vision work in the human brain. He\nco-authored the widely used textbook Visual Perception: Physiology, Psychol-\nis on the editorial boards of several research journals."
}