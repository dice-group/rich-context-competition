{
    "abstract": "Abstract\nThis paper builds off the Our Data Ourselves research project, which examined ways of understanding and reclaiming the\ndata that young people produce on smartphone devices. Here we explore the growing usage and centrality of mobiles in\nthe lives of young people, questioning what data-making possibilities exist if users can either uncover and/or capture what\ndata controllers such as Facebook monetize and share about themselves with third-parties. We outline the MobileMiner,\nan app we created to consider how gaining access to one's own data not only augments the agency of the individual but of\nthe collective user. Finally, we discuss the data making that transpired during our hackathon. Such interventions in the\nenclosed processes of datafication are meant as a preliminary investigation into the possibilities that arise when young\npeople are given back the data which they are normally structurally precluded from accessing.\n",
    "reduced_content": "Original Research Article\nHacking the social life of Big Data\nJennifer Pybus1, Mark Cote\n\u00b42 and Tobias Blanke3\n Keywords\nBig Data, data making, datafication, hacking, mobiles, youth\nIntroduction\nEver since the Snowden revelations in June 2013 there\nhas been a growing awareness of the depth and breadth\nof the data we generate and how it renders us into ever\nmore traceable objects of surveillance. The profoundly\nasymmetrical, political economic dimensions of the\nproduction and circulations of data have led to deeply\nproblematic power relations wherein every keystroke,\nwebsite visited or application downloaded are now rich\nsites of potential surplus value. With the proliferation\nof mobile platforms, digital footprints are expanding\nrapidly, especially those of young people.\nTeenagers between the ages of 13 and 17 are spending\nmore time on their mobiles and less time accessing social\nmedia platforms on their Internet browsers. Nielsen stu-\ndies show that mobile phone data usage of young people\nsuch as Facebook can now regularly gather data from\nover 500 million active users via their Messenger app, in\naddition to the 30 billion messages that pass daily\nthrough their recently acquired WhatsApp (Weisenthal,\npercent in the United States (Lenhart, 2015). And yet,\nlittle is known about the different ways in which apps\ngenerate and share data.\nWhen using an Internet browser on a laptop, desk-\ntop, mobile or otherwise, there are a number of avail-\nable plugins such as DisconnectMe or Lightbeam\nwhich, to varying degrees, reveal and in some instances\nblock third-party marketing and analytic companies\nfrom gathering personal social data.1 Browsers such\nas Chrome, Safari or Firefox \u00ad the primary windows\nonto the Internet from a desktop or laptop computer \u00ad\nalso offer methods in their preferences or plugins for\nblocking or clearing some of the unwanted cookies.\nBy contrast, while an app such as DisconnetMe\ncan be downloaded for users to retain some data con-\ntrol when browsing on their mobiles, for the most\npart, individual apps offer their users even less con-\ntrol over the data being gathered and/or shared\n(Han et al., 2012). Given the growing usage and cen-\ntrality of the smartphone in the lives of young people,\nwe see an urgent need to understand and unpack ques-\ntions around a) the extent to which data is produced\n1London College of Communication, University of the Arts London, UK\n2Digital Culture and Society, King's College London, UK\n3Digital Humanities, King's College London, UK\nCorresponding author:\nJennifer Pybus, London College of Communication, University of the Arts\nLondon, Elephant & Castle, London SE1 6SB, UK.\nEmail: jennifer.pybus@lcc.arts.ac.uk\nBig Data & Society\nReprints and permissions:\nsagepub.com/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons Attribution-\nNonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use, reproduction\nand distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nand shared by the apps that teenagers routinely down-\nload; b) how this routine extraction of data impacts\nhow young people negotiate and conceptualize digital\nprivacy; and c) what agentic `data-making' possibilities\nexist if users can either uncover and/or capture what\ndata controllers monetize and share about themselves\nwith third-parties. Thus our research focuses on what\nwe call big social data (Cote\nthat is, the data we produce through our mediated cul-\ntural and communicative practices both on the Internet\nand now on mobile devices.\nThe leaky mobile ecosystem\nAccording to Han et al. (2012), mobile applications\nor apps are an inherently `leakier' medium; that is,\nthey extract more personally identifiable information\ncompared to platforms that run off a desktop browser.\nThe configuration of the mobile's intensive data flow\nis in part rooted in the infrastructure of applications\nthat do not necessarily distinguish between first and\nclarify, the first party represents the app proprietor\nsuch as Facebook or Google or Candy Crush.\nConversely, the third-party represents a tracking body\nthat has been granted access to a user's data via the first\nparty, typically for commercial purposes (although not\nexclusively). Web browsers, unlike apps, entail proto-\ncological restrictions between first and third-parties,\nwhich have been established by the World Wide Web\nConsortium (W3C). However, Han et al.'s research\nsuggests that both Android and iPhone applications\ncan and do share the device and SIM identifiers \u00ad\nsuch as the user's phone number \u00ad thereby providing\npersonally identifiable information about the user to\nthird-parties. The problem, they argue, is that ``this\nmeans that mobile third-party tracking may be done\nwith identifiers that allowed activity to be linked to\npeople over long periods of time'' (2012: 3). In addition,\nthe mobile ecosystem offers what Han et al. refer to as\nsensor data, that is, sensitive data such as location,\nimages and audio from smartphones. The combination\nof both real world names and sensor data that can now\nbe easily gathered are allowing for even richer and more\nhyper individuated data profiles.\nComing to terms with the leakiness of the app eco-\nsystem is critical given that our time spent within these\nsiloed environments is only increasing. In the US, a\npercent of people's time spent online transpires on\nsmartphones, compared to on browsers (Perez, 2014).\nYoung people are in the vanguard of this trend, with 91\npercent of teenagers in the US regularly reaching for\nsmartphones and the ubiquitous connectivity that they\noffer (Lenhart, 2015). The increasing use of applications\non mobile devices does not, however, mean that they are\nunaware of the compromises required to manage their\ndigital privacy. Raines-Goldie (2010) and Marwick and\nBoyd (2014) have demonstrated how young people deal\nwith such challenges, and draw on highly developed stra-\ntegies to obfuscate aspects of themselves within the\npublic platforms they are using. In short, they have\nlearned to hide in the open.\nDespite looking for ways in which they can control\ntheir online identity, young people often feel caught in\nwhat has been referred to as a `privacy paradox'\nIn other words, there is a strong sentiment that levels of\ndata surveillance are simply `creepy' or rather too intim-\nate. Yet this sentiment notwithstanding, most appear\nresigned to pressing `agree' to the countless number of\n`terms and conditions' agreements, which function lar-\ngely to safeguard and legitimize the extraction and mon-\nPrivacy policies and terms and conditions, virtually\nnon-existent prior to 1998, have since become: ``the pri-\nmary legal instruments conveying representations to con-\nsumers regarding third-party data sharing'' (Kim, 2014:\ntrying to come to terms with this imbalanced relationship\nwherein the access users are granted to mobile apps\nultimately surrenders their social and cultural data to\nprivate interests. And yet, while users may feel ``out-\nraged'' or ``express dismay'', they proceed with ``business\nas usual'', going back to the same routine habits that only\nintensify those processes of extraction (2014: 8).\nAs Crawford and Boyd argue, it is not simply the\namount or size of the data being extracted that matters;\nrather, what requires our attention is the inherent\npotential value derived from its relationality with\nother data points (2012). Here, value is not simply\nbeing derived from the petabytes of information being\nextracted, instead it comes out of a newfound capacity\nto process large volumes of data from a multitude of\ndifferent structured and unstructured points, at increas-\ningly higher velocities (Kitchin, 2014). As such, the data\nthat is generated via our social relations online has\ngained a newfound depth and breadth of potential\ndue to its varied form, routine generation and new\nmodes of algorithmic processing.\nDatafication to data making\nMayer-Schou\n\u00a8 nberger and Cukier (2013) refer to datafi-\ncation as a process of the quantification of the world\ninto data that is in turn reconstituted into new forms of\nvalue. Their emphasis is on its potential for analysis,\npredictive and otherwise, that they believe provides pre-\nviously unavailable kinds of insights. We find datafica-\ntion useful for our research in identifying an emergent\n2 Big Data & Society\nobject of study: the quotidian data we generate. This\n`born digital' material is distinct from digitisation,\nwherein analogue cultural expression is converted into\ndigital form, the traditional focus of digital humanities.\nFor Mayer-Schou\n\u00a8 nberger and Cukier, datafication is\npresented primarily via the data-driven economy which\ncreates the conditions for mediated social and cultural\npractices and expression to be repurposed and trans-\nformed into a quantified format \u00ad unlocking the poten-\ntial to create something new that lies dormant within the\ndata. Google Books is an exemplar. Scanning millions of\nbooks, hence datafying hundreds of millions of data\npoints on every page that entered their vast digital arch-\nive, ultimately led to the creation of a new asset \u00ad Google\nTranslate. Value for Google was not a simple effect of\nthe data they extracted from all of the books they\nscanned; instead, it came through realising the relational\npotential within those datasets to create what is now the\nmost used translation platform in the world. Such a pro-\ncess is not necessarily forthcoming; for example, there is\nno Amazon Translate, despite their extensive digitisation\nof books for Kindle. In both instances, Google and\nAmazon had access to a massive archive of digitized\nand datafied books and yet only Google sought to lever-\nage the potential in their data sets into a new service that\nwould generate even more data.\nDatafication is therefore not a straightforward pro-\ncess that transforms analogue or digital material into\nquantifiable data for the production of surplus value. It\nis equally about recombination; therein finding expres-\nsions of relationality that are inherently possible among\nmutable data points. The multivalent variability of data\nthat allows it to be constantly reimagined, signals that\nvalue is not necessarily forthcoming through mere\naccess to a large data set. Instead, value is produced\nin the algorithms that are programmed to ask different\nquestions, across different data sets, allowing for new\nforms of recombination and reuse.\nDatafication, however, as presented by Mayer-\nScho\n\u00a8 nberger and Cukier suffers from what we call the\nresolution of verisimilitude. We intend a double articu-\nlation of resolution denoting i) the will and determin-\nation of those who assert that with enough data we can\nknow the world, and ii) the ever more finely granulated\ndata points that are meant to render it transparent and\ntrue. We question such faith in data plenitude, an\nn \u00bc all reality where empirical analysis is transformed\ninto an automated algorithmic effect as subsequent pre-\ndictive analytics become fact.\nOther interlocutors share such reservations. Van\nDijck, for instance, notes that the concept of datafication\nis ``rooted in problematic ontological and epistemo-\nas a neutral process. Instead, it is predicated on both\naccess and the capacity to generate new forms of value\nfrom preexisting and newly acquired data. Elsewhere\nCote\n\u00b4 has referred to this asymmetrical process as data\nmotility (2014). This denotes the way in which from the\nmoment we tap send, the data we generate richly circu-\nlates almost wholly outside of our control, yet remains\nprofoundly tethered to us, enabling and constraining our\nconditions of possibility.\nThe relevance of datafication to our work is two-fold.\nFirst, it demonstrates a new materiality of data wherein\ncheap memory, powerful processors, algorithms and\nmachine learning quantify our world and selves.\nSecondly, it raises questions of agency within this pro-\ncess. Mayer-Schou\n\u00a8 nberger and Cukier's framing of data-\nfication fails to move beyond the uncritical capture and\ntransformation of data for economic gain. However,\naccording to O'Neil (2013), this increasingly pervasive\nprocess needs to account for who is actually controlling\nand framing the data and for what purpose. In short,\nimportant questions which appear to be absent in\nMayer-Schou\n\u00a8 nberger and Cukier's account of\ndatafication.\nVis (2013) furthers this critique through a nuanced\nreckoning of the ways data is shaped by everything\nfrom application program interfaces (APIs) to data\nmining methods to researcher motivation. She notes\nhow these processes of `data making' create myriad\nchallenges for researchers both in terms of data access\nand quality. We concur that there is a need for further\ncritical examination of the methods and tools, espe-\ncially as a means for rebalancing agency within data-\nintensive ecosystems. Foregrounding `making data' in\nprocesses of datafication can highlight the asymmetry\nthat demarcates this socio-technical assemblage of\naccess and capacities, especially in terms of the ability\nto activate the transformational potentialities located in\nthe data itself. Whether it be a researcher accessing\na Twitter feed, or someone using their smartphone,\nidentifying the `whom' and `how' of data making is\nnot so simple.\nDatafication frames us as primarily passive gener-\nators in the social life of Big Data. Conversely, valoris-\ning `making data' opens the possibility of becoming\nmore active. In the context of datafication, the drive\ntowards `making data' can thus be seen as a strategic\nmode of agency that can arise if the subjects of datafi-\ncation are given tools to both understand and work\nwith the data that they produce. Innovative methods\ncan provide insight into that which is regularly being\ncaptured about users. Our research approach is but one\nof many possible ways of understanding the social life\nof the data we generate, wherein we might be able to\ncritically leverage the spirit of Jenkins' `participatory\nculture' (2006) into a realm of Big Data. However, we\ndon't simply want to celebrate our capacity to produce\nand widely share content, we need to gain clearer\nPybus et al. 3\ninsight into the extensive ecosystem in which our data is\nalready participating. The approach we took sought to\nenable the YRSers to become data-makers. Similar to\nNick Couldry (2014), we see a need for new kinds of\ninnovative research that examines how we can take up\nand use analytics more autonomously.\nData literacy can act as an extension and updating\nof traditional discourses around media literacy2 by\nrefocusing our attention to the material conditions\nthat surround a user's data within highly proprietary\ndigitised environments. Given the growing imbalance\nbetween those who produce data and those who pro-\nduce value from that data, there is a need to open up\nnew forms of digital literacies, such as privacy literacies,\ninformation literacies, code literacies, algorithmic lit-\neracies, database literacies and so forth.\nPuschmann and Burgess (2013) reach a similar end\npoint in their work on the politics of Twitter's ecosystem.\nIf a user does not understand how they can leverage their\nAPI, nor understand its technical constraints, then they\nare unable to effectively interact with the platform. As a\nresult, mainly corporate actors or those who are techno-\nlogically adept and/or possess the resources can meaning-\nfully engage with the data that is being collectively\nproduced. Similarly, we are interested in what happens\nwhen closed data becomes open, to reveal what young\npeople regularly generate but typically cannot access.\nIn trying to unpack the processes by which data is col-\nlected, brokered, aggregated, analysed, monetized and\nacted upon, we conceived of our project as an initial\nstep toward the development of a holistic approach to\ndata literacy. One that is able to both question how\nmeaning is constructed and (re)presented from the data\nbut equally seeks to unpack those opaque material pro-\ncesses that enable this capture and (re)presentation\nalongside the active (re)shaping of data infrastructures.\nMobile methodologies: Our Data\nOurselves\nWe have taken an interdisciplinary approach with a\nresearch team comprised of media and cultural theor-\nists, computer scientists, programmers and youth. The\ngambit has been that such a grouping would enable a\nrigorous exploration of our data to facilitate a critical\nintervention into the datafication of youth cultures via\nthe mobile phone. Our focus has been on the asymmet-\nrical power relations that are deeply imbricated in the\nstructural ways in which data is produced by and yet\nflows away from the user.\nTo begin, we set out to work with a very specific\ndemographic of young people between the ages of 14\nand 18 years old. The participants were all affiliated\nwith Young Rewired State (YRS). This non-profit,\nUK based organization brings together communities\nof youth who have an interest in coding. By using pro-\nject-focused learning, young people work in groups to\nimprove their coding, alongside both peers and men-\ntors. The members of YRS are also given opportunities\nto experiment with new technologies, software and\ncomputer languages while being actively encouraged\nto turn their ideas into real prototypes at different\nhackathon events. The pre-existing rich computer lit-\neracies that these young people possessed were seen as\nan asset to our project, enabling us to establish both a\nco-learning and research relationship.\nThere is a wide range of participatory research meth-\nods (cf. Reason and Bradbury, 2008) yet we use co-\nresearch in explicit reference to the politicised methods\nof conricerca, evoking the Italian operaismo, or `work-\nerist' movement dating back to the 1960s. The subse-\nquent conricerca or co-research method developed as\nboth the production of knowledge and organisation.\nOur method is also situated within the expansive field\nof action research given the opacity of the material\ninfrastructures that predominantly govern our data\nbeyond our understanding or control. Our partnership\nwith YRS marked an opportunity to examine the data\nproduced by mobile apps without reproducing those\nconditions which render individuals powerless against\nthe ubiquitous data sharing that transpires with eco-\nnomic and political third-parties. In short, we did not\nsimply want to use our subjects as data producers,\ninstead we wanted to imagine what a data literate sub-\nject might look like.\nCollaboration with our participants was therefore\ncritical. From the beginning we expected the YRSers\nto help us access the data they were generating within\ntheir mobile environments and then analyse what had\nbeen collected through the creation of different appli-\ncations. The endpoint, however, was not to realize a\ncompleted prototype but rather to observe their heur-\nistic process and approach, which could potentially\nfacilitate different pedagogical practices for those who\ndo not have the same technological expertise. We thus\nfound resonance with action based research methodol-\nogies, such as those described by Baym (2013) and\nKennedy et al. (2014) who specifically argue in favour\nof ``small-scale, qualitative studies [which] open up a\nspace for reflecting on the affordances of digital meth-\nods'' (p. 174). Similarly, Coleman's study of the myriad\ntechnologically savvy direct actions taken by Lulz\nand Anonymous (2011) points to the creative possibi-\nlities of hacking.\nAs a first step, we provided 20 young participants\nwith smartphones, a six-month data plan and created\nan app called the MobileMiner. The app was designed\nto learn about the data being generated by both the\ndevices and applications that our participants were\nusing. While we were aware that most of our participants\n4 Big Data & Society\nwere also using their pre-existing mobiles, we hoped that\nthe free data plan we provided would entice them to use\nour phones. Ultimately, given the exploratory nature of\nour project, we were more focused on the quality, as\nopposed to the quantity, of what could be gathered\nand analysed. That being said, to account for this dis-\ncrepancy of mobile use, we asked our participants to\nkeep tumblr media diaries to investigate the apps they\nwere regularly using (regardless of the device) and to\nascertain their perception of the amount of time they\nthought they were spending on their devices. In addition,\nwe held two hackathons; the first explored ways of\nimproving the MobileMiner app, and the second allowed\nour participants to work with the data that our applica-\ntion had collected from their devices.\nIn addition, we divided all our research participants\ninto groups and held three, two hour focus groups at the\nbeginning of the project. The aim of these sessions was\nto a) establish relations of trust and b) gain a broad sense\nof how our participants view, understand and negotiate\ntheir privacy online. Additionally, we conducted inter-\nviews during and after the second hackathon to observe\nthe individual's reaction once presented with their per-\nsonal data cache amassed by the MobileMiner app and\nthen later to gain a clearer understanding of the proto-\ntypes they constructed.\nMobileMiner: Collective construction\nof research devices\nThere were two primary deliverables from our co-\nresearch: a data-gathering app and the data itself. The\nMobileMiner application we created was initially\ndownloaded onto the Android smartphones we gave\nto our participants. It was designed to gather the data\nwhich is most typically harvested by apps. The applica-\ntion was always conceptualized as a data-making tool\nthat could eventually be used outside of our research\nproject and can be found on GitHub for free download.\nTo ward off `creepy' surveillance and enable greater\nprivacy for our co-researchers, they had the autonomy\nto turn on and off the app as they wished and thus were\nnever forced to have their data mined.\nWe envisioned our application as a specific contri-\nbution to the growing number of open source tools that\nare making visible the dynamic ways in which a user's\ncultural practices and sociality become datafied. It's\nfunction was to collect in- and outgoing communica-\ntions from the smartphones, including information on\nthe total amount of data sent and app network activity,\nalongside location information and identifiers. We\nwanted the application to function as a kind data spy,\nthereby examining the frequency at which apps rou-\ntinely harvest data. The approach we undertook is\nused by commercial providers and has the advantage\nthat it does not require permissions granted by the user\nwhen the app is installed. We decided early to not be\ntoo aggressive about tracking the app behaviour and\nexcluded, for instance, direct access to GPS informa-\ntion on the phone. Instead, we used opencellid.org to\nlink our app to the cell tower location database.\nBuilding trust with our co-researchers factored more\nstrongly into our research design then maximising the\nharvesting capacity of the MobileMiner. Furthermore,\nin contrast to surveillant-modes of maximum data\nscooping, we wanted to find out what non-aggressive\nmodalities of datafication could yield.\nThe second research deliverable co-developed with\nthe YRSers was the actual data that was collected via\nthe MobileMiner app. We envisioned this as part of\nwhat a big social data commons could look like, insofar\nas it was anonymised but open to exploration and cre-\native use by our co-researchers. Data harvested from our\nmobile devices almost invariably ends up in proprietary\ndatasets over which we have no access. In contrast, we\nwanted to explore an alternative infrastructure. To do\nso, we used a Comprehensive Knowledge Archive\nNetwork (CKAN) platform, an open source repository\ndeveloped by the Open Knowledge Foundation, as the\ncore element of an open data ecosystem.\nThe CKAN instance was updated at regular intervals\nfrom a local database on the mobile phone via the\nMobileMiner app. Finally, we took the innovative\napproach of packaging the CKAN data together with\na standard toolbox so that this prototype of a big social\ndata commons could be worked over in a virtual\nmachine that is free to download from our website.\nOnce both the MobileMiner and CKAN were in place,\nwe started a controlled experiment to receive data from\nour participants over a six-month period. We returned\nthis to our co-researchers during the second hackathon\nfor creative inquiry.\nFocus groups: From individual agency\nand control to group privacy\nThe focus groups revealed that most of our co-research-\ners are deeply aware of the compromises involved when\nit comes to managing their digital privacy. All of the\nteenagers we spoke with know that their data is being\nroutinely mined. At issue, however, is not the know-\nledge of data extraction but rather what happens to\nthis information once it moves beyond their reach.\nReactions among our participants were varied. Kylie,\nfor example, spoke out at length about her frustrations\naround the monetization of data:\nThe problem with this generation is that we are far\nmore scared of the individual, you know the pedophiles\nand the online bullies rather than corporations. What\nPybus et al. 5\nwe are not taught about is that fact we shouldn't be\nallowing big corporations like Google and Facebook to\nhave access to our personal details.\nIn fact, she was so bothered by the privatization of data\nthat she and her friends had refused having a\nFacebook, Instagram or Twitter account. Conversely,\nmost of the other participants showed far less concern.\nJacob put his thoughts the most succinctly: ``Perhaps\nthe most surprising thing is just how little we care about\nthat!'' (in relation to the growing number of third-parties\nmining personal data), followed by a very animated\ndiscussion whereby others in the group confirmed and\nreiterated his opinion.\nJacob's comments, however, need to be taken into\ncontext. As one of the stronger coders in the room, he\nalso expressed how important it was to have control over\nthe technologies he was using; a sentiment that was\ntaken up by almost everyone we spoke to. According\nto Anna (which garnered a number of nods in focus\ngroup A):\nBeing of this generation and being tech savvy we have\nsome control because we know how to have control,\nwhereas I know that my Mum doesn't have any\nidea. . .We know we can control our privacy and a lot\nof people do but then a lot of people also go and they\nare just using the technology but don't actually under-\nstand how it works.\nControl, within this context, links directly with Anna's\nsense of agency that is bolstered by her intimate know-\nledge of how to use and manipulate the technologies\nthat she is engaged with. Overall, we would summarise\nour findings on agency and control over privacy as fol-\nlows: i) a desire for control over messages being sent\nabout oneself; ii) control over a message in relation to\npeer groups \u00adthus it mattered more if a close friend\nuncovered a bad photograph posted on Instagram\nthen a complete stranger; and, iii) a desire for better\nunderstanding of the technological affordances of a\nmedium.\nWe observed the relationship between the desire for\nagency and control and technological literacies playing\nout in a number of different ways for our participants.\nFor example, several of our co-researchers actively\nobfuscated the data being captured about themselves,\nmost notably through the routine removal of Google's\ngeolocation data from their mobile browsers. The tac-\ntics used to protect their privacy \u00ad `unmaking data' \u00ad\nranged from deleting metadata that reveal geolocation\nin photographs, deleting accounts, withholding per-\nsonal information such as addresses, setting up proxies\n(one participant claimed he had set up seven proxies on\nhis mobile phone) and using alternative open sourced\nplatforms that run on Linux. What these strategies\nunambiguously revealed for this group of young\npeople is the inherent confidence that comes out of\ntheir various technological literacies.\nMaintaining digital privacy might be somewhat\neasier for our participants, but if their peer groups\nwant to use a leaky app, we discovered that most of\nour participants will use it too. Phoebe laughed, recall-\ning when she had tried to get her friends to take up an\nopen source alternative to Skype. She quickly\nabandoned these efforts because her friends found this\nplatform too difficult and cumbersome to use. Despite\nhow effective this other platform was at preventing\ndata from being tracked, she went back to Skype. She\nwent on to recall why she never stayed on `Diaspora', an\nopen-source, decentralized social network that has tried\nto provide users with control over their data. When her\nfriends again refused to migrate, she remained on\nFacebook. So while she would have preferred to use\nthis alternative network, she elected to remain where\nher friends were. For her, privacy is arguable not inher-\nently individual, but, rather, far more collectively under-\nstood. A similar sentiment was expressed by David\nwhen he was talking about using the privacy settings\non Facebook: ``it's kind of herd thing, you've all got\nto do it otherwise, one person is in trouble.'' Again,\nprivacy is not simply about him but about collective\nchoices that are made by his peer group.\nOften, when it comes to online privacy, the focus has\nremained on what the individual does or should do,\nsuch as in Livingstone's study on teenagers in the age\nof social networking (2008) that assesses privacy\nthrough the lense of risk assessment. Later, she expands\nthis work with another study performed with\nLivingstone et al. (2014), wherein their findings focus\non the identity management techniques of EU children.\nConversely, Boyd and Marwick's (2011) work on priv-\nacy explores the various strategies that young people\nhave invoked to maintain control within a networked\nenvironment. Their findings suggest that on-line priv-\nacy does matter significantly and is observed through\nthe paucity of ways in which their participants had\nlearned to conceal information from undesirable inter-\nlocutors while remaining visible to their peer groups.\nWhat Boyd and Marwick do not explicitly mention,\nbut what our research suggests, is that there are also\ninherent group dynamics making it possible for these\nyoung people to hide in the open and maintain some\ndegree of control over the content they have chosen to\ncirculate within the wider domain. Seeing the dynamics\nof privacy as being rooted in a collective, based on the\ncultural norms that have been established by a peer\ngroup, is an interesting finding with practical and the-\noretical implications, particularly when it comes to\npedagogical approaches to data literacy.\n6 Big Data & Society\nHackathons: Making tools\nOur hackathons draw on the digital humanities trad-\nition of `critical making' as complementary to `critical\nthinking'; that is, as a material form of critique which is\nboth `external' and `community-oriented' (Svensson,\nto discuss all of the tools and prototypes that were\ncreated during our second hackathon, it is instructive\nto offer a brief overview of what some of our coders\nwere able to produce when given access to their data on\nthe CKAN instance. The challenge with our methodo-\nlogical approach lies in its demand for specific techno-\nlogical competencies to manipulate the data that we\nwere able to provide. Indeed, how can a user participate\nin building an open and transparent digital commons if\nthey cannot confidently engage with platforms at the\nlevel of code, algorithms and databases? There is no\ncomprehensive or immediate way to meet this chal-\nlenge. Nonetheless, we anticipated that there was\nmuch to learn from the technologically savvy young\npeople we worked with.\nHere we can present some relevant examples. Phoebe\ncreated what she referred to as `sous-sousveillance' of\nthe apps she was using. This approach was inspired by\nthe initial observations that revealed how some of the\napplications being used by our participants were\nextracting significantly more data than others. For\nexample, the MobileMiner registered that three of our\nYRSers (Kylie, Edward and Julian) were playing a\ngame entitled: `Don't Tap the White Tile,' which was\nperiods of 21, two and three days, respectively.\nAccording to our analysis, the frequency at which\ndata was exchanged between this app and the server\nis supported by commercial studies, which report that\nup to 95% of mobile apps see similar patterns of use\n(Boris, 2013). However, these data patterns are in stark\ncontrast to Kylie's interaction with another game: `The\nLine-Keep In,' a simple app involving the navigation of\na dot through a vertically scrolling maze.\nOn closer inspection of the code, the game uses vari-\nous tools to gather deep statistics and push user mes-\nsages. Permission to access player GPS location is\nrequested, even though the Mobile Country Code of\nany device's last connected cell tower would be suffi-\ncient to localize advertisements to the player's country.\nDespite the game's simplicity, her device called home\nactivity registered every day (Blanke et al., 2014).\nThis number is notably higher than the other applica-\ntion we observed and raises questions in relation to\nthe structural differences between the apps users regu-\nlarly download.\nEquipped with the data from MobileMiner, Phoebe\nwanted to consider what constituted a leaky app.\nShe therefore tried to create an application that could\nsonify what she called the ``attention grabbing-ness of\napps . . . so you could tell immediately which were worse\nfor calling home.'' To clarify, the term calling home\nrefers to when an application accesses its server on\nthe Internet, presumably to relay personal and or\nGPS data accumulated from the user's smartphone\nand/or other applications. The MobileMiner app was\ndesigned to track the frequency by which data moves\nbetween the user and any given downloaded app. Our\nchallenge, however, arose in determining what, specif-\nically, passes between the mobile and the app's server.\nNevertheless, the data that we did procure was enough\nto facilitate Phoebe's hack on the ``noisiness of apps.''\nUltimately, she wanted to create an application that\ncould listen to the data as it moves from an individual\nphone to a server. She therefore assigned tones and col-\nours to correlate with the frequency of data requests that\nare routinely made by apps. Had she completed this\nhack, her app would have generated brighter and more\ngrating sounds to coincide with the leakier and more\ninvasive apps found more broadly on a user's device.\nWhen asked why she wanted to turn the data into\nsounds and colours, Phoebe told us that these kinds of\nvisualizations were in many respects more accurate:\nMost people would prefer this to numbers on a screen\nor paper, as it's a lot more jarring for the non-savvy, as\nsome could say that higher, louder tones are uncom-\nfortable, whereas seeing numbers is relatively meaning-\nless unless you know the context . . . This could break\ndown the complicatedness for the end user . . . It would\nbe great if you could listen to a list of apps, to find the\ntones, to find the ones that are potential problems.\nThe tool she set out to create was meant to easily draw\na user's attention towards the leakiness of different\napps, regardless of their technological expertise. This\nis but a small example of the kinds of creative and\ncritical possibilities that might emerge when users\nhave access to their data, in this case via a CKAN\ninstance. Subsequently, Phoebe's hack reflects both\nher strong political engagement and a desire to create\ntools that might engage others:\nFar too many people don't understand quite how much\nthey are giving to companies and how much this data is\nworth to them especially when the privacy policies are\nshady at best. And when you can't have members of the\npublic check what the Facebooks and Googles are\ndoing inside of these apps and with the data behind\nclosed doors then it becomes very easy for them to\nexploit the user. After all, data is the new currency\nand with the amounts these companies have they\ncould buy anyone.\nPybus et al. 7\nAgency, here, lies in having more transparency in the\nability to work on, process and transform the materiality\nof datafication, elements which typically move outside\nthe user's knowledge or control. The sonification tool\nrepresents a creative possibility in a data literacy toolkit,\nfostering resistance by illuminating those covert `sous-sur-\nveillance', data mining practices that sustain new economic\nand algorithmic relations. Tom's hack also examined the\nvalue of collective surveillance/sous-surveillance prac-\ntices. However, his interest lay in the frequency of app\nactivity, and whether there was a correlation between\napp usage and the amount of information being relayed\nto a server.\nTom used the CKAN instance data to develop a\ngraph generating tool to demonstrate when and for\nhow long our participants were using the Twitter,\nFacebook and Facebook Messenger app. More specif-\nically, he wanted to know what days of the week these\napps were being used, alongside the frequency and\ntimes in which they were accessed. He then cross refer-\nenced these with the number of notifications that the\napps sent back to their home servers. By so doing, he\nasked three questions of the data: 1) Does using an\napplication result in an increased number of notifica-\ntions? 2) Is there a day of the week that appears to\nmake the user more vulnerable to the app leaking? 3)\nIs there a time a day that makes the user more vulner-\nable to the app leaking? His end point was to visualize\nand see how this might change over time.\nWhile Tom was less concerned about the appropri-\nation of his data for commercial use in the focus group,\nit remained important to quantify and qualify his social\nmedia usage, again echoing those discourses discussed\nearlier around control. Yet, instead of tracking the\nmaterial body's movement through space and time,\nTom wanted to grasp his movements within those digit-\nally networked social media environments. He imagines:\nMaybe in the future this could work on a daily basis\nover months and years rather than just a week. We\ncould see how social media is used more on important\ndays such as during big events. For others it could also\nbe used for statistical analysis along with other social\nmedia datasets to create a wider picture of what we do\nonline.\nSimilar to Phoebe, Tom wants to have access and con-\ntrol over his data to better understand his data profile.\nHowever, this is not simply about having more open\ndata3 but instead, to develop more nuanced ways of\nunderstanding his own personal data production in\nrelation to his peers. Here he states:\nWhile I agree with open datasets, I don't think that\ndata should be taken without permission \u00ad people\nshould have control over their data, anonymous or\nnot, and if anything is to be done with it it should be\nopen to all rather than kept by companies.\nWhen we think about how data literacy might be devel-\noped through further research, we are drawn to the\nempowerment that comes from gaining access to what\nwe collectively generate. For these coders, agency began\nwith their ability to manipulate and make something\nfrom the entire set of data that the MobileMiner app\ngathered from all of our participants' smartphones in\nthe CKAN instance.\nConclusion\nThroughout the project, the active participation of the\nYRSers has always been paramount. Echoing Kelty\n(2008), we tried to facilitate the development of a recur-\nsive data public by practically modifying the material\ninfrastructure of datafication to critically engage\npower\u00adknowledge relations. Our research shows that\nthere is tremendous untapped potential in the general\nintellect and technical practice, not just among our teen\ncoders but in the figure of the data generator who wants\nto be in control and, more importantly, seeks to under-\nstand the data they collectively generate.\nFor us, a recursive data public is one with aug-\nmented critical data making capacity. We therefore\nsee our contribution in two ways: The first lies in creat-\ning open social and cultural data sets that are accessible\nfor critical and creative use by both researchers and the\ngeneral public \u00ad an area of research that we are cur-\nrently pursuing, as are others. Some, for example, are\nexploring the potential of blockchain technology, the\n`distributed ledger' underpinning BitCoin that may\nfacilitate new forms of digital commons (see Bollier,\nIaconesi and Oriana Persico, are building a ubiquitous\ncommons;4 that is, a space calibrated by new techno-\nlogical, legal and social protocols which assure greater\nuser control \u00ad a sentiment that strongly resonates with\nour empirical research.\nOur second contribution is to further develop non-\nprescriptive modes of interdisciplinary research, includ-\ning but not limited to hackathons and workshops. Our\nproject demonstrated the enriching and critical value\nforthcoming from working with and learning from\nyoung coders. More research is required to explore a\ncollective understanding of digital privacy, in addition\nto innovative digital methods that can further unpack\nthe mobile ecosystem. The realm of datafication is\nopaque; metaphorically we would like to imagine\nattaching radio-frequency identification (RFID) tags\nto granular data points and tracking their flow through\nthe social life of data which drives predictive analytics,\n8 Big Data & Society\ncircuits of consumption, business intelligence and state\nsurveillance. More collective interdisciplinary methods\nthat engage our contemporary technological condition\nbeyond the enclosures of platforms, apps and user inter-\nfaces are required. Moving forward, if we want to\ndevelop new tools and methods to enhance the active\nparticipation of users, then we must carefully consider\nhow we can both make and unmake data. The sous-\nsurveillance and social media quantification tools are\nbut two examples meant to highlight the possibilities\nthat can exist if users have access to their own data.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with\nrespect to the research, authorship, and/or publication of this\narticle.\nFunding\nThe author(s) disclosed receipt of the following financial sup-\nport for the research, authorship, and/or publication of this\nNotes\n1. The term is used loosely here, as more often blocking\nthird-parties or cookies ultimately means that the user\nwill then not have access to the website.\n2. Media literacy here refers to a large body of work in\nCultural and Media Studies that has been aimed at build-\ning various tools to empower individuals to think critically\nabout how meaning gets sedimented and in turn how the\nworld around them is constructed. The end point is to\nempower individual subjects to understand this process\nso that they can shape their own identity and, as Kellner\nand Share argue, ``transform the material and social con-\n3. For a more comprehensive critique of open data initiatives\nplease refer to Rob Kitchin's work (Kitchin, 2013).\n4. cf. http://www.ubiquitouscommons.org/\nReferences\nAcquisti A and Grossklags J (2005) Privacy and rationality in\nindividual decision making. IEEE Security and Privacy 3:\nBaym N (2013) Data not seen: The uses and shortcomings of\nsocial media metrics. First Monday. Available at: http://\nBlanke T, Greenway G, Pybus J, et al. (2014) Mining mobile\nBollier D (2015) The blockchain: A promising new infrastruc-\nture for online commons, news and perspectives on the\ncommons. In: David Bollier, 3 April. Available at: http://\nbollier.org/blog/blockchain-promising-new-infrastructure-\nBoris C (2013) Twenty-two percent of mobile apps are only\nused once. Marketing Pilgrim, 6 September. Available at:\npercent-of-mobile-apps-are-only-used-once.html (accessed\nboyd D and Marwick AE (2011) Social privacy in networked\npublics: Teens' attitudes, practices, and strategies. A\nDecade in Internet Time: Symposium on the Dynamics\nof the Internet and Society. Available at SSRN: http://\nColeman G (2011) Anonymous: From the Lulz to collective\naction. The New Everyday: A Media Commons Project.\nAvailable at: http://mediacommons.futureofthebook.org/\ntne/pieces/anonymous-lulz-collective-action (accessed 15\nCote\n\u00b4 M (2014) Data motility: The materiality of big social\nCouldry N (2014) Inaugural: A necessary disenchantment:\nMyth agency and injustice in a digital world. The\nCrawford K and Boyd D (2012) Six provocations for big data.\nEgele M, Kruegel C, Kirda E, et al. (2011) PiOS: Detecting\nprivacy leaks in iOS applications. NDSS. Available at:\nhttps://www.iseclab.org/papers/egele-ndss11.pdf (accessed\nEnck W, Gilbert P, Chun B-G, et al. (2010) TaintDroid: An\ninformation-flow tracking system for realtime privacy\nmonitoring on smartphones. OSDI. Available at: http://\nstatic.usenix.org/event/osdi10/tech/full_papers/Enck.pdf\nHan S, Jung J and Wetherall D (2012) A study of third-party\ntracking by mobile apps in the wild. Report, University\nof Washington, US, 1 March. Available at: ftp://ftp.cs.\nJenkins H (2006) Convergence Culture: Where Old and New\nMedia Collide. New York: NYU Press.\nKellner D and Share J (2005) Toward critical media literacy:\nCore concepts, debates, organizations, and policy.\nDiscourse: Studies in the Cultural Politics of Education\nKelty CM (2008) Two Bits: The Cultural Significance of Free\nSoftware. Durham: Duke University Press.\nKennedy H, Moss G, Birchall K, et al. (2014) Balancing the\npotential and problems of digital methods through action\nresearch: Methodological reflections. Information,\nKim N (2014) Three's a crowd: Towards contextual integrity\nin third party data sharing. Harvard Journal of Law and\nKitchin R (2014) Big data, new epistemologies and paradigm\nshifts. Big Data and Society April\u00adJune: 1\u00ad12.\nKitchin R (2013) Four critiques of open data initiatives. In: LSE:\nThe impact blog, 27 November. Available at: http://blogs.\nLenhart A (2015) Teens, social media and technology over-\nview 2015. The Pew Research Centre, 9 April. Available at:\nPybus et al. 9\nLivingstone S (2008) Taking risky opportunities in youthful\ncontent creation: Teenagers' use of social networking sites\nfor intimacy, privacy and self-expression. New Media &\nLivingstone S, Mascheroni G and Murru MF (2014) Social\nnetworking among European children: New findings on\nprivacy, identity and connection. Herme`s. CNRS Editions.\nManovich L (2011) Trending: The promises and the chal-\nlenges of big social data. In: Gold MK (ed.) Debates in\nthe Digital Humanities. Minneapolis: The University of\nMinnesota Press. Available at: http://www.manovich.net/\nDOCS/Manovich_trending_paper.pdf (accessed 28\nMarwick A and Boyd D (2014) Networked privacy: How\nteenagers negotiate context in social media. New Media\nMayer-Schou\n\u00a8 nberger V and Cukier K (2013) Big Data. A\nRevolution that will Transform How we Live, Work, and\nThink. London: John Murray Publishers.\nNielsen (2011) New mobile obsession: U.S. teens triple data\nusage. Nielsen, 15 December. Available at: http://\nwww.nielsen.com/us/en/insights/news/2011/new-mobile-\nobsession-u-s-teens-triple-data-usage.html (accessed 28\nO'Dwyer R (2015) The revolution will (not) be decentralised:\nBlockchains, common transitions. Common Transition, 11\nJune. Available at: http://commonstransition.org/the-\nrevolution-will-not-be-decentralised-blockchains/\nO'Neil C (2013) The rise of big data, big brother. Mathbabe, 2\nOsborn C (2012) Teenagers: Mobile gaming, apps and data\ngreed. Znet, 26 March. Available at: http://www.zdnet.\ncom/article/teenagers-mobile-gaming-apps-and-data-\ngreed-infographic/ (accessed 28 January 15).\nPerez S (2014) Majority of digital media consumption now\ntakes place in mobile apps. TechCrunch 21 August.\nof-digital-media-consumption-now-takes-place-in-mobile-\nPuschmann C and Burgess J (2013) The politics of Twitter\ndata. SSRN Electronic Journal.\nRaines-Goldie K (2010) Aliases, creeping and wall cleaning:\nUnderstanding privacy in the age of Facebook. First Monday,\n15(1\u00ad4). Available at: http://firstmonday.org/article/view/\nReason P and Bradbury H (eds) (2008) The Sage Handbook\nof Action Research. Participative Inquiry and Practice.\nLondon: Sage.\nShklovski I, Mainwaring SD, Sku\n\u00b4 lado\nLeakiness and creepiness in app space: Perceptions of priv-\nacy and mobile app use. In: Proceedings of the 32nd annual\nACM conference on human factors in computing systems -\nSpence E (2013) Smartphones kicks in the UK (with some\nhelp from Windows phones). Forbes, 4 April. Available\nteenage-smartphone-kicks-in-the-uk-with-some-help-\nSvensson P (2012) The digital humanities as a humanities pro-\nject. Arts and Humanities in Higher Education 11(1\u00ad2):\nvan Dijck J (2014) Datafication, dataism and dataveillance:\nBig data between scientific paradigm and ideology.\nVis F (2013) A critical reflection of big data: Considering APAs,\nresearchers and tools as data makers. First Monday, 10(2).\nAvailable at: http://firstmonday.org/ojs/index.php/fm/article/\nWeisenthal J (2014) Why Facebook bought WhatsApp in one\nchart. Business Insider, 19 February. Available at: http://\nwww.businessinsider.com/whatsapp-growth-2014-2?IR\u00bcT\nThis article is part of a special theme on Data and Agency. To see a full list of all articles in this special theme,\nplease click here: http://bds.sagepub.com/content/data-agency.\n10 Big Data & Society"
}