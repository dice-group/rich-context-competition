{
    "abstract": "Abstract\nThis paper explores bias in the estimation of sampling variance in Respondent Driven Sam-\npling (RDS). Prior methodological work on RDS has focused on its problematic assump-\ntions and the biases and inefficiencies of its estimators of the population mean.\nNonetheless, researchers have given only slight attention to the topic of estimating sam-\npling variance in RDS, despite the importance of variance estimation for the construction of\nconfidence intervals and hypothesis tests. In this paper, we show that the estimators of\nRDS sampling variance rely on a critical assumption that the network is First Order Markov\n(FOM) with respect to the dependent variable of interest. We demonstrate, through intuitive\nexamples, mathematical generalizations, and computational experiments that current RDS\nvariance estimators will always underestimate the population sampling variance of RDS in\nempirical networks that do not conform to the FOM assumption. Analysis of 215 observed\nuniversity and school networks from Facebook and Add Health indicates that the FOM\nassumption is violated in every empirical network we analyze, and that these violations lead\nto substantially biased RDS estimators of sampling variance. We propose and test two alter-\nnative variance estimators that show some promise for reducing biases, but which also illus-\ntrate the limits of estimating sampling variance with only partial information on the\nunderlying population social network.\n",
    "reduced_content": "Network Structure and Biased Variance\nEstimation in Respondent Driven Sampling\nAshton M. Verdery1*, Ted Mouw2, Shawn Bauldry3, Peter J. Mucha4\n1 Department of Sociology and Criminology, Population Research Institute, and Institute for CyberScience,\nThe Pennsylvania State University, University Park, Pennsylvania, United States of America, 2 Department\nof Sociology, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States of America,\n3 Department of Sociology, University of Alabama at Birmingham, Birmingham, AL, United States of\nAmerica, 4 Department of Applied Science, University of North Carolina at Chapel Hill, Chapel Hill, NC,\nUnited States of America\n Introduction\nRespondent driven sampling (RDS) is a popular means of sampling difficult to survey popula-\ntions. The ISI Web of Science database currently tags 642 academic articles with RDS listed as\nthe NIH RePORTER database shows that the National Institutes of Health has awarded more\nthan $180 million to 448 projects and subprojects with \"respondent driven sampling\" as a\ntopic [2]. Much of this popularity owes to the fact that RDS is a cost effective and rapid means\nof sampling hard to reach populations, which have received increased attention across the\nsocial and health sciences.\nCitation: Verdery AM, Mouw T, Bauldry S, Mucha PJ\n(2015) Network Structure and Biased Variance\nEstimation in Respondent Driven Sampling. PLoS\nEditor: Sergio G\u00f3mez, Universitat Rovira i Virgili,\nSPAIN\nCopyright: \u00a9 2015 Verdery et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which permits\nunrestricted use, distribution, and reproduction in any\nmedium, provided the original author and source are\ncredited.\nFunding: The authors are grateful to the Carolina\nPeter J. Mucha was supported by the National\nGeneral Medical Sciences. This research uses data\nfrom Add Health, a program project directed by\nKathleen Mullan Harris and designed by J. Richard\nUdry, Peter S. Bearman, and Kathleen Mullan Harris\nat the University of North Carolina at Chapel Hill, and\nThere are two key components to the RDS approach. The first concerns sampling and\nrecruitment, where respondents themselves are asked to find new survey participants through\ntheir social network connections with members of the target population, which are tracked\nwith anonymous codes or coupons [3]. This is encouraged through a dual incentive structure\nwhere recruiters are paid for participating in the study and for recruiting others. The second\ncomponent of RDS is inferential. Recruitment through social networks is complemented by a\nset of estimation techniques. Many of the estimation techniques used in RDS derive from the\nmathematics of random walks on graphs [4\u00ad6], because when RDS sampling and recruitment\nconforms to theoretical assumptions it mimics a simple random walk on an undirected, con-\nnected graph [7\u00ad9]. Under ideal conditions [10\u00ad12], RDS estimators of the population mean\nare asymptotically unbiased and generalizable to the population of interest, even absent a con-\nventional sampling frame [7,13].\nIn this paper, we focus on an aspect of RDS inference that has received only limited atten-\ntion in the literature to date: variance estimation. Most prior work on RDS inference focuses\non estimating population means. Some have noted that RDS assumes sampling properties that\nare not followed in practice (e.g., non-branching recruitment, sampling with replacement,\naccuracy of degree reporting, an undirected network), which can lead to substantial biases\n[10,13\u00ad16]. Others have evaluated the precision of RDS mean estimates, or, more precisely, the\nvariance in the sampling distribution of mean estimates (\"sampling variance\" [17]). An impor-\ntant recent finding is that RDS mean estimates may exhibit very high sampling variance com-\npared to simple random sampling (SRS), even when assumptions are met [18]. This is an\nalarming finding for practitioners who typically collect only one sample, because their mean\nestimates may be far from the population mean, even if the average value from repeated sam-\npling would converge to the population parameter.\nPrior work has not thoroughly addressed the accuracy of RDS estimates of sampling vari-\nance, however. There are two commonly used estimators of sampling variance in RDS, known\nas the Salganik bootstrap estimator (SBE) [19], which uses a bootstrapping procedure to obtain\nvariance estimates, and the Volz-Heckathorn estimator (VHE), which obtains variance esti-\nmates algebraically [7]. These approaches are quite similar, as both attempt to account for sam-\nple-induced correlations between cases that are close together in the referral network [14].\nSuch correlations lead the sampling variance of RDS to be larger than what would be obtained\nvia SRS, yielding design effects greater than one, much in the same way that the design effects\nof cluster-based sampling increase as a function of intra-cluster correlations between units\n[20]. It is possible to obtain an exact variance estimator for random walks by incorporating\ndata on the entire population's social network structure to account for these correlations [6];\nwe refer to this exact estimator as the Bassetti and Diaconis estimator. However, the RDS vari-\nance estimators lack data on the population network\u00adthey have only a sample\u00adand as such\nneed to approximate it. With a poor approximation, however, these variance estimators will be\nbiased.\nTo date, despite attention to the general issue of sampling variance in RDS, the actual esti-\nmators of sampling variance used by researchers have escaped evaluation. The most thorough\nprior treatment was by Neely [14], who diagnosed fundamental similarities between the SBE\nand VHE and limitations of both. Only two prior works have explicitly considered biased vari-\nance estimates in RDS [14,18]. Initial inquiries suggest that researchers should be wary when\nreporting confidence intervals and hypothesis tests based on commonly used RDS variance\nestimators. One study used simulated sampling and found that the SBE underestimates the\nempirical sampling variance using a set of school-based social networks [18], and two addi-\ntional studies report that known population means are frequently much larger than the upper\nbounds of confidence intervals produced using the SBE [21,22]. However, the generality of\nRDS Variance Estimation Bias\nKennedy Shriver National Institute of Child Health\nand Human Development, with cooperative funding\nfrom 23 other federal agencies and foundations. No\nfor this analysis. The funders had no role in study\ndesign, data collection and analysis, decision to\npublish, or preparation of the manuscript.\nCompeting Interests: The authors have declared\nthat no competing interests exist.\nthese findings is uncertain. Whether they are limited to the cases studied or are endemic\nremains an open question. In general, the sampling variance of random walks on graphs, and\nby extension other chain referral methods like RDS, depends on the specific network structure\nof the population under study which determines the closeness of nodes in the network, and,\nhence their covariance [6], and researchers do not know how closely the VHE or SBE can\napproximate it [14]. Because of this, it is important to assess why the RDS variance estimators\nmight not reflect the population sampling variance, and whether this is a general problem or\none that is primarily confined to specific types of \"problem\" networks.\nIn this paper, we diagnose when and why the current RDS variance estimators are biased\nand assess the generality of that bias across different types of networks. We build on Neely's\n[14] observation that both the SBE and the VHE rely, at a fundamental level, on a First Order\nMarkov (FOM) assumption. This assumption holds that RDS recruitment can be modeled as a\nFOM process on the nodal attribute of interest, where transitions between states depend solely\non the prior state and not a higher order sequence of prior states [23]. It is a convenient\nassumption for estimating RDS sampling variance, because a single RDS sample consists of a\nsequence of observed cases rather than the whole (population) network. Though the FOM\nassumption allows the VHE and SBE to estimate sampling variance from RDS sample data,\nresearchers have not evaluated whether it is justifiable or assessed the potential consequences\nof its violation.\nWe organize the remainder of the paper as follows. We first provide a technical discussion\nof variance estimation in link tracing samples. We next extend this to RDS, wherein we explain\nthe FOM assumption. We then offer two intuitive and general examples which demonstrate\nthe VHE is biased when the FOM assumption is unwarranted. The first of these is a proof of\nconcept and demonstrates the limitations the FOM assumption places on network structure.\nThe second offers a simple model of correlated homophily which shows the VHE underesti-\nmates sampling variance when the FOM assumption is incorrectly applied, a problem which is\nlikely to be quite general, at least whenever homophily based on an unaccounted for factor is\npresent. After this, we test five variables in 215 empirical social networks for violations of the\nFOM assumption. We find that it is violated in every case for the full network data. However,\nwhen simulated samples are drawn from these data, these samples pass the test for FOM in the\nmajority of cases. These results mean that, were a researcher in the field to have collected one\nof these simulated samples, she would not know, on the basis of the data collected, whether the\nRDS sampling variance estimators are likely to be biased. A fact which we confirm with our\nnext set of analyses wherein we test whether sample-level FOM violations indicate especially\npoor estimates of the sampling variance (we find that they do not). This is a grave situation for\nRDS, whose mean estimators are known to exhibit high-sampling variance, because it indicates\nthat researchers are unable to detect situations where mean estimates would have high variance\nand produce correspondingly large confidence intervals and other indicators of statistical\nuncertainty. Finally, we propose and test two modifications to the VHE that account for the\nbranching structure of RDS data and higher-order Markov transition matrices and afford\ncloser approximation of the actual RDS sampling process. These modifications improve sam-\npling variance estimation in RDS, but they do not offer a complete solution.\nThis paper contributes to the literature on drawing inferences from network sampling\ndesigns by demonstrating that RDS sampling variance estimators are biased because their\nassumptions are invalid for many social networks and not just \"unusual\" or \"difficult\" ones.\nOur results also defy heuristic notions that situations where RDS estimates will exhibit high\nsampling variance can be easily detected on the basis of observed homophily, perceptions of\nnetwork choke points, or sample level indicators of whether the network is FOM. They show\nthat homophily is not strongly correlated with biases in variance estimates, that even though\nRDS Variance Estimation Bias\nthe networks we examine do not have choke points they still have high sampling variance, and\nthat sample level indications that the network is not FOM give little indication of the extent of\nbias in estimates of sampling variance. Taken together, we show that RDS researchers using\ncurrently available estimators are unlikely to know\u00ada priori or even after RDS data has been\ncollected\u00adwhether a given network would exhibit high sampling variance. Such uncertainty\ncalls for further development of procedures for accurately estimating RDS sampling variance.\nSampling Variance Estimation in RWS vs. SRS\nWe can calculate nodal sampling probabilities at any sample size under a simple Markovian\nrandom walk model, which has the features of random referral, non-branching recruitment\nand with-replacement sampling assumed by RDS under ideal conditions [7,24]. These can be\nused to express the exact sampling variance of random walk sampling (RWS). In this section,\nwe contrast how this calculation differs from analogous estimation in simple random sampling\n(SRS); we rely on a similar discussion in reference [14].\nLet the matrix G represent a population's underlying social network, which we assume com-\nprises a single undirected connected component with at least one triangle. Ties between nodes i\nand j are indicated in cells Gij\nand Gji\nwith a value of 1, while unlinked nodes have values of 0\nin Gij\nand Gji\n. A person's degree measures how many ties they have; the degree of person i is\ngiven by d\ni\n\u00bc\nP\nN\nG\nij\n, where N is the population size. If D is a square diagonal matrix with 1/di\nalong the diagonal, the Markov transition matrix is defined as M = DG, where Mij\n= Gij\n/di\nis a vector containing probabilities of starting the random walk in each node of the network,\nM gives the probability of being in each node after one random walk step through\nthe network, and Ps\nMs gives probabilities of the random walk being at each node in the\nnetwork after s steps conditional on the starting probabilities [5].\nIt is convenient to express the transition matrix M in terms of its eigenvalue decomposition.\nEq (1) presents M in terms of a set of eigenvalues and corresponding eigenvectors:\nM \u00bc\nP\nN\nl\nk\nk\nk\nwhere k\nis the kth orthonormal eigenvalue of M ordered in terms of magnitude 1 . . . N, vk\nis\nthe kth eigenvector of a symmetrized version of M, and D is the diagonal matrix of inverse\ndegrees described above (primes denote the transpose operator). The eigenvectors of M will\nnot necessarily be orthonormal because M is not symmetric. However, as suggested by others\n[4], consider the matrix M\u00c3 = D-1/2MD1/2 where D is the diagonal matrix of inverse degrees\nand M is the Markov transition matrix defined above. This matrix is symmetric, as each cell\nM\u00c3\nij\n\u00bc Gij\ni\nj\n\u00bc M\u00c3\nji\n. M\u00c3 can be decomposed as M\u00c3 = VLV0 where L is a diagonal matrix con-\nsisting of the eigenvalues of M\u00c3 along the diagonal and zeros off diagonal, and V is a matrix of\nM\u00c3's eigenvectors. M and M\u00c3 share the same eigenvalues.\nA key feature of the eigenvalue decomposition of M is that the largest eigenvalue 1\nits corresponding eigenvector 1\nhas elements n\n\u00bc\nffiffiffiffi\np\nj\np\n, where j\n= dj\n/2m is the steady state\nprobability of being in node i, and m = 1/2i\ndi\nis the total number of edges in the network [4].\nAfter expressing M in terms of the eigendecomposition in Eq (1), we can find the transition\nmatrix after s steps:\nMs \u00bc\nP\nN\nl\nk\nk\nk\nh i\ns\n\u00bc\nP\nN\nls\nk\nk\nk\nwhere k\nis the kth (right) eigenvector of M\u00c3 = D-1/2MD1/2 (see note 3). Using Eq (2),\nwe see that lims!1\nMs \u00bc ls\nj\nbecause the first eigenvector has elements\nRDS Variance Estimation Bias\nv\n\u00bc\nffiffiffiffi\np\ni\np\n\u00bc\nffiffiffiffiffiffiffiffiffiffiffiffi\nd\ni\np\n[5]. Importantly, j\nis a probability vector where each element represents\nthe probability of being in node j in the steady state equilibrium. This is an important result\nbecause it means that the probability vector Ps\ndoes not depend on P0\nwhen s gets large. This is\nthe source of the argument that the particular seeds from which an RDS sample begins will not\nbias estimates from large RDS samples, provided the sample size remains a small fraction of\nthe population [10].\nSampling variance in RWS differs from the sampling variance of SRS in two important\nways. The first owes to non-uniform sampling probabilities. The effects of this are most clearly\nunderstood by considering the probability model underlying SRS in terms of the matrix algebra\nintroduced above. To get the sampling variance of SRS, we first arrange members of the popu-\nlation into a vector Y with elements Y = {y1\n, . . ., yN\n}, and define Y\u00c3 as its mean centered version\nY\u00c3 \u00bc y\n\u00c0\nP\nN\nyi\nN\n \n; \u00f0. . .\u00de; y\nN\n\u00c0\nP\nN\nyi\nN\n \n \n. We denote the sampling variance of mean esti-\nmates of Y from simple random samples as s2\nb\nm\n, which can be estimated with the population\nvariance and sample size as c\nb\nm\nS\nP\nN\ni\nN\n, where S indicates the sample size. If units are\nselected with given probabilities (in the vector , where i\ni\n= 1) instead of with equal probabil-\nities (1/N), then the sampling variance is defined as:\nc\nb\nm\n\u00bc\nS\nP\nN\np\ni\ni\n\u00bc\nS\n(Note that we present the matrix portion of Eq (3) in this way\u00adbreaking out the squared devia-\ntions into two pieces and taking the square roots of  \u00adto simplify algebra presented later).\nThe most important thing to note about Eq (3) is that it uses population values of Y\u00c3 and ,\ndespite being an estimate based on a sample. However, with a sample, researchers almost never\nknow these values, which must be approximated. Denote the elements selected in a sample of\nsize S as YSRS \u00bc fySRS\n; . . . ; ySRS\nS\ng and their sampling probabilities as pSRS\ni\n; assume\nP\nS\ni\nDefine the sample mean centered Y values of the elements selected in the sample as\nY\u00c3SRS\ni\n\u00bc ySRS\n\u00c0\nP\nS\nS\n \n; \u00f0. . .\u00de; ySRS\nS\n\u00c0\nP\nS\nS\nS\n \n \n. The estimated sampling variance on\nthe basis of the sample is then:\nc\nb\nm\n\u00bc\nP\nS\ni\ni\nEq (4) resembles the presentation in Eq (3), except that it now has sampled squared deviations\nY\u00c3SRS (based on the sample estimate of the mean) and sampling probabilities SRS (based on an\nestimate of these probabilities derived from the sample). Due to the Law of Large Numbers, Eq\n(4) provides an unbiased estimator of the sampling variance for SRSs where cases are selected\nwith probability  if S is large; in other words c\nb\nm\nb\nm\n. In the case of SRS, sampling probabili-\nties are uniform across units. In other sampling designs, however,  can take on other values,\nand, indeed, in random walk samples pRWS\ni\n\u00bc d\ni\n=2m as per above, where pRWS\ni\nindicates random\nwalk sampling probabilities.\nThe estimation of sampling variance in link-tracing designs also differs from the analogous\nestimator in SRS because if there is homophily\u00adthe tendency for individuals with similar attri-\nbutes to be friends with one another [25]\u00adon the basis of some variable, then individuals in the\nnetwork who are connected will tend to have similar values of that variable. As a result, values\nof the variable of interest from two cases in a random walk will be correlated if the number of\nsteps between them is small. This results in non-zero covariances between cases in link-tracing\nRDS Variance Estimation Bias\nstyle samples, which must be accounted for when estimating sampling variance. It is important\nto remember that homophily can exist on any sort of characteristic, observed (e.g., race) or\nunobserved (e.g., propensity to engage in risky behavior; [26]).\nThe variance of a RWS on a network can be analytically derived from the eigenvalue decom-\nposition in Eqs (2) and (3) [6]. First, working from Eq (3), we can express the population vari-\nance ((SRS)1/2Y\u00c3)((SRS)1/2Y\u00c3)0 in terms of an orthonormal eigenvector basis {vk\n: K = 1 . . . N},\nP\nN\nk\nv\nk\nk\n\u00bc\nP\nN\nk\n, where k\nis a scalar constant that maps the kth eigenvector of the transi-\ntion matrix M\u00c3 onto 1/2Y\u00c3. Note that n\nk\nk\nj\n\u00bc 0 because they are orthonormal.\nWith this, we can denote the covariance between the ith and jth step of a random walk on G as:\ncov\u00f0i; j\u00de\nRWS\n\u00bc\nP\nK\nk\nljj\u00c0ij\nk\nwhere k\nis the mapping of the variable Y\u00c3 onto the kth eigenvector of the transition matrix, k\nis the kth eigenvalue of the transition matrix, and |j - i| is the number of steps between the ith\nand jth cases sampled by the random walk [6]. In general the covariance between two steps of a\nrandom walk is affected by all three components: k\n, k\n, and |j - i|. Using Eq (5), we can write\nan estimate of the sampling variance of a size S random walk sample as the average of all the\npossible covariances among the population that the walk could take on G:\nd\nb\n\u00bc\nP\nS\nP\nS\ncov\u00f0i; j\u00de\nRWS\n\u00bc\nP\nS\nP\nS\nP\nK\nk\nljj\u00c0ij\nk\n\u00bc c\nb\nm\n\u00fe\nP\nS\nP\nS\nP\nK\nk\nljj\u00c0ij\nk\nWhen |j - i| = 0, this reduces to the estimated simple random sampling variance of Y, c\nb\nm\n. Eq\n(6) highlights that the sampling variance of a RWS will be greater than the sampling variance\nof a same sized SRS if the variable Y\u00c3 maps onto the eigenvectors such that the contribution in\nthe sum from the positive eigenvalues outweighs that from the negative eigenvalues.\nThe other critical difference between Eqs (6) and (4) is that the latter for SRS operates on a\nsample and estimates the sampling variance, while the former for RWS requires the underlying\nsocial network and dependent variable data from the entire target population. A researcher in\nthe field, for example, would be unable to use Eq (6) without knowing the entire social network\nconnecting individuals in the target population, which will obviously not be the case with a hid-\nden population. In the next section, we discuss the VHE, which is an approximation of the Bas-\nsetti and Diaconis estimator used by the RDS literature to estimate the sampling variance of a\nrespondent driven sample absent complete knowledge about the underlying social network.\nVariance Estimation in RDS\nIn RDS the researcher does not have data on the network itself, only data on the sequence of\nrecruitments that occurred and the characteristics of those recruited, i.e., a sample. We present\nthe VHE in the same framework as Eqs (3)\u00ad(6) above. The key difference between the VHE\nand the exact estimator of Bassetti and Diaconis discussed above is that the estimator devel-\noped by Volz and Heckathorn uses the patterning of recruitments and characteristics in the\nsample in place of the entire population network. Given a RDS sample on the population con-\nnected by the social network G, let YRDS 2 Y indicate the cases sampled from the Y values of\nRDS Variance Estimation Bias\nthe population. If Y is dichotomous, let the matrix C be a 2 \u00d7 2 matrix showing observed transi-\ntion probabilities among values of YRDS between respondents and those they referred to the\nstudy. If Qt\nis a 2 \u00d7 1 row vector indicating the probability that the Y value of the jth respondent\n(or jth \"step\" in the interview) is 0 or 1, then we can estimate the Markov transition probability\nbetween any two steps j and i of the survey using observed categories of the dependent variable\nrather than nodes in the network as we did in Eq (6) above:\nQ\ns\n\u00bc Q\nr\nCjj\u00c0ij: \u00f07\u00de\nWe can then estimate the covariance between the jth and ith steps by modifying Eq (5) as:\nd\ncov\u00f0j; i\u00de\nRDS\n\u00bc\nP\nk\nk\n\u00dejj\u00c0ij; \u00f08\u00de\nwhere the superscript VHE on alpha and lambda indicate that we are using  (the dependent\nvariable Y projected into the orthonormal basis) and  (the eigenvalues) from the eigendecom-\nposition of sample observed category transition probabilities from the 2 \u00d7 2 matrix C instead of\nthe population node transition probabilities from the N \u00d7 N matrix M\u00c3. This yields the VHE\nas:\nd\nb\n\u00bc c\nb\nm\n\u00fe\nP\nS\nP\nS\nd\ncov\u00f0i; j\u00de\nRDS\n\u00bc\nP\nS\ni\ni\nP\nS\nP\nS\nP\nk\nk\n\u00deji\u00c0jj; \u00f09\u00de\nwhere pRDS\ni\nis the RDS sampling probabilities. Connecting Eq (9) to the notation used in Volz\nand Heckathorn [7], we can write\nP\nS\ni\ni\nS\nP\ns\ni\nYRDS\ni\ni\nP\ns\ni\ni\n \nP\ns\ni\nYi\nP\nS\nP\nS\nCjj\u00c0ij\n \n, where Y\u00c3RDS\ni\nis the\nY value of the ith case selected mean-centered via the Volz-Heckathorn \"RDS-2\" mean estima-\ntor, pRDS\ni\nis the corresponding case's sampling probability, dRDS\ni\nis its degree, and Cjj\u00c0ij\nis the esti-\nmated transition probability between Yj,j 6\u00bc i\n= 1; this presentation can be found in\nP\nS\ni\ni\n\u00de2 is analogous to the estimated sampling variance of\nSRS (i.e., c\nb\nm\nP\ns\ni\nYRDS\ni\ni\nP\ns\ni\ni\nis the Volz-Heckathorn estimate of the sampling mean, and\nP\ns\ni\nYi\nP\nS\nP\nS\nCjj\u00c0ij\n \nis the expected correlation between sampled units if the pro-\ncess is FOM.\nUsing C instead of M equates to making the FOM assumption because it assumes the likeli-\nhood of transitioning between categories of the Y variable in question only depends on the cat-\negory of the currently sampled node, one of several assumptions in RDS variance estimators\ndescribed in detail in prior work [14]. Importantly, this is the same assumption made by the\nother commonly used RDS variance estimator, the SBE [14], which we evaluate via simulation\nlater in the paper. The SBE is defined in the literature [14,19] as using a bootstrap sampling\nprocedure to simulate synthetic RDS chains from the FOM approximation embedded in the C\nmatrix. Using C to approximate the node-specific Markov transition probabilities is a simplifi-\ncation, as pointed out by its developers [7]. It may be a reasonable one to make because the M\nmatrix is unknown; however, the validity of this assumption has rarely been examined or tested\nin the RDS literature [14]. In the remainder of the paper, we explore the implications of the\nFOM assumption in greater detail.\nRDS Variance Estimation Bias\nWhat Happens to the VHE when FOM Is Violated?\nIn this section, we provide several examples of what happens to RDS variance estimation via\nthe VHE if the FOM assumption is violated.\nIllustration 1: Intuition\nWe begin with an illustration that highlights how the relationship between sampling variance\nand sample size differs between FOM and non-FOM networks when using random walk sam-\npling (RWS). This example is intentionally stylized so readers can see what is occurring and\nintuit the effects of network structure on the VHE of RDS sampling variance. Fig 1 shows two\nnetworks, A and B, where clear circles indicate nodes where Y = 1 and dark circles indicate\nnodes where Y = 0. These networks share several features: they have the same size, density, and\ndegree distributions. In addition, Fig 1 was intentionally constructed so that both networks\nwould have identical transition probabilities between categories of Y. This is important as it\nmeans that both networks have identical levels of dyadic homophily and that they share the C\ntransition matrix used by the VHE; that is, C\nA\n\u00bc\n\" #\n\u00bc C\nB\n. Because C is identi-\ncal in these two networks, they will produce identical estimates of RDS sampling variance\nbased on the VHE as shown in Eq (9).\nHowever, there is one key difference between these networks: Network A is FOM with\nrespect to Y while Network B is not. This difference can be described in terms of the condi-\ntional probability of the current node's Y value given the Y values of prior nodes visited [23]:\nPr\u00f0Y\ns\n; Y\n; . . . ; Y\n\u00de \u00bc Pr\u00f0Y\ns\nEq (10) holds for network A, and therefore network A is FOM, while for network B it does not\nhold (see below for a test of whether a network is FOM). Does this difference in network\nFig 1. Networks with same degree distribution and proportion cross racial ties.\nRDS Variance Estimation Bias\nstructure matter for RWS sampling variance? Given that the VHE estimates of sampling vari-\nance for these two networks will be identical (because they share the same C matrix), if there is\na large discrepancy between these networks in terms of the empirical RWS sampling variance\n(i.e., population sampling variance), then it suggests potential problems with the VHE.\nFig 2 shows how large an impact network structure can have on the sampling variance of\nrandom-walk based designs and that the VHE cannot detect these differences. Because we\nknow the complete network structure, we can calculate the exact sampling variance of RWS\nestimates for these two networks using Eq (6). Alternatively, we can approximate it using the\nvariance in the distribution of proportion estimates produced by repeatedly sampling the net-\nwork with random walks starting from random points proportional to their stationary distribu-\ntion probabilities a large number of times; these approaches yield indistinguishable results.\nThe striking result in Fig 2 is that while the sampling variance in Network A (the FOM net-\nwork) approximates to the sampling variance of SRS as the sample size increases, the sampling\nvariance in Network B (the non-FOM network) is much higher at every sample size. More\nimportantly, while estimates from the VHE accurately describe the sampling variance of net-\nwork A, they fail to do so for network B (the hollow circles on the graph show the VHE esti-\nmates run on both networks A and B). In fact, the VHE estimates for network B are identical to\nthose obtained for network A, which makes sense as both networks have the same first-order\ntransition probabilities. In terms of design effects (the ratio of RWS sampling variance to SRS\nsampling variance, where 1 indicates they are identical), the design effect from sampling\ndesign effect of 29.2601 (the magnitude of this difference is roughly constant across sample\nFig 2. Sampling variances on Networks A and B from Fig 1, by method and sample size. Note: Like SRS, VHE produces identical estimates on\nnetworks A and B. For both networks, these estimates are identical to the population RWS sampling variance on A because network A is FOM.\nRDS Variance Estimation Bias\nsizes). In substantive terms, we can say that mean estimates based on RWS samples with 5,000\ncases from Network B will be more almost 15 times more variable than the same estimates\nfrom Network A, yet, even with perfect information, the VHE will estimate that they have iden-\ntical sampling variance. This finding is problematic for RDS because it indicates that if the\nFOM assumption is violated, researchers may have no idea whether their estimates of sampling\nvariance\u00adand, hence, their confidence intervals and hypothesis tests\u00adare accurate or not.\nIllustration 2: Generality\nThough Figs 1 and 2 indicate that the VHE may produce estimates that are quite far from the\npopulation sampling variance of a network if the network is not FOM, one may wonder\nwhether this result is produced by some feature of the two networks we considered. For\ninstance, these are low degree networks and Network B has \"choke points\" (i.e., few paths\nbetween otherwise well connected clusters; see below for a more formal definition), which\nmakes it the type of network that RDS heuristics suggest should be avoided (though, it is an\nopen question whether a researcher or respondents themselves will know that the network of a\nhidden population has choke points in it and thus should not be surveyed with RDS). Because\nof these issues, we now turn to a more general illustration showing that the VHE will be down-\nwardly biased\u00adi.e., underestimate the population sampling variance\u00adin all cases where there is\nhomophily on an unobserved variable that is correlated with the Y variable of interest.\nImagine a population composed of two groups categorized by a dichotomous Y variable\nwhich are connected via a social network but which exhibit homophily on Y. We wish to take a\nRWS or RDS sample to estimate the population proportion of Y = 1. In addition, imagine there\nis a variable, Z,\u00adunobserved by the researcher\u00adwhich organizes a portion of the social ties in\nthis network. As has been well documented, homophily exists on a wide range of dimensions,\nsome of which may not be observed or anticipated by researchers or even research participants\n[25,26]. In this case, Z indicates a propensity for forming cross-group ties: individuals for\nwhom Z = 0 only have ties with those within their Y group, while those for whom Z = 1 have\nties across Y groups. For instance, if Y indicated a dichotomous measure of race, then Z might\nindicate an individual preference for interracial friends. Other examples that may generate a\nlack of conditional first-order independence are given on page 75 of reference [14].\nFor the sake of simplicity, assume an equal number of people of each Y value in each of the\nZ groups, and that the total degree of each Y|Z combination is the same. The number of friends\namong and between the different Y|Z groups is depicted in Table 1. For example, there are H\nfriendships between people with different values of Y, while friendships among those with\nequal Y values are marked in Table 1 as either D, E, or F, depending on the shared Y value and\nTable 1. Algebraic representations of friendships between Y|Z groupings.\nAlter values\nNotes: Superscripts indicate no friendships in this cell because 1 Zego\n= 0 and Yego\nZalter\nand Yego\n; 3 Zalter\n= 0 and Yego\n.\nRDS Variance Estimation Bias\nthe whether the ego and alter share Z values and which Z value they have. Because the total\ndegree is the same for each Y|Z combination we have (D + E) = (E + F + H), ; D = (F + H).\nThe transition matrix M can be written as M \u00bc\n,\nwhere a \u00bc F\nand b \u00bc H\n. M represents a situation where there is heterogeneity in the\nlevel of dyadic homophily on Y. Individuals with Z = 1 form cross Y friendships, while those\nwith Z = 0 do not. Here Z can represent anything that causes heterogeneity in mixing between\nYs. Note that both of the assumptions underlying this example can be relaxed without affecting\nthe conclusions derived here. For example, we can allow for different numbers of people in\neach of the Y|Z combinations and we can allow the degrees to vary. We have tested numerical\nexamples under a variety of conditions (available upon request). The fundamental conclusion\nis the same, namely that homophily on an unobserved variable that is correlated with the\ndependent variable will lead to a biased VHE.\nIn contrast to the population transition matrix M, the VHE estimates sampling variance\nusing the sample estimated 2 \u00d7 2 transition matrix C as a function of the friendship propensi-\nties and the size of each group, C \u00bc\n\" #\n, where i \u00bc cross Y friends\ntotal friends\n\u00bc H\n\u00bc b\n. A criti-\ncal result is that C and M have different eigenvalues. Because it is dimension two, C has only\ntwo which are\n\" #\nwhen ordered by size. By contrast, M has four eigenvalues which are\n1 \u00c0 b \u00c0 a \u00fe\nffiffiffiffiffiffiffiffiffiffiffiffiffiffi\np\n1 \u00c0 b \u00c0 a \u00c0\nffiffiffiffiffiffiffiffiffiffiffiffiffiffi\np\nwhen ordered by size. Recalling Eqs (5) and (6), for the VHE to\naccurately estimate the sampling variance of Y via a random walk based approach like RDS, the\nsecond largest eigenvalues of these C and M would need to be equivalent. However, they are\nnot, which means that when a correlated unobserved variable structures the homophily on Y,\nthe VHE will not accurately estimate sampling variance. In fact, we can make a stronger claim\nin this case. Because \u00f01 \u00c0 b \u00c0 a \u00fe\nffiffiffiffiffiffiffiffiffiffiffiffiffiffi\np\n\u00de > \u00f01 \u00c0 b\u00de for all nonzero as and bs, we can say\nthat the VHE will always underestimate the true sampling variance with this kind of network\nstructure. This is a general result that compliments the intuition provided in Figs 1 and 2.\nThere we showed that a random walk on a FOM network will mix more slowly than a ran-\ndom walk on a network with a higher order Markovian structure, but that the VHE will not\nbe able to detect these differences. Slower mixing results in higher covariances between any\ntwo steps of a RWS or RDS sample drawn from that network, and, thus, higher sampling\nvariance of mean estimates and larger design effects. However, the inability of the VHE to\ndetect these differences\u00adits biasedness\u00admeans that researchers will understate their\nuncertainty.\nIllustration 3: Computational Examples\nWe now provide two concrete examples based on this illustration to demonstrate the effect of\nhomophily on correlated unobserved variables.\nRDS Variance Estimation Bias\nFor the first example, let E = F = H = 10, M \u00bc\nand\nC \u00bc\n\" #\n. In both transition matrices, the observed homophily between Y groups is\nidentical; that is, 16.7% of friendship ties are between those with Y = 1 and those with Y = 0.\nHowever, there is heterogeneity in the mixing between Y groups defined by the unobserved Z\nvariable. Individuals in the first and fourth row of M have no cross Y mixing, while individuals\nin rows two and three have twice the average Y mixing. In this example, the second largest\neigenvectors are .804 and .667 for M and C, respectively, indicating that a random walk on M\nwill reach equilibrium slower than a random walk on C. The standard deviation of a sample of\neffect = 4.88) for C. In other words, using the dyadic transition matrix C in place of M \u00adi.e.,\nusing the VHE\u00adresults in a substantial underestimate of the true sampling variance.\nAs a second example, let D = F = 100 and E = 10, M \u00bc\nand\nC \u00bc\n\" #\n. The second largest eigenvectors are .954 and .524 for M and C, respec-\n0.0887 (design effect = 3.15) for C. In this second example, the observed homophily across Y\ngroups is lower than what was shown in the first example; here, 23.8% of friendships are cross\ngroup. However, Z more fully structures the interaction of those within Y groups\u00adi.e., heteroge-\nneity in cross Y mixing\u00adand this results in a dramatically higher difference in design effects for\nSummary of VHE Bias\nThe model of homophily on unobserved variables presented in this section is purposively sim-\nple in order to make analytical results tractable. Nonetheless, the basic intuition should be\nclear: if there is clustering within categories of the observed dependent variables--such as is\nevident in matrix M of the second example above--then the VHE, which relies upon the\nobserved transition matrix between categories of the variable of interest, C, will exhibit down-\nward bias. The variance of a random walk is not just a function of dyadic homophily between\ndifferent categories of the dependent variable, as both M and C have the same level of dyadic\nhomophily but different design effects. In other words, it is network structure--not homophily\non the observed, focal variable per se--that affects design effects and biases RDS sampling vari-\nance estimators downward [14]. Moreover, the examples presented here likely underestimate\nthe role played by network structure as they focus on a simple set of networks and a limited\n4 \u00d7 4 category transition matrix rather than a node level transition matrix that would be found\nin a real network. Indeed, the sampling variance of our computational examples could be cor-\nrectly estimated by making a Second Order Markov assumption, but real world networks are\nunlikely to conform to that assumption as well. Below we test a modification to the VHE based\non a second order assumption and show that while it frequently outperforms the classic VHE,\nRDS Variance Estimation Bias\nit still does a poor job capturing the sampling variance of simulated RDS in empirical\nnetworks.\nThe fundamental point of this section was to show that if the FOM assumption is violated,\nas it is by the case of homophily on an unobserved variable, then the accuracy of the VHE\nderived estimates of RDS sampling variance are indeterminate, and will be downwardly biased\nunder rather general conditions. As illustrated in the these examples, unbiased RDS variance\nestimators are predicated on the network being well described by homophily on a single\nobserved category, and they are of little use when there is heterogeneity in the mixing among\nmembers of the groups defined by those categories. We now consider empirical data to evaluate\nthe generality of these problems.\nHow Often Is FOM Violated in Empirical Networks?\nIn this section, we ask whether researchers should generally expect networks to be well\ndescribed by homophily on a single dimension, or, more specifically, how often they should\nexpect the FOM assumption to be violated. The RDS literature has not explored this idea since\nits foundation [3]. We test the FOM assumption in 215 heterogeneous empirical networks\ndrawn from two separate datasets. We then outline the issues faced by the two most used RDS\nvariance estimators\u00adthe VHE and the SBE\u00adwhen they are applied to networks that violate\nFOM, as we find that most empirical networks do.\nData, Methods, and Measures\nMuch prior methodological work in RDS has used simulated data [7,10,27]; however, it is chal-\nlenging to accurately simulate all structural features found in empirical networks [28,29].\nBecause of this, we use data from the National Longitudinal Survey of Adolescent Health (Add\nHealth) [30] and the Facebook 100 datasets [31\u00ad33]. These networks have been used in simula-\ntion based studies of network sampling performance [11,18]. In all networks, we restrict our\nanalysis to individuals in the largest weakly connected components, and, in the Add Health\ndata, we ignore the directionality of ties and treat all nominations as reciprocal. We use 115\nnetworks from Add Health and 100 from the Facebook data set for a total of 215 empirical net-\nworks. In the Add Health networks, we test whether the FOM assumption holds for the follow-\ning three dichotomous variables: race (white = 1), gender (female = 1), and sports participation\n(yes = 1). We look at the validity of the FOM assumption in two variables in the Facebook data:\ngender (female = 1), and class year (freshmen = 1).\nThese data are faithful to real world network patterns [34,35]. More importantly, they con-\ntain a diversity of network structures, which makes them excellent candidates for assessing the\ncredibility of the FOM assumption in empirical networks and allows us to overcome criticisms\nthat have plagued prior simulation work in RDS, namely that the empirical networks studied\nwere too sparse, small, or contained \"choke points\". While these properties may characterize\nsome of the Add Health networks, the Facebook networks we examine are not so limited. The\nbest measure of choke points in a network is the average number of node independent paths.\nIn any connected component, a set of nodes exists that, if removed, would disconnect that\ncomponent. For a chain referral strategy to pass from one side of this nodal cutset to the other,\nit must pass through a node in this set. Menger's theorem [36] proves that the number of node\nindependent paths in a graph is equal to the size of the smallest nodal cutset, which has been\nused to define the structural cohesion of a network [37]. We measured the numbers of node\nindependent paths in the symmetrized largest connected components of the Add Health and\nFacebook networks used in this paper. Owing to the size of these networks and the computa-\ntional complexity of calculating the number of node independent paths amongst all dyads in a\nRDS Variance Estimation Bias\nnetwork, we estimate the number of node independent paths in each network based on random\nsamples of 10,000 dyads using maximum flow algorithms on the complete network. This pro-\nvides asymptotically unbiased estimates. The Facebook networks studied had an average num-\nmacro-structural features, in addition to the high average degree (FB = 51.640, AH = 6.971),\nsuggest that we study a substantial range of networks that are not limited by the heuristic\nnotion of choke points. Other relevant statistics are as follows. The largest connected compo-\nHealth, these numbers were 52\u00ad1,610 with a mean of 488. The proportions female in the Face-\nbook networks ranged from 0.24\u00ad1.00 with a mean of 0.54, while the proportions freshmen in\n0.95 with a mean of 0.56. In sum, the Facebook networks we examine are also quite large,\norders of magnitude larger than the Add Health networks.\nThe definition of a FOM process is as follows (see Eq 10 above): Pr(Ys\n, . . .,\n) = Pr(Ys\n) [23]. Given this, a sufficient condition that satisfies that the network\nis not FOM is:\nPr\u00f0Y\ns\n; Y\ns\nBy sufficient condition, we mean that if the preceding equation is true, then the network is not\nFOM. However, note that because this is only a sufficient condition, a failure to satisfy the pre-\nceding equation does not guarantee that the network is FOM. This makes it a conservative test:\nin cases where Eq 11 does not hold (i.e., the quantities are equal), the network may still not be\nWe test whether Eq 11 holds by estimating the following ordinary least squares regression\nwith robust standard errors for each of the variables of interest in each of the networks from\nthe Add Health and Facebook data sets:\nPr\u00f0Y\ns\n\u00de \u00bc b\n\u00fe b\n\u00f0Y\n\u00de \u00fe b\n\u00f0Y\n\u00de \u00fe b\n\u00f0Y\nwhere Pr(Ys\n) is the proportion of an ego's alter's alters with Y = 1, while (Ys-2\n) and (Ys-1\n) are\ndichotomous indicators of whether ego's or alter's Y = 1, respectively. Note that we include ego\nhimself as one of ego's alter's alters, which suffices to retain ego's alters who lack alters (i.e.,\npendants) in the sample, and which makes sense for the with-replacement process we study\nhere. The resulting regression model thus contains one observation for each edge in the net-\nwork (or referral in the sample, depending on whether the analysis is conducted at the popula-\ntion or sample level, see below). Though each ego will have several alters in the data, and we\nmake use of even more alters' alters in our definition of the dependent variable, the use of\nrobust standard errors reduces concerns about clustering of the data. The sufficient condition\nshown in Eq 11 is true if the estimated coefficients for 2\nare not jointly equal to 0,\nwhich we evaluate with the F-test of joint significance. Our null hypothesis is that the sufficient\ncondition shown in Eq 11 is untrue\u00adi.e., that Pr(Ys\n) = Pr(Ys\n). While\nthis does not guarantee that the networks are FOM, in cases where this test indicates we should\nreject the null hypothesis it means that the network is unlikely to be FOM because the current\nstate depends on the prior state as well as how that state was reached.\nIn addition to testing the FOM assumption in the complete networks, we also test it in RDS\nsamples of size 200 on those networks conducted with replacement from a single seed drawn at\nRDS Variance Estimation Bias\nrandom from the equilibrium distribution, because this is the type of data that a researcher\nwho had collected a single sample might possess. We allow branching to occur where the prob-\nBecause this is the approach used in an influential past study [18], we focus on these results.\nWe also tested variants where we allow branching with the same probabilities as above, but the\nsamples are conducted without replacement, and where we do not allow branching (both with\nand without replacement). We do not present these results but they did not alter our conclu-\nsions of substantial biases in the VHE and SBE. We conduct 500 simulated RDS samples in\neach of the 215 Add Health and Facebook schools, storing the relevant variables of interest.\nAfter testing for FOM violations in these sampled network data, we then summarize some\nof the problems that the VHE and SBE estimators exhibit when applied to empirical network\ndata. In each sample, we calculate the predicted proportion of Y via the Volz and Heckathorn\n(i.e., the \"RDS2 estimator\") estimator of the mean b\nmRDS \u00bc\nP\ns\nj\nYj=dj\nP\ns\nj\n, where d indicates degree\n[14,38]. We define the \"population sampling variance\" as the variance of the distribution of\nmean estimates obtained over R = 500 simulated samples in that network (which is approxi-\nmately equal to what would be obtained via Eq 6 but is computationally feasible for larger net-\nworks); in other words,\npopulation sampling variance \u00bc\nP\nR\n\u00f0b\nr\nR\nb\nwhere r indexes the simulated replication of the sample (i.e., we simulate 500 replication sam-\nples in each empirical network). Defined in this way, the population sampling variance is the\nvariance of the distribution of mean estimates across repeated samples. We use the population\nsampling variance to define the bias for the VHE and the other popular means of estimating\nsampling variance in RDS, the Salganik Bootstrap Estimator (SBE), which is\nbias \u00bc\nP\nR\n\u00f0 d\nb\nb\n\u00de\nR\nwhere a value of zero indicates that the estimator is unbiased for that variable in that network.\nTo gauge the potential influence of outlier RDS variance estimates on the relationship between\nthe estimated sampling variance and the population sampling variance, we tested using the\nmedian estimate across the 500 simulations rather than the mean (not shown). This led to\nmore severe biases and other problems than those reported in the manuscript.The next quan-\ntity of interest is the ratio of the estimated sampling variance to the population sampling vari-\nance, which helps quantify how closely the VHE and SBE approximates the population\nsampling variance; thus, we also examine:\nratio \u00bc\nP\nR\nd\nb\n=R\nb\nin each network. Finally, though it may be biased, there is the possibility that the VHE esti-\nmates of sampling variance are highly correlated with the population sampling variance and\nthus researchers could simply inflate the variance estimator by some factor. To examine this\npossibility, we consider the correlation of the mean variance estimates in each network with\nRDS Variance Estimation Bias\nthe population sampling variance for each variable:\ncorrelation \u00bc cor\u00f0\u00f0\nP\nR\nd\nb\nb\nFinally, we note that the results about whether the network or sample is FOM pertain to\nwhether or not researchers should expect that RDS estimators of sampling variance are under-\nestimates (network level analysis) and can detect those cases (sample level analysis), as was\ndemonstrated in the prior section. However, a different question is whether researchers can\npredict how large the underestimation bias in a given sample is likely to be rather than whether\nor not the estimators are biased toward underestimation. Building from the literature reviewed\nin section 2, we know that the degree of bias is determined by higher order features of a net-\nwork that is not FOM.\nEchoing a general sentiment in the literature, it may be that homophily on the focal variable\nexplains the degree of bias in cases where FOM is violated, so, to test this, we examine whether\nsample level homophily can predict levels of bias in cases where FOM is violated at the network\nlevel (we thank a reviewer for this suggestion). To do this, we compute the sample level homo-\nphily defined as the ratio of observed cross-group ties to expected cross-group ties in a given\nsample. We then regress bias on this measure of homophily to determine whether there is a\nmeaningful and consistent relationship between bias and the homophily of a sample, which, if\nfound, would indicate that the homophily observed in a sample can alert researchers to cases\nwhere bias is especially problematic. To facilitate interpretation, we focus on XY standardized\nregression models, where both the independent and dependent variables are standardized to\nhave a mean of 0 and a standard deviation of 1. In XY standardized regression, the interpreta-\ntion of coefficients is natural: a one standard deviation change in X (sample level homophily in\nthe case we test) leads to a b\nb standard deviation change in Y (sample level bias in the estimate\nof sampling variance in this case). We obtained substantively equivalent results in models run\nwithout XY standardization, but we focus on the XY standardized results because of their sim-\npler interpretation in this case. To determine whether results owe to features of the networks or\nestimators we study or are general, we obtain parameters from regression models with and\nwithout absorbing indicators (i.e., fixed effects) for the network studied and for both the VHE\nand SBE estimators.\nResults\nThe results of our tests of the FOM assumption on the complete networks are shown in panel\nA of Table 2, while results of the FOM test on individual samples are shown in panel B. Columns\n1\u00ad3 show the proportion of FOM tests where we reject the null hypothesis that the network may\nbe FOM under standard social science thresholds based on the F-test of joint significance\nworks (panel A), we reject the null hypothesis that the variable of interest in each network is\nFOM almost every single time. The one exception is a Facebook school where we could not calcu-\nlate the FOM test for gender because the school is not co-educational. In other words, we find no\ncases where the fundamental premise of RDS variance estimation is a justifiable assumption.\nWorse still, the second key result in this table shows that, for the sample level tests (panel B), a\nnear majority of the samples indicate the opposite, that the network may be FOM. This disjunc-\nture indicates that it would be difficult for a researcher to know a posteriori whether the current\nmethods of RDS variance estimation can be applied aptly. Though a given sample may seem\nappropriately characterized as FOM [3], the network from which it was drawn is highly unlikely\nto be. We return later to this disjuncture and its consequences for RDS variance estimation.\nRDS Variance Estimation Bias\nWe next consider how problematic RDS variance estimation is when it is applied to empiri-\ncal data whose complete network structure violates the FOM assumption. We look at the two\nmost commonly used RDS variance estimators. Table 3 separate these estimators into two pan-\nels, with panel A showing the VHE and panel B showing the SBE. The first column shows the\nmean of the bias across the networks for each dataset and variable (Eq 14). The key point to\nnotice about this column is that both the VHE and the SBE estimates are negatively biased in\nall cases. The second column shows the mean of the ratios of average VHE and SBE estimates\nof sampling variance in a given dataset and school to the population sampling variance (Eq\n15). Most of the variables understate the true variance substantially\u00adin the Add Health schools,\nthe VHE estimated sampling variance understates the empirical sampling variance of RDS by\nabout 85%\u00adbut this number ranges from as low as 55% to as high as 90% in the Facebook data-\nTable 3 shows the correlations (Eq 16), which highlight that there are substantial deviations\nfrom direct positive correlation and that the relationships between the average RDS estimates\nand the population values differ substantially by variable and dataset. We argue that this varia-\ntion in correlations implies that researchers cannot know a priori whether the VHE or SBE esti-\nmates of sampling variance are useful.\nThe results in Table 3 are a conservative estimate of the problems with variance estimation\nin RDS. This is because they average, respectively, all VHE and SBE estimates across 500 RDS\nsamples conducted in each school, which may paint an unrealistic picture of the practical utility\nof these estimators. Because researchers typically only collect one sample, we now turn to Fig 3\nTable 2. Descriptive statistics of First Order Markov (FOM) tests on Add Health and Facebook Net-\nworks, by analysis level and variable.\nPanel A) Complete network FOM tests\nAdd Health Data Set\nFacebook Data Set\nPanel B) Sample level FOM tests\nAdd Health Data Set\nFacebook Data Set\nNote: Pr. p<0.05, Pr. p<0.01, and Pr. p<0.001 indicate the proportion of networks in which the FOM test\nindicated we reject the null hypothesis that the network may be FOM. Note that in cases where the FOM\ntest could not be calculated\u00ade.g., non-coeducational schools or samples of only one gender\u00adwe\nconsidered this as indicating the network or sample may be FOM.\nRDS Variance Estimation Bias\nTable 3. Measures of the relationship between VHE and SBE estimates of sampling variance and the population sampling variance.\nData Set and Variable Bias Ratio Correlation\nPanel A) VHE Results\nPanel B) SBE Results\nNote: Bias shows the mean of the average deviations between the sample estimates and the population parameters across replications and networks.\nRatio shows the average ratio of estimated sampling variance to the population parameter. Correlation shows the correlation between the average of the\nsample estimates of sampling variance in each network and that network's population sampling variance.\nFig 3. Distribution across networks of coverage rates based on the VHE and SBE estimators, by variable and data set. Note: The expected coverage\nrate across networks for SRS is .95 (thick dashed line). AH indicates Add Health data set; FB indicates Facebook 100 data set. VHE indicates the Volz-\nHeckathorn Estimator, and SBE indicates the Salganik Bootstrap Estimator.\nRDS Variance Estimation Bias\nwhich shows box plots of the distribution across networks of the coverage rates by dataset, vari-\nable, and estimator (VHE vs. SBE). A given network's coverage rate is defined as the proportion\nof cases where the population mean  is in the range b\nffiffiffiffiffiffiffiffiffiffi\nd\nb\nr\n, i.e., within the esti-\nmated 95% confidence interval. In SRS, the coverage rate is expected to be 0.95, but, as Fig 3\nshows, the coverage rate for the VHE is substantially lower, and we see substantial variability in\nthe distributions by data set and variable. For example, the \"FB Freshman\" variable shows that,\non average, the 95% confidence interval for the VHE estimates of the mean proportion of fresh-\nmen contained the true mean in only 36.5% of the networks under study. This is substantial\nfailure of confidence intervals for RDS. Beyond the poor coverage seen across all of the vari-\nables, a secondary point conveyed by Fig 3 is that the SBE generally outperforms the VHE.\nWith Table 4, we return to the disjuncture between population-level failure of the FOM test\nand sample-level passing of it that we noted in our discussion of Table 2. A natural question to\nask is whether\u00ada posteriori\u00ada researcher can test her sample for FOM violations and discern\nwhether the RDS variance estimators are likely to be biased. We split Table 4 into two panels:\npanel A shows the cases where the samples in Table 2 were found to not be FOM, while panel\nB shows those which may be FOM. The columns show the data set and variable combinations.\nWithin each panel, we present the most relevant statistics averaged samples within that panel:\nthe empirical design effect calculated from the population sampling variance in Eq 13 (\"Mean\nempirical DE\"), the VHE and SBE estimated design effects (\"Mean VHE/SBE estimated DE\"),\nand the coverage rates from both estimators (\"Mean VHE/SBE 95% coverage rate\"). The\nempirical design effects are generally smaller in the samples that may not be FOM; however,\nthis is not true for the FB Freshman variable. However, the estimated DEs, using either the\nVHE or the SBE, do not appear appreciably closer to the population values (the empirical\nDEs). Neither do the coverage rates. Taken as a whole, these results suggest limited potential\nfor sample-level FOM tests to be used as a diagnostic tool. Though researchers do not typically\ntest for FOM violations, and while other, potentially yet-to-be-developed tests may be able to\nTable 4. Comparison of Design Effects, Estimated Design Effects, and Coverage Rates across samples that are not FOM or may be FOM, by data\nset and variable.\nData Set and Variable\nAH Female AH White AH Sports FB Female FB Freshmen\nPanel A) Results on samples that are not FOM\nPanel B) Results on samples that may be FOM\nstatistics are averaged across samples in each panel.\nRDS Variance Estimation Bias\ndetect FOM violations in RDS sampled data, the most natural means of testing for FOM viola-\ntions is unable to detect them. The development of methods to detect such violations thus rep-\nresents a key area for potential research on RDS variance estimation.\nLastly, we estimated the parameters of XY standardized regression models for the relation-\nship between sample level bias in the VHE and SBE estimators of RDS sampling variance and\nsample level homophily. These results are shown in Table 5. The key points highlighted in this\ntable are that the relationship between sample level homophily and bias a) are in different\ndirections across variables, b) are generally of low magnitude and often not distinguishable\nfrom 0 despite the large sample sizes, and c) differ between the VHE and SBE estimators. The\nconclusion to be drawn from these tests is that sample level homophily cannot be used to char-\nacterize the degree of bias in RDS estimators of sampling variance. These results show that\nanother feature of networks that is commonly assumed to explain biases in RDS sampling vari-\nance estimators, level of homophily, is not a reliable indicator of whether the results of a single\nsample are biased.\nIn this section we found that the FOM assumption is routinely violated in empirical net-\nworks, but that researchers will not know this from the results of a single sample. Building on\nTable 5. XY Standardized Regressions of Sample-Level Biases in Variance Estimates using VHE and SBE Estimators on Sample Level Homophily\nacross the 5 Data Set/Variable Combinations Analyzed.\nVHE VHE w/fixed network effects SBE SBE w/fixed network effects\nRegression of variance estimate bias (standardized) for %:\n1) female variable in Add Healtha\n2) non-white in Add Healtha\n3) sports participants in Add Healtha\n4) female in Facebookb\n5) freshmen in Facebookb\nNotes: Standard errors in brackets. All regressions are based on XY standardized coefficients within estimator and data set/variable so all variables have\na mean of 0 and a standard deviation of 1; models with fixed network effects mean dummy variables for each data set and network were absorbed by the\nmodel thereby removing network level differences. Constants not shown but all approximately 0 as would be expected in a XY standardized regression.\na All models using Add Health data contain 57,500 simulated samples.\nb All models using Facebook data contain 49,000 simulated samples.\nRDS Variance Estimation Bias\narguments introduced in Section 2, this finding indicates that the RDS variance estimators in\ncommon use can be expected to substantially underestimate the population sampling variance\nthat RDS is likely to exhibit. We also examined a related question that helps contextualize the\nimportance of our FOM results: how much do these violations of matter? More specifically, we\nexplored the extent to which the current estimators for RDS sampling variance, the VHE and\nthe SBE, are likely to underestimate the true sampling variance in these empirical networks.\nOur findings in this regard were surprising in two ways. First, Table 3 showed substantial\ndownward biases in the VHE and SBE estimators of RDS sampling variance. It also showed lit-\ntle consistency across variables or data sets in the magnitude of this bias, or other properties of\nthe relationship between the estimated values and the population parameter. This is important\nbecause it highlights that the current techniques of RDS variance estimation are wildly inaccu-\nrate, which makes sense because they are premised on a faulty assumption. In other words, this\nsection has provided suggestive evidence that the core assumption underpinning variance esti-\nmation in RDS (the FOM assumption) is violated in a large proportion of empirical cases, that\nRDS variance estimators are biased in such circumstances, and that researchers will have diffi-\nculty knowing when this will be the case.\nImprovements to the VHE\nIn this section, we test the performance of two improvements to the VHE. An easily diagnos-\nable flaw in the VHE is that it fails to account for the branching nature of RDS data. As shown\nin Eqs (5) and (6) above, the VHE uses the distance between sampled individuals i and j, which\nin a random walk is equal to the number of steps between their appearances in the sample.\nHowever, in RDS, because of the branching structure of recruitment, these distance calcula-\ntions will be more complicated. As such, the first estimator we introduce, based off of an earlier\nestimator developed by Neely in a prior investigation [14], which we call the \"VHE with\nbranching correction\" (VHEwbc for short), explicitly tracks the network distance between\nindividuals, so, if i recruits j who recruits both k and l, we define the distance between i and\nboth k and l as 2. This approach should improve the VHE by more accurately calculating the\ncovariance between cases.\nThe second improvement we test is relaxing the FOM assumption in the VHE. The VHE\nassumes the network is FOM with respect to the variable of interest because it uses a 2 \u00d7 2 tran-\nsition matrix populated with the observed categorical transitions in the data. However, we can\nrelax this assumption by making, e.g., a 4 \u00d7 4 transition matrix which is populated with the\nobserved three step transitions (i.e., a second order chain); that is how often we see three-step\n1-0-1, g) 1-1-0, or h) 1-1-1. This transition matrix encodes the probabilities by which the most\nrecent pair of observed Y values yield the next value; for example:\nC\n\u00bc\n= p(yt\n= 0), that is the proportion of observed sequences of Y val-\n= p(yt\n= 1), and so on (note that 8 of the 16 ele-\nments in this transition matrix will be 0 by definition). In principle, one could further relax this\nassumption to incorporate even high-order chains, but there is a tradeoff in terms of the num-\nber of such chains that one can observe in a single sample. As such, we test whether\nRDS Variance Estimation Bias\nincorporating higher order Markov assumptions improves the validity of the VHE. In all cases,\nwe also include the branching correction (i.e., VHEwbc); we call this estimator the \"VHE with\nhigher order Markov\", or VHEhom for short. We test two higher order Markov assumptions:\nfirst we focus on a 2nd order assumption then we focus on a 3rd order assumption. We also\npresent results for the SBE which adds another dimension of comparison with three variants of\nthe algebraically based VHE estimator.\nFig 4 presents the distribution of coverage rates across the different networks for the VHE\nestimates of RDS sampling variance, for the VHEwbc estimates, for the VHEhom estimates\n(note we did not calculate the VHEhom in the Facebook data set), and for the SBE estimates.\nIn most cases, the SBE outperforms the variants of the VHE we tested in most cases. This is\nmost clearly true for estimates of percent female in both the Add Health and Facebook net-\nworks and the percent participating in sports in the Add Health networks. The SBE's results\nare closer to the VHE variants for the race variable in the Add Health networks and worse than\nthe VHEwbc estimator for the freshman variable in the Facebook networks. The proposed\nadjustments we consider generally improve the median coverage rate, but not substantially.\nTheir effects also differ by variable and dataset. For the female variable in the Add Health net-\nworks, the VHEwbc improves estimates in all cases; the median, both quartiles and the outlier\ndots move closer to the desired 0.95. The VHEhom also improves estimates, if only marginally.\nFor race in the Add Health networks, both the VHEwbc and the VHEhom outperform the\nVHE, but the VHEhom underperforms the VHEwbc. By contrast, for sports participation in\nFig 4. Distributions across networks for coverage rates based on the VHE, VHEwbc, VHEhom, and SBE estimators, by variable and data set. Note:\nThe expected coverage rate across networks for SRS is .95. AH indicates Add Health data set; FB indicates Facebook 100 data set. VHE indicates the Volz-\nHeckathorn Estimator; VHEwbc indicates the VHE with Branching Correction; VHEhom is the VHE with Higher Order Markov assumptions; and SBE\nindicates the Salganik Heckathorn Estimator. The estimators are described in text.\nRDS Variance Estimation Bias\nthe Add Health networks, the VHEhom substantially outperforms the VHEwbc. These cases\nillustrate that neither approach is significantly better than the other. In the Facebook 100 net-\nworks, we did not test the VHEhom owing to the size of these networks and the computational\ncomplexity of enumerating higher order chains, but suspect that the same general conclusions\nwill hold. However, these networks are still interesting because they show just how much of a\ndifference the VHEwbc can make. For the gender variable, there is almost no difference\nbetween the VHE and the VHEwbc. However, for percent freshmen, the difference is enor-\nmous with the 25th percentile estimate from the VHEwbc higher than the 95th percentile whis-\nker from the VHE. On balance, however, the proposed corrections do not appear to\nsubstantially improve the coverage rates as none of median estimates are close to 0.95. On bal-\nance, researchers would be less likely to make inferential errors using the SBE estimator than\nany of the VHE variants we tested, but we note that they would still make the wrong inference\nfrequently.\nAs a final illustration of the potential of these adjustments, we consider Fig 5. It plots differ-\nences between population design effects and the estimated design effects for the first (i.e., the\nVHEwbc), second (the VHEhom), and third order Markov strategies (not shown previously)\nfor one variable (race) across the different networks in the Add Health data. The VHEwbc esti-\nmates are primarily found in the top left, and are often about an order of magnitude lower than\nthe population DE. The VHEhom (2nd Order) is slightly closer to the line of parity, but still\nsubstantially different. The 3rd Order Markov estimates are more scattered, but do not appear\nFig 5. Population RDS sampling variance vs. VHE estimated sampling variance with branching correction under different Markov Order\nassumptions, for Race in the AH data set. Notes: Both scales are design effect scales and are logged. Symbols in the graph are as follows: 1--FOM\nassumption (VHEwbc in Fig 4); 2--Second Order Markov assumption (VHEhom in Fig 4); 3--Third Order Markov Assumption (not shown in Fig 4).\nRDS Variance Estimation Bias\nto be much better than the 2nd Order estimates. Indeed, some are worse. This is because there\nis less and less data the higher order Markov process we estimate, and consequently additional\nerror may be introduced by using higher order estimates. The reason for this fact is that there\nare fewer cases corresponding to each type of sequence the higher we go; as the cells become\nsparser, the precision with which they are estimated decreases.\nTo summarize our analyses of potential corrections to the VHE, we note that the proposed\ncorrections\u00admore accurately accounting for the branching structure of the RDS chain rather\nthan assuming a simple random walk and attempting to estimate higher order Markov transi-\ntion patterns\u00addo generally improve the variance estimation. However, the improvements we\nsee are small and variable, and they do not improve coverage rates to a desirable level. None-\ntheless, these procedures are a plausible first step toward improving estimates, and future work\nmay improve on them. For instance, it may be that the eigensystem-based approach of the\nVHE fails with higher order Markov chains, but that a bootstrap approach more similar to the\nSBE would perform more desirably. We leave these questions for future work. More impor-\ntantly, however, these results suggest the constraints that emerge from the typical RDS sam-\npling methodology which focuses solely on recruiter-recruit links to the neglect of other\nrelevant network data. We argue that a more fruitful approach may be to collect additional net-\nConclusions\nThis paper has contributed to the literature on sampling hidden and hard to reach populations,\nand specifically Respondent Driven Sampling, by focusing on the issue of biased sampling vari-\nance estimation, which has only rarely been addressed to date [14,18]. Whereas prior work has\ndocumented biases in RDS mean estimators and the potential for RDS estimators to exhibit\nhigh sampling variance, the actual estimation of sampling variance has received considerably\nless attention. This is unfortunate for two reasons. First and most generally, if the RDS estima-\ntors of sampling variance are biased, then researchers cannot trust confidence intervals and\nhypothesis tests derived from these estimators. This is a problem for researchers and policy\nmakers seeking to determine which populations have the highest disease prevalence, or\nwhether observed changes in behaviors within a single population over time are due to actual\nchanges or simply the variability that would be obtained through repeated sampling, to name\ntwo examples. Second, in the case of RDS, whose mean estimators are known to exhibit high\nsampling variance, an inaccurate means of estimating sampling variance will be especially\nproblematic if it is downwardly biased. Our results suggest that the sampling variance estima-\ntors in use for RDS data are downwardly biased, indeed, massively so. Similar conclusions on a\nsmaller scale have been highlighted in prior work [14,18]. We also found that the SBE generally\noutperforms the VHE or any natural extension of it, if only by a marginal amount.\nFurther, by focusing on the exact reasons for biases in the RDS variance estimators, this\npaper clarifies the heuristic notions prevalent in the RDS literature about which types of net-\nworks will be \"problem cases\" where RDS should not be applied. Unfortunately, our results\ndemonstrate that such \"problem cases\" are common. Through mathematical illustrations,\ncomputational examples, and empirical analysis of 215 observed social networks from two dif-\nferent data sources, we have shown that the key assumption made by current RDS variance\nestimators\u00adthe First Order Markov assumption\u00adis frequently violated. In addition, our results\nextend those of prior work [14,18] and show that the variance estimators perform poorly in\nmany situations, and that the VHE as well as the SBE suffers this limitation. We examined two\nmodifications to the VHE in an effort to reduce these biases, but, though they both offered\nsome improvement, neither fundamentally solved the problem.\nRDS Variance Estimation Bias\nThis paper has outlined new reasons that variance estimation in RDS needs more attention.\nBased on the performance of currently available estimators, a prudent researcher must wonder\nwhether meaningful confidence intervals and hypothesis tests can be constructed. Given the\nresults presented here, this does not appear to be the case because the variance estimators are\nso biased as to be effectively meaningless. However, further work may correct these issues, and\nsampling [11,42,45\u00ad47] are being developed. These approaches, combined with renewed atten-\ntion to the issue of estimating sampling variance in RDS, should pave the way for more accu-\nrate sampling variance estimation and a renewed emphasis on collecting additional network\ndata as part of the sampling process.\n"
}