{
    "abstract": "Public Opinion Quarterly, Vol. 68 No. 1 Pp. 102\u00ad108, \u00a9 American Association for Public Opinion Research 2004; all rights reserved.",
    "reduced_content": "Public Opinion Quarterly, Vol. 68 No. 1 Pp. 102\u00ad108, \u00a9 American Association for Public Opinion Research 2004; all rights reserved.\nUniversity of Alabama\nThis research note examines whether people who overreport voting or voting\nrecords (or both) account for different results from self-reported and validated\nvoter turnout research.\nPresser, Traugott, and Traugott (1990) raised the possibility that findings of\noverreporting bias in self-reported turnout studies may be artifacts of validation\nerror. They showed that inferior voting records may deter validators from finding\nevidence of actual voting in central cities, the South, and African American\ncommunities. This is a critical concern for political scientists because some\nstudies have found that overreporters bias the effects of the same or overlapping\nreporters alter the effect of race on turnout. Bernstein, Chadha, and Montjoy\n(2001) found that overreporters alter the effect of race, residence in the Deep\nSouth, Hispanic ethnicity, the interaction of region and race, and minority\nrace, southern residence, and Hispanic ethnicity.1 Past research still leaves\nseveral questions unanswered. Do nonvoters who falsely claim to vote distort\nwhat we might otherwise predict about the effect of African American race,\nsouthern residence, Hispanic ethnicity, and related variables? Or do inferior voting\nrecords in some voting districts cause validators to undercount African American,\nsouthern, or Hispanic voters? What is the magnitude of validation error?\nPrevious Research\n1992) reach different conclusions about whether poor-quality voting records\nmay bias validated turnout estimates. Presser and his colleagues examined\nI am indebted to Michael Traugott for helpful comments on an earlier version of this note.\nAddress correspondence to the author; e-mail: ccassel@tenhoor.as.ua.edu.\n1. Cassel (2002) found that overreporters bias the effect of Hispanic ethnicity in midterm, but not\npresidential, elections.\nVoting Records and Vote Validation 103\nrecord quality indicators available in the 1988 National Election Study (NES)\nelection administration study and found that African Americans, southerners,\nand central city residents tend to live where record management is poorest.2\n(The study reported here looks at the same record quality variables, identified\nin the \"analysis\" section below.) Furthermore, they show that validators are\nleast likely to confirm self-reports of voting in these communities. For example,\nvalidators confirmed 90 percent of self-reports of voting among African\nAmerican registrants who lived where record quality and access is highest, but\nonly 52 percent of self-reports among African American registrants who lived\nwhere record quality and access is lowest (calculated from Presser, Traugott,\nand Traugott 1990, table 6). Presser and his colleagues conclude that validated\nvoting studies overestimate misreporting, and the well-known finding that\nAfrican Americans overreport voting more than whites overreport voting\nmight be at least in part an artifact of poor-quality voting records. However,\nthey also advised that political scientists need further, multivariate tests to\ndetermine the relative effects of the quality of voting records and the respon-\ndents on validated turnout.\nvoting records in African American and white communities from an examination\nstudies. They concluded that voting records do not distort racial differences in\nvalidated turnout. However, the record quality variables Abramson and Claggett\nexamine are not the same variables that Presser and his colleagues find important\nso the former's study does not directly counter the research claims of the\nlatter.3 Yet a third, indirect test of record quality supports Abramson and\nMontjoy (2001, n. 12) compared validated turnout models that include and\nexclude people classified as overreporters because validators could not find their\nvoting records.4 Results from the two models are approximately the same.\nAnalysis\nThis research extends Presser, Traugott, and Traugott's (1990) study with\nmultivariate tests of 1988 NES data to determine whether poor-quality and\n2. African Americans and southerners are twice as likely, and central city residents are three\ntimes as likely, as others to live where voting record quality and access are lowest (calculated\nfrom Presser, Traugott, and Traugott 1990, table 6).\n3. Abramson and Claggett (1990) examine validators' subjective assessments of record quality,\nwhether voting offices have procedures to see if people live at the address where they are registered,\nwhether master files contain the names of all people who are registered, whether master files are\ncomputerized, whether one needs to know the precinct to find a voting record, and whether\none does not need to know the precinct or could locate a person's voting record from his or her\nregistration record.\n4. In the NES validation procedure, field staff will misclassify actual voters as overreporters if\ninaccessible voting records bias the effects of race, region, etc. on validated\nturnout (i.e., to determine the relative effects of the voting records and the\ncharacteristics of respondents on validated turnout).5 NES interviewers ques-\ntioned local government officials about the nature of registration and voting\nlarger 1988 study contains the necessary variables. The multivariate tests also\nmake it possible to estimate the magnitude of validation error.\nTo determine the effects of voting records on validated turnout research,\nthis study compares results from validated turnout models that exclude and\ninclude Presser, Traugott, and Traugott's (1990) record quality indicators. The\nmodels contain the demographic variables whose effects may be biased by\nfaulty voting records--race, and southern and central city residence--and\ninterrelated socioeconomic control variables. These independent variables are\nstandard explanations of turnout in voting participation research (Conway\nThe record-keeping variables are the number of offices to register, office\nworkload, and a record quality and access index. Whether there is more than\nrecord quality and access index is a 3-point measure of complications in voting\nrecords, combining whether election officials merge the registration records\nwith vote information (V1133, no =1, yes =0); whether all voting records are\navailable (V1145, no = 1, yes= 0); whether the validator needs the exact\naddress to locate an individual (V1176, yes =1, no =0); whether officials had\nthe number of offices to register, voters per precinct, and record quality and\nThe socioeconomic and demographic predictors of turnout examined here\nare education, age, and length of residence in the community in years; family\nincome in ordinal categories; dummy variables measuring whether people are\nmarried, southern residents, female, homeowners, Hispanic, or central city\nthey fail to find the voting records of validated registrants or the registration records of self-\nreported voters.\n5. The data analyzed here are from the 1988 National Election Study. Neither the principal inves-\ntigators (Warren E. Miller and the National Election Studies) nor the suppliers of the data (Sapiro,\nRosenstone, Miller, and the National Election Studies 1998) bear any responsibility for the analysis\nor interpretation.\n6. Approximately 56 percent of respondents live in areas with no complications in voting record\nkeeping (the index of record quality and access = 0), about 35 percent live where there is one\ncomplication (the index = 1), and 8.4 and .1 percent live where there are two and three complica-\ntions, respectively (the index = 2).\nVoting Records and Vote Validation 105\nresidents; and two dummy variables--African American and \"other\"--\nmeasuring race. \"White\" is the omitted race category; \"other\" is Asian, Native\nAmerican, and other. Age and length of residence are natural logarithms to\ncorrect for nonlinear relationships with turnout.\nTable 1 presents the logistic regression predictions of turnout from models\nthat exclude and include the three record-keeping variables. In the right-hand\nequation the effects of the number of registration offices and office workload\nare not significant. The effect of the third record-keeping variable, the voting\nrecord quality and access index, is significant and moderately large: we expect\na 9 percentage point difference in turnout when changing from the lowest to\nhighest value of the index. Yet adding the voting record index and other\nrecord-keeping variables to table 1's left-hand equation does not notably\nchange the coefficients, significance levels, or effect sizes of the other variables.\nAll differences in effects in the two sets of equations are less than those\nincluded in 95 percent confidence intervals.\nWhy does controlling for the record-keeping variables--particularly the\nvoting record quality and access index--make so little difference for the\neffects on validated turnout of race, southern and central city residence, and\nthe other independent variables? Further analysis shows that the correlations\nbetween the voting record quality and access index and race, southern\nresidence, and central city residence are .12, .11, and .23, respectively. All\np-values are <.01. However, central city residence does not affect turnout\n(table 1), so the strongest relationship, between record keeping and central city\nresidence, is not important. In fact, because turnout in central cities may be\nexplained by the characteristics of individual residents, U.S. voting participation\nstudies generally do not include a size of place variable (Conway 1999;\nvoting records index and both race and region indicate that voting records\nexplain about 1 percent of their variance and explain why these relationships\nare not important as well. African Americans and southerners may be twice\nas likely as others to live where validators have more difficulty matching self-\nreports of voting with actual voting records, yet only 16 percent of African\nAmericans and 13 percent of southerners (and 8.5 percent of all Americans)\nlive in these districts (Presser, Traugott, and Traugott 1990).7\nFinally, to estimate the magnitude of validation error, we present an analysis\nthat assumes that no actual voters would be misclassified as overreporters if\nall voting records were of the highest quality. This assumption overlooks ran-\ndom error from misspelled names, inexperienced validators, registration in\ndifferent counties, or other unmeasured factors. However, we assume the\n7. Presser, Traugott, and Traugott (1990) show that \"match\" rates, or validators' ability to con-\nfirm self-reports of voting, are similar in voting districts with zero or one complication in voting\nrecords; but match rates decline 9 percentage points in districts with two or more complications\n(the voting record quality and access index = 2).\nTable 1. Estimated Effect of NES Misclassification of Voters as Overreporters on Predictions of Validated Turnout, 1988\n(Logistic Regression)\nIndependent Variable Coef SE\n%\nProba Coef SE\n%\nProb\nSES and demographic\nRecord keeping\na Change in expected turnout produced by change from lowest to highest value of a predictor. If dichotomy, change in expected turnout produced by change from zero to one.\nb Weighted by the number of politically eligible adults in the household.\n* p < .05 (one-tailed).\n** p < .01, (one-tailed).\nVoting Records and Vote Validation 107\nunderestimation of actual voters from these additional factors is small. For\nexample, Traugott, Traugott, and Presser (1992) report that validators' prior\nexperience made no difference in finding voting records; and Traugott (1989)\nreports that validators check many possible misspellings, although some\nvoters may be registered in different counties. Here, we estimate the actual\nvoters misclassified as overreporters as the difference in validated turnout\npredictions from the right-hand equation in table 1 when setting all indepen-\ndent variables at their mean value, and after setting the record-keeping index\nto reflect the highest quality and accessibility. This method indicates the NES\nmisclassified 2 percent of respondents as overreporters. This suggests that in\n61.1) percent were actual voters. The low 2 percent estimate of the NES\nmisclassification of voters as overreporters may be explained by the fact that\nmore than 90 percent of Americans live in areas with little or no problem in\nvoting record quality or accessibility.\nConclusion\nThe measurement of whether people did or did not vote is critical to political\nscience. This research note helps to clarify our understanding of whether NES\nvalidated turnout predictions are an accurate standard for assessing self-\nreported turnout research. Validation error from poor-quality or inaccessible\nvoting records--located particularly in central city, African American, and\nsouthern communities--does not bias the effects of related turnout predictors.\nThe small 2 percentage point estimate of validation error from voting records\nhelps explain why the NES validated voting data are an accurate standard for\nassessing electoral participation research. Validators confirm the fewest self-\nreports of voting where record quality is poorest, but only small minorities of\npotential voters--including African Americans and southerners--live in such\ncommunities.\nReferences\nAbramson, Paul R., and William Claggett. 1984. \"Race-Related Differences in Self-Reported and\n------. 1986. \"Race-Related Differences in Self-Reported and Validated Turnout in 1984.\"\n------. 1989. \"Race-Related Differences in Self-Reported and Validated Turnout in 1986.\"\n------. 1991. \"Racial Differences in Self-Reported and Validated Turnout in the 1988 Presiden-\n------. 1992. \"The Quality of Record Keeping and Racial Differences in Validated Turnout.\"\nBernstein, Robert, Anita Chadha, and Robert Montjoy. 2001. \"Overreporting Voting: Why It\nHappens and Why It Matters.\" Public Opinion Quarterly 65:22\u00ad44.\nCassel, Carol A. 2002. \"Hispanic Turnout: Estimates from Validated Voting Data.\" Political\n------. 2003. \"Overreporting and Electoral Participation Research.\" American Politics Research\nConway, M. Margaret. 1999. Political Participation in the United States. 3d ed. Washington, DC:\nCongressional Quarterly Press.\nPresser, Stanley, Michael W. Traugott, and Santa Traugott. 1990. \"Vote `Over' Reporting in\nSurveys: The Records or the Respondents?\" Technical Report no. 39. Ann Arbor, MI: National\nElection Studies.\nRosenstone, Steven J., and John Mark Hansen. 1993. Mobilization, Participation, and Democracy\nin America. New York: Macmillan.\nTeixeira, Ruy. 1992. The Disappearing American Voter. Washington, DC: Brookings.\nTraugott, Michael W., Santa Traugott, and Stanley Presser. 1992. \"Revalidation of Self-Reported\nVote.\" Technical Report no. 42. Ann Arbor, MI: National Election Studies.\nAnn Arbor, MI: National Election Studies.\nVerba, Sidney, and Norman H. Nie. 1972. Participation in America. New York: Harper and Row.\nVerba, Sidney, Kay Lehman Schlozman, and Henry Brady. 1995. Voice and Equality: Civic\nVoluntarism in American Politics. Cambridge, MA: Harvard University Press.\nWolfinger, Raymond E., and Steven J. Rosenstone. 1980. Who Votes? New Haven, CT: Yale\nUniversity Press.\n"
}