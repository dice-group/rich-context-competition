{
    "abstract": "Abstract\nToday's world allows people to connect over larger distances and in shorter intervals than ever before, widely monitored by\nmassive online data sources. Ongoing worldwide computerization has led to completely new opportunities for social scientists\nto conceive human interactions and relations in unknown precision and quantities. However, the large data sets require\ntechniques that are more likely to be found in computer and natural sciences than in the established fields of social relations.\nIn order to facilitate the participation of social scientists in an emerging interdisciplinary research branch of \"computational\nsocial science,\" we propose in this article the usage of the Python programming language. First, we carve out its capacity to\nhandle \"Big Data\" in suitable formats. Second, we introduce programming libraries to analyze large networks and big text\ncorpora, conduct simulations, and compare their performance to their counterparts in the R environment. Furthermore, we\nhighlight practical tools implemented in Python for operational tasks like preparing presentations. Finally, we discuss how the\nprocess of writing code may help to exemplify theoretical concepts and could lead to empirical applications that gain a better\nunderstanding of the social processes initiated by the truly global connections of the Internet era.\n",
    "reduced_content": "Creative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons\nAttribution-NonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use,\nreproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open\nAccess pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).\nMethodological Innovations\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\nmio.sagepub.com\nIntroduction\nIn recent years, the ability of people to connect across the\nglobe has dramatically increased due to technological inno-\nvations related to the Internet. Ongoing worldwide com-\nputerization provides great opportunities for scientists to\nenhance our understanding of the complex systems in which\nhumans live today. Increasing availability of massive social\nmedia data abets efforts trying to explain collective behavior\nwith methods stemming from the natural and computational\nRising computer power enables and enhances this devel-\nopment. The capacity to collect and analyze large amounts of\ndata with computational techniques has already transformed\nphysics (quantum computing; Steane, 1998) and biology\n(computational biology; Kitano, 2002). However, in the\nmost influential journals of the social sciences, the potential\nof Internet data and computational methods is only starting\nto take off, although large companies are worth hundreds of\nbillions of dollars mainly because of their understanding to\nutilize \"big (social) data\" (e.g. Google, Facebook, Twitter)\nand state institutions are using similar techniques for the bet-\nter and worse of their citizens (most prominently the National\nSecurity Agency [NSA]). Thus, \"computational social\nscience\" (CSS) is occurring. The question is whether it\nhappens with or without social scientists.\nInstalling computational social science:\nFacing the challenges of new information\nand communication technologies in social\nscience\nRaphael H. Heiberger1 and Jan R. Riebling2\n Keywords\nComputational social science, Python, R, data management, research practices, theory development\n1Institute for Sociology, University of Bremen, Bremen, Germany\n2Otto-Friedrich-Universit\u00e4t Bamberg, Bamberg, Germany\nCorresponding author:\nRaphael H. Heiberger, Institute for Sociology, University of Bremen,\nEmail: raphael.heiberger@uni-bremen.de\nOriginal Article\n2 Methodological Innovations\nTo be sure, there have been recently some prominent pub-\nlications that, for instance, are using computational text anal-\nthe Internet movie database (Lutter, 2015), Facebook friend-\nship networks (Wimmer and Lewis, 2010), or even career\nhistories of video game developers and their creative prod-\nucts (De Vaan et al., 2015). Yet these efforts, valuable as they\nmay be, still seem very few when compared to the overall\nresearch endeavor of the Social Sciences. In an age of\nincreasing technological means and challenges, this relative\nreluctance seems ill-advised.\nGiven our profession as trained sociologists, we clearly\nopt for a more active participation of our discipline in this\nnew research paradigm. This article aims to accomplish this\nin two ways: on one hand, we want to discuss the chal-\nlenges as well as the potential CSS poses for research\nefforts in the field of Social Science. Since CSS has some-\ntimes been relegated to either Big Data applications or\nsome very specific methods (mostly Social Network\nAnalysis [SNA]), we want to instead emphasize the broad\ninfluence and transformative power CSS will have on the\nSocial Sciences in general. On the practical side, we illus-\ntrate the usage of computational methods and techniques in\nthe Python language, which serves as a generalized pro-\ngramming framework to conduct all steps of a \"CSS analy-\nsis.\" Being far from the only programming language to\ncater to the needs of CSS researchers, Python offers some\ndistinct advantages. Most prominent is its focus on the\nreadability and accessibility of code, which is especially\nimportant to social scientists, who in general have received\nlittle to no training in programming and coding. Python is\nalso easily extendable with a wide variety of libraries for\nscientific computing. Since most of these extensions are\nmaintained by professional programmers and a very active\ncommunity, they are exceptionally well documented and\nhelp is never far away.\nFor this purpose, we first discuss the position of social\nscientists in the young but growing research area of CSS\nand the challenges that may have led to the relative\nabsence. Next, we illustrate the capabilities of CSS with\nregard to four major areas of the social scientific research\nprocess. The first is the capacity to manage, gain access,\nand analyze a wide variety of data structures, which is one\nof the core properties of CSS. Second, we take a look at\nsome innovative methods which are normally associated\nwith CSS, more specifically SNA and quantitative text\nanalysis. These two steps--handling data and applying\nmethods with adequate speed--are strongly related to gen-\neral problems of CSS (Lazer et al., 2009). From these basic\nvirtues, we elaborate on further opportunities of CSS in\ngeneral and Python specifically. Thus, third, we highlight\nthe practical tools implemented in Python, for example,\ntechniques to prepare presentations or lectures. Finally, we\ndiscuss some ideas about theory building, especially how\nthe process of writing code can help to exemplify\ntheoretical concepts. Altogether, we want to picture the\ngeneral usefulness of CSS for the \"whole\" research pro-\ncess in Social Sciences, especially with regard to the chal-\nlenges and opportunities provided by the Internet as a\ndriving force behind the revolution of data describing and\nreflecting the social world.\nSocial scientists and CSS\nThe claim of CSS was first made prominently by Lazer et al.\n(2009). They summarized the possibilities (and problems)\nthat arise with the availability of massive social data pro-\nduced by the usage of the Internet.1 Most techniques neces-\nsary to analyze these kinds of data are adapted from\ncomputer science since social scientists are usually not\ntrained to handle \"Big Data.\" However, the principal ques-\ntions arising from growing global interconnectedness are\nvery much social. For instance, who is related to whom and\nwho has the most influential positions (Lewis et al., 2008)?\nWhat impact has the structure of particular societies on\nthese relations (Onnela et al., 2007)? What are general prop-\nerties of human communications (Karsai et al., 2011)? Thus,\n\"computer-science students had much better methodologi-\ncal chops than their sociology counterparts, but the sociolo-\ngists had much more interesting questions,\" as renowned\nThe diagnosis of advantageous methodical knowledge\nseems to be true not only for computer scientists as \"natural\ninhabitants\" of the new world of digital connections, posts,\nand tweets but also for physicists who are highly skilled in\nthe analysis of large amounts of data and complex systems.\nConsequently, there exists a growing movement within phys-\nics that tries to take advantage of the increasingly growing\namount of online data. In stark contrast to the Social Sciences,\nthere is an atmosphere of departure that enables them to\nwrite a \"manifesto\" (Conte et al., 2012) and to make a strong\nclaim on the analysis of large social (online) data. They pro-\npose a computer-based approach that could lead to predictive\nand explanatory models that utilize the large data sets on\nevery level of behavior (i.e. individuals and their various\naggregations). A member of this group also published the\nfirst textbook on CSS (Cioffi-Revilla, 2014). He also identi-\nfies all Social Sciences as potential application areas and,\nvery wisely, does not narrow CSS to certain methods like\nSNA nor to certain type or scale of data.\nHowever, it is common sense among these authors that\nInformation and Communication Technologies (ICT) play a\nkey role in CSS since the possibilities provided by connected\nobjects like computers, smartphones, cars, and even houses\n(as well as many more to come) have produced a worldwide\nsystem that rivals our planet's ecology in its sheer complexity.\nThe ICT are transforming (already complex) social systems,\nmost visibly the economy and the financial markets, but also\nthe way we communicate and live in general. These structures\ncan be thought of as \"Artificial Social Systems\" (Helbing,\nHeiberger and Riebling 3\n2012: 6). They are man-made, yet at the same time give rise\nto a far greater complexity than intended and understood by\ntheir original creators. Consequently, many current societal\nproblems can be traced back to a lack of expertise in dealing\nwith these new social phenomena, including but not limited to\neconomic instabilities, environmental change, and cyber\nwarfare.\nTo mitigate present and future challenges regarding\nthe ICT, physicists already created the project initiative\n\"FutureICT\" (www.futurict.eu/), funded by the European\nUnion (EU) as a \"Flagship Pilot Project,\" which participated in\nthe race for the EU's US$1.3billion provided \"to move the\nICT frontier.\" However, for social scientists, their own absence\nshould be more noteworthy than the overall funding scheme.\nThe project's Principal Investigators (PIs) are physicists, and\nthe list of disciplines involved in the \"best of all relevant knowl-\nedge\" does not even include sociology or political sciences.\nThis underlines the fact that in the Social Sciences, efforts\nto break into CSS seem rather modest. To be sure, there have\nbeen studies conducted by social scientists that make use of\nthe new possibilities, especially in terms of networks\nWatts, 2004). However, compared to the publication and col-\nlaboration efforts in the computer and natural sciences, the\nutilization of computational methods and large social data\nsets of social scientists is rather expandable.\nTo be one of the disciplines participating in, by definition,\ninterdisciplinary CSS and not being marginalized from the\nbeginning, social scientists have to rethink their tools and\n\"computerize\" their methods and theories. This is reminis-\ncent of the situation in the SNA community around the mil-\nlennium. SNA tries to explore empirical social interactions\nwith elaborated mathematical modeling (Scott and\nsomehow ignored by physicists (Freeman, 2011). For a long\ntime, there existed many approaches in the Social Sciences\nfor the explanation and analysis of cohesive groups with\nregard to social networks (Freeman and Webster, 1994;\nHomans, 2003). Physicists widely ignored such efforts until\ntheir colleagues Girvan and Newman (2002) developed an\nalgorithm to detect those communities. The missing mutual\nrecognition is also evident in regard to the \"Small World\"\nformal approach to describe certain properties of networks\nresulted in more papers and citations by natural scientists in\na few years than Social Science produced in 45\nyears\n(Freeman, 2011). Knowing this story, one feels unsurprised\nthat the CSS manifesto mentioned above proposes \"tradi-\ntional tools of social sciences would at most scratch the sur-\nface of these issues [of ICT related phenomena], whereas\nnew tools can shed light onto social behaviour from totally\nTo support the development of new tools that are undoubt-\nedly needed for the interconnected world of the 21st century,\nwe propose a technical instrument that allows the integration\nof all necessary steps for the analysis: the Python language.\nAs a kind of minimum common sense in the existing litera-\n2009), CSS approaches focus the utilization of the ever-\ngrowing computer power and large data sets stemming from\nthe Internet. We see at least two substantial (and intertwined)\nbarriers: first, to access terabytes of data is not part of stand-\nard statistical programs used in Social Sciences. The trace\nleft by the description of real-time interactions of entire pop-\nulations of humans is far greater than the largest longitudinal\nsocial surveys are handling today. Second, existing methods\nof analysis and theories are based on those surveys (and\nother rather coarse observations) to conceive social behavior\nand relations. In network theory, for instance, most theories\nand methods are built on groups of maybe hundreds or, less\noften, thousands of people, but are most definitely not\nadapted to analyze data sets of millions of people, including\nadditional information about their locations, preferences, or\nother attributes. One first step for social scientists to develop\nsuch tools and, hence, to participate in the application of\ncomputer-aided methods is a flexible programming lan-\nguage. In our view, it seems preferable to choose a holistic\nlanguage for this purpose and to use the same language in all\nsteps of analysis, from data mining and transformation to\napplying methods in practice. In the next sections, we are\ngoing to elaborate on each of these steps and show the ben-\nefits of using a general programming language.\nNew types of data\nThe digital revolution has greatly transformed one of the\ncentral domains of Social Science, our data. We concur with\nSavage and Burrows (2007) that the rise of new types of data\ncan be considered a fundamental \"crisis of empirical sociol-\nogy.\" This follows from the fact that the careful acquisition\nand quality of empirical data can be considered one of the\ncornerstones of the Social Sciences claim to actually be part\nof the sciences and not just social commentary. Among the\nmany challenges and problems stemming from the rise of\nnew data sources, two of them stand out. First, there is the\nsheer amount of data generated by digital transactions, which\nis sometimes labeled as \"Big Data.\" Second, the emergence\nof new data sources with the promise of solving central ques-\ntions of the Social Sciences, which are not too big, but are\notherwise not suitable for analysis right away. The problem\nhere stems from the fact that much of these data are provided\nand structured in ways unfamiliar to most social scientists.\nWe call this \"Medium Data.\"\nBig Data has become something of a buzz word in recent\nyears which seems to have finally reached the Social Sciences\nalthough it has not been a very warm welcome (Burrows and\nGenerally, the term refers to data which \"exceeds the process-\ning capacity of conventional database systems\" (Dumbill,\n2012). Data of this magnitude are produced either as\n4 Methodological Innovations\nuser-generated data in social media and networks (e.g. email,\nvideo-streaming, online discussion groups) or as process-\ngenerated data (e.g. administrative processes, server logs,\nmachine transactions). To get grasp of what \"Big\" means in\nthis context, we can take a look at some of the leading compa-\nnies in this sector.According to Kerzner and Maniyam (2013),\nthese are some of the estimates for active data storage:\n\u00b7\nterrabyte\ncaptured a day;\n\u00b7\n\u00b7 Yahoo: 60pb a day;\n\u00b7\n\u00b7 Twitter: 8tb a day.\nThese figures pale in comparison with the very rough esti-\nmates on Google's active storage, which based on the power\nconsumption of Google's data centers is somewhere in the\nThe problem Big Data poses for the Social Sciences is\ntwofold. On one hand, it is a technical problem; on the other\nhand, it is mostly a problem on the conceptual level. From a\ntechnical perspective, Big Data requires expertise in handling\nlarge hierarchical data structures (e.g. HDFS, HBase, S3) and\nusing parallel programming techniques (i.e. MapReduce) to\nanalyze these data. While the statistical models are mostly the\nsame as in standard Social Science methodology, it is the\noverall framework in which these models are implemented\nwith regard to software and hardware specification that is\nchallenging social scientists. Most of the Big Data applica-\ntions are oriented around specific programming techniques,\nlike functional programming or similar models, which are\neasy to grasp for programmers but at the same time are barely\nknown among social scientists.\nIn our opinion, this limited understanding of the technical\naspect sometimes spills over into the Social Sciences percep-\ntion of Big Data. In general, Big Data is considered to be a\nthreat to the methodology and the empirical claims of Social\nScience. Instead of incorporating it into the research method-\nologies, its conceptual and ethical problems are discussed\nof reasons to be concerned regarding Big Data, without\nmuch practical knowledge about its implementation Social\nSciences stance on Big Data is in danger of sounding unin-\nformed, whereas other disciplines are already making use of\nthe new possibilities.\nWhether we like it or not, Big Data is here to stay. To\nparticipate in its ongoing development, social scientists will\nneed to develop the technical expertise to at least understand\nthe basic concepts. Beyond that, there is and will be a grow-\ning demand for professionals inside and outside of academia\nable to actually carry out Big Data analysis. This is espe-\ncially true with regard to CSS.\nPython seems to be a good choice in helping our disci-\npline in getting to grasps with Big Data. There are many\npackages for interacting with large data sets as well as algo-\nrithms designed for parallel computing.3 In addition to the\non-board functionality of Python distributions geared toward\nscientific computing--most notably the IPython Anaconda\ndistribution--there are also specialized Big Data frameworks\n(e.g. Hadoop, Sparks) which provide interfaces for high-\nlevel languages like R or Python. Besides making the techni-\ncal entry hurdles much less intimidating, Python provides an\neasy access to the basics of computer science. It is easily\naccessed and focuses on readable and easy to maintain code.\nIn short, one of the easiest ways to think like a computer\nscientist is to \"Think Python\" (Downey, 2012).\nChances are that the majority of social scientists are never\ngoing to work with actual Big Data. The tricky part here is\nthe word \"actual.\" Since Big Data is usually defined as\n\"being too big for conventional means,\" the problematic\nnature of data has to be considered with regard to the meth-\nods and techniques common in a discipline.4 Much of the\nnew data structures encountered in the Social Sciences would\nnot be seen as Big Data by computer scientists because they\nare familiar with conventional means to tackle these kinds of\nstructures. We will refer to such data that are too big and\nunfamiliar for social scientist, yet not big enough to warrant\nBig Data analytics as \"Medium Data.\"\nSo what are those conventional means defining the Social\nSciences in terms of data structures? Ask any social scientist\nto visualize data; chances are they will picture a rectangular\ntable consisting of observations along the rows and variables\nas columns. Since this is what we are taught in every under-\ngraduate course on methods, this is what data produced by\nprestigious surveys looks like, and last but not least, this is\nwhat most of the computer programs we use expect as input.\nThis tendency to equate data with tables has problematic\nconsequences for research practices and for the ability to\naccess new and unorthodox data structures.\nIf every row corresponds to one observation and most\nvariables have at least a chance to be present, the data frame\nis one of the best solutions. Yet, if the sparsity of the data is\nvery high, meaning many cells of the data frame will be left\nempty, the table structure becomes very cumbersome. This\nis almost always the case when we look at social network or\ntextual data. For example, the number of nodes occurring in\na network is mostly orders of magnitudes greater than the\nnumber of edges one node is connected to. Thus, a network\nrepresenting the same data as a list of edges would yield a\ndata structure with a magnitude of only 15,000 units.\nNetwork data are also a good example for the general\nproblem of complex, that is, hierarchical data. Consider a\nnetwork made up of social relationships among a group of\npeople. Besides the edges, there can be many different lev-\nels of data attached to this structure. There could be data on\nthe intensity of the relationships or data concerning the per-\nsons (e.g. age, sex) as well as meta-data about the entire\nnetwork (i.e. date of collection, context, etc.). Adding this\ninformation to a table would result in many duplicates across\nlines and if done extensively enough would make the whole\nHeiberger and Riebling 5\nthing indecipherable. The main advantage of using hierar-\nchical data structures (e.g. XML) or relational databases\n(SQL) over simple tables lies in their ability to manage\nentire projects within one well-defined data framework.\nFrom this data repository, data frames can be easily extracted\nfor further analysis. Instead of focusing on one data struc-\nture, CSS emphasizes techniques of converting data between\ndifferent data structures according to the needs of the overall\nresearch goals.\nKnowing how to manage hierarchical data is even more\nimportant if we consider the new data generated by the ICT.\nMost of the social data available online already exist in a\nhierarchical standardized form. Webpages, for example, are\nwritten in HTML, which is simply a hierarchical ordering of\nelements. One of the most promising new data sources comes\nin form of WebAPIs (Web-based Application Programming\nInterfaces). In this model, a request for specific data points is\nsent to a server, often mitigated through a wrapper in a spe-\ncific language, for example, Python. Barring any connection\nproblems, the server responds by sending the requested data\nto the client. Most of these data come in a hierarchical struc-\ntured form, mostly XML or JSON. There are many interest-\ning WebAPIs for Social Science research.5 Most of the big\nonline social networks like Facebook and Twitter provide at\nleast limited access. Data repositories are also starting to\nimplement WebAPIs, for example, the World Bank\nIndicators, Yahoo! Finance, Google Analytics, which can be\ndirectly called from Python's Pandas package (together with\nsome other open data sources).\nInnovative methods\nThe types of data delivered by ICT are mostly interconnected\nby the design of the Internet as a network of billions of nodes.\nNetwork analysis is therefore a direct candidate for under-\nstanding the structure of relations between diverse actors\naround the globe. Furthermore, the Internet produces large\namounts of text in blogs, posts, messages, or news. They are\nan essential part of today's communications, regardless of\nwhether one-to-one (e.g. Skype, Facebook messaging), one-\nto-many (blogs, comments), many-to-one (Twitter accounts\nof prominent people), or many-to-many (group conversa-\ntions, forums). The potential of classic qualitative approaches\nto understand these texts through \"manual\" reading is clearly\nlimited because they do not scale very well. A more quantita-\ntive understanding as provided by \"natural language process-\ning\" is needed.\nFor both methods, convenient solutions are already imple-\nmented in Python in terms of the graph-tool (Peixoto, 2015)\nor NetworkX (Hagberg et al., 2008) as well as the Natural\nLanguage Toolkit (NLTK) (Bird et al., 2009). As discussed\nin the section \"New types of data,\" the volume of Big Data\nsets makes fast solutions more necessary than ever. To\nsupport our arguments, we will test the performance of the\nPython applications in comparison with the R environment\nand its respective solutions since R is often seen as stand-\nard solution for statistical analysis in Social Sciences\nTo demonstrate the performance of Python in regard to\nnetworks, we rely on a well-documented test that is con-\nducted by the author of the graph-tool package (Table 1).7\nThe network in question is a directed graph, with 39.796\nare considered (i.e. no multi-threading). As is expected,\nbetweenness centrality as a computational complex measure\ntakes most time (Brandes, 2001). The performance differ-\nences between packages are striking, but are not primarily\noccurring between Python and R, but if the respective pack-\nages are assembled in C++. Both graph-tool and igraph\nuse C++ and their performance is rather alike, with slight\nadvances for graph-tool except for the calculation of\nbetweenness centrality. NetworkX, in contrast, is a pure\nPython implementation and is by far the slowest of the pack-\nages. Thus, it is not the language alone that decides the\nperformance, but the package implementation.\nWith regard to text analysis, until now no comparison\nbetween Python and R exists. The most elaborated solution\nfor text analysis in R is included in the tm package (Feinerer\net al., 2008). We test the performance by using the \"Brown\ncorpus\" created in 1961 at Brown University.8 It was the first\nelectronic corpus in English with more than 1million words\nfor \"Part-of-speech tagging.\" The comparison has three steps\nand starts with the same \"corpus\" consisting only of\nsequences of tokens (i.e. no sentence or document structure):\nfirst, we run a basic cleaning procedure by removing a list of\n\"stop words\" (174 words used most often in the English lan-\nguage) and write all words in lower cases to avoid\nTable 1. Performance of packages in Python and R regarding social network analysis.\nMeasure Python graph-tool Python NetworkX R igraph\n6 Methodological Innovations\nambiguities. Second, we calculate the word frequency of all\nwords in the \"cleaned\" corpus. Third, the incorporation of a\nmore elaborated detection of topics within the corpus is con-\nducted using a \"Latent Semantic Analysis\" (Deerwester\net al., 1990), which is implemented in the \"genism\" package\nin Python (Rehurek and Sojka, 2010) and the \"lsa\" package\nin R (Wild, 2015). For this purpose, all words of each cate-\ngory are treated as one document, and the number of catego-\nries (15 in total) is used as the predefined number of topics\nthat should be retrieved.\nThe results in Table 2 show that Python and the NLTK\npackage largely outperform R. This is true for the simple\ncleaning procedures as well as for the calculation of the word\nfrequencies, indicating that R has problems with \"strings\"\nand, consequently, manipulating and/or counting text ele-\nments since it is designed for statistical analysis using vector\nmatrices. The NLTK package, in contrast, provides a very\nfast and convenient way to analyze large amounts of text. As\nwe have already seen with the analysis of networks, the per-\nformance depends very much on the package in use. Striking\nas the differences between Python and R in terms of simple\nword transformations may be, the performance of the LSA\npackage is much closer to its Python counterpart. Still, the\ntime R needs for the transformation of the \"bag-of-words\" in\na semantic space is nearly twice of Python.\nThe merit of this exercise lies not only in comparing dif-\nferent tools and packages but also in showing the differ-\nences across the ever-growing number of methods and\ntoolset. Besides contributing heavily to the development of\nnew methods and software solutions, CSS also offers the\nexpertise to decide which tool fits the job. Knowing how to\ntest and compare different implementations of the same\nmethod becomes increasingly important. Without some\nfamiliarity with algorithms and a basic knowledge of at\nleast one programming language, it is difficult to adequately\njudge or increase the performance of software. The digital\nliteracy provided by CSS can be seen as one of the greatest\nmerits this emerging field has to offer. Yet, this contribution\nof CSS can only be properly utilized if it becomes part of\nthe professional training of social scientists. A task for\nwhich Python seems to be especially well suited because of\nthe easy access it provides to basic programming tech-\nniques, as exemplified by Allen Downey's (2012) aptly\ntitled book Think Python. How to Think Like a Computer\nScientist.\nDoing sociology in the 21st century\nIt is not only the data sources and methods of Social Sciences\nthat are transformed by ICT. The same can be said about the\nday-to-day practices, meaning the way we do research, teach,\nreview literature, write articles, and so on. While we do\ndevote conferences, articles, and books to abstract models\nand research techniques, there is not much discussion about\nthe actual way scientists engage in their daily work life.\nSome disciplines may have manuals and protocols for inter-\nacting with dangerous or valuable equipment, but most\nprofessional expertise of scientists can be considered tacit\nknowledge, which is mostly acquired on the job.\nSince most of our work is nowadays in some way con-\nnected or mitigated through digital media, CSS offers a\nchance to make research more effective. Most of the practi-\ncal work of scientists involves processing information in one\nway or the other: sending emails, making presentations, for-\nmatting articles, preparing courses, just to name a few. Most\nof these tasks are necessary byproducts or pre-conditions for\ndoing actual research.\nObserving our own work flows and those of our col-\nleagues, we found that there are two main problems that\nseem to be responsible for a significant loss of time: first,\ndoing a machine's work the way a machine would do it; sec-\nond, using a patchwork of different, specialized programs\nmost of which are proprietary, thereby making it almost\nimpossible to know their exact inner workings or definitions\nand resulting in an inflexible workflow.9\nThe overall usefulness of machines lies in the fact that\nthey do exactly what they are told in a repetitive fashion.\nHumans would fail miserably if they would be given special-\nized machine tasks, while on the other hand machines would\nfail at tasks most humans, regardless of their training, would\nexcel at. While we are generalists, being able to switch seam-\nlessly between different tasks, machines are specialists\nwhose essential specialty is repetition. If you have ever\nworked in the Social Sciences, chances are you were asked\nto do machine tasks. Copying something from one Excel\nspreadsheet to another, albeit in a different layout, is still\nsurprisingly (and horrifyingly) common.10 Most of this work\nis apparently delegated to student workers, which basically\nmakes sure that future generations of social scientists will\nhave internalized bad practices from the start.\nBesides the essentially dehumanizing aspects, there are\nmany practical reasons to avoid giving machine jobs to\nTable 2. Performance of packages in Python and R regarding text analysis.\nProcedure Python NLTK R tm\nNLTK: Natural Language Toolkit; LSA: Latent Semantic Analysis.\nHeiberger and Riebling 7\nhumans. Most prominently: humans are bad at these tasks.\nOur species is prone to making errors when performing\nrepetitive tasks. Because a machine is instructed by humans\nvia code, their errors are essentially our errors as well, but in\nthis case we can find the error by looking at the code. More\nprecisely, human error seems to be mostly erratic, while\nmachine errors are systematic and can therefore be fixed.\nTragedies like the \"Excel Depression\" in economics\nremind us of the separation between human tasks and\nmachine ones. In this case, errors of experienced researchers\nand the reluctance to use reproducible code led to empirical\ninadequate political advice in regards to the financial crisis\nand contributed to the suffering resulting from the imple-\nmented austerity policies.\nInstead of doing a machine's job, CSS reminds us of the\nhuman job at hand. We are the ones constructing and instruct-\ning the machines. Only by learning complete programming\nlanguages and gaining at least some partial understanding of\ndigital technologies will we be able to delegate machine\ntasks effectively. Because these are relatively new skills for\nsocial scientists, we cannot rely on a pool of well-trained\nprofessionals to make this transition for us. Those of us who\ndo engage in CSS do so for the sake of their own research\nagendas and not to provide tech support to the rest of the\ndiscipline. Therefore, an easy accessible programming lan-\nguage like Python seems to be the right tool to bring digital\nliteracy to the Social Sciences. A simple understanding of\nwhat a machine can do and how one can access these capa-\nbilities to free oneself from the burdens of repetitive tasks in\norder to have more time for actual research should be enough.\nBecause Python is rather flexible, fast, and can be easily\nextended through modules, it is an excellent candidate for an\nintegrated framework for Social Science research (see also\nthe section `Innovative Methods'). Looking at the standard\npractices of the social scientists around us, we found that\nthey employ a mixture of different programs. For example,\nthey would manage their data using one program, analyze it\nin a second one, write it down in a third one, and finally use\na fourth one to create the presentation. Often other more spe-\ncialized programs like citation management software were\nadded to the mix. This is not necessarily detrimental to the\nspeed and effectiveness of the work process because people\ncan become very accustomed to these procedures. The prob-\nlem is the loss of flexibility and reproducibility because the\nentire work flow can become broken when some of the steps\nchange. Technical or methodological requirements can\nchange, leading, for example, to data formats no longer being\ncompatible with the programs used for analysis. The chain of\nprograms can break at any point because in such a work flow\nall points are interconnected but not necessarily maintained\nin one framework. This problem is enhanced by the use of\nproprietary software. A closed format has the consequence\nthat the user has to rely on the developers for ensuring com-\npatibility which results in work flows often being guided by\nthe implicit demands of the software instead of the explicit\nrequirements of the subject matter.\nAn integrated framework can help to lessen some of these\nproblems. However, the flexibility offered by such a frame-\nwork will inevitably come at the cost of reorientation and\nmakes it necessary to acquire at least some basic technical\nknowledge. The Jupyter (former IPython) Notebook keeps\nthis price very low, while at the same time offering a huge\nfunctionality. Basically, the notebook is a browser-based edi-\ntor which functions as a client connected to a kernel. Code\ncan be written inside a notebook and sent to the kernel which\nwill then return the results to this notebook. Since the project\nbecame language agnostic, many different additional kernels\nfrom various programming languages are offered (e.g. R,\nJulia, C, Perl). Besides its capability to execute code, the\nNotebook allows for easy text formatting in Markdown and\nHTML and provides native support for the rendering of\nmathematical equations through MathJax. The resulting\nnotebook can be converted to many different formats, which\ngiven a specific style template can be publication-ready,\nincluding figures and tables. Thanks to easy installable\nplugins like RISE, the notebook can also be rendered as a\nJSON slideshow by the click of a button. This slideshow is\nlive, meaning one can type in and execute code within the\nrunning presentation, which is especially helpful when it\ncomes to teaching and giving workshops. Jupyter Notebooks\ntherefore provide an integrated, open-source framework with\nall the functionality one could hope for.\nComputational theory building\nTheory is an instrument to explain what we observe and to\nput single elements in (abstract) relations. In other words,\ntheories are ideas about the mechanism behind the evidence\nthat a researcher gathers in order to systematize her observa-\ntions (Harrington, 2005: 3). These ordering frames should\nnot rely on certain schools of thoughts but on general rela-\ntionships between elements, their assumptions, and restric-\ntions (as done, for instance, in Friedkin (1986)). The best\nway to do this would be as a formal model because only as\nsuch a critical discourse can be ensured. A formal language\nallows us to focus on the results and their theoretical implica-\ntions rather than discuss the choice of words or argue\nsemantics.\nAlthough not much thought regarding theory has been\npublished in the current CSS literature, there exist attempts\nto model relations of actors to analyze social systems through\nthe interaction among autonomous, cognitive individuals\n(Conte et al., 2001). Theories of social choice point in the\nsame general direction. They are highly intertwined with\ncomputational methods and concentrate on social phenom-\nena also known from game theory regarding, for instance,\nresource allocation and fair division of goods (Chevaleyre\net al., 2007). These approaches are mostly used in combina-\ntion with social simulations, in which theoretically derived\n8 Methodological Innovations\nrules are tested in varying virtual contexts and are considered\none especially fruitful approach in CSS (Conte et al., 2012).\nHowever, agent-based modeling faces problems when it\ncomes to the aggregation of individual actions, which is why\nthese variants of rational choice theory have been heavily\ncriticized in Social Sciences (for a recent overview, see Watts\nferent degree) the second basic element of social theory in\naddition to individual action: structure. Not speaking for all\ntheories of social action in general, we nevertheless argue\nthat we are describing a common ground of theoretical think-\ning about social phenomena. For almost all theories, the rela-\ntion between structure and action is central, regardless of\nwhether it is spheres and individuals in Weber's work\n(Kalberg, 1980), structures and practices in field theory\ncommunications (Bailey, 1994), or, in contemporary rational\nchoice, whether it is the interplay (\"bridges\") between the\nframe of actions and the rational agent (Kroneberg and\nvariations on the concept of \"rationalizable action\" (p. 316)\nin the sense that rational (and computable) actions are\nassumed to be limited by some sort of boundary. This has\nbeen noted earlier and essentially led to the now famous\nnotion of a \"bounded rationality\" (Simon, 1982) of actors.\nAssuming that this general pattern of interdependence\nbetween structure and individual in social theory exists, we\nwant to transfer it to the process of coding. We think that\nspelling out each theory is a necessary step to write any use-\nful code for empirical studies since any code must be trans-\nlated in a formal language that the computer understands. In\norder to do this, the theoretical concepts in mind must be\nrewritten, that is, they have to be formalized. We exemplify\nfour steps that are essential for theory building, or even bet-\nter, for theoretical application since most theories should be\n\"testable\" with that approach.\n(1) The objects (agents) in question have to be defined\nand, hence, operationalized. In sociology, this can be indi-\nviduals, organizations, or any other form of (collective)\nactor. (2) The agents have certain attributes that can be latent\n(e.g. beliefs, expectations) or manifest (gender, age). The\nattributes are programmatically inherited by Python's\nclasses. This means that properties of objects are stemming\nfrom their affiliation to a certain class, resulting in a pattern\nof succession for derivations of these objects. (3) The objects\nhave certain relations with each other. This step has to be\nspecified, including whether self-loops (i.e. self-references)\nare useful. In the social world, these relations translate into\ninteractions between actors, for example, by ego communi-\ncating with alter, which may implicate ego as a person (or\nnation, organization, etc.) to a certain part. (4) The patterns\nof relations between the attributes of the interacting agents\nfrom the relations in (3) resemble Heinz von Foerster's\n(2007) notion of \"order from noise\" (p. 13). This means that\nthe cooperation of elements runs along intrinsic ordering\nproperties of a \"system,\" which can be any assemblage of\nelements. In sociological terms, we then observe structure\nin a sense that not every relation between every agent has an\nequal probability, but some relations \"are more equal than\nothers.\" This selection process stems directly from the irri-\ntations due to the attributes (and accompanying expecta-\ntions) of the actors in (2) since ego has to be aware of the\nexpectations of alter to arrange his own expectations. By\ndoing so (and not doing other things), certain patterns will\nemerge that can be generally interpreted as structures, for\nexample, cultural preferences, shared beliefs, or common\npersonal histories.\nThe process from (1) to (4) is thought to be recursive,\nmeaning that the \"heritage\" in terms of classes is memorized,\nbut updated continuously by every loop. In this manner,\nchange is incorporated in the model. This corresponds to the\nconcept of \"boundary objects\" that \"are plastic enough to be\nadaptable across multiple viewpoints, yet maintain continu-\nity of identity\" (Star, 1989: 37). The basic objects have such\na--programmatically inherited--contingency that they can\nbe defined as the researcher seems it appropriate but are open\nenough to change according to interaction and structure. In\nthis sense, a code application of the elements of general\nsocial theory avoids to think of interaction as a fixed mode in\nreality, but as something that is continually renegotiated.\nAlso, it is not the efficiency of agents (and their models)\nalone but mutual interaction and the iterative derivation of\nstructure and the recursive impact of this structure that con-\ndition action.11 Setting up a model in Python, the general lay-\nout of the language enforces a researcher to think along these\nlines.\nIn addition to the general structuring of theories by a\nformal language, Python also provides ways for the easy\nimplementation and construction of simulations. Specialized\npackages like SimPy12 and nxsim already exist, which are\nimplemented in an object-oriented fashion. As described\nunder step (1), the object-oriented framework lends itself\nespecially well to agent-based simulations. In this case, we\ncan define the base agents as objects with basic strategies\n(like cooperation and defection in the prisoner's dilemma)\nand subsequently use these objects as templates for more\nelaborate types of agents. This way we can progress from\nsimple games to iterative games to evolutionary and topologi-\ncal simulation (demonstrated in pure Python by Isaac, 2008).\nThe main advantage of using such an approach to simu-\nlation and modeling is twofold. First, it forces the scientist\nto be explicit in the construction of the model. Every step of\nthe model needs to be created in a formal language, leading\nto a precise and readable theory. Second, it allows for trial-\nand-error theory development. To test a new idea, ad hoc\nhypotheses or strategies can be easily incorporated in the\nsimulation, thereby creating a kind of experimental setting\nto explore new ideas and get a feeling for the far-reaching\nconsequences they might have when introduced to complex\nsystems.\nHeiberger and Riebling 9\nOutlook\nThe Internet has not only revolutionized our daily lives,\nglobal economic trade, or the work of intelligence agencies\nbut also the possibilities for researchers. In this article, we\ndiscussed certain obstacles of this development and why\nsocial scientists are until now bystanders in conducting\n\"CSS,\" a branch that studies the data delivered by the online\nsocial realm. While physicists and other natural scientists are\nalready exploiting the digital connections and their social\nconsequences, we diagnose that social scientists are gener-\nally not well-prepared for this endeavor.\nAs an initial countermeasure, we proposed the usage of\nPython as an easy-to-learn, general-purpose programming\nlanguage to facilitate the entrance to computational methods\nand complex new data. We argue that Python is a very con-\nvenient choice since it provides researcher with ample tools\nto handle the growing amount of rich data on human interac-\ntions and offers the prospect of addressing major, and funda-\nmentally interdisciplinary, scientific and social challenges.\nWe discussed its advantages in terms of appropriate struc-\ntures for the huge collections of data, the easy and fast imple-\nmentation of methods, the high practicability for operational\ntasks, and the usefulness of writing code in order to derive\nempirical applications from theoretical ideas. Beyond this, it\nis mostly the superior readability and accessibility that makes\nPython seem like a good choice to promote digital literacy\namong Social Scientists and thereby opening up the emerg-\ning field of CSS.\nA growing utilization of Python in Social Sciences may\nalso lead to an enhanced applicability of social scientists'\nresearch results. Consultation of practitioners could\nimprove from (rather costly) samples, their distributions,\nand correlations to very accurate, near real-time analysis of\nempirical social behavior that we can observe now \"live\nand in action,\" that is, how people relate to each other in\nvarious social contexts and not \"only\" agglomerations\nabout such social connections or limited examples with\nspecific properties. In this sense, the adaption of computa-\ntional techniques could bring many new opportunities to\nsocial scientists in order to share their expertise and to\nderive everyday-life applications out of our efforts--which\nwould also increase the probability of getting heard in pub-\nlic discussions and by decision makers. For instance, it\nwould be very practical in many circumstances to develop\nmore efficient ways to connect people and/or ideas over\nlarge geographical distances (Heiberger and Riebling, in\npress). Theoretically and methodically, this would mean to\nclose structural holes, a procedure that is already well\nestablished in SNA (Burt, 1995). The challenge at hand\nwould be to adapt these solutions developed for rather\nsmall groups on a much larger scale, that is, in fact, the\nwhole globe. What is already done in some privileged cor-\nporations and consultancies may be worthwhile to be\nexplored by social scientists. In this way, social scientists\ncould contribute to a better understanding of the complex\nsocial system that is now connected by a giant global infra-\nstructure with more transparent processes than any before.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with respect\nto the research, authorship, and/or publication of this article.\nFunding\nThe author(s) received no financial support for the research,\nauthorship, and/or publication of this article.\nNotes\n 1. We will not further elaborate in this article on general prob-\nlems of \"computational social science.\" This is done in other\n 2. Calculated by Randal Munroe in his \"What If\" Blog. This fig-\nure does not contain data in \"cold\" storage.\n 3. An overview over the essential packages needed to take a look\ninto Big Data analytics using Python and/or R can be found\nhere.\n4. There is a second, much more subtle reason to be skeptical\nabout the urgency to utilize Big Data methods in the Social\nSciences--the general timeframe in which a task should be\nexecuted. For example, no social network could afford to make\nits customers wait a week to connect with their friends. In the\ncontext of research and the construction of abstract models,\nthere is no need to rely on almost instant results.\n 5. We provided mostly hyperlinks to python wrappers for the\ngeneral Application Programming Interfaces (APIs) since\nwe focus on Python in this article. It should be mentioned,\nhowever, that wrappers in many different languages exist.\n7. https://graph-tool.skewed.de/performance\n8. http://clu.uni.no/icame/brown/bcm.html\n 9. Of course, there are many more inefficiencies and nonsensi-\ncal time-consuming activities forced upon scientists which\nare essentially beyond our own control. For example, journals\nnot providing formatting templates or administrative red-tape\ndoled out generously by universities.\n10. To give short anecdotal evidence of the \"tantalusian\" conse-\nquences: at the university of one of the authors, a research\nassistant was specifically hired to transfer data from a website\ninto an Excel sheet and to update that Excel sheet whenever\nthe data on the site changed. The real tragedy stems from the\nfact that the website essentially serves XML data. Years ago,\nwe had been asked to do a similar task; using an ordinary\nphone we called the site's administrator and simply asked him\npolitely to send us a copy of the data in question. This helps to\nshow that the problem lies not only in the absence of techni-\ncal expertise. As long as we are willing to do a machine's job,\nsomeone else gets to do the human job.\n11. These issues of mutual influence within and between com-\nplex social entities are, for instance, also discussed in Niklas\nLuhmann's (1990) comprehensive work about social systems.\n10 Methodological Innovations\nHis ideas, in turn, are strongly based on findings about mecha-\nnisms of self-organization and perpetuation in biological sys-\n12. A module for process-oriented discrete simulations.\nReferences\nBail CA (2012) The Fringe Effect Civil Society Organizations\nand the evolution of media discourse about Islam since the\nSeptember 11th attacks. American Sociological Review 77:\nBail CA (2014) The cultural environment: Measuring culture with\nBailey KD (1994) Sociology and the New Systems Theory: Toward\na Theoretical Synthesis. Albany, NY: SUNY Press.\nBird S, Klein E and Loper E (2009) Natural Language Processing\nwith Python--Analyzing Text with the Natural Language\nToolkit. Sebastopol, CA: O'Reilly Media.\nBourdieu P (1977) Outline of a Theory of Practice. Cambridge,\nUK: Cambridge University Press.\nBrandes U (2001) A faster algorithm for betweenness centrality.\nBuldyrev SV, Parshani R, Paul G, et al. (2010) Catastrophic cas-\ncade of failures in interdependent networks. Nature 464:\nBurrows R and Savage M (2014) After the crisis? Big Data and the\nmethodological challenges of empirical sociology. Big Data\nBurtRS(1995)StructuralHoles:TheSocialStructureofCompetition\n(reprint edition). Cambridge, MA: Harvard University Press.\nChevaleyre Y, Endriss U, Lang J, et al. (2007) A short introduction\nto computational social choice. In: van Leeuwen J, Italiano\nGF, van der Hoek W, et al. (eds) SOFSEM 2007: Theory and\nPractice of Computer Science. Berlin, Heidelberg: Springer,\nCioffi-Revilla C (2014) Introduction to Computational Social\nScience (Texts in Computer Science). London: Springer.\nConteR,EdmondsB,MossS,etal.(2001)Sociologyandsocialtheory\nin agent based social simulation: A symposium. Computational\nConte R, Gilbert N, Bonelli G, et al. (2012) Manifesto of compu-\ntational social science. European Physical Journal: Special\nDe Vaan M, Stark D and Vedres B (2015) Game changer: The\ntopology of creativity. American Journal of Sociology 120:\nDeerwester S, Dumais ST, Furnas GW, et al. (1990) Indexing by\nlatent semantic analysis. Journal of the American Society for\nDiekmann A, Jann B, Przepiorka W, et al. (2014) Reputation for-\nmation and the evolution of cooperation in anonymous online\nDowney A (2012) Think Python: How to Think Like a Computer\nScientist. Sebastopol, CA: O'Reilly Media.\nDumbill E (2012) What Is Big Data? O'Reilly Media. Available\nat: https://beta.oreilly.com/ideas/what-is-big-data (accessed 3\nFeinerer I, Hornik K and Meyer D (2008) Text mining infrastruc-\nture in R. Journal of Statistical Software 25: 1\u00ad54.\nFligstein N and McAdam D (2012) A Theory of Fields. New York:\nOxford University Press.\nFreeman LC (2011) The development of social network analysis--\nWith an emphasis on recent events. In: Scott J and Carrington\nPJ (eds) The SAGE Handbook of Social Network Analysis.\nFreeman LC and Webster CM (1994) Interpersonal proximity in\nFriedkin NE (1986) A formal theory of social power. Journal of\nGiles J (2012) Computational social science: Making the links.\nGirvan M and Newman ME (2002) Community structure in social\nand biological networks. Proceedings of the National Academy\nGoel S, Hofman JM, Lahaie S, et al. (2010) Predicting consumer\nGolder SA and Macy MW (2011) Diurnal and seasonal mood\nvary with work, sleep, and daylength across diverse cultures.\nHagberg AA, Schult DA and Swart PJ (2008) Exploring net-\nwork structure, dynamics, and function using NetworkX. In:\nVaroquaux G, Vaught T and Millman J (eds) Proceedings of\nthe 7th Python in Science Conference (SciPy2008): Presented\nhttp://conference.scipy.org/proceedings/scipy2008/paper_2/\nHarrington A (2005) Modern Social Theory. Oxford: Oxford\nUniversity Press.\nHeiberger RH (2014) Stock network stability in times of crisis.\nPhysica A: Statistical Mechanics and its Applications 393:\nHeiberger RH (2015) Collective attention and stock prices:\nEvidence from Google Trends Data on Standard and Poor's\nHeiberger RH and Riebling J (2015) U.S. and whom? Structures\nand communities of international economic research. Journal\nHelbing D (2012) Introduction: The FuturICT knowledge accelera-\ntor towards a more resilient and sustainable future. European\nHerndon T, Ash M and Pollin R (2014) Does high public debt con-\nsistently stifle economic growth? A critique of Reinhart and\nHomans GC (2003) The Human Group. New Brunswick, NJ:\nTransaction Publishers.\nIsaac AG (2008) Simulating evolutionary games: A Python-\nbased introduction. Journal of Artificial Societies and Social\nKalberg S (1980) Max Weber's types of rationality: Cornerstones\nfor the analysis of rationalization processes in history.\nKarsai M, Kivel\u00e4 M, Pan RK, et al. (2011) Small but slow world:\nHow network topology and burstiness slow down spreading.\nKerzner M and Maniyam S (2013) Hadoop Illuminated. Hadoop\nIlluminated LLC. Available at: http://hadoopilluminated.\ncom/hadoop_illuminated/hadoop-illuminated.pdf\nKing G (2011) Ensuring the data-rich future of the social sciences.\nHeiberger and Riebling 11\nKroneberg C and Kalter F (2012) Rational choice theory and empir-\nical research: Methodological and theoretical contributions in\nLazer D, Kennedy R, King G, et al. (2014) The parable of Google\nLazer D, Pentland A, Adamic L, et al. (2009) Computational Social\nLehmann TC, Rolfsen JA and Clark TD (2015) Predicting the\ntrajectory of the evolving international cyber regime:\nSimulating the growth of a social network. Social Networks\nLewis K, Kaufman J, Gonzalez M, et al. (2008) Tastes, ties, and\ntime: A new social network dataset using Facebook.com.\nLuhmann N (1990) Essays on Self-Reference. New York: Columbia\nUniversity Press.\nLutter M (2015) Do women suffer from network closure? The\nmoderating effect of social capital on gender inequality\nMcCullough BD (2010) Econometric computing with R. In: Vinod\nHD (ed.) Advances in Social Science Research Using R. New\nMaturana HR and Varela F (eds) (1973) Autopoiesis and Cognition:\nThe Realization of the Living. Dordrecht: D. Reidel.\nMay RM, Levin SA and Sugihara G (2008) Complex systems:\nMilgram S (1967) The small world problem. Psychology Today 2:\nOnnela J-P, Saram\u00e4ki J, Hyv\u00f6nen J, et al. (2007) Structure and\ntie strengths in mobile communication networks. PNAS 104:\nPeixoto TP (2015) graph-tool: Efficient network analysis with\npython. Available at: https://graph-tool.skewed.de/ (accessed\nQin X, Cunningham P and Salter-Townshend M (2015) The\ninfluence of network structures of Wikipedia discussion\npages on the efficiency of WikiProjects. Social Networks\nRehurek R and Sojka P (2010) Software framework for topic mod-\nelling with large corpora. In: Proceedings of the LREC 2010\nworkshop on new challenges for NLP frameworks, 22 May,\nReinhart CM and Rogoff KS (2011) The forgotten history of\nRuths D and Pfeffer J (2014) Social media for large studies of\nSavage M and Burrows R (2007) The coming crisis of empirical\nSchweitzer F, Fagiolo G, Sornette D, et al. (2009) Economic\nScott J and Carrington PJ (2011) The SAGE handbook of social\nnetwork analysis. Los Angeles, CA: SAGE.\nSimon HA (1982) Models of Bounded Rationality: Empirically\nGrounded Economic Reason. Cambridge, MA: MIT Press.\nStar SL (1989) The structure of Ill-structured solutions: Boundary\nobjects and heterogeneous problem solving. In: Gasser LM\nand Huhns N (eds) Distributed Artificial Intelligence. London:\nSteane A (1998) Quantum computing. Reports on Progress in\nVon Foerster H (2007) Understanding Understanding: Essays\non Cybernetics and Cognition. New York: Springer\nScience+Business Media.\nUprichard E (2013) Big Data, Little Questions? Discover Society.\nAvailable at: http://www.discoversociety.org/focus-big-data-\nWassermann S and Faust K (1994) Social Network Analysis:\nMethods and Applications. Cambridge, MA: Cambridge\nUniversity Press.\nWatts DJ (2004) The \"New\" science of networks. Annual Review of\nWatts DJ (2014) Common sense and sociological explanations.\nWatts DJ and Strogatz SH (1998) Collective dynamics of \"small-\nWild F (2015) LAS: Latent Semantic Analysis. Available at: https://\ncran.r-project.org/web/packages/lsa/index.html\nWimmer A and Lewis K (2010) Beyond and below racial\nhomophily: ERG models of a friendship network docu-\nmented on Facebook. American Journal of Sociology 116:\nAuthor biographies\nRaphael H. Heiberger is a postdoc at the Institute for Sociology\nat the University of Bremen. His primary research interests are in\nsocial network analysis, statistical computing, and econophysics.\nJan R. Riebling is a doctoral student at the chair of theoretical soci-\nology at the university of Bamberg. His main research interests are\ncomputational models of social symbols, mathematical sociology\nand network analysis."
}