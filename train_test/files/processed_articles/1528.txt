{
    "abstract": "O'Muircheartaigh, C., Eckman, S., & Smith, S. (2009). Statistical design and estimation for the national social life, health, and aging project. Journal of Gerontology: Social Sciences, 64B(S1), i12\u00adi19, \u00a9 The Author 2009. Published by Oxford University Press on behalf of The Gerontological Society of America.",
    "reduced_content": "O'Muircheartaigh, C., Eckman, S., & Smith, S. (2009). Statistical design and estimation for the national social life, health, and aging project. Journal of Gerontology: Social Sciences, 64B(S1), i12\u00adi19,\n\u00a9 The Author 2009. Published by Oxford University Press on behalf of The Gerontological Society of America.\nAll rights reserved. For permissions, please e-mail: journals.permissions@oxfordjournals.org.\nTHE overall goal of the National Social Life, Health, and\nAging Project (NSHAP) is to study the links between\nhealth and sexuality in the lives of older Americans. The\nsample and estimation plan that we developed was intended\nto generate an observed sample that can be generalized to\nthe target population: U.S. adults aged 57\u00ad85 years living in\nhouseholds. The foundation of the design is a probability\nsample that gives each element in the population a known\nnonzero chance of being selected into the sample. The NS-\nHAP sample is based on a standard multistage area proba-\nbility design, which selects large area units at the first stage,\nsmaller area units at the second stage, and households at the\nthird stage. National Opinion Research Center (NORC)\nentered into a partnership with the Survey Research Center\nat the University of Michigan, and together they conduct the\nHealth and Retirement Study (HRS) for these stages of the\ndesign, an arrangement which benefited both surveys. Se-\nlection of eligible members from these households used an\ninnovative sampling technique to meet a variety of design\ngoals and constraints. The next two sections of this paper\ngive details on the NSHAP sample design.\nAfter selection of individuals for the NSHAP survey,\nNORC interviewers visited each case to complete a face-to-\nface interview and conduct biomeasures using a modular-\nized questionnaire design to reduce respondent burden. We\nachieved a response rate of 75.5%. Below we discuss the\nfieldwork and its effect on estimation in more detail.\nWe discuss the details of the NSHAP sample design not\nonly because it provides important ideas for future surveys of\nsimilar populations but also because an understanding of the\ndesign is crucial in calculating appropriate estimates and their\nstandard errors. The final two sections of the paper discuss\nthe implications of the design for estimation procedures.\nSample Design\nThe NSHAP sample consisted of multiple stages of selec-\ntion: (a) two area stages, in which geographic areas were\nselected into the sample with probabilities proportional to\ntheir sizes, (b) a household selection stage in which a sample\nof households was selected from the selected areas for\nscreening, (c) an individual selection stage in which persons\nwere selected for the NSHAP interview. These stages to-\ngether determine the probabilities of selection of the individ-\nuals in the study. This design is a classic multistage area\nprobability sample (for details on this class of sample designs,\nsee Harter, Eckman, English, & O'Muircheartaigh, in press).\nNSHAP wished to interview adults aged 55\u00ad85 years.\nHowever, only approximately 30% of U.S. households con-\ntain an individual in this age range. Identifying such house-\nholds and the eligible individuals within them would have\ninvolved an extremely expensive (about $2 million) and\ntime-consuming screening of a large sample of households.\nAt the time that we were planning the NSHAP design, the\nHRS (also funded by the National Institute on Aging) was\nabout to embark on the recruitment of a new cohort. Through\nan innovative collaboration between NSHAP and HRS (and\nbetween the NORC and the Institute for Social Research\n[ISR], the respective survey organizations), the screening\nfor both surveys was carried out as a single operation, with\nStatistical Design and Estimation for the National Social\nLife, Health, and Aging Project\nColm O'Muircheartaigh,1,2 Stephanie Eckman,2 and Stephen Smith2\n1Harris School of Public Policy and 2National Opinion Research Center, University of Chicago, Illinois.\nObjectives. The paper discusses the sample design of the National Social Life, Health, and Aging Project (NSHAP)\nand how the design affects how estimates should be calculated from the survey data. The NSHAP study allows research-\ners to study the links between sexuality and health in older adults. The goal of the design was to represent adults aged\nMethods. The sample design begins with a national area probability sample of households, carried out jointly with the\n2004 round of the Health and Retirement Study. Selection of respondents for NSHAP balanced age and gender subgroups\nand oversampled African Americans and Latinos. Data collection was carried out from July 2005 to March 2006.\nResults. The survey obtained an overall response rate of 75.5%.\nDiscussion. The complex sample design requires that the selection probabilities and the field implementation be ac-\ncounted for in estimating population parameters. The data set contains weights to compensate for differential probabili-\nties of selection and response rates among demographic groups. Analysts should use weights in constructing estimates\nfrom the survey and account for the complex sample design in estimating standard errors for survey estimates.\nKey Words: Design effect--Health--Sample design--Sample size--Sexuality.\nsubstantial saving in costs. As HRS interviewers screened\nhouseholds in the selected segments for individuals eligi-\nble for their survey, they also identified individuals who\nwere eligible for NSHAP. HRS screening took place from\nFebruary to November 2004. At the end of their data col-\nlection period, they sent all NSHAP-eligible individuals to\nNORC, and we selected our final sample of households\nand individuals from this database. This sharing of field\nresources allowed NSHAP to have a much larger sample\nsize than would otherwise have been possible. However,\nthis collaboration did require that the NSHAP redefine its\ntarget population to adults aged 57\u00ad85 years. This change\nmeant that the HRS and NSHAP populations were nearly\nnonoverlapping.\nCoverage of the Sampling Frame\nUndercoverage occurs whenever some eligible persons\nhave no chance to be selected for the survey. There are two\nminor sources of undercoverage in the NSHAP design:\nFirst, as the survey was to be carried out as a household\nsurvey, the population was limited to adults living in house-\nholds; thus, the institutionalized population and the home-\nless were excluded; second, those absent from the country\nduring the period of the fieldwork were excluded.\nThe only substantial source of undercoverage arises from\nthe link between HRS and NSHAP fieldwork. HRS was\nrecruiting the 50- to 56-year-old cohort (the Early Baby\nBoomers) and their partners as well as the next cohort, the\n44- to 49-year-old Middle Baby Boomers and their partners.\nDue to HRS's complex eligibility rules, 57- to 85-year-olds\nliving in households with 44- to 56-year-old nonpartners\nwould not be available for NSHAP by virtue of their resi-\ndence in the household of an HRS-eligible individual.\nTo estimate the magnitude of the undercoverage due to\nthe loss of these nonpartners, we used the household com-\nposition data in the U.S. Census Bureau's Public Use Mi-\ncrodata Set. Overall, we estimated that this constraint could\nexclude just more than 5% of the NSHAP-eligible popula-\ntion (6% of the eligible women and 4% of the men). This is\na relatively low degree of undercoverage overall, but there\nis some concern that those excluded would be concentrated\nin particular (and potentially interesting) subclasses of the\npopulation. The most common reason that we expected in-\ndividuals to be excluded was that they were living with an\nadult child. Other common reasons included living with a\nsibling, an unmarried partner, or an unrelated housemate.\nData about the excluded cases from the HRS recruitment\nprocess itself are not available.\nArea Stages of the Design\nThe sample designs for NSHAP and HRS are identical at\nthe area stages. The first stage consists of primary sampling\nunits (PSUs; either metropolitan areas or counties) selected\nwith probability proportional to size. Within selected PSUs,\nsecond stage units (segments) were formed from Census\nblocks and selected with probability proportional to size. In\norder to generate sufficient sample size forAfricanAmerican\nand Latino subsamples, the probabilities of selection of seg-\nments with more than 10% African American or Latino\npopulation were more than doubled relative to all other seg-\nments. This meant that all adults living in these segments,\nwhether African American or Latino, or not, were overrep-\nresented in the sample at this stage. The spatial correspon-\ndence between the HRS and NSHAP samples also has\nsignificant potential for future joint analyses of the data\nfrom the two surveys. For details on selection of multistage\narea probability samples generally, see Harter et al. (in\npress). At the time of this writing, some details on the HRS\n2004 design were available at the HRS Web site at the Insti-\ntute for Social Research, University of Michigan; see http://\nhrsonline.isr.umich.edu/.\nWithin these selected segments, a full listing of housing\nunits (households) was carried out by HRS field staff. Health\nand Retirement Study interviewers selected 30,000 house-\nholds from those listed. Although they planned to select\nhouseholds with equal probability within four domains de-\nfined by the concentration of minorities, they deviated from\nthis plan and oversampled segments, regardless of domain,\nthat were found to have higher proportions of eligible per-\nsons. HRS also subsampled cases to hasten the end of the\nfieldwork (private correspondence from HRS statisticians).\nISR then delivered all screened households containing at least\none NSHAP-eligible member (except as discussed earlier),\nand we performed additional stages of selection.\nDesign for Sample of Households and Individuals Within\nHouseholds\nIn planning the analyses we wished to run with the NSHAP\ndata, we indentified six domains of interest, that is, sub-\nclasses of the population for which separate estimates would\nbe required: three age groups, each subdivided by gender. We\ndetermined, using approximate power calculations, that a\nsample size of 500 would be required for each subclass,\ngiving an overall sample size of 3,000. The binding con-\nstraints are those for men and women in the oldest age group.\nAlthough we did not use race or ethnicity in the formation of\nour explicit domains, another design goal was to overrepre-\nsent African Americans and Latinos in our final sample.\nA general principle of estimation is that, ceteris paribus,\na sample design in which individuals are selected with equal\nprobabilities will provide more precise estimates (estimates\nwith smaller standard errors) than a sample in which the\nprobabilities vary arbitrarily from individual to individual\nviduals into the study from the frame provided to us by the\nHRS screening, we wished to equalize the probabilities of\nselection of the individuals as much as possible within our\nsix domains.\nTo avoid possible within-household contamination of re-\nsponses, we also wanted to select no more than one person\nin any household. This decision made it much more difficult\nto meet our domain targets as the number of respondents\navailable for selection into a particular sample was thereby\nmuch reduced. For example, a household containing an\n82-year-old woman and an 84-year-old man contains an in-\ndividual from our two challenging domains, but it was not\npossible to have both of them in the sample.\nThe screener data delivered by ISR contained 7,407\nhouseholds, each of which contained at least one person\nborn before 1948, together with data on adults within these\nhouseholds. Sample eligibility for NSHAP was defined\nof the delivered households had at least one person born in\nthis range (9,816 eligible people). Twenty-three percent of\nthe eligible people were identified as African American and/\ntuted the sampling frame for the selection of individuals for\nFrame preparation.--The HRS interviewers attempted to\ncollect name, race/ethnicity (race was collected in the HRS\nscreener instrument as a dichotomous variable: minority\n[meaning African American or Latino] and nonminority [all\nothers]), and birth year for all eligible individuals in the\nhouseholds they screened. The data quality was imperfect,\nwith design and estimation implications. Several steps were\nnecessary to prepare the frame for the sample selection pro-\ncess: gender coding, gender and race imputation, and sub-\nsampling in segments oversampled by HRS due to race/\nethnic composition.\nThe HRS screening operation did not collect gender.\nBecause gender was so important to the NSHAP sample\ndesign, we coded gender for each age-eligible case from\nname and family relationship data. In conducting the\nhousehold roster to identify individuals eligible for\nNSHAP and HRS, interviewers permitted respondents to\nidentify household members by initials or family roles\n(\"husband,\" \"abuela\") rather than by names. Tourangeau,\nShapiro, Kearney, and Ernst (1997) find that this can\nreduce undercoverage in rosters. We coded 87.52% of the\neligible cases (12.48% contained no data from which we\ncould deduce gender) and 52.09% of these were deter-\nmined to be women.\nWe imputed gender for the 12.48% of cases where it\ncould not be determined, and we imputed race/ethnicity for\nthe 1.23% of cases where it was missing. Age was not miss-\ning for any cases on the frame. For gender, imputation was\ndone systematically, sorted on PSU, segment, and individual\nwithin segment. After this step was completed, the eligible\nindividuals consisted of 52.10% women. Imputation of\nrace/ethnicity was based on the dominant race of the seg-\nment. In 19 of the 416 segments, African American/Latino\nindividuals were the dominant group and all cases with\nmissing race/ethnicity were imputed to this category. In all\nother segments, cases with missing race/ethnicity data were\nimputed to \"not African American/Latino.\" After this step\nwas completed, 22.61% of eligible individuals were coded\nas African American/Latino. Gender and race imputation\nwas carried out only to form strata for use in the sample\nselection process: The final sample file does not include\nthese imputed variables.\nThe HRS national sample design oversampled segments\nwith high minority concentration and household within\nthese segments, introducing unequal probabilities of selec-\ntion for all residents in these segments. Our design inten-\ntion, however, was to increase the selection probabilities\nonly for African American and Latino individuals. To re-\nduce diversity of selection probabilities of nonminorities in\nthese segments (and thus produce a sample that has more\nnearly equal probability), we subsampled these cases. Prior\nto the selection of households for interview, we selected a\nsample of nonminority individuals (not households) and\ndiscarded them from the frame. (Because additional sub-\nsampling was carried out by ISR during the screening, this\nadjustment did not fully equalize the selection probabilities\namong the nonminority cases.)\nAfter imputation and subsampling, the final frame con-\nerage of 1.31 eligible members per household). In total\nwere racial/ethnic minorities. Individuals were coded into\nthree age categories based on year of birth: 49.11% of eli-\ngible individuals were in the first age category (57\u00ad65 years;\nSize of sample.--Our objective was to complete inter-\nviews with 3,000 eligible respondents, with approximately\n500 completed interviews in each of the six age/gender do-\nmains. We anticipated a 5% ineligibility rate (although the\nsample had been recently screened, we did expect some loss\ndue to moving or death) and a response rate of 70% or a\nlittle more. Thus, the necessary number of cases to issue to\nsentation, we felt that we should maximize the response\nrate; consequently, we decided to select 4,400 individuals\nfrom the frame; to generate 3,000 interviews under our as-\nsumption of 5% ineligibility, this would require a response\nSample Selection\nThe objective was to draw a sample of 4,400 people with\nequal sample sizes in the six target domains. The con-\nstraints we faced were to select only one individual per\nhousehold and as much as possible equalize selection prob-\nabilities within domains. The overall selection probability\nof a case is the product of the probabilities at each stage:\nPSU, segment, household (including subsampling by\nHRS) subsampling of nonminority cases after screening,\nand selection of households and individuals within house-\nholds for interview. Our goal in selecting households and\nindividuals for NSHAP was to manipulate these last two\nprobabilities such that the overall probability of selection\nwas nearly constant across all cases in each domain; the\ncloser a sample is to having equal probabilities (referred to\nas an equal probability of selection method sample), the\nhigher the precision, ceteris paribus. We devised an itera-\ntive process that would select individuals with probabili-\nties as close to these ideal probabilities as possible; details\nare given in Appendix A.\nResult\nThe final sample consisted of 4,400 individuals, distrib-\nuted as shown in Tables 1 and 2. We were not able to achieve\nequal numbers of selections in each of the six age\u00adgender\ncells, but we came as close as we could given the fixed size\nof the screened sample and our additional constraints. In\nhad unknown race. In total, 18.35% had first and/or last\nname missing (13.45% had first name missing). (In Tables 1\nand 2, cases with unknown gender or race are shown by\ntheir imputed values.)\nData Collection Issues\nAt each stage of implementation, there are deviations\nfrom the optimal or intended execution. These arise from\nnonresponse in the screener, nonresponse in the interview,\nand other random deviations from the expected outcomes.\nWhenever feasible, we provide weights to compensate (in\npart at least) for these deficiencies.\nScreener Response\nThe overall screener completion rate was 95%. As the NS-\nHAP sample used the screened sample as a frame, this 5%\nshortfall is essentially noncoverage for NSHAP. We do not\nknow the NSHAP eligibility rate among these unscreened\nhouseholds. We do not make any adjustments to the weights\nfor this undercoverage, which is equivalent to assuming that\nthe unscreened cases are identical to the screened cases.\nModularization of the Questionnaire and Biomeasures\nAs discussed in Smith and colleagues (2009), we con-\nducted a pretest of our questionnaire and interviewing\nmethods. The pretest showed that collecting all the data on\neach respondent would make the interview unacceptably\nlong and would very likely seriously compromise the NS-\nHAP response rate. To reduce respondent burden to an ac-\nceptable level while obtaining population-representative\ndata on as many key variables as possible, a modular imple-\nmentation was designed. All respondents received a set of\ncore interview and biomeasure items; the remaining mea-\nsures were allocated to two questionnaire modules and\nthree biomeasure modules. Respondents were randomly\nassigned to one of six paths containing a set of these mod-\nules. The paths and their contents are described in Smith\nand colleagues. Respondents assigned to paths where mod-\nularized interview questions were not asked were instead\ngiven a mail-in self-administered questionnaire that in-\ncluded these items. As a check on the fidelity of implemen-\ntation of the randomization, Table 3 shows the number of\ncompleted interviews for each of the six paths. A c2 test of\n(not significant).\nThe modularization affects the design (and consequently\nthe estimation) in two ways. First, the number of cases\nfor which data are available varies depending on whether\na measure was included in the core or only in one or more\nTable 1. Final Sample Counts (race and gender imputed where necessary)\nFemale\nFemale total\nMale\nMale total Grand total\nTable 2. Final Sample Percentages (race and gender imputed where necessary)\nFemale\nFemale total\nMale\nMale total Grand total\nNot African American/Latino\nBlack/Hispanic\nof the modules; the expected variance is essentially in-\nversely proportional to the number of cases, and thus,\nsome estimates will have larger variances than others sim-\nply because they were asked of fewer cases. Second, for a\nnumber of questionnaire items, some respondents will\nhave received the items in a face-to-face interview, whereas\nothers will have completed them in a self-completed ques-\ntionnaire. Whenever data collection modes are mixed in\nthis way, the possibility of a mode effect arises: The mode\nof collection may influence the data reported by the re-\nspondent. (A review of the extensive literature on mode\neffects is outside the scope of this paper, but see AAPOR,\nResponse Rates and Nonresponse Bias\nA survey response rate is defined as the rate of success-\nful completion of interviews. It is generally interpreted as\na measure of how successfully the responding cases repre-\nsent the population. In the case of an equal probability\nsample design, this is simply the percentage of selected\neligible cases for which an interview is obtained. In the\ncase of a sample where selection probabilities vary across\ndifferent domains in the population, the definition of the\nresponse rate is more complex, and the simple unweighted\nrate is inappropriate. In estimating a characteristic of the\npopulation, survey data should be weighted to take into\naccount probabilities of selection; otherwise, the estimate\nwould overrepresent cases with low probabilities of selec-\ntion. The calculation of response rates is no different.\nThe American Association for Public Opinion Research\n(AAPOR) provides a document that explains in detail how\nresponse rates should be calculated for different modes\nand sample designs (Groves, 2006; Groves & Couper,\nTable 4 presents the weighted response rates, using\nAAPOR's RR2, for the survey as a whole and for selected\ndomains. Although we do not show the unweighted re-\nsponse rates, they are very similar to the weighted rates,\nreflecting the relative uniformity of the response rates across\nthe different domains of the sample design.\nWhenever a survey fails to interview all eligible cases,\nthere is potential for nonresponse bias. Bias can be intro-\nduced into survey estimates when the nonresponding cases\nare different from the responding cases. Understanding,\npreventing, and adjusting for nonresponse is an active area\nof research in the survey methodology field, and a discus-\nsion of this literature is not possible here; Kalton and\nWe can examine response rates across domains to gauge\nthe risk of nonresponse bias in the measures collected by\nNSHAP. We see in Table 4 that response rates vary 8%\npoints across the three age groups, four points between the\nurban and nonurban groups, and only 2.5 points between\nmen and women. There is a 4.5-point difference in re-\nsponse rates for minority and nonminority households\n(and much larger differences between these and house-\nholds of unknown minority status, though there are few\ncases in these cells). We find these results somewhat reas-\nsuring: they suggest that demographically the respondents\nand the nonrespondents seem to be similar. In a later sec-\ntion, we discuss how we adjusted the weights to account\nfor nonresponse.\nThe earlier discussion has focused on unit response rates,\nwhich measure response to the survey as a whole, but we\nare also concerned with response rates and nonresponse\nbias on specific items or sets of items. For the face-to-face\ninterview, item response rates (again weighted to account\nfor differential selection probabilities) were uniformly\nhigh. The response rate to the mail-back survey was satis-\nThe biomeasures, similarly, had commendably high re-\nsponse rates, but we believe that this set of items might show\nmore nonresponse bias than others; those who agreed to the\nbiomeasures may have different health status than those who\nrefused them outright. We suggest that analysts consider im-\nputing biomeasure results for those cases that refused them\nbefore generating population estimates based on the ob-\nserved cases (Jaszczak, Lundeen, & Smith, 2009). For more\ndetails on the collection of the biomarker variables in the\nNSHAP interview, see Kalton and Kasprzyk (1986).\nTable 3. Random Assignment of Modules\nPath (all paths contain the core\nquestionnaire, core biomarkers, and core\nleave-behind questionnaire) No. of cases Test\n(not significant)\n3 Modules A, B, and E; module B\nas leave behind\n4 Modules A, C, and E; module B\nas leave behind\n3 Modules B, C, and D; module A\nas leave behind\n3 Modules B, C, and E; module A\nas leave behind\nTable 4. Overall and Domain Response Rates\nWeighted response rate (%)\nMinority Status Not Known by HH informant\n(HH level)\nMinority refused (HH level) 44.1\nNote: HH = household.\nSample Outcomes\nIn all, we completed interviews with 3,005 selected re-\ngive the numbers of interviews achieved in each of the six\nage/gender domains. Table 5A presents the a priori classifi-\ncation of respondents based on the screener data (imputed\nwhere necessary, see above); Table 5B presents the a poste-\nriori classification (corrected with interview data where\npossible). The two tables are quite close, though we see a\nslight tendency to misclassify more women than men and to\nunderstate the numbers in the highest and lowest age\nclasses.\nWeighting\nThe complex design of NSHAP requires that the data\nbe weighted in the analysis in order to provide unbiased\nestimates of population characteristics. We provide two\nweight variables to meet the needs of researchers. The steps\nin the construction of the weights are given subsequently.\nBaseweight\nThe selection probability for each case in the NSHAP\nsample is the product of its household's probability of selec-\ntion for the HRS screening operation (HRS) and its proba-\nbility of selection for the NSHAP survey, given its selection\nfor HRS (NSHAP). The first probability includes the proba-\nbility of selection of the PSU and segment that contain the\ncase and the probability of selection of the household within\nthe segment, as well as any subsampling adjustments late in\nthe HRS field period. (As mentioned earlier, HRS carried\nout some modest subsampling of cases both to improve the\nhit rate of HRS-eligible households and to speed up the\nclose of data collection.) The components of the second\nprobability are any adjustments due to the subsampling of\nnonminority cases in minority segments, the probability of\nselection of the household for NSHAP, and the probability\nof selection of the given individual within the household.\nThe baseweight is the inverse of the overall unconditional\nprobability of selection: baseweight = (HRS\n\u00b4 NSHAP)-1.\nAdjustment for eligibility at the time of interviewing.--\nNot all screened cases were truly eligible for the NSHAP\nsurvey; some were outside the eligible age range, others had\nmoved out of the study population; the ineligible cases are\nnot included in the final data set. The weights for eligible\ncases were unchanged in this step. (No cases were finalized\nwith unknown eligibility status.)\nAdjustment for Nonresponse\nNonresponse of any magnitude threatens the basis of in-\nference from the survey data to the population. We provide\nan adjustment to the weights to account for nonresponse.All\nnonresponse adjustments rely on a model that makes as-\nsumptions about the nonrespondents. The method we used,\nwhich Kalton and Kasprzyk (1986) call sample-based\nweighting, assumes that once we control for a few key char-\nacteristics, nonrespondents are like respondents. The only\nvariables that can be used to control for nonresponse are\nthose that exist on both the responding and the nonrespond-\ning cases. Age and race/ethnicity provided the greatest dis-\ncrimination in response rates (see Table 4). In each of the six\ncells formed by crossing age and race/ethnicity, weights for\nresponding cases were increased by the reciprocal of the\ncell-level response rate such that the responding cases take\non the weight of the nonresponding cases. To the extent that\nthe correspondence between respondents and nonrespon-\ndents is closer within these adjustment classes than it is\noverall, adjusting the weights separately within these classes\nwill improve the validity of our estimates (Kish, 1992).\nTable 5A. A Priori Classification of Respondents\n(based on screener data)\nTable of age category by gender (based on preselection information)\nAge category\nGender\nTotal\nFemale Male\nNote: Row Pct = Row Percent; Col Pct = Column Percent.\nTable 5B. A Posteriori Classification of Respondents\n(corrected with interview data)\nTable of age category by gender (corrected after selection)\nAge category\nGender\nTotal\nFemale Male\nNote: Row Pct = Row Percent; Col Pct = Column Percent.\nScale Adjustment\nThere are two sets of weights provided with the final NS-\nincludes the nonresponse adjustment and WEIGHT does\nnot. Both weight variables were rescaled so that they sum to\nthe total number of completed interviews.\nUse of Weights and Calculation of Standard\nErrors\nUse of Weights\nWe recommend that all analyses carried out with NSHAP\ndata incorporate weights. At a minimum, the weight vari-\nable without the nonresponse adjustment (called WEIGHT\nin the data set) should be used; otherwise, the estimates will\nnot represent the population and may be subject to serious\nbiases (Kish & Frankel, 1974). We suggest that in general,\nthe weights incorporating the adjustment for nonresponse\n(WEIGHTNR) are to be preferred over the weights without\nthe adjustment. These adjusted weights help ensure that\nestimates project to the known structure of the selected\nsample.\nCalculation of Standard Errors\nAlthough using weights will ensure that analysts have the\nright point estimates, the standard errors (and confidence\nintervals [CIs]) on these estimates will be incorrect unless\nadditional care is taken. To calculate standard errors cor-\nrectly for NSHAP data, it is necessary to take into account\nthe sample design and the fieldwork outcomes. Importantly,\nfailing to account for the design will lead to serious under-\nestimation of standard errors and CIs (Kish, 1965; Lee &\nNote that ignoring the design (and underestimating CIs) is\nthe default behavior in most statistical packages, which will\nlead researchers to conclude that their results are statisti-\ncally significant when they are not.\nThree aspects of the sample design can have a substantial\neffect on standard errors: stratification, clustering, and un-\nequal probabilities of selection. The design effect (deff)\nsummarizes the combined effect of these three influences\non the variance of estimates from a sample. The square root\nof the deff, called the design factor (deft), gives the effect of\nthe design on standard errors. A deff on a given estimate less\nthan one indicates that the estimate from a complex sample\nis more efficient (has lower variance and standard error)\nthan one from a simple random sample of the same size. A\ndeff greater than one indicates that a complex sample gives\nless efficient estimates. Stratification tends to reduce the\ndeff and clustering, and unequal weights tend to increase it.\nDifferent variables within a given survey will have different\ndeff values because some are more highly clustered than\nother: Variables with high rates of within-cluster homoge-\nneity suffer more (have a higher deff) than those that have\nlow rates of homogeneity (Kreuter & Valliant, 2007).\nTable 6 presents estimates of deffs for a number of vari-\nables. The estimates in Table 6 were calculated using the\nnonresponse-adjusted weight, WEIGHTNR. Here we can\nsee that whether respondents have a sexual partner is not ho-\nmogenous within clusters (whether you have a sexual partner\nis not related to whether your neighbor does, for the NSHAP\npopulation). The deff for this variable is very close to 1.0, and\nour sample design is just about as efficient as a simple ran-\ndom sample of the same size in estimating this variable. Con-\nversely, there is a high degree of within-cluster homogeneity\nin education: People who live together in clusters tend to\nhave the same levels of education. This clustering in the vari-\nable means that our design is much less efficient at estimat-\ning this characteristic than an unclustered sample would be.\nCIs on estimates of the proportion of the NSHAP population\nthat has a college education will be nearly twice as large\nsame size. This discussion has implicitly assumed that the\nonly quantities being estimated are population means.\nCorrectly estimating standard errors requires passing\nstratum, cluster, and weight variables into appropriate sta-\ntistical software. Most packages offer special routines for\nthis kind of estimation: Stata's svy commands, R's survey\npackage, and SAS's proc surveymeans, proc surveyfreq,\netc. The NSHAP data file includes stratum and cluster iden-\ntifiers as well as weights so that these can be passed into the\nsoftware routine to produce appropriate standard errors.\nConclusions\nThe paper describes the design and implementation of the\nsample for the NSHAP. The sample design began with a\nnational area probability sample of households carried out\njointly with the HRS. Subsequently, the selection of respon-\ndents for NSHAP produced a balanced sample across age\nand gender subgroups, with an oversample ofAfricanAmer-\nicans and Latinos. The sample equalized as far as possible\nthe probabilities of selection of individual respondents, given\nthe overall constraints. The complex nature of this design\nrequires that analysts use weights that produce unbiased esti-\nmates of the population parameters. The data file contains\ntwo weight variables that enable analysts to compensate for\nTable 6. Some Examples of the deff for NSHAP Data\nVariable deffa\nDo you currently have a romantic, intimate, or sexual\npartner?\nHow is your sense of smell? 5-point scale 1.50\nHow many living grandchildren do you have? 2.37\nHow many living sons do you have? 2.38\nDid you attend college or university? 3.88\nNotes: deff = design affect; NSHAP = National Social Life, Health, and\nAging Project.\na This effect incorporates all stages of selection, for both the Health and\nRetirement Study screener sample and the NSHAP design.\nthe differential probabilities of selection of individuals and\nthe differential response rates for identifiable subclasses of\nrespondents. The analysis of the data should further take\ninto account the stratified and clustered nature of the design\nto produce unbiased estimates of standard errors for the sur-\nvey estimates; these variables are also available on the NS-\nHAP data set.\nThe sample we designed and implemented for NSHAP\nsucceeded in achieving the goals of NSHAP subject to the\nconstraints imposed by the sometimes conflicting objec-\ntives. Partnering with HRS enabled us to obtain a larger\nsample for the same data collection budget than we would\nhave been able to achieve without this partnership. Such\npartnerships should be considered by other major studies\nthat require substantial screening efforts to identify special\ntarget populations.\nFunding\nThe NSHAP is supported by the National Institutes of Health--the Na-\ntional Institute on Aging, Office of Women's Health Research, Office of\nAIDS Research, and the Office of Behavioral and Social Science Research\n"
}