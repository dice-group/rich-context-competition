{
    "abstract": "Models of human\u00adautomation interaction con- cerned with \"who should do what\" or \"who should be responsible for what\" fail to appreciate how complex cognitive work is carried out in sociotechnical systems.",
    "reduced_content": "Models of human\u00adautomation interaction con-\ncerned with \"who should do what\" or \"who should be\nresponsible for what\" fail to appreciate how complex\ncognitive work is carried out in sociotechnical systems.\nSuch systems,which have complex problem spaces with\nhigh levels of instability,uncertainty,and unpredictability,\nare necessarily self-organizing. In these systems, actors'\nbehaviors and structures are closely interconnected, or\ncorrelated, and vary continuously in ways that are fit-\nted,or adapted,to the demands of a constantly evolving\nwork environment.To preserve the capacity of socio-\ntechnical systems for self-organization, and thus their\ncapacity for dealing with the complexity of their work\nenvironments, the design of human\u00adautomation inter-\naction must be concerned fundamentally with identi-\nfying the limits on \"who can do what\" and providing\nconstrained flexibility in the workplace.\nKeywords: adaptation,human\u00adautomation interaction,\nself-organization\nDavid Kaber (2018 [this issue]), in his arti-\ncle in this issue of the Journal of Cognitive\nEngineering and Decision Making, considers a\nvariety of issues relating to models of human\u00ad\nautomation interaction in complex systems,\nincluding the need for specifications of what the\nhuman and automation will do, and how, for the\npurposes of effective design. In this commen-\ntary, I argue that models of human\u00adautomation\ninteraction that focus on \"who should do what\"\nor on \"who should be responsible for what\" fail\nto appreciate how complex cognitive work is\ncarried out in sociotechnical systems, which\nare necessarily self-organizing. To this end, I\ndiscuss some of the essential characteristics of\nsociotechnical systems, empirical observations\nof how work unfolds in these contexts, and the\nkinds of models that are needed for creating\neffective designs for self-organizing systems.\nSome of the most demanding aspects of per-\nforming cognitive work in sociotechnical systems\nis that they tend to present very large and complex\nproblem spaces characterized by high degrees of\ninstability, uncertainty, and unpredictability (Nai-\nkar, 2013; Naikar & Brady, in press). Workers\nmust contend with dynamic operating conditions,\nin which the problems, demands, and pressures\nthey are faced with change or evolve constantly.\nFor example, the particular challenges posed by a\nwildfire to emergency management workers may\nfluctuate widely depending on the current and\nanticipated weather conditions or population sizes\nand infrastructure in areas to which the fire is\nspreading. Furthermore, workers must deal with\nconsiderable uncertainty, especially in relation to\nthe accuracy or completeness of the information\navailable to them. In the naval domain, for\ninstance, imperfections in acoustics sensors for\ndetecting objects submerged underwater may\nmean that the true situation can never be estab-\nlished with complete certainty. Finally, adding to\nthis complexity is the inherent unpredictability of\nthe work requirements. Workers must contend\nwith events that have not been--and cannot be--\nforeseen or specified fully by analysts or designers\n1999), such as a new kind of military threat (Her-\nzog, 2011; Reich, Weinstein, Wild, & Cabanlong,\n2010), an unexpected reaction of a patient to an\nanesthetic during surgery (Hoppe & Popham,\n2007), or an unforeseen chain of supplier col-\nlapses in the wake of a natural disaster (Park,\nAddress correspondence to Neelam Naikar, Defence\nScience and Technology Group, Melbourne, 506\nLorimer St, Fishermans Bend, Victoria 3207, Australia,\nneelam.naikar@dst.defence.gov.au.\nSpecial Issue\nHuman\u00adAutomation Interaction in Self-Organizing\nSociotechnical Systems\nNeelam Naikar, Defence Science and Technology Group\nJournal of Cognitive Engineering and Decision Making\nCopyright \u00a9 2017, Commonwealth of Australia.\nHAI in Self-Organizing Sociotechnical Systems 63\nThese fundamental characteristics of socio-\ntechnical systems make adaptation necessary for\ntheir viability. Workers cannot rely solely on\nexecuting well-established procedures or trained\ntask sequences or on recognizing suitable solu-\ntions from their prior experiences, even if they\nhave extensive know-how (Rasmussen, 1986;\nRasmussen, Pejtersen, & Goodstein, 1994;\nVicente, 1999). Instead, workers must be capa-\nble of continuously and reliably adapting their\nactions to the evolving nature of the problem,\nsometimes exercising significant ingenuity or\ncreativity.\nA variety of empirical studies demonstrate\nthat adaptations in sociotechnical systems can\nbe observed at the levels of the behaviors of\nindividual actors and the structures of multiple\nactors (Naikar & Brady, in press; Naikar & Elix,\n2016). In other words, workers in these systems\nfunction within groups or teams, or within a\nsocial context, and they adapt not only their indi-\nvidual behaviors but also their structures, or\norganization, in line with the evolving situation\n(e.g., Bigley & Roberts, 2001; Bogdanovic,\nPerry, Guggenheim, & Manser, 2015; Rochlin,\nLaPorte, & Roberts, 1987). For example, in a\nfield study of a widespread approach to emer-\ngency management in the United States (Bigley\n& Roberts, 2001), some of the kinds of behav-\nioral adaptations that were observed included\nimprovisations in the use of tools, such as those\navailable on a fire truck at the scene of an emer-\ngency, and adjustments in standard routines,\nsuch as those for \"hose laying\" or \"ladder throw-\ning.\" Moreover, sometimes the adaptations\nincluded departures from rules, so that workers\nwere directly breaching standard operating pro-\ncedures. For instance, one procedure prohibits\nfirefighting teams from approaching a fire from\nopposite positions, as one group can push the\nfire into another. However, firefighters discussed\na situation in which \"opposing hose streams\"\nwas in fact used as the primary tactic.\nField studies of sociotechnical systems also\nprovide strong evidence of structural adaptation.\nAs an example, Rochlin et al. (1987) found that\nthe work organization on naval aircraft carriers\nshifts spontaneously between formal and infor-\nmal structures. The formal structure, that which\nis documented on paper, is rigid, hierarchical,\nand centralized, and typically governs opera-\ntions on a ship. However, during complex opera-\ntions, a different kind of organizational structure\nis exhibited. This structure is informal in that it\nis not officially documented, and it is flat and\ndistributed. For instance, faced with significant\ntime constraints, lower-ranked personnel can\nmake critical decisions without the approval of\nofficials with higher rankings. The work organi-\nzation on the ship is flexible in that there is no\nprespecified plan for when the shifts between\nformal and informal structures will occur. More-\nover, the informal structure that is adopted\non any one occasion is emergent. That is, there is\nno single, fixed mapping between people and\nroles. Instead, the mapping changes with the\ncircumstances.\nIn this context, the concept of self-organization\nis important (Naikar & Brady, in press; Naikar,\nElix, D\u00e2gge, & Caldwell, 2017). This concept can\nprovide an explanation of how behavioral and\nstructural adaptations in sociotechnical systems\ncan be achieved spontaneously, continuously, and\nrelatively seamlessly, consistent with the observa-\ntions of field studies (e.g., Bigley & Roberts,\n1987). Specifically, field studies demonstrate that\nnew organizational structures may be observed in\nsociotechnical systems that are not planned a pri-\nori, centrally coordinated, or imposed by external\nagents but instead appear to be a spontaneous\nresponse of the system itself to challenges posed\nby its environment. The self-organization concept\nHofkirchner, 1998) suggests that a system's struc-\nture may constrain its response in ways that are\nunsuitable or ineffective when particular circum-\nstances are encountered (Figure 1). However, in\nresponding to the local conditions, individual,\ninteracting actors may engage in spontaneous\nbehaviors from which novel structures emerge\nthat enable the system to respond appropriately to\nthe circumstances. A new structure may be suit-\nable for a time, constraining and enabling behav-\niors in ways that are appropriate to the circum-\nstances--until the situation changes--and the\nspontaneous actions of individual, interacting\nactors result in further structural changes.\nBoth actors' structures and behaviors,\nthen, may evolve continuously to deal with the\n64 March 2018 - Journal of Cognitive Engineering and Decision Making\nchallenges posed by the environment. More-\nover, although this self-organizing process may\nnot be perfect, it may be relatively seamless,\nparticularly in well-established systems, and in\nany case, it is necessary. Significant events occur\ntoo quickly and conditions are too unstable,\nuncertain, and unpredictable for a priori plan-\nning, centralized coordination, or external inter-\nvention to provide feasible strategies consis-\ntently. Instead, flexibility and adaptation within\nthe system are required to resolve--in time and\nin context of the local operating conditions--the\n\"proper, immediate balance\" between the sys-\ntem's safety and productivity goals (Rochlin\nThe phenomenon of self-organization has\nsignificant implications for the design of human\u00ad\nautomation interaction in sociotechnical sys-\ntems. Designs based on normative or prescrip-\ntive models of \"who should do what\" may\ncompromise performance by limiting the\ncapacity of a system for self-organization, and\nthus its capacity for dealing with instability,\nuncertainty, and unpredictability. In addition,\nmodels of human\u00adautomation interaction\nfocused either at the level of behavior or struc-\nture will not be sufficient. Designs based pre-\ndominantly on the behaviors of individual\nactors may have unintended, negative conse-\nquences for the structural relationships between\nthese actors, and the converse is also true.\nInstead, human\u00adautomation interaction must\nbe conceived in the context of both structure\nand behavior--in an integrated manner--and\nthus in the context of self-organizing systems.\nA suitable starting point for achieving these\ndesign objectives is offered by the diagram\nof work organization possibilities (or WOP\ndiagram), a modeling tool recently proposed as\nan extension to the cognitive work analysis\nframework, specifically the social organization\nand cooperation dimension (Naikar & Elix,\n2016). This tool models the structural possibili-\nties of multiple actors and the behavioral oppor-\ntunities of individual actors within a single, inte-\ngrated representation in a way that is consistent\nwith the phenomenon of self-organization (Fig-\nure 2; Naikar et al., 2017). The set of work orga-\nnization possibilities encapsulated in such a\nmodel is independent of specific circumstances,\nso that the model is relevant to recurring situa-\ntions or novel or unforeseen events. Thus this\ntool has the potential to foster the development\nof human\u00adautomation interaction designs that\ndo not limit artificially a system's capacity for\nself-organization and therefore its capacity for\ndealing with a dynamic and ambiguous work\nenvironment.\nSpecifically, a key design intent is to preserve\nthe inherent structural possibilities of multiple\nactors and behavioral opportunities of individual\nactors, so that new or different temporal, spatial,\nor functional structures can emerge from the\nspontaneous behaviors of interacting actors,\nconstrained by a set of boundary conditions for\nsafe and productive performance, consistent\nwith the cognitive work analysis framework.\nNotably, the actors in a WOP diagram may\nencompass both human workers and automated\nagents, so that the emergent structures may\nencompass a mix of human and machine actors.\nUltimately, such a design approach reveals the\nlimits on \"who can do what\" rather than specify-\ning \"who should do what,\" which can be con-\nceived only in the context of events that are\nknown or can be anticipated in detail.\nThe boundaries or limits on action are estab-\nlished by analyzing the organizational con-\nstraints, or the relationships between the action\npossibilities afforded by the work context, or the\nenvironment in which actors are situated, and\nthe actors themselves (Naikar et al., 2017). As a\nresult, the WOP diagram simultaneously reveals\nthe behavioral opportunities of individual actors\nand the structural possibilities of multiple actors.\nThe structural possibilities are interconnected\nwith actors' behavioral opportunities in a man-\nner that accommodates the observation that, in\nFigure 1. Social self-organization. Adapted from\nHAI in Self-Organizing Sociotechnical Systems 65\nself-organizing systems, the structural forms of\nmultiple actors emerge from the flexible actions\nof individual, interacting actors while at the\nsame time constraining or enabling their behav-\niors, in ways that are fitted to the circumstances\n(cf. Figure 1). Thus, it is proposed that designs\nbased on this diagram may facilitate the emer-\ngence of novel temporal, spatial, or functional\nstructures from the flexible behaviors of indi-\nvidual, interacting actors, such that the system\nhas greater capacity for adapting to a constantly\nevolving work environment.\nA particular design goal within this approach\nis to facilitate effective interrelationships between\nhuman and machine actors as a central means\nfor promoting emergence and adaptation of the\nsystem to the work environment. The relational\npossibilities of human and machine actors must\nbe comprehended in view of each actor's full,\nalthough meaningfully constrained, spaces of\nopportunities for action. The specific intent is to\nprovide actors with pathways for interaction that\ncan preserve each actor's degrees of freedom for\nbehavior within the specified boundaries of\neffective performance, as revealed by means of\na WOP diagram.\nConsiderable further research, however, is\nnecessary to realize the ideals of this framework.\nFirst, empirical studies to develop a deeper\nappreciation of the nature of self-organization in\nsociotechnical systems, especially those with\nboth human and sophisticated automated agents,\nare needed. Second, techniques for analyzing\nand modeling self-organizing sociotechnical\nsystems with both human and machine actors\nrequire attention. Here, it is suggested that the\nWOP diagram and, more broadly, the concepts\nof cognitive work analysis provide a suitable\nstarting point, but further research in this area\nwould be worthwhile. Finally, design strategies\nfor promoting self-organization in sociotechni-\ncal systems require further investigation. Such\ninvestigations should consider means for enrich-\ning the interactions needed between human and\nmachine actors, which may not be of precisely\nthe same kinds that are natural among human\nactors, if the respective capabilities of those\nactors are to be exploited successfully.\nThis research on human\u00adautomation interac-\ntion will contribute to the overarching design\ngoal of creating integrated system designs (Nai-\nkar & Elix, 2016) that are compatible with how\ncomplex cognitive work is carried out in socio-\ntechnical systems. Such systems are necessarily\nself-organizing, at least during complex, non-\nroutine operations, so that specifications of\n\"who should do what\" are likely to lead to\nuncompromising designs that do not facilitate\nand, worse still, deliberately inhibit flexibility in\nthe workplace, forcing workers to improvise in\nan ad hoc manner, which could lead to unsafe or\nunproductive outcomes. Instead, actors must be\nsupported systematically in adapting both their\nstructures and behaviors, in an integrated manner,\nif we are to recognize that self-organization occurs\nin sociotechnical systems and that this phenome-\nnon is important for dealing with a dynamic and\nambiguous work environment. This design goal\nrequires a change in perspective in which the\nemphasis is placed squarely on revealing the lim-\nits on \"who can do what\" and promoting con-\nstrained flexibility in the workplace.\nReferences\nBigley, G. A., & Roberts, K. H. (2001). The incident command\nsystem: High-reliability organizing for complex and volatile\ntask environments. Academy of Management Journal, 44,\nBogdanovic, J., Perry, J., Guggenheim, M., & Manser, T. (2015).\nAdaptive coordination in surgical teams: An interview study.\nFigure 2. Relationship of the diagram of work\norganization possibilities to self-organization (cf.\nFigure 1).\n66 March 2018 - Journal of Cognitive Engineering and Decision Making\nFuchs, C. (2004). Knowledge management in self-organizing\nsocial systems. Journal of Knowledge Management Practice,\n5. Retrieved from http://www.tlainc.com/articl61.htm\nHaken, H. (1988). Information and self-organization: A macroscopic\napproach to complex systems. Berlin, Germany: Springer.\nHerzog, S. (2011). Revisiting the Estonian cyber attacks: Digital\nthreats and multinational responses. Journal of Strategic Secu-\nHeylighen, F. (2001). The science of self-organization and adaptiv-\nHofkirchner, W. (1998). Emergence and the logic of explanation.\nAn argument for the unity of science. Acta Polytechnica Scan-\ndinavica, Mathematics, Computing and Management in Engi-\nHoppe, J., & Popham, P. (2007). Complete failure of spinal anaes-\nthesia in obstetrics. International Journal of Obstetric Anes-\nKaber, D. (2018). Issues in human\u00adautomation interaction model-\ning: Presumptive aspects of frameworks of types and levels of\nautomation. Journal of Cognitive Engineering and Decision\nLeveson, N. G. (1995). Safeware: System safety and computers.\nReading, MA: Addison-Wesley.\nNaikar, N. (2013). Work domain analysis: Concepts, guidelines,\nand cases. Boca Raton, FL: CRC Press.\nNaikar, N., & Brady, A. (in press). Cognitive systems engineer-\ning: Expertise in sociotechnical systems. In P. Ward, J. M.\nSchraagen, J. Gore, & E. Roth (Eds.), The Oxford handbook\nof expertise: Research and application. Oxford, UK: Oxford\nUniversity Press.\nNaikar, N., & Elix, B. (2016). Integrated system design: Promoting\nthe capacity of sociotechnical systems for adaptation through\nextensions of cognitive work analysis. Frontiers in Psychol-\nNaikar, N., Elix, B., D\u00e2gge, C., & Caldwell, T. (2017). Designing\nfor self-organisation with the diagram of work organisation\npossibilities. In J. Gore & P. Ward (Eds.), Proceedings of the\n13th International Conference on Naturalistic Decision Mak-\nfrom https://www.eventsforce.net/uob/media/uploaded/EVUOB/\nPark, Y., Hong, P., & Roh, J. J. (2013). Supply chain lessons from\nthe catastrophic natural disaster in Japan. Business Horizons,\nPerrow, C. (1984). Normal accidents: Living with high risk tech-\nnologies. New York, NY: Basic Books.\nRasmussen, J. (1968a). Characteristics of operator, automatic\nequipment and designer in plant automation (Ris\u00f8-M-808).\nRoskilde, Denmark: Ris\u00f8.\nRasmussen, J. (1968b). On the reliability of process plants and\ninstrumentation systems (Ris\u00f8-M-706). Roskilde, Denmark:\nDanish Atomic Energy Commission, Research Establishment\nRis\u00f8.\nRasmussen, J. (1969). Man\u00admachine communication in the light\nof accident records (Report No. S-1-69). Roskilde, Denmark:\nDanish Atomic Energy Commission, Research Establishment\nRis\u00f8.\nRasmussen, J. (1986). Information processing and human\u00admachine\ninteraction: An approach to cognitive engineering. New York,\nNY: North-Holland.\nRasmussen, J., Pejtersen, A. M., & Goodstein, L. P. (1994). Cogni-\ntive systems engineering. New York, NY: Wiley.\nReason, J. (1990). Human error. Cambridge, UK: Cambridge Uni-\nversity Press.\nReich, P. C., Weinstein, S., Wild, C., & Cabanlong, A. S. (2010).\nCyber warfare: A review of theories, law, policies, actual\nincidents--and the dilemma of anonymity. European Journal\nRochlin, G. I., La Porte, T. R., & Roberts, K. H. (1987). The self-\ndesigning high-reliability organization: aircraft carrier flight\nVicente, K. J. (1999). Cognitive work analysis: Toward safe, pro-\nductive, and healthy computer-based work. Mahwah, NJ: Law-\nrence Erlbaum.\nNeelam Naikar leads the Centre for Cognitive Work\nand Safety Analysis at the Defence Science and\nTechnology Group in Melbourne, Australia. Her\nprimary research interests are in methods for work\nanalysis and system design.\n"
}