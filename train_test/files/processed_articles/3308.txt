{
    "abstract": "Abstract\nThe present research investigates whether spontaneous trait inferences occur under conditions characteristic of social media and\nnetworking sites: nonextreme, ostensibly self-generated content, simultaneous presentation of multiple cues, and self-paced\nbrowsing. We used an established measure of trait inferences (false recognition paradigm) and a direct assessment of impres-\nsions. Without being asked to do so, participants spontaneously formed impressions of people whose status updates they saw.\nOur results suggest that trait inferences occurred from nonextreme self-generated content, which is commonly found in social\nmedia updates (Experiment 1) and when nine status updates from different people were presented in parallel (Experiment 2).\nAlthough inferences did occur during free browsing, the results suggest that participants did not necessarily associate the traits\nwith the corresponding status update authors (Experiment 3). Overall, the findings suggest that spontaneous trait inferences\noccur on social media. We discuss implications for online communication and research on spontaneous trait inferences.\n",
    "reduced_content": "Article\nSpontaneous Trait Inferences\non Social Media\nAna Levordashka1 and Sonja Utz1\n Keywords\nspontaneous trait inferences, false recognition, social media, Internet/cyberpsychology, impression formation, person perception\nSocial media allow people to communicate at virtually no cost\nand effort and build large online networks, which can be pow-\nerful sources of social and emotional support (Donath, 2007).\nThe challenge lies in finding successful ways to maintain and\nnavigate those networks, since their size and diversity render\ntraditional maintenance strategies, such as face-to-face com-\nmunication, less feasible (Resnick, 2001; Tong & Walther,\n2011). Snap social processes like spontaneous inferences pres-\nent a potential solution. Research has shown that people spon-\ntaneously infer traits, goals, and values from minimal exposure\nto information (Uleman, Saribay, & Gonzalez, 2008). Social\nmedia offer a near constant stream of information, and if infer-\nences indeed require no more than a passing glance, browsing\nmight help users gain awareness of their online networks\nextent to which such snap inferences are made online is not\nclear. We examine key conditions that could hinder sponta-\nneous inferences on social media and report experiments\ndesigned to test whether inferences occur under these\nconditions.\nIn research on online impression formation, it is common to\nexplicitly ask participants to judge others, whose profiles they\nview at their own pace (e.g., Antheunis & Schouten, 2011;\nAugustine, Vazire, Holtzman, & Gaddis, 2011; Pennington &\nHall, 2014; Westerman, Van Der Heide, Klein, & Walther,\n2008). In contrast to this deliberate evaluation, browsing\ninvolves skimming through information without any particular\nintention. Even if the encountered posts contain relevant cues,\nwe do not know whether these cues will lead to inferences\nwhen people encounter them briefly and without explicit\nimpression formation goals.\nThere is robust evidence that people spontaneously infer\nsocial information and form impressions (Ambady &\ntime and affect behavior (Todorov, Mandisodza, Goren, &\nbehavioral descriptions as a cue (Carlston, Skowronski, &\nwhen reading about others' behavior, people make inferences\neven when their task is unrelated to impression formation or\nwhen they are under high cognitive load (Todorov & Uleman,\n2003). Status updates often contain trait-implying information\nand can therefore be expected to produce similar effects. How-\never, the evidence for spontaneous trait inferences comes from\nlaboratory experiments with conditions that differ from social\nmedia in important ways.\nSpontaneous trait inference experiments typically use third-\nparty descriptions (Rim, Uleman, & Trope, 2009; Saribay,\n1 Leibniz-Institut fu\n\u00a8r Wissensmedien, Tu\n\u00a8bingen, Germany\nCorresponding Author:\nAna Levordashka, Leibniz-Institut fu\nTu\n\u00a8bingen, Germany.\nEmail: a.levordashka@imw-tuebingen.de\nSocial Psychological and\nPersonality Science\nReprints and permission:\nsagepub.com/journalsPermissions.nav\njournals.sagepub.com/home/spp\nwhich are particularly powerful in driving impressions. Even\nwhen first-person descriptions are used (e.g., Carlston et al.,\n1995), the information is provided to the participants with no\ncontext, and there is little reason to doubt its accuracy. Social\nmedia updates, however, are self-generated and shared volun-\ntarily, which makes them less reliable due to strategic self-\npresentation (warranting principle; Utz, 2010; Walther, Van\nDer Heide, Kim, Westerman, & Tong, 2008).\nMoreover, the information in laboratory experiments can be\nof rather extreme nature. Behaviors such as ``She threw a chair\nat her classmate'' (Bliss-Moreau, Barrett, & Wright, 2008) or\n``I kicked [a puppy] out of my way'' (Carlston & Skowronski,\nused as stimuli, but would rarely be shared online, where infor-\nmation tends to be more mild and appropriate (Utz, 2014). This\nis problematic because extreme information is known to influ-\nence impressions more strongly (Fiske, 1980; Skowronski &\nCarlston, 1989). Indeed, researchers have speculated that too\nmild content might not result in spontaneous inferences (Skow-\nAnother major difference lies in how information is pre-\nsented. Nearly, all experiments on spontaneous trait inferences\npresent only one pair of actor and behavior at a time. Forming a\ndistinct association under such conditions is more straightfor-\nward than on social media, where different actors and beha-\nviors appear in parallel and users browse through without\nbeing particularly attentive. A social media user could easily\nbe looking at one person, while still processing information\nabout another, especially while browsing.\nSince updates on social media are self-generated and often\nmild in content, it is not clear whether they will be sufficiently\npowerful as a cue to produce spontaneous inferences. Further-\nmore, viewing multiple updates in parallel and in ``browse''\nmode might hinder the associative process. In a series of\nexperiments, we tested whether people will spontaneously infer\ntraits from mild, self-generated social media updates (Experi-\nment 1), when information is presented in parallel (Experiment\n2) and merely browsed through (Experiment 3).\nGeneral Method\nOverview\nWe adapted an established trait-inference paradigm (false rec-\nognition; Todorov & Uleman, 2002). The paradigm assesses\ntrait inferences via a recognition task. First, participants see a\nnumber of actors paired with brief trait-implying descriptions.\nThey are asked to read the descriptions without any mention of\nimpression formation (learning phase). In a subsequent recog-\nnition task, the same actors are paired with single words, and\nfor each pair, participants indicate whether the word appeared\nin the actor's description. It has been shown that if the target\nword is the trait implied by the actor's description, participants\nmake more mistakes saying that it was in the description\n(Todorov & Uleman, 2002). This false recognition of implied\ntraits occurs because, while reading the descriptions, partici-\npants spontaneously infer the implied traits and associate them\nwith the corresponding authors. When developing the para-\ndigm, researchers adopted additional control conditions and\ncounterbalancing to rule out alternative explanations, such as\nmere word activation, and effects of extraneous characteristics\nof the stimuli. It was consistently demonstrated that the\ncounterbalancing had no effect, which led the authors and\nother researchers employing the paradigm to drop the\ncounterbalancing.\nWe followed the same procedure but changed the content\nand presentation of stimuli. The stimuli were social media\nupdates, ostensibly posted by the actor (self-generated) and\nnonextreme (appropriate) in content. Experiment 1 followed\nthe original paradigm but with status updates as stimuli. In\nExperiment 2, we used the same content and varied the number\nof updates presented simultaneously. In Experiment 3, partici-\npants browsed through all updates at their own pace. Our pri-\nmary dependent variable was the number of mistakes (false\nrecognitions). Whether trait inferences will be made in these\nconditions is an open question. What we hypothesize and test\nin each experiment is that if trait inferences occur, participants\nwill make more mistakes for implied traits as compared to other\ntraits.\nPrior research has assessed response times (RTs) to correct\ntrials. Since longer RTs can be indicative of greater difficulty,\nit can be expected that if spontaneous inferences are made, RTs\nto implied traits should be longer. Although there has been\nsome supporting evidence, RTs are not a reliable indicator of\ntrait inferences. Nevertheless, to be consistent with prior work,\nwe recorded and reported RTs. In addition to false recognitions,\nwe developed an alternative assessment of impressions.\nWe report how we determined sample size, all data exclu-\nsions, manipulations, and measures (Simmons, Nelson, &\nSimonsohn, 2012). The design and hypotheses were preregis-\ntered (osf.io/jqhdz). The experiments were designed in Psy-\nchoPy (Peirce, 2007) and analyzed in R (R Core Team,\n2015). The research was approved by an ethics committee.\nWe conducted pilot research for Experiments 1 and 2, which\nis not reported here, but a report is available online (Levor-\ndashka, 2016). The results are consistent with the remaining\nexperiments and including them in the article would not have\naltered our conclusions.\nSample\nThe effect sizes in spontaneous trait inferences experiments\nusing the false recognition paradigm are moderately large\nhave been sufficient to achieve statistical power of 0.95 in a two-\ntailed dependent-samples t-test. We have decided on larger sam-\nples to ensure power of at least 0.90 for effect sizes of dz\nFor all experiments, participants were recruited from the\nparticipant pool of a German research institute. Some experi-\nence with social media was called for during recruitment but\nnot subsequently assessed. Since prior research has not found\n94 Social Psychological and Personality Science 8(1)\ngender differences in spontaneous impression formation, we did\nnot consider it necessary to discriminate participants based on\ntheir gender to ensure a balanced sample. Gender distribution\nis reported per experiment. Other demographic information was\ncollected separately and reported for the sample across experi-\nments. The participants were undergraduate students of various\nfaculties (no discipline was represented by more than 10%). Age\nExperiment 1\nMethod\nParticipants\nThirty participants took part in the study (22 female). After pro-\nviding an informed consent, participants received instructions\nand completed the study on individual computer screens. The\ntotal duration was 15 min. At the end, participants were\ndebriefed and reimbursed (2 EUR).\nProcedure\nParticipants saw 36 social media updates (Figure 1), which they\nwere asked to read carefully (learning phase). On each trial, a\nsingle update was presented for 5 s. In the recognition task, par-\nticipants saw each face from the learning phase, paired with a\nword, and had to indicate as quickly as possible whether the\nword had appeared in the status update of the person (old word)\nor whether it is a new word that was not in the update. For\nexample, if person A's description was ``Just spilled coffee all\nover my laptop!'' and in the test phase person A appeared with\nthe word laptop, the correct response would be old; any word\nthat was not in the update (e.g., clumsy) would be a new word.\nThe presentation order of single trials was randomized in each\ntask and for each participant.\nFor the updates, we used 36 sentences (in German), 12 of\nwhich mentioned a personality trait and 24 implied a trait with-\nout explicitly mentioning it. The associations between sen-\ntences and implied traits were pretested. The number of\npositive and negative sentences was balanced.\nThe sentences were randomly paired with 36 faces from\nBainbridge, Isola, and Oliva (2013). We used equal number\nof male and female faces of similar attractiveness and memor-\nability (based on the ratings from the database).\nFor the recognition task, each face was paired with a word.\nEveryone faces whose status update mentioned a trait were\npaired with this same trait (presented trait). The remaining 24\nsentences were split into three groups: eight faces were paired\nwith the trait implied by the status update of the same actor\n(implied-trait condition); eight faces with the trait that was\nimplied by a status update of another actor (other-trait condi-\ntion); eight faces with a novel trait (control-trait condition).\nPresented-trait trials served as fillers and were not analyzed.\nThe correct response to all other trials was new. Responses old\nwere coded as errors (false recognitions).\nMemory of Stimuli\nWe assessed participants' memory for the sentences form the\nlearning phase in a recall task. Participants saw a random selec-\ntion of six faces and had to type the corresponding updates. The\nresponses were coded by research assistants unaware of the\nstudy design. The scale for accuracy was: 0 \u00bc no response,\n1 \u00bc not at all accurate, 2 \u00bc accurate meaning; mistakes in word-\ning, 3 \u00bc mostly accurate, 4 \u00bc accurate. Another item assessed\nwhether participants recalled a sentence but paired it with the\nwrong target. If a participant's response was a somewhat accu-\nrate recollection of one of the stimulus sentences but not that of\nthe target face, the response was coded as mistaken target.\nIntercoder reliability was estimated on 20% of the responses,\nwith ratings from two coders (intraclass correlation coefficient\nDirect Assessment of Impressions\nParticipants were asked to evaluate some of the actors (n \u00bc 12\nper participant) from the learning phase. On each trial, they saw\na face, paired with two traits: The trait implied by the status\nupdate and another trait of the same valence and had to choose\none of the traits to evaluate the person. This assessment of\nimpressions was an additional measure of trait inferences.\nExcluded Cases\nOur a priori criterion was 3 SD above or below the sample\nmean for each measure in the study. There were no outliers.\nOne participant made no correct responses in the implied-\ntrait condition. Since the RT analyses were based on correct\ntrials, this resulted in missing data. To ensure a balanced\ndesign, we excluded this participant from the RT analysis.\nAlternative approaches (replacing the missing data with the\nparticipant's average RTs in the other conditions or with the\naverage RTs of other participants in the missing condition)\nyielded similar results.\nResults\nWe used paired-sample t-tests to test our hypothesis regarding\nfalse recognition rates (Table 1). Participants made more mis-\ntakes when an actor's face was paired with the trait implied for\nthis actor (implied-trait condition; M \u00bc 0.55, SD \u00bc 0.24) as\ncompared to a trait implied for another actor (other-trait condi-\ntion; M \u00bc 0.34, SD \u00bc 0.22) or a novel trait (control condition;\nFigure 1. Example of status update stimulus. The actual stimulus had a\ndifferent face and name, and the text was in German.\nLevordashka and Utz 95\nspontaneously inferred traits when reading status updates with\nmild content, written from a first-person perspective.\nassumptions of normality. We performed a log10 transforma-\ntion on the row data (RTs per trial). To avoid negative values,\nwe added 1.0 to all values prior to the transformation. Follow-\ning the transformation, the data no longer violated assumptions\nof normality and equal variances (Shapiro Wilk's ps > .06;\nLevene's test ps > .1). There were no significant differences\nThe recall of the stimulus material was low. For 40% of the\ntrials, participants were not able to recall anything and 42% of\nthe recalled sentences were classified as ``not at all accurate.''\nAs we expected, participants occasionally recalled the status\nupdate of a person other than the one whose picture was dis-\nplayed. This however occurred in only 16% of the cases, which\nindicates that overall retention of the stimuli was indeed low.\nThe occurrence of spontaneous inferences was apparent in the\ndirect evaluations measure. When asked to evaluate the actors\nfrom the learning task, participants selected the implied trait over\nanother trait of the same valence 62% of the time. An exact bino-\nmial sign test indicated that this was significantly higher than\npreference is likely due to implicit evaluation based on the\nactor's update rather than direct recall of the update.\nDiscussion\nThe results of this experiment show that the content typically\nencountered on social media can result in spontaneous trait infer-\nences. These inferences were reflected in the outcome of a word\nrecognition task: Participants were more likely to falsely recog-\nnize a word as having been previously mentioned in an actor's\nstatus update, when the word was the trait implied by the update,\nas compared to traits implied for other actors and to novel traits.\nWe also found that when directly asked to evaluate a person,\nparticipants were more likely to choose the trait, implied by this\nperson's update. Importantly, this likelihood was higher than\nwhat the memory of stimulus materials would suggest. That\nis, participants' evaluations were driven by status updates they\nhad previously seen but could likely no longer recall.\nIn sum, we provide evidence for trait inferences on the basis\nof ostensibly self-generated status updates. However, the pos-\nsibility remains that if too much information is presented at\nonce, there will not be clear associations and person-specific\ninferences. The following experiment was designed to address\nthis concern.\nExperiment 2\nMethod\nNineteen participants took part in the experiment (16 female).\nThe recruitment, procedure, stimuli, and measures were identi-\ncal to that in Experiment 1, with the exception of how we pre-\nsented the stimuli. Instead of one at a time, participants saw\nnine updates in each of the four trials (60 s per trial). In the test\nphase, the implied-trait condition remained unchanged. There\nwere two comparison conditions: Faces paired with traits\nimplied by other updates from the same trial and faces paired\nwith traits from other trials.\nThere were no outliers based on the three SD criterion. One\nparticipant had to be excluded from the analysis of RTs because\nthey made no correct responses in the implied-trait condition,\nwhich resulted in missing data.\nResults\nThe number of false recognitions differed significantly across\nconditions (Table 2). Participants made considerably more mis-\ntakes when an actor's face was paired with the trait implied for\nthis actor (implied-trait condition; M \u00bc 0.57, SD \u00bc 0.23), as\ncompared to a trait implied for another actor in the same trial\n0.18). There was no significant difference between the two con-\ntrol conditions. Crucial here is the difference in false recogni-\ntions between traits implied by status updates that were\npresented during the same trial. Although the updates appeared\nsimultaneously, the trait implied by each update was specifi-\ncally associated with the person who posted the update.\nMdn \u00bc 2.41, SD \u00bc 0.99). Due to violated assumptions of normal-\nity,weperformeda log10transformationonRTspertrial(1.0was\nadded to all values). Following log transformation, the data no\nlonger violated the assumptions of normality and equal variances\n(Shapiro Wilk's ps > .09; Levene's test ps > .79). RTs for correct\nresponses for implied-trait trials (M \u00bc 3.11, SD \u00bc 0.92) were\nshorter than in the other two conditions (same trial: M \u00bc 3.49,\nThe recall of status updates was low. On the majority of\ntrials, participants provided no response (47%) or a highly inac-\ncurate response (28%). There were some cases of recalled\nupdate but a mistaken target (18%), which shows that partici-\npants recalled more than their raw memory scores suggest.\nEven when considering these cases, the overall recall was low.\nDespite having poor recall of the seen updates, when asked\nto evaluate an actor, participants chose the implied trait over\nanother trait of the same valence 75% of the time, which was\n.0001. These results provide evidence that participants made\nactor-specific trait inferences.\nTable 1. Results of Dependent-Samples t-Tests Comparing False Rec-\nognition Rates across Conditions (Experiment 1).\nComparison df t Sig. (Two Tailed) Hedges' g [95% CI]\nNote. CI \u00bc confidence interval.\n96 Social Psychological and Personality Science 8(1)\nDiscussion\nExperiment 2 provided evidence that the simultaneous presen-\ntation of status updates can result in distinct, actor-specific\ninferences. Participants were more likely to falsely recognize\nan implied trait as having been previously presented, which\nindicated that they spontaneously inferred the trait. They were\nalso more likely to associate an actor with the trait implied by\nthis actor's update, without necessarily being able to recall the\nupdate. We did not find the expected differences in RTs.\nUnique to this experiment is the demonstration that when par-\nticipants viewed updates simultaneously, the traits they inferred\nfrom each update were distinctly associated with the author of the\nupdateandnotwiththeotheractorswhosepictureandupdatethey\nviewed at the same time. However, the experimental setup does\nnot rule out the possibility that browsing poses a boundary condi-\ntion to this association. We therefore conducted a third experi-\nment, in which participants browsed through the updates at\ntheir own pace in a setup that closely resembled social media.\nExperiment 3\nMethod\nForty-five participants took part in the study (37 female).\nRecruitment was identical to that in previous experiments and\nwe used a similar procedure. The stimulus material was the\nsame as in the previous experiments, but instead of presenting\nthe status updates in discrete trials for fixed amount of time, all\nupdates appeared on a time line and participants could scroll\nthrough for as long as they like. They were instructed to mark\nthe updates they found interesting and proceed when ready\n(browsing time was recorded). In the test phase, the experimen-\ntal conditions were the same as in Experiment 1: implied trait,\nother trait, and a novel trait.\nScenario-Based Evaluation Measure\nWe developed a novel scenario-based measure of direct\nimpressions. On each of four trials, participants read a situation\nand were asked to make a choice between two people. The\nsituations were such that a person with certain trait would be\npreferred (e.g., ``Who would you rather give your house key\nto?'' would likely be somebody who is trustworthy rather than\nunreliable). For each question, participants had a choice\nbetween two actors: one for which the desired trait was implied\nand one for which an opposite trait was implied. We compared\nthe likelihood of choosing a person with a desired trait over a\nperson with an undesired trait. To control for the influence of\nfaces, for every pair of actors in a scenario, we swapped the\ntraits implied during the learning phase. This manipulation was\ndone between participants. That is, already in the learning\nphase, for half of the participants, person A was paired with the\ndesired trait and, for the other half, person A was paired with\nthe undesired trait.\nExcluded Cases\nThere were no outliers in the false recognitions measure and\none RT outlier, who was excluded from the RT analysis. We\nexcluded one more participant from the RT analysis due to\nmissing data: They had no correct responses in the implied-\ntrait condition.\nResults\nOn average, participants spent 2.42 (SD \u00bc 1.19) min browsing\nthe updates, which is an average of 4 s per update. They\nmarked 20% (SD \u00bc 15) of the updates as interesting. Brows-\ning time was positively correlated with memory of the stimu-\nlus updates (r \u00bc .32, p \u00bc .032) but not with error rates\n(r \u00bc .18, p \u00bc .243). The number of interesting updates was\npositively correlated with browsing time (r \u00bc .51, p < .001).\nAll zero-order correlations are reported in the supplemental\nmaterial.\nThe pattern of means was consistent with our previous\nfindings: higher number of error rates in the implied-trait con-\ndition (M \u00bc 0.43, SD \u00bc 0.25) as compared to other-trait (M \u00bc\nference between implied and other-traits was small and only\napproaching significance (Table 4). Given that the means are\nin line with our hypothesis and a one-sided test (justified by\nour preregistered directional prediction) would have been sig-\nnificant, we consider that spontaneous inferences did occur.\nThere was also a significant difference between the other- and\ncontrol-trait condition, which we did not find in the previous\nexperiments. If we are to interpret this pattern according to\nTodorov and Uleman (2002), we would conclude that infer-\nences occurred (the least mistakes were made for novel traits)\nbut were not successfully bound to corresponding faces (no\ndifference between correctly paired trait-face trials, i.e.,\nTable 3. Results of Dependent-Samples t-Tests Comparing RTs\nacross Conditions (Experiment 2).\nComparison df t\nSig.\n(Two Tailed) Hedges' g [95% CI]\nNote. st \u00bc same trial; ot \u00bc other trial; CI \u00bc confidence interval.\nTable 2. Results of Dependent-Samples t-Tests Comparing False Rec-\nognition Rates Across Conditions (Experiment 2).\nComparison df t\nSig.\n(Two Tailed)\nNote. st \u00bc same trial; ot \u00bc other trial; CI \u00bc confidence interval.\nLevordashka and Utz 97\nimplied trait condition, and mismatched pairs, that is other-\ntrait condition).\ntion (per trial; 1.0 added to each value), the data no longer vio-\nlated the assumptions of normality and equal variances\n(Shapiro Wilk's ps > .02; Levene's test ps > .11). Only the dif-\nference between implied and novel traits was significant, t(43)\nThe recall of status updates was low. Responses were mostly\nabsent (45%) or highly inaccurate (41%). Occasionally, partici-\npants recalled the sentence of a different actor from the data set\nThe results of our scenario-based assessment offer support\nfor the occurrence of trait inferences. Across four different sce-\nnarios, participants selected the actor whose status update\nimplied a trait that would be desirable in the particular scenario\n61% of the times, which was significantly higher than chance,\nDiscussion\nEvidence for spontaneous inference during browsing was\nfound in the direct evaluation measure. In the false recognition\nmeasure, the difference between the implied- and other-trait\nconditions was not significant. According to the traditional\ninterpretation of the paradigm, this pattern suggests that infer-\nences occurred (the least mistakes were made for novel traits)\nbut were not successfully bound to corresponding faces, as\nindicated by the small difference between correctly paired\ntrait-face trials (implied-trait condition) and mismatched pairs\n(other-trait condition). However, it is not clear whether this pat-\ntern is robust. The pattern of means corresponds to what was\nfound in the first two experiments and we found evidence for\ninferences in the alternative measure, which renders the possi-\nbility that the effect was present but weaker.\nGeneral Discussion\nThe information social media users encounter online is rich in\nsocial cues. Psychological research on first impressions sug-\ngests that even without attending to the social aspects of infor-\nmation, users might form impressions based on that\ninformation. Despite this possibility and its implications, spon-\ntaneous inferences have not been studied in the context of\nsocial media. We provide evidence that trait inferences occur\nspontaneously from content and under conditions resembling\nsocial media (Figure 2).\nParticipants spontaneously formed impressions on the basis\nof single, nonextreme, ostensibly self-generated status updates\nwithout being instructed to do so. Our research supports the\nrobustness of spontaneous trait inferences and their relevance\nfor online communication.\nPrior research has shown that person inferences are uninten-\ntional, cognitively efficient, long-lasting, and can be of traits\nbut also values, goals, or intentions (Uleman et al., 2008). This\nmakes them highly relevant for online communication, where\ninformation is often merely glanced at. Our work is an impor-\ntant first step toward examining the impact of spontaneous\nimpression formation on relational and informational processes\nonline.\nWe used an established measure of trait inference. Using a\npreviously validated measure strengthens the conclusions we\ncan draw from the research. This particular measure requires\nthe use of cues that do not explicitly contain the target impres-\nsion, which limits the possibility of conducting research with\nnonconstructed stimuli (e.g., posts directly taken from social\nmedia). We therefore included alternative assessments, which\ninvolved choosing traits to describe an actor and choosing\nbetween two actors for a scenario that calls for the trait implied\nfor one of the actors. The outcomes of these alternative mea-\nsures were consistent with the false-recognitions measure,\nwhich offers support for their effectiveness.\nFraming a spontaneous-inferences paradigm in a social\nmedia setting is another innovation, which can be helpful for\nfuture research. Social media provides a realistic setting for\nresearch on spontaneous inferences, with possibility to manip-\nulate social context and integrate additional tasks in a smooth\nway that is intuitive and familiar for the participants.\nThe experiment in which we investigated impressions dur-\ning browsing provided evidence for actor-specific trait infer-\nences on scenario-based measure of inferences but had\ninconclusive results on the recognition measure. Participants\nwere more likely to falsely recognize previously implied\ntraits (as compared to novel traits), regardless of whether\nthey were paired with the person who posted them or another\nperson from the stimulus set. This pattern suggests that peo-\nple inferred traits from status updates but did not necessarily\nassociate these traits with their corresponding authors. One\nexplanation of this would be that while browsing, people paid\nmore attention to the content itself rather than who posted it.\nThis would be an interesting result, but we cannot firmly\nassess its robustness, which we acknowledge as a limitation\nof our present work. The extent to which people form\nactor-specific inferences while browsing is an important\nfuture direction. If future research reproduced the pattern\nwhere only novel traits are less likely to be falsely recog-\nnized, it would be important to investigate the conditions\nunder which actor-specific inferences do occur.\nOne limitation of this and prior research is the handling of\nextraneous characteristics of the stimulus material (e.g., faces).\nPrior research has included replication conditions with\nTable 4. Results of Dependent-Samples t-Tests Comparing False Rec-\nognition Rates across Conditions (Experiment 3).\nDifference df t\nSig.\n(Two Tailed) Hedges' g [95% CI]\n98 Social Psychological and Personality Science 8(1)\ndifferently paired stimuli and shown that the pairing does not\ninfluence the overall effects, which led the researchers to drop\nthe replication conditions from future work (Todorov & Ule-\nman, 2003). However, the means of assessing that (through\nreplication conditions which double the sample size) are not\noptimal. It would be possible to program studies in a way that\nrandomizes stimulus pairs at each run thus reducing extraneous\neffects to random noise.\nBringing together research on snap social judgment and\nonline impression formation opens up important directions for\nfuture work. Clearly, there is more to social media than what\nour experiments aimed to capture. Under conditions of true\ninformation overload, the ability of cues to attract attention\nmight matter more than it did in the present research, thus it\nwill be important to reproduce the effect under even more\ncognitively demanding conditions. Another direction for\nfuture studies we have already mentioned is whether and how\nspontaneous inferences can help users navigate and maintain\ntheir vast online networks. Examining the accuracy of infer-\nences will be important for understanding such interpersonal\neffects.\nConclusion\nThere are many reasons to browse the streams of updates on\nsocial media sites--to kill time, to catch up on current events,\nto have a laugh at a friend's joke. The present research sug-\ngests that, without necessarily having the intention to do so,\npeople form impressions of others. These spontaneous pro-\ncesses paint a different picture of what browsing social media\nmight entail. While scrolling down to catch a colleague's\nmost recent pun about conference deadlines, a social media\nuser might also be picking up bits of information that shape\nher perceptions of people from various corners of her vast\nonline networks.\n"
}