{
    "abstract": "Abstract\nTemporal aggregation in general introduces a moving average (MA) component\nin the aggregated model. A similar feature emerges when not all but only a few vari-\nables are aggregated, which generates a mixed frequency model. The MA component\nis generally neglected, likely to preserve the possibility of OLS estimation, but the\nconsequences have never been properly studied in the mixed frequency context. In\nthis paper, we show, analytically, in Monte Carlo simulations and in a forecasting\napplication on U.S. macroeconomic variables, the relevance of considering the MA\ncomponent in mixed-frequency MIDAS and Unrestricted-MIDAS models (MIDAS-\nARMA and UMIDAS-ARMA). Specifically, the simulation results indicate that the\nshort-term forecasting performance of MIDAS-ARMA and UMIDAS-ARMA is bet-\nter than that of, respectively, MIDAS and UMIDAS. The empirical applications on\nnowcasting U.S. GDP growth, investment growth and GDP deflator inflation confirm\nthis ranking. Moreover, in both simulation and empirical results, MIDAS-ARMA is\nbetter than UMIDAS-ARMA.\n",
    "reduced_content": "Discussion Paper\nDeutsche Bundesbank\nMixed frequency models with MA components\nClaudia Foroni\n(Deutsche Bundesbank)\nMassimiliano Marcellino\n(Bocconi University, IGIER and CEPR)\nDalibor Stevanovi\n(Universit\u00e9 du Qu\u00e9bec \u00e0 Montr\u00e9al, CIRANO)\nDiscussion Papers represent the authors` personal opinions and do not\nnecessarily reflect the views of the Deutsche Bundesbank or the Eurosystem.\nEditorial Board:\nDeutsche Bundesbank, Wilhelm-Epstein-Stra\u00dfe 14, 60431 Frankfurt am Main,\nPlease address all orders in writing to: Deutsche Bundesbank,\nInternet http://www.bundesbank.de\nReproduction permitted only if source is stated.\nDaniel Foos\nThomas Kick\nMalte Kn\u00fcppel\nJochen Mankart\nChristoph Memmel\nPanagiota Tzamourani\nNon-technical summary\nResearch question\nTemporal aggregation generally introduces a moving average (MA) component in the\nmodel for the aggregate variable. A similar feature should be present in the mixed frequency\nmodels, and indeed we show formally that this is in general the case. The effects of\nneglecting the MA component have been rarely explicitly considered in a single frequency\ncontext. For mixed frequency models, there are no results available.\nContribution\nWe close this gap and analyze the relevance of the inclusion of an MA component in\nmixed-data sampling (MIDAS) and unrestricted mixed-data sampling (UMIDAS) mod-\nels, with the resulting specifications labeled, respectively, MIDAS-ARMA and UMIDAS-\nARMA. We first compare the forecasting performance of the mixed frequency models with\nand without the MA component in a set of Monte Carlo experiments, using a variety of\nData Generating Processes (DGPs). Next, we carry out an empirical investigation, where\nwe predict several quarterly macroeconomic variables using timely monthly indicators. In\nparticular, we forecast three relevant quarterly U.S. macroeconomic variables: real GDP\ngrowth, real private non residential fixed investment (PNFI) growth and GDP deflator\ninflation.\nResults\nIn the Monte Carlo simulations, the short-term forecasting performance is better when\nincluding the MA component, and the gains are higher the more persistent is the se-\nries. Moreover, in general the MIDAS-ARMA specifications are slightly better than the\nUMIDAS-ARMA specifications. This pattern suggests that adding the MA component to\nthe MIDAS model helps somewhat in reducing the potential misspecification due to impos-\ning a specific lag polynomial structure. In the empirical exercise, the inclusion of an MA\ncomponent generally improves the forecasting performance substantially. For all variables,\nand in line with the simulation results, MIDAS-ARMA is better than UMIDAS-ARMA.\nNichttechnische Zusammenfassung\nFragestellung\nDurch zeitliche Aggregation einer hochfrequenten Variablen entsteht eine Variable mit niedri-\ngerer Frequenz. In Folge der Aggregation tritt in der Dynamik der niederfrequenten Variablen\ndann \u00fcblicherweise eine Komponente auf, die einem (gewichteten) gleitenden Durchschnitt\n(GD) entspricht. Eine vergleichbare Komponente sollte auch in Modellen mit gemischten\nFrequenzen, also in Modellen mit hoch- und niederfrequenten Daten vorhanden sein. Wie\nsich die Nichtbeachtung der GD-Komponente auswirkt, ist in den \u00fcblichen Zeitreihenmodel-\nlen bislang kaum explizit betrachtet worden. F\u00fcr gemischt-frequente Modelle, die sogenann-\nten MIDAS-Modelle, liegen indes \u00fcberhaupt keine Ergebnisse vor.\nForschungsbeitrag\nWir untersuchen die Auswirkungen auf MIDAS- und unrestringierte MIDAS-Modelle (UM-\nIDAS-Modellen), wenn eine GD-Komponente mit einbezogen wird. Die sich daraus ergeben-\nden Spezifizikationen werden als ,,MIDAS-ARMA\" bzw. ,,UMIDAS-ARMA\" bezeichnet. Zu-\nn\u00e4chst wird die Prognoseg\u00fcte der gemischt-frequenten Modelle mit und ohne GD-\nKomponente in einer Monte-Carlo-Simulation unter Ber\u00fccksichtigung verschiedener Daten-\ngenerierungsprozesse verglichen. Anschlie\u00dfend werden in einer empirischen Untersuchung\ndrei makro\u00f6konomische US-amerikanische Quartalsvariablen \u00ad das reale BIP-Wachstum,\ndas Wachstum der realen privaten Anlageinvestitionen (ohne Wohnungsbau) und die Wachs-\ntumsrate des BIP-Deflators \u00ad unter Verwendung zeitnaher monatlicher Indikatoren prognosti-\nziert.\nErgebnisse\nIn der Monte-Carlo-Simulation zeigt sich bei der Kurzfristprognose eine h\u00f6here Treffgenauig-\nkeit, wenn die GD-Komponente einbezogen wird. Die Prognoseg\u00fcte verbessert sich umso\nst\u00e4rker, je h\u00f6her die Persistenz der Zeitreihe ist. Zudem schneiden die MIDAS-ARMA-\nModelle allgemein etwas besser ab als die UMIDAS-ARMA-Modelle. Daraus l\u00e4sst sich\nschlussfolgern, dass die Einbeziehung der GD-Komponente dazu beitr\u00e4gt, potenzielle Fehl-\nspezifikationen in MIDAS-Modellen zu verringern. Auch in der empirischen Analyse verbes-\nsert die Einbeziehung einer GD-Komponente die Prognoseg\u00fcte oft deutlich, und MIDAS-\nARMA-Modelle liefern \u00ad im Einklang mit den Simulationsergebnissen \u00ad treffgenauere Prog-\nnosen als UMIDAS-ARMA-Modelle.\nMixed frequency models with MA components \nClaudia Foroni  Massimiliano Marcellino  Dalibor Stevanovi\u00b4\nc \u00a7\n Keywords: Temporal aggregation, MIDAS models, ARMA models.\nThe views expressed in this paper are those of the authors. No responsibility for them should be\nattributed to the Deutsche Bundesbank. Aniss Benmoussa has provided excellent research assistance.\nWe thank Ana Galv~\nao, Pierre Gu\u00b4\nerin, Christian Schumacher and the participants to the ECB Workshop\nin Advances in short-term forecasting, the IWH-CIREQ-GW Macroeconometric Workshop and the CFE\nconference for the very useful comments. The third author acknowledges financial support from the Fonds\nde recherche sur la soci\u00b4\net\u00b4\ne et la culture (Qu\u00b4\nebec) and the Social Sciences and Humanities Research Council.\nDeutsche Bundesbank\nBocconi University, IGIER and CEPR\n\u00a7Universit\u00b4\ne du Qu\u00b4\nebec `\na Montr\u00b4\n1 Introduction\nThe use of mixed-frequency models has become increasingly popular among academics\nand practitioners. It is in fact by now well recognized that a good nowcast or short-term\nforecast for a low frequency variable, such as GDP growth and its components, requires\nto exploit the timely information contained in higher frequency macroeconomic or finan-\ncial indicators, such as surveys or spreads. A growing literature has flourished proposing\ndifferent methods to deal with the mixed-frequency feature. In particular, models cast in\nstate-space form, such as vector autoregressions (VAR) and factor models, can deal with\nmixed-frequency data, taking advantage of the Kalman filter to interpolate the missing ob-\nservations of the series only available at low frequency (see, among many others, Mariano\nand Murasawa (2010) and Giannone et al. (2008) in a classical context, and Chiu et al.\n(2011) and Schorfheide and Song (2015) in a Bayesian context). A second approach has\nbeen proposed by Ghysels (2016). He introduces a different class of mixed-frequency VAR\nmodels, in which the vector of endogenous variables includes both high and low frequency\nvariables, with the former stacked according to the timing of the data releases. A third\napproach is the mixed-data sampling (MIDAS) regression, introduced by Ghysels et al.\n(2006), and its unrestricted version (UMIDAS) by Foroni et al. (2015). MIDAS models are\ntightly parameterized, parsimonious models, which allow for the inclusion of many lags of\nthe explanatory variables. Given their non-linear form, MIDAS models need to be esti-\nmated by non-linear least squares (NLS). UMIDAS models are the unrestricted counterpart\nof MIDAS models, which can be estimated by simple ordinary least squares (OLS), but\nwork well only when the frequency mismatch is small.1\nIn this paper, we start from the observation that temporal aggregation generally in-\ntroduces a moving average (MA) component in the model for the aggregate variable (see,\ne.g., Marcellino (1999) and the references therein). A similar feature should be present in\nthe mixed frequency models, and indeed we show formally that this is in general the case.\nThe MA component is often neglected, both in same frequency and in mixed frequency\n1The literature on mixed-frequency approaches is vast. The papers cited in the text are a non-exhaustive\nlist of key contributions to the field. For a review of the mixed-frequency literature, see Bai et al. (2013)\nand Foroni and Marcellino (2013) among many others.\nmodels, likely to preserve the possibility of OLS estimation and on the grounds that it can\nbe approximated by a sufficiently long autoregressive (AR) component.\nThe effects of neglecting the MA component have been rarely explicitly considered. In\na single frequency context, Lutkepohl (2006) showed that VARMA models are especially\nappropriate in forecasting, since they can capture the dynamic relations between time se-\nries with a small number of parameters. Further, Dufour and Stevanovic (2013) showed\nthat a VARMA instead of VAR model for the factors provides better forecasts for several\nkey macroeconomic aggregates relative to standard factor models, as well as producing a\nmore precise representation of the effects and transmission of monetary policy. Leroux\net al. (2017) found that ARMA(1,1) models predict well the inflation change and outper-\nform many data-rich models, confirming the evidence on forecasting inflation by Stock and\nmodels are often the correct reduced form representation of DSGE models (see, for example,\nRavenna (2007)). For mixed frequency models, there are no results available.\nWe close this gap and analyze the relevance of the inclusion of an MA component\nin MIDAS and UMIDAS models, with the resulting specifications labeled, respectively,\nMIDAS-ARMA and UMIDAS-ARMA. We first compare the forecasting performance of\nthe mixed frequency models with and without the MA component in a set of Monte Carlo\nexperiments, using a variety of Data Generating Processes (DGPs). It turns out that\nthe short-term forecasting performance is better when including the MA component, and\nthe gains are higher the more persistent is the series. Moreover, in general the MIDAS-\nARMA specifications are slightly better than the UMIDAS-ARMA specifications, though\nthe differences are minor. This pattern is in contrast with the findings in Foroni et al. (2015),\nand suggests that adding the MA component to the MIDAS model helps somewhat in\nreducing the potential misspecification due to imposing a specific lag polynomial structure.\nNext, we carry out an empirical investigation, where we predict several quarterly macroe-\nconomic variables using timely monthly indicators. In particular, we forecast three relevant\nquarterly U.S. macroeconomic variables: real GDP growth, real private non residential fixed\ninvestment (PNFI) growth and GDP deflator inflation. The latter variable is particularly\nrelevant, as Stock and Watson (2007) show that the MA component for US inflation is\nimportant, especially after 1984. In fact, while during the 1970s the inflation process could\nbe very well approximated by a low order AR, after the 1980s this has become less accurate\nand the inclusion of an MA component more relevant. Evidence on the importance of the\nMA component for the U.S. inflation is also found by Ng and Perron (2001) and Perron\nand Ng (1996). As monthly explanatory variables, we consider industrial production and\nemployment for the real GDP growth and the PNFI growth, CPI inflation and personal\nconsumption expenditures (PCE) inflation for the GDP deflator. The inclusion of an MA\ncomponent generally improves the forecasting performance substantially. In particular,\nadding the MA part to forecast GDP growth one-year ahead ameliorates the MSE up to\n10%, while for PNFI we obtain even bigger gains, up to 30% one-year ahead. Also in the\ncase of GDP deflator we obtain robust improvements, which go up to 15%. For all variables,\nand in line with the simulation results, MIDAS-ARMA is better that UMIDAS-ARMA.\nLastly, full sample estimates of MA coefficients are significant and important in most of\nMIDAS-ARMA and UMIDAS-ARMA specifications.\nThe remainder of the paper proceeds as follows. In Section 2 we show that temporal\naggregation generally creates an MA component also in mixed frequency models. In Section\n3 we describe parameter estimators for the MIDAS-ARMA and UMIDAS-ARMA models.\nIn Section 4 we present the design and results of the simulation exercises. In Section 5\nwe develop the empirical applications on forecasting U.S. quarterly variables with monthly\nindicators. In Section 6 we summarize our main results and conclude.\n2 The rationale for an MA component in mixed fre-\nquency models\nThe UMIDAS regression approach can be derived by aggregation of a general dynamic\nlinear model in high frequency, as shown by Foroni et al. (2015), while the MIDAS model\nimposes specific restrictions on the UMIDAS coefficients in order to reduce their number,\nwhich is particularly relevant when the frequency mismatch is large (for example, with\ndaily and quarterly series). In Section 2.1, we briefly review the derivation of the UMIDAS\nmodel, highlighting that, in general, there should be an MA component, even though it is\ngenerally disregarded. In Section 2.2, we provide two simple analytical examples in which,\nstarting from a high-frequency model without MA term, we end up with a mixed frequency\nmodel in which the MA component is present. We discuss estimation of mixed frequency\nmodels with an MA component in a separate section.\n2.1 UMIDAS regressions and dynamic linear models\nLet us assume that the Data Generating Process (DGP) for the variable y and the N\nvariables x is an ARDL(p, q) process, as in Foroni et al. (2015):\na(L)ytm\n+ ... + bN\n(L)xNtm\n+ eytm\nL - ... - ap\nL, bj\nL + ... + bjq\nLq, j = 1, ..., N, and the error eytm\nis white noise. We assume, for simplicity, that p = q and the starting values y-p\nand\nx-p\nare all fixed and equal to zero.\nWe then assume that x can be observed for each period tm\n, while y can be only observed\nevery m periods. We define t = 1, ..., T as the low frequency (LF) time unit and tm\n=\n1, ..., Tm\nas the high frequency (HF) time unit. The HF time unit is observed m times in\nthe LF time unit. As an example, if we are working with quarterly (LF) and monthly (HF)\ndata, it is m = 3 (i.e., three months in a quarter). Moreover, L indicates the lag operator\nat tm\nfrequency, while Lm is the lag operator at t frequency.\nWe also introduce the aggregation operator\nL + ... + m-1\nwhich characterizes the temporal aggregation scheme. For example, (L) = 1 + L + ... +\nLm-1 indicates the sum of the high-frequency observations over the low-frequency period,\ntypically used in the case of flow variables, while (L) = 1 corresponds to point-in-time\nsampling and is typically used for stock variables. As we will see, different aggregation\nschemes will play a role in generating MA components.\nTo derive the generating mechanism for y at mixed frequency (MF), we introduce a\npolynomial in the lag operator, (L), whose degree in L is at most equal to pm - p and\nwhich is such that the product h(L) = (L)a(L) only contains powers of Lm, so that\nh(L) = h(Lm). It can be shown that such a polynomial always exists, and its coefficients\ndepend on those of a(L), see Marcellino (1999) for details.\nIn order to determine the AR component of the MF process, we then multiply both\nsides of (1) by (L) and (L) to get\nh(Lm)(L)ytm\n(L)(L)x1tm\n+ ... + (L)bN\n(L)(L)xNtm\n+ (L)(L)eytm\nHence, the autoregressive component only depends on LF values of y. Let us consider now\nthe x variables, which are observable at high frequency tm\n. Each HF xitm\ninfluences the\nLF variable y via a polynomial (L)bj\n(L)(L) = bj\n(L)(L)(L), j = 1, ..., N. We see that\nit is a particular combination of high-frequency values of xj\n, equal to (L)(L)xjtm\n, that\naffects the low-frequency values of y.\nOnly under certain, rather strict conditions, it is possible to recover the polynomials\na(L) and bj\n(L) that appear in the HF model for y from the MF model, and in these cases\nalso (L) can be identified. Therefore, when (L) cannot be identified, we can estimate a\nmodel as\nc(Lk)(L)ytm\n+ ... + N\n+ tm\ntm\nwhere c(Lm) = (1 - c1\nLm - ... - cc\nLmc), j\n(L) = (j,0\nL + ... + j,v\nLv), j = 1, ..., N.\nWe can focus now on the error term of equation (3). In general, there is an MA\ncomponent in the MF model, q(Lm)uytm\n, with q(Lm) = (1+q1\nLm +...+qq\nLmq). The order\nof q(Lm), q, coincides with the highest multiple of m non zero lag in the autocovariance\nfunction of (L)(L)eytm\n. The coefficients of the MA component have to be such that the\nimplied autocovariances of q(Lm)uytm\ncoincide with those of (L)(L)eytm\nevaluated at all\nmultiples of m. Consequently, also the error term tm\nin the approximate mixed frequency\nmodel (4), which is the UMIDAS model, in general has an MA structure. It can be shown\nthat the maximum order of the MA structure is p for average sampling and p-1 for point-\nin-time sampling, where p is the order of the AR component in the high frequency model\nfor ytm\n(see, e.g., Marcellino (1999) for a derivation of this results).\n2.2 Two analytical examples\nIn this section, we consider two simple DGPs and show that, even in these basic cases,\nan MA component appears in the mixed frequency model. In the first example, we consider\nan ARDL(1,1) with average sampling, in the second one an ARDL(2,2) with point-in-time\nsampling. In both cases, we work with monthly and quarterly variables, therefore m = 3,\nas in the empirical applications that will be presented later on. The examples could be\neasily generalized to consider higher order models and different frequency mismatches m.\nARDL(1,1) with average sampling\nLet us assume an ARDL(1,1) as HF DGP:\nytm\n+ eytm\nwhere ytm\nis a variable unobservable at HF, xtm\nis the high-frequency variable, eytm\nis white\nnoise, and tm\nis the high-frequency time index. Although we do not observe ytm\n, we observe\nthe quarterly aggregated values of the series.\nIn order to obtain the model for the quarterly aggregated series, let us write (5) as\n(1 - aL) ytm\n= bLxtm\n+ eytm\nWe consider average sampling, and therefore we define the aggregation operator  (L) =\n1 + L + L2. Then, we first introduce a polynomial in the lag operator, (L), which is such\nthat the product h(L) = (L) (1 - aL) only contains powers of L3. This polynomial exists\nand it is equal to (1 + aL + a2L2) . We then multiply both sides of equation (6) by  (L)\nand  (L) and we obtain:\n+\nor equivalently:\n+\nwhere ytm\nand tm\nAs we saw it in Section 2.1, the order of the MA component coincides with the highest\nmultiple of 3 non zero lag in the autocovariance function of the error term in equation (8),\nand it is bounded above by the AR order of the model for ytm\n.\nEq. (8) is then estimated at quarterly frequency, but making use of all the information\navailable in the HF variable xtm\n, and including the MA component, which is of order 1\nin this case (being the relevant lag for the quarterly model L3). The model in eq. (8) is\ntherefore a UMIDAS-AR with an MA(1) component.\nARDL(2,2) with point-in-time sampling\nLet us now assume an ARDL(2,2) as HF DGP:\nytm\n+ eytm\nor, equivalently,\n+ eytm\nwhere ytm\n, xtm\n, eytm\nand tm\nare defined as in the previous example.\nWe consider point-in-time sampling, and therefore  (L) = 1. Next, we need to multiply\nboth sides of equation (9) by (L) and find a polynomial (L) such that the product\nL2) only contains powers of L3. In can be easily shown that\n (L) exists and it is equal to\nThe resulting mixed frequency model for the low-frequency variable is:\n+\nwith tm\n= 3, 6, 9, ... Hence, also in this case there is an MA component in the mixed\nfrequency model for y. Its order coincides with the highest multiple of 3 non zero lag\nin the autocovariance function of (1 + a1\n, and it is\nbounded above by the AR order of the model for ytm\nminus one, which is 1 in this example.\nFollowing the same line of reasoning as in the previous example, the MA component is of\n3 UMIDAS-ARMA and MIDAS-ARMA: forecasting\nspecifications and estimation\nWe describe now in more detail the model specifications we consider for forecasting,\nand the estimation details. We first recall the main features of the standard MIDAS\nregression, introduced by Ghysels et al. (2006), and its unrestricted version, as in Foroni\net al. (2015). Then, we discuss their extensions to allow for an MA component and we\ndiscuss the estimation of the models.\nThe starting point for our MF models is equation (4). In order to simplify the notation,\nwe assume (L) = 1 and one explanatory variable xtm\n2. Further, we allow for incorporat-\ning leads of the high frequency variable in the projections, which captures asynchronous\nreleases.\nThe equation we are going to estimate to generate an hm\n-step ahead forecast is the\nfollowing:\nytm\n= ~\nc(Lm)ytm-hm\n+ (L)xtm-hm+w\n+ tm\nwhere ~\nc(Lm) is a modified lag structure of equation (4) to obtain a direct forecast and w\nis the number of months with which x is leading y.\nIf tm\nis serially uncorrelated, equation (12) represents the UMIDAS-AR model. Given\nthat the model is linear, the UMIDAS-AR regression can be estimated by simple OLS.\nEmpirically, the lag length of the high frequency variable x is often selected by means of\nan information criterion, such as the BIC.\nAdding an MA component to the UMIDAS-AR yields the UMIDAS-ARMA model:\nytm\n= ~\nc(Lm)ytm-hm\n+ (L)xtm-hm+w\n+ utm\n+ q(Lm)utm-hm\nwhere utm\nis a (weak) white noise with E(utm\n) = 0 and E(utm\nutm\nu\n< , and all\nthe remaining terms stay the same as in equation (12). Given that MIDAS models are\ndirect forecasting tools, we decided to follow a direct approach also when modelling the\nMA component.\nOLS estimation of the UMIDAS-ARMA model is no longer possible, because of the\nMA component in the residuals. We then estimate the model as in the standard ARMA\nliterature, by maximum likelihood or, as we will actually do to be coherent with the MIDAS\nliterature, by non-linear least squares (NLS).\n2This is an innocuous simplification, as with a generic aggregation scheme (L) = 1 we could just work\nwith the redefined variable ~\nytm\n= (L)ytm\n.\nThe MIDAS-AR specification is a restricted version of the UMIDAS-AR. The MIDAS-\nAR model as in Ghysels et al. (2006), specified for forecasting hm\nperiods ahead, can be\nwritten as follows:\nytm\n= ~\nc(Lm)ytm-hm\n+ B(L, )xtm-hm+w\n+ tm\nwhere\nB(L, ) =\nK\nb(j, )Lj,\nb(j, ) =\nK\n,\nand K is the maximum number of lags included of the explanatory variable.\nAs it is clear by comparing equation (12) and equation (14), the MIDAS model is nested\ninto the UMIDAS model.\nThe MIDAS-AR model in equation (14) is estimated by NLS. Given that it is hm\n-\ndependent, as in the UMIDAS case it has to be re-estimated for each forecast horizon.\nExactly as for the UMIDAS, we extend the MIDAS-AR in equation (14) to incorporate\nan MA component:\nytm\n= ~\nc(Lm)ytm-hm\n+ B(L, )xtm-hm+w\n+ utm\n+ q(Lm)utm-hm\nwhere the error term is defined as in (13). Given the nonlinearity of the model, we estimate\nits parameters by NLS. Appendix A provides additional details on the NLS estimation\nprocedures.\nTo conclude, it is worth briefly comparing the use for forecasting of UMIDAS-ARMA\nversus the Kalman filter. The latter is clearly optimal in the presence of mixed frequency\ndata and linear models. However, UMIDAS-ARMA is equivalent if it is theoretically derived\nfrom a known high frequency linear dynamic model, as UMIDAS-ARMA coincides with\nthe mixed frequency data generating process. The ranking of the two approaches is unclear\nif the high frequency model is mis-specified. Moreover, the Kalman filter can incur into\ncomputational problems when the frequency mismatch is large. Something similar happens\nto UMIDAS-ARMA, due to parameter proliferation, and in this case the parsimony of\nMIDAS-ARMA can be particularly helpful. Bai et al. (2013) propose a more detailed\ncomparison of the Kalman filter and the MIDAS approach.\n4 Monte Carlo evaluation\nWe now assess the forecasting relevance of including an MA component in MIDAS and\nUMIDAS models by means of simulation experiments. We use two designs, closely related\nto the two analytical examples described in Section 2.2. We present first the Monte Carlo\ndesigns and then the results.\n4.1 Monte Carlo design\nIn the first design, the DGP is the HF ARDL(1,1):\nytm\n+ l\n+ ey,tm\nwhere ytm\nis unobservable at HF, but available at LF, while xtm\nis the HF variable, tm\nis the\nHF time index, the aggregation frequency is m = 3 (as in the case of quarterly and monthly\nfrequencies), and t is the LF time index, with t = 3tm\n. We assume that (L) = 1 + L + L2,\ncorresponding to average sampling.\nThe shocks ey,tm\nare independent and sampled from a normal distribution with zero\nmean and variance chosen such that the unconditional variance of y is equal to one. We\nconsider different combinations of  and l\n, representing different degrees of persistence\nand correlation between the HF and the LF variables. In detail, we evaluate the following\nparameter sets:\n(, l\nFinally, xtm\nis generated as an AR(1) with coefficient .\nIn the second design, the DGP is the HF ARDL(2,2):\nytm\n+ ey,tm\nWe still assume m = 3 but now (L) = 1, so that the LF variable is skip-sampled every\nm = 3 observations.\nIn this second DGP, we consider the following parameter combinations:\nAll the other design features are as in the first DGP.\nWe focus on typical sample sizes for the estimation sample, with T = 50, 100. The size\nof the evaluation sample is set to 50, and the estimation sample is recursively expanded as\nwe progress in the recursive forecasting exercise. The number of replications is 500.\nThe competing forecasting models are the following:\n1. A MIDAS-AR model, with 12 lags in the exogenous HF variable and 1 lag in the AR\ncomponent;\n2. A MIDAS-ARMA model, as in the previous point but with the addition of an MA\ncomponent;\n3. A MIDAS-ARMA model, with only 3 lags in the exogenous HF variable and 1 AR\nlag;\n4. A UMIDAS-AR model, with lag length selected according to the BIC criterion, where\nthe maximum lag length is set equal to 12;\n5. A UMIDAS-ARMA model, as in the previous point, with the addition of an MA\ncomponent;\n6. A UMIDAS-ARMA, fixing at 3 the number of lags of the HF exogenous variable.\nIn all ARMA models there is an MA(1) component, in line with the theoretical results,\nbut an higher order can be allowed.\nWe evaluate the competing one-step ahead forecasts on the basis of their associated\nmean square prediction error (MSE), assuming that information on the first two months\nof the quarter is available (as it is common in nowcasting exercises).\nIn Tables 1 to 4 we report the mean relative MSE across simulations, and numbers\nsmaller than one indicate that the model is better than the benchmark (model 1, the\na measure of the dispersion in the results.\nTables 1 and 2 present the results for the first DGP (the ARDL(1,1) with average\nsampling), using T = 100 in Table 1 and T = 50 in Table 2. The corresponding Tables 3\nand 4 are based on the second DGP (the ARDL(2,2) with point-in-time sampling).\nA few key findings emerge. First, adding an MA component to the MIDAS model\ngenerally helps. The gains are not very large but they are visible at all percentiles, with a\nfew exceptions for the second DGP. The gains are larger either with substantial persistence\n= 0.5 in the second DGP) or with\nlow persistence in the first DGP ( = 0.1), but in the latter case the result is mainly due\nto a deterioration in the absolute performance of the standard MIDAS model. The more\nparsimonious specification with 3 lags only of the HF variable is generally better, except\nSecond, adding an MA component to the UMIDAS model is also generally helpful,\nthough the gains remain small.\nThird, in general the MIDAS-ARMA specifications are slightly better than the UMIDAS-\nARMA specifications, though the differences are minor. This pattern is in contrast with\nthe findings in Foroni et al. (2015), and suggests that adding the MA component to the\nMIDAS model helps somewhat in reducing the potential misspecification due to imposing\na specific lag polynomial structure.\nFinally, results are consistent across sample sizes, and the models do not seem sensitive\nto short sample sizes.\n5 Empirical applications\nIn this section, we look at the performance of our MA augmented mixed frequency mod-\nels in forecasting exercises with actual data. The analysis focuses on forecasting quarterly\nU.S. variables.\nIn particular, we consider three relevant quarterly U.S. macroeconomic variables: real\nGDP growth, real private non residential fixed investment (PNFI) growth and GDP de-\nflator inflation. As monthly explanatory variables, we consider industrial production and\nemployment for the real GDP growth and the PNFI growth, while we consider CPI infla-\ntion and personal consumption inflation for the GDP deflator. A complete description of\ndata sources and transformations is available in Table 5.\nThe total sample spans over 50 years of data, from the first quarter of 1960 to the end\nof 2015. The forecasts are computed in pseudo real time, with progressively expanding\nsamples. The evaluation period goes from 1980Q1 to the end of the sample, covering\nroughly 35 years. As a robustness check, we will also analyze a shorter sample ending\nin 2007Q3, to assess the effects of the recent crisis. At each point in time, we compute\nforecasts from 1- up to 4-quarter ahead. The forecasting target is the annualized growth\nrate. Although the information contained in the monthly variables updates every month,\nwe focus on the case in which the first two months of the quarter are already available.3\nWe consider the models (1) to (7) as described in Section 4.1, plus a simple low frequency\nAR(1) model as a further benchmark for the usefulness of the mixed-frequency data. In\nparticular, we consider the direct forecast resulting from the model:\nyt\n= c + yt-h\n+ et\nWe evaluate the forecasts both in terms of mean squared errors (MSE) and in terms of\nmean absolute errors (MAE). We then compare the forecasting performance relative to a\nstandard MIDAS model with an autoregressive component and 12 lags of the explanatory\nvariable (as the model (1) in Section 4).\nIn Tables 6 to 8 we report the results for, respectively, the real GDP growth, the real\nPNFI growth and the GDP deflator inflation rate. Each table is organized in the same way:\nit reports the value of MSE and MAE for each model, the ratio of those criteria for each\nmodel relative to the MIDAS-AR, our benchmark model, and the p-value of the Diebold-\nMariano test, to check the statistical significance of the differences in forecast measures\nwith respect to the benchmark (see Diebold and Mariano (1995)).\n3With the MIDAS setup, we could also report the results when no information or only one month of\ninformation is available. However, for the sake of conciseness we focus only on the case in which we are\ntwo months into the quarter, to have the shortest nowcast horizon. Given that our models are all mixed\nfrequency, this choice does not bias the comparison.\nThe tables are broadly supportive of the inclusion of the MA component in the mixed\nfrequency models, as the MSE and MAE ratios are often smaller than one for the MIDAS-\nARMA and UMIDAS-ARMA models when compared with their versions without MA.4\nMore in detail: for forecasting GDP growth, adding the MA component does not provide\nsubstantial improvements with respect to standard mixed frequency models for h = 1,\nwith industrial production being the best indicator. When h = 2, employment becomes\nbetter than industrial production, and adding an MA term matters, with gains of 8% for\nthe MIDAS-ARMA model. A similar results holds for h = 3, with gains increasing to\n20%. Four-quarter ahead, industrial production returns best, and MIDAS-ARMA leads to\na decrease of 10% in the MSE. For PNFI growth, MIDAS-ARMA is best at all horizons,\nwith employment preferred to industrial production except for h = 1. The gains are\nsmall for h = 1, 2, 3, in the range 1%-8%, but increase to 30% for h = 4. For GDP\ndeflator, PCE inflation is systematically better than CPI, and MIDAS-ARMA yields gains\nfor h = 1 and 2 of, respectively, 15% and 10%. It is also worth mentioning that MSE\nand MAE lead to the same rankings, and that the gains from adding the MA parts are\ngenerally statistically significant. Finally, the models perform well with respect to the AR\nbenchmark. Confirming the widespread evidence in the literature, the mixed frequency\nmodels perform the best at short horizons. However, we get satisfactory results also up to\nWe now decompose the MSE in bias and variance, as:\nMSE = (E(e))2\nBias\n+ V ar(e)\nVariance\nwith e = y - ^\ny. We find that the MA part helps especially in reducing the bias, suggesting\nthat the MA part is important to well approximate the conditional mean of y (the optimal\nforecast under the quadratic loss). When the models with the MA component are not\nperforming well, this is due especially to the variance term, instead. Detailed results on\nthe bias/variance decomposition are presented in Table 9. In particular, in the table we\nreport the ratio of the bias and of the variance of each model relative to the bias and\nvariance of the MIDAS-AR model, which is taken as a benchmark.\nThe MSE and MAE are computed over the entire evaluation sample. To check whether\nthe performance of our models remains good across the entire sample, in Figure 1 we report\n4The models which include an MA component are indicated in bold in the tables, while the lowest MSE\nand MAE values are underlined.\nthe one-quarter ahead forecasts of the benchmark MIDAS-AR model and of one of the MA\naugmented models, together with the realized series. In Figure 2, instead, we report the\n4-quarter ahead forecasts.5 It turns out that, on average, MIDAS models perform well\nthroughout the sample, both with and without an MA component.\nTables 10 and 11 report the full-sample estimates of MA coefficients in MIDAS-ARMA\nand UMIDAS-ARMA models that have been used in the forecasting exercise. The cor-\nresponding t-statistics are shown in parentheses. We observe that many MA coefficients\nare significant. For instance, MA(1) coefficient in MIDAS-ARMA-3lags model on GDP\ngrowth equation with employment growth is precisely estimated at horizons h = 1, 2, 3.\nThis MIDAS-ARMA model was also the best in out-of-sample forecasting exercise, see ta-\nble 6. In case of PNFI, when forecasting one quarter ahead with industrial production as\nhigh frequency predictor, MA coefficient is significant in all models. Same result holds at\nlonger horizons with employment growth. When it comes to GDP deflator prediction, an\ninteresting finding is that the MA(2) component is highly strong and significant for most\nof the horizons and models.\nFinally, to assess whether our results are robust to the exclusion of the recent crisis,\nwe have rerun the forecast evaluation over a sample ending in 2007Q3. Results do not\nchange substantially, and remain broadly supportive of the inclusion of the MA component\nin the mixed-frequency models. In most of the cases, the best performing model up to\n2007 remains the best in the full sample. The magnitude of improvements is also very\ncomparable. Detailed results are provided in Appendix B.\n6 Conclusions\nIn this paper, we start from the observation that temporal aggregation in general in-\ntroduces a moving average component in the aggregated model. We show that a similar\nfeature also emerges when not all but only a few variables are aggregated, which generates\na mixed frequency model. Hence, an MA component should be added to mixed frequency\nmodels, while this is generally neglected in the literature.\nWe illustrate in a set of Monte Carlo simulations that indeed adding an MA compo-\nnent to MIDAS and UMIDAS models further improves their nowcasting and forecasting\n5Figures 1 and 2 focus only on a small portion of results that we have available. The same figures for\nother models, other forecast horizons and other explanatory variables are available upon request.\nabilities, though in general the gains are limited and particularly evident in the presence\nof persistence. Interestingly, the relative performance of MIDAS versus UMIDAS further\nimproves when adding an MA component, with the latter attenuating the effects of impos-\ning a particular polynomial structure in the dynamic response of the low frequency to the\nhigh frequency variable.\nA similar pattern emerges in an empirical exercise based on actual data. Specifically,\nwe find that the inclusion of an MA component can substantially improve the forecasting\nperformance of quarterly macroeconomic U.S. variables, as GDP growth, PNFI growth and\nGDP deflator inflation. MIDAS-ARMA models perform particularly well, suggesting that\nthe addition of an MA component to the MIDAS model helps somewhat in reducing the\npotential misspecification due to imposing a specific lag polynomial structure. Finally, full\nsample estimates of MA coefficients are significant and important in most of MIDAS-ARMA\nand UMIDAS-ARMA specifications.\nReferences\nBai, J., Ghysels, E., and Wright, J. (2013). State Space Models and MIDAS Regressions.\nChiu, C. W. J., Eraker, B., Foerster, A. T., Kim, T. B., and Seoane, H. D. (2011). Esti-\nmating VAR's sampled at mixed or irregular spaced frequencies : a Bayesian approach.\nResearch Working Paper RWP 11-11, Federal Reserve Bank of Kansas City.\nDiebold, F. X. and Mariano, R. S. (1995). Comparing Predictive Accuracy. Journal of\nDufour, J.-M. and Stevanovic, D. (2013). Factor-Augmented VARMA Models With\nMacroeconomic Applications. Journal of Business & Economic Statistics, 31(4):491\u00ad\nFaust, J. and Wright, J. H. (2013). Forecasting Inflation. Handbook of Economic Forecast-\nForoni, C. and Marcellino, M. (2013). A survey of econometric methods for mixed-frequency\nForoni, C., Marcellino, M., and Schumacher, C. (2015). U-MIDAS: MIDAS regressions\nwith unrestricted lag polynomials. Journal of the Royal Statistical Society - Series A,\nGhysels, E. (2016). Macroeconomics and the reality of mixed-frequency data. Journal of\nGhysels, E., Santa-Clara, P., and Valkanov, R. (2006). Predicting volatility: getting the\nmost out of return data sampled at different frequencies. Journal of Econometrics, 131(1-\nGiannone, D., Reichlin, L., and Small, D. (2008). Nowcasting: The real-time informational\nLeroux, M., Kotchoni, R., and Stevanovic, D. (2017). Forecasting economic activity in\ndata-rich environment. EconomiX Working Papers 2017-5, University of Paris West -\nNanterre la Dfense, EconomiX.\nLutkepohl, H. (2006). Forecasting with VARMA Models, volume 1 of Handbook of Economic\nMarcellino, M. (1999). Some Consequences of Temporal Aggregation in Empirical Analysis.\nMarcellino, M., Stock, J. H., and Watson, M. W. (2006). A comparison of direct and\niterated multistep AR methods for forecasting macroeconomic time series. Journal of\nMariano, R. S. and Murasawa, Y. (2010). A Coincident Index, Common Factors, and\nMonthly Real GDP. Oxford Bulletin of Economics and Statistics, 72(1):27\u00ad46.\nNg, S. and Perron, P. (2001). LAG Length Selection and the Construction of Unit Root\nPerron, P. and Ng, S. (1996). Useful Modifications to some Unit Root Tests with Dependent\nErrors and their Local Asymptotic Properties. Review of Economic Studies, 63(3):435\u00ad\nRavenna, F. (2007). Vector autoregressions and reduced form representations of DSGE\nSchorfheide, F. and Song, D. (2015). Real-Time Forecasting With a Mixed-Frequency VAR.\nStock, J. H. and Watson, M. W. (2007). Why Has U.S. Inflation Become Harder to Forecast?\nTable 1: Monte Carlo simulations results: MSE(model) relative to MSE(MIDAS) - DGP:\nNote: The four panels report the results for four different DGPs for 1-quarter ahead horizon (with the infor-\nmation of the first two months of the quarter available). The numbers (2) to (6) refer to the corresponding\nmodels described in Section 4. The results reported are the average, median and the 10th, 25th, 75th, 90th\npercentiles of the MSE of the indicated model relative to the average, median and the 10th, 25th, 75th, 90th\npercentiles of the MSE of the benchmark MIDAS (model (1) in Section 4) computed over 500 replications.\nTable 2: Monte Carlo simulations results: MSE(model) relative to MSE(MIDAS) - DGP:\nNote: See Table 2.\nTable 3: Monte Carlo simulations results: MSE(model) relative to MSE(MIDAS) - DGP:\nNote: The four panels report the results for three different DGPs. The numbers (2) to (6) refer to\nthe corresponding models described in Section 4. The results reported are the average, median and the\n10th, 25th, 75th, 90th percentiles of the MSE of the indicated model relative to the average, median and the\n10th, 25th, 75th, 90th percentiles of the MSE of the benchmark MIDAS (model (1) in Section 4) computed\nTable 4: Monte Carlo simulations results: MSE(model) relative to MSE(MIDAS) - DGP:\nARDL(2,2) with point-in-time sampling, T = 50\nNote: see Table 3.\nTable 5: Data description\nSeries Source Source Code Transformation Frequency\nUS data\nGDP Deflator FRED GDPDEF Log-difference Quarterly\nReal GDP FRED GDP Log-difference Quarterly\nPrivate Nonresidential Fixed Investment FRED PNFI Level Quarterly\nNonresidential (implicit price deflator) FRED A008RD3Q086SBEA Level Quarterly\nReal Private Nonresidential Fixed Investment PNFI / A008RD3Q086SBEA Log-difference Quarterly\nConsumer Price Index (CPI) FRED CPIAUCSL Log-difference Monthly\nPersonal Consumption Expenditures: Price Index (PCE) FRED PCEPI Log-difference Monthly\nEmployment FRED PAYEMS Log-difference Monthly\nIndustrial Production FRED INDPRO Log-difference Monthly\nTable 6: Forecasting U.S. GDP growth\nExplanatory variable: Explanatory variable:\nIndustrial production growth Employment growth\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nNote: The table reports the results on the forecasting performance of the different models. In the columns\n\"value\" we report the MSE and the MAE respectively. In the columns \"ratio\" we report the MSE and\nMAE of each model relative to the MIDAS-AR benchmark. In the columns \"DM\" we report the p-value of\nthe Diebold-Mariano test. The forecasts are evaluated over the sample 1980Q1-2015Q4. The lowest values\nfor each variable are underlined.\nTable 7: Forecasting U.S. Real Private Nonresidential Fixed Investment growth\nExplanatory variable: Explanatory variable:\nIndustrial production growth Employment growth\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nNote: See Table 6.\nTable 8: Forecasting U.S. GDP Deflator\nExplanatory variable: Explanatory variable:\nCPI inflation PCE inflation\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nNote: See Table 6.\nTable 9: Bias/Variance decomposition of MSE\nBias Variance\nNote: The table the decomposition of the MSE of the different models as presented in Section 4 into\nbias and variance, for different forecasting horizons. The forecasts are evaluated over the sample 1980Q1-\n2015Q4. The numbers reported are the ratio of the bias and of the variance of each model relative to the\nbias and variance of the MIDAS-AR model.\nTable 10: Full-sample estimated MA coefficients\nForecasting U.S. GDP growth\nExplanatory variable: Explanatory variable:\nIndustrial Production Employment\nForecasting PNFI growth\nExplanatory variable: Explanatory variable:\nIndustrial Production Employment\nNote: The table reports the estimated values of MA coefficients using the full sample 1960-2015. The\nvalues in parentheses are t-statistics calculated with Newey-West standard errors to take into account the\nserial autocorrelation of order h - 1, possibly induced by direct forecasting.\nTable 11: Full-sample estimated MA coefficients\nForecasting U.S. GDP deflator\nExplanatory variable:\nConsumer Price Index\nExplanatory variable:\nPCE Price Index\nNote: The table reports the estimated values of MA coefficients using the full sample 1960-2015. The\nvalues in parentheses are t-statistics calculated with Newey-West standard errors to take into account the\nserial autocorrelation of order h - 1, possibly induced by direct forecasting.\nFigure 1: Out-of-sample performance: one-quarter ahead\n(a) GDP with monthly industrial production (b) PNFI with monthly industrial production\n(c) GDP deflator with monthly CPI (d) GDP deflator with monthly PCE\nFigure 2: Out-of-sample performance: four-quarters ahead\n(a) GDP with monthly employment (b) PNFI with monthly employment\n(c) GDP deflator with monthly CPI (d) GDP deflator with monthly PCE\nA Estimation of (U)MIDAS-ARMA models\nIn this section we detail the algorithm used to estimate the (U)MIDAS-ARMA models\nwith non-linear least squares (NLS).\nA.1 NLS estimation of MIDAS-ARMA\nThe MIDAS-ARMA specification is as in (15):\nytm\n= ~\nc(Lm)ytm-hm\n+ B(L, )xtm-hm+w\n+ utm\n+ q(Lm)utm-hm\n.\nThe estimation procedure, for given orders of the lag polynomials, consists of the following\nsteps:\nStep 1 Get initial values for all the parameters but q(Lm) following Foroni et al. (2015) (the\nstarting values are chosen with a grid search over a set of values for , which minimize\nthe residual sum of squares). Set the initial values for q(Lm). We initialize the MA\ncoefficients by a draw from the uniform U(0.1, 0.5) distribution. In principle, it is\npossible to include the selection of initial value of q(Lm) into the grid search.\nStep 2 Estimate all the parameters, including the weights in the Almon polynomial, simul-\ntaneously by NLS, numerically minimizing the residual sum of squares, starting from\nthe initial values obtained in Step 1.\nA.2 NLS estimation of UMIDAS-ARMA\nThe UMIDAS-ARMA specification is as in (13):\nytm\n= ~\nc(Lm)ytm-hm\n+ (L)xtm-hm+w\n+ utm\n+ q(Lm)utm-hm\n,\nwith p, d and r being the lag orders of ~\nc(Lm), (L) and q(Lm) respectively. The\nestimation procedure consists of the following steps:\nStep 1 Get the initial values for all the parameters but q(Lm) by projecting ytm\non p\nytm-hm-j\nand d\nxtm-hm+w-j\n. Set the initial value for q(Lm). We initialize the MA coeffi-\ncients by a draw from the uniform U(0.1, 0.5) distribution. In principle, it is possible\nto perform a grid search and find a set of starting values of q(Lm) which minimize\nthe residual sum of squares.\nStep 2 Estimate all the parameters simultaneously by NLS, numerically minimizing the resid-\nual sum of squares, starting from the initial values obtained in Step 1.\nB Evaluation excluding the Great Recession\nTo see whether our results are robust, and not driven by the Great Recession, we\nrecompute the forecast evaluation stopping our evaluation sample in 2007Q3.\nTables 12 to 14 are the equivalent of Tables 6 to 8 for the full sample. Results do not\nchange substantially, and remain broadly supportive of the inclusion of the MA component\nin the mixed-frequency models. In most of the cases, the best performing model up to\n2007 stays the best in the full sample also. Also the magnitude of improvements is very\ncomparable.\nExplanatory variable: Explanatory variable:\nIndustrial production growth Employment growth\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nNote: The table reports the results on the forecasting performance of the different models. In the columns\n\"value\" we report the MSE and the MAE respectively. In the columns \"ratio\" we report the MSE and\nMAE of each model relative to the MIDAS-AR benchmark. In the columns \"DM\" we report the p-value of\nthe Diebold-Mariano test. The forecasts are evaluated over the sample 1980Q1-2007Q3. The lowest values\nfor each variable are underlined.\nTable 13: Forecasting U.S. Real Private Nonresidential Fixed Investment growth growth:\nExplanatory variable: Explanatory variable:\nIndustrial production growth Employment growth\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nExplanatory variable: Explanatory variable:\nCPI inflation PCE inflation\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM\nValue Ratio DM Value Ratio DM Value Ratio DM Value Ratio DM"
}