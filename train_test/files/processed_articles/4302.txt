{
    "abstract": "Abstract: Although much recent attention has focused on identifying domain-specific\ntaxonomic differences in cognition, little effort has been directed towards\ninvestigating whether domain-general differences also exist. We therefore conducted\na meta-analysis of published nonhuman primate cognition studies, testing the\nprediction that some taxa outperform others across a range of testing situations. First,\nwithin each of nine experimental paradigms with interspecific variation, we grouped\nstudies by their procedures and the characteristics of their study subjects. Then, using\nBayesian latent variable methods, we tested whether taxonomic differences\nconsistently held within or across paradigms. No genus performed especially well\nwithin particular paradigms, but genera differed significantly in overall performance.\nIn addition, there was evidence of variation at higher taxonomic levels; most notably,\ngreat apes significantly outperformed other lineages. These results cannot be readily\nexplained by perceptual biases or any other contextual confound and instead suggest\nthat primate taxa differ in some kind of domain-general ability.\n",
    "reduced_content": "Evolutionary Psychology\n\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\nOriginal Article\nDo some taxa have better domain-general cognition than others? A meta-\nanalysis of nonhuman primate studies\nRobert O. Deaner, Department of Neurobiology, Duke University Medical Center, Box 3209, Durham,\nCarel P. van Schaik, Anthropological Institute and Museum, University of Z\u00fcrich, Winterthurerstrasse\nValen Johnson, Biostatistics and Applied Mathematics, The University of Texas M. D. Anderson\n Keywords: intelligence, modularity, Bayesian analysis, great apes.\n\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\u00af\nIntroduction\nA major goal for many comparative psychologists of previous generations\nwas to identify taxonomic differences in overall intelligence (e.g., K\u00f6hler, 1925;\nbelieve it is still profitable to pursue this line of research. For one thing, there is now\ncompelling evidence that individuals possess many distinct cognitive abilities,\nincluding specific types of learning, memory, and timing (e.g., Sherry & Schacter,\nMeta-analysis of Primate Cognition\n1987; Gallistel, 2000). In addition, investigators taking a comparative evolutionary\napproach have identified domain-specific abilities that were apparently selected to\nincrease an animal's fitness in its taxon-typical environment (e.g., Rozin, 1976;\nAlthough the notion of ranking taxa on a uni-dimensional scale of intelligence\nis flawed, there could be instances where one taxon possesses better domain-general\ncognition than another. Specifically, although taxon A might share many abilities\nwith taxon B or lack some of B's domain-specific abilities, if A possessed an ability\nor abilities that allowed it to excel in a wide variety of contexts requiring behavioral\nflexibility (cf. fluid intelligence: Cattell, 1971), the claim of some sort of domain-\ngeneral cognitive difference would be appropriate. Demonstrating the existence of\nsuch a difference will clearly be difficult, but we suggest that progress can be made\nwith the following steps: (1) focusing on a taxonomic group where species have\nsimilar motor and sensory capacities; (2) considering all paradigms (i.e., general\nkinds of problems) where interspecific variation has been identified; (3) and testing\nwhether some taxa consistently perform better than other ones across the paradigms.\nThis meta-analysis approach has two important advantages. First, it largely\nresolves the performance-ability conundrum (i.e., the fact that performance\ndifferences may arise because animals differ in motivation, adaptability to the testing\nsituation, or ability or preparedness to perceive or respond to the experimental\ndifference is found in a range of situations, the likelihood diminishes that the\ndifferences merely reflect a particular testing variable (Kamil, 1988). Second,\nconsidering performance in a number of paradigms explicitly addresses the issue of\ndomain-generality: if one taxon truly has better domain-general cognition than\nanother, it should perform better in a variety of unrelated situations. In contrast,\ninvestigations attempting to test for uni-dimensional intelligence have often searched\n(unsuccessfully) for a single \"holy grail\" paradigm (Schrier, 1984).\nHere we apply this approach to the order primates, a group that is ideal for\nthree reasons. First, much relevant information has already been collected, meaning\nthat it is possible to conduct an analysis with a reasonable degree of statistical power.\nSecond, despite all of the research, there are few demonstrations of taxon-specific,\ndomain-limited cognitive abilities in primates (e.g., Platt, Brannon, Briese, & French,\n1996; Stevens, Hallinan, & Hauser, 2005). The paucity of such demonstrations (if\ntruly indicating few specializations), should increase the possibility of detecting\ndomain-general differences, the existence of which has been repeatedly suggested in\nSchaik, Deaner, & Merrill, 1999; Reader & Laland, 2002). Third, although primates\nare behaviorally diverse, most taxa are highly dependent on visual processing and\npossess considerable manual coordination. Hence, the same testing procedures should\nbe applicable for most subjects.\nSeveral previous studies have surveyed primate cognition and reached a range\nMeta-analysis of Primate Cognition\nof answers to the question of whether there are overall taxonomic differences across\nparadigms (e.g., Rumbaugh, 1970; Ehrlich, Fobes, & King, 1976; Tomasello & Call,\n1997). The divergent conclusions can be attributed to the fact that none of the surveys\nhave been performed systematically. In particular, they combined data that were\ncollected with substantially different procedures, compared subjects of differing ages\nand experience, and based their overall conclusions on qualitative impressions, rather\nthan statistical tests.\nTherefore, in the present study, we (1) attempt to exhaustively search the\nliterature for all relevant data, (2) restrict comparisons to subjects with similar\nbackgrounds and studies conducted with extremely similar procedures, (3) use\nexplicit criteria for deciding if there is a taxonomic difference within a type of study\nprocedure, and, finally, (4) employ a recently developed hierarchical Bayesian model\n(Johnson, Deaner, & van Schaik, 2002) to test if taxa perform especially well across\nall paradigms or instead excel in particular paradigms. By systematically addressing\nthese issues in a well-studied lineage, this paper provides a strong test of the\nhypothesis that there are taxonomic differences in domain-general cognition.\nMaterials and Methods\nWe began by searching published reviews of primate cognition (e.g.,\nMacPhail, 1982; Tomasello & Call, 1997), looking for indications of inter-specific\nvariability within experimental testing paradigms that were deemed relevant to issues\nof \"learning\", \"cognition\", or \"intelligence\". We eliminated from consideration\nparadigms where animals were not rewarded for their performance because, in this\nsituation, poor performance could be indicative of an animal being unmotivated or\nmisunderstanding the experimenter's expectations. Examples of this are\ninvestigations of object manipulation, gaze-following, and mark tests of \"self\nrecognition\" (see Tomasello & Call, 1997).\nAfter identifying potentially useful paradigms, we went to the relevant\nresearch articles, searched these for other relevant citations and then repeated the\nprocess several times. We also employed the \"PsychLit\" computer database,\nsearching with several keywords relevant to each paradigm. For instance, for the\nreversal learning paradigm we considered all articles that contained this phrase,\n\"transfer learning\", or \"intra-dimensional shift learning.\" Although we attempted to\nexhaustively search the relevant literature, our survey is likely biased towards reports\nin English. We completed our literature survey in February of 2001.\nA variety of procedures have been used to investigate most paradigms. For\nexample, some studies of object discrimination learning sets employ six trials per\nproblem, whereas others administer trials until a criterion level of performance is\nreached. In most cases, procedural differences are known or expected to affect\nperformance. Thus, we only pooled data from separate studies if they were conducted\nMeta-analysis of Primate Cognition\nwith extremely similar or identical procedures. Rather than rating one type of study\nprocedure as better than the others, we retained data from all suitable procedures.\nTherefore, for most paradigms, several separate taxonomic rankings were obtained.\nWe refer to these separate taxonomic rankings as procedure rankings within\nparadigms.\nTo make statistical treatment more tractable, and because most behavioral\nvariation in primates occurs at higher-order taxonomic levels (e.g., Harvey, Martin, &\nClutton-Brock, 1987), we used the genus, rather than the species, as the minimal\ntaxonomic unit. The data on the various macaque species, for example, were all\ngrouped into Macaca. Because most proposed differences occur at even higher-order\ntaxonomic levels than the genus, we also conducted some analyses after placing\ngenera into the following groups: prosimians (Eulemur, Galago, Lemur, Microcebus,\nNycticebus, Phaner, Varecia), New World monkeys (Aotus, Ateles, Callithrix, Cebus,\nLagothrix, Saimiri), Old World monkeys (Cercocebus, Cercopithecus, Macaca,\nMandrillus, Miopithecus, Papio, Presbytis), lesser apes (Hylobates) and great apes\n(Gorilla, Pan, Pongo). To further keep the study manageable in scope, we only\nconsidered paradigms where comparisons involved at least three genera. In several\ncases, a single procedure only allowed a comparison between two genera, but this\ninformation was included if there were other procedures within the paradigm. Thus, if\nthere were two procedures within a paradigm and both involved comparing two taxa,\nwe retained data from both procedures.\nTaxonomic comparisons would ideally occur among a random sample of\nsubjects that each had species-typical rearing histories, similar maturity levels,\nmotivation, and experience relevant to the testing situation. Towards this end, we\ntook the following steps. First, we omitted subjects that were drawn from a larger\npool because they were thought to have unusually poor or excellent abilities. Second,\nwe omitted all subjects that were reared in social isolation or had undergone\nneurosurgery (although control subjects from neurosurgery studies were considered).\nWe did not omit great ape subjects that had extensive language or symbolic training\nbecause there is no indication that this experience affects performance on tasks\ninvolving non-social cognition (Call & Tomasello, 1996), and all data were drawn\nfrom non-social paradigms. Third, we excluded infants, operationally defined as\nanimals whose age at testing was indicated to be less than 1/5 the age at first\nreproduction (AFR; data from Ross & Jones, 1999). In most great apes, for example,\nthis corresponds to less than about two years, whereas in most Old World monkeys it\ncorresponds to less than about one year. Because performance may improve\nconsiderably after 1/5 AFR (e.g., delayed response: Harlow, Uehling, & Maslow,\n1982; patterned-string problems: Mason & Harlow, 1961), we also repeated all tests\nafter excluding animals that were less than 1/2 AFR. In many studies, ages were not\nprovided: to be conservative, if no information was available or if subjects were\ndescribed as \"juveniles\", \"immatures\", or \"adolescents\", we considered them to be at\nMeta-analysis of Primate Cognition\nleast 1/5 AFR but less than 1/2 AFR; if animals were described as \"late adolescents\",\n\"late juveniles\", \"subadults\" or \"adults\", we considered them to be at least 1/2 AFR.\nFourth, we frequently omitted subjects that were known to differ from others in\nexperience known to be relevant to the task (see Appendix A). Fifth, one study was\nomitted where investigators noted that animals were not tested with a favored or\npreferred food (Riopelle & Moon, 1968). Finally, in one case, we omitted subjects\nthat did not attempt to solve the problem (Davis & Leary, 1968).\nIn ranking genera within procedures, we had to consider two opposing\nconcerns. On one hand, we did not wish to rank one genus over another based on\nextremely small performance differences, because such differences are likely to\nreflect various sorts of error, rather than intrinsic differences. On the other hand,\nbecause most studies employed modest sample sizes, if we only assigned rankings\nwhen taxa differed significantly or dramatically, there would be very little data left to\nanalyze. In an effort to balance these two concerns, we used the following guidelines.\nFor qualitative comparisons, we considered taxa to be different if they met\neither of two criteria. First, at least half of the subjects of one taxon performed\npositively (i.e., met some qualitative distinction), and none of the subjects of the other\ntaxon performed positively; there had to be a minimum of two subjects in the taxon\nwith no positive performance. Second, all subjects of one taxon performed positively,\nand less than half of the subjects of the other taxon performed positively; there had to\nbe a minimum of two subjects in the taxon with all positive performance.\nWe also used two criteria for making quantitative distinctions. First, in cases\nwhere there was a single relevant performance measure, either the original\ninvestigators or we had to demonstrate statistically significant taxonomic variation.\nFor establishing taxonomic variation within study procedures, we set significance at\n = 0.05 and used two-tailed tests. Second, in procedures where multiple measures\nwere available, we sought evidence of significant taxonomic variation in at least one\nmeasure or consistent taxonomic variation across all measures (i.e., one taxon doing\nbetter than others did across all types of problems, or problem blocks).\nEmploying these quantitative criteria was sometimes difficult because in\nprocedures where data were available for three or more taxa, there were often\nproblems of intransitivity in significance or consistency. For instance, genus A might\nhave a significantly (or consistently) higher overall mean score than genus C but only\na slightly (and non-significantly) higher score than genus B; genus B, however, might\nnot have a significantly higher score than genus C. We generally resolved\nintransitivities by assuming that once significant or consistent overall variation had\nbeen demonstrated across all taxa, all differences among taxa were meaningful. So, in\nthis example, we would rank genus A first, genus B second, and genus C third, rather\nthan considering them all tied or representing the information in some other way.\nAnother complication was that in some cases where overall taxonomic variation was\ndemonstrated among three or more taxa, two taxa might differ on measures that could\nnot be quantitatively collapsed. For instance, one taxon might score higher score on\nMeta-analysis of Primate Cognition\none problem type, the other taxon might score higher on another, and collapsing the\nscores into some sort of grand mean would be unjustified. In such cases, we generally\nregarded the taxa as tied. In the specific procedures where this issue arose, it is\naddressed in more detail.\nThe sample: paradigms, procedures and rankings\nThis section briefly describes and reviews each of the paradigms employed.\nUnder each paradigm are subsections providing details on each of the procedures that\nallowed taxonomic rankings. We attempt to provide enough detail on each procedure\nto give a flavor for the research and to make clear the reasoning for the grouping the\nstudies as we did. In doing so, we make it possible to repeat this study using slightly\ndifferent decision rules.\nWithin each procedure, we list the number of subjects for each genus that\nwere considered to be at least 1/5 AFR. We also note whether they participated in\nother studies included in the data set, allowing us to address the possible impact of\npseudo-replication. We generally do not discuss subjects' pre-training or prior\nexperience because, if it differed substantially from that of others within the\nprocedure, the exceptional subjects were excluded or grouped with other, similarly\nexperienced subjects in other procedures. We state the criteria used in ranking the\ngenera and the evidence that indicated meaningful taxonomic variation. For\nquantitative measures, we only provide details of statistical tests if there was no\ndocumentation of meaningful variation in the original publications. We also note if\nany subjects were excluded because of evidence of poor motivation. Finally, we note\nif comparisons could be made among subjects greater than 1/2 AFR. The overall\nrankings for all procedures across all paradigms are presented in table 1.\nDespite the details presented above, there may still be questions regarding\nwhy we did not include particular studies in the analysis. To more fully explain these\ndecisions, we have provided two appendices. Appendix A discusses particular studies\nthat do fit within the paradigms we employed but that, nevertheless, could not be\nincorporated in our analysis. Generally, these studies could not be used because they\ndid not provide data on multiple taxa, did not reveal significant taxonomic variation,\nor, because of procedural differences, could not be combined with other studies\nwithin their paradigm. Appendix B lists paradigms from which researchers have\ndrawn, or might consider drawing, taxonomic distinctions and clarifies why these\nparadigms could not be included in our sample. Appendices A and B are not intended\nto serve as a comprehensive guide to all primate cognition studies that were not\nincluded; they are meant only to clarify our decision making for the studies about\nwhich readers are most likely to be curious.\nMeta-analysis of Primate Cognition\nTable 1. The full data set. Lower ranking indicates better performance. DP = detour\nproblems; PS = patterned-string problems; ID = invisible displacement; TU = tool\nuse; DL = object discrimination learning sets; RL = reversal learning; OD = oddity\nlearning; SO = sorting; DR = delayed response.\nGENUS\nNycticebus 2\nPresbytis 1\nDetour Problems\nDetour problems investigate the ability to form and act on spatial\nrepresentations. Although detour problems frequently focus on subjects' locomotion\nthrough mazes, primates have mainly been investigated on problems where they are\nrequired to manually move an object through a spatial field that contains one or more\nobstacles.\nMeta-analysis of Primate Cognition\nMacaca on problems where a preferred food was impaled on a bent wire. For\ninstance, in one problem the subject had to first move the food to her right before\npulling it towards her, whereas in another problem, the subject had to move the food\nto her left and then push it away from her. There were 40 different kinds of bent wire\nproblems in all. Across all problem blocks and all problem types, Pan performed\nbetter than Macaca, and hence was ranked lower (i.e., superior). Because no data\nwere presented on Macaca that were greater than 1/2 AFR, this study only applies to\ngreater than 1/5 AFR analyses.\nprocedure 2. McDowell & Nissen (1959) tested 24 Macaca and five Pan in a\nseries of problems where subjects worked to free a food-containing stylus. (Most\nsubjects had participated in procedure 1.) The stylus was positioned behind a short\nladder, so that it could only be obtained by alternately using two hands to bring the\nstylus to the top of the ladder. On all variations of the problem, Pan performed better\nthan Macaca and hence was ranked lower. All subjects were greater than 1/2 AFR.\nprocedure 3. Davis & Leary (1968) tested 19 Macaca, two Cercopithecus,\nfour Cebus, four Lagothrix, four Lemur and seven Saimiri on three kinds of bent wire\ndetour problems (similar to procedure 1). Data were presented on mean success rate\nat seven separate time blocks, for each species. After calculating weighted mean\nscores for all Macaca (three species were included), we used analysis of covariance\n(ANCOVA) on the log-transformed test scores to confirm that there was significant\ncalculated a grand mean for each genus and ranked them from lowest to highest, as\nfollows: Macaca, Cercopithecus, Lagothrix, Cebus, and Lemur. We omitted Saimiri\nfrom the rankings because most subjects did not attempt to solve the problem.\nBecause the subjects' ages were not provided, this study was only incorporated in the\ngreater than 1/5 AFR analyses.\nPatterned-string problems\nPatterned-string problems investigate the ability to represent spatial\nrepresentations among objects. In this paradigm, a subject is shown an array of strings\n(or wires), one of which is tethered to a desirable food. The subject is allowed to pull\nonly one of the strings, and hence must determine before pulling which string is\nactually attached to the food. The difficulty is that many patterned-string problems\nconsist of strings that cross or are otherwise misleading.\nCha & King (1969) presented evidence indicating that Saimiri may solve\npatterned-string problems by simply learning which perceptual configurations have\nbeen previously rewarded. If this is true generally, taxonomic differences in\npatterned-string problems might reflect differences in perception and discrimination\nlearning rather than spatial representation (Tomasello & Call, 1997). Nevertheless, a\nlearning strategy cannot explain why many non-Saimiri subjects perform virtually\nMeta-analysis of Primate Cognition\nperfectly from the onset of trials, and why, across subjects, these superb performances\ntend to occur on the same \"easy\" problems (see papers cited in procedure 4). Thus,\npatterned-string problems probably do reflect the ability for spatial representation, at\nleast for subjects that perform well.\nprocedure 4. Harlow & Settlage (1934) first employed the method of giving\nsubjects 10 standardized patterned string problems for approximately 100 trials.\nSubsequent investigations (Finch, 1941; Riesen, Greenberg, Granston, & Fantz, 1953;\nextremely similar methods, allowing us to pool data for 20 Macaca, three\nCercocebus, two Cercopithecus, one Papio, six Mandrillus, two Cebus, one Ateles,\nfour Pan, five Gorilla, and two Pongo. We first calculated the mean error score for\neach genus on each problem and then conducted a two-way analysis of variance\n(ANOVA) to confirm that there was significant variation across genera across all\nmean score across all problems and obtained the following ranking, from least to\nmost errors: Pongo, Pan, Ateles, Gorilla, Mandrillus, Cercocebus, Macaca,\nCercopithecus, Cebus, and Papio. Tomasello & Call (1997) suggested that taxonomic\ncomparisons may be most meaningful if only the most difficult problems are\nconsidered. Because the error rates on the rates on the last two problems are 1.7 to 10\ntimes higher than on the first eight problems, we re-ranked the taxa based only on the\nmeans on these last two problems. The first four and last two rankings remained\nunchanged, but the ranks of Mandrillus, Cercocebus, Macaca, Cercopithecus\ndiffered, and we therefore considered these genera tied. Finally, we repeated the\nanalysis after omitting all subjects (n = 11) that were not at least 1/2 AFR. The\nrankings were very similar and, furthermore, did not change when we repeated the\nanalysis using only the two most difficult problems. In this case, the rankings were\nPan, Ateles, Cercocebus, Mandrillus, Macaca, Cercopithecus/Papio (tied), and\nCebus.\nInvisible displacement\nThe invisible displacement paradigm is best understood as an extension of the\nvisible displacement paradigm, a paradigm where virtually all species studied so far\nsucceed (reviewed in Dor\u00e9 & Dumas, 1987; Tomasello & Call, 1997). In the visible\ndisplacement paradigm, a subject views an object moving towards and then\ndisappearing behind one or more barriers. If the subject searches the barrier behind\nwhich the object disappeared, this suggests the subject can represent the existence of\nunperceived objects or possesses object permanence. By contrast, in most variations\nof the invisible displacement paradigm, the subject views an object being placed into\na container, the container is moved behind one or more barriers, and then the subject\nis shown that the container is empty. If the subject searches only the barriers behind\nwhich the container passed, it indicates the subject can represent the existence and\nMeta-analysis of Primate Cognition\nspatial movements of unperceived objects.\nNumerous studies of invisible displacement have been conducted, but\nunfortunately most of them cannot be used for making taxonomic comparisons. One\nproblem is that early studies did not employ adequate controls to ensure that\nsuccessful searching was actually mediated by a representational strategy, rather than\na spatial or associatively learned rule (reviewed in Natale, Antinucci, Spinozzi, &\nPoti, 1986; Gagnon & Dor\u00e9, 1992). A second problem is that, although the capacity\nto represent the existence and movements of unperceived objects has been\ntraditionally viewed as a monolithic entity (i.e., a subject is or is not capable), recent\nresearch indicates that performance is dependent on the specific requirements of the\nproblem and/or a subject's previous experience (Filion, Washburn, & Gulledge, 1996;\nde Blois, Novak, & Bond, 1999). Thus, as for other paradigms, comparisons must be\nrestricted to studies conducted with the same procedures. Because of the number and\ncomplexity of the test conditions in each study, we have not provided procedural\ndetails. For these, we urge readers to consult the original publications.\none Gorilla, four Macaca and two Cebus, and after employing a variety of control\nprocedures, showed that only the Gorilla used a representational strategy to solve the\ntask. Because several of the subjects, including the Gorilla were less than 1/2 AFR,\nthis data only counts towards greater than 1/5 AFR analyses.\nprocedure 6. de Blois, Novak, & Bond (1998) tested seven Pongo and nine\nSaimiri in a variety of conditions and found that most or all Pongo subjects used a\nrepresentational strategy to solve some kinds of invisible displacement problems. In\ncontrast, there was no evidence that any Saimiri subjects were capable of solving\nproblems in this way. All subjects were greater than 1/2 AFR.\nprocedure 7. de Blois et al. (1999) tested seven Pongo (all had participated in\nprocedure 6) and five Macaca (see de Blois & Novak, 1994) on a series of problems\nthat were designed to detect if memory demands affect invisible displacement\nperformance. There was no evidence that any of the Macaca spontaneously employed\nrepresentational strategies, whereas there was such evidence for four Pongo subjects.\nAll subjects were greater than 1/2 AFR.\nTool Use\nTool use addresses abilities to understand and manipulate how one's actions\naffect an intermediate object (the tool), and how the intermediate object affects\nanother object or substrate. It thus involves aspects of causal reasoning, spatial\nrepresentation, and motor coordination. Although many aspects of primate tool use\nhave been well-studied (reviewed in Beck, 1980; Tomasello & Call, 1997; van Schaik\net al., 1999), there are remarkably few experimental studies that indicate taxonomic\ndifferences in the abilities which underlie tool use.\nprocedure 8. Natale (1989) studied the development of one Gorilla, three\nMeta-analysis of Primate Cognition\nMacaca, and four Cebus in \"the stick problem\". (All subjects had participated in\nprocedure 5). Here food is placed beyond a subject's reach, and a stick is placed in\none of several positions near the food; the subject's task is to employ the stick as a\nrake to access the food. All of the subjects readily manipulated the stick and, at least\noccasionally, succeeded in accessing the food. Furthermore, the gorilla and three of\nfour Cebus learned to systematically make contact between the stick and the reward.\nIn contrast, the three Macaca and one of the Cebus did not develop this strategy,\ninstead manipulating the stick without reference to the reward, a practice that was less\nsuccessful. Hence, Gorilla and Cebus were ranked tied and superior to Macaca. The\ngorilla subject was less than 1/2 AFR, as were one Cebus and one Macaca. Of the\nremaining subjects, two of three Cebus learned to make systematic contact and none\nof the three Macaca did. Hence, Cebus was ranked superior to Macaca in the greater\nthan 1/2 AFR analysis.\nprocedure 9. Visalberghi, Rumbaugh, & Fragaszy (1995) tested six Cebus,\nfive Pan, and one Pongo in a task where a food reward was placed inside a\ntransparent tube. After subjects had shown the ability to use a dowel to push the food\nfree, they were provided with a bundle of sticks that was too wide to insert into the\ntube. All but one of the Cebus repeatedly made the error of attempting to insert the\nentire bundle into the tube. In contrast, all Pan and Pongo subjects consistently\nunbundled the sticks before attempting to insert one in the tube. Thus, Pan and Pongo\ncan be ranked below Cebus. All of the Cebus, one Pan and the one Pongo were\ngreater than 1/2 AFR, so this ranking also applies to that analysis.\nObject Discrimination Learning Set\nIn the object discrimination learning set paradigm, the subject is first\nconfronted with the problem of discriminating between two \"junk\" objects. One of\nthe objects is arbitrarily designated correct, and the subject is rewarded for selecting\nit. The subject is given several trials under these conditions and usually will learn to\nconsistently make the correct choice (regardless of the object's spatial position). The\nlearning set phenomenon refers to the observation that if the subject is given another\ndiscrimination problem, with two novel stimuli, it will tend to learn this second\ndiscrimination problem more quickly than it did the first one. Over the course of\nseveral hundred problems, a subject's performance on trial 2 might improve from\nabout 55% to 80%. (Trial 1 performance must be at chance levels, because there is no\nbasis for discrimination.) Beginning with Harlow (1949), numerous investigations of\nthe learning set phenomenon have led to the consensus that it truly indicates the use\nsome type of abstract rule or hypothesis (e.g., \"win-stay, lose-shift\") that goes beyond\nAlthough there is a vast amount of published data on learning sets in different\nprimate species, it is difficult to make meaningful quantitative comparisons because\nMeta-analysis of Primate Cognition\ninvestigations usually differ in many ways that are known to affect performance.\nThese include the amount pre-training and/or previous experience, the number of\ntrials per problem, the use of a correction procedure, and the position of the objects\nrelative to the food wells (reviewed in Miles, 1965; Fobes & King, 1982). Although\nimprovements across trials (i.e., the learning set phenomenon) have been shown for\nmany types of learning, we only present information in this section on object\ndiscrimination learning sets. Taxonomic comparisons for other types of learning\nimprovements are included in other paradigms (e.g., detour problems, reversal\nlearning, oddity learning).\nthree Callithrix, and four Macaca with six trials per problem after minimal pre-\ntraining. For trial 2 performance across all problem blocks, Macaca consistently\noutperformed Saimiri, which in turn consistently performed better than Callithrix.\nRumbaugh Sammons, Prim, & Philips (1965a) tested four Saimiri with extremely\nsimilar procedures. Although Rumbaugh et al. (1965a) presented data on smaller\nproblem blocks (50 vs. 200 problems), through interpolation, we were able to make\nsome direct comparisons. In all cases, the Saimiri of Rumbaugh et al. (1965a) were\nalso intermediate between Macaca and Callithrix. All Callithrix, and the Saimiri from\nRumbaugh et al. (1965a) were greater than 1/2 AFR, allowing this ranking to be\ncounted in the greater than 1/2 AFR analysis.\nprocedure 11. Shell & Riopelle (1958) tested three Ateles, six Cebus, and\nthree Saimiri. Subjects had blocks of six trials per problem, alternated with blocks of\nproblems that were learned to a criterion. On trial 2 of all problem blocks, Ateles\nperformed better than Cebus, which, in turn, consistently performed better than\nSaimiri. Because all subjects were listed as adolescents, this data only counts for\ngreater than 1/5 AFR analysis.\nprocedure 12. Stevens (1965) tested five Macaca, four Cebus, and three\nLemur with six trials per problem after subjects had previously worked in studies of\nreversal and concurrent and successive discrimination learning. Across all problem\nblocks, Macaca and Cebus consistently performed better than Lemur on trials 2-6;\nhowever, Macaca and Cebus did not differ consistently or significantly from each\nother. Because the subjects' ages were not provided, this data only counts towards the\ngreater than 1/5 AFR analysis.\nprocedure 13. Stevens (1965) tested five Macaca, four Cebus, and two Lemur\n(different subjects than in procedure 12) in problems where subjects worked on a\nparticular discrimination until they reached a criterion of eight consecutive correct\nresponses. Subjects had previously worked in studies of reversal and concurrent and\nsuccessive discrimination learning. Across all problem blocks, Macaca consistently\nperformed better than Cebus, which, in turn, consistently performed better than\nLemur. Because the subjects' ages were not provided, this data only counts towards\nthe greater than 1/5 AFR analysis.\nprocedure 14. Manocha (1967) tested four Presbytis and six Macaca with six\nMeta-analysis of Primate Cognition\ntrials per problem. This study was unusual because stones were used as\ndiscrimination objects, and data were presented on performance across all six trials,\nrather than just for trial 2. Across all problem blocks, Presbytis performed better than\nMacaca. All subjects were greater than 1/2 AFR.\nprocedure 15. Rumbaugh & McCormack (1967) tested six Pan, three Pongo,\nseven Gorilla, five Hylobates, and seven Macaca in several conditions. Subjects first\nwere given 500 problems of six trials each; then they were given 25 trial problems\nuntil they scored 20 correct for 10 out of 12 consecutive problems (inter-problem\ncriterion); finally, they were given 50 problems of two trials each. There was very\nlittle variation in the second condition but, in the first and third conditions, there was\nvariation, and rankings were consistent: Macaca, Pan, Gorilla, Pongo, and\nHylobates. When we removed subjects that were less than 1/2 AFR (n = 17), the\nrankings on phase 1 one were Gorilla, Macaca, Pan, Hylobates, Pongo. On phase\ntwo the rankings were Macaca, Pan, Gorilla, Hylobates, and Pongo. Because we\nconsider taxa with inconsistent rankings to be tied, the final ordering for subjects\ngreater than 1/2 AFR was Macaca/Gorilla/Pan (tie), Hylobates, and Pongo.\nprocedure 16. Schrier (1972) tested six Macaca and four Miopithecus in a\nhigher-order type of object discrimination learning set study. Subjects first learned a\nseries of 24 color or form discrimination problems to criterion and then learned 24\nproblems of the opposite type (e.g., if color first then shift to form). The question was\nhow well subjects would do when shifting to a new type of problem (i.e., how much\ntheir previous experience would help them). Macaca and Miopithecus did not differ\nin learning their original of the 24 problems, but Schrier (1972) showed that Macaca\nperformed significantly better than Miopithecus when shifted to the new kind of\nproblem. It might be argued that this difference mainly reflects Macaca's slightly\n(and non-significantly) better performance on the original learning and hence\nadvantage in these particular kinds of discrimination. Nevertheless, Schrier's (1972)\ntable 2 shows that, although both Macaca and Miopithecus were nearly perfect\ndiscriminators on the final day of original learning, Macaca performed far better on\nthe first day of shift learning. Thus, we ranked Macaca below Miopithecus. Because\nthe ages of Miopithecus were not provided, this data only counts for greater than 1/5\nAFR analysis.\nsix Nycticebus, five Lemur, and five Galago with six trials per problem after 32\ntraining problems with 50 trials per problem. Lemur achieved the highest mean trial\ntwo score across all problem blocks, indicating the existence of meaningful\ntaxonomic variation (see also Ohta et al., 1987). Nycticebus achieved the second\nhighest grand mean across all problem blocks, and hence is ranked below Galago. All\nsubjects were greater than 1/2 AFR.\nMeta-analysis of Primate Cognition\nReversal Learning\nThe reversal learning or intra-dimensional shift paradigm investigates the\nability to reverse a previously learned discrimination. Most commonly, over the\ncourse of several trials, a subject learns to make one object discrimination in order to\nget a reward (e.g., picking one object rather than another). Then, without warning, the\nvalues of the objects change so that the previously unrewarded object is rewarded for\na run of trials. As in the discrimination learning set paradigm, reversal learning is\nthought to reflect a subject's ability to form and use abstract rules or \"hypotheses\"\nquestions include \"how quickly do subjects learn to reverse a previously acquired\ndiscrimination?\" and \"does better acquisition learning lead to faster or to slower\nreversal learning?\" The expectation is that if subjects can employ abstract rules, better\nacquisition should lead to better reversal. On the other hand, if subjects are more\nlimited to associative learning, then better acquisition should lead to poorer\nperformance when reward values are reversed. The major advantage of the reversal\nlearning paradigm is that taxonomic comparisons can be made after equating subjects\nfor baseline acquisition learning. In other words, taxonomic differences are unlikely\nto simply reflect artifacts such as one species' predisposition for certain kinds of\nnine Macaca and two Callithrix (both Callithrix participated in procedure 10) on a\nseries of problems consisting of a six, eight, or 10 acquisition trials and eight reversal\ntrials. Direct comparisons could be made for three problem blocks, and in all cases,\non trial 2, Macaca performed better than Callithrix. Because no ages were provided\nfor the Macaca subjects, this data cannot be included in the greater than 1/2 AFR\nanalysis.\nprocedure 19. Crawford (1962) tested three Macaca, three Cebus, and three\nAteles (the same Cebus and Ateles probably participated in procedure 11) in reversal\nlearning with spatial cues. The apparatus allowed four possible object locations, left\nlower, left upper, right lower, and right upper. At the beginning of a problem, for\nexample, the rewarded object would be in left lower, a non-rewarded object would be\nin left upper, and the two right positions would be empty. After three or eight\nconsecutive correct trials, the reward values were reversed for the objects, and the\nobjects also shifted to a new spatial orientation, e.g., right upper rewarded object, left\nupper non-rewarded object, and two lower positions empty. Thus, this was an object\ndiscrimination reversal problem with spatial cues indicating the onset of reversal. We\nranked Ateles first because it had the highest mean score across problem blocks for all\ntrials. Macaca performed better than Cebus on reversal trial 1, but Cebus did better\noverall; hence these taxa were considered tied. Because subjects were described as\nimmatures, this study cannot be included in the greater than 1/2 AFR analysis.\nMeta-analysis of Primate Cognition\n(all subjects had participated in procedure 12 or procedure 13). Each day subjects\nwere given trials on an object discrimination problem until they chose the correct\nobject for 12 consecutive trials or had received 50 trials. After subjects had performed\ncorrectly for 12 consecutive trials on two consecutive days, on the following day, the\nvalues of the objects were reversed. Subjects were given the reversal problem until\nthey had reached the same criterion used in the acquisition phase. On the two error\nscore measures, Macaca performed better than Cebus, which in turn performed better\nthan Lemur. On one of these measures, the \"reversal perseveration score\", Stevens\n(1965) demonstrated the taxonomic variation was statistically significant. Hence, we\nordered the taxa as Macaca, Cebus and Lemur. At least some of the subjects in each\ngenus were apparently less than 1/2 AFR, so this data only counts for greater than 1/5\nAFR analysis.\nprocedure 21. Gossette and colleagues (Gossette & Inman, 1966; Gossette &\nSlonim, 1969; Gossette, 1970) tested three Aotus, four Hylobates, three Saimiri, and\nfour Cebus on a series of spatial reversal problems. Subjects experienced daily\nsessions of 20 discrimination trials where either the left or right object was\nconsistently rewarded. Once a subject had reached the criterion of 18 or more correct\nchoices in a session, the rewarded position was reversed and the subject had sessions\nof 20 trials under this new condition; once the criterion of 18 correct was reached the\nrewarded position was again reversed. Subjects had a total of 20 position reversals\nand Gossette (1970) provided data on the mean error scores for each genus for the\nfirst 20 trials after each reversal. Gossette (1970) showed that there was significant\ntaxonomic variation across the 20 position reversals, and the overall rankings for\ngrand mean error scores were Cebus, Hylobates, Aotus, and Saimiri. Ages were not\nprovided for Cebus and Saimiri, but all Aotus and Hylobates were adults, and hence\ntheir rankings apply to the greater than 1/2 AFR analysis.\nprocedure 22. Rumbaugh & Arnold (1971) tested four Cercopithecus, one\nEulemur, and two Lemur in a reversal task where subjects had to choose between a\ngreen circle and a white circle. For 51 trials one color was rewarded and then, for the\nnext 51 trials, the other color was rewarded; a total of 200 reversals were presented to\neach subject. The authors pooled results for Eulemur and Lemur as \"Lemur\" and this\ngroup did significantly worse than Cercopithecus by several criteria. Most strikingly,\nin cases where \"Lemur\" subjects had achieved a high acquisition score on the last 20\npre-reversal trials, they did very poorly when they had to reverse the discrimination.\nIn contrast, Cercopithecus showed the opposite pattern, performing better on reversal\nafter performing well in acquisition. Although data on Lemur and Eulemur are not\npresented separately, Rumbaugh & Arnold (1971) indicated that there was little\ndifference between them. Hence, we considered Cercopithecus to rank below Lemur\nand Eulemur and consider the latter two genera tied. Subjects were \"late juveniles or\nyoung adults,\" and thus this data is included in the greater than 1/2 AFR analysis.\nMeta-analysis of Primate Cognition\nVisalberghi, 1994) compiled data for 11 genera on series of reversal problems that\ncollectively yield a \"transfer-of-learning\" score. The subject first receives visual\ndiscrimination problems where, for each problem, reversal occurs after the subject\nhas achieved 67% performance on the acquisition trials; the subject then receives 11\nreversal trials. Over a series of problems, the ratio of percentage correct in the\nreversal trials (omitting the first trial) to percentage correct in the acquisition trials\n(approximately 67%) yields a transfer index at 67% (TI-67). This technique is then\nrepeated with an 84% criterion for acquisition trials, and a TI-84 is produced. Finally,\nthe TI-67 value is subtracted from the TI-84 and the remainder is the \"transfer-of-\nlearning\" score. A negative score indicates a subject is better able to reverse a learned\nresponse if the original learning was weak, whereas a positive score indicates a\nsubject can better reverse a learned response if the original learning was strong. Thus,\na positive \"transfer-of-learning\" score can be taken as evidence that the subject relies\nmore on an abstract rule about the potential relationships between elements, rather\nthan simply associating their outcomes. Although variances are not available of\n\"transfer-of-learning\" scores, the ranges for various genera on the TI-67 and TI-84\nare provided in Rumbaugh & Pate (1984), and indicate that some taxa do not overlap\nothers at all. Hence, it can be assumed that there is substantial variation. We ranked\ngenera according to the mean scores presented in Rumbaugh (1997), except that we\ncombined the scores for all Pan (including language-trained subjects) and excluded\nSaimiri because the five subjects tested were the best performers in a colony of 40\n(Rumbaugh & Pate, 1984; Rumbaugh, pers. comm.). The rankings were Pan/Gorilla\n(tied), Pongo, Macaca, Cercopithecus, Cebus/Hylobates (tied), Lemur, Phaner,\nMicrocebus, Miopithecus. Because some subjects in Rumbaugh's compilation were\njuveniles (Rumbaugh, pers. comm.), this data only counts towards the greater than\nOddity Learning\nThe oddity learning paradigm addresses the ability to use a relational or\nabstract concept. Most commonly, a subject is simultaneously provided with three\nvisual stimuli, two of which are identical, and one that differs; the subject is rewarded\nfor choosing the differing or odd stimulus. One difficulty is that with several of the\nprocedures that have been employed, subjects could succeed in the task without using\na true oddity concept. For instance, for various reasons, investigators frequently\nomitted stimulus configurations where the middle object was odd; thus, subjects\ncould have succeeded using the rule, \"pick the end stimulus that differs from the\nmiddle stimulus\" (King & Fobes, 1982). Although the fact that some procedures may\nnot necessarily reveal the use of an oddity concept is of interest (e.g., Thomas &\nNoble, 1988), this issue is not crucial for the present comparisons, provided the\nsubject must use some other type of conceptual strategy or, at the very least, must\nemploy learning sets. In the procedure previously mentioned, for example, subjects\nMeta-analysis of Primate Cognition\nwould at least have to use some kind of same-different concept. Hence, we included\nnearly all procedures that allow taxonomic comparisons. The only exception is that\nwe did not consider studies that use the same few stimulus configurations throughout\nthe entire study (i.e., one-odd, two-odd procedures: Bromer, 1940; Vatsuro &\nKashkay, 1965) because it is known that in such studies subjects may memorize the\nrewards associated with different configurations. Hence, the entire study may only\nrequire learning a handful of pattern discriminations (King & Fobes, 1982) and so\nmay not provide a discriminating cognitive task.\nprocedure 24. Strong & Hedges (1966) tested three Pan and three Macaca on\nproblems where the odd stimulus never appeared in the middle position. Nine wood\nobjects were used in 72 different configurations to test a subject until they scored\n90% within a session of 48 trials. Pan reached criterion in significantly fewer\nsessions than Macaca. Because subjects were not greater than 1/2 AFR, this study\nonly applies to greater than 1/5 AFR analyses.\nnine Cebus, eight Saimiri, four Lagothrix, two Cercopithecus, and four Lemur on\nproblems where the odd stimulus never appeared in the middle position. (Most\nsubjects probably also participated in procedure 3.) Each problem included 12\nshaping or training trials and 12 test trials, all based on four related stimulus\nconfigurations. After pooling the data from the three Macaca species, we used\nANCOVA to confirm that across the 15 eight-problem blocks, there was significant\nmean score for each genus and obtained the following ranks: Lagothrix, Cebus,\nMacaca, Saimiri, Lemur, Cercopithecus. The data were not presented in a manner\nthat allowed subjects that were more than 1/5 AFR to be distinguished from those that\nwere more than 1/2 AFR; hence, this data only counts towards the greater than 1/5\nAFR analyses.\nprocedure 26. Thomas & Boyd (1973) tested Saimiri and Cebus on three\ntypes of oddity problems. First, four subjects of each genus were given a series of five\ntrial problems where each problem presented the same stimulus configuration for all\ntrials. Second, four of these subjects (two per genus) were given a similar series of\nfive trial problems, but on trials two to four, the configuration was altered so that the\nstimulus that had been odd became common. Finally, four of the subjects were given\none-trial oddity problems. Although all subjects performed fairly well, Cebus\nperformed better than Saimiri on all three types of problems and hence was ranked\nlower. All subjects were greater than 1/2 AFR.\nSorting\nThe sorting paradigm examines the ability to form abstract concepts and to\nuse them to categorize stimuli accordingly. Numerous approaches have been used to\ninvestigate sorting in primates (reviewed in Tomasello & Call, 1997), but apparently\nMeta-analysis of Primate Cognition\nonly one study has employed formal training (i.e., providing rewards) to investigate\nmultiple genera.\nprocedure 27. Garcha & Ettlinger (1979) tested five Pan, six Macaca, and\nthree Cebus in a task wherein subjects were presented with three exemplars of three\ndifferent kinds of objects (nine objects total) and three jars. To be rewarded, subjects\nhad to place the similar objects in the same jar. Pan can be ranked first in this\nprocedure, because four of five Pan subjects but none of the others performed above\nCebus and one Macaca performed above chance. Thus, although Cebus performed\nslightly better than Macaca, this does not meet our criterion of a meaningful\ndifference and so these taxa were considered tied. Because it is unclear whether any\nof the Cebus or Macaca subjects were greater than 1/2 AFR, this test only counts for\ngreater than 1/5 AFR analyses.\nDelayed Response\nThe delayed response paradigm investigates a subject's memory or ability to\nmaintain a representation of an item when it is no longer available to immediate\nperception. In most studies, the subject observes a reward being hidden in one of two\nspatial locations, there is a delay, and then the subject is allowed to search one of the\nlocations. The questions of interest are \"for any given time interval, what percentage\nof first searches are correct?\" and \"what is the maximum delay at which a subject can\nstill score above chance?\" Since its introduction by Hunter (1913), many\ninvestigators have questioned the validity of the paradigm on the grounds that\nexperimental procedures, contextual variables, and previous experience can\ndramatically alter a subject's maximum delay (e.g., Maier & Schneirla, 1935; Fobes\ncomparisons to subjects with similar experience, operating in the same conditions,\nFletcher (1965) provides an excellent review of the delayed response paradigm and\nthe variables known to affect performance.\nprocedure 28. Tinklepaugh (1932) tested two Macaca and two Pan subjects in\ntests of multiple delayed response. In one variation, subjects were led into a series of\nrooms and in each room they witnessed a reward being hidden in one of two similar\ncontainers; after a delay, they were allowed to revisit the rooms and search one of\ncontainers in each room. A second variation of the study was conducted entirely in\none room; the subject witnessed a series of paired containers being baited (one of the\ntwo containers with reward); after a delay, they were allowed to search one of the\ncontainers in each paired set. In both variations, Pan generally showed such greater\nproficiency in pre-training that they were given more difficult tests. Despite the\ngreater difficulty, however, they invariably performed better than Macaca. For\ninstance, in the first version of the study, Pan obtained a mean score of 90% when\nMeta-analysis of Primate Cognition\ntested with 10 rooms whereas Macaca scored 80% when being tested with only five\nrooms. A direct comparison could be made in the case where both genera witnessed\neight pairs of containers being baited in the same room. Macaca achieved a mean\nscore of 61% whereas Pan scored 87%. Hence, Pan was ranked below Macaca. All\nsubjects were greater than 1/2 AFR.\ndata on delayed response for one Pongo, one Pan, one Gorilla, one Hylobates, six\nPapio, five Mandrillus, nine Macaca, three Cercopithecus, one Cercocebus, five\nCebus, one Lagothrix, and one Varecia. (Several of these subjects also participated in\nseconds; once they had demonstrated proficiency on one delay, they began receiving\nproblems with the next longest delay. Subjects typically received 60 to 200 problems\nwith each delay, but if they demonstrated exceptional performance, they were\nsometimes advanced to the next delay after fewer problems. We first computed mean\nscores for each genus at each interval, although we omitted two scores that were\nbased on only one or two trials. Calculating mean scores for genera with multiple\nsubjects was complicated by the fact that subjects that performed poorly on one\ninterval were usually not tested on longer intervals. This could have biased scoring\ntowards better-represented genera, as their scores on longer intervals would be based\non their best subjects. We avoided this problem by assuming that if a subject had\nperformed below chance on one interval (as determined with chi-square tests; Deaner\nunpublished), they could be assigned a score of 50% (chance) on longer intervals. We\nwere thus able to calculate a meaningful mean score for each genus at each interval.\nIn using these scores for rankings, we looked for evidence that a taxon performed\nconsistently better or worse than others across all intervals or at least across relatively\nlong intervals. Because Pongo was the best performer at each interval and Papio was\nconsistently second best, we ranked these genera first and second, respectively. The\nremaining genera were more difficult to rank, because they sometimes reversed ranks\naccording to the time delay. Hence, we considered the longest interval at which the\ngeneric mean was above chance. This was 120 seconds for Pan, Macaca, Mandrillus,\nHylobates, and Cercopithecus, 30 seconds for Gorilla and Cercocebus, and 15\nseconds for Lagothrix, Cebus, and Varecia. Pan, Gorilla, and two of the Mandrillus\nsubjects were less than 1/2 AFR. Using the same logic as above, we reconsidered the\ndata without these younger subjects and obtained the following rankings: Pongo,\nPapio, Mandrillus, Hylobates/ Macaca/ Cercopithecus (tied), Cercocebus/ Varecia/\nLagothrix/ Cebus (tied).\nprocedure 30. Miles (1957b) tested three Callithrix and three Macaca. After\nproblems where randomly occurring delays were one, two, four, or 16 seconds.\nMacaca performed consistently better than Callithrix at all comparable delays.\nFischer & Kitchener (1965) conducted a very similar study with two Pongo and two\nGorilla (subjects participated in procedure 4) although in this case, delays of 32 and\nMeta-analysis of Primate Cognition\n64 seconds were also interspersed with the shorter delays. (This modification could\ndepress performance on shorter delays: see Fletcher, 1965.) When comparisons are\nrestricted to comparable delays where subject have comparable experience (see\nFischer & Kitchener's figure 3), Pongo performed consistently better than all other\ntaxa and Callithrix consistently performed the worst. The grand mean for Gorilla was\nhigher than for Macaca, suggesting that Gorilla should be ranked lower, but, because\nMacaca actually performed slightly better on the longest comparable delay (arguably\nthe most crucial measure), we considered Gorilla and Macaca tied. Because none of\nthe subjects in these studies were greater than 1/2 AFR, this test only counts for\ngreater than 1/5 AFR analysis.\nStatistical methods\nFactor analysis has proven useful in characterizing the abilities underlying\nhuman performance in IQ and related testing batteries (reviewed by Child, 1970;\nMackintosh, 1998). Although the structure of the present data set is somewhat\nsimilar, we did not use factor analysis because there were numerous missing values in\nthe data matrix, and because we wished to avoid the assumption of a linear effect\nunderlying trait variables between paradigms (Bartholomew, 1987).\nInstead, we employed a Bayesian latent variable model of multi-study rank\ndata, which was designed to assess whether there is a global variable that explains\ntaxonomic variation in rankings across paradigms and procedures (Johnson et al.,\n2002; for a potential non-Bayesian approach to analyzing this data, see Yu, Lam, &\nLo, 2005). The model is based on the assumption of a latent ability ij\nsatisfying\nij\n= i\n+ i,g(j)\n+ ij\n,\nwhere ij\ndenotes a latent variable representing the perceived performance of\nthe ith genus in the jth procedure. The variable ij\nis related to the observed ranking of\nthe procedure by making the assumption that Yij\n, the rank of the ith genus in the jth\nprocedure, is greater than Ykj\n, the rank of the kth genus in the jth procedure, only when\nZij\n> Zkj\n. The variable i\ndenotes the global variable of the ith genus and estimates its\ngeneral cognitive ability. Paradigm-genus biases are denoted by i,g(j)\nand represent\nbias of the jth procedure in the gth paradigm for showing the ability of the ith genus.\nRandom errors associated with the observation of  in the jth procedure are\nrepresented by ij\n.\nThe model assumes, therefore, that any given ranking derives from two\nunderlying, continuous latent variables: a global variable for the cognitive ability of\nthe genus and a paradigm-genus bias effect which represents variations in the\nobserved rankings due to the genus-paradigm interaction. More simply, the global\nvariable for each genus represents its overall score across all procedures and\nparadigms (i.e., corresponding to domain-general ability), whereas the paradigm-\ngenus bias effect indicates the extent to which a genus performs better or worse on\nMeta-analysis of Primate Cognition\none paradigm compared to other paradigms (domain-specific abilities). Significant\nparadigm-genus bias effects indicate that the assumption of a uni-dimensional global\nvariable is violated. Likewise, the greater the proportion of variation explained by the\nparadigm-genus bias effects, the smaller the proportion of variation potentially\nexplained by the global variable. We have previously demonstrated that this model is\ncapable of detecting paradigm-genus bias effects (Johnson et al., 2002).\nIn order to establish a scale of measurement for the global variables, these\nvariables are assumed a priori to have a standard normal distribution. Similarly, the\nparadigm-genus bias effects are assumed to have a mean zero normal distribution,\nand both the procedure variance (i.e., error) parameters and the paradigm-genus\nvariance parameters are assumed drawn from a common inverse-gamma distribution.\nFurther details concerning this hierarchical specification are provided in Johnson et\nTwo additional points deserve mention here. First, the model considers tied\nrankings to be indicative of similarity in underlying parameters, i\nand i,g(j)\n, rather\nthan indicative of insensitive tests. This assumption is warranted because we only\nincluded procedures in the meta-analysis that yielded clear rank differences among at\nleast some genera. Thus, these procedures can be considered sensitive enough to\npermit the conclusion that tied rankings reflected similar abilities, rather than poor\ntests. Second, the probabilities of the model parameters can be readily assessed using\nMarkov chain Monte Carlo methods. This allowed us to determine the probability\nthat genera differed from each other in their estimated global variables and to assess\nwhether paradigm-genus bias effects were significantly different from zero.\nTo examine differences between taxonomic groupings above the genus (see\nabove for taxonomic groupings), we also examined the probability that the mean of\neach taxonomic grouping's global variable differed from the global variable of each\nof the other taxonomic groupings. To compute these probabilities, we compared the\nsample means of the global variables for each taxonomic grouping using 1,000,000\nsimulated values of each genus's global variables obtained from the Markov chain\nMonte Carlo algorithm that was used to sample from the posterior distribution over\nthese variables. In other words, we estimated the probability that the mean value of\nthe global variable for the great apes (Pongo, Pan, and Gorilla) was less than the\nmean value of global variable for the lesser apes (Hylobates), and so on for all other\ncomparisons among all groupings.\nResults\nGeneral patterns\nNone of the posterior means of the paradigm-genus bias effects were found to\nbe statistically significant, meaning there was no indication of domain-specific\nabilities. In fact, the posterior mean of the paradigm-genus bias precision parameters\nMeta-analysis of Primate Cognition\nwas approximately seven times larger than the posterior mean of the procedure-\nprecision (error) parameters, suggesting that the paradigm genus-bias effects\naccounted for less than 1/7 of the variation attributable to the procedural variation\n(see Johnson et al., 2002). Only two of the paradigm-genus bias effects, both in the\nobject discrimination learning sets paradigm, exceeded 0.5, but neither of these could\nbe reliably distinguished as being either positive or negative (see Johnson et al.\n[2002] for details). The first paradigm-genus bias effect refers to Presbytis's\nperformance in procedure 14; because Presbytis is not represented in any of the other\nprocedures, its performance cannot meaningfully be attributed to a paradigm-genus\nbias effect. Second, in procedure 15, Macaca outperformed the three great apes,\nGorilla, Pan, and Pongo, which was unexpected based on its performance in the rest\nof the data set. In this case, the paradigm-genus bias effect did not reach significance\nbecause Macaca's strong performance in other procedures within this paradigm was\nachieved primarily against taxa that it also outperformed in other paradigms. These\nexamples illustrate the general pattern that, although there were some outlying\nprocedures in this data set, they were not concentrated in particular paradigms.\nHence, because paradigm-genus bias effects were unimportant, we fit a reduced\nmodel without these effects.\nThe global variables for the genera in the reduced model varied substantially,\nas they did in the full model (figure 1). In fact, pair-wise comparisons indicated that,\nin several cases, genera differed significantly (figure 2). Although Bayesian models,\nsuch as the one we employed, do not readily lend themselves to inferences regarding\nthe amount of variation explained (but see Menard, 2000), a simple way to investigate\nthe power of the hypothesized global variables is to ask how often they correctly\npredict rankings in the data set. It turns out that out of 229 genus-by-genus\ncomparisons, 194 (84.7%) were predicted correctly with the reduced model. The\ncomplete model (i.e., incorporating estimates of paradigm-genus bias effects) also\npredicts 194 of the 229 comparisons (table 2). Hence, the hypothesis of differing\ndomain-general cognitive abilities, estimated by a uni-dimensional global variable, is\nstrongly supported.\nVisual inspection of figures 1 and 2 suggests a pattern of taxonomic variation,\nwith the great apes performing better than the other taxonomic groupings. When we\nexplored this possibility more formally with simulations, we found that great apes did\nindeed have significantly lower global variable means than any other taxonomic\ngrouping (table 3), indicating that they were generally the best performers. Among\nthe other comparisons, the only other significant difference was that Old World\nmonkeys had lower global variable means than did prosimians, although New World\nmonkeys tended to outperform prosimians as well. Although these results imply, for\nexample, that the \"average Old World monkey\" outperforms the \"average\nprosimian\", our data set did not include information on all genera in these groupings\nand thus these results should be viewed cautiously.\nMeta-analysis of Primate Cognition\nFigure 1: Global variable means for each genus as estimated with four variations of a\nhierarchical Bayesian model: (A) all data, with paradigm-genus bias effects; (B) all\ndata, reduced model; (C) restricted to subjects >1/2 AFR, with paradigm-genus bias\neffects; (D) restricted so subjects only used once, with paradigm-genus bias effects;\nIndeed, there is a trend in the Old World and New World monkeys for\nsmaller-bodied (and usually smaller-brained) genera to perform poorly, and thus the\noverall poor performance of the prosimian group could be due to the fact that there\nwas no information available on the relatively large-bodied genera, Daubentonia,\nPropithecus, and Indri. Likewise, it is worth emphasizing that some genera\nMeta-analysis of Primate Cognition\nFigure 2: Genus global variable means and matrix showing probability of genera\ndiffering from others. Based on reduced model with all data. For global variables, ,\nlower scores indicate better performance. For the probability matrix, black boxes\nindicate genera differ at p < 0.025; dark-gray boxes indicate genera differ at p < 0.05;\nlight-gray boxes indicate that genera differ at p < 0.10; unmarked boxes indicate that\ndifferences are not significant at p < 0.10.\nperformed markedly better (Ateles) or worse (Callithrix, Miopithecus) than others in\ntheir taxonomic grouping. Another reason these taxonomic comparisons should be\nviewed cautiously is that the large number of comparisons (10) inflates the type 1\nerror rate. If the conventional  of 0.05 is adjusted to 0.005, the Old World monkeys\nand prosimians no longer differ significantly, although great apes remain distinct\nfrom every other taxonomic group.\nMeta-analysis of Primate Cognition\nTests of robustness\nOne reason that paradigm-genus bias effects might not have been detected is\nthat bias effects may span several paradigms and were masked because the paradigms\nwere treated separately, rather than grouped according to underlying task demands.\nFor instance, if a genus performed extremely well in five theoretically similar\nparadigms but performed rather poorly in the other four paradigms, it would be\nunlikely that the model would detect any paradigm-genus bias effects because effects\nin each paradigm would be assessed relative to the eight other paradigms, three or\nfour of which would exhibit similar rankings.\nThe simplest way to explore the possibility of masking is to group paradigms\ninto \"superparadigms\" based on a priori similarity. Tomasello & Call's (1997)\nreview of primate cognition suggests the following superparadigms: (1) space and\nobjects: detour problems, patterned-string problems, and invisible displacement; (2)\nfeatures and categories: object discrimination learning sets, reversal learning, oddity\nlearning, sorting, and delayed response; (3) discrimination learning: object\ndiscrimination learning sets, reversal learning, and oddity learning; and, finally, (4)\nlearning sets: object discrimination learning sets and reversal learning. Hence, we\nrepeated our analyses four times, testing for different superparadigm-genus bias\neffects in each case. In other words, in the first replication, all procedures in detour\nproblems, patterned-string problems, and invisible displacement were grouped as the\nspace and objects paradigm, and all other procedures remained assigned to their\noriginal paradigms. However, contrary to the idea of underlying superparadigms, we\nfound no significant superparadigm-genus bias effects in any of these analyses.\nFurthermore, the explanatory power of these superparadigm models was nearly\nidentical to that obtained with the reduced model (table 2) and the global variables of\nthe genera were nearly identical.\nAnother reason that we might not have detected paradigm-genus bias effects\nis that our analysis included all subjects greater than 1/5 AFR, and it is conceivable\nthat such a broad age range somehow obscured the effects. Hence, we repeated our\nanalysis using the data restricted to subjects greater than 1/2 AFR. In this analysis, we\nagain found that global trait values often differed significantly and no evidence for\nsignificant paradigm-genus effects. Although the explanatory power of this greater\nthan 1/2 AFR model was slightly less than that of the reduced model based on all\ndata, it was still quite high (table 2). More notable is the fact that the global variables\nof the genera are substantially more compressed than in the other analyses (figure 1).\nThis, however, is attributable to the fact that there was little data in this\nanalysis and, under the Bayesian model used here, all genera begin with global\nmeasures of zero and only become differentiated as rankings are incorporated.\nBecause of the limited data, the ordering of the global variables is also somewhat\ndifferent than in other models (figure 1), although Pongo and Pan remain the best\nperformers.\nMeta-analysis of Primate Cognition\nTable 2: Comparison of the predictive ability of 8 variations of a hierarchical\nBayesian model.\nModel\nNumber of\nprocedures\nincluded\nNumber of dyadic\ncomparisons\n% comparisons\npredicted correctly\nAll data, with paradigm-genus bias\neffects\nAll data, with superparadigm 1\u00ad\ngenus bias effects\nAll data, with superparadigm 2\u00ad\ngenus bias effects\nAll data, with superparadigm 3\u00ad\ngenus bias effects\nAll data, with superparadigm 4\u00ad\ngenus bias effects\nRestricted to subjects >1/2 AFR,\nwith paradigm-genus bias effects\nRestricted so subjects only appear\nonce, with paradigm-genus bias\neffects\nTable 3: Pair-wise comparisons of the mean global variables for taxonomic\ngroupings. Entries denote the probability that the row grouping had a higher mean\nglobal variable (i.e. performed worse in the procedures) than the column grouping.\nResults are based on the full data set, reduced model.\nGreat\napes\nLesser\napes\nOld World\nmonkeys\nNew World\nmonkeys\nProsimians\nOld World\nmonkeys\nNew World\nmonkeys\nMeta-analysis of Primate Cognition\nA third potential problem with our analysis is that several individuals are\nrepresented twice in the data set. Thus, what we have interpreted as consistent\ntaxonomic differences might instead reflect consistent differences among individuals\nthat happen to belong to different genera. Of course, these interpretations are not\nmutually exclusive (i.e., consistent individual differences are likely to be at least\npartially due to taxonomic effects). The crucial question is whether taxonomic\ndifferences remain once the data set is restricted such that each subject may\ncontribute to it only once. Hence, we repeated the initial analysis after omitting\nprocedures and thus any potential \"double counting\". In deciding which procedures to\nomit when two employed the same subjects, we retained the one that included more\ngenera; in cases where both procedures included the same number of genera, we\nretained the one that came first in chronological order. Thus, we omitted procedures\nno significant paradigm-genus bias effects, several significantly differing global\nvariables, and explanatory power and global variable orderings that were extremely\nsimilar to those of the reduced model based on all data (table 2, figure 1). Thus, the\ntaxonomic differences in our analysis are not merely the product of a few exceptional\nsubjects.\nDiscussion\nThis study's primary finding is that some primate taxa performed consistently\nbetter than others across a wide range of cognitive paradigms. In contrast, there was\nno evidence that some taxa performed especially well in particular paradigms.\nFurthermore, these results proved robust when paradigms were grouped into various\nsuperparadigms and when the potential effect of pseudo-replication of individuals\nwas eliminated. The possibly confounding effect of age was examined by excluding\nsmall juveniles (between 1/5 and 1/2 AFR), and this result differed most clearly from\nthe others (figure 1). Importantly, however, paradigm-genus bias effects remained\nsmall and insignificant, suggesting that the poor differentiation among the genera was\ndue to the small size of the remaining sample, rather than to the presence of\nspecialized abilities.\nTaken together, these results imply the existence of taxonomic differences in\nsome sort of domain-general cognitive ability. It is important to stress, however, that\ndifferences in a domain-general ability are fully compatible with the existence of\nother differing abilities, including domain-specific ones. In fact, it is probable that as\nmore data accumulate, including on additional paradigms, future studies will detect\nparadigm-genus bias effects and other higher dimensional factors. Nonetheless,\nbecause the factor identified here already predicts approximately 85% of the\nrankings, it is likely to re-emerge as the primary factor in future studies, at least in\nprimates.\nMeta-analysis of Primate Cognition\nObjections\nComparative learning reviews commonly argue that claims of taxonomic\ndifferences are weak because within species variation often exceeds between species\nvariation so that individuals of \"low-achieving\" taxa sometimes outperform those of\n\"high-achieving\" taxa (e.g., Ehrlich et al., 1976; MacPhail, 1982; Essock-Vitale &\nSeyfarth, 1987; Tomasello & Call, 1997). Nonetheless, the apparent absence of the\npredicted taxonomic variation could have several causes besides the absence of\nunderlying cognitive differences. First, upon close inspection of the evidence, it is\nclear that some claims of taxonomic overlap are misleading. For example, Tomasello\nmacaco) perform better than or equal to most monkeys and apes in object\ndiscrimination learning sets. However, the lemurs generally had between five and\nfifteen times more trials per problem than did subjects in other studies, a difference\nthat should have dramatically improved their performance (Levine, Levinson, &\nHarlow, 1959). Second, because tests directly measure performance, not intrinsic\nabilities, contextual confounds can obscure true differences. In procedure 15, where\nseveral apes performed poorly, the relevant objects were encased in plexi-glass bins,\na situation which was later shown to be highly distracting for some species\nThe final, and most important, reason that taxonomic overlap does not weaken our\nclaim of taxonomic differences is that evolutionary theory fully expects that\ndevelopmental and genetic differences will produce substantial phenotypic variation.\nAlthough this variation is worth emphasizing, it is fully compatible with the\nsignificant overall taxonomic differences we demonstrated.\nThe second issue alluded to in the previous paragraph\u00adthe maxim that\ndifferences in performance do not automatically indicate differences in ability\u00ad\ndeserves further attention. As noted in the Introduction, the meta-analysis approach\nshould generally resolve the performance-ability conundrum because, if consistent\ndifferences are found across varying situations, it is unlikely that the difference\nmerely reflects an unconsidered variable that biases testing towards particular taxa\n(Kamil, 1988). Nevertheless, it is conceivable that, although the paradigms in the data\nset involve a variety of testing contexts and materials, they might share some\nunderlying bias that allows certain taxa (e.g., great apes) to do better than others.\nThere are two likely candidates: manual skill and visual ability.\nManual skill of some kind is required for almost all of the testing procedures,\nand there is a strong relationship between overall global indices and manual skill\n(Deaner, unpublished; van Schaik et al., 1999). Nevertheless, in most of the\nprocedures, differences in manual skill per se cannot explain performance differences\n(but see Beck, 1967). For instance, in object discrimination learning sets, reversal\nlearning, oddity learning, and delayed response paradigms, animals must choose\nwhich food well to uncover. In preliminary trials, virtually all subjects master this\nMeta-analysis of Primate Cognition\ntask; pronounced differences emerge only after the manipulation of certain variables\n(e.g., length of delay) unrelated to reward recovery.\nVisual ability is also required in all of the tests, and it could be argued, for\ninstance, that prosimians performed poorly because of their relatively low acuity\nargument is sensible for prosimians in detour problems and patterned-string problems\nbut does not accommodate results in other paradigms where baseline levels of\nperformance must be demonstrated initially, such as object discrimination learning\nsets, reversal learning, oddity learning, and delayed response. Furthermore,\ndifferences in visual ability cannot readily explain the differing performances of great\napes and monkeys. Most relevantly, Macaca, although performing worse than the\ngreat apes in most procedures, is thought to possess visual capabilities that are\nvirtually identical to those of great apes and humans (Berkley, 1976; Jacobs, 1995).\nAlthough visual processing requirements cannot account for most taxonomic\ndifferences, the ubiquity of visual requirements is potentially relevant to the\ninterpretation of these differences. In particular, it could be argued that rather than\nimplying differences in some kind of \"domain-general\" cognition, this study's results\nonly indicate differences in general cognition in the visual domain. At present, there\nsimply is no relevant data to test this interpretation (e.g., whether prosimians perform\nbetter than anthropoids in learning set problems if olfactory rather than visual stimuli\nare employed). Nonetheless, even if it turns out that the differences we identified are\nrestricted to the visual problems, these differences would still be very important, as\nvision is the dominant sensory modality for most primates (Martin, 1990; Allman,\nSimilarly, none of the paradigms in our data set involve social problems, and\nit is possible that the taxonomic differences we have detected will not hold in this\nTooby & Cosmides, 1992). Although there is little data available to address this\nquestion, recent experimental work suggests that the differences might hold.\nChimpanzees, mangabeys, and ringtailed lemurs have all been tested in versions of\nMenzel's (1973) deception paradigm, and the sophistication of performance in this\nsituation corresponds with the results of the present study (Menzel, 1973; Coussi-\nDeaner, 2002). Similarly, chimpanzees have been shown to take the visual\nperspective of conspecifics in a competitive foraging paradigm, whereas capuchin\nmonkeys failed to show this ability (Hare, Call, Agnetta, & Tomasello, 2000; Hare,\nAdessi, Call, Tomasello, & Visalberghi, 2003; for a similar conclusion based on a\ndifferent task, see Povinelli, Nelson, & Boysen, 1992; Povinelli, Parks, & Novak,\nMeta-analysis of Primate Cognition\nImplications\nThe fact that some genera perform better than others across a range of\nparadigms challenges current thinking that taxonomic difference in cognitive abilities\nare manifest only in specific contexts (e.g., Tooby & Cosmides, 1992; Shettleworth,\n1998; Gallistel, 2000). Nevertheless, our results actually provide little insight into the\nnature of the underlying cognitive ability (or abilities) that produce these performance\ndifferences. Indeed, the contentious field of human intelligence testing demonstrates\nall too clearly that the meaning of a primary statistical factor, g, is open to numerous\nThe number of potential explanations is perhaps even greater for the\ncomparative primate data because cross-species studies raise unique issues. For\ninstance, rather than accepting that the results found here reflect taxonomic\ndifferences in a single mechanism (or group of inter-related mechanisms), one might\nargue that taxa perform well across paradigms because they do in fact have distinct,\nrestricted abilities, but happen to possess these for most or all of the paradigms in the\ndata set. The extreme form of this argument \u00adthat each paradigm involves a distinct\nability\u00ad seems unlikely, but it is quite plausible that there might be a few abilities,\neach of which supports excellent performance in a few related paradigms. In this\nview, the reason that we did not detect superior performance in particular paradigms\nor superparadigms is that the same taxa that possess a cognitive ability that allows\nthem to excel in one paradigm also tend to possess another cognitive ability that\nallows them to excel in other paradigms; hence performance is uniformly excellent.\nAlthough this scenario requires that distinct cognitive abilities have generally\nundergone correlated evolution, there are theoretical reasons to think that this could\nbe true (Deaner, Nunn, & van Schaik, 2000; van Schaik & Deaner, 2003). To test this\npossibility, data could be gathered on within species variation across tasks; if the\nsame individuals do well across all tasks, it would support the notion of a primary\ndomain-general ability (see Crinella & Yu, 1995; Anderson, 2000). Alternatively, if\nindividuals were shown to have particular domains of expertise, this would be more\nconsistent with the notion of distinct abilities with distinct mechanistic bases.\nAlthough our result fits with the intuitive, traditional idea that some taxa,\nespecially great apes, are \"more intelligent\" than others, our results do not suggest\nthat we should re-embrace the outdated notion of a scala naturae, wherein species\ncan be viewed as evolving in a pre-ordained progression, ultimately leading to\nhumans (Hodos & Campbell, 1969). Instead, they suggest that under some\nconditions, there can be selection for fairly generalized cognitive abilities (Balda,\nEmery & Clayton, 2004) or else a suite of independent but consistently co-evolving\nones. Although this type of cognitive evolution may have occurred more frequently\nin some radiations than in others (i.e., those with slow life history: Deaner, Barton, &\nvan Schaik, 2002; van Schaik & Deaner, 2003), there are no compelling theoretical\nMeta-analysis of Primate Cognition\nreasons to assume that domain-general cognition is restricted to primates or even\nIf taxa do indeed differ in domain-general cognitive abilities, then this could\nhelp explain the distribution of spontaneously occurring complex behavior. Thus, in\nprimates, the great apes, the best performers across the cognitive paradigms, show\nrelatively high rates of deception, highly complex manipulation, population-wide tool\nuse in the wild, and robust mirror self-recognition (Byrne & Whiten, 1992; Tomasello\nNakamura, 1997). By contrast, prosimians, which had the overall lowest scores,\nexhibit little manual dexterity and no tool use, deception, or mirror self-recognition\n(ibid). Future studies will be necessary to determine the robustness of these\ntaxonomic differences and to test if the global variables also explain variation within\ngreat apes, monkeys, and prosimians.\nFinally, the global variables generated in this paper should be useful for\ntesting the assumptions of comparative neuroanatomical investigations. Such\ninvestigations generally take for granted that a relative measure of the size of the\nbrain or of a brain structure corresponds with some overall level of information\nprocessing capacity or \"intelligence\" (Deaner et al., 2000; van Schaik & Deaner,\n2003). Researchers can now test which, if any, neuroanatomical measures correspond\nto an objective standard, namely the global variables generated in this study.\n"
}