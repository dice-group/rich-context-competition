{
    "abstract": "Abstract\nThis article explores the ways in which data centre operators are currently reconfiguring the systems of energy and heat\nsupply in European capitals, replacing conventional forms of heating with data-driven heat production, and becoming\nimportant energy suppliers. Taking as an empirical object the heat generated from server halls, the article traces the\nexpanding phenomenon of `waste heat recycling' and charts the ways in which data centre operators in Stockholm and\nParis direct waste heat through metropolitan district heating systems and urban homes, and valorise it. Drawing on new\nmaterialisms, infrastructure studies and classical theory of production and destruction of value in capitalism, the article\noutlines two modes in which this process happens, namely infrastructural convergence and decentralisation of the data\ncentre. These modes arguably help data centre operators convert big data from a source of value online into a raw\nmaterial that needs to flow in the network irrespective of meaning. In this conversion process, the article argues, a new\ncommodity is in a process of formation, that of computation traffic. Altogether data-driven heat production is suggested\nto raise the importance of certain data processing nodes in Northern Europe, simultaneously intervening in the global\npolitics of access, while neutralising external criticism towards big data by making urban life literally dependent on power\nfrom data streams.\n",
    "reduced_content": "Original Research Article\nData that warms: Waste heat,\ninfrastructural convergence and the\ncomputation traffic commodity\nJulia Velkova\n Keywords\nWaste heat, data heat recycling, data furnace, computation traffic, big data, server cooling\nIntroduction\nIn 2011, a team of researchers at Microsoft published a\npaper in which they argued for the need to decentralise\ndata centres and place servers in private living spaces as\na way to offset problems with managing the heat that\nthreatens server halls with disruptions (Liu et al., 2011).\nThey called the system `data furnaces'. The data fur-\nnace represents a high performance server designed to\nlook like a heater which disperses the heat emitted in\nthe process of networked computation into private\nliving and office spaces. It is supposed to reduce the\ncost of waste heat management for the data centre by\nconverting server heat into a new commodity to be sold\nto internet users. Internet users would also host the\nservers of the data centre in their private space and\npay for doing so. The paper concludes that such a solu-\ntion is environmentally friendly as it reduces the carbon\nfootprint of the data industry and brings more profit to\nthe data centre by eliminating the need to acquire land,\npay for electricity and invest in cooling systems.\nAt the time when the paper was published, a mod-\nified version of this idea had already been implemented\nin the Finnish capital, Helsinki. In a Cold War bunker\nlocated under a cathedral near the city centre, the IT\ncompany Academica built a data centre and connected\nit to the pipes of the local district heating system,\nrerouting the waste heat from the servers to heat the\nSo\n\u00a8derto\n\u00a8rn University, Sweden\nCorresponding author:\nJulia Velkova, Department of Media and Communication Studies,\nSo\n\u00a8derto\nEmail: julia.velkova@sh.se\nBig Data & Society\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\njournals.sagepub.com/home/bds\nCreative Commons NonCommercial-NoDerivs CC-BY-NC-ND: This article is distributed under the terms of the Creative Com-\nmons Attribution-NonCommercial-NoDerivs 3.0 License (http://www.creativecommons.org/licenses/by-nc-nd/3.0/) which permits\nnon-commercial use, reproduction and distribution of the work as published without adaptation or alteration, without further permission provided the\noriginal work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).\nSince then, similar solutions have been rapidly emer-\nging in a number of European cities. Besides Helsinki,\nStockholm, Paris and London have been at the fore-\nfront of pushing corporate imaginaries of a new role\nfor data centres, as energy providers and important\nglobal data processing hubs. TelecityGroup in Paris\nhas been rerouting its waste heat into an arboretum to\ngrow plants (TelecityGroup, 2010). Telehouse West in\nLondon Docklands disperses heat from its server halls\ninto the local district heating system and provides hot\nwater to nearby houses (Telehouse, n.d.). In Stockholm,\nthe internet service provider Bahnhof is experimenting\nwith turning waste heat into the main source of heating\nin the Swedish capital while establishing standards for\nfuture `green' data centres (Elementica, 2016; Triple\nGreen, n.d.). This future is imagined to be `not in the\ncountryside, it is in cities with a well connected district\nheating system', Bahnhof's CEO proclaims (Bahnhof,\n2015a). In confirming this statement, the Russian\nsearch engine Yandex opened in early 2016 a massive\ndata centre in Ma\n\u00a8 ntsa\n\u00a8 la\n\u00a8 , Finland that now provides\nthe energy to heat water for 20,000 town inhabitants\nThe examples above resemble a new wave of techno-\noptimism and are commonly veiled in a discourse of\ninnovation, environmental friendliness and `smarter'\ndata processing. They are at the same time alarming\nas they normalise the production of big data and inter-\nconnect internet infrastructures with the critical infra-\nstructures of urban life, that is the systems of water,\nenergy and heat supply. As Halpern (2014) reminds,\nfantasies that connect large data streams with sustain-\nability have been present for a while in contemporary\nurban development projects aimed at creating `smart'\ncities powered with new media. Inspired by cybernetic\nimaginaries from the 1950s, such urban landscapes con-\nceptualise data as a source of stability, wealth and sen-\nsory pleasure while converting it into a new raw\nmaterial to mine, creating new orders of control and\nThe bright sustainable future that data centre oper-\nators chart seems to take place in a universe in which\nthe critical debates that surround big data do not exist,\nwhile cementing data production as a regime of com-\nputation that can literally power everyday life. An\nenquiry into the nature and implications of this expand-\ning phenomenon is therefore urgent and represents the\nmain objective of this article.\nBig data has been defined as the capacity of certain\nactors to compute large data streams (boyd and\nCrawford, 2012). This capacity, possessed primarily\nby corporate data centre operators, internet service\nproviders and government security agencies redefines\nour ontological and epistemological orientation in the\nworld, bringing about issues of global surveillance,\nethics, privacy, algorithmic governance, new digital div-\nides and transformations of the public sphere (boyd\nThis article extends these concerns by asking what\nkind of issues, practices, modes of valorisation and\ninfrastructural interconnection arise when big data\nstreams become the raw material that replaces older\nforms of energy supply in the urbanised world.\nTaking as an empirical object the heat generated from\nserver halls, the article asks what implications does the\nuse of waste heat for urban heating have on the eco-\nnomic, symbolic and institutional significance of data\nand data centre operators? What are the processes by\nwhich the data processing industry becomes an energy\nsupplier, and with what societal consequences?\nDrawing on new materialisms, infrastructure studies\nand classical theory of valorisation through waste in\ncapitalism, the article suggests that by paying close\nattention to the ways in which urban infrastructures\nare rewired to transport waste heat, we could under-\nstand better the processes of ongoing renegotiations of\nthe meaning, materiality and the value of digital data.\nNot least, we can see how the data industry contributes\nto extend the sphere of capitalist production and the\ndigital economy by redefining waste into a desirable\ncommodity.\nUsing examples from Stockholm and Paris, two\nmodes of valorisation of waste heat are outlined: first\nthrough a process of infrastructural convergence, or the\ncreation of links of dependencies through loops of\nenergy transfer between the flows of data streams and\nthose of urban energy supply. And, second, by obscur-\ning power through dismantling the data centre spatially\nand moving it into our homes, converting it into yet\nanother ephemeral artefact. The main contribution of\nthe article is in showing how these two modes convert\ndata from a source of value online into a broader\nresource of significance. In this process of conversion,\na new commodity is emerging, that of computation\ntraffic. This commodity arguably extends the power of\ndata centre operators by allowing them to, first, valor-\nise data online, and second, use big data streams as a\nraw material that has to increase and flow perpetually\nin the network irrespective of its meaning. The article\nconcludes with a discussion of the broader implications\nof this emerging commodity.\nServers, hot and cold\nWithin media studies, heat and media temperatures\nhave been referred to predominantly metaphorically,\nand more rarely as the main object of study. Mapping\nthe historical terrains of the use of temperature in\nmedia studies, Starosielski (2014) reminds of four\n2 Big Data & Society\nuses. The first, and more common, is McLuhan's (1994)\nmetaphor of media as cold or hot which refers to the\naffective intensities that our engagements with different\nmediums evoke. Another use is in Shannon's theory of\nthermodynamics where heat describes the conductivity\nof communication technologies, whether or not they\ncan transmit information. A third approach with\nMarxian roots refers to transformations of media\nover time, moving from one phase to another, or\nwhen media objects change form. Finally, heat as\nused by new materialisms has been concerned with\nthe analysis of media environments and `the expansive\ncooling infrastructure needed to dissipate communica-\nspective is useful to map the context in which the\ninfrastructures of big data are currently being rewired\nand to start charting the modes in which they transform\nthe value, materiality and cultural meaning of data\nstreams.\nMateriality of media is both about the physicality of\nhardware, software, digital objects and artefacts, and\nabout the material conditions of producing the digital\n(Munster, 2014). From a materialist perspective, as\nwith any other body, media hardware radiates heat\n(Mulvin and Sterne, 2014). As a consequence, heat\nhas always been a problem in electronics. Maxwell\nessay by Gordon Moore from 1968 about the exponen-\ntial increase in density of transistors on a chip, there is\nan overlooked section called `Heat Problem'. In it, the\nheat generated by the components in a chip is regarded\nas an engineering problem that requires consideration.\nIn 2011, the problem was solved by inventing a new\nchip called dark silicon (Maxwell and Miller, 2012:\n28). Yet, if solved locally at the level of electronics,\nthe problem of heat re-emerges in the broader context\nof the expansive infrastructures of networked data cen-\ntres made of energy-hungry server halls.\nIn order for the signals of telecommunication net-\nworks to be pushed through the transoceanic fibre optic\ncables, cable stations need to be powered by electricity\nminimal part of the energy that powers server rooms is\nactually needed to emit signals in the telecommunica-\ntion network (Liu et al., 2011). Most of the input elec-\ntricity is transformed into heat by the servers, which\ncan become warm even when computing only a little,\nsimply due to the close proximity of large numbers of\nmachines located in a dense space. The heat increases\nduring computing when a greater load is placed on the\nservers' processors.\nIntense computation emerges from more than simply\ncollecting data for surveillance purposes or for produ-\ncing `the cloud'. The digital version of the oldest new\nmedia, animation (Manovich, 2001), requires massive\ncomputation power, called render power, to be mobi-\nlised. In order to create their 3D films, Hollywood ani-\nmation studios use thousands of servers with tens of\nthousands of cores to render their animations. Those\nwho do not possess such computing power revert to the\nservices of online render farms. These farms usually\noperate as part of data centres and cloud-computing\ninfrastructure, and share their computational capacity.\nBecause of this infrastructural coexistence, emerging\nmajor actors in the area of online distributed render\npower are, unsurprisingly, Google, through its ZYNC\nservice, and Amazon through its Elastic Compute\nCloud. Universities and other large-scale research facil-\nities face similar needs for large-scale computation\npower.\nIntense computation processes can make server\nrooms reach temperatures of 35\u00ad45C that could\nresult in server failure. Surprisingly, the effort that the\nindustry exerts to offset this threat has largely evaded\nscholarly attention, which has instead predominantly\ndiscussed the input problem, the electricity.\nmonth to its server farms and Google already had\nabout half a million servers, `the cloud' was consuming\ngigawatts of energy, representing about 2% of US elec-\ntricity consumption, with prospects for doubling every\nthree years later the energy consumption of server\nhalls surpassed 10% of the global electricity consump-\ntion (Cubitt et al., 2011). A much cited report from\nGreenpeace shows that up to 80% of this energy\ncame from coal, making data centres a major polluting\nindustry (Cook and Van Horn, 2011). This pollution is\nspecific and it leaves carbon footprints, coal dust and\nexploits vast amounts of land needed to store the ser-\nvers of the data centres (Gabrys, 2015).\nAdditional specificity is added by the emission of\n`waste heat'. From a materialist perspective heat is an\ninstance of a `weird materiality' (Parikka, 2012), or a\n`material immateriality' (Gabrys, 2015). It is `weird'\nbecause it does not `bend to human eyes and ears\n[and is] not only touchable objects, but also modula-\ntions of electrical, magnetic, and light energies, in which\nThe `weirdness' of heat stems from its ontology of being\na form of energy in flux, one which is culturally con-\nstructed by the operators of data centres as `dirt and\ncommunication, computation and economic flows.\nWaste heat threatens the information power gathered\nby destabilising the infrastructures of the data centres\nand the carefully crafted illusion of `the cloud' that the\nindustry has laboriously (and successfully) created\nIn order to offset this threat, data centres usually use\nwater. Mel Hogan (2015) demonstrates how the\nNational Security Agency constructed its surveillance\ndata centre, the third largest on the planet, such that\nit requires 1.7 million gallons of water per day to keep\nits servers running. While half of the world's population\nlacks adequate access to clean water, Hogan notes how\nwater is used for both propelling a surveillance machine\nand enabling the digital networked lives that we live:\nThe huge amount of water currently required to\nmanage our digital lives is inextricably linked to\nvalues we uphold, such as power and control, assumed\nto be inherent to Big Data and deeply rooted into the\nprovisions of nature, while never fully committed to\nIn Europe, new data centres tend to be built close to\nseas, rivers and lakes in order to ease the supply of water\nto server cooling systems. This is also one of the reasons\nwhy cities located in water abundant Northern Europe\nare becoming attractive locations for the data industry.\nAt one of the largest data centres in London,\nPowerGate, TelecityGroup collects rain water, stores\nit and evaporates it in a controlled way into the atmos-\nphere doing `smart climate management' through `free\ncooling' (TeleCity Engineering Group, n.d.).\nAnother way to offset waste heat is by relocating\ndata centres to geographically colder locations, such\nas those in the Arctic climate zone, reshaping the top-\nography of the internet infrastructure (Starosielski,\n2014). A paradigmatic example has been Facebook's\ndata centre in the city of Lulea\n\u00b0 in Northern Sweden,\nthe first one to be opened outside of the US. While\nusing as much energy as a steel plant, the centre, also\ncalled `The Node Pole', cools down its servers by pump-\ning outside air into the building and exhausting waste\nheat (Harding, 2015). Similar solutions have been\nimplemented by Google's data centre in Finland and\nApple's equivalent in Denmark.\nA commonality of these approaches to cooling is that\nthey treat heat as `a matter out of place' (Douglas, 2002:\n44). But whether matter is in the right or wrong place in\ntelecommunication systems is negotiated in the process\nof capitalist production. The next section extends the\nmaterialist framework by revising theories that help\nrelate waste heat to circuits of commodity production\nand circulation, value and power.\nWaste, value and infrastructural\nstability\nAs a material and cultural category, waste is never an\nend point. Inherent to capitalism and its need to\nexpand, waste is created in the dialectical processes of\nproduction and consumption, both of which are con-\ntingent on the supply of raw material and the availabil-\nity of infrastructures to transport and process it. What\nis of value and what is its opposite, i.e. waste, is deter-\nmined by the interested parties in the production pro-\ncess. Waste could be a by-product of production, and\nequally a by-product of productive consumption, when\nthe practice of consumption produces the raw material\nfor new production and consumption practices to\nWaste is also an intermediate state and a boundary\ncategory in which an object is not in movement towards\nvalorisation or devaluation but is temporarily exempted\nfrom value (Thompson, 1979). This state is important\nfor two reasons. First, Thompson notes that at each\nmoment in time an object is located on a specific trajec-\ntory of valorisation, either increasing its value over time,\nand hence becoming durable, or decreasing its value and\nbecoming transient. The conversion from transient to\ndurable takes place when something becomes waste,\nan object of no value and no projected lifespan. If `dis-\ncovered', the object can increase in value and lead to the\ncreation of new commodities. Second, the possibility for\nthese transfers to occur permits the maintenance of\nsocial boundaries and the uneven distribution of\nthose who have the power to define what is valuable\nin a society (including redefining waste as a valuable\nasset) are those who produce and maintain difference.\nIn a capitalist system, raw materials need to be con-\nstantly reinvented in order to allow capital to expand.\nAs discussed above, the raw material that powers the\ndata infrastructures, at least in the US, has been pre-\ndominantly coal. Yet such raw material is insufficient to\ncreate surplus value in the digital economy, which also\ndepends on creating symbolic raw materials, such as\ninternet users to be fed to algorithms (Gillespie, 2014:\n173). Occasionally, waste also needs to be converted\ninto a symbolic raw material in order to expand the\ndigital economy.\nIn the context of the internet infrastructures, spam is\na good example of the latter. Spam is ambiguous gar-\nbage and it is simultaneously the agent that clogs band-\nwidth and the ever multiplying by-product of this\nclogging (Brunton and Coleman, 2014). It is quotidian\nyet rarely noticed or read by those who receive it.\nDespite hijacking bandwidth, spam has been valuable\nnot only for the economic practices of the dark internet\nnotes, for internet service providers because it creates\ntraffic, a commodity that is produced by the flow of\nvisitors to websites (van Couvering, 2008).\nIn the case of waste heat, its conversion into a raw\nmaterial of value could not happen at once.\n4 Big Data & Society\nAn important step in the process was the phase when\ndata centre infrastructure operators constructed `the\ncloud' and themselves as powerful nodes on which the\ndigital economy depends.\nThe creation of the cloud has been predicated upon\naggregating and centralising user information manage-\nment, moving it away from users' personal computers.\nAs Jakobsson and Stiernstedt (2012) show, this move\nhad to be perceived as safe. This perception has been\ncarefully crafted by deliberately inscribing the data\ncentre in the temporalities of geological, historical\nand technological change, placing data centres in his-\ntory through which they become part of a desired\nfuture. Stories about the formation of Earth's surface,\nthe bedrock and broadly geological, political and eco-\nnomic stability have been used particularly in the\nNordic countries to define data centres as eternal, and\nhence durable (Jakobsson and Stiernstedt, 2012).\nOnce objects are defined as valuable they also tend\nAerial photos of sleek containers embedded in scenic\nlandscapes, clean server rooms with shiny pipes, colour-\nfully blinking electronics and James Bond-inspired\ninteriors hyper stylise data centres and make the\nvisual argument that the landscape becomes more\nbeautiful through data (Holt and Vonderau, 2015).\nMaking data beautiful is also intrinsically related to\nthe process of making data useful (Halpern, 2014).\nYet, as long as heat remains waste within the data\ncentre it acts as a material force that devalues this so\neffortfully and carefully constructed social image of\ndurable data and its extended utilisation. Waste heat\nacts as the major agent of disruption from within the\ndata centre and threatens its power through the threat\nof network instability, transience and decay.\nDestabilisation is a common problem for global\ncommunication flows, one that requires constant\neffort, strategic material and cultural interventions to\noffset disturbances (Graham and Thrift, 2007; Jackson,\nstabilise the internet infrastructure has been through\nconnection'. By this she means the process of adding\ncultural and material layers of insulation that facilitate\nthe transfer of multiple forms of energy between the\nsystems of the cable network and the cultural geogra-\nphies into which it is inserted, keeping the network in\nequilibrium. Such strategies have ranged from using the\nocean to ground the signals transferred through fibre\noptic cables, to arranged marriages between workers in\norder to help `sustain the operators and therefore sta-\nbilise transoceanic signal traffic in remote locales'\nCommodifying waste heat can therefore represent a\nway to insulate the data centre network from inner\ndisturbances, and therefore stabilise it. Not least, it\ncan help bring attention to a new commodity that the\ndata industry creates, that of computation traffic, while\nneutralising external criticism by reframing data pro-\nduction as environmentally responsible and necessary\nfor everyone's well-being. The next sections illustrate\nhow this process happens through discussing examples\nfrom Stockholm and Paris.\nInfrastructural convergence\nOne emerging approach to commodifying waste heat is\nthrough infrastructural convergence. To explain the\nprocess I will use as an example the workings of\nBahnhof, a Swedish internet service provider that has\nrecently constructed a number of data centres in\nStockholm, in a way that rewires the systems of\nenergy supply in the Swedish capital to become contin-\ngent on data.\nFounded in 1994, Bahnhof was one of the first inter-\nnet providers in Sweden and aims to deliver `Internet\nwith privacy' as its slogan reveals. Bahnhof adhered to\nthis principle on multiple occasions. It has been provid-\ning hosting services to Wikileaks since Amazon stopped\nservicing it in 2010. It also offered free VPN encryption\nto all its clients when the European Union passed the\ndata retention directive in 2014 that forced all internet\nservice providers to collect data from their users, thus\nmaking such collection worthless (Bahnhof, 2014).\nThe data centre that hosts Wikileaks is Pionen.\nInaugurated in 2008 in a Cold War nuclear bunker in\nthe city centre, Pionen attained a cult status for its\nfuturistic cyber-utopian design largely inspired by\npopular culture, and the symbolism of its location\nwhich in the event of a cataclysm would likely be one\nof the few that would remain intact, signifying the value\nof the data hosted there (Holt and Vonderau, 2015;\nWhile providing cloud services online, Bahnhof also\ncreated a visible cloud of steam in central Stockholm,\nwhich for years was a cause of anxiety for citizens. In a\n2015 press release, the company explained that the\ncloud of steam was generated by its underground ser-\nvers. It also announced its new project to eliminate the\nvisually disturbing sight of the steam cloud by routing\nheat into the pipes of the district heating system in this\nBahnhof's solution was to create a large cooling\nplant inside the data centre that would absorb the\nwaste heat from the servers and pump it in the homes\nof the city dwellers. The system was serviced by\nFortum, one of Stockholm's largest electricity and dis-\ntrict heating providers (Open District Heating, n.d.). As\nof 2016, the plant's waste heat is said to provide a con-\nstant supply of between 600 kW and 1 MW of heat\nwith a delivery temperature of 68C (Open District\nHeating, n.d.).\nThe streams of waste heat that enter homes, shops\nand offices in Stockholm currently pair the production\nof digital data with the residents' sensory experiences of\nambience. This process of integration literally shows\nhow heat can move `across and through infrastructure,\necologies, and bodies' (Starosielski, 2014: 3). As Larkin\n(2013) reminds us, infrastructures are able to influence\nsensory experiences of softness, hardness, the noise of a\ncity or the feeling of being hot or cold, affecting per-\nceptions of temporality, speed and the sense of what it\nis to be modern and part of a specific future.\nThe future of Bahnhof is one of intervening in the\nenergy politics of the Swedish capital through comput-\ning data and providing heating with it, attempting to\neliminate older forms of energy supply and convert the\ndata centre into an essential energy provider. The cool-\ning plant in Pionen, likewise in other data centres is far\nlarger than the current capacity requires (Open District\nHeating, n.d.). In building a cooling system on such a\nscale, Bahnhof reflects the general principle of the tele-\ncommunication cable industries' to bind their economic\nmodels and infrastructures to a projection of media as\nan ever-expanding resource to be capitalised on\n(Starosielski, 2015a). The value of the heat fluctuates,\nbased not on the servers' temperature but on the out-\ndoor temperatures making servers in colder climates\neconomically more profitable, strengthening the\nattractiveness of northern locations: `On a cold winter's\nday one megawatt hour can be worth ten times as much\nas on an ordinary summer's day. Bahnhof still knows\nthat it has made a good investment' (Open District\nHeating, n.d.).\nSince Pionen, Bahnhof and Fortum have built three\nlarger data centres in Stockholm with this system in\nplace and two more are in the planning stage. One of\nthem is intended to be Stockholm's largest data centre\ncode named Elementica. Admitting that the new `21\nmegawatt monster' is a heavy industry project, its cre-\nators nevertheless promise it will be the world's most\nmodern and climate smart data centre. They envision a\nfuture where Stockholm is Northern Europe's internet\nhub, replacing the main sources of heating for the cap-\nital with the waste heat from the data centre (Bahnhof,\ngenerate 112 GW h of heat per year and provide that\nSuch a replacement is significant for converting the\nproduction of data from a source of value online into a\nraw material to power urban life. Yet, the success of the\nimaginary that underpins this multimillion investment\nis crucially dependent on the ability of data centre oper-\nators to fill the data processing and storage capacity of\nthese oversized centres. This need implies that we are\nstill to see an increase in the intensity of the generation\nof big data, while the projected infrastructures that\nanticipate such production already create firm depen-\ndencies between the ambient experience of comfort of\ncity dwellers and the need for increased data produc-\ntion and computation.\nWhen new infrastructures are established they tend\nto be layered upon older ones, creating historical lines\nthat chart different temporalities and cultural contexts\nin which each layer has emerged (Star and Ruhleder,\n1996). The type of infrastructural connection that\nBahnhof makes is somewhat different. It is not about\nlayering on top, but about converging older infrastruc-\ntures with those of big data. The heat emitted by servers\nand its valorisation extends the process of media con-\nvergence beyond that of media formats and devices.\nInstead it becomes materially implicated with legacy\ninfrastructures, transforming them and replacing their\nraw material with data and waste heat.\nThe spatial dismantling of the\ndata centre\nAnother way to valorise waste heat in European capital\ncities, albeit on a smaller and more experimental scale,\nis through the attempts of providers of computation\nservices to realise the idea of data furnaces.\nOne of the most successful examples so far is that of\nQarnot computing, a French company that specialises\nin providing computation power rather than storage to\nbanks, research institutes and animation studios.\nFounded in 2013, the company has created a `smart'\nheater that represents `a fusion of an electrical heater\nand a high-performance computer server' (Qarnot\nComputing, n.d.). The device is called Q.rad and pro-\nduces heat by computation. When a client of Qarnot\nrequires computing power to process financial data or\nrender a scene of an animation film, the Q.rads are\nactivated and each of them produces 500 W of energy\nthat heats up a space of 13\u00ad25 m2. If no computation is\nrequested, the server pulls tasks from its cache or per-\nforms dummy calculations to emit heat. The electrical\nconsumption is measured by an embedded meter, and\nthe bill is sent to the client who ordered the computa-\ntion, rather than the one who used the heat. Since 2013,\nthe company has installed 300 such heaters in Paris\napartment blocks and 25 in the Telecom ParisTech\nincubator, with plans for expanding to the Nordic\ncountries, the US and China.1\nIn this scheme of valorising waste heat, the space of\nprivate homes and office buildings becomes the infra-\nstructure that bears the data centre, supplies it with\nelectricity and cools it down. The home becomes a cool-\ning environment and a node in the telecommunication\nnetwork that ensures its stability. It powers it physically\n6 Big Data & Society\nwith electricity, cools it down and fills it symbolically\nwith content through the more mundane online activ-\nities of the household members. The production of con-\ntent does not directly heat the living space, but it\nsupplies the network with more data, a justification\nfor such infrastructure to be built at the first place.\nMore importantly though, the members of the house-\nhold are made involuntary into service staff that can\nobserve and report the physical attributes of the\nheater, push buttons or carry out hard reboot of the\nserver if requested, in the case of malfunction, or need\nof repair. These services are normally provided by dedi-\ncated staff at the data centre, but in Qarnot's configur-\nation there is no need for such paid labour. There is\nalso no central space in which such labour could poten-\ntially work. Data furnaces installed in private living\nspaces fiscally devalue the work of data centre mainten-\nance. What the household members receive in return is\na product that has sign value. It comes in the form of a\nsupposedly enhanced sensory experience of comfort\nthat the heat produced through computation creates.\nAs Qarnot claims, it is `a high quality ``soft'' heat as\nopposed to electrical convectors' (Qarnot Computing,\nn.d.). Such an aestheticised waste heat can provide resi-\ndents with a sense of pleasure and evoke feelings of\nprogress, of belonging to the future and of giving mean-\ning to what it is to be a responsible producer of big\ndata. In a campaign video by the Dutch company\nNerdalize, which is experimenting with an identical\napproach to Qarnot in cooperation with the energy\nprovider Eneco, an elderly couple shares their positive\nfeelings about the new server heater they received:\nDoes it buzz? Does it hiss? Does it gurgle? Does it beep?\nNot at all -- it's completely silent! (giggle) -- I just\nthink the whole idea is brilliant -- that rather than\nputting all those things together inside a single unit\nthat you then need to cool, you spread them around\ninstead, one by one, among private individuals so that\neveryone gets to benefit from it. I think that before long\nhundreds of families will start enjoying the benefits of\nBesides homes, other important nodes in the dis-\ntributed data centre are schools where Qarnot has\nexperimentally placed 50 server heaters to guarantee\nthat even if households turn off the heaters on warm\nsummer days, those in schools will keep computing\nand cool the network by emitting waste heat while\nstudents are on vacation (Judge, 2014). In addition\nto considerations about locations in which the ser-\nvers could be placed as part of the topography of\nthe internet, data centres anchor their infrastructures\nin the temporal cycles of social life and seasonal\nchange.\nTo sum up, in this mode of valorising waste heat, the\ndata centre is fragmentised, decentralised and its com-\nputing servers are moved into multiple private and\npublic spaces. Such a move introduces a new degree\nof ephemerality to `the cloud'. Its materiality and work-\nings are veiled in a new degree of abstraction that is\never harder to locate. With materiality reconfigured,\ndata centre service workers redefined and data ready\nto replace heat supply in private living spaces, the\ndata centre rises in power and veils itself in deeper\nopacity.\nIn a certain way, this approach mirrors some earlier\ninternet infrastructures such as the bit torrent protocol\nthat made possible peer-to-peer file sharing. It also\nexhibits similarities to the commons-based peer produc-\ntion mode of creating value in the internet economy\n(Benkler, 2006). One lesson that these models of cul-\ntural production have taught us is that their emergence\nhas come with a profound transformative charge that\nhas altered economic, cultural and technological pro-\nduction, bringing about phenomena such as Wikipedia,\nNapster and concentrations of algorithmic power.\nThe concluding section of this article discusses the\ntransformations that occur through the two modes of\nturning waste heat into a utility and their broader\nimplications.\nTransformations of data and the birth of\nthe computation traffic commodity\nWe can see that with the intensification of big data\nproduction there have emerged particular locations in\nEurope where waste heat is being converted into a valu-\nable asset and a raw material to mine by data centre\noperators. These developments are significant in\nseveral ways.\nFirst, the creation of this raw material is a sign of the\nongoing formation of a new commodity, that of com-\nputation traffic. Traffic as a commodity emerged after\nthe Dotcom crash, as a result of the process of the\nreconfiguration of the web portals and the search\nengine market (Van Couvering, 2008). This reconfigur-\nation implied that it was no longer as valuable to pro-\nvide content to users as to increase and keep the flow of\nvisitors, a move that led to search engines becoming\noutright winners. The traffic commodity was further\ndeveloped by internet server providers and data centre\noperators that were able to aggregate and organise\ninformation about these flows and sell it to third par-\nties. Bolin (2014) shows how this process extended the\ngeneral traffic commodity and made it more specific by\nselling visitor data to advertisers. The cases discussed in\nthis article show instead how data centre operators are\nattempting to create surplus value from the flows of\ndata in the network and the need to process them and\nassure their stability rather than from the flows of vis-\nitors or audiences. This shift in focus signifies that digi-\ntal data is starting to be valued by data centre operators\nfirst of all as a source of content or information that\ncan be valorised back online, and then again, as a raw\nmaterial that has to increase and flow perpetually in the\nnetwork in order to stabilise it and generate energy to\nsell in urban areas. A logical implication is to see the\nappearance of novel media practices that could poten-\ntially fill the emerging infrastructures of waste heat cir-\nculation with computation traffic.\nSecond, valorising waste heat arguably integrates the\ndata centre industry with the energy sector. Yet, this\nintegration does not happen by generating truly green\nenergy. Even if the data industry claims to be an active\nagent against global warming that reduces its carbon\nfootprint by creating infrastructural loops of renewable\nheat, none of the approaches discussed in this article\nprovide an actual alternative to polluting energy\nsources that power data centres with electricity, such\nas coal. Rather, the data centre industry relies on the\nexisting sources of power available in each specific loca-\ntion, and these can differ substantially.2 Nor do data\ncentre operators reduce the amount of electricity\nneeded to power a data centre. Instead, the claimed\nenergy efficiency through valorising waste heat trans-\nlates into economic efficiency for the data centre oper-\nators, which decrease their maintenance costs while\nexpanding their sphere of influence, by introducing\nserver waste heat as a competing resource to other\nforms of recycled waste, such as biomass used for heat-\ning. Hence, data centre operators do not offset the\nenvironmental problems that the industry generates,\nbut rather reshape the discourse around it. Rather\nthan an image of powerful actors who change our epis-\ntemological orientation in the world, the operators of\ndata centres are redefined culturally into providers of\ndesired infrastructures that are needed for a sustain-\nable, fossil-free future. In effect, data production\nbecomes connected with imaginaries of an environmen-\ntally responsible global citizenship and illustrates how\ninfrastructures can produce specific citizens (Larkin,\ndata for the improvement of everyone's well-being.\nIn the context of these developments, there are\nnevertheless some structural constraints to these shifts\nin the meaning and value of data that need to be\nacknowledged.\nThe convergence between the data centre industry\nand urban heating infrastructures is dependent on a\nwell developed and broadly used district heating\nsystem. In Europe it is the Nordic, Baltic and some\nEastern European countries that have more than half\nof the population heated in this way and serviced by\nfibre optic internet, making them potentially attractive\nlocations for such approaches. Other European regions,\nlikewise rural areas have limited or no access to district\nheating, and a much less developed fibre optic connect-\nivity (Euroheat and Power, 2015; European\nCommission, 2015). This unequal geographical distribu-\ntion poses limits for where data and heat infrastructures\ncan converge, yet makes certain locations, particularly\nmajor cities in the Nordic countries, into potentially\nmore important data and energy nodes in the future.\nOn the other hand, the possibility to create a distrib-\nuted data centre depends on the abilities of the data\nindustry to make specific arrangements with major\nactors in the telecom industry. In order for Qarnot com-\nputing to be able to heat homes with computation, it had\nto enter into a partnership with Orange, a large telecom\nand fibre optic cable operator in France, which installed\ndedicated fibre optics in selected buildings on top of\nexisting fibre optic connectivity as a way to secure a reli-\nable and fast link to the Q.radsi. Similarly, Bahnhof in\nSweden rents dark fibre from the municipal company\nStokab and Skanova, a private holding for its own ser-\nvices. Therewith, the potential for making distributed\ndata and heating infrastructure is dependent on the tele-\ncom switching and backbone industry which determines\nits outreach and speed of expansion.\nThese dependencies ultimately illuminate the import-\nance of the geographical locations where the data pro-\ncessing industry becomes an energy provider, and how\nthey contribute to sustain and reproduce existing digital\ndivides and politics of access. The new generation of\nenergy efficient data centres seem to be the ones located\nin the colder climate zones of the fibre-abundant global\nNorth, pushing the need for further investment in rapid\nand reliable connections there, while solidifying the\nrural network edge as a periphery and a host of\nlarger yet less efficient, slower and polluting data pro-\ncessing facilities.\nThe present analysis suggests that there are a range\nof issues arising from the currently decentralising and\nconverging data centre infrastructures which require\nfurther critical analysis as their operators experiment\nwith diverse schemes to commodify waste heat. This\narticle is a modest attempt to start such a discussion\nand hopes to prompt further critical engagement with\nthe expanding infrastructures of big data as they get\nintegrated into realms beyond the online.\n"
}