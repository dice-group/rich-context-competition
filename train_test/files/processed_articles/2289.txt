{
    "abstract": "This paper is motivated by a Eurobarometer survey on science knowl- edge. As part of the survey, respondents were asked to rank sources of science information in order of importance. The official statistical analysis of these data however failed to use the complete ranking information. We instead pro- pose a method which treats ranked data as a set of paired comparisons which places the problem in the standard framework of generalized linear models and also allows respondent covariates to be incorporated.",
    "reduced_content": "The Annals of Applied Statistics\n\u00a9 Institute of Mathematical Statistics, 2010\n \n \nThis paper is motivated by a Eurobarometer survey on science knowl-\nedge. As part of the survey, respondents were asked to rank sources of science\ninformation in order of importance. The official statistical analysis of these\ndata however failed to use the complete ranking information. We instead pro-\npose a method which treats ranked data as a set of paired comparisons which\nplaces the problem in the standard framework of generalized linear models\nand also allows respondent covariates to be incorporated.\nAn extension is proposed to allow for heterogeneity in the ranked re-\nsponses. The resulting model uses a nonparametric formulation of the random\neffects structure, fitted using the EM algorithm. Each mass point is multival-\nued, with a parameter for each item. The resultant model is equivalent to a\ncovariate latent class model, where the latent class profiles are provided by\nthe mass point components and the covariates act on the class profiles. This\nprovides an alternative interpretation of the fitted model. The approach is also\nsuitable for paired comparison data.\n1. Introduction. Ranked data commonly arise in many substantive areas such\nas psychology, social research and marketing research when the interest is focused\non the relative ordering of various items, options, stimuli or objects. A typical aim\nof such studies is to estimate the mean or average ordering of a set of items, and to\ninvestigate how this ordering changes with respondent characteristics. This paper\nfocuses on the analysis of a survey question from a special Eurobarometer survey\non science knowledge, which asked respondents to rank six sources of science\ninformation in order of importance.\nEurobarometer public opinion surveys have been carried out in all member\nstates of the European Union since 1973. Eurobarometer 55.2 was a special survey\ncollected in 2001 and designed to elicit information on European experience and\nperception of science and technology. 17 countries in total were surveyed--with\nNorthern Ireland, Great Britain, East Germany and West Germany being treated\nas separate countries for the purposes of the survey. Within each country a multi-\nstage sampling scheme was used. Primary sampling units (PSUs) were randomly\nKey words and phrases. Ranked data, random effects, NPML, paired comparisons, Bradley\u00adTerry\nmodel, latent class analysis, mixture of experts, Eurobarometer.\nHere are some sources of information about scientific developments.\nPlease rank them from 1 to 6 in terms of their importance to you\n(1 being the most important and 6 the least important)\n(a) Television .....\n(b) Radio .....\n(c) Newspapers and magazines .....\n(d) Scientific magazines .....\n(e) The internet .....\n(f) School/University .....\nFIG. 1. The 'Sources of science information' question.\nselected with probability based on population size after stratification by admin-\nistrative region and by the degree of urbanization. Within each PSU, a cluster of\naddresses was sampled, and random route methods were used to select households.\nFinally, a respondent was selected at random from within each household. Face to\nface interviewing was used to elicit responses.\nOur question of interest in this paper is given in Figure 1. The survey report\n[Christensen (2001)] describes how this question was analyzed. Only the first two\nrank positions were examined, and the percentage of times a source was mentioned\nin either the first or second position was reported. This was presented as given in\nThis method of analysis, however, does not use the respondent's last four ranked\npositions, and also does not distinguish in importance between the first and second\nranked position. Thus, information is wasted and other issues such as the influence\nof covariates and respondent heterogeneity are not considered.\nWe proceed by examining current approaches to ranked data in Section 2, be-\nfore describing our modeling approach in Sections 3\u00ad5. This approach combines\nthe modeling of ranked data patterns through the Bradley\u00adTerry model, We para-\nmeterize the items through a set of worth parameters which sum to 1, and which\nwe allow to depend on covariates. The model also incorporates discrete or non-\nparametric (mass-point) random effects to account for heterogeneity. This model\nRespondents mentioning source of information in first or second position\na b c d e f\nTelevision Radio Press Scientific Internet School and\nmagazines university\n(TV) (Radio) (Press) (SciM) (WWW) (Edu)\ncan also be thought of as a mixture or latent class model on the ranks. Algorith-\nmic and computational issues are discussed in Section 6, and the results of the\nnew analysis on the Eurobarometer question above are discussed in Section 7. The\npaper finishes with a discussion of the methodology.\n2. Existing approaches to ranked data. Three simple approaches to analyz-\ning ranked data are common in the literature. The crudest method is simply to\nanalyze only the first ranked response, but this wastes information by not using\nthe other ranks. Another approach is to assume that the rankings are from a con-\ntinuous scale, and to analyze mean ranks, perhaps invalidly assuming normality.\nA third approach, used by sensory perception researchers, uses the nonparametric\nFriedman two-way analysis of variance. This test, however, simply examines the\nnull hypothesis that the median ranks for all items are equal, and does not consider\nany differences in ranking between respondents [Sheskin (2007)]. Moreover, if the\nFriedman test rejects the null hypothesis, no quantitative interpretation, such as the\nodds of preferring one item over another, is provided.\nAll of these simple approaches fail both to consider the underlying psycholog-\nical mechanism for ranking, and to formulate correct statistical models for this\nmechanism. In contrast, the approach taken in this paper is statistically more rigor-\nous, and involves modeling the observed ranks by assuming that they are generated\nthrough an underlying choice or preference model.\nThere are also a variety of modeling approaches to ranked data. One common\napproach assumes that the respondent carries out the ranking by first choosing\nthe most preferred item, and then the next preferred, and so on. This has led to\nthe choice set explosion model of Chapman and Staelin (1982) and the multistage\nmodel of Fligner and Verducci (1988). For example, a series of papers by Gorm-\ning ranks through the Plackett\u00adLuce and Benter models and have illustrated the\nmethodology using Irish electoral data. However, more generally, the choice set\napproach has the disadvantage of inconsistency: models which assume instead that\nrespondents first choose the least preferred, then the next least preferred, and so on\nlead to different conclusions and estimates of worths.\nOther modeling approaches have assumed an underlying distance metric on\nthe ranks--thus, Busse, Orbanz and Buhmann (2007) assumed that differences\nbetween ranks can be measured through the Kendall distance, which measures\nthe number of adjacent transpositions needed to transform one rank into another.\nD'Elia and Piccolo (2005) suggested that a two-component mixture of a shifted\nbinomial and a uniform distribution be used to model the rank of an specific item.\nIn this paper we assume that a ranking of items is produced by the respondent\nmaking a set of consistent paired comparison experiments, comparing each item\nmentally with each of the others, until a consistent ranking is obtained.\nFligner and Verducci (1993) described suitable probability models for ranked\ndata such as the Babington Smith model, where the probability for rankings are de-\nfined via parameters for paired comparisons. The usual model for paired compar-\n(the Mallows\u00adBradley\u00adTerry model).\nmodel is a Generalized linear model (GLM) and extended the model by introduc-\ning item-specific variables. We adopt this approach in this paper, extending it by\nthe addition of respondent covariates and random effects structures.\nRanked responses will vary between respondents. While measured covariates\ncan be taken into account [Dittrich, Hatzinger and Reisinger (2000); Francis et al.\n(2002)], there are likely to be other unmeasured or unmeasurable characteristics\nof the respondents which will also affect the response. This will give rise to het-\nerogeneity in the data which need to be taken into account. One approach is to use\na mixing distribution approach. Lancaster and Quade (1983) considered random\neffects models for paired comparison data and fitted a beta-binomial distribution.\nMatthews and Morris (1995) later extended the model to involve ties and used a\nDirichlet mixing distribution; B\u00f6ckenholt (2001a) fitted a binomial-Normal distri-\nbution.\nIn this paper we use a random effects approach, but adopt a discrete nonpara-\nmetric mass point distribution rather than a continuous mixing distribution. The\nuse of a discrete distribution both avoids the considerable computational complex-\nity of multiple integrals in the continuous case, and also avoids the need to spec-\nify a specific distribution which may by inappropriate. Heterogeneity in effect is\nmodeled through the incorporation of a missing latent factor representing group\nmembership. If there are no respondent covariates, then the approach reduces to\nand Gormley and Murphy (2008a) have considered the use of latent class models\nfor ranked data, they take a choice-based rather than a paired comparison approach.\n3. Ranked data and paired comparisons. The ranking of items can be de-\nscribed either by a rank vector (which gives the ranks of the items) or by an order\nvector (which gives the items in rank order).\nPaired comparisons have much in common with ranking tasks. In a paired com-\nparison task the respondents are asked to choose the preferred item in each pair\nof items. The number of pairs for a set of J items is given by J\n. In general, the\nobserved paired comparison response for two items i and j can be coded as\nyij\n=\n1 if item i is preferred to item j (i j),\n-1 if item j is preferred to item i (j i).\nIt is straightforward to transform a rank order into derived paired comparison data.\nSuppose the order vector of a respondent on four items is (c,a,b,d), then we\nknow that item c is preferred to item a, item a is preferred to item b and so on.\nHowever, true paired comparison data and derived paired comparison data from\nranks differ in two ways:\n(1) In true paired comparison tasks, respondents might be inconsistent in their\npreferences, producing an intransitive pattern where the respondent is not\nchoice consistent. In ranking tasks inconsistent response patterns cannot oc-\ncur.\n(2) The mode of presenting the items is different for the two tasks. In ranking data\nall items are presented at once, while in a paired comparison task all item pairs\nare presented in turn. Accordingly, different effects concerning the order of the\npresentation of the items may occur.\n4. Modeling ranked data.\n4.1. Modeling a single paired comparison. The standard approach to mod-\neling paired comparisons is the Bradley\u00adTerry (BT) model [Bradley and Terry\n(1952)]. We define the response in a single paired comparison (ij) to be Yij . It\nis assumed that the probability of an item i being preferred to j depends on the\nnonnegative parameters i and j of the items i and j, defined as follows:\nP{Yij\n} =\ni\ni\n+ j\nand\nP{Yij\n} =\nj\ni\n+ j\n,\nwhere we later ensure that the i sum to one for identifiability.\nThus,\nP{Yij\n= yij\n|i,j\n} =\ni\ni\n+ j\ni\n+ j\n= cij\n\ni\n\nj\nyij\n,\nwith yij\n {1,-1} and with a constant c-1\nij\n= i/j\n+ j /i which does not\ndepend on yij . We now reparameterize i as i\nlni or i\n= exp(2i). Equa-\ntion (4.1) then becomes\nP{Yij\n= yij\n|i,j\n} = cij exp yij (i\n- j )\nij\n= exp(i\n- j ) - exp(j\n- i).\n4.2. Response patterns. When transforming ranked data to paired comparison\ndata with J items, we form all possible pairs of items. The number of such pairs\nis J\n...,(2J);...;((J - 1)J). The ranking outcome can therefore be recorded as a\npaired comparison response pattern vector denoted by y = (y12,y13,...,yJ-1,J )\nand consists of a series of 1's and -1's representing the values of the yij 's.\nIn the case of a true paired comparison task where all possible comparisons are\nmade, the number of all possible response patterns is given by the number of pos-\nsible outcomes to the power of the number of paired comparisons. If yij can take\nonly two values, there are 2(J\n) possible response patterns in the space . However,\nthese response patterns also include intransitive patterns which can not be gener-\nated from a ranking task. Removing these intransitive patterns, the total number\nof patterns is considerably reduced to L = J!. The space of transitive patterns\nis denoted by T . For instance, the intransitive paired comparison pattern (1 2,\n2 3, 3 1) has no correspondence with any pattern generated from ranking three\nitems, since ranking patterns are transitive by nature. Incorporation of intransitive\npatterns in the contingency table would generate structural zeros and neglecting\nthem leads to biased estimates. Therefore, the use of a simple BT model, which\ncorresponds to a pattern model including intransitive patterns, is not appropriate.\nMoreover, the dependence introduced by rankings transformed to paired compar-\nisons would not be addressed properly. For instance, assuming independence, and\nin the simple case of three items, given Y12\nis one, whereas the probability of Y13\n= -1 is zero. However, modeling the proba-\nbilities of whole response patterns and reducing the number of possible patterns to\nthose which are transitive removes these dependencies. We want to emphasize that\nwe only consider complete rankings throughout the paper. It is possible, however,\nto allow for partial rankings where only a subset of items is ranked (see Section 8).\n4.3. Modeling and estimation of transitive response patterns. The probability\nfor observing a sequence of paired comparisons y is defined by\ni<j\nP(yij ),\nassuming independence between the comparisons. Using the probabilities for a\nsingle paired comparison defined in (4.1), we then get\nP(y) =\ni<j\ncij exp yij (i\n- j )\nor, equivalently,\nP(y) = y\ni<j\ncij with y\n= exp\ni<j\nyij (i\n- j ).\nParameter estimation is based on multinomial sampling over the transitive\npaired comparison patterns where it is supposed that each of the N respondents\nhave completely ranked all J items and thus contribute to one of the L transi-\ntive response patterns. The probability for observing a certain response pattern y ,\n= 1,...,L, given J comparisons and transitive relations only, is given as\nP(y |J, T ) =\nP(y )\nL\nP(y )\n=\nexp( ) i<j\ncij\nexp( ) i<j\ncij\n=\nexp( )\nexp( )\n,\nwhere\n =\ni<j\nyij; (i\n- j ).\nTo ease notation, P(y |J, T ) is denoted as P(y ) throughout the paper.\nLet n be the number of times the response pattern is observed, then the n 's\nare multinomially distributed where N = n is the total number of respondents\nand the probability P(y ) for a certain response pattern is given in (4.3).\nThus, the likelihood function is\nL = P(y )n .\nThe parameters j can be estimated (using suitable parameter restrictions, e.g.,\nsetting the last parameter to zero for identifiability) by using standard software\nsuch as the prefmod package in R [Hatzinger (2009)]. To fit the model, a variable\ncontaining the counts n and a specific design matrix X both need to be set up.\nThe method corresponds to a Poisson log-linear formulation of model (4.4) which\nis described in detail in Dittrich et al. (2007), who also describe the more general\ncase when undecided responses can occur.\nAll parameters in  have interpretation in terms of log odds. Comparing two\nresponse patterns and where only one yij differs, that is, yij; = 1 and yij; =\n-1, the log odds are ln(P(y )/P(y )) =  -  = 2(i\n- j ). If the item j is the\nreference item J, the odds reduce to exp(2i).\nEstimates of the worths ^\nj are calculated through the expression\nj\n=\nj\nto ensure that the sum of the worths is equal to 1.\n4.4. Respondent covariates in ranked data. In most practical applications it is\nimportant to determine if the importance of items depend on respondent covariates.\nThis can be viewed as a mixture of experts model. Gormley and Murphy (2008a)\ngive an example analyzing ranked data using a choice-based modeling approach.\nInitially, we consider categorical covariates only. In this case, each distinct com-\nbination of covariates observed will form a covariate set; assume that there are K\nsuch sets (1 < K  N). For example, with two factors AGE (with four levels) and\nSEX (with two levels), there will be eight covariate sets. To model the effect of\nthe covariates, the J! = L response patterns now become LK response patterns.\nThe number of times the th response pattern occurs within each covariate set k is\ndenoted by n k. The linear predictor  becomes\n k\n=\ni<j\nyij; k(ik\n- jk).\nEach jk is an interaction effect of the item j and the covariates. Thus, two covari-\nates A and B could potentially lead to the following effects j.A\n+ j.B\n+ j.A.B\nif an interaction effect on the items between A and B needs to be considered.\nWith continuous covariates, in general, each respondent will be likely to have\nhis/her own distinct set of covariates, and K will usually be close to N. In the\nparticular example of a single covariate x, the linear predictor of the model gener-\nalizes to be of the form\n k\n=\ni<j\nyij; k(i\n+ xki\n- j\n- xkj ).\n5. The random effects model. While the previous section has allowed for\nknown covariates, there may be other variables which are unmeasured or omitted\nfrom the data set, and these will produce heterogeneity between respondents in\nthe item parameters. One common way to account for such heterogeneity is to\nintroduce random effects for each respondent. These random effects would adjust\neach item parameter up or down to allow for these missing covariates and, thus,\nwe need J random effect components, one for each of the items being ranked.\nWe now extend the above model to allow for random effects. As before, we\nwork with data aggregated into patterns and covariate sets. For each covariate set\nand response pattern we need to specify J random effect components jlk. The\nlinear predictor now becomes\n k\n=\ni<j\nyij; k(ik\n+ i k\n- jk\n- j k).\nOn the worth scale, the random effects become multiplicative, which will multiply\nthe worths by adjustment factors, shifting the worth for each item up or down in\nan unique way for each k combination. We set J k to be zero for identifiability,\nand we define\n k\na (J - 1)-component random effect vector for each combination of response pat-\ntern and covariate pattern.\nIntegrating over the unknown (J -1)-component random effects, the likelihood\nthen becomes\nL =\nk\n\n-\n...\n\n-\nP(y k\n\u00b7\u00b7\u00b7 dJ-1; k\nn k\n,\nwhere g( k) is the multivariate probability density function or mixing distribu-\ntion of the random effects vector. For dealing with the multivariate random ef-\nfect, Hartzel, Agresti and Caffo (2001) suggest a number of possible approaches.\nThe first approach is to assume multivariate normality for g(\u00b7):  k\n MVN(0, ),\nwhere is an unknown (J - 1) \u00d7 (J - 1) covariance matrix which would be\nestimated from the data. For example, Coull and Agresti (2000) explored a multi-\nvariate binomial logit-normal distribution, where the mixing distribution is multi-\nvariate normal.\nAn alternative method, and one which we explore in this paper, is to adopt a\nnonparametric solution. This solution replaces the parametric multivariate normal\ndistribution by a series of mass point components with unknown mass or proba-\nbility, and unknown location. This nonparametric maximum likelihood (NPML)\ntechnique [Mallet (1986); Aitkin (1996)] has the advantage of being able to iden-\ntify subpopulations of the respondents with specific response patterns, as well as\nidentifying the effect of respondent covariates on these patterns. The mass-point\napproach is in fact a mixture model, with the earlier multinomial covariate model\nbeing replaced by a mixture of multinomials.\nInitially, we suppose that the number of components is known and is set to R.\nThen we have R mass-point vectors; a typical mass point component r would have\nunknown mass-point locations\nr\nand unknown component probability qr . If R is small, this substantially simplifies\nthe problem by replacing a J - 1 dimensional integral with a sum over R terms.\nThe likelihood now becomes\nL =\nk\nR\nqrP kr(y k\n|r)\nn k\nwhere P kr\nThe model can be interpreted in two ways. If we consider the discrete mass\npoint components as approximating an underlying multivariate distribution, then\nwe should ignore any interpretation of the mixing structure and interpret the jk\nalone. However, we can also think of the model as representing underlying sub-\npopulations (or latent classes) of the respondents, and we can then interpret the jr\n(which for a specific latent class r gives the extra increase or decrease in item j's\nparameter over the reference latent class R).\nWe determine the number of mass point components by choosing the model\nwhich minimizes the Bayesian Information Criterion (BIC) proposed by Schwarz\n(1978), which provides a penalty on the deviance which is a function of the number\nof pattern\u00adcovariate sets,\nBIC = -2lnL + p ln(LK),\nwhere LK represents the number of pattern\u00adcovariate combinations and p is the\nnumber of parameters in the model.\nWe need to make clear that the likelihood in (5.2) does not necessarily account\nfor the complex sampling design in the Eurobarometer survey. As the latent classes\naccount for heterogeneity, it is likely that some of the latent classes will reflect\nclustering and design effects. We return to this point later in the discussion section.\n6. Algorithmic and computational issues. The EM algorithm provides a\ncomputationally elegant solution to the maximization of the the likelihood given\nin equation (5.2) [Aitkin (1996)]. The use of this algorithm is well known; we give\nbrief details here and provide more detail in the online supplement [Francis, Dit-\ntrich and Hatzinger (2010)]. We start by observing that we can view the problem\nas a missing data problem, where the latent class membership indicators for each\npattern and covariate set are missing. We can write these as z kr, with z kr\npattern k belongs to class r, and zero otherwise. The expected values of the z's\nare defined to be w kr and are the posterior probabilities of class membership for\na respondent with pattern and covariate set k. The E-step of the EM algorithm\ncomputes the conditional expectation of the complete log-likelihood (involving the\ncalculation of the w's), whereas the M-step maximizes the multinomial likelihood\nwith respect to the 's and 's, given the current expected values of the z's, which\ncan be carried out through an expanded Poisson log-linear model with weights\nw kr. Fitting the multinomial through a Poisson log-linear model necessitates that\na set of nuisance parameters be included in the linear predictor; these constrain the\nmarginal totals for each covariate set to be equal to the observed totals.\nThe w kr can potentially be used to assign respondents to classes. If a respon-\ndent belongs to covariate set k and has response pattern , then we can assign to\nthe class with the highest posterior probability w kr over the r classes.\nThere are a number of specific problems related to the fitting of latent class mod-\nels of this kind. The first is that of multiple maxima. The EM algorithm guarantees\nconvergence to a local maximum of the likelihood, but not to a global solution.\nTo minimize this problem, we chose fifty different sets of starting values for each\nvalue of R and for each covariate model, and quote the best value of -2lnL and\nBIC found.\nThe second problem relates to the well-known slow convergence of the EM\nalgorithm. A relatively tight convergence criterion of 0.001 on the deviance differ-\nence was chosen to ensure convergence of parameter estimates.\nAdditionally, the EM algorithm does not give correct standard errors for the\nparameters, as the method assumes that the z's are known rather than estimated.\nTwo solutions are used in this paper. First, it is possible to adopt a hybrid scheme\nwhere the EM algorithm is used to obtain convergence, and then a series of Gauss\u00ad\nNewton steps are used to obtain the full Hessian matrix [Aitkin and Aitkin (1996)].\nA second method which is appropriate where the likelihood is likely to be non-\nquadratic is to use a procedure described by Aitkin (1994) and Dietz and B\u00f6hning\n(1995) to obtain correct standard errors. This sets the Wald test statistic equal to the\nlikelihood ratio chi-squared statistic obtained by equating one of the parameters in\nthe model to zero. From the Wald-test statistic, the appropriate standard error is\nobtained for the 's associated with effect X,\ns.e.(^\njX) =\n^\njX\n= ^\njX) - 2lnL(jX\n.\nIt is important that this second procedure is carried out by using as starting values\nthe final estimates of w kr obtained from the final model. This will ensure that the\nalgorithm will not converge to a local maximum with higher deviance.\nBoth methods have advantages. The first method, while computationally com-\nplex, gives asymptotic standard errors for all estimated parameters, provided that\ngood starting values are used for the Gauss\u00adNewton steps. The second method has\nthe advantage of providing a standard error which gives a t-test p-value equiva-\nlent to the appropriate likelihood ratio test. However, label switching problems can\noccur in using the second method especially when setting, for example, a specific\ndelta parameter to zero.\nFinally, for large K, the algorithm will take longer to converge and require more\nmemory, both because of the need to increase the size of the table [y k] to be\nanalyzed, and the large number of lambda parameters jk and nuisance parameters\nneeded to fit the multinomial by means of a Poisson log-linear model. Numerical\nprocedures such as those described in Hatzinger and Francis (2004) can be used to\nremove the need to estimate the nuisance parameters and to speed convergence.\nFor this paper, models were fitted using the pattnpml.fit function of the\nThe pattnpml.fit function is a modification of the alldist function in the\npackage npmlreg [Einbeck, Darnell and Hinde (2007)], and has been adapted\nto allow multiple random effects terms and more flexibility in the choice of start\nvalues.\n7. Data analysis. We now apply the above model to the Eurobarometer ques-\ntion. There are 12216 complete responses in the data set. We choose covariates\nmale) to illustrate the methodology. There are other important covariates, such as\neducational level, income and country of origin, which have been identified by\nChristensen (2001), but we exclude these in this illustration to ensure that omitted\nvariables and random effects are needed in the analysis. Of the 720 response pat-\nterns, the most popular response is (TV,Rad,Press,SciM,WWW,Edu) with 526\nrespondents, followed by (TV,Rad,Press,SciM,Edu,WWW) with 507. Only 70\n(9.7%) of the response patterns are not used at all by the respondents.\n7.1. Modeling \"Sources of science information\" data. Our model fitting strat-\negy was to determine a covariate model using simple fixed effects models (that is,\nwithout random effects terms), then fixing the covariates in the model and increas-\ning the number of mass point vectors to allow for the unknown random effects\ndistribution to be approximated by the nonparametric mass point components. We\nstarted with the \"null\" model without covariates (4.5), which estimated a common\nset of item parameters for all respondents. We then included the respondent co-\nvariates AGE and SEX and examined possible main effect and interaction models.\nEquation (4.6) reminds us that when we refer to the model SEX, we are in fact\nfitting an interaction term between the items (TV,Rad,Press,SciM,WWW,Edu)\nand SEX and specifying 12 interaction parameters in the model: TV.SEX, Rad.SEX,\nPress.SEX, SciM.SEX, WWW.SEX and Edu.SEX. Two of these parameters (Edu.male\nand Edu.female) are constrained to zero for identifiability. We examined changes\nin deviance and the Bayesian information criterion BIC [Schwarz (1978)] to com-\npare model fits and to find the best model (that is, the model with the lowest BIC).\nTo allow deviances and BIC values to be compared, we fitted models to the same\nsized table [y k]--with eight covariate sets, all model fits included eight nuisance\nparameters (the AGE by SEX interaction).\nAs can be seen in Table 2, the main effects model AGE+SEX has the lowest BIC\n(= 18,100) and there is no need for the interaction between AGE and SEX. In the\npaired comparison model this means both factors AGE and SEX have a separate\neffect on the item parameters and, therefore, the worths of the items change with\nAGE and SEX.\nWe can consider two forms of random effects models. We first investigated\nwhether a simple random effects model without covariates provides a better ex-\nplanation than the fixed effects model. The model without covariates is equivalent\nto fitting a latent class model to the data. We then fitted random effects models\nwith fixed covariate terms AGE+SEX, and tested whether the covariates are still\nimportant.\nThe model with a single mass point component means that all respondents are\nin one latent class, and corresponds to the null fixed effect model (deviance =\n21,293). Increasing the number of mass point components (Table 3a), we observed\nFixed effect models\nModel Deviance No. of parameters BIC\nNPML random effects models with and without covariates\n(a) Without covariates (b) With AGE and SEX as covariates\nNo. of No. of No. of\nmass para- para- Final\npoints r Deviance meters BIC Deviance meters BIC model\nthat the BIC steadily decreases with no sign of a minimum being reached. We\nstopped at eight mass point components, as we were not specifically interested\nin determining the number needed for the model without covariates. However, we\ncan observe two features. First, through examination of BIC values, the latent class\nmodel with two (BIC = 12,650) or more components fits substantially better than\nthe covariate model without random effects AGE+SEX (BIC = 18,100). Second,\na large number of latent classes will be needed to fully represent omitted covariates\n(which in this model also include AGE and SEX).\nCan a mixed model provide a way forward, and are the measured covariates still\nimportant given the importance of latent class structure? Table 3b shows the results\nobtained by fitting the random effects model with fixed covariates AGE+SEX. With\none mass point component, the model corresponds to the fixed effects AGE+SEX\nmodel in Table 2. The minimum BIC is found at r = 6 classes; the deviance is\nsubstantially less than the deviance for r = 8 classes with no covariates. It appears\nthat the fixed effects provide additional explanatory power, and this becomes our\nfinal model. Removal of AGE and SEX in turn produces a large significant change\nin deviance and the covariate model cannot be simplified.\nWe can interpret the final fitted model in two ways. We can treat the mass point\ncomponents as approximating an unknown multivariate distribution, and focus at-\ntention primarily on the covariates. As an illustration, Table 4 shows the estimates\nfor SciM.AGE for both the fixed effects model and the final random effects model,\nwith a reference category of school/university (Edu). We can see that as age in-\ncreases, the preference for scientific magazines compared to school/university as\na source of information increases--this is true for both fixed and random effects\nmodels, but the effects are attenuated for the random effects model. Other age\nparameters (not shown) show a relative preference decrease in the use of the inter-\nnet (WWW), and an increase in TV, newspapers (Press) and scientific magazines\nParameter estimates for SciM.AGE for fixed and random effects models:\n(a) Fixed effects model (b) Mixture random effects model\nRaw EM Corrected\nStandard standard standard\nAGE Estimate error Estimate error error\ncompared with school/university. Unadjusted and corrected standard errors [Aitkin\n(1994)] are given for the random effects model and we can observe that the uncor-\nrected and corrected standard errors are relatively close in this example.\nFrom the estimates of items.SEX (not shown), we can also conclude that the\npreference for both scientific magazines and the internet relative to school/univer-\nsity is significantly lower for females than for males.\nIt is also possible to proceed by treating the mass point components as latent\nclasses. Table 5 shows the estimated proportions of patterns ^\nqr (which are ob-\ntained directly from the algorithm) and the estimated proportions of respondents\nwhich are weighted averages of the posterior probabilities of pattern membership\nin each class (w kr), weighted by the proportion of respondents in each pattern.\nEquations (3) and (4) in the online supplement provide further details. Examining\nthe proportions of respondents, we see that class 6 is the largest class with just\nunder 29% of respondents, followed by class 3 with about 25% and class 1 with\nFigure 2 shows the estimated random effect components r for all items and all\nclasses (apart for the reference item J and class R which are set to zero) including\n95% confidence intervals based on the corrected estimated standard errors. The\nbars (jr) are half the log odds ratios comparing the extra effect of item j to\nthe reference item J (education) and for class r related to the reference class R\n(class 6).\nProportions in the six classes\nFIG. 2. Parameter estimates for r and 95% confidence intervals based on corrected standard\nerrors.\nIt can be seen, for example, that for class 1 the odds for TV and Radio are\nsubstantially lower than for Education compared to class 6 [TV: exp(-0.84 \u00b7 2) =\nEducation are about 1.5 times higher and for WWW 2.1 times higher than in class\nFigure 3 shows, for males and for females, the plotted worths against age for\neach of the six sources of information, for two of the six latent classes. We see that\nthe two classes represent different preference patterns in the data. Class 6 repre-\nsents a large subpopulation who prefer to obtain most of their scientific information\nfrom nontext and nonscholarly sources. For all age groups and for both males and\nfemales, TV is the most preferred source, with radio the second most preferred\nand increasing in preference with age. Class 1, in contrast, represents a smaller\nsubpopulation which prefers academic sources of information over more popular\ninformation sources. In this class, for all but the youngest age group, scientific\nmagazines and school/university sources rank in the top two places (with scientific\nmagazines winning out over school/university for males but not for females). For\nthe youngest age group, the school/university followed by the internet are preferred\nfor both males and females. Class 3, the second largest group (not shown), shows a\nlatent class which is similar to class 6 but with a different second preference. TV is\nstill the most preferred source, followed by newspapers and the radio for the three\nolder age groups. For the youngest age group, radio declines in preference and the\nthird preferred source becomes the internet for males and school/university for fe-\nmales. In terms of the other classes which are not displayed, classes 4 and 5 also\nhave TV in first place, but with different orderings of other sources in other places.\nFIG. 3. Item worths by age and gender for two extreme latent classes.\nClass 2 (7%) prefers school/university as the most preferred source of information\nbut with TV in second place.\n7.2. Analysis of class membership. It is to be expected that relevant variables\nnot included in the model are absorbed in the latent classes. This relates to variables\nwhich are (i) known but for various reasons not accounted for (e.g., variables with\nmany categories making computation unfeasible or impossible) and also to (ii)\npossibly unknown sources of variation. In the Eurobarometer survey, for example,\nthere is a complex five-level clustering design of households within address clus-\nters within PSUs within urbanization and administrative region strata and within\ncountries. While some of these variables are present in the data set, others are not.\nIn addition, each country has used a different coding scheme for determining de-\ngree of urbanization. This means that a full multilevel analysis taking account of\nall design components is not possible. However, it could be argued that the most\nimportant strata are degree of urbanization and country, and these two levels would\naccount for most variability within the clustered sample. We therefore examine the\neffect of these two variables below.\nTo evaluate the effect of known variables, a post-hoc analysis may be performed\nby analyzing their association with the respondents' class memberships. Two ap-\nproaches are possible which use different definitions of class membership. We\nillustrate using two covariates not in the model but which are used in the sample\ndesign--degree of urbanization and country. For degree of urbanization, we adopt\na common three-level categorization which is consistent across countries. We use\n15 countries rather than 17 for this investigation, combining East and West Ger-\nmany (D), and Great Britain and Northern Ireland (GB). The remaining countries\nare labeled by their international licence plate country code.\nThe first method uses the posterior probabilities of class memberships to con-\nstruct the expected number of respondents in each class within each category of the\ncovariate of interest [see equation (4) in the online supplement]. We present two\nmosaic plots [Hartigan and Kleiner (1984)] which cross-classify the expected class\nmembership with degree of urbanization and with country (displayed in Figure 4).\nIn examining the degree of urbanization mosaic plot, it can be seen that the\nproportion of rural residents are underrepresented in class 1 and have a higher\nproportion in class 6 as opposed to residents of large cities. The country mosaic\nplot shows much greater variability. Respondents in Italy, for example, are far less\nlikely to belong to latent class 6 and far more likely to belong to latent class 1.\nIn contrast, respondents in Austria and Germany are far more likely to belong to\nclass 6. One explanation for this variability might be the varying quality of TV\nFIG. 4. Mosaic plots showing expected class membership and degree of urbanization (left) and\ncountry (right).\nFIG. 5. Plot of observed log-odds ratios for class 1 against class 6 for assigned class membership\nclassified by country and degree of urbanization.\nacross countries in broadcasting science information, coupled with a large number\nof excellent science magazines in Italy.\nA second approach, as mentioned in Section 6, assigns the respondents (who\nbelong to covariate set k and have response pattern ) directly to the class with the\nhighest posterior probability maxr(w kr). Following this procedure, we can obtain\na response variable with categories according to the classes and investigate the\neffects of some variables not included in the model via a multinomial regression\nmodel. We then form a cross-classified table of assigned class by country and by\ndegree of urbanization to evaluate possible influences due to part of the multistage\nsampling design. By fitting a multinomial model, we found a strong interaction\neffect between degree of urbanization and country.\nThis interaction can be visualized by examining observed log-odds ratios in the\nconstructed table. Figure 5 shows the observed log-odds ratios comparing classes\n1\u00ad6 for the 15 countries both for rural areas and for large cities. We can notice,\nfor example, that Italy has a positive log-odds ratio for both rural areas and large\ncities, indicating the relative underrepresentation of class 6 is true both for urban\nand rural locations. In other countries such as Finland, class 6 is more prevalent in\nrural areas, and class 1 in large cities.\n8. Discussion. Random effects models are often necessary in models for\nranked and paired comparison data but the multivariate nature of random effects\nin these type of models adds complexity. NPML methods of the type described\nhere provide a suitable way forward. The models give greater insight into the na-\nture of subgroups in the data set, but interpretation can be problematic because of\nthe number of parameters being estimated. We recommend the use of graphical\ndisplays on the worth scale.\nDiagnostic checks are important for these models. It is important to examine\nthe solution to check both that there are no overly small latent classes, and also\nthat the parameter estimates for each mass point component are sufficiently sepa-\nrate [McLachlan et al. (1999)]. Posterior probabilities of component membership\ncould also be examined in relation to other covariates not in the model to aid inter-\npretation of the latent classes [Kamakura and Mazzon (1991)].\nThe basic model described in this paper can be extended in various ways:\n\u00b7 Extensions to models which allow varying coefficients with latent classes is\nstraightforward. This model will allow for different respondent covariate effects\nwithin each latent class. These random coefficient models can be fitted by al-\nlowing interactions between the latent class group and the covariates, but with\nthe disadvantage of a sizeable increase in the number of model parameters.\n\u00b7 It is possible to extend the model to allow for tied ranks. Such data will lead to an\nunderlying ordinal paired comparison model [Dittrich, Hatzinger and Katzen-\n\u00b7 Item covariates could also be included along the lines suggested by Dittrich,\n\u00b7 The model presented here needs to be extended to allow explicitly for more\ncomplex sampling designs and other multilevel structures which may be present\nin the data. Further research is needed on this topic.\n\u00b7 Finally, incomplete or partial rankings could also be taken account of. This\nwould lead to a paired comparison model which allows for missing comparisons\nwithin a response. The basic idea here is to extend the set of response patterns to\ninclude patterns where certain comparisons are not available. For partial rank-\nings a composite link approach to this problem has been described in Dabic and\nHatzinger (2009); the general case for paired comparisons with missing data is\ntreated in Dittrich et al. (2010). Unfortunately, the number of response patterns\nmay increase dramatically and, thus, this approach is computationally feasible\nonly for a small number of items.\nIn conclusion, our approach provides a methodology which allows the modeling of\nranked data in many applied areas, allowing covariates to be taken into account and\nlatent classes to be detected. The underlying paired comparison approach provides\nan attractive alternative to the choice based models dominant in the literature.\n"
}