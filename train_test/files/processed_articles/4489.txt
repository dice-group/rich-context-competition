{
    "abstract": "Abstract\nThe Council for the Accreditation of Educator Preparation (CAEP) Standards requires educator preparation programs\n(EPPs) to ensure instruments used to assess their candidates are both valid and reliable. Due to size and limited financial\nresources, this task may be challenging for some EPPs. In an effort to address CAEP's expectations, 26 EPPs in one state\nformed a collaboration to develop and implement an instrument for use during student teaching, and then conducted\nanalyses of its data to determine the validity and reliability. This article uses a case study methodology to investigate the EPPs'\nmotivations for participating in the collaboration, and the benefits, challenges, and learning that resulted from participation.\nThe findings, principally related to aspects of individual program improvement, have implications not only for EPPs pursuing\nCAEP accreditation but also for any higher education institutions interested in collaborative assessment development.\n",
    "reduced_content": "journals.sagepub.com/home/sgo\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of\nthe work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nArticle\nWithin the field of educator preparation, there have been dis-\ncussions about the possibilities afforded by conducting large-\nscale research in a variety of institutional contexts\n(Cochran-Smith & Fries, 2005; Liston, Whitcomb, & Borko,\nbecause such research has not been extensively pursued,\nthere are few models to provide guidance for multi-institu-\ntional collaborations. Knowing collaboration among organi-\nzations is motivated by both internal and external factors\nhaps not surprising that aspects of the 2013 Council for the\nAccreditation of Educator Preparation (CAEP) Standards\n(namely, a call for the development of valid and reliable\ninstruments for use in educator preparation) have inspired a\nmulti-institutional collaboration. Within this article, we\ndescribe the findings of a case study exploring the motiva-\ntions, benefits, challenges, and learning that occurred as part\nof a collaboration among 26 educator preparation programs\n(EPPs) in Ohio and the potential implications for institutions\nthat are interested in engaging in collaborations for accredi-\ntation or other purposes.\nMotivation for Collaboration\nIn 2013, CAEP approved a set of standards for EPPs prepar-\ning candidates for initial teacher licensure (CAEP, 2015a).\nThe standards brought about revisions to the accreditation\nprocess, including redefinition of the qualities and character-\nistics of the evidence submitted during the accreditation\nreview. One of the six aspects of evidence specifies,\n\"Educator preparation providers are responsible for the\nvalidity and reliability of evidence they offer to demonstrate\nthat CAEP standards are met\" (CAEP, 2013, p. 4). In the\n2013 CAEP Accreditation Standards and Evidence docu-\nment, a version of the word valid (valid or validity) appeared\n36 times, and reliable (reliable or reliability) appeared 22\ntimes; the preponderance of these words emphasizes the\nimportance of this shift in requirements. One type of evi-\ndence is the data from assessment instruments (e.g., rubrics)\nused to evaluate teacher candidates' performance on course-\nwork and field/practicum experiences. Thus, EPPs are now\nrequired to document evidence supporting the validity and\nreliability of assessment instruments used for evaluation of\nBecause establishing the validity and reliability of instru-\nments can require a significant investment of time and\n1The Ohio State University, Columbus, OH, USA\n2Ohio Dominican University, Columbus, OH, USA\nCorresponding Author:\nCarolyn Shemwell Kaplan, Office of Educator Preparation, College of\nEducation and Human Ecology, The Ohio State University, Columbus, OH\nEmail: shemwell.2@buckeyemail.osu.edu\nOne for All and All for One: Multi-\nUniversity Collaboration to Meet\nAccreditation Requirements\nCarolyn Shemwell Kaplan1, Erica M. Brownstein1,\nand Kristall J. Graham-Day2\n Keywords\ncollaboration, assessment, accreditation, educator preparation, CAEP\n2 SAGE Open\nresources (e.g., content experts and psychometricians;\nistic for each of the more than 700 CAEP accredited EPPs,\nespecially for institutions smaller in size and scope, to estab-\nlish true validity and reliability for self-developed instru-\nments used. To facilitate the creation of these instruments,\nwhile also supporting CAEP's mission to \"advance excellent\neducator preparation through evidence-based accreditation\nthat ensures quality and supports continuous improvement to\nstrengthen P-12 student learning\" (CAEP, n.d.), a group of\nfaculty and staff members from 26 colleges and universities\nin Ohio organized as the valid and reliable instruments for\neducator preparation programs (VARI-EPP) Project. Over\nthe course of 3 years, this group developed, implemented,\nand conducted analyses on a summative instrument to assess\nteacher candidates during their student teaching practicum:\nthe Candidate Preservice Assessment of Student Teaching\n(CPAST) Form. The authors served as the coordination team\nfor the project, overseeing planning and ongoing communi-\ncations with participating institutions. The work was guided\nby Freeman's (1993) definition of collaboration: \"When two\nor more people or organizations join forces over a long\nperiod of time to produce something neither can achieve\nalone\" (p. 33). The project was supported by limited funding,\nsupplied by Race to the Top, the state American Association\nof Colleges for Teacher Education (AACTE) chapter, and\nthe University Center for the Advancement of Teaching\n(UCAT) at the authors' university.\nKnowing the success rate of collaborative ventures is less\ndents) and contexts (public/private) on a limited budget was\nintimidating. To provide a framework for other institutions\nthat may wish to engage in a similar endeavor, we reviewed\nliterature on collaborations in higher education, and used the\nthemes we discovered as the conceptual framework for a\ncase study investigating the collaboration that occurred dur-\ning the VARI-EPP Project. Within this article, we begin with\na brief review of literature related to key factors that enable\ncollaborations in higher education, followed by a summary\nof the CPAST Form developed by the VARI-EPP Project\nteam, and a description of the development and implementa-\ntion process. Next, we present the findings of the following\nresearch questions and the implications of their findings:\nResearch Question 1: What were EPPs' motivations for\nparticipating in a statewide collaborative effort to develop\nvalid and reliable assessment instruments for educator\npreparation?\nResearch Question 2: What are the benefits and chal-\nlenges encountered by EPPs when engaging in a multi-\nuniversity collaborative effort?\nResearch Question 3: What learning occurred across\ninstitutions as a result of participating in the statewide\ncollaboration?\nLiterature Related to Collaborations in\nHigher Education\nAccording to Kezar (2005), \"In order to be considered a col-\nlaboration, it is key that the process entail an interactive pro-\ncess (relationship over time) and that the groups develop\nshared rules, norms and structures which often become their\nfirst work together\" (p. 834). As previously mentioned, col-\nlaboration among organizations is motivated by both internal\nuniversities and P-12 schools, one potential external factor is\n\"the challenge of being asked to pursue both excellence and\nequity in a climate of accountability and competition\"\nuniversities, the \"climate of accountability\" is frequently\nestablished by the requirements of CAEP accreditation.\nAlthough collaboration can be a valuable tool to address such\nneeds and develop new knowledge, Kezar notes \"institutions\nare, generally, not structured to support collaborative\napproaches to learning, research, and organizational function-\ning\" (p. 832). In the last 20 years, literature describing univer-\nsity/collegecollaborations,consortiaefforts,andrecommended\nbest practices has become more prevalent (e.g., Andrews &\n& Blalock, 2006), including an article focusing specifically on\na collaboration among three teacher education programs that\n\"developed a common tool for formative and summative eval-\nAfter reviewing literature focusing on multi-institutional\ncollaborations in higher education, we found a dearth of\ninformation about collaborations intended to develop perfor-\nmance assessments to meet accreditation needs. Addressing\nthis lack of information is necessary because, as Eddy (2010)\nadvised, \"it is important to understand more about partner-\nships to discern the reasons for their frequent failures and to\nhighlight the structures and processes that promote success\nand sustainability\" (p. 2). Based on our review of literature\nthat described collaborative endeavors in higher education,\nwe identified the following themes (or variations thereof)\nmentioned repeatedly as key factors necessary for collabora-\ntion: external pressures, mission/shared purpose, integrating\nstructures/resources, mutual benefit, networks/relationships/\ngovernance, trust, membership of collaboration, learning,\nand communication.\nKey Factors Enabling Collaboration\nCollaborations between institutions are complex because it is\nnot merely individuals collaborating to accomplish a com-\nmon goal, but rather individuals who are embedded within\n(and representatives of) an institution with its own norms,\nrules, and structures. External pressures (e.g., messages from\nexternal groups, such as CAEP) are a key component for\nmotivating collaborations because they create a strong ratio-\nnale for the need to engage in collaborative work. In fact,\nKaplan et al. 3\n\"without a compelling external argument for why collabora-\ntion is necessary, it is unlikely to occur\" (Kezar, 2005, p.\n847). Organizational incentives for collaboration include a\nshared purpose, shared resources, and mutual benefits.\nOnce a collaboration is formed, it is important it be driven\n\"shared purpose\" (Butcher et al., 2011). This mission may be\nmotivated by the external pressures inspiring the collaboration,\nand creates common ground for the work to be completed.\nAnother foundational element necessary for collaboration\nin higher education is \"integrating structures\" (Kezar, 2005),\nExamples of integrating structures include formation of a\ncenter, creation of a central collaboration unit, and support-\ning technology systems (Kezar, 2005). Similarly, Butcher\net al. (2011) identified resources as \"the financial and human\nassets that partners contribute to a given project to ensure its\nFinally, it is also important for the collaboration to be\n\"mutually beneficial\" (Duffield et al., 2013) for it to be sus-\ntainable. For this reason, Strieter and Blalock (2006) speci-\nfied that collaborations should \"provide benefits to members\"\n(p. 2) and \"define strategies to eliminate/minimize discrep-\nancies in effort and benefits\" (p. 3). These benefits, like\nrewards systems (e.g., tenure and promotion; Kezar, 2005),\ncan increase the appeal of participation in the collaboration.\nAlthough the key factors for collaboration described above\nare organizational in nature, there are other key factors more\nclosely associated with interpersonal interactions.\nThe first interpersonal key factor necessary for collabo-\nration is \"networks\" (i.e., relationships between peers) that\nare established at the beginning of a collaboration with a\ncore group of people genuinely dedicated to the success of\nthe work. Throughout a collaboration, networks of individ-\nuals work together to solve problems and create intellectual\nresources as a way to overcome challenges that could\npotentially decrease collaboration (Kezar, 2005). The\nimportance of these \"relationships\" was frequently high-\nlighted in Duffield et al.'s (2013) description of their col-\nlaborative partnership. Similarly, Strieter and Blalock\n(2006) advised the importance of \"[establishing] and [nur-\nturing] trusting working relationships between collabora-\ntors\" (p. 2). Duffield et al. extolled the importance of a\ngovernance structure to manage the relationships (e.g.,\nspecifying the partners' roles within the collaboration,\nwhich should be \"based on characteristics and skills\";\nA second key factor for collaboration is that networks and\nrelationships are developed through \"trust,\" which Andrews\nand Lind (2007) noted as \"a key element of success\" (p. 2) in\ncollaborations. However, networks and relationships cannot\ngo unmanaged, as Duffield et al. (2013) spoke of the impor-\ntance of building \"trust\" among collaborative partners, and\nthe amount of time necessary to do so. Butcher et al. (2011)\nencouraged collaborative partners to \"relate on a basis of\ntrust\" (p. 36), and also identified collaborative leadership as\nan important principle:\n[Collaborative leadership] requires educative, relational, and\nevaluative strategies that involve all stakeholders. All need to be\nrepresented in the decision-making that occurs across\norganizations and all need to be aware of their capacity to\ninfluence the decision making. (p. 39)\nAthird key factor identified by multiple authors (Andrews &\nthe importance of the membership of the collaboration.\nSpecifically, Duffield et al. (2013) advised that \"team members\nneed to be carefully chosen because personal agendas or institu-\ntionally competitive interests that are not beneficial to all part-\nners can push partnership work off track and create conflict\" (p.\nmembers from as many diverse segments of the community and\ncompatible with your mission\" (p. 3), and Andrews and Lind\n(2007) encouraged the formation of \"collaborative . . . teams\nwith a variety of skills and skill levels\" (p. 2).\nTwo other key factors for collaboration were predominant\nin the literature: learning and communication. Although it\nhas been described in different ways, \"learning\" has been\nidentified as a key factor in collaborations. According to\nKezar (2005), \"learning\" refers to the idea that collaborators\nneed to be educated about \"the skills of collaboration\" (p.\n827) and \"the benefits of collaboration in order to motivate\npeople to conduct collaborative work\" (p. 847). In Butcher\net al. (2011), however, the authors advise that participants in\ncollaborations \"remain open to learning and change\" (p. 36)\nbecause,\ngiven that initiatives are often implemented to create new\nknowledge and new growth, it should be expected that those\ninvolved will develop and grow. There needs to be a willingness\nto learn on the part of all participants. (p. 38)\nFinally, \"communication\" is the key factor for collabora-\ntion that enables all of the other key factors to succeed. For\nexample, Andrews and Lind (2007) stated, \"Effective com-\nmunication is crucial\" (p. 2); Gottlieb et al. (1999) advised\nthat collaborators \"strive for open communication, flexibil-\nquently discussed the role and importance of communication\nin their collaborative partnership.\nThe aforementioned list of key factors of collaboration is\nnot exhaustive of all topics discussed in the literature.\nInstead, it reflects the most prevalent themes and those that\nresonated as most applicable to the collaborative VARI-EPP\nProject.\nSummary of the VARI-EPP Project\nAs previously described, the VARI-EPP Project was com-\nprised of a group of faculty and staff members from\n4 SAGE Open\n26 colleges and universities in Ohio. They developed and\nimplemented the CPAST Form, an instrument to assess\nteacher candidates during their student teaching practicum.\nThe authors served as the coordination team for the project,\nand the project was supported by limited funding from exter-\nnal and internal sources. Within this section, we summarize\nthe content of the CPAST Form, and describe the develop-\nment and implementation process undertaken by the VARI-\nEPP Project.\nStructure of the CPAST Form. The CPAST Form is a summa-\ntive performance assessment instrument developed and\ntested over the course of 3 years. It is a rubric with 21 perfor-\nmance criteria, designed to assess pedagogical skills in four\ncategories (Planning for Instruction and Assessment, Instruc-\ntional Delivery, Assessment, and Analysis of Teaching) and\ndispositions in three categories (Professional Commitment\nand Behaviors, Professional Relationships, and Critical\nThinking and Reflective Practice) that teacher candidates\nacross disciplines are expected to demonstrate. The rubric is\naligned to multiple sources including the CAEP standards,\nthe Interstate Teacher Assessment and Support Consortium\n(InTASC) standards, and the Ohio Standards for the Teach-\ning Profession (Ohio Department of Education, 2005).\nDevelopment and implementation of the CPAST Form.The\nCPAST Form was developed based on multiple widely\naccepted frameworks that are the crux of a preservice curricu-\nlum focused on effective pedagogy. First, the Form develop-\nment team examined the Danielson Framework (Danielson,\n2011) to address the following teaching domains and compo-\nnents: (a) Planning and Preparation, (b) the Classroom Envi-\nronment, (c) Instruction, and (d) Professional Responsibilities.\nNext, the Form development team considered High Leverage\nTeaching Practices, which include practices used by teachers\nthat are most likely to result in student learning (Ball, Sleep,\nBoerst, & Bass, 2009). Finally, the development team studied\nexisting performance assessments such as edTPA (Stanford\nCenter for Assessment, Learning, and Equity [SCALE], n.d.-\na) and the Ohio Teacher Evaluation System for further insight\ninto performance criteria selection.\nIn Year 1, faculty and staff members from the authors'\ninstitution developed the first version of the rubric, which\nwas implemented with more than 350 teacher candidates in\nmultiple content areas. The following year, the initial rubric\ndeveloped at the authors'institution provided a starting point\nfor the collaborative effort undertaken when volunteers from\nEPPs at eight public and private institutions of higher educa-\ntion (IHEs) from across the state participated in the develop-\nment of a similarly structured performance assessment based\non research and best practices in the field of teacher educa-\ntion (Ball & Forzani, 2010; Council of Chief State School\nMarzano, Pickering, & Pollock, 2001; SCALE, n.d.-a,\namong others). This second version of this rubric (the first\nCPAST Form) was piloted with the teacher candidates from\nthe eight institutions who participated in the CPAST Form\ndevelopment, and validity and reliability analyses were con-\nducted with the data. The findings from these analyses were\nused to revise the CPAST Form for the third year of the proj-\nect. Faculty and staff members from 10 IHEs were involved\nin the CPAST Form revision, which was also vetted by con-\ntent experts (including a P-12 teacher and a teacher educator\nexternal to the project). The Form was then implemented\nwith teacher candidates at 26 IHEs, allowing for greater\npower in the second round of validity and reliability analy-\nses. All participating institutions were provided with a\n90-min online training (including an assessment). The train-\ning was mandatory for supervisors and optional for cooperat-\ning teachers, and was designed to provide instruction about\nhow to use the CPAST Form to score teacher candidates. At\nthe conclusion of the academic year, all participating institu-\ntions received their EPPs and the statewide mean scores by\nrubric row, which could then be submitted to fulfill accredi-\ntation requirements. Table 1 describes the context of the par-\nticipating institutions and their level of involvement in the\ncollaboration.\nMethod\nAccording to Brown and Rodgers (2002), a case study is\n\"[an] intensive study of the background, current status, and\nenvironmental interactions of a given social unit: an individ-\nual, a group, an institution, or a community\" (p. 21). This\nstudy employed case study design (Yin, 2009) to examine\nthe \"environmental interactions of a given social unit\"\ninteractions of the institutions participating in the VARI-EPP\nProject. The multi-institutional collaborative effort of devel-\noping and implementing the CPAST Form served as a revela-\ntory case because \"the descriptive information alone [was]\nCase Study Participants\nFor this case study, participants were obtained through pur-\nposive sampling, which is commonly used when pursuing\ncase study research in special populations (Bernard, 2006).\nIn this case, the special population is comprised of the one\nfaculty and/or staff member at each institution who served\nas the liaison on their campus for the VARI-EPP Project\nand implementation of the CPAST Form (i.e., the person\nwho principally communicated with the project coordina-\ntion team [the authors] to ensure implementation). As indi-\ncated in Table 1, 16 of the liaisons (11 from private\ninstitutions and five from public institutions) participated\nin this case study.\nIn Year 1, faculty and/or staff members from eight EPPs\nparticipated in the initial development of the CPAST Form\n(Development Team 1) and implemented the Form at their\nKaplan et al. 5\ninstitutions. In Year 2, those same institutions plus two addi-\ntional EPPs participated in the process of revising the CPAST\nForm (Development Team 2). Following the revisions in\nYear 2, 24 EPPs around the state ultimately implemented the\nCPAST Form with some or all of their student teachers\n(Implementation Team).\nData Collection\nWhen designing this study, the goal was to collect data that\nwould enable the development of a descriptive case study\nreport (Merriam, 1998). Data were collected through mul-\ntiple procedures to enhance the data credibility (Baxter &\nJack, 2008). Specifically, this study employed method-\nological triangulation (Stake, 1995), that is, \"using multi-\nple methods to confirm emerging findings\" (Merriam,\ngroups, and semistructured interviews. The questions for\neach were developed based on the themes we noted repeat-\nedly as key factors necessary for collaboration: external\npressures, mission/shared purpose, integrating structures/\nresources, mutual benefit, networks/relationships/gover-\nnance, trust, membership of collaboration, learning, and\ncommunication.\nSurvey. A five-question qualitative survey was distributed to\nthe case study participants via Qualtrics. The survey ques-\ntions asked participants to describe the following: their EPPs'\nmotivation for participating in the VARI-EPP Project, the\nrole of their EPP's leaders in adopting and implementing the\nCPAST Form, external and internal pressures contributing to\nthe EPP's involvement in the project, and any additional\ninformation they would like to provide about their EPP's par-\nticipation in the VARI-EPP Project. As shown in Table 1,\nTable 1. EPPs Developing and Implementing CPAST.\nDevelopment\nteam\nImplementation\nteam\nUrban, suburban,\nrural\nNumber of\nFocus\ngroup Interview\nPrivate institutions\n X Urban A Small X X \n X Urban B Medium X X \n X Urban C Medium X X \n X Urban D Medium \nX X Urban E Large \n X Suburban A Small X X \n X Suburban B Small X X \n X Suburban C Medium \n X Suburban D Medium X X\n X Suburban E Large X X \n X Suburban F Large X X \n X Rural A Small \n X Rural B Small \n X Rural C Small X X \nX Rural D Small \nX Rural E Small X X\n X Rural F Medium X\nPublic institutions\n X Urban F Large \nX X Urban G Large X X \nX X Urban H Large X\nX X Urban I Large X X \nX X Urban J Large X\nX X Urban K Large NA NA NA\nX X Urban L Large \n X Suburban G Large \nX X Suburban H Large X X \nNote. \"Number of completers\" data provided by the Ohio Department of Higher Education (2015), which represents the Title II data from 2013 to 2014.\nTo retain anonymity of the institutions, the number of completers has been classified as small (<50), medium (51-100), and large (>100). The geographical\nclassification data was obtained from the Ohio Department of Education (2013). \"NA\" is listed for Public Urban K because it is the authors' institution.\nEPP = educator preparation program; CPAST = Candidate Preservice Assessment of Student Teaching.\n6 SAGE Open\nrepresentatives from 13 institutions completed the survey\n(from 10 private and three public institutions).\nFocus groups. Focus groups are \"widely used to find out why\npeople feel as they do about something or the steps that peo-\nple go through in making decisions\" (Bernard, 2006, p.\n233). Three focus groups of three to five participants each\nwere conducted via web conferencing at the conclusion of\nthe third year of the project. Following the methods pro-\nvided by Krueger (1998), the researchers led the focus\ngroups and posed questions related to the case study partici-\npants' perceptions of the benefits and challenges experi-\nenced by each EPP when participating in the collaboration,\nand the supports and resources that were available, or cre-\nated, to participate in the project. The focus groups were\naudiorecorded and selectively transcribed. Representatives\nfrom 11 institutions (eight private and three public) partici-\npated in a focus group (Table 1).\nSemistructured interviews.Using a list of researcher-devel-\noped interview prompts, and interview strategies and tech-\nniques suggested by Charmaz (2001), Kvale and Brinkmann\nengaged in individual, approximately one hour semistruc-\ntured interviews via telephone with five participants (Table\n1), two of whom had been highly involved in the CPAST\nForm project from its inception (both from public institu-\ntions), and three of whom were involved in only the imple-\nmentation stage (all from private institutions). The questions\nfor these interviews were drafted based on themes that arose\nfrom the focus group discussions and survey responses. The\ninterviews were audiorecorded and selectively transcribed.\nData Analysis\nBecause \"the process of data collection and analysis is recur-\ncase study research, analysis was ongoing throughout the\ndata collection procedures. For example, once surveys were\nreceived, they were analyzed to inform the next steps in the\ndata collection process (i.e., drafting appropriate questions\nfor the ensuing focus groups and semistructured interviews).\nData source triangulation was used throughout the data anal-\nysis process, in an attempt to corroborate and replicate find-\nings across sources (Miles & Huberman, 1994). First, the\ndata sources were analyzed using categorical construction\n(Merriam, 1998). The goal of this type of analysis was to\nidentify themes that reflected recurring patterns found in the\nunits of data (Merriam, 1998), which in this study included\nkey words and sentences from the survey responses, focus\ngroup transcriptions, and semistructured interviews. The key\nwords and sentences were organized into categories using\nthe constant comparative method (Merriam, 1998).\nClustering (i.e., \"clumping together things that `go together'\nby using single or multiple dimensions\"; Miles & Huberman,\nries and create the case study database (Yin, 2009).\nLimitations\nThere are two principal limitations to this study. The first is\ndata were collected from an emic viewpoint; that is, the\nresearchers were part of the collaboration and therefore col-\nlecting data from other partners. An etic viewpoint (i.e., data\ncollected from someone who was not participating in the col-\nlaboration) may yield different findings. The second limita-\ntionisthatonlyasampleofthe26institutionsthatparticipated\nin the development and/or implementation of the CPAST\nForm also participated in this case study. Responses from all\nparticipating institutions would have yielded more thorough\ndata. However, the 16 case study participants represented\nboth public (five) and private (11) institutions in urban\n(seven), suburban (six), and rural (three) contexts.\nResults\nThe results of the analysis of the survey responses and focus\ngroup and interview transcripts are organized below by the\nthemes of the study's research questions:\nResearch Question 1: What were EPPs' motivations for\nparticipating in a statewide collaborative effort to develop\nvalid and reliable assessment instruments for educator\npreparation?\nResearch Question 2: What are the benefits and chal-\nlenges encountered by EPPs when engaging in a multi-\nuniversity collaborative effort?\nResearch Question 3: What learning occurred across\ninstitutions as a result of participating in the statewide\ncollaboration?\nMotivations for Participation\nThe data revealed there were three separate, yet interrelated\nmotivations for institutions' participation in the VARI-EPP\nProject including the necessity of revisions/updates to their\ncurrent instruments for evaluating student teaching, the exter-\nnal pressure of accreditation requirements, and the increased\nresources afforded by implementing the CPAST Form.\nNeed for revisions/updates to current instrument.Of the 16\ninstitutional representatives who participated in this case\nstudy, 11 identified their institution's need for a new student\nteaching assessment instrument as a motivation for partici-\npating in the development and/or implementation of the\nCPAST Form. The reasons they were seeking a new instru-\nment ranged from\nnoticing . . . we weren't seeing a lot of differentiation in the\nranking of some of our students, and it seemed we needed to\nKaplan et al. 7\nhave an overhaul of what was the purpose of assessing our\nstudent teachers . . . and we thought this would be a way to\njumpstart the conversation (Private Rural D)\nto a need for \"student teaching forms that were more aligned\nwith educator standards\" (Private Suburban F) and/or the\nneed for a \"valid and reliable\" instrument (mentioned by\nseven institutions: four private and three public) for student\nteaching. It is important to note the need for a revised instru-\nment (especially one that was \"valid and reliable\") was\npotentially due to the CAEP accreditation requirements for\nsuch instruments.\nAccreditation requirements. The second most frequently men-\ntioned motivation for participating in the CPAST Form\ndevelopment and implementation process was the need to\ncomply with CAEP requirements. Nine institutional repre-\nsentatives explicitly mentioned \"CAEP\" or \"accreditation\"\nas a motivator for involvement in the project. Specific com-\nments included the following: \"First of all, CAEP was at the\nuppermost of our minds\" (Private Suburban A); \"We are all\nlooking for valid and reliable instruments that CAEP will\naccept\" (Public Suburban H); and \"We were trying to get\nahead of the CAEP situation, and the idea of having valid and\nreliable instruments is huge\" (Public Urban I).\nIncreased resources.Finally, six of the participating institu-\ntions (five private and one public) identified the resources of\nthe collaborative CPAST Form project as a motivator for par-\nticipating. Meaning, by participating in the development of\nthe Form and providing data for the statistical analyses, they\nwere able to accomplish a task collaboratively that would\nhave been incredibly challenging, if not impossible, to\naccomplish individually. The institutional representative\nfrom Private Suburban A noted, \"Our institution is small,\ntherefore we did not have the resources to develop the valid-\nity and reliability of any instrument in the same way we can\ndo this as a collaborative effort.\" The representative from\nPrivate Urban Institution B corroborated this comment in a\nseparate focus group: \"We are a small university so taking\nthis on ourselves would be difficult, so having the support\nand collaborative efforts to arrive at a well-researched instru-\nment is important.\" Finally, the representative from Private\nSuburban D acknowledged in an interview:\nI just think that it would take one of the bigger schools to be able\nto reach out and make something like this happen. I don't think\nany of our smaller universities would be able to pull such an\nextensive piece of research off, and be able to create something\nthat all of us could use for CAEP.\nBenefits of Participation\nGiven the wide variety of the contexts and needs of the EPPs\nthat participated in the VARI-EPP Project, the institutional\nrepresentatives who participated in the survey, focus group,\nand interviews identified a variety of benefits they experi-\nenced from participating in the collaboration. The benefits\ndescribed here are those stated most frequently by the institu-\ntions and included having an identical form at multiple insti-\ntutions, and the positive impacts of the Form and its\nimplementation processes within the individual EPPs.\nIdentical form across institutions. The representative from Pri-\nvate Suburban B stated, \"I believe a statewide form to evalu-\nate student teachers is best for all,\" and her belief was\nsupported by comments from other institutions who identi-\nfied unpredicted benefits they found when implementing the\nsame student teaching form as other institutions in the state.\nFor example, the representative from Public Urban G men-\ntioned, \"We felt strongly that it would be a benefit to our\ncandidates, our faculty, and our school partners if we were\nusing the same instrument that other institutions would be\nusing.\" The Private Suburban F representative provided spe-\ncific examples of what those benefits were when stating the\nfollowing:\nConsistency is kind of key, so . . . if we have transfer students\nwho come in from Public Urban H, or another institution, and if\nthere are several institutions using the same form across the\nboard, it kind of makes it a little bit easier for those students\ncoming in.\nIn a separate interview, the representative from Public Urban\nH (who is located in the same region of the state as Private\nSuburban F) made a similar observation:\nCooperating teachers loved the idea that [the Form] could be the\nsame form for multiple institutions. Because we've got Private\nSuburban F, we've got Private Suburban C . . . we've got so\nmany people up in our area. Public Urban J bumps up against us.\nPublic Urban L often. Public Urban I. I mean, that's not\nuncommon, to have all of our [P-12] schools having to deal with\npeople from [multiple institutions]. And so when [P-12 school\npartners] said, \"Oh my gosh. We can see a similar form even\nthough the [CAEP Specialized Professional Association]\nassessments might be different,\" they loved it. Any place where\nyou've got institutions that tend to bump up because of location,\nI think there's great benefit for that . . . if we really want to be\nable to share that resource of our P-12 partners, instead of having\nexclusiveness . . . I think that would break some of the barriers\ndown for us as an institution.\nIn another focus group, Private Urban B and C noted that\nthey shared some supervisors between them, and also with\nPublic Urban F (i.e., supervisors were employed part-time\nby multiple institutions). Therefore, the continuity of forms\nacross institutions enabled the supervisors to become\nCPAST Form experts and benchmark scores, even across\ninstitutions. In sum, using an identical form across institu-\ntions provided benefits for students/candidates, P-12 part-\nner schools, and supervisors who are employed by multiple\ninstitutions.\n8 SAGE Open\nForm impact on individual programs. Two institutional represen-\ntatives acknowledged one benefit of participating in the col-\nlaborative project was being able to \"to see what we're doing\nin comparison to other institutions across the state\" (Private\nSuburban F), and \"see best practice, and get a better feel of\nwhere do we sit in the continuum of what's going on across the\nstate\" (Public Urban H). Because the Form was \"designed for\nthe profession, by the profession\" (SCALE, n.d.-b), \"best\npractices\" from individual institutions on the Development\nTeam were incorporated into the CPAST Form content and\nimplementation process. As a result, some institutional repre-\nsentatives mentioned the CPAST Form content and implemen-\ntation process positively affected other assessments and\nprocesses in their program. For example, at three institutions\n(privates Urban B, Rural C, and Suburban D), the \"Disposi-\ntions\" section of the CPAST Form was used to inform revi-\nsions of dispositional assessments used earlier in their\nprograms. The representative from Private Rural C stated,\nWe started using [the Dispositions section of the Form] with\nsome of our clinical courses . . . so students . . . start to have a\nsense of the professionalism that's required . . . in a way that's\nconsistent of how they're going to be assessed down the road.\nPrivate Suburban D noted they were now beginning to \"look\nat the dispositions [as] more of a ladder . . . to see if we can\nmove the dispositional part throughout the whole program,\"\nwhile Private Urban B stated, \"We decided to rewrite our\ndispositions as a result of looking at the dispositions of the\n[CPAST Form]; that was a definite benefit.\"\nAnother program impact explicitly noted by four institu-\ntions was the requirement for the formative midterm and final\nsummative Three-Way Conferences (i.e., two meetings of the\ncandidate, university supervisor, and cooperating teacher\nwhere each used the CPAST Form to evaluate the candidate's\nperformance before the meeting, and then used the meetings to\narrive at a consensus score for each row). In one case (Private\nUrban A), the requirement was the impetus to implement such\na process: \"I had never done a Three-Way Conference. It was\nsomething I was always wanting to try, so this gave me the\ncatalyst to do that and I see lots of good benefits.\" The institu-\ntional representation from Private Rural F noted,\nWe had a lot of favorable comments on the Three-Way\nConferences. And while we used to always encourage them, we\nfelt like there's a little more pressure this year to go ahead and\ndo [them], because that was specifically part of the [CPAST\nForm] process, and that ended up being very beneficial. We got\na lot of positive comments from our public school mentors.\nHearing more from the supervisors, the students, even though\nstudents were uncomfortable, they felt that it was good to hear\nfrom both mentor and supervisor. That was a positive, a benefit\nfor our EPP as well.\nThe Three-Way Conference was also a brand-new process for\nthe EPP at Private Suburban D, whose representative said, \"It's\na benefit for everybody, because then they definitely [talk]\nabout the rubric a little bit more, to understand it. Because\nthere's some parts, that I'm sure [student teachers] don't really\nunderstand, not being out in the field that long.\" Similarly, the\nPrivate Rural C representative mentioned the benefits for\ninvolving the candidates in the assessment process, \"We really\ndid like the fact that the student was included in the process,\nand it's really helped to open their eyes to the depth of areas\nthat they need to be cognizant of becoming more proficient in.\"\nChallenges of Participation\nAlthough the institutional representatives were largely posi-\ntive about the experience of participating in the collaborative\nCPAST Form development and implementation process, it is\nimportant to note \"every rose has its thorn\" (Michaels,\nDeVille, Dali, & Rockett, 1988), and the process of imple-\nmenting the CPAST Form was not without challenges. As\nwith the benefits, the challenges were varied, depending\nupon the contexts of the individual institutions. For example,\nthree institutions mentioned they faced technological chal-\nlenges (either with distributing the training to supervisors or\ncollecting the data at the end of the study) when implement-\ning the CPAST Form. Two institutions noted difficulties\nimplementing the CPAST Form while also continuing to use\ntheir previous form. However, the one area where institu-\ntional representatives noted the most significant challenges\nwas in relation to communicating about the CPAST Form\nwith the cooperating teachers in the P-12 schools where the\nteacher candidates were placed.\nCommunication with cooperating teachers.Two institutional\nrepresentatives cited cooperating teacher confusion about a\nCPAST Form row titled \"Connections to Research and The-\nory.\" This row is aligned to CAEP Standard 1.2 and assesses\nthe student teacher's inclusion and reflective articulation of\nteaching methods based on research and theory. In a focus\ngroup, the representative from Private Urban A reported \"the\ncooperating teachers wouldn't know if [the student teachers]\nwere using educational research or not.\" In a separate inter-\nview, the representative from Public Urban J mentioned that\nmentor teachers frequently asked questions about the\n\"research row.\" She said some expressed a belief that student\nteachers \"shouldn't be able to do that.\" The Public Urban J\nrepresentative then provided examples of the evidence the\nstudent teachers should provide to meet the expectations of\nthe row. Based on her experience, she advised that institu-\ntions should provide \"better framing [about the rubric] and\ncommunication . . . with the mentor teachers\" because\n\"things that I just took for granted because I understood the\nrubric, they didn't really seem to understand what it really\nmeant.\" Likewise, the representative from Private Suburban\nD believed \"the only part that is difficult is communication\nwith the cooperating/mentor teachers. I hope that this col-\nlaboration will enable us to include some information that\nKaplan et al. 9\nwill help them understand the use of the form.\" The repre-\nsentative from Private Suburban B also felt further commu-\nnication with mentor teachers was necessary because\nthe challenge we had was one particular cooperating teacher--\nthey spent probably an hour and a half during their [Three-Way\nConference] . . . and I don't think that's the amount of time that's\nnecessary. So I guess the challenge for me is to make sure the\ncooperating teacher has a better understanding of the time\ncommitment for this.\nAlthough these institutions identified a need for increased\ncommunication with cooperating teachers, other institutions\nhighlighted the challenge of communicating with cooperat-\ning teachers due to the time constraints. For example, the\nrepresentative from Private Rural C mentioned,\nWe had some challenges with everybody really understanding\n. . . we offered [the training] to the cooperating teachers, but\nnone of them took us up on that offer, and so there was some\nvariance in terms of them understanding [the Form] as well\nas the supervisors who completed the training. Private Rural\nF's representative expressed a similar challenge when stating\nit was \"a little hard to train all the . . . mentor teachers. It's a\nlittle hard to ask them to watch all those videos [in the train-\ning] and do all those hoops.\"\nLearning That Occurred From Participation\nThe institutional representatives indicated that learning\noccurred for candidates, supervisors, faculty, and cooperat-\ning teachers in the P-12 schools as a result of developing\nand implementing the CPAST Form across a variety of institu-\ntions. The representative from Public Urban I (who was\ninvolved in the Form development process) stated a \"real eye\nopener\"waswhenshelearned\"howmanydifferentapproaches\nthere were across the state to observation and assessing stu-\ndents in the field . . . and the variability of the things that we\nthink are important at the different institutions.\" The examples\nof learning spanned a variety of topics including a need for\nincreased internal communication, technology use, and super-\nvisor reflection, among others. However, learning articulated\nmost frequently by the institutions was in relation to how\nsupervisors, student teachers, and P-12 mentors were scoring\nthe student teachers' performance using the form.\nUse of \"Exceeds Expectations.\"When the CPAST Form was\ndesigned, the development team decided, consistent with the\nOhio Teacher Evaluation System, the highest level of perfor-\nmance (Three--\"Exceeds Expectations\") should be aspira-\ntional and reserved for the very highest performing student\nteachers. The Form's levels of performance were designed\naccordingly, and the Form training advised Form users that\n\"Exceeds Expectations\" should be used sparingly, and only\nfor those students demonstrating exceptional, or \"rock star,\"\nperformance in the classroom. This transition proved to be\nchallenging for supervisors, student teachers, and cooperat-\ning teachers in some programs and was educative for the EPP\nas a whole. When asked whether any learning occurred in the\nEPP as a result of using the CPAST Form, the representative\nfrom Private Suburban F noted,\nWe potentially learned that some of our supervisors are giving\nreally high ratings. Not that we don't think that our students are\nawesome and wonderful, but . . . they are still pre-service teacher\ncandidates and they are still learning, and they're still growing,\nbut they shouldn't necessarily be rock stars. And so we kind of\nlearned where our supervisors, and when it comes to evaluating\n[student teachers] as a professional, what [the supervisors] are\ndoing.\nMeanwhile, at Private Urban C, the supervisors learned that\nthe student teachers had inflated perspectives of their\nperformance:\nSome of our student teachers rated themselves a lot higher than\nthe supervisors and their [cooperating] teachers did . . . where\nwe thought, \"Oh they're meeting expectations,\" [the student\nteachers] thought they exceeded it. And so it was the basis of\nsome good conversation about, \"You're not fantastic, you're still\nlearning\" . . . that's an \"ah ha\" moment that several of the\nsupervisors, including me, had.\nThe EPP leadership at Public Urban I had a similar realiza-\ntion with their student teachers:\nThe other piece that we learned was that a lot of the students\ndidn't understand, or had a hard time with that midterm. Why\nthey didn't get that highest rating. Again, that was a learning\ncurve for us to talk about \"This is a snapshot of where you are in\nweek eight. You wouldn't be at the [Exceeds Expectations level]\nin week eight.\" But that was a conversation that was very\ndifficult for many student teachers. Especially our grad level\nstudents, and our 4.0 students. Because they're always used to\nhaving the highest score.\nFinally, Private Suburban D acknowledged there was tension\nwith the CPAST Form scale because the levels of perfor-\nmance on the previous instrument used for assessing student\nteachers\n[don't] quite synch with what the CPAST Form has. Like our\n\"three\" is sort of where we really want them to be by [the end of]\nstudent teaching . . . So I think it was just a little bit hard for our\ncooperating teachers and our supervisors to realize the difference\nbetween a \"three\" on the forms we've been using, isn't\nnecessarily the same as a three on the CPAST Form. So we had\nto address some of that.\nThese comments from the representatives of the VARI-EPP\nProject institutions demonstrated that participating in the\ncollaboration promoted learning by supervisors, candidates,\nand program leaders in their individual EPPs.\nDiscussion\nThis case study examined a collaborative effort among 26\ninstitutions (the VARI-EPP Project), and specifically\nexplored their motivations for participation, the benefits and\nchallenges of participation, and the learning that occurred\nwithin the individual institutions as a result of their participa-\ntion. Table 2 summarizes the principal findings for each of\nthe three research questions. These findings are representa-\ntive of some, but not all, of the themes we noted as key fac-\ntors necessary for collaboration according to literature about\nthe topic (i.e., external pressures, mission/shared purpose,\nintegrating structures/resources, mutual benefit, networks/\nrelationships/governance, trust, membership of collabora-\ntion, learning, and communication), and have implications\nfor multi-institutional collaborations and accreditation in the\nfield of educator preparation.\nRelationship of Findings and Key Factors for\nCollaboration in Higher Education\nThe formation of the VARI-EPP Project and the findings of\nthis study are representative of some of the key factors for\ncollaboration in higher education. First, participants noted\nthe \"external pressure\" (i.e., CAEP requirements) played an\nimportant role in motivating this collaboration. This \"exter-\nnal pressure\" partially shaped the \"mission/shared purpose\"\nof the Collaboration, which was to develop valid and reliable\nassessment instruments for EPPs. Eddy (2010) emphasized\nthe important role of \"common goals\" in establishing suc-\ncessful partnerships in higher education. For the partners in\nthe VARI-EPP Project, the need for a revised student teach-\ning form and to meet accreditation requirements created a\ncommon goal to motivate collaboration among these EPPs.\nIn addition, the \"integrating structures/resources\" were\nalso a factor that motivated the institutions' participation in\nthe project. By implementing the CPAST Form, the partici-\npating institutions received access not only to the CPAST\nForm and were required to implement processes such as the\nThree-Way Conference, but they also received a series of\ntraining modules about the use of the Form at the beginning\nof the academic year. At the end of the academic year, they\nreceived the means of each row for all teacher candidates\nwho were scored using the Form (which they could then use\nfor comparative purposes for accreditation reporting). These\ndata then served as one of the many \"mutual benefits\"\nafforded to VARI-EPP Project members.\nThe participants also mentioned two other \"mutual benefits.\"\nFirst, by using a Form and implementation process developed\nby a team of institutions based on scholarship from the field, the\nVARI-EPP Project participants were able to benefit from one\nanother's \"best practices,\" which then had positive influences\non some programs (e.g., the development of longitudinal dispo-\nsitions assessments). Second, participants noted using an identi-\ncal form across institutions was a \"mutual benefit,\" both for the\nEPPs who shared supervisors and for the EPPs who shared P-12\nschool partners; in both cases, the supervisors and cooperating\nteachers had only one form to learn and use.\nAlthough the data presented in this study did not directly\nreflect the themes of \"networks/relationships/governance,\ntrust, and membership of collaboration,\" the themes were a\nkey factor of the VARI-EPP Project. Specifically, it could not\nhave taken shape without the already formed network of\nquality EPPs within the state that had long-standing relation-\nships established on trust.\nThe key factor of \"learning,\" as defined by Butcher et al.\n(2011), was apparent in the case study data, where partici-\npants described the various types of learning that took place\non their campus as a result of participating in the\nCollaboration (e.g., a need for increased internal communi-\ncation, technology use, supervisor reflection, and how the\nForm was used to score). In the data presented here, the key\nfactor of \"communication\" emerged as a challenge; while\nthe case study participants noted that communication\namong the institutions during the Collaboration was posi-\ntive, multiple institutions learned that communication\nbeyond the immediate collaboration members (i.e., cooper-\nating teachers) of the VARI-EPP Project was less success-\nful, and efforts to share information more fully beyond the\nparticipating EPPs' representatives should be explored. By\nTable 2. Summary of Principal Research Findings.\nResearch question Summary of findings\nWhat were EPPs' motivations for participating in\na statewide collaborative effort to develop valid\nand reliable assessment instruments for educator\npreparation?\n\u00b7 Need for a revised student teaching assessment instrument\n\u00b7\nNeed to meet accreditation requirements (i.e., for valid and\nreliable assessment instruments)\n\u00b7\nAvailability of resources in collaboration\nWhat are the benefits and challenges encountered by\nEPPs when engaging in a multi-university collaborative\neffort?\nBenefits:\n\u00b7 Identical form used across multiple EPPs\n\u00b7\nPositive impact of form on individual EPPs\nChallenge:\n\u00b7 Communication with cooperating teachers\nWhat learning occurred across institutions as a result of\nparticipating in the statewide collaboration?\n\u00b7\nHow supervisors and candidates used the CPAST Form to score\nperformance\neducating P-12 partners about the CPAST Form as a best\npractice tool, the CPAST Form and implementation process\nprovide a way for EPPs to connect with P-12 schools, as\nexpected by CAEP Standard 2.\nImplications\nSchwarz (2015) reported that \"one finds very little resistance\namong the teacher educators in the United States\" (p. 105) to\nthe mandates imposed by organizations such as CAEP.\nIndeed, although the CAEP requirements have elicited vary-\ning levels of consternation in EPPs and may not be entirely\nfeasible and realistic as a whole in all contexts, there are\ncomponents of the Standards that have the capability to move\nthe profession forward. The VARI-EPP Collaboration would\nnot have been conceived, nor had the sense of priority (Kezar,\n2005) from participating institutions, without the external\npressure of the CAEP Accreditation requirements. As stated\nby the representative from Private Suburban A,\nWe would much prefer to use our own student teaching form.\nHowever, with CAEP demands for reliability and validity\nstudies that are concluded through research, it is more than our\ninstitution has time to do, so we are embracing the collaboration.\nAs shown by the data presented here, this collaborative\nproject had numerous benefits beyond merely developing\ninstruments that would produce valid and reliable data for\naccreditation purposes. The goal of the VARI-EPP Project\nwas to create a transformational partnership of institutions\n\"based upon genuine engagement and a focus on common\ngoals and mutual benefits\" (Butcher et al., 2011, p. 29), with\nthe hope the collaboration enables \"each of the member\ninstitutions to do more together than could be accomplished\nalone . . . an essential component of partnership\" (Duffield\nThe process of establishing an instrument with valid and\nreliable results for the purposes of accreditation was just\none component of the collaboration. Approaching this pro-\ncess as \"one for all and all for one\" reduced the workload\nfor all involved and provided enhanced results in a variety\nof contexts. For the VARI-EPP Project, the collaborative\nprocess of developing and/or implementing an instrument\ndesigned to yield valid and reliable results for accreditation\npurposes encouraged discussion and learning across EPPs\nthat improved other aspects of their programs (e.g., deeper\nreflection during Three-Way Conferences, and more con-\nsistent assessment of teacher candidates' dispositions\nthroughout the program). As noted by the institutional rep-\nresentative from Public Urban H, the VARI-EPP Project\nalso provided participating institutions with momentum\nand traction to implement other program improvements.\nShe described the process of participating in the VARI-EPP\nProject from its initiation as \"rolling the boulder up the\nhill,\" further elaborating,\nBy working as a team, it gave me the energy to be able to move\nit, first of all . . . I was just getting enough energy because it's not\nsomething that I'm going to be moving alone, because I think\nmoving it alone within my institution would have been at a\nsnail's pace . . . and even it felt like at one point it wasn't just one\nboulder, but we started moving multiple pieces up at different\nlevels, and addressing the [Specialized ProfessionalAssociation]\npieces, in different ways, and hearing where people were going\nwith that, and addressing the IT component of the integrity of\ngetting them into Tk20 or Taskstream. I think all of those things\nallowed for multiple pieces in my world to be moved at the same\ntime, and also gave me energy from outside of my institution,\nthat allowed for that momentum, and got me closer to tipping\npoints, where I'm not putting it up, that we're actually getting it\nto the point where we want it to be.\nHer comments support that when EPPs participate in a multi-\ninstitutional collaboration, there are benefits beyond those\nrelated directly to the task at hand.\nConclusion\nWithin this article, we have described the findings of a case\nstudy exploring the motivations, benefits, challenges, and\nlearning that occurred as part of a collaboration among 26\nEPPs in Ohio. The findings demonstrate that conducting col-\nlaborative instrument development may be accomplished if\nthere are common mission and values, by beginning on a\nsmall scale and with minimal funding. These findings have\nimplications not only for institutions addressing accredita-\ntion requirements but also for any institutions or programs\nthat may wish to engage in a collaborative effort for program\nenhancement. Plumb and Reis (2007) noted, \"Administrators\nneed to provide faculty with examples of collaborations that\nare already working, either from within the institution or\nfrom similar colleges and universities\" (p. 29). Therefore,\ncollaborations such as the VARI-EPP Project described here\nare much needed to inspire and perpetuate future multi-insti-\ntutional collaborations. With more than 1,500 individual\nEPPs that are public, private, large, small, urban, suburban,\nbrick and mortar, and/or online, there is a wealth of diverse\nwisdom in our profession, and uniting it in collaborative\nefforts will only help to move the profession forward.\n"
}