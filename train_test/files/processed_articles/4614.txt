{
    "abstract": "Abstract\nOnline social media are a perfect text source for stance analysis. Stance in human communication is con-\ncerned with speaker attitudes, beliefs, feelings and opinions. Expressions of stance are associated with the\nspeakers' view of what they are talking about and what is up for discussion and negotiation in the intersubjec-\ntive exchange. Taking stance is thus crucial for the social construction of meaning. Increased knowledge of\nstance can be useful for many application fields such as business intelligence, security analytics, or social\nmedia monitoring. In order to process large amounts of text data for stance analyses, linguists need interac-\ntive tools to explore the textual sources as well as the processed data based on computational linguistics\ntechniques. Both original texts and derived data are important for refining the analyses iteratively. In this\nwork, we present a visual analytics tool for online social media text data that can be used to open up the\ninvestigation of stance phenomena. Our approach complements traditional linguistic analysis techniques and\nis based on the analysis of utterances associated with two stance categories: sentiment and certainty. Our\ncontributions include (1) the description of a novel web-based solution for analyzing the use and patterns of\nstance meanings and expressions in human communication over time; and (2) specialized techniques used\nfor visualizing analysis provenance and corpus overview/navigation. We demonstrate our approach by means\nof text media on a highly controversial scandal with regard to expressions of anger and provide an expert\nreview from linguists who have been using our tool.\n",
    "reduced_content": "Article\nInformation Visualization\nReprints and permissions:\nsagepub.co.uk/journalsPermissions.nav\nivi.sagepub.com\nVisual analysis of online social media to\nopen up the investigation of stance\nphenomena\nKostiantyn Kucher1, Teri Schamp-Bjerede2, Andreas Kerren1,\nCarita Paradis2 and Magnus Sahlgren3\n Keywords\nVisual analytics, visualization, text visualization, interaction, time-series, stance analysis, sentiment analysis,\ntext analytics, visual linguistics, online social media, text and document data\nIntroduction\nThe vast amount of digital data available online pro-\nvides unprecedented opportunities for automated\nanalyses. For example, text data of all kinds make it\npossible for researchers in the field of linguistics to\nemploy a bottom-up approach to understand various\naspects of language: while the traditional way of man-\nual text investigation involved static corpora, linguists\nnowadays can analyze text data that reflect global\nevents and ongoing language evolution. The research\non specific language phenomena benefits from text\ndata collected from web sources such as online social\nmedia (Twitter, Facebook, blogs, forums, etc.). Those\n1Department of Computer Science, Linnaeus University, Va\n\u00a8xjo\n\u00a8,\nSweden\n2Centre for Languages and Literature, Lund University, Lund,\nSweden\n3Gavagai AB, Stockholm, Sweden\nCorresponding author:\nKostiantyn Kucher, Department of Computer Science, Linnaeus\n\u00a8xjo\n\u00a8, Sweden.\nEmail: kostiantyn.kucher@lnu.se\ntexts are typically created by multiple authors who are\nengaged in discussions or refer to each other's mes-\nsages in which they express their thoughts and\nopinions.\nThis presents an opportunity for researchers who\nare interested in stance analysis. Stance is a relatively\nbroad concept in linguistics related to (inter-)subjec-\ntivity expressed in text or human conversation, for\nexample, attitudes, feelings, perspectives, or judg-\nments. Note that stance is not just another concept for\nsubjectivity. It is beyond subjectivity in that the pro-\ncess of taking stance itself is evaluative and interac-\ntional. Stance could be viewed as a concept that\nincludes sentiment, certainty, and so on as its subcate-\ngories. Analyzing these subcategories leads toward bet-\nter understanding of stance.\nResearch on stance includes both theoretical efforts\n(related to the definition and the knowledge about the\nnature of this phenomenon) and practical efforts\n(related to collecting evidence and explaining the\nmeans of taking stance), and it can lead to various text\nanalytics applications. The practical tasks require pro-\ncessing large quantities of textual data that are infeasi-\nble for manual investigation, for example, providing a\ntemporal overview of stance usage in social media,\nretrieving the corresponding text data relevant to\nstance phenomena, or analyzing the occurrences of\nstance expressions. Therefore, stance researchers are\ninterested in automated ways of text processing that\ncan be offered by researchers from the field of compu-\ntational linguistics or natural language processing\n(NLP).\nHowever, many linguists face difficulties when try-\ning to interpret the output of NLP algorithms. For\nNLP experts, it is equally challenging to gain insight\ninto the underlying text data and to provide useful\nfeedback in order to refine their automatic analyses. In\nfact, NLP researchers would also benefit from a tech-\nnique that could improve their understanding of the\ncomputational processes associated with the state-of-\nthe-art NLP algorithms (e.g. it is difficult to interpret\nthe state of a large artificial neural network just by\nweight matrices). This predicament can be resolved by\nintroducing a visual analytics (VA) approach to pro-\nvide linguistics researchers with interactive visualiza-\ntions for analyzing large text data and for presenting\nthe NLP experts with feedback at the same time. Our\nresearch project StaViCTA (Advances in the descrip-\ntion and explanation of Stance in discourse using\nVisual and Computational Text Analytics (project web\npage: http://cs.lnu.se/stavicta/)) addresses this chal-\nlenge and aims to produce a refined theory of stance,\nefficient interactive visualization, and computational\ntechniques for its analysis, as well as solutions for spe-\ncific applications. Due to the early stage of research in\nstance analysis, the project itself follows an iterative\nprogress plan. Therefore, we consider sentiment anal-\nysis, including certainty or uncertainty, as underlying\naspects of linguistic stance in order to support the con-\nstruction of the model in general.\nIn this work, we focus on the exploration of social\nmedia documents (in English) and the collection of a\ntraining dataset which later will be used to develop\nappropriate machine learning (ML) approaches. The\ncomposed training data consist of text chunks, called\nutterances, that are associated with specific expressions\nof stance (see Figure 1). These utterances can be used\nfor both NLP purposes and manual linguistic investi-\ngation; we denote them by stance markers. This collec-\ntion of relevant stance markers is the basis for a refined\ntheory and sophisticated NLP models for stance analy-\nsis in general.\nHere, we present our tool called uVSAT that can\nhelp stance researchers to identify candidate docu-\nments that may contain stance expressions, analyze the\ndocument texts, and export the new stance markers\n(as introduced in our previous poster abstract1).\nuVSAT supports the research task of how we can study\nthe use and patterns of stance meanings and stance\nexpressions in human communication over time in\norder to investigate what stance markers and stance\nmarkings are used when, why, how, where, and in what\ntype of dialogic sequences related to the contexts\nwhere they occur. Our effort described in this article is\nmeant to complement the existing techniques for\nstance analysis based on manual close reading and tra-\nditional linguistic tools by introducing a VA approach\nto this problem, while not providing a completely\nautomatic stance analysis yet. The main contributions\nof the VA approach presented in this article include\nthe following:\n A web-based VA solution for investigating stance\nphenomena based on sentiment analyses of docu-\nment texts and time-series;\n An interactive history diagram for document set\nqueries that facilitates the analysis provenance;\n Interactive aggregation charts that provide docu-\nment set overview, navigation, and comparison\nfunctionality with regard to stance types or specific\nstance markers.\nThe remainder of this article is organized as fol-\nlows: the next section provides the background of\nstance analysis from the perspective of linguistics and\nNLP. The subsequent section covers the related work\nin text visualization, including work dedicated to senti-\nment analysis visualization. After this, we explain the\nsystem architecture and data model as well as user\ntasks supported by uVSAT. Then, we describe in\ndetail our visualization and interaction approaches for\nthis tool. The subsequent section discusses a use case\nfrom the linguistics domain based on exploration of\ndata with regard to anger sentiment as a subcategory\nof stance. The penultimate section provides the results\nof a domain expert review and our reflections about\nthe tool. Finally, we summarize the contributions and\nfuture work in the last section.\nBackground\nOur research on visual stance analytics is by nature\ntightly connected to the domains of linguistics and\nNLP. Since the problem of stance analysis is not widely\ndiscussed in the VA community (as opposed to senti-\nment analysis), we present the theoretical background\nof stance and its relation to sentiment in this section.\nStance and sentiment model\nStance is a topical area of interest in linguistics because\nthe interactive nature of communication between indi-\nviduals is considered vital. The function of taking\nstance in the communicative situation is to convey the\nspeaker's viewpoint of what is talked about and to reg-\nulate the exchange between the dialog partners.\nCommunication here works on more than the pure\nunderstanding of words. Words are always understood\nin the light of the contexts and the situations where\nthey are used.2,3 In doing so, language is used to\nrecontextualize human experiences into written and\nspoken forms. Its social role is to affect the state of\nmind of other people and to negotiate meanings in\norder to bring about cognitive changes.4,5 Language\nusers construe their expressions to communicate their\nparticular perspective and viewpoint of what is talked\nabout. As the following scheme6 demonstrates, this\nprocess of taking stance is evaluative and fundamen-\ntally interactional, a type of ongoing negotiation:\n1. An utterance proposed by X;\n2. Y's engagement (mental processing or interpreta-\ntion or positioning) as to the utterance in context;\n3. Y's response to X's utterance;\n4. X's engagement (mental processing or interpreta-\ntion or positioning) as to the utterance in context;\n5. X's response to Y's utterance;\nOurs is a broad understanding of the process of tak-\ning stance, as it is critical to address the subtle but\nimportant differences in how people create\ndiscourse--imbuing it with their personal word\nchoices as distinct acts of taking stance. This encom-\npasses expressions of subjectivity, ranging from indi-\nvidual words to larger chunks of text. These items\nFigure 1. The diagram gives an overview of the underlying research problems from the user perspective. To succeed\nwith the analysis of stance, linguists require means to analyze and interact with the output of NLP algorithms as well as\nmeans of further manual investigation. These means are still missing in the analysis loop and are indicated by the red\nquestion mark. The dashed edges denote the user operations that depend on the results of interactive visual analysis.\nexpress speaker's (1) sentiments, (2) attitudes, and (3)\nbeliefs, covering meanings of certainty, volition, evi-\ndence, emotion, valence, degree, and so on. Following\nDu Bois,7 we divide the process of taking stance into\nthree parts: (1) speaker evaluation of what is talked\nabout, (2) speaker positioning (epistemicity), and (3)\nalignment in communication, that is, establishment of\nagreement or disagreement. Stance has been studied\nunder different headings and scope, such as evalua-\nunder the title stance itself.5,12\u00ad14 Yet, at the present\ntime, there is no conclusive and universally accepted\ndefinition of linguistic stance.\nAs stated above, subcategories of stance include\nsentiment, certainty or uncertainty, as well as other\nsubcategories that are not well-defined yet. For this\narticle, we have limited the scope of our understanding\nof stance to sentiment and certainty or uncertainty.\nThese subcategories are generally considered to\ndescribe the feelings and assessments of an utterance;\nas such, they can encapsulate an evaluative statement\nthat is deemed to be a stance act. Our approach is\nbased on the expectation that the occurrences of such\nexpressions lead to occurrences of other stance\nexpressions--we denote the particular analyzed subca-\ntegories by stance types throughout this article to sim-\nplify the notation. From the computational\nperspective, this approach could be described as ``mul-\ntidimensional'' sentiment analysis.\nSentiment analysis\nFrom an operational point of view, stance includes\nphenomena such as subjectivity, sentiment, belief,\ntrust, and uncertainty. Some of these phenomena,\nsuch as sentiment and subjectivity, have enjoyed con-\nsiderable attention in the NLP community (for\ninstance, see the works of Pang and Lee,15 Liu,16 and\nLin et al.17), while others, such as belief, trust, or\nuncertainty, have remained comparatively peripheral\n(but there is a number of efforts18,19 to analyze uncer-\ntainty and speculation, respectively). Sentiment analy-\nsis in particular has become a staple in NLP, both in\nresearch and in commercial applications, with a large\nnumber of vendors offering solutions for social media\nmonitoring where sentiment analysis is an important\npart of the analytics suite.\nAs with any research area that gains popularity in a\nresearch community, there has been a wide variety of\napproaches suggested in the literature. Examples range\nfrom simple keyword matching20 over standard\nmachine learning techniques15,21 to the use of topic\nmodeling algorithms and latent variable models22\u00ad24\nto deep learning architectures.25,26 State-of-the-art\napproaches to sentiment analysis now approach, and\nin some cases even exceed, 90% accuracy on standar-\nSentiment analysis is normally considered as a clas-\nsification problem over two or three classes, where pos-\nitive and negative define the basic polarity, and neutral\nis used to describe a lack of attitudinal content. From\nthe perspective of stance analysis, this is a very simplis-\ntic ontology of emotions that is likely to be too\nrestricted to be useful for analyzing and describing\ncomplex interpersonal processes of taking stance.\nCurrent research on sentiment analysis is beyond the\nstandard positive\u00adnegative dichotomy and operates\nover a wider spectrum of emotions, such as Ekman's29\nsix basic emotions (the so-called Big Six): anger, fear,\nhappiness, surprise, disgust, and sadness,30 or some other\nmulti-class taxonomy of sentiments.25,31 Another\nexample of a more complex sentiment palette is the\nRepTrak model used in the RepLab evaluation cam-\npaign that includes eight different categories designed\nspecifically for reputation classification.32\nAs opposed to some of more complex approaches\nbased on ML, we opt for a simplistic approach to senti-\nment classification for the purposes of the visualization\ntool in order to preserve transparency and simplicity.\nAs previously noted, we have chosen to address stance\nthrough subcategories. More specifically in uVSAT,\nthese are based on Ekman's Big Six emotions, employ-\ning the NLP solution of simple lexical matching over\nlists of attitude terms (which we call stance markers as\nalready mentioned in the ``Introduction'' section). The\nmain goal at this stage of the project is to facilitate\nexperiments to further improve our understanding of\nstance in general and our analysis techniques in partic-\nular. While our method of sentiment analysis is simple,\nsuch a lexical-based approach is still widely used by\nvisualization and VA solutions,33,34 especially the ones\naiming for high performance when processing large\namounts of input data.35 There are also several exam-\nples of combining both lexical-based and machine\nlearning\u00adbased approaches for sentiment analysis that\nreports similar36 or even surprisingly good37 results\nwhen using the lexical approach.\nRelated work\nOur tool uVSAT was designed to visualize and interact\nwith large text data sources as well as the results of\nautomatic text processing which include time-series.\nThere have recently been multiple works dedicated to\ntext visualization and analytics of social media. Survey\narticles by Alencar et al.,38 Gan et al.,39 Kerren\net al.,40 and Kucher and Kerren41 demonstrate a vari-\nety of techniques used for the visualization of\nsingle documents, document collections (corpora),\nand text-related data streams. In this section, we will\ndiscuss several groups of works relevant to our\nresearch from various aspects.\nTime-dependent text visualization\nA good number of such works address temporal\naspects to visualize events, topic competition or evolu-\ntion, or other time-dependent data. While some of\nthem introduce novel metaphors for visual encoding,\nmultiple techniques combine well-known representa-\ntions such as line plots, river metaphors, or animated\nforce-directed graphs. Havre et al.42 introduce\nThemeRiver, the original technique for temporal data\nvisualization based on a river metaphor that is\ndesigned to depict topic evolution in document collec-\ntions. Dou et al.43 combine trees, text tags, and rivers\nin their HierarchicalTopics system to visualize the tem-\nporal evolution of topics in corpora. Xu et al.44 com-\nbine line plots, stacked charts, and word clouds to\ndepict topic competition in social media document\ncollections. To support the real-time monitoring of\nstreaming Twitter data backed up with automatic text\nclassification, Bosch et al.45 use timeline, word clouds,\nglyphs, and maps in the ScatterBlogs2 system. For the\nwork in this article, we decided to choose simple visual\nrepresentations (line plots, text tags, and bubble\ncharts) for the data currently available to us, although\nwe plan to design more specialized visual encodings\nfor other tasks in the future.\nSentiment visualization\nWhile specific problems (and the corresponding analy-\nsis techniques) such as topic modeling and event\ndetection have been very popular in text visualization,\nthe interest for sentiment analysis and visualization is\nalso arising in the VA community. Liu et al.46 and\nOelke et al.47 describe visualizations for opinion min-\ning of reviews. Wanner et al.,48 Cui et al.,49 and\nRohrdantz et al.50 present approaches for visual senti-\nment analysis that supports temporal data. Go\n\u00a8rg\net al.37 describe the fluid integration of sentiment anal-\nysis as well as other computational text analyses with\ninteractive visualizations in their system Jigsaw. Online\nsocial media data are used for visual sentiment analysis\nSentiView, introduced by Wang et al.,54 not only facili-\ntates temporal sentiment analysis but also augments it\nwith relation analysis based on graph representation--\nthis is relevant to our long-term research goals involv-\ning intersubjectivity and stance analysis. The recent\nwork of Zhao et al.33 describes PEARL, a VA system\nfor multidimensional personal emotion or sentiment\nvisualization of Twitter posts over time, and uses an\napproach similar to ours (based on lexical matching of\nemotional words pertaining to eight emotion categories\nand three additional emotion dimensions)--however,\nour work focuses on the analysis and visualization of\ndata related to multiple posters and sources, and we\nare interested in categories beyond emotions or senti-\nment. In general, most of the discussed works involve\nsentiment analysis as a means rather than the object of\nresearch. Our approach, in contrast to theirs, focuses\non the analysis of sentiment to bootstrap the research\non visual stance analysis. This leads us to the involve-\nment of experts in linguistics as users and the discus-\nsion of existing visualization approaches related to the\ndomain of linguistics.\nVisualization for linguistic research\nInfoVis and VA techniques have been used to facilitate\ntasks such as the analysis of corpora (e.g. Compus by\nFekete and Dufournaud,55 CorpusSeparator by\nCorrell et al.,56 Text Variation Explorer by Siirtola\net al.,57 and those techniques proposed by Regan and\nBecker58), the analysis of relations or reuse (e.g.\nShakerVis by Geng et al.59 and techniques proposed\nby Ja\n\u00a8nicke et al.60), and lexical analysis (e.g. the study\nby Rohrdantz et al.61). An additional category of tasks\nthat is worthy of mention is related to semantics: while\nnumerous text visualization techniques use topic mod-\neling, experts in computational linguistics use visuali-\nzation to facilitate their research on this subject. For\ninstance, Kaba\n\u00b4n and Girolami62 visualize their own\nmodel of dynamically evolving text collections.\nAnother task related to stance analysis is discourse\nanalysis. Existing work on visualization of discourse\nincludes the graph-based approach by Brandes and\nCorman,63 Conceptual Recurrence Plots by Angus\net al.,64 and several recent works that focus on dis-\ncourse in online social media: Lingoscope by\nDiakopoulos et al.65 or ConVis by Hoque and\nVA for sentiment research\nFinally, the work that is most relevant to our approach\nin this article is dedicated to sentiment visualization\nwhich facilitates the research on sentiment for lin-\nguists. Gregory et al.67 conduct visual sentiment analy-\nsis of document collection with regard to affect bearing\nwords. Their approach involves eight affect categories\n(positive, negative, virtue, vice, pleasure, pain, power\ncooperative, and power conflict) and uses IN-SPIRE\nfor visualization purposes. The recent work of Makki\net al.68 focuses on sentiment lexicon refinement from\nreviews dataset which involves user input via interac-\ntive visualization. Their sentiment analysis is based on\na standard positive\u00adnegative dichotomy. The two\nmajor differences between these works and our pro-\nposed approach in uVSAT are the involvement of\nonline social media text data (which is dynamic with\nregard to analysis sessions and available for temporal\nanalysis) and the choice of sentiment categories (which\nis a base for the further analysis of stance).\nTo the best of our knowledge, the problem of stance\nanalysis and visualization has not been addressed by\nwork in VA or information visualization. Therefore,\nwe would like to raise the awareness of the InfoVis and\nVA communities in this article by building on the dis-\ncussed work in text visualization for sentiment analysis\nand existing work on visual text analytics for linguists.\nOverall architecture and data\nBefore we can discuss the overall architecture of our\nVA approach, we have to briefly present the different\nmembers of the StaViCTA project in order to moti-\nvate our designs. The visualization group at the\nDepartment of Computer Science, Linnaeus\nUniversity, is responsible for VA research and the\ndevelopment of the VA approaches needed in the proj-\nect and presented in this work. A domain expert group\nin linguistics at the Centre for Languages and\nLiterature, Lund University, is in charge of task identi-\nfication, stance theory construction, evaluation, and so\non. Finally, a group at the company Gavagai has broad\nknowledge in NLP and develops automatic analysis\ntechniques and tools for the project. Gavagai monitors\nand processes online media (e.g. newswire, weblogs,\nforums, and social media such as Twitter and\nFacebook) for media monitoring and text analytics\npurposes.\nSystem architecture and workflow\nFigure 2 displays the overall architecture of uVSAT\nthat is implemented as a web application. The back-\nend consists of a (visualization) server application\nimplemented in Java that communicates with the\nGavagai computing server, fetches the HTML content\nfrom URI links, processes the text data, and communi-\ncates the results in JSON format to the client(s). The\nfront-end is implemented in JavaScript with D369 and\nRickshaw70 libraries, and it only requires a modern\nweb browser. While the major and cost-intensive com-\nputational analyses are processed by the Gavagai and\nvisualization servers, several minor analyses (which do\nnot require intense computations for large amounts of\ndata) are implemented on the client side.\nData model\nuVSAT has been designed to use time-series data from\nexternal providers through a RESTful API,71 as well as\nto fetch and process corresponding HTML data from\nrespective web servers. Currently, we use time-series\ndata only from our collaboration partners at Gavagai\n(although we plan to support other data sources in the\nfuture). Gavagai analyzes text data from multiple\nsources, but for the purposes of the system presented\nin this article, they use the data fetched from various\nblogs and forums.\nAs mentioned in the ``Background'' section, we\nfocus on the simplest possible type of stance analysis,\nthat is, counting the occurrences of sentiment terms in\ndocuments that mention specific target terms. This\nsimple approach allows our partners to support the\nanalysis of large amounts of text data, up to 15 million\nFigure 2. The architecture of uVSAT comprises front-end and back-end tiers that communicate with external servers.\ndocuments per day. Here, a target can be anything of\ninterest: a person, a brand, a company, a location, an\nevent, or even something abstract such as a concept or\nan idea--as long as it can be defined by a set of key-\nwords (also denoted by target terms in the context of\nour tool). Our present set of targets T includes the\nfollowing\nT = diet, weapons, Hobbit, Coca\u00c0Cola, Pepsi\nf g\nTo detect documents associated with stance, we\nconsider specific markers relevant to sentiment and\n(un)certainty from several available sources (WordNet-\nwhile refining those marker lists is one of the purposes\nof uVSAT (since the sources above do not differentiate\nstance from sentiment, etc.). Our choice of analyzed\nstance types (also denoted by observers in the context of\nour tool) includes the Big Six emotions (see the\n``Background'' section) as well as two other categories\nO = anger, joy=happiness, fear, sadness,\nf\ndisgust, surprise, certainty, uncertaintyg\nAs an example, weapons is a monitored target which\nis defined by a list of 3771 keywords, harvested from\nthe Wikipedia lists of weapons.75 Whenever one of\nthese keywords is mentioned in open online media,\nthe entire utterance containing the keyword is ana-\nlyzed for occurrences of stance markers. Here, utter-\nance is simply defined as a sequence of text defined by\ndelimiter symbols, for instance, the text fragment\nI am so sick of people who sell such rifles and so sick of\npeople who buy this distasteful weapon.\ncontains two occurrences of the stance marker ``sick\nof'' and one occurrence of ``distasteful,'' generating a\npolarization value of 3 for the target weapons for obser-\nver disgust.\nTo summarize the description of n targets, m\nobservers, and their possible combinations, we can\ndescribe the hierarchical structure of the data as {(Ti\n,\n, ., Oij\nTi\n2 T and the corresponding observers Oik\ninstance, (Hobbit, {disgust, anger, .}).\nThe occurrence counts are aggregated for each\ntarget\u00adobserver combination (Ti\n, Oik\n)--for example,\nHobbit/disgust or Hobbit/anger (note that we equiva-\nlently use the notations (Ti\n, Oik\n) and Ti\n/Oik\n)--over a\nspecific time frame which is presently set to 1 h. Thus,\nall occurrence counts for a specific stance type within\nthis time frame [t1\n] are summed, resulting in an\nhourly value v for each combination. These values are\nthen retrieved and visualized by uVSAT as time-series.\nBecause of this aggregation step (which is necessary to\nreduce the complexity and computational demands),\nthe time-series data describe the general tendencies\nwith regard to stance but do not directly provide any\ndetails about the distribution of specific markers.\nTherefore, further exploration of the original text doc-\numents is required from the users.\nThe Gavagai API also provides URIs to the docu-\nments used to calculate the polarization values (taking\n(Ti\n, Oik\n) as arguments and returning sets of\nURIs), although the corresponding HTML content\nhas to be downloaded and processed on our side.\nUnfortunately, the total amount of available data\nmakes it infeasible for the VA tool to prefetch every-\nthing. Therefore, we limit ourselves to queries for\nspecified sets of target\u00adobserver combinations across\ninteractively selected time intervals (although we plan\nto support streaming data in the future).\nRequirement analysis\nAfter the introduction of the fundamentals and\nresearch gaps of visual stance analytics including a\nshort discussion of the origin and structure of available\ndatasets, we are able to take a closer look at the actual\nanalysis challenges and most important tasks that\nuVSAT should address. They are based on extensive\ndiscussions with our collaboration partners in linguis-\ntics and computer linguistics.\nAnalysis challenges\nWe have designed uVSAT to facilitate users with\nanswering the following questions:\nQ1. How do the calculated values for targets or\nobservers change over time? What are the overall tem-\nporal trends?\nQ2. How to identify ``interesting regions'' in multiple\ntime-series which span over long intervals of time?\nHow to reduce the visual complexity with regard to\nnoisy data?\nQ3. What are the original documents associated with\nthe values for targets or observers? How to identify the\nmost interesting documents with regard to stance\nanalysis?\nQ4. How are markers distributed in a particular\ndocument?\nQ5. How are specific markers distributed in the\nretrieved sets of documents? How to identify the doc-\numents with a large number of markers or the docu-\nments which contain a lot of unique marker types?\nQ6. How to handle a long analysis session involving\nmultiple time intervals and document sets? How to\nrecover a previously discarded document set? How to\nnavigate quickly to a previously analyzed document\nset?\nQ7. Are there any relationships between analyzed doc-\nument sets?\nQ8. How to use particular marker, document or docu-\nment set analysis results for further investigation?\nAnalytical tasks\nThese questions and problems can be mapped to the\nfollowing categories of high-level (analytical) tasks:\nT1. Time-series analysis: compare the values for various\ntargets and observers (Q1, Q2), explore trends (Q1,\nQ2), and identify interesting regions for further inves-\ntigation (Q2);\nT2. Document sets navigation: query for the documents\nassociated with selected observers or time intervals\n(Q3), keep track of related queries (Q7), and navigate\nthe queries history (Q6);\nT3. Document sets analysis: explore the retrieved docu-\nment sets (Q3) and reveal the general trends by using\ndata aggregation (Q5);\nT4. Document navigation: query for specific documents\neither explicitly (Q6) or while navigating enclosing\ndocument sets (Q3) and aggregated data (Q5);\nT5. Document analysis: explore the text content and\nstance marker distribution in a selected document\n(Q4) and export the static content for manual investi-\ngation (Q8);\nT6. Stance marker collection: export the selected utter-\nances (or parts of them) as new markers (Q8).\nIn the following section, we discuss our visualiza-\ntion approach in detail, justify the design decisions,\nand refer back to the above-listed research questions\nand tasks.\nVisualization approach\nThe graphical user interface (GUI) of our tool offers a\ntab-oriented design with two types of tabs (cf.\nFigures 3 and 4): a single timeline view tab that is used\nto work with an arbitrary number of timeline plots,\nand multiple document view tabs that are opened by\nthe user when fetching the document URIs for\nselected time intervals. As the timeline view is the\nentry point of all visual analyses supported by our\napproach, we start our discussion with this view.\nTimeline view\nThe timeline view tab (cf. Figure 3) provides the users\nwith the interfaces for exploring time-series data for\nselected targets or observers and specified time\nintervals. Note that fetching the input data to be\nanalyzed--that is, the initial selection of specific tar-\ngets, observers, and time ranges--from the Gavagai\nserver is done via a simple dialog box as explained in\nour use case (cf. the corresponding section). In this\nsection, we concentrate on overall design aspects\nincluding visual representation and interaction\npossibilities.\nColor coding considerations. Before we address the\nparticular representations, we have to explain the color\ncoding scheme used for the timeline view as well as\ndocument views. As mentioned in subsection ``Data\nmodel,'' the analyses supported by our tool involve the\ncombinations of targets Ti\nand specific observers Oik\n.\nSo, the resulting hierarchical data structure for one\nspecific target might be (diet, {anger, joy, .}), for\ninstance. The time-series data fetched from our part-\nners are organized this way with the focus on target\u00ad\nobserver combinations, and our initial choice of the\ncolor coding was based on the decision to provide a\nunique color for each combination. However, this\napproach had two issues: first, the sheer number of\ncombinations (45 entries in our present set of target\u00ad\nobserver combinations) made it difficult to use a color\nscheme that would facilitate the users' perception of\nthe data and, second, this color scheme was not related\nto the scheme for document views (described below),\nso the users could easily lose the mental map when\nswitching between the view tabs.\nThe analyses employed by document views (see the\ncorresponding subsection below) concentrate on the\nobservers, that is, stance types, and do not differenti-\nate between observers related to various targets. This\nhad an implication that the color coding for document\nviews was initially based on ColorBrewer,76 and it con-\ntained separate colors for observers and targets.\nAfterward, we have changed the color coding used\nfor the timeline view in accordance to the TreeColors\napproach.77 To generate the colors, we have inverted\nour hierarchy to the form {(Oj\n, .,\nTji\nHobbit, .}), and then used the TreeColors package.\nThe resulting color coding aims to assign different\nobservers distinct color hues although it is not perfect\nsince there are still too many of those. The colors\nassigned to target\u00adobserver combinations pertaining to\nthe same observer have rather similar hues. This, on\none hand, makes it simple to spot such similar combi-\nnations. On the other hand, although, it makes it diffi-\ncult to discern such plots--this is partially alleviated\nby interaction techniques such as details on hover and\nfiltering. Overall, the main benefit of this approach is\nthat it allows of using the same color hues for\nFigure 3. The screenshot of our tool shows the timeline view. Users start by loading time-series data associated with the two targets Hobbit and Coca-Cola and two\nobservers certainty and joy. Then, they can explore the data and select time intervals for specific target\u00adobserver combinations (see the blue-shaded area) in order to\nfurther analyze the corresponding documents.\nThe screenshot demonstrates (a) the data hierarchy view, (b) timeline plots, (c) trend lines, and (d) the history diagram.\nFigure 4. The screenshot displays our document view for a selected time interval (cf. Figure 3) and the target\u00adobserver combinations Coca-Cola/joy, Hobbit/joy, and\nHobbit/certainty. Here, users can explore the resulting set of documents (on the left) and are able to analyze the contents of specific documents (middle) with regard\nto the occurrence of stance markers summarized on the right-hand side.\nThe screenshot demonstrates (a) the document links list, (b) the current document view, (c) the document marker view, and (d) the current document overview.\nobservers across the timeline and document views that\nhelps to preserve the users' mental map.\nData hierarchy view. After the input data have been\nloaded, the users are provided with the data hierarchy\nview displayed in Figure 3(a) that shows the hierarchi-\ncal structure of the available target\u00adobserver combina-\ntions. Users can also open a tab with iconic ``overview\nplots'' (cf. Figure 10) for all fetched time-series which\nare similar to regular timeline plots with highlighted\nregions of interest (ROIs) (see below). These overview\nplots support a simple way to compare the time-series\nand to find more general patterns in the data (research\nquestions Q1 and Q2). As soon as interesting target\u00ad\nobserver combinations are found, the user may want\nto investigate these data in detail and drag-and-drop\nthe entries from the data hierarchy view onto the main\npart of the tab. Then, uVSAT displays the timeline\nplots for the chosen combinations. For instance, in\nFigure 3, a user has selected three views where several\ntarget\u00adobserver combinations are visualized.\nTimeline plots. uVSAT uses a standard line plot repre-\nsentation for time-series data (cf. Figure 3(b)) and\nsupports usual interaction techniques for such plots\n(research question Q1). We have chosen this visual\nrepresentation as our domain experts are already famil-\niar with it. In addition, line plots can be easily extended\nwith additional graphical features. Details on hover,\nplot overview, and scroll and zoom are provided by\ndefault by the Rickshaw component. Users are also\nable to filter the plots with regard to visible target\u00ad\nobserver combinations by switching on and off the cor-\nresponding labels. Our tool supports multiple plots\ndisplayed on the same canvas (users can drag-and-drop\nadditional items from the data hierarchy view) or sepa-\nrately (users can drag the plot containers to change the\ntimeline view layout). For the comparison of several\nplots displayed side by side, users can control the auto-\nmatic vertical scaling--by default, plots are scaled to\nfit the containers. This functionality was explicitly\nwished by our domain experts.\nROI highlighting. To facilitate the search for ROIs, our\ntool also supports automatic ROI highlighting\n(research question Q2). Currently, we use a basic ad\nhoc algorithm for marking the ROIs based on outlier\nor differential analysis. As a first step of the algorithm,\ntime-series points xi\nare marked, which differ signifi-\ncantly (with regard to threshold parameters u1\n)\neither from the mean value mx\n(standard deviation sx\nis used for comparison) or from the preceding point\n(judging by the first derivative x0\ni\n)\nA = xi : jxi\n\u00c0 mx\nsx\ni\nmax\nj\nj\nj\n \n \nSince the source time-series data are in general\nnoisy, A will result in multiple regions of small size\n(comprising only one or several points). Therefore, in\nthe second step, we smooth the results by marking\nneighboring points as parts of ROI, which will result\nin contiguous regions\nROI = A [ xi : xi\u00c01\n\u00f0 \u00de _ xi + 1\n\u00f0 \u00de\nf g\nROIs are highlighted by thick line segments (cf.\nFigure 3(b)). The algorithm parameters u1\ncan\nbe adjusted by the user, which can be used to partially\nalleviate the problem of noisy data or to increase or\nreduce the number of highlighted regions to focus on.\nTrend analysis. Users have several options of conduct-\ning trend analyses over selected time intervals for spec-\nified observers (cf. Figure 3(c)). uVSAT supports\nlinear and quadratic time-series trend analysis based\non polynomial regression (calculated with the ordinary\nleast squares (OLS) method). We implemented two\nvariations: one can choose to either render trends as\noverlay plots (cf. Figure 5(a)) or to substitute selected\ntimeline plot segments with trend lines (cf.\nFigure 5(b)) to reduce the visual complexity of the dis-\nplayed data (research questions Q1 and Q2). Trend\nlines are easily distinguishable by the use of dashed\nlines. Even information about the predicted value\nchange at the current trend rate and a button for\nremoving trend lines are available on hover.\nDocument URI links queries. As soon as the user is\nmore interested in the concrete documents whose fre-\nquencies are represented by the different time plots,\nhe or she can select time intervals for specific sets of\nobservers and load the corresponding URI links to the\ndocuments (research question Q3). In this case, a new\nFigure 5. Trends can be displayed as either (a) overlay\nplots or (b) instead of original plot segments.\ndocument view tab is created and a thumbnail of the\nline plot used for the query is displayed in this new\nview in order to preserve the mental map. An example\nof this thumbnail can be seen in Figure 4 in the left\nupper corner.\nHistory diagram\nSince the workflow of uVSAT involves multiple docu-\nment view tabs that also may be closed by a user dur-\ning the analysis process, the need for overview and\ncontrol of such user actions arises. Our interactive his-\ntory diagram (cf. Figure 3(d) and Figure 6) provides\nan overview of the document URI queries sequence,\ntheir results, and relations to each other (research\nquestions Q6 and Q7).\nIn this diagram that supports the so-called analysis\nprovenance,78 nodes represent URI queries and edges\nrepresent the detected relations between correspond-\ning query results (this partially resembles the visualiza-\ntion approach described by Cernea et al.79). The size\nof every node is proportional to the number of URI\nlinks retrieved for the corresponding query. Nodes are\nrepresented by glyphs similar to pie charts (although\nonly qualitative information about relevant observers\nis used), following the same color coding of observers\nas the timeline plots. The currently selected node is\nhighlighted in yellow. Since the diagram is used for\nhistory navigation, it also contains a dedicated node\n(depicted by a triangle) that represents the up-to-date\ninterface state. Edges connect only nodes whose query\nresults contain common subsets of URI links. The size\nof common subsets (i.e. Jaccard similarity of link\nsets80) is mapped to edge opacity, thickness, or both of\nthese attributes (selected as a user setting). The layout\nof the history diagram is based on arc diagrams by\nWattenberg:81 nodes are simply aligned along a hori-\nzontal axis in the order of corresponding queries, and\nedges are rendered as curved arcs. We apply a\nrandom-order greedy heuristic described by He\net al.82 to decrease the number of edge crossings when\nallocating edges to the upper or lower part of the\ndrawing.\nThe interactive history covers the following func-\ntionalities: every time a user issues a URI links query\nthat leads to the creation of a new document view tab,\nthe state of this new tab and the timeline view tab are\nsaved and a corresponding node is added to the his-\ntory diagram. When the user clicks on a history node,\nthe timeline view tab state is restored, a document\nview tab with corresponding state is either created or\nbrought into focus (if currently present), and the user\nactions temporarily stop affecting the history state\n(e.g. issuing a new query will not add the resulting\nstate to history)--we have chosen such behavior to\nkeep the history sequential. When the user clicks on\nthe triangle, the previously saved up-to-date state is\nrestored. Under circumstances, this can lead to some\ndocument view tabs getting closed.\nDocument views\nA document view tab (cf. Figure 4) basically consists\nof two areas. The left (smaller) area provides informa-\ntion about all documents fetched based on the selec-\ntion described at the end of subsection ``Timeline\nview.'' Thus, it shows the aforementioned line plot\nthumbnail used for the query as well as a link list (cf.\nFigure 4(a)) to HTML documents (blog posts, forum\nmessages, etc.) that were marked as associated with a\nspecific target\u00adobserver combination. Users can filter\nthe list by URI domain and sort it by the timestamp\nvalue or by polarization value (as reported by the\nGavagai server). Polarization values are also used for\nthe color coding of list entries (research question Q3).\nBy selecting a link from the list, the corresponding\ndocument content is fetched, processed at the (visuali-\nzation) server side, and rendered at the client side. If\nthe content is not available at this time, the corre-\nsponding list entry is marked. The document data at\nthis stage are raw HTML which affects the analysis.\nThis is because the source code comments and meta-\ndata (such as keywords) often contain text irrelevant\nto the document content. To direct the user's focus on\ntextual document data, uVSAT renders the HTML\ncontent as plain text by using the Jericho library.83 All\ndata and analysis results related to the single focus\ndocument are shown in the second area on the right-\nhand side of the document list. This area integrates\nfour subviews: the current document view, the current\ndocument details view (not further discussed here),\nthe document marker view, and the current document\noverview.\nIt should be noted that uVSAT also provides an\nopportunity to copy the query link for a given\nFigure 6. The history diagram allows users to keep track\nof document queries and navigate between interface\nstates.\ndocument view tab and to use it in later analysis ses-\nsions by opening a tab with identical contents\n(research question Q6).\nCurrent document view. Figure 4(b) displays the text\nrepresentation of a document. The stance markers\nand target terms are highlighted and support brushing\nin coordination with the other views (research ques-\ntion Q4). The motivation for the color coding for doc-\nument view tabs was described above: it uses a scheme\nwith eight colors for stance markers and a separate\nscheme with five colors based on ColorBrewer for tar-\nget terms since targets share stance markers associated\nwith observers (types of stance), for example, the word\n``commendable'' is a marker of joy for both Hobbit and\nCoca-Cola. To distinguish target terms from stance\nmarkers, the former are marked by a striped back-\nground pattern.\nDocument marker view. Information about stance\nmarkers (and their occurrence counts) as well as target\nterms detected in the current document is summarized\nin the document marker view (cf. Figure 4(c)). The\nstance markers for each observer are sorted by their\ncounts to facilitate user investigations (note that target\nterms occurrences do not affect the statistics since\nsuch terms are not directly related to expressions of\nstance). The users can navigate the document with\nregard to markers or terms occurrences and to filter\nthem (research question Q4).\nCurrent document overview. To give users an overview\nof marker or term distributions in the current docu-\nment (and an additional means of navigation), uVSAT\nprovides several visual representations displayed in\nFigure 4(d). First of all, a two-dimensional (2D) over-\nview is visualized by mapping the current positions of\nall markers or terms onto a canvas (they are repre-\nsented by circles and diamonds, respectively). The\ncurrent viewport is displayed as a rectangle. This over-\nview supports navigation by clicking on a plot item or\nthe canvas. Additionally, a separate one-dimensional\n(1D) overview for each observer and target is visua-\nlized by projecting the positions of corresponding mar-\nkers or terms onto a vertical axis. Such overviews help\nthe users to immediately perceive the distributions\nover the document length since the 2D overview can\nbecome cluttered in case of numerous markers or\nterms. 1D overviews support document navigation by\nclicking on plot items. Seeing such distributions is\nespecially interesting for our domain experts because\nit is important for a better understanding of stance in\ndiscourse (research question Q4), for instance, if a\nmarker for a specific stance type mostly occurs in the\ncontext of another marker.\nAggregation charts\nWhile the techniques discussed above allow the users\nto analyze a selected document in detail and provide\nan indication of interesting documents (by polarization\nvalues), the document sets retrieved for certain queries\nmay contain thousands of documents, and the users\nwill benefit from a method that helps them to select\ndocuments that are interesting for further stance mar-\nker investigation (research question Q5). uVSAT\naddresses this problem with a technique that we call\naggregation charts: it provides an informative overview\nand means of navigation for the current document set\nwith regard to detected markers and observers (cf.\nThe visual representation is based on basic bubble\ncharts described by Vie\n\u00b4gas et al.84 Every item in the\nchart represents a single document which corresponds\nto the target; the color coding is based on the nominal\ntarget values. A single item is visually represented by a\nglyph consisting of two nested circles. The size of the\nouter circle is proportional to the total number of cor-\nresponding stance markers detected in the document,\nand the size of the inner circle (filled with a more satu-\nrated color) is proportional to the number of unique\nmarker types detected in the document. For instance,\na document with 100 occurrences of a marker ``good''\nand 100 occurrences of a marker ``bad'' has only two\nunique marker types: ``good'' and ``bad.''\nThe aggregated data used for these charts can be\norganized in two ways: by observer and by stance mar-\nker. In the former case, a separate chart is visualized\nfor each observer associated with the document set. In\nthe latter case, one individual chart is visualized for\neach unique marker type (belonging to present observ-\ners) that has been detected in at least one document.\nFigures 7 and 8 display examples of aggregation\ncharts visualized for a document set based on 1517\nURIs retrieved for the target\u00adobserver combinations\nCoca-Cola/joy, Hobbit/joy, and Hobbit/certainty. In\nFigure 7, the charts are organized by observer: the left\nchart contains items pertaining to both Coca-Cola and\nHobbit; however, the right one does not contain items\nfor Coca-Cola since no corresponding target\u00adobserver\ncombination was available. This figure also shows the\ndetails for a chart item displayed on hover. An exam-\nple of aggregation charts organized by stance markers\nis displayed in Figure 8. There are multiple charts\nsorted by the corresponding document numbers in\ndecreasing order, and the user can browse these charts\nwith a specific marker in mind. Details for the first\nchart (marker: ``good'') are provided in a tooltip. Here,\nFigure 7. Aggregation charts organized by observer allow users to explore the distribution of documents with respect to\nthe corresponding observer.\nFigure 8. Aggregation charts organized by marker allow users to reverse the flow of analysis: they can concentrate on\ndocument distributions with regard to a specific interesting stance marker.\nthe currently selected document is highlighted (yellow)\nin all charts.\nAggregation charts facilitate the quick perception of\nthe distribution of observers or stance markers in all\ndocuments, the identification of documents with a\nlarge number of stance markers or unique marker\ntypes, the navigation to such documents, and the anal-\nysis of document properties concerning other observ-\ners or stance markers (by brushing the corresponding\nchart item).\nMarker and document export\nOne aim of our visualization tool is to identify and col-\nlect relevant stance markers from a larger number of\nanalyzed documents (research question Q8). uVSAT\nsupports the export of new stance markers from docu-\nment view tabs by selecting a portion of text in the\ncurrent document view (depicted in Figure 4(c)),\nassigning it with arbitrary tags, and exporting it to a\nJSON file. This approach allows us to collect a dataset\nof stance markers not restricted by the categories cur-\nrently used for observers. Moreover, we are able not\nonly to collect stance markers as short phrases (1-\ngrams,85 2-grams, or similar) but also to collect larger\nutterances which provide context for stance analysis.\nOur tool also supports the export of currently\nviewed documents and aggregation charts as static\nHTML pages. In the former case, the document view\nwith highlighted stance markers and target terms, doc-\nument details, hierarchical markers view, and docu-\nment overview (essentially, all the data pertaining to\nthe current document on a document view tab) are\nexported. In the latter case, all aggregation charts that\nare currently available are exported together with the\ncorresponding document set query (used observers,\nselected time interval, etc.). This feature allows users\nto store static data for further manual investigation or\nreferencing, which can be especially helpful for\nresearchers in linguistics.\nUse case: linguistics research\nThe use case described here is one in which a linguist\nhas chosen to analyze negative sentiments of stance\n(focusing on anger) in blogs, within a limited 1-week\ntime frame. This example illustrates how researchers\nin linguistics benefit from our tool when conducting\nstance analysis. The event chosen was the highly con-\ntroversial Coca-Cola commercial presented during\naims of the analysis are the following:\nA1. Analyze the overall usage of stance-related senti-\nments for the scandal time span;\nA2. Identify the document with the largest number of\nmarkers of anger;\nA3. Identify the most frequently used anger markers;\nA4. Analyze how such markers are used in the previ-\nously identified document;\nA5. Finalize the choice of the detected document for\nfurther linguistic research.\nFor performing an accurate analysis, data revealing\ninformation about the communicative forces and the\nattitudes to the ideas discussed at different points in\ntime as well as possible relationships between those\nattitudes must be made available to the researcher. By\nusing uVSAT, the linguist is able to analyze these\naspects of the social media data which would be impos-\nsible for manual stance analysis.\nTimeline data analysis\nFirst, the researcher uses the Load data dialog box and\nselects all Coca-Cola observers for the time interval 30\norder to obtain a very broad return of data (cf.\nFigure 9). The time-series calculated for correspond-\ning observers are loaded from Gavagai API.\nBy viewing the hierarchy and overview tabs (cf.\nFigure 10), the researcher verifies that all of the cho-\nsen observers have been loaded and confirms that\nthere are sufficient data to be analyzed.\nThe researcher immediately notices the spike of\nactivity on multiple plots around early hours of 3\nFebruary CET, which corresponds to the late evening\nof 2 February EST--the time when the advertisement\nwas aired in the United States (aim A1).\nThen, the researcher creates timeline plots by drag-\nging-and-dropping the observer items onto the timeline\nview. Using the slider control, the researcher concen-\nthat some of the observers have extremely low counts\nin the current time span (aim A1), the researcher fil-\nters them out. The remaining observers are certainty,\njoy, uncertainty, and anger (see Figure 11). To start ana-\nlyzing the textual data, the researcher issues a request\nfor corresponding URIs.\nIdentifying the document of interest\nThe resulting URI set comprises 3424 document\nlinks. While the researcher could explore this dataset\nmanually, it would take a significant amount of time to\nachieve aim A2. At this point, the researcher decides\nto build the aggregation charts for the current\ndocument set and to investigate the charts organized\nby observer. For this, the text document data are\nfetched from respective web servers and processed by\nThe aggregation chart for anger (cf. Figure 12)\nunique markers of anger. The researcher immediately\nidentifies two candidate documents with the largest\nnumber of corresponding markers which are repre-\nsented by glyphs with the largest diameters (also, with\nlarge shaded areas which means large number of\nunique marker types). By hovering on these glyphs,\nthe researcher finds out that one of them contains 142\noccurrences of anger markers (39 unique types) and\ntypes). The researcher selects the latter glyph by click-\ning and loads the corresponding document.\nThe loaded document of interest (depicted in\nFigure 13) is a blog post87 with a heated discussion in\ncommentaries. To concentrate on the analysis of anger\nmarkers, the researcher filters out all markers of other\nobservers. The current document overview plots at the\nbottom of the screenshot clearly show that the markers\nof anger, as well as the target terms of Coca-Cola, are\nFigure 9. The dialog box used to select the time intervals and target\u00adobserver combinations to load time-series data.\nNote that there are additional observer types (frequency, positivity, and negativity) provided by Gavagai by default that are\nnot associated with concrete stance markers (therefore, they are beyond the focus of our research).\nFigure 10. Part of the timeline overview: the plots for observers are ordered by mean value in descending order,\ncertainty being the first. Note the spike around 3 February, when the scandal occurred.\nevenly distributed throughout the entire document. To\nrefine the analysis, the researcher needs to concentrate\non specific markers.\nIdentifying the markers of anger\nThe aggregation charts for the current document set\ncan be organized by stance marker instead of observer.\nThe researcher selects this option and explores the\nresulting set of 605 aggregation charts (one per each\nunique stance marker type). Since the charts are\nordered by marker occurrences number in descending\norder, the researcher quickly identifies several most\nfrequent markers of anger, thus achieving aim A3 (see\nFinal document analysis\nAfter identifying the most frequent markers of anger\nusing the aggregation charts (here: ``hate,'' ``angry,''\n``offended,'' etc.), the researcher concentrates on the\npreviously selected document and filters out all the\nother markers. It turns out that some of the identified\nmarkers are also among the most frequent markers of\nanger in the document as well (cf. Table 2).\nThe researcher reviews the current document over-\nview once more (cf. Figure 14) and concludes that the\nidentified markers are also distributed throughout this\ndocument. As the observer anger has the marker\n``hate'' prolifically used, the analyst investigates fur-\nther, addressing the linguistic characteristics that are\nemployed by users who have posted these. The linguist\nFigure 11. Timeline view: four observers for target Coca-Cola that are used for detailed analysis are certainty, joy,\nuncertainty, and anger.\nFigure 12. The aggregation chart for anger provides an\nopportunity to identify the document with the largest\nnumber of corresponding stance marker occurrences.\nThere seem to be two candidate documents which are\nrepresented by large glyphs (also with large shaded area).\nBy hovering on these glyphs, the one with larger count of\nmarkers (in this case, 193 occurrences) is identified and\nlater used for detailed analysis.\nTable 1. Stance markers of anger in the documents.\nMarker Corresponding\ndocuments\nUnique markers\nin documents\nThe most frequently used stance markers of anger in the\ndocument set related to the use case. These data have been\ndiscovered by investigating the details when hovering over\naggregation charts' labels.\nFigure 13. Document view for a selected document with majority of stance markers filtered out. Besides the Coca-Cola target terms, only the instances of all\nmarkers of anger are displayed.\nnow proceeds with a close analysis of the document\ngiving critical attention to the markers ``hate,''\n``offended,'' and ``angry,'' thus achieving aim A4. The\nresearcher's conclusion is that the identified document\nis interesting for further manual linguistic analysis with\nregard to the flow of the conversation, and so on, as\nwell as for preparation of an ML training dataset. By\nexporting the document from uVSAT, the linguist\nachieves aim A5.\nSummary\nBy using uVSAT, the researcher has been able to\nachieve his or her analysis aims, that is, exploring the\ndata related to the case, analyzing the stance-related\nphenomena of anger and exporting the analyzed text\ndata. By being able to interpret the ROIs on the time-\nline view, the researcher was able to limit a great\namount of documents to an amount for a more\ndetailed review. The tool's ability to visualize multiple\nmarkers simultaneously in the document overview\npositively guided the investigation. By viewing the\naggregation charts, the researcher's decisions were\nvisually supported, and he or she was able to draw the\nconclusions about stance phenomena in the dataset.\nThe potential for employing these different refinement\npossibilities lets the researcher review statistical plots\nthat are dynamic and updated as new postings are\nincorporated into the document view. The analysis\nfeatures provided by the document view complements\nthe manual stance analysis based on close reading.\nOverall, the patterns constructed by uVSAT create an\nample opportunity for the researcher to employ user-\nbased data en masse.\nOn a final note, the linguist began with one specific\nstudy area. After using uVSAT, the researcher con-\ncluded that the data have also revealed three other pos-\nsible areas of interest: (1) directionality and frequency\nof the anger markers, that is, who the poster intends as\nthe recipients and how often they appear and respond;\n(2) instances of how posters modify their use of anger,\nthat is, intensifiers or attenuators; and (3) if anger is\nnegated so as to create a positive meaning. The tool\nhas provided several new potentials for future lines of\nresearch that could have gone unnoticed if traditional\nlinguistic investigations were used.\nExpert reviews and discussion\nIn this section, we present the results of two domain\nexpert reviews as well as performance issues. Based on\nthese findings, we discuss some lessons learned during\nthe development and testing phase of uVSAT.\nDomain expert reviews\nFor the time being, our research partners at Lund\nUniversity have been the primary users of uVSAT.\nThey are familiar with standard tools for corpus analy-\nsis (e.g. AntConc, BYU-BNC, WORDSMITH, or\nGoogle Ngram Viewer) and manual text analysis. As a\nkind of project preparation, we introduced basic visua-\nlization concepts and techniques to them at the begin-\nning of our collaboration. Their suggestions and\nfeedback during the design and development stage of\nuVSATare summarized in the following with regard to\ngeneral analysis workflow, visualization and interaction\ntechniques, and possible improvements for the tool.\nGeneral analysis workflow. The experts have been\nvery enthusiastic about the opportunity to analyze a\nlarge number of online social media documents in\ndetail with regard to stance and sentiment in an inter-\nactive way. They have noted that their usual tools of\nTable 2. Stance markers of anger in the selected\ndocument.\nMarker Occurrences\nin document\nRank in document\nThe number of occurrences and ranks of the previously identified\nstance markers of anger in the current document.\nFigure 14. The overview for the previously selected\ndocument with only five marker types of anger displayed.\nNote that even after filtering the other anger markers (cf.\nFigure 13), numerous instances of these five marker types\nremain and they seem to be distributed throughout the\nwhole document.\nchoice in most cases require text preprocessing and\nemploy static or rarely updated corpora, as opposed to\nour approach:\nThe uVSAT tool can accommodate the time factor\nand help the analyst sift through large amounts of data\nwhere important chunks could easily be overlooked.\nUsing the uVSAT tool, which is visually driven to reveal\npatterns, the researcher can track these and follow\nhow language is being shaped by current digital\ncommunications.\nThe experts have also appreciated the fact that\nuVSAT is implemented as a web application which\ndoes not require a specific OS or installation or update\nprocedures.\nInteractive visualization approach. The feedback on\nthe design of both timeline and document views has\nbeen positive. The experts have approved of the fea-\ntures facilitating the time-series analysis, in particular,\nthey have liked that ROI highlighting is turned on by\ndefault. The experts have commended the usage of\ncolor coding to highlight the ROIs as well as the mar-\nkers or terms. They have also approved our decision to\nconvert HTML documents into plain text in order to\nconcentrate on the text content in the document view\ntabs. The experts have also been very positive about\nthe aggregation charts as a means of overview, pattern\ndetection, and navigation:\nAggregation charts give extremely comprehensive views\nthat are easily understood by this user. These images\nresult in giving the researcher a direct visual confirmation\nof the number of markers, which then can be scrolled\nthrough, chosen and loaded.\nThe ability to export stance markers as well the con-\ntent for further manual investigation was also com-\nmented on:\nThis gives the user a pro-active involvement in the\nongoing improvement of the tool that is neither confusing\nnor time-consuming.\nPossible improvements. One of the experts' sugges-\ntions during the development was related to the com-\nparison of several timeline plots. We have addressed it\nby providing an ability to control the layout of the\ntimeline view and to disable the automatic vertical\nscaling which allows the user to compare the plots\nsituated side by side. The feedback also included some\ncomplaints related to the tool performance (see below\nin the next subsection) as well as a wish for additional\nfunctionality related to document set overview (e.g.\nclustering the documents in aggregation charts by the\nURL domain). We have also learned that the trend\nanalysis feature is only rarely used since it currently\nfocuses on already-available time-series data--there-\nfore, we are planning to extend this feature by sup-\nporting predictive trend analysis to increase its level of\nutility.\nSummary. The experts have stated that uVSAT is a\nuseful addition into their arsenal of stance analysis\ntechniques. They are using it to explore and analyze\nthe social media data and complement it with manual\nstance analysis as well as by processing the exported\ndata with other software tools, for example, for con-\ncordance analysis. They have also started to collect the\nML training dataset, thus achieving the general design\ngoals. In general, the domain experts have concluded\nthe following:\nFor a linguist, uVSAT is a viable tool for working with\nstance analysis.\nPerformance and scalability\nIn this subsection, we discuss certain aspects that\naffect the user experience when trying to apply uVSAT\nfor the analysis of rather large datasets: data transmis-\nsion delays, data processing delays, and user interface\nresponsiveness.\nWe currently store neither time-series data nor doc-\nument text data on our visualization server. Hence,\nuVSAT issues request for time-series data, URIs, and\nHTML content from external servers on demand.\nThis leads to delays while retrieving the source data.\nAdditional delays occur while transmitting the data\nbetween the front-end and back-end components and,\nfinally, while processing the data at the server side.\nWe address the networking delay by conducting\nsome types of analyses (such as ROI highlighting or\ntrend computations) on the client side. It currently\nseems, although, that the performance bottleneck is\nthe step of fetching the HTML content from numer-\nous external servers which may have varying connec-\ntion speed, performance, access frequency limitations,\nand even availability. We plan to introduce a local\ndatabase for caching the external data (as well as some\nprocessing results), although it can lead to validity\nconcerns (see subsection ``Lessons learned'').\nAs for the UI responsiveness: D3 and Rickshaw use\nSVG for rendering which may require significant com-\nputational resources (and leads to UI lags). On a 2013\nMacBook Pro computer with Intel Core i7 processor\n(2.3 GHz), sensible UI delays start to occur when re-\nrendering plots with a total of about 3000 points. This\nis partially addressed with a style of workflow involving\npreliminary analysis of time-series overview and focus-\ning on selected time intervals.\nLessons learned\nOur current visualization approach involves multiple\ncoordinated views based on standard representations.\nIts main advantage (as opposed to a more complex\nintegrated view) is the ease of user adoption: the pri-\nmary users of our tool are researchers in linguistics\nwho do not tolerate abundant details or unintuitive\nvisual representations. The corresponding disadvan-\ntage, however, is the necessity of large display area to\nlay out all the views in sufficient size. We plan to\naddress this issue in the future by developing novel\nvisual representations for stance-related and time-\ndependent text data, having the domain particularities\nin mind.\nThe fact that our source data originate in online\nsocial media also has certain consequences: the text\ndocuments may be edited or deleted at any time. This\npresents us with a trade-off between data validity and\nperformance. By fetching online data on user's\ndemand (as uVSAT currently does), every document\nis analyzed in its up-to-date state (or it is marked as\nunavailable), but it requires computational resources\n(and it is also related to inevitable networking delays).\nOtherwise, if the data are cached while the original\ndata are modified, it would invalidate the detailed\nanalysis of document contents. To address this issue,\nwe plan to involve uncertainty tackling techniques.\nAnother possibility would involve storing the versioned\nsource documents--while in practice, it would require\nsignificant resources, in theory, it could provide an\nanalysis opportunity with regard to additional tem-\nporal dimension.\nConclusion and future work\nIn this article, we have introduced the problem of\nstance analysis of online social media texts that\nrequires a joint multidisciplinary effort of researchers\nin linguistics, NLP, and VA. We have described an\nanalysis approach for stance analysis based on senti-\nment or certainty considerations and presented our\ntool uVSAT for visual stance analysis that supports\nthe interactive exploration of time-series data associ-\nated with online social media documents, including\nthe text content of such documents. While uVSAT\ndoes not provide completely automatic stance analysis,\nit facilitates the linguists by complementing manual\nstance analysis of text documents based on close\nreading with a VA approach that allows the researchers\nto use massive datasets originating from social media.\nThe contributions of this article include the descrip-\ntion of a VA tool that contains multiple approaches for\nanalyzing temporal and textual data as well as export-\ning stance markers in order to prepare a stance-\noriented training dataset. We also presented special\nvisualization techniques developed for our tool: the\nhistory diagram (for document set query analysis pro-\nvenance) and the aggregation charts (for document set\noverview, navigation, and comparison).\nWe already used uVSAT for the purposes of the\nStaViCTA project, and we provided feedback from the\nlinguistics experts in this article. Using uVSAT, our\nresearchers in linguistics have been able to collect\nstance markers that are now being used to define\nstance categories other than sentiment and certainty\nor uncertainty (e.g. concessions and judgment). The\ntool is currently being used for collecting documents\nthat form the training dataset for our researchers in\nNLP as well as for actual stance analysis conducted by\nthe linguists. We are convinced that our tool will be\nuseful for other interested researchers.\nFuture work includes additional overview and navi-\ngation techniques for document sets, support for local\ndatabase caching, streaming data, uncertainty tackling\n(with regard to missing time-series data as well as una-\nvailable web documents), and arbitrary time-series\ndata sources. In order to provide our tool to others,\nwe will develop our own (more lightweight) analysis\nengine to become independent from Gavagai. We also\nplan to conduct a larger study to evaluate the effective-\nness of single techniques such as history diagram and\naggregation charts.\n"
}