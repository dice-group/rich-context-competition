{
    "abstract": "Abstract. The research described in the present article was designed to compare three types of\nimage shading: one generated with a Lambertian BRDF and homogeneous illumination such that\nimage intensity was determined entirely by local surface orientation irrespective of position; one that\nwas textured with a linear intensity gradient, such that image intensity was determined entirely by\nlocal surface position irrespective of orientation; and another that was generated with a Lambertian\nBRDF and inhomogeneous illumination such that image intensity was influenced by both position\nand orientation. A gauge figure adjustment task was used to measure observers' perceptions of local\nsurface orientation on the depicted surfaces, and the probe points included 60 pairs of regions that\nboth had the same orientation. The results show clearly that observers' perceptions of these three\ntypes of stimuli were remarkably similar, and that probe regions with similar apparent orientations\ncould have large differences in image intensity. This latter finding is incompatible with any process for\ncomputing shape from shading that assumes any plausible reflectance function combined with any\npossible homogeneous illumination.\n",
    "reduced_content": "James T. Todd*\nDepartment of Psychology, The Ohio State University, Columbus, OH; e-mail: todd.44@osu.edu\nEric J. L. Egan\nDepartment of Psychology, The Ohio State University, Columbus, OH; e-mail: egan.51@osu.edu\nFlip Phillips\nPsychology & Neuroscience, Skidmore College, Saratoga Springs, NY; e-mail: flip@skidmore.edu\n Keywords: 3D shape perception, shading, surface material properties.\n1 Introduction\nOne of the most difficult problems in the study of human perception involves the ability of observers\nto correctly interpret patterns of image shading. The light that reflects from a visible surface toward\nthe point of observation is influenced by three factors: (1) the surface geometry, (2) the pattern of il-\nlumination, and (3) the manner in which the surface material interacts with light. The problem for per-\nceptual theory is to explain how it is possible to tease apart these separate influences in order to make\njudgments about three-dimensional (3D) shape, the pattern of illumination, or an object's material\nproperties.\nIn most natural situations, the light that reflects from a local surface region toward the point of\nobservation (i.e. luminance) varies systematically with surface orientation, as is typically described\nusing the bi-directional reflectance distribution function (BRDF; Nicodemus, Richmond, Hsia,\nGinsberg, & Limperis, 1977). Pont and Koenderink (2007) have proposed four theoretical BRDFs\nthat represent generic types of surface materials that occur in the natural environment. These include\ndiffuse (Lambertian) reflection on matte surfaces, specular reflection on glossy surfaces, backscatter-\ning on rough surfaces, and asperity scattering on surfaces with fine hairs such as peach skin or velvet.\nFor a given homogeneous illumination and a given viewing direction, the BRDF describes a specific\nmapping between local surface orientation and luminance. This is in general a many-to-one mapping,\nso that it is possible for local regions with different 3D orientations to have the same luminance. How-\never, under homogeneous illumination, all points with the same local 3D orientation must always have\nthe same luminance.\nThe traditional approach to computing shape from shading is based on an assumption that all\nvariations in luminance are due entirely to variations in surface orientation. It is typically assumed,\nfor example, that a surface has a Lambertian reflectance function that scatters light equally in all\ndirections, and that it is illuminated homogeneously by a collimated light field. Most models have\na Pion publication\n*Corresponding author.\nIs the perception of 3D shape from shading based on\nassumed reflectance and illumination?\n498 Todd JT, Egan EJL, Phillips F\nassumed that the illumination direction is known. However, Kunsberg and Zucker (2013) have recently\ndemonstrated that it is possible to obtain shape estimates that are light source invariant by analyzing\nthe second-order differential structure of the luminance field. Although this is an important advance,\ntheir analysis still retains the traditional assumptions about Lambertian reflectance and homogeneous\nillumination.\nThere is considerable evidence to suggest that the perception of shape from shading by human\nobservers cannot be based on a default Lambertian reflectance assumption. It was demonstrated early\non that the accuracy of observers' judgments about shape or lightness are as good or better when the\npatterns of shading have both Lambertian and specular components (Mingolla & Todd, 1986; Norman,\nsimulated displays are purely Lambertian, observers' shape judgments can deviate significantly from\nthe expected results based on traditional models (Khang, Koenderink, & Kappers, 2007; Seyama &\nSato, 1998). Of course these results do not preclude the possibility that some other assumed reflectance\nfunction exists that could account for perceptual performance.\nIt is possible that observers adopt a context-dependent strategy in which they first attempt to\nidentify the surface material and then use the appropriate reflectance function to estimate 3D shape.\nAlternatively, they could adopt a single, hybrid reflectance function that is applied over multiple sur-\nface materials (e.g. see Wijntjes, Doerschner, Kucukoglu, & Pont, 2012). In the present article, we will\npresent evidence that is inconsistent with either of these possibilities. In particular, we will introduce a\ntechnique called ramp shading to create stimuli for which observers'perceptions are incompatible with\nany plausible reflectance function combined with any possible homogeneous illumination.\nA ramp-shaded image is created by texturing a surface with a planar projection of a linear inten-\nsity gradient. This defines the local image intensity for each local surface region based on its position\nirrespective of its orientation. Note that this is the opposite of an image rendered with a BRDF, which\ndefines the local image intensity for each local surface region based on its orientation irrespective of\nits position. For surfaces that are approximately spherical, ramp-shaded images can be quite similar to\nthose rendered with a Lambertian BRDF. This is demonstrated in Figure 1, which shows two images\nof a deformed sphere. The image in Panel A was rendered with a Lambertian BRDF using a collimated\nlight field that was parallel to the viewing direction. The one in Panel B was textured with a linear\nintensity gradient that was oriented in depth (i.e. it is the equivalent of a range image). Panels C and D\nFigure 1. Two images of a deformed sphere (A and B) and their corresponding patterns of isophotes (C and D).\nThe image in Panel A was rendered with a Lambertian BRDF using a collimated light field that was parallel to\nthe viewing direction. The one in Panel B was textured with a linear intensity gradient that was oriented parallel\nto the viewing direction. The isointensity contour plots are coded so that red bands represent the highest image\nintensities and the violet bands represent the lowest.\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 499\nshow the pattern of isophotes for these images, in which the borders between the colored bands mark\npoints with the same image intensity, and the hue of these bands identifies the magnitudes of image\nintensity. Note that both images have quite similar patterns of isophotes. It is mainly in the concave\ncrease where they diverge, such that the Lambertian shading in this region is much brighter than in the\nramp-shaded version.\nLambertian and ramp-shaded images deviate more substantially when they depict distorted planes,\nsuch as the one shown in Figure 2. The image in Panel A was again rendered with a Lambertian BRDF\nusing a collimated light field that was parallel to the viewing direction; the one in Panel B was textured\nwith a linear intensity gradient that was oriented at a 45\u00b0 angle to each of the primary axes; and Pan-\nels D and E show the patterns of isophotes for these images. Although ramp shading is a completely\nartificial technique for depicting surfaces, it is similar in some respects to translucency. The apparent\nglow on a translucent surface due to sub-surface scattering (e.g. on a burning candle) is attenuated by\nthe distance that light rays must travel through the volume of the material, much like ramp shading is\nattenuated with distance along the gradient of the texture map. Indeed, observers often comment that\nthe image in Panel B appears to depict a translucent material like frosted glass or snow, but that its\napparent 3D shape is quite similar to the surface in Panel A.\nThere are other natural processes that also cause shading to vary as a function of local surface\nposition in addition to local surface orientation. These include light attenuation with distance from the\nlight source, cast shadows, and surface interreflections, all of which are demonstrated in Figure 2C.\nThe surface depicted in this image has a Lambertian BRDF, and was illuminated by a large rectangular\narea light positioned near the lower left of the surface with two bounces of interreflection. Traditional\ncomputational models would produce distorted shape estimates for this scene because it violates the\nassumption of homogeneous illumination. This occurs because the ridge casts a shadow penumbra\nonto the valley--what is sometimes referred to as vignetting. Another thing to note in this image is the\nintensity gradient on the background surface due to light attenuation from the lower left to the upper\nFigure 2. Three images of a deformed plane (A, B, and C) and their corresponding patterns of isophotes (C,\nD, and E). The image in Panel A was rendered with a Lambertian BRDF using a collimated light field that was\nparallel to the viewing direction; the one in Panel B was textured with a linear intensity gradient that was oriented\nat a 45\u00b0 angle to each of the primary axes; the one in Panel C was rendered with a Lambertian BRDF using a\nlarge rectangular area light positioned near the lower left of the surface with two bounces of interreflection. The\nisointensity contour plots are color-coded so that red bands represent the highest image intensities and the violet\nbands represent the lowest. Observers typically report that the depicted 3D shapes in Panels A, B, and C appear\nquite similar, though not identical. The peaks and troughs of the ridges and valleys appear slightly less curved in\nthe ramp-shaded image relative to the Lambertian one with homogeneous illumination, and slightly more curved\nin the Lambertian image with inhomogeneous illumination.\n500 Todd JT, Egan EJL, Phillips F\nright. This would be interpreted as a curved surface by traditional models, but it is perceived correctly\nby human observers as an inhomogeneity in the pattern of illumination (see also Koenderink, Pont,\nTo better appreciate the theoretical significance of the images presented in Figures 1B, 2B, and\n2C, it is useful to consider the expected outcome if observers' perceptions of shape from shading were\nbased on an assumed BRDF and an assumed pattern of homogeneous illumination. A strong prediction\nof that hypothesis is that all image regions with the same apparent 3D orientation should have the same\nimage intensity. This can be observed most clearly by examining a horizontal cross-section through\nthe center of Figure 1A. Note that there are three points along this cross-section that appear to have a\nfronto-parallel orientation, and that they all have the same intensity. Contrast that with the perceptual\nappearance of Figures 1B, 2B, and 2C. In Figure 1B, there are also three points that have an apparent\nfronto-parallel orientation, but the one in the center is much darker than the other two. In Figures 2B\nand 2C, there are many pairs of points on opposite sides of the circular ridge that have different image\nintensities with the same apparent 3D orientation. This is simply not possible based on any process that\ncomputes 3D shape using an assumed BRDF with an assumed homogeneous illumination.\nThe research described in the present article was designed to confirm these anecdotal observations\nwith more rigorous psychophysical measures. Observers made local orientation judgments at numer-\nous probe points on the three shaded images shown in Figure 2. A key aspect of the experimental\ndesign is that the probe points included numerous matched pairs that both had the same depicted local\norientation. For the Lambertian surface with homogeneous illumination depicted in Figure 2A, the\npoints with the same local orientation also had the same image intensity. However, for the ramp shaded\nimage in Figure 2B and the Lambertian surface with inhomogeneous illumination in Figure 2C, the\nintensities of the matched points were generally quite different.\nMethods\nFive observers participated in the experiment, including both authors, and three others who were na\u00efve\nabout the issues being investigated. All of the observers had normal or corrected-to-normal visual acu-\nity, and they all wore an eye patch to eliminate conflicting flatness cues from binocular vision.\nApparatus\nThe experiment was conducted using a Dell Dimension 8300 PC with an ATI Radeon 9800 PRO\ngraphics card and a 19-inch gamma corrected cathode ray tube (CRT) with a spatial resolution of\nStimuli\nThe stimuli consisted of the three images shown in Figure 2. The surface depicted in Panel A was\nrendered with a Lambertian BRDF using a collimated light field that was parallel to the viewing direc-\ntion; the one in Panel B was textured with a linear intensity gradient that was oriented at a 45\u00b0 angle to\neach of the primary axes; and the surface in Panel C was illuminated by a large rectangular area light\npositioned to the lower left with two bounces of interreflection.\nProcedure\nThe task on each trial was to adjust the slant and tilt of a circular gauge figure centered at a given probe\npoint so that it appeared to be within the tangent plane of the surface at that point (see Koenderink,\nvan Doorn, & Kappers, 1992, 1995). Slant is defined in this context as the angle between the surface\nnormal and the line of sight, whereas tilt is the direction of the surface depth gradient within the fronto-\nparallel plane. The gauge figure simulated a small circle in 3D space with a radius of 18 pixels, and a\nperpendicular line at its center with a length of 18 pixels. These appeared in the image as a red ellipse\nwith a small line along the minor axis, whose lengths and orientations could be manipulated using a\nhandheld mouse. When adjusted appropriately, all of the observers were able to perceive this configu-\nration as a circle oriented in depth in the tangent plane with a line perpendicular to it in the direction\nof the surface normal. Observers report that when performing this task they do not make quantitative\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 501\nestimates of local orientation. Rather, they adjust the gauge figure so that it appears to fit on the sur-\nface, and they perform these judgments quite rapidly at a rate of 8 to 10 per minute. Another important\naspect of this procedure is that it is largely unaffected by an observer's knowledge about the stimuli.\nFor example, there have been several studies in which observers compared stimuli that had identi-\ncal occlusion boundaries, but with different material properties, or presented under different viewing\nconditions (e.g. monocular vs. stereoscopic). These studies have revealed large differences in apparent\n3D structure, even though some or all of the observers were cognitively aware that the surfaces they\nwere comparing had the same ground truth (e.g. Khang et al., 2007; Todd, Koenderink, van Doorn,\nobservers in these studies who do not have knowledge of the ground truth produce judgments that are\ncomparable to those that do.\nThe probe points on each image included 60 pairs of regions that both had the same orientation. To\nselect the probe points, all possible pairs of pixels were analyzed to find those whose surface normals\nwere within 1\u00b0 of one another; whose slants were between 0\u00b0 and 75\u00b0; and whose image locations were\nseparated by at least 100 pixels. Points on the planar portion of the surface were excluded from this\nsearch. The matched point pairs were sorted into five bins that spanned the range of possible slants in\n15\u00b0 intervals. Twelve pairs were chosen from each bin to distribute them as evenly as possible on the\nsurface.\nAn experimental session was divided into three blocks, in which observers made settings for all\nof the different probe points within one of the possible stimulus images. Within a session, the blocks\nfor each stimulus were presented in a random order. Each observer participated in four experimental\nsessions on separate days. Thus, each possible probe point in each condition was judged four times by\neach observer.\nResults\nWe began our analysis by measuring the consistency of observers' judgments over multiple experi-\nmental sessions. In order to assess their test-retest reliability, we averaged the judgments over all five\nobservers, and calculated the angular difference between their settings in the first and second halves of\nthe experiment for each probe region in each condition. The black curve in Figure 3 shows the distribu-\ntion of these test-retest differences. Note that they are all tightly clustered around a mean of only 3.2\u00b0.\nThis provides a good estimate of the measurement error in this experiment for evaluating other find-\nings. The red curve in Figure 3 shows the distribution of differences between the average settings at\nFigure 3. The distribution of test-retest differences between the first and second halves of Experiment 1 (black);\nthe distribution of differences between corresponding probe points in all possible pairs of conditions (red); the\ndistribution of differences between the ground truth and the average of observers' settings for each probe point\nin each condition (green); and the distribution of differences between the average settings of the matched probe\npoints within a given condition (blue).\n502 Todd JT, Egan EJL, Phillips F\ncorresponding probe points in each possible pair of conditions. Because this distribution is remarkably\nsimilar to the test-retest differences, these results indicate that any variations in the apparent shapes\nproduced by the three types of shading were quite minimal.\nThe green curve in Figure 3 shows the distribution of differences between the ground truth and\nthe average of observers' settings for each probe point in each condition. Note that the observers made\nlarge systematic errors, such that the average difference from the ground truth was 15.8\u00b0--almost five\ntimes larger than the measurement error in this experiment. Finally, the blue curve in Figure 3 shows\nthe distribution of differences between the average settings of the matched probe points within a given\ncondition. It is clear from these results that there were reliable differences in apparent surface orienta-\ntion for many of the matched probe pairs. This has some interesting theoretical implications, because it\nprovides strong evidence that distortions of perceived shape relative to the ground truth could not have\nbeen based entirely on the bas-relief ambiguity (Belhumeur, Kriegman, & Yuille, 1999; Koenderink,\nvan Doorn, Kappers, & Todd, 2001). Because this ambiguity does not affect affine structure, the rela-\ntive orientations of parallel regions would be invariant over all possible 3D interpretations. Thus, the\nfact that such regions can appear perceptually to have different orientations indicates that the relation-\nship between apparent shape and the ground truth must include a non-affine component.\nIn an effort to understand the specific nature of these perceptual errors we performed affine trans-\nformations on the ground truth using the following equation:\nto estimate the values of the coefficients (a, b, c) that minimize the differences between the normals of\nthe transformed surface and the observers' judgments. If observers' judgments of these surfaces had\nbeen veridical, then the values of the coefficients would be (0, 0, 1). Significant deviations from zero\nfor the first two coefficients indicate that the apparent 3D structure is sheared relative to the ground\ntruth. The third coefficient indicates the slope of apparent depth relative to the ground truth. For exam-\nple, a slope of 0.9 would reveal that the depth relief of the surfaces was systematically underestimated\ntion. We also performed a similar analysis on the average data collapsed over conditions, and the best\nfitting parameter values in that case were (0.02, 20.15, 0.56). These results indicate that the apparent\nshapes of the depicted objects were compressed in depth by roughly 44% relative to the ground truth,\nand that there was also a significant shear in a vertical direction. There were some variations among the\ndifferent observers in this analysis, which are described in Table 1. These results are consistent with\nmany previous studies of 3D shape from shading (e.g. Koenderink et al., 2001; Wijntjes et al., 2012)\nthat have investigated the bas relief ambiguity. It is also important to note, however, that the average\nresidual error with respect to the optimally transformed surface was 7.28\u00b0, which is still over twice\nas large as the estimated measurement error for this experiment. This provides further evidence that\nthere was a non-affine component of the apparent distortions of the surface relative to the ground truth.\nFigure 4 shows all of the probe points employed in this study superimposed on the image of\nthe Lambertian surface with homogeneous illumination. These points are color-coded to identify the\nrelative magnitudes of the residual errors in quintiles from the combined analysis that collapsed over\nconditions. The color coding of these points is based on a ROYGB convention such that points with\nthe highest residuals are marked red, and those with the lowest are marked blue. Perhaps not surprisingly\nTable 1. The best fitting coefficients (a, b, c) and residual error for the average judgments of\nindividual observers collapsed over conditions.\nSubject Mean Residual Angle Horizontal Shear (a) Vertical Shear (b) Depth Scaling (c)\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 503\nthese residuals were highly correlated with the apparent differences between the matched probe pairs\nTo what extent can traditional models of shape from shading account for these results? Let us\nfirst consider a Lambertian surface with a collimated light field that is parallel to the line of sight (see\nFigure 2A). Suppose that the surface has a reflectance (R), an illumination (L), and a fixed ambient\ncomponent (A). For this particular special case, the image intensity (I) for any local surface region with\na slant (s) is determined by the following equation:\n2) I = RL cos(s) 1 A\nAfter rearranging terms, this can be converted to the following:\n3) cos(s) = (I2A)/RL,\nwhich provides a simple method for determining local slant from shading based on known or estimat-\ned values of R, L, and A. Note that for all possible values of these parameters, cos(s) will vary linearly\nwith I. However, our empirical results demonstrate quite clearly that there is a strong curvilinear re-\nlationship between image intensity and the cosine of observers' slant judgments (see Figure 5). These\nresults are similar to those reported previously by Seyama and Sato (1998) and Khang et al. (2007),\nand they provide additional evidence that observers' shape judgments can be incompatible with an as-\nsumed Lambertian BRDF, even when the stimulus displays are consistent with that assumption.\nThe results presented thus far provide strong evidence that observers' judgments of local surface\norientation could not have been based on an assumed Lambertian reflectance function with an assumed\ncollimated light field that is parallel to the line of sight, but they do not eliminate the possibility that\nthese judgments were based on some other assumed BRDF with some other pattern of homogeneous\nillumination. One of the primary goals of this experiment was to provide an empirical test of that possi-\nbility. If the perception of local surface orientation from shading is computed using an assumed BRDF\nand an assumed homogeneous illumination, then all image regions with the same apparent 3D orienta-\ntion should also have the same image intensity. The present experiment was designed specifically to\ntest that prediction by including matched probe regions whose local orientations were within 1\u00b0 of one\nanother. It is important to keep in mind, however, that our proposed test requires that the probe regions\nto be compared must have the same perceived orientation, as opposed to the same ground truth.\nOur analysis of this issue is complicated by the fact that there were reliable differences in appar-\nent surface orientation for many of the matched probe pairs. Fortunately, however, there were still a\nFigure 4. The residuals of the affine deformation analysis in quintiles for all of the possible probe points in\nExperiment 1, superimposed on the image of the Lambertian surface with homogeneous illumination.\n504 Todd JT, Egan EJL, Phillips F\nsubstantial number of point pairs for which the average settings were within measurement error of one\nanother, and we therefore restricted subsequent analyses to those for which the apparent difference in\norientation was less than 6\u00b0. Almost 1/3 of the probe pairs satisfied this criterion, including 17 in the\nhomogeneous Lambertian condition, 18 in the inhomogeneous Lambertian condition, and 21 in the\nramp shading condition. The average difference in judged orientation for these restricted probe pairs\nwas 3.3\u00b0, which is close to the average of 3.2\u00b0 for the test-retest differences.\nTwo different analyses were performed on these restricted probe pairs. First we simulated what\nthe differences in luminance would be for their apparent orientations using the four generic BRDFs\ndescribed by Khang et al. (2007) using the following equations:\n(h\u00b7n)\n\u00b7n\ni\u00b7j\ni j\n(i\u00b7n)(j\u00b7n)\nwhere i is the angle of incidence, j is the angle of exit, and n is the surface normal. These simulations\nused a random sample of 25 illumination directions with a range of slants between 240\u00b0 and 40\u00b0\nrelative to the viewing direction; and the values of the parameters a and k were varied over a range\nbetween 1 and 21 in increments of 5. For the backscattering and asperity BRDFs, the average differ-\nences in luminance were both less than 0.01 on a normalized scale from zero to one. For the diffuse\nBRDF, the average difference was 0.02. The highest variations of luminance occurred for the specular\nBRDF with an exponent of 21, which was the largest one we simulated. The average difference in that\ncase was 0.04. Using that as a frame of reference, we then compared the differences in image intensity\nbetween the restricted probe pairs on the inhomogeneous and ramp-shaded images used in the present\nexperiment. The average differences in these conditions were 0.17 and 0.19, respectively, which is 4.5\ntimes larger than the simulated differences for a specular BRDF. Although it would be mathematically\npossible to construct an artificial BRDF that would produce large differences in luminance for small\ndifferences in surface orientation, it would be highly implausible to suggest that such a BRDF is used\nFigure 5. The cosine of adjusted slant in the homogeneous Lambertian condition of Experiment 1 as a function\nof image intensity.\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 505\nfor the computation of 3D shape from shading in human perception. Thus, excluding that possibility,\nthe present results provide strong evidence that observers'perceptions of these displays could not have\nbeen based on any plausible BRDF combined with any possible homogeneous illumination.\nA reviewer of an earlier draft of this article argued that the results of Experiment 1 do not necessarily\nindicate that observers perceive 3D shape from shading in the conditions with inhomogeneous illu-\nmination or ramp shading. According to this argument, observers may have inferred that all three of\nthe depicted surfaces must have the same ground truth because they had identical occlusion contours.\nThey could then have used their memories of the judged orientations in the Lambertian condition with\nhomogeneous illumination to make their settings in the other two conditions, using the occlusion con-\ntours as an anchor to identify corresponding positions among the different stimuli. Experiment 2 was\ndesigned to test the feasibility of this strategy.\nMethods\nThere were only two possible stimuli in this experiment: the Lambertian surface with homogeneous\nillumination used in Experiment 1 (see Figure 2A), and a toon-rendered version of the same surface\nthat only depicted the occlusion boundaries (see Figure 6). These displays were judged by two of the\nna\u00efve observers who participated in Experiment 1. In all other respects, the methods were identical to\nthose reported for the previous study.\nResults\nWhen we showed the first observer the occlusion-only condition and explained the task, his immedi-\nate response was \"Are you kidding?\" This provided the first indication of how the results would turn\nout. For the judgments of the shaded image, the average test-retest difference for the two observers\nwas 5.6\u00b0 between the first and second halves of the experiment. That increased by almost three folds\nto 15.6\u00b0 for the occlusion-only condition. Similarly, the average difference between the corresponding\nprobe points in the different conditions was 12\u00b0, which is three times larger than the comparable dif-\nferences obtained in Experiment 1. These findings show clearly that the results obtained in the inho-\nmogeneous conditions of Experiment 1 could not have been determined based solely on the occlusion\ncontours and observers' memories of their responses in the homogeneous Lambertian condition.\nAlthough observers in Experiment 2 could not reliably judge local orientation from occlusion contours\npresented in isolation, it does not necessarily follow that the presence of smooth occlusion boundaries\nin Experiment 1 had no effect at all on observers'judgments. Previous research has shown that smooth\nocclusion contours can provide a powerful source of information for the analysis of 3D shape from\nFigure 6. A toon-rendered image that depicts the occlusion contours from the stimuli in Experiment 1. This image\nhas been cropped relative to the one that was used in the Experiment.\n506 Todd JT, Egan EJL, Phillips F\nshading. The surface normals along smooth occlusion contours are always perpendicular to the line\nof sight (Ikeuchi & Horn, 1981), which can provide a critical boundary condition for computational\nanalyses. These contours also provide information about the surface curvature in their immediate lo-\ncal neighborhoods, because the sign of surface curvature in a direction perpendicular to an attached\nsmooth occlusion contour must always be convex (Koenderink, 1984; Koenderink & van Doorn,\n1982b). Under conditions of homogeneous illumination, the local luminance maxima along smooth\nocclusion boundaries provide additional information about the tilt of the illumination direction (Todd\nThere have been several empirical studies to show that this information can influence observers'\nperceptions by resolving ambiguities in the sign of surface relief (Howard, 1983; Reichel & Todd,\n1990; Todd & Reichel, 1989). Consider, for example, the image presented in Figure 7A, which depicts\na Lambertian surface with a collimated light field that is parallel to the line of sight. In the absence of\nsmooth occlusion contours, the depicted relief of this surface is mathematically ambiguous. Neverthe-\nless, for most observers, the apparent relief will be perceptually stable, because they have a strong\nbias to interpret the scene so that depth increases with height in the visual field. If the image is turned\nupside down, however, then the apparent relief can be inverted either wholly or in part (see Reichel &\nTodd, 1990). When surfaces are illuminated by extended light sources, there is other information from\nvignetting that could also be used to disambiguate the sign of surface relief (see Langer & Zucker,\nvex regions, the mean luminance within small concavities will be darker.\nFigure 7. Three images of a deformed plane (A, B, and C) and their corresponding patterns of isophotes (C,\nD, and E). The image in Panel A was rendered with a Lambertian BRDF using a collimated light field that was\nparallel to the viewing direction; the one in Panel B was textured with a linear intensity gradient that was oriented\nat a 45\u00b0 angle to each of the primary axes; and the one in Panel C was rendered with a Lambertian BRDF using a\nlarge rectangular area light positioned near the lower left of the surface with two bounces of interreflection. The\nisointensity contour plots are color-coded so that red bands represent the highest image intensities and the violet\nbands represent the lowest. Observers typically report that the depicted 3D shapes in Panels A, B, and C appear\nquite similar, though not identical. The peaks and troughs of the ridges and valleys appear slightly less curved in\nthe ramp-shaded image relative to the Lambertian one with homogeneous illumination, and slightly more curved\nin the Lambertian image with inhomogeneous illumination.\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 507\nTo what extent did the visible occlusion contours influence performance in Experiment 1? Experi-\nment 3 was designed to address this issue. The stimuli were identical to those used in the earlier study,\nexcept that the overall slant of the surface was reduced just enough to eliminate all occlusions.\nMethods\nThe methods were identical to those reported for Experiment 1 with three exceptions: (1) the three\nshaded images shown in Figure 7 were used as stimuli; (2) a different set of probe points were selected\nusing the same procedure as in the previous study; and (3) these displays were judged by only four of\nthe five observers who participated in Experiment 1. These included both authors, and two others who\nwere na\u00efve about the issues being investigated.\nResults\nThe results are presented in Figure 8. The black curve shows the distribution of test-retest differences\nbetween the first and second halves of the experiment; the red curve shows the distribution of differ-\nences between corresponding probe points in all possible pairs of conditions; the green curve shows\nthe distribution of differences between the ground truth and the average of observers' settings for each\nprobe point in each condition; and the blue curve shows the distribution of differences between the\naverage settings of the matched probe points within a given condition. These findings indicate that: (1)\nobservers judgments were highly reliable; (2) variations in the apparent shapes of the depicted surfaces\namong the different conditions were quite minimal; (3) observers' judgments were systematically\ndistorted relative to the ground truth; and (4) there was a non-affine component to these perceptual\ndistortions. In other words, the results were remarkably similar to those obtained in Experiment 1. In\nthis case, however, the observers'judgments could not have been influenced by the presence of smooth\nocclusion contours, because the stimuli did not contain any occlusions.\nAs in Experiment 1, an affine deformation analysis was performed to measure the affine compo-\nnents of the systematic variations between the observers' judgments and the ground truth. The best fit-\nting parameter values for horizontal shear, vertical shear, and compression in depth were (0.01,20.05,\ncondition. A similar analysis was performed on the average data collapsed over conditions, and the\nbest fitting parameter values in that case were (0.01, 20.02, 0.56). These results are quite similar to\nFigure 8. The distribution of test-retest differences between the first and second halves of Experiment 3 (black);\nthe distribution of differences between corresponding probe points in all possible pairs of conditions (red); the\ndistribution of differences between the ground truth and the average of observers' settings for each probe point\nin each condition (green); and the distribution of differences between the average settings of the matched probe\npoints within a given condition (blue).\n508 Todd JT, Egan EJL, Phillips F\nthose obtained in Experiment 1, except for a reduced amount of vertical shear. The average residual\nerror with respect to the optimally transformed surface was 8.0\u00b0, which is over twice as large as the\nmean test-retest difference of 3.8\u00b0 that was obtained for this experiment. This again confirms that there\nwas a non-affine component of the apparent distortions of the surface relative to the ground truth.\nThe magnitudes of the residuals in quintiles are shown in Figure 9 for all of the possible probe points\nsuperimposed on the image of the Lambertian surface with homogeneous illumination.\nAn additional analysis was performed on the restricted set of probe pairs within each condition\nwhose judged orientations were sufficiently close to be categorized as perceptually equivalent. Because\nthe measurement error in this study was slightly higher than in Experiment 1, we expanded the maxi-\nmum difference for this set to be 7\u00b0. Over 25% of the probe pairs satisfied this criterion, including 16 in\nthe homogeneous Lambertian condition, 19 in the inhomogeneous Lambertian condition, and 16 in the\nramp shading condition. The average difference in judged orientation for these restricted probe pairs\nwas 4.3\u00b0, which is close to the average of 3.8\u00b0 for the test-retest differences. The average differences\nin image intensity for these restricted probe pairs in the inhomogeneous and ramp shaded conditions\nwere 0.16 and 0.20, respectively, which is again much larger than what would be expected from any\nof the generic BRDFs proposed by Khang et al. (2006) with any possible homogeneous illumination.\n5 Discussion\nThe research described in the present article was designed to compare three types of image shading:\none generated with a Lambertian BRDF such that image intensity was determined entirely by local\nsurface orientation irrespective of position; one that was textured with a linear intensity gradient, such\nthat image intensity was determined entirely by local surface position irrespective of orientation; and\nanother that was generated with a Lambertian BRDF and inhomogeneous illumination such that image\nintensity was influenced by both position and orientation. The results show clearly that observers' per-\nceptions of these three types of stimuli are remarkably similar, even though there was little similarity\nin their patterns of image intensity.\nIt is interesting to note in this regard that there have been several other studies reported in the\nliterature for which changes in illumination or surface material properties have not produced the same\ndegree of shape constancy as in the present experiments (e.g. see Khang et al., 2007; Mingolla &\nFigure 9. The residuals of the affine deformation analysis in quintiles for all of the possible probe points in\nExperiment 3, superimposed on the image of the Lambertian surface with homogeneous illumination.\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 509\nTodd, 1986). The primary reason for these discrepancies, we suspect, involves the depicted surface\ngeometry. For example, in the experiments by Khang et al. (2007) and Mingolla and Todd (1986) the\nstimuli were restricted to ellipsoid surfaces, which appear much less perceptually compelling than the\nsurfaces used in the present studies that contained ridges, valleys, and saddle-shaped regions. Another\npossible source of violations of shape constancy with changes in illumination is the use of collimated\nlight fields. As the collimated beams become more and more slanted relative to the line of sight, the\nproportion of visible surface regions within attached shadows will increase. In the absence of surface\ninterreflections, these regions will have no shading at all, and cannot therefore provide any information\nfor the computation of 3D shape from shading (e.g. see Nefs, Koenderink, & Kappers, 2005).\nA key aspect of the design of the present experiments is that the probe points included numer-\nous matched pairs that both had the same depicted local orientation. If the perception of local surface\norientation from shading is computed using an assumed BRDF and an assumed homogeneous illu-\nmination, then all image regions with the same apparent 3D orientation should also have the same\nimage intensity. Among the sixty probe pairs we examined in each condition in each of the two experi-\nments, approximately 30% of them had judged orientations that were within measurement error of one\nanother. The image intensity differences between those matched probe regions in the inhomogeneous\nand ramp-shaded conditions were much larger than what would be expected from any of the generic\nBRDFs that have been proposed in the literature combined with any possible homogeneous illumina-\ntion.\nThe present results would not necessarily be incompatible with an assumed BRDF for the com-\nputation of 3D shape from shading if the assumption of homogeneous illumination were abandoned.\nThat latter assumption is only adopted for computational convenience, and it is almost always violated\nin natural vision, especially in indoor environments. However, it is not at all clear how an assumed\nBRDF by itself would provide sufficient constraint to compute local surface orientation from inverse\noptics with patterns of illumination that are inhomogeneous. Moreover, it is also difficult to reconcile\nthat assumption with the fact that human observers can identify a wide variety of material properties.\nFor example, consider the images presented in Figure 10, which depict a translucent milky substance,\nhammered gold, glossy red paint, glass, four different types of cloth and blue fur. Not only can we\nidentify the materials in these images, but we can also perceive the depicted 3D shapes, despite the fact\nthat they all have different inhomogeneous patterns of illumination. These observations suggest that\nthe perception of 3D shape and material properties are somehow determined simultaneously with one\nanother, and that they do not depend on prior knowledge about the light field.\nThe traditional theoretical approach to the analysis of image shading is nicely summarized in a\nrecent paper by O'Shea, Agrawala, and Banks (2010): \"Three scene properties determine the lumi-\nnances in the image of a shaded object: the material reflectance, the illuminant position, and the\nobject's shape. Because all three properties determine the image, one cannot solve for any one prop-\nerty without knowing the other two. Nevertheless, people perceive consistent 3D shape and con-\nsistent lighting in shaded images; they must therefore be making assumptions about the unknown\nproperties.\" Computational models for determining shape from shading based on assumptions about\nillumination and material properties have been around since the 1970s, but their performance has\nbeen consistently disappointing (see Zhang & Tsai, 1999, for a review). The problem with all of these\nmodels is that they are designed to be used in narrowly constrained contexts, and they do not degrade\ngracefully when their numerous underlying assumptions are violated--as is almost always the case\nin natural vision.\nThe perceptual analysis of image shading by human observers, in contrast, is remarkably robust.\nObservers can correctly interpret a wide variety of optical phenomena that would wreak havoc on\nexisting computational models, including light attenuation (e.g. Koenderink et al., 2007), cast shadows\n(e.g. Liu & Todd, 2004; Mamassian, Knill, & Kersten, 1998), specular highlights (e.g. Doerschner,\nparency (e.g. Fleming, J\u00e4kel, & Maloney, 2011), translucency (Fleming & B\u00fclthoff, 2005), and surface\ninterreflections (e.g. Gilchrist & Jacobsen, 1984; Madison, Thompson, Kersten, Shirley, & Smits,\n2001). The present research has demonstrated, moreover, that observers can even obtain reliable infor-\nmation about 3D shape from images created using an artificial rendering technique that has no direct\nanalog in natural vision. This remarkable generality is one of the most important characteristics of the\nability of human observers to perceptually interpret patterns of image shading, and it should not be\nignored in theoretical discussions of this phenomenon.\n510 Todd JT, Egan EJL, Phillips F\nOne possible alternative to traditional models has recently been proposed by Sun and Schofield\n(2012). They argued that the perception of shape from shading involves two distinct modes of analysis.\nOne they refer to as the linear shading model (Pentland, 1989) is presumed to operate for oblique illu-\nminations such that perceived slant is proportional to local image intensity. The other they refer to as\nthe dark-is-deep rule (Langer & Zucker, 1994). It is presumed to operate for fronto-parallel or diffuse\nilluminations such that perceived position in depth is proportional to local image intensity. In order to\nassess this hypothesis, we created images of a spherical surface illuminated by a distant point light or\na hemispheric dome light at five different slants varying from 0\u00b0 to 90\u00b0. We then correlated the local\nimage intensities in these images with the local surface depths and slants on the depicted surface. The\nresults of these analyses are presented in Table 2. Note that depth and slant both have a high negative\ncorrelation with image intensity when the primary direction of illumination is parallel to the line of\nsight, but that the correlations drop quite rapidly as the illumination angle is increased. Although it\nis conceivable that the perception of shape from shading involves multiple modes of analysis as sug-\ngested by Sun and Schofield (2012), there are very few contexts in natural vision for which a linear\nshading model or a dark-is-deep rule would provide an effective strategy for estimating either depth or\nFigure 10. Example images of different 3D shapes with different material properties and different inhomogeneous\nilluminations. The depicted materials include a translucent milky substance, hammered gold, glossy red paint,\nglass, four different types of cloth, and blue fur. The glass example was created by Toni Fresnedo (tonifresnedo.\ncom) using the Maxwell renderer. The cloth examples are from Sadeghi et al. (2013) using a new state-of-the-art\nalgorithm for simulating cloth materials. All of the cloth examples have the same depicted geometry and the same\nillumination, but they have different BRDFs, which produce noticeably different patterns of shading. All of the\nother examples were created using the VRAY renderer. The translucent material was created using a bidirectional\nsurface scattering reflectance distribution function (BSSRDF) for skim milk based on measurements by Jensen,\nIs the perception of 3D shape from shading based on assumed reflectance and illumination? 511\nAnother possible alternative to traditional methods of shape reconstruction from shading was\ncontours that connect points of equal intensity in an image, called isophotes, in an effort to identify\ninvariant features in these patterns that could be informative about 3D shape. Consider, for example,\nthe X-junctions where two isophotes cross one another. For surfaces with Lambertian BRDFs and\nhomogeneous illumination (e.g. see Figures 1A, 2A, and 7A), these X-junctions will always cor-\nrespond to parabolic points on the depicted surface where there is zero curvature in one direction.\nA similar approach was later adopted by Breton and Zucker (1996), and, more recently, by Fleming,\nTorralba, and Adelson (2004). Some empirical evidence to support this approach has been reported by\nWijntjes et al. (2012). They showed that two images depicting different 3D shapes appear perceptually\nsimilar if they have similar patterns of isophotes.\nTable 2. The correlation of local image intensity with\ndepth and slant for a spherical surface illuminated by a\ndistant point light or a hemispheric dome light at five\ndifferent slants varying from 0\u00b0 to 90\u00b0.\nIllumination\nSlant (degrees)\nCorrelation (r)\nPoint Light Dome Light\nSlant Depth Slant Depth\nFigure 11. The isophote patterns from the homogeneous and inhomogeneous Lambertian conditions of Experiment 3,\nsuperimposed on one another in different colors. All adjacent contours in this figure represent a difference of\n14.3% of the entire luminance range.\n512 Todd JT, Egan EJL, Phillips F\nIt is unlikely, however, that observers' perceptions of 3D shape from shading are based solely on\nthe pattern of isophotes or luminance gradients, because there are some manipulations of a scene that\ncause large changes in the first-order image structure, but have a negligible effect on observers' shape\njudgments (e.g. Mingolla & Todd, 1986; Todd & Reichel, 1989). Our manipulation of the direction\nand manner of illumination in the present experiments provides an excellent example of this phenom-\nenon. The effects of these lighting changes on observers' judgments were quite minimal, but they had\na large effect on the first-order image structure. To demonstrate this more clearly, Figure 11 shows the\nisophote patterns from the homogeneous and inhomogeneous Lambertian conditions of Experiment 3,\nsuperimposed on one another in different colors. All adjacent contours in this figure represent a differ-\nence of 14.3% of the entire luminance range, such that the luminance gradients are inversely propor-\ntional to the spacing between the isophotes. Note in this case that the gradients were much steeper in\nthe condition with a fronto-parallel collimated light field than in the one that was illuminated with a\ndiagonally positioned area light, although the latter display produced slightly more apparent depth and\ncurvature. Note also that in most regions of these images the isophotes (and gradients) were oriented\nin different directions. Based on these observations, we suspect it is the case that the higher order dif-\nferential structure of an image plays a critical role in the analysis of image shading, as has also been\nsuggested by Kunsberg and Zucker (2013). The theoretical analysis of those higher order properties\nremains as an important problem for future research.\n"
}