{
    "abstract": "Abstract\nBackground: The Organizational Process Improvement Intervention (OPII), conducted by the NIDA-funded Criminal\nJustice Drug Abuse Treatment Studies consortium of nine research centers, examined an organizational intervention\nto improve the processes used in correctional settings to assess substance abusing offenders, develop case plans,\ntransfer this information to community-based treatment agencies, and monitor the services provided by these\ncommunity based treatment agencies.\nMethods/Design: A multi-site cluster randomized design was used to evaluate an inter-agency organizational process\nimprovement intervention among dyads of correctional agencies and community based treatment agencies. Linked\ncorrectional and community based agencies were clustered among nine (9) research centers and randomly assigned\nto an early or delayed intervention condition. Participants included administrators, managers, and line staff from the\nparticipating agencies; some participants served on interagency change teams while other participants performed\nagency tasks related to offender services. A manualized organizational intervention that includes the use of external\norganizational coaches was applied to create and support interagency change teams that proceeded through a\nfour-step process over a planned intervention period of 12 months. The primary outcome of the process improvement\nintervention was to improve processes associated with the assessment, case planning, service referral and service\nprovision processes within the linked organizations.\nDiscussion: Providing substance abuse offenders with coordinated treatment and access to community-based services\nis critical to reducing offender recidivism. Results from this study protocol will provide new and critical information on\nstrategies and processes that improve the assessment and case planning for such offenders as they transition between\ncorrectional and community based systems and settings. Further, this study extends current knowledge of and\nmethods for, the study of evidence-based practice adoption and implementation.\n",
    "reduced_content": "A cluster randomized trial of an organizational\nprocess improvement intervention for improving\nthe assessment and case planning of offenders: a\nStudy Protocol\nMichael S Shafer*, Michael Prendergast, Gerald Melnick, Lynda A Stein, Wayne N Welsh\nand the CJDATS Assessment Workgroup\n Keywords: Correctional treatment systems; Assessment; Case planning; Change teams; Facilitators;\nMulti-site cluster randomized design\nCorrespondence: michael.shafer@asu.edu\nArizona State University, School of Social Work, 500 N. Third Street, Suite 200,\n\u00a9 Shafer et al.; licensee Springer. This is an open access article distributed under the terms of the Creative Commons\nAttribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original work is properly cited.\nShafer et al. Health and Justice\nhttp://www.healthandjusticejournal.com/content/2/1/1\nBackground\nScreening and assessment are clinical processes used to\ndetect and then determine the extent, pervasiveness, or\nseverity of presenting problems or issues by patients in a\nvariety of health and other service settings. For indivi-\nduals engaged in criminal justice or correctional systems,\nthese screening and assessment processes should identify\nand evaluate criminogenic risks, including mental health\nand drug abuse problems, in order to tailor correctional\nsupervision and rehabilitative services to those who\nneed them (Lowenkamp and Latessa 2005; Taxman and\nand assessment tools have been validated for use in both\nsubstance abuse treatment and correctional programs.\nThese instruments assess static and dynamic individual\nfactors that can aid in informing the intensity and course\nof substance abuse treatment and correctional supervi-\nsion that is expressed in an offender case plan. Linking\nscreening and assessment information to offender case\nplans is a cornerstone of the Risk-Need-Responsivity\nprinciple, a feature of evidence-based correctional pro-\nThere is some evidence that the assessment and case\nplanning processes used in criminal justice and correc-\ntional settings are less than optimal (Taxman, Cropsey\nof institutional correctional agencies (prisons and jails)\nin the United States reported use of standardized assess-\nment instruments, with community correctional agencies\n(probation and parole) showing even lower rates of\nutilization (Taxman, Cropsey et al. 2007). The lack of val-\nidated screening and assessment processes in correc-\ntional settings represents a significant threat to the\noverall effectiveness of correctional services. In the ab-\nsence of effective offender assessment processes, re-\nsponsive supervision and treatment plans cannot be\ndeveloped, putting the offender at risk of re-offending,\nand the public at risk of victimization and crime.\nSystematic approaches to organizational change within\ncorrectional and criminal justice settings date back to\nthe 1960s with a focus on prison reform and community\n1975). Nonetheless, rigorous research related to the im-\nplementation of specific, targeted, evidence-based super-\nvision and/or clinical practices is lacking in criminal\njustice systems. The supervision and clinical practices\nassociated with the assessment, case planning, and refer-\nral to community-based substance abuse treatment of\noffenders is an important dimension of the criminal just-\nice system. These practices take on particular import-\nance when one considers the growth in the offender\npopulation in general, the prevalence of community cor-\nrectional supervision, the high prevalence of substance\nuse disorders among individuals under correctional\nsupervision, and the resulting reliance on interagency\n(correctional-treatment) models of service delivery\nAims and objectives\nThe aim of this study is to test an interagency implemen-\ntation strategy in linked correctional and community-\nbased treatment systems to improve the assessment and\ncase planning processes that these agencies and their staff\nperform as they coordinate substance abuse treatment\nand services for offenders transitioning between these two\nsystems. Since correctional and community-based treat-\nment systems are heavily influenced by state-level policies\nand funding resources, a randomized cluster design, with\nclusters formed at the state level, controls for the effects\nof the exogenous policy environment. The implementa-\ntion strategy consists of externally facilitated orga-\nnizational coaching and interagency Local Change Teams\n(LCTs) that include individuals in staff and managerial po-\nsitions from correctional and community treatment agen-\ncies. The objectives of this study are threefold: (1)\nimprove the quality of the assessment and case planning\nprocesses of correctional-based agencies; (2) assess the ef-\nfectiveness of an externally facilitated, interagency change\nteam process in implementing targeted process improve-\nments; and (3) evaluate the impacts and determinants of\nthis change process upon staff behavior, attitudes, and\nquality of assessment and case planning processes.\nSignificance\nThe social significance of this study lies in its context\nwithin criminal justice systems and its focus on the pro-\ncesses of offender assessment and case referral, an inter-\nagency juncture long recognized to be faulty and ill-\ndevised (Taxman, Cropsey et al. 2007; Taxman, Perdoni\nand Harrison 2007). As society continues to grapple with\nthe explosion in incarceration and community supervi-\nsion, it is critical to identify more effective and efficient\nprocesses and procedures for correctional systems to\nbetter assess the needs of offenders and to provide this\ninformation to community-based providers to enable\nthem to deliver evidence-based treatment to offenders.\nThe utilization of organizational coaching and external\nfacilitation has been well documented in the research lit-\nerature, and change teams have been a common element\nin implementation change processes, but the facilitation\nof interagency change teams, which involve the needs,\nabilities, and priorities of different systems of care, such\nas correctional agencies and treatment programs, has\nbeen less well studied (Aarons et al. 2009).\nThe research significance of this study lies in its\napplication of an innovative research design and the\nutilization of multi-method measurement processes to\nShafer et al. Health and Justice Page 2 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\nstudy community-generated process improvement targets.\nThe diversity of process improvement action targets taken\non by the LCTs and the reliance upon newly developed\nnon-psychometrically validated instrumentation cre-\nates potentially significant analytic and interpretation\nchallenges. The lessons learned from this study may\ncontribute to a better understanding of appropriate\nand efficacious methodological approaches to the study\nof organizational change and implementation.\nMethods/Design\nIntervention\nThe OPII tested the effects of an organizational imple-\nmentation strategy upon improvements in an intervention\nstrategy, consistent with the emergent field of implemen-\ntation research that distinguishes intervention strategies\n(those activities delivered to program recipients) from\nimplementation strategies (those activities delivered to or-\nganizations and providers delivering the intervention\nstrategy) (Proctor et al. 2009). The intervention strategy\nthat we targeted was the linked processes of offender as-\nsessment, case planning, and referral to community based\ntreatment shared by correctional agencies and linked\ncommunity based treatment agencies. The implementa-\ntion strategy tested was an organizational intervention\nconsisting of externally facilitated organizational coaching\nprovided to interagency LCTs.\nThe implementation strategy of the OPII is similar to\nthe NIATx model that uses a change team and coach to\nbring about process improvements in behavioral health\nsettings (McCarty et al. 2007). However, the OPII differs\nfrom the NIATx model in the following ways: (1) the fa-\ncilitator in OPII was more engaged with the LCT than a\nNIATx coach would be; (2) the OPII had defined phases\nwith phase-specific activities and reports in contrast to\nthe more open-ended process of NIATx; (3) the OPII\ndid not use rapid-cycle testing, Plan-Do-Study-Act\n(PDSA) processes, which are core elements of NIATx;\nand (4) the OPII targeted interagency change team pro-\ncesses (corrections and treatment) while NIATx involves\na single agency.\nEach LCT was made up of individuals from a partici-\npating correctional agency and at least one community-\nbased substance abuse treatment agency that received\nreferrals from the correctional agency. The LCT ranged\nin size from 6 to 10 individuals, and included individuals\nwith responsibility for the assessment, case planning,\nreferral processing, and substance abuse treatment plan-\nning functions. The size and composition of LCTs\ndepended upon the local context and the organizational\ncharacteristics of the participating correctional and pro-\nvider agencies.\nEach LCT had a Local Change Team Leader (LCTL).\nThe individual designated for this position was expected\nto have direct line communications to the chief execu-\ntive officer (e.g. commissioner, chief probation officer,\nparole board chair, or parole director) of the corrections\npartner agency in which the OPII was being conducted.\nThe LCTL served as the communication and decision-\nmaking pipeline with the corrections agency CEO and\nfacilitated logistical and operational change processes\nidentified by the LCT.\nThe facilitator was an individual who worked with the\nLCT throughout the organizational improvement pro-\ncess. Each research center, in cooperation with the rele-\nvant correctional agency partner, selected facilitators\nwho were under the employ of the RC. In general, facili-\ntators had previously worked directly with agency pro-\nviders in some capacity and possessed credentials and\nexperience that provided credibility with the LCT.\nFacilitators helped LCTs stay on track and on task as\nthey engaged in a structured, five-phase model of as-\nsessing and improving the quality of their interagency\nassessment and case planning mechanisms within cor-\nrectional and community treatment systems. The five\nstructured phases of the OPII and the planned duration\nof each phase were as follows: (1) Team Development\nProcess Improvement Planning (3\u00ad4 months); (4) Imple-\nmentation (6 months); and (5) Follow-Up/Sustainability\n(6 months).\nDuring the Needs Assessment phase, the LCT engaged\nin a variety of information gathering and group decision-\nmaking techniques to critically examine and prioritize gaps\nor capacities in four core quality dimensions of their\nshared assessment and case planning processes: (1) Was\nthe correctional agency using evidence-based and vali-\ndated means for assessing the needs of offenders? (2) Were\nthese needs identified and prioritized in the resulting case\nplans developed by the correctional agency? (3) Did the\ncorrectional agency share this assessment and case plan\ninformation with their referring community-based treat-\nment providers, and did the providers find this informa-\ntion useful? (4) Did the community based agency provide\nservices that addressed the needs of the offenders? The\nLCT, with assistance provided by the facilitator, used infor-\nmation gathered during the Needs Assessment to identify\nimprovement goals, created a Process Improvement Plan\n(PIP), and carried out the implementation activities\nthey had set out for themselves (see Table 1). During the\nSustainability phase, the LCT developed a plan to continue\nimplementation activities and the planned withdrawal of\nthe facilitator. During this phase, attention was paid to\ndetermining if continuing work on the PIP goals was\nneeded, if new goals were needed, and whether the LCT\nprocess would continue.\nCross-site fidelity among those individuals serving as\nfacilitators was attained through three mechanisms.\nShafer et al. Health and Justice Page 3 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\nFirst, a facilitators' manuala was developed prior to the\nlaunch of the study. Second, weekly learning circle calls\namong the facilitators, which included discussion of site\nupdates and group problem-solving of organizational\nimpediments and challenges, assisted in enhancing cohe-\nsion and consistency in approach. Third, a secure web-\nportal utilized by the facilitators to report the frequency,\nduration, and type of contacts that they had with mem-\nbers of their change teams, along with descriptive pro-\ngress notes, allowed the research team to monitor the\nactivities of the facilitators.\nNine research centers (RC) participated in this study,\nwith each RC comprised of correctional/criminal justice\n(CJ) agencies, community-based treatment agencies, and\nresearchers. The role of each RC in the OPII study was\nto create and participate in the implementation strategy\nand to participate in workgroups that addressed issues\nsuch as implementation, data collection and quality, ana-\nlysis, and publication. Resources and incentives provided\nby the research centers to the CJ and community pro-\nviders varied across centers, but included opportunity\nand nominal funding for education (continuing educa-\ntion units), improvements in delivery of services, and de-\nvelopment of an implementation process that could be\nused after the research was completed.\nResearch design\nEvaluation of the OPII used a multi-site cluster random-\nized design. Organizational clusters consisted of linked\ncorrectional and one or more community-based sub-\nstance abuse treatment agencies providing correctional\nand substance abuse treatment services to common cli-\nents. Nine research centers contributed at least two clus-\nters both of which were located within the same state. In\nthis design, one cluster was randomly assigned to an early\nstart condition, and the other cluster was assigned to a de-\nlayed start condition (see Figure 1). Randomization as-\nsignment was conducted by the cross center research\nworkgroup using the randomization function in Excel for\neach research center prior to their kick-off meeting. Early-\nStart sites began the OPII, while the Delayed-Start sites\nmaintained business as usual without any additional inter-\nvention. The Delayed-Start LCT was supposed to begin\nthe OPII after approximately 12 months, or when the\nEarly-Start site LCT had completed the Implementation\nphase of the OPII. The time required for each LCT to\ncomplete each phase of the OPII varied, based upon the\nexisting cohesion among the LCT members, local con-\ntextual factors, and the complexity of the system and\nresulting goals set by the LCT. Within each research cen-\nter, the Early and Delayed-Start sites were chosen so their\nsystems of care were relatively independent.\nCluster randomization designs are more complex than\nrandomization at the individual level, in part because\nintra-cluster inter-correlations (e.g., individual-level fac-\ntors) introduce a design effect that must be estimated\nfor sample size determinations and incorporated into\nanalyses of study data (Glynn et al. 2007). However,\nTable 1 Core dimensions of the assessment continuum\nMeasurement and\ninstrumentation\nThis dimension is concerned with the breadth and quality of instruments that a correctional agency uses to identify the\nstrengths, weaknesses, and service needs of substance-using offenders. Nine domains have been identified as being\nfundamental to a high quality assessment of offenders with substance use disorders:\n1. History and patterns of substance abuse\n2. History of and engagement in drug treatment\n3. Motivation for treatment\n4. History of mental illness\n5. Suitability for pharmacological treatment\n6. Medical history\n7. HIV/AIDS status and risk factors\n8. Criminal behavior\n9. Criminogenic risk factors\nIn addition to focusing on the comprehensiveness of the assessment, this dimension is also concerned with the\npsychometric properties of the instruments.\nIntegration with the\ncase plan\nThis dimension is concerned with the extent to which the correctional case plan explicitly addresses each of the nine\nassessment domains. It also seeks to gauge efficacy and suitability to the needs of the offender as called for in the written\nproblem statement, goals, objectives, and suggested interventions.\nConveyance and\nutility\nThis dimension is concerned with the extent to which community-based treatment programs receive the information\ncontained in the corrections agency case plan and with the degree to which the programs find the information useful in\narranging services for clients.\nService activation/\nprovision\nThis dimension is concerned with whether the client is engaged in community treatment, with the type and nature of\nservices received, and with communication between agencies about the treatment.\nShafer et al. Health and Justice Page 4 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\ncluster randomized designs are well suited to studies in\nwhich the intervention is targeted at the organizational ra-\nther than at the client level, as was the case for the OPII.\nInitially, the Delayed-Start sites served as the comparison\nfor the Early-Start sites in that they continued to conduct\ntheir assessment, case planning, and referral procedures as\nusual. Since these procedures varied considerably across\nthe correctional systems involved in the study, there was\nno uniform comparison condition across all sites.\nSample\nThe CJDATS research centers each recruited two cor-\nrectional agencies, and each correctional agency had one\nor more community treatment providers. Correctional\nsettings included prisons, probation and parole units.\nMost (19) of the participating correctional settings\nserved adults, but two of them served juveniles. There\nare 10 sites (clusters) in each study condition, for a total\nof 21 study sites.b As indicated earlier, staff members\nparticipating in the LCT included representatives from\nboth correctional and community-based treatment agen-\ncies who conducted assessments and/or prepared case\nplans and those who held management or clinical super-\nvision positions. Each LCT included 6\u00ad10 staff mem-\nbers. Thus, the total number of LCT members ranged\nwere the main participants in the study, correctional and\ntreatment staff who were not members of the LCT were\nincluded in the administration of some of the surveys.\nData collection and measures\nOutcomes\nThe outcomes of primary interest were those related to\nchange in the intervention being provided to offenders,\nnamely, assessment and case planning processes. Mea-\nsures of intervention outcomes included congruence be-\ntween assessed needs and case plan recommendations,\nquality of the content of the case plan, conveyance of\ncase plans to community treatment providers, and\ncross-organizational coordination.\nDesign Overview and Planned Timeline*\nFacilitator Training\n(Initial 2-day face-to-face meeting and weekly conference calls)\nBaseline Data Collection: Early-Start and Delayed-Start Sites\nBSOC Surveys\nStudy-Specific Surveys\nCase Plan Ratings\nRandomization to Early-Start or Delayed-Start Site\nEarly-Start Sites Delayed-Start Sites\nOPII Intervention No Intervention\n1. Start-up Phase Activities\n2. Needs Assessment\n3. Process Improvement Planning\n4. Implementation\n5. Sustainability/Follow-up\nFollow-up Data Collection: Early-Start and Delayed-Start Sites\nStudy-Specific Surveys\nChange Team/Agency Staff Interviews\nCase Plan Ratings\nEarly-Start Sites Delayed-Start Sites\nNo Intervention OPII Intervention\n1. Start-up Phase Activities\n2. Needs Assessment\n3. Process Improvement Planning\n4. Implementation\n5. Sustainability/Follow-up\nFollow-up Data Collection Delayed-Start Sites\nStudy-Specific Surveys\nChange Team/Agency Staff Interviews\nCase Plan Ratings\n* See text for description of data collection forms.\nOPII = Organizational Process Improvement Intervention\nBSOC = Baseline Survey of Organizational Characteristics\nFigure 1 Design overview and planned timeline*.\nShafer et al. Health and Justice Page 5 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\nAlso of interest were the implementation outcomes of\nthe facilitated change intervention process itself, which are\nrelated to fidelity and acceptability of the activities of the\nOPII. It was hypothesized that success in achieving process\nimprovement goals, with regard to the assessment and case\nplanning process, were dependent upon commitment to\nthe intervention by members of the LCT, satisfaction with\nthe facilitation, executive management support, interagency\ncollaboration, and the quality and intensity of facilitation.\nQuantitative data collection\nQuantitative data collected for this study included struc-\ntured ratings of correctional agency offender case plans\nand surveys of members of the LCT and other\norganizational staff in the participating agencies.\nCase plan ratings The Assessment and Recommenda-\ntions for Treatment Rating Form (ART/RF) provided rat-\nings of four quality dimensions of the case plans. These\ndimensions included: (1) Measurement (the problem or\nservice needs assessed by a given agency); (2) Integration\nwith the Case Plan (the degree to which the case plan tar-\ngets needs identified); (3) Conveyance (evidence that the\ncase plan was shared with the community based treat-\nment provider); and (4) Services Activation (evidence that\nthe community-based treatment provider delivered ser-\nvices in accordance with the needs identified in the case\nplan). Case plan ratings were collected before the start of\nthe intervention (baseline), during the intervention (Needs\nAssessment phase, Process Improvement Plan phase, Im-\nplementation phase), and during the Sustainability/Fol-\nlow-up phase. In each period, research staff randomly\nselected five case plans per month from agency records\nand rated them using the ART-RF. Case plans from the\nDelayed-Start sites were rated during the same period of\ntime as for the Early-Start sites. Composite scores for each\nof the four quality dimensions were calculated for the five\ncases sampled each month, generating four ratings (Meas-\nurement, Integration, Conveyance, and Services Activa-\ntion) per month.\nBSOC Scales The Baseline Survey of Organizational\nCharacteristics (BSOC) describes the organizational\ncharacteristics, climate, and culture of the participating\nsites across the three CJDATS studies (the OPII study,\nas described here, the MATICCE study, which was de-\nsigned to improve access to medication-assisted treat-\nment, and the HIV-STIC study, which was intended to\nimprove the HIV continuum of care). The BSOC was\nadapted from previously developed and validated instru-\nmentation, including the TCU Survey of Organizational\nFunctioning (TCU-SOF) (Lehman et al. 2002). There are\ndifferent versions of the BSOC, with item wording tai-\nlored to the type of respondent: treatment staff,\ncorrectional staff, treatment director, and correctional\ndirector. In addition, treatment executive and correc-\ntional executive versions of the BSOC collected data on\nnumber of staff, staff turnover, types of services pro-\nvided, admissions, caseload, and budget.\nOther surveys Other survey instruments (listed in\nTable 2) provide information on staff perceptions of the\nassessment-case planning process, conveyance and use\nof assessments and case plans by community treatment\nagencies, goal commitment by members of the LCT,\nworking alliance between the facilitator and members of\nthe LCT, completion of implementation tasks per phase,\nperceived management support for the process improve-\nment process, and staff satisfaction with the OPII. To as-\nsess costs of the intervention, members of the LCT were\nasked to report monthly on the number of hours they\nspent on LCT activities.\nQualitative data collection\nSemi-structured interviews with members of the LCTs\nand other staff (front-line staff, and administrators) of\nthe participating agencies were conducted periodically\nthroughout the OPII intervention, specifically at the end\nof the Process Improvement Planning Phases, the end of\nthe Implementation Phase and at the end of the Sustain-\nability/Follow-Up Phase. Respondent interviews were\nvaluable to understand and clarify the experiences, moti-\nvations, and underlying attitudes of participants involved\nin change projects (Tracy 2013). The interviews, which\nwere conducted across all research sites, followed stan-\ndardized interview guides for each phase of the project\nfocused, although interviewers were encouraged to use a\n\"conversational give-and-take\" style (Lindlof and Taylor\n2002) to probe for additional detail and ask clarifying\nquestions when necessary. Interview guides focused on\nthe respondents' experiences with and perspectives re-\ngarding the implementation of the OPII, both from an in-\nsider (LCT member) and outsider (line staff, administrator)\nperspectives, and asked respondents to report about\nimportant issues including, for example: LCT cohesion\nand group process, specific goals and their feasibility,\npersonal and team participation, facilitator strengths/\nweaknesses, effects of the change process, etc. These\ninterviews were particularly useful for identifying unantici-\npated factors that affected the success of the change\nprocess.\nInterviews were conducted by members of each re-\nsearch center, either in person or over the phone. Inter-\nviews were audio recorded, transcribed, fact-checked,\nstripped of identifying information, and then analyzed\nusing a multi-part group and individual coding process.\nShafer et al. Health and Justice Page 6 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\nAims and/or hypotheses\nHypotheses\nThe primary hypotheses of the study are that enhance-\nments or improvements in each of the following out-\ncomes occur only after the introduction of a specific and\nstructured process improvement initiative (OPII):\n1. The level of congruence between transitional\noffender assessments and case plans.\n2. The level of presence of accepted principles of case\nplan development in case plans.\n3. The percentage of case plans forwarded from\ncorrectional agencies to community treatment\nprograms.\n4. The level of the use of case plans by community-\nbased substance abuse treatment programs.\n5. Staff perceptions of the assessment-case planning\nprocess.\nSecondary hypotheses are concerned with factors affect-\ning the degree of success that LCTs experienced in achiev-\ning the goals they established for themselves. LCTs'\nTable 2 OPII Variables, instruments, and assessment schedule\nConstruct/Variable Instrument Who assessed When assessed\nOrganizational Climate\nand Culture\nBaseline Survey of Organizational\nCharacteristics\nChange Team Baseline\nCorrectional Staff\nTreatment Staff\nCorrectional Managers\nTreatment Managers\nQuality of Assessment and\nCase Planning\nAssessment and Recommendations\nFor Treatment Rating Form\nCorrectional facility case plans Monthly sample of case plans from\nbaseline through end of follow-up\nGoal Commitment Goal Commitment Change Team Baseline\nEnd of Planning Phase\nManagement Support Management Support (Change\nTeam; Management Versions)\nChange Team Baseline\nChange Team Supervisors End of Planning Phase\nEnd of Implementation Phase\nPerceptions of\nAssessment Process\nStaff Perceptions of\nAssessment Process\nChange Team Baseline\nCorrectional and Treatment involved\nin assessment and treatment planning\nEnd of Implementation Phase\nEnd of Follow-up Phase\nUse of Case Plans Community Provider Assessment of\nConveyance and Use of Case Plans\nCommunity Treatment Provider\nAdministrator\nBaseline\nEnd of Implementation Phase\nEnd of Follow-up Phase\nSatisfaction Staff Satisfaction (Change Team;\nManagement Versions)\nChange Team End of Planning Phase\nChange Team Supervisors End of Implementation Phase\nWorking Alliance Working Alliance (Change Team;\nFacilitator Versions)\nChange Team End of Needs Assessment Phase\nFacilitator End of Implementation Phase\nInteragency Collaboration Services Coordination Scale\n(from BSOC)\nChange Team Baseline\nCorrectional Staff End of Follow-up Phase\nTreatment Staff\nCorrectional Managers\nTreatment Managers\nCost Change Team Time Report Change Team Every month during the\nintervention\nImplementation Implementation Checklist Research Staff Monthly\nAttitudes toward and\nExperiences with\nImplementation Strategy\nQualitative Interviews Change Team End of Planning Phase\nFacilitators End of Implementation Phase\nCorrectional Staff End of Follow-up Phase\nTreatment Staff\nShafer et al. Health and Justice Page 7 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\nsuccess in achieving the goals for their Process Improve-\nment Plans (PIP) were expected to be positively related to:\n1. The degree to which LCTs exhibit fidelity to the\ndesignated elements of OPII.\n2. The degree of commitment by LCT members to\nachieving the goals of the plan.\n3. The level of staff satisfaction with the\nimplementation strategy.\n4. The degree of management support within the\norganization for the intervention.\n5. The strength of the working alliance between the\nfacilitator and the LCT.\nImplementation questions\nThe implementation questions for the OPII study in-\nclude: (1) How are implementation outcomes related to\nvariations across states in system characteristics, config-\nurations of LCTs, assessment processes, and study im-\nplementation? (2) Were the improvements in assessment\nand case planning procedures identified by each LCT\nimplemented as intended? (3) What does the OPII cost\nin terms of staff time devoted to designing and imple-\nmenting the PIP? (4) Are OPII-initiated changes in as-\nsessment and case planning sustained following the end\nof the intervention? (5) In what ways does collaboration\nbetween organizations involved in the OPII change over\nthe course of the intervention?\nHuman subject protections\nEach research center obtained Institutional Review Board\napproval through an established FWA-recognized entity.\nIn most instances, approvals were also secured from par-\nticipating correctional and/or treatment agency research/\nIRB committees. Informed consent was obtained by re-\nsearch participants, including staff and managers of par-\nticipating agencies, at varying points of time throughout\nthe study, depending upon data collection requirements.\nBaseline structured staff surveys and corresponding par-\nticipant consent were administered at the time of the kick\noff meeting of the early start site for participants of both\nthe Early-Start and Delayed-Start sites. Qualitative inter-\nviews occurred after the randomization. ART-RF case rat-\nings samples began six months prior to randomization;\nsince the ratings did not collect personal identifying infor-\nmation, but rather agency documentation patterns, of-\nfender consent was not required.\nDiscussion\nThe organizational intervention under study in this paper\nwill extend the use of interagency LCTs and externally fa-\ncilitated organizational coaching to enhance the shared\nprocesses of assessment, case planning, service referral,\nand treatment provision processes between correctional\nagencies and community based treatment agencies. This\nstudy will generate and extend knowledge related to the\nscience of implementation and organizational change in\nat least four key areas.\nFirst, the study will provide some of the first evidence of\nthe effectiveness of change teams and facilitated coaching\nstrategies to bring about changes in organizational pro-\ncesses (specifically assessment and case planning) within\ncorrectional systems. While the utilization of orga-\nnizational coaching and facilitation has been recognized\nas an effective organizational change process in correc-\ntional systems (National Institute of Corrections 2001),\nscant empirical evidence exists of its impact in promoting\nadoption and implementation of evidence-supported\npractice.\nSecond, the application of organizational change strat-\negies such as change teams, and process improvement\ninitiatives, such as NIATx, typically target change pro-\ncesses within a single organization. This study targets\norganizational processes within and between systems and\nagencies; criminal justice/correctional agencies and pri-\nvate, mostly non-profit community-based treatment agen-\ncies. The interagency contexts of this study, coupled with\nthe divergence in organizational culture between correc-\ntional and treatment settings, provide unique context\nwithin which to study the complexities of bringing about\nenhancements in the delivery of evidence-supported client\nlevel interventions.\nThird, this study provides a highly structured and rigor-\nous approach to ensuring and documenting the fidelity of\nthe facilitated intervention, including the development of\na facilitation intervention manual and learning circles\namong the facilitators. These enhancements introduce sig-\nnificant opportunities to better understand the nature and\nquality of effective organizational facilitation.\nFourth, this study extends methodological approaches\nto the inquiry of implementation and organizational im-\nprovement in a number of ways. As noted, the use of\nnon-validated instrumentation, most notably in the case\nfile review process (ART-RF), but also nearly all of the\nsurvey measures, present major risks and challenges to\nthe analysis and interpretation processes. Nonetheless,\nthe focused efforts at construct triangulation, drawing\nupon multi-methods data collection (survey, chart ab-\nstraction, qualitative interviews) provide the potential for\nadvancing measurement sophistication in this nascent\nfield of inquiry. The reflective nature of our intervention\ndesign, one in which the speed at which the LCTs pro-\ngress through the planned phases of the intervention,\nas well as the targeting of the process improvement\ngoals selected by each LCT, present significant risks and\nchallenges to analysis and interpretation. Finally, given\nthe local setting context within which these LCTs are\nformed, the potential for spillover or generalization\nShafer et al. Health and Justice Page 8 of 9\nhttp://www.healthandjusticejournal.com/content/2/1/1\neffects between early start and local start sites is an area\nfor concern. For each of these methodological risks and\nliabilities, we have taken efforts to anticipate and guard\nagainst the most egregious risks, and we hope, in the\nprocess, to make significant contribution to the study of\norganizational improvement and implementation in gen-\neral and within the unique context of correctional set-\ntings in particular.\nEndnotes\naCopies of the Facilitator Manual can be obtained by\ncontacting the corresponding author.\nbAlthough there were nine (9) CJDATS Researcher\nCenters, one Center had two sets of study sites in two\nstates, while another Center had a total of three study\nsites. The remaining seven research centers fielded one\ncluster each, with two study sites per cluster (n = 14).\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthors' contributions\nThe named authors contributed directly to the adaptation of the protocol to\nconform to Health & Justice publication format: Michael S Shafer, Michael\nPrendergast, Gerald Melnick, Lynda A Stein, Wayne N Welsh, and the CJDATS\nAssessment Workgroup. Arizona State University, University of California Los\nAngeles, National Development and Research Institutes, Inc., University of\nRhode Island, Temple University. All authors read and approved the final\nmanuscript.\nAuthors' information\nThe CJDATS Assessment Workgroup members who participated in the\ndevelopment of the Assessment protocol are (in alphabetical order within\neach Research Center): David Duffee, Cassia Spohn (Arizona State University),\nKaren McKendrick, (National Development and Research Institutes, Inc.),\nMatthew Hiller, Roger Peters, Ralph B. Taylor, Gary Zajac (Temple University),\nWayne Lehman (Texas Christian University), Linda K. Frisman, Colleen\nGallagher, Eleni Rodis (University of Connecticut), Steven S. Martin, Cynthia\nRobbins (University of Delaware), Jamieson Duvall, Erin McNees Winston,\nMichele Staton Tindall (University of Kentucky), Bennett W. Fletcher\n(Bethesda, MD).\n"
}