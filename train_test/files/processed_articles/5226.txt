{
    "abstract": "Abstract\nLinkage of population-based administrative data is a valuable tool for combining detailed individual-level information from\ndifferent sources for research. While not a substitute for classical studies based on primary data collection, analyses of\nlinked administrative data can answer questions that require large sample sizes or detailed data on hard-to-reach\npopulations, and generate evidence with a high level of external validity and applicability for policy making. There are\nunique challenges in the appropriate research use of linked administrative data, for example with respect to bias from\nlinkage errors where records cannot be linked or are linked together incorrectly. For confidentiality and other reasons,\nthe separation of data linkage processes and analysis of linked data is generally regarded as best practice. However, the\n`black box' of data linkage can make it difficult for researchers to judge the reliability of the resulting linked data for their\nrequired purposes. This article aims to provide an overview of challenges in linking administrative data for research. We\naim to increase understanding of the implications of (i) the data linkage environment and privacy preservation; (ii) the\nlinkage process itself (including data preparation, and deterministic and probabilistic linkage methods) and (iii) linkage\nquality and potential bias in linked data. We draw on examples from a number of countries to illustrate a range of\napproaches for data linkage in different contexts.\n",
    "reduced_content": "Original Research Article\nChallenges in administrative\ndata linkage for research\nKatie Harron1, Chris Dibben2, James Boyd3, Anders Hjern4,\nMahmoud Azimaee5, Mauricio L Barreto6 and\nHarvey Goldstein7\n Keywords\nData linkage, record linkage, epidemiological studies, measurement error, selection bias, data accuracy\nadministrative data\nBackground\nAdministrative data collected for financial or clinical\nmanagement purposes contain rich, detailed informa-\ntion, and their great potential for research has been\nincreasingly exploited over recent years. Linking\ntogether information across multiple data sources\n(e.g. health, social welfare, or employment) can further\nenhance existing data. As traditional methods for data\ncollection (e.g. cohort studies and surveys) become\nmore problematic due to high cost and low response\nrates or attrition, use of linked individual-level data has\nbecome an attractive alternative (Jutte et al., 2011;\nThe strengths of linked administrative data are well-\ncharacterised, particularly for research requiring large\nsample sizes, detailed data on hard-to-reach popula-\ntions, or little loss to follow-up, and for generating\nevidence with a high level of external validity and\napplicability for policy making (Holman et al., 2008).\n1Department of Health Services Research and Policy, London School of\nHygiene & Tropical Medicine, London, UK\n2Institute of Geography and the Lived Environment, University of\nEdinburgh, Edinburgh, UK\n3Centre for Population Health Research, Curtin University, Perth,\nAustralia\n4CHESS Karolinska Institutet, Stockholm University, Stockholm, Sweden\n5Institute for Clinical Evaluative Sciences, Toronto, Canada\n6Center of Data and Knowledge Integration for Health (CIDACS),\nInstituto Gonc\n\u00b8alo Moniz, Fundac\n\u00b8a\nSalvador-Bahia, Brazil\n7Graduate School of Education, University of Bristol, Bristol, UK, and\nUCL Great Ormond Street Institute of Child Health, London, UK\nCorresponding author:\nEmail: Katie.harron@lshtm.ac.uk\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License (http://\nwww.creativecommons.org/licenses/by/4.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-\nat-sage).\nBig Data & Society\njournals.sagepub.com/home/bds\nHowever, the limitations of administrative data are also\nwell understood, particularly those relating to data\nquality and missing data (Hashimoto et al., 2014; van\nWalraven and Austin, 2012). For example, missing data\ncan occur in the traditional sense, i.e. where recording is\nincomplete, but can also occur if a person fails to inter-\nact with a service (e.g. a school based exam or a hos-\npital clinic) and is therefore not captured in the\nadministrative data (Weitoft et al., 1999). Data linkage\nadds a further dimension: missing or inaccurate data\ncan also be introduced if the individual's school or\nhospital record could not be accurately linked due to\ninsufficient identifying information.\nLinkage of administrative data to support popula-\ntion-based analyses also poses a unique set of methodo-\nlogical challenges related to the use of personal\nidentifiers. In many jurisdictions, the separation of link-\nage and analysis processes is considered as best practice\nfor confidentiality, meaning that those conducting the\nlinkage (often a `trusted third party') only have access\nto a set of identifiers, whilst those analysing the linked\ndata only have access to de-identified attribute data\n(Kelman et al., 2002). Although this strategy limits the\nrisk of disclosing sensitive information about individ-\nuals, the separation of functions means that important\naspects of the linkage process, which impact on the reli-\nability of the resulting linked dataset, can be obscured\nfrom those analysing and interpreting the linked data.\nThis aim of this article is to improve understanding\nof approaches to administrative data linkage, and to\nprovide an overview of important considerations for\nlinking administrative data for research. We begin by\nconsidering the data linkage environment and the\nimplications of safeguarding administrative personal\ndata. We then provide an overview of the linkage pro-\ncess, including data preparation and linkage methods,\nand discuss how these processes may affect the linked\ndataset. Finally, we consider linkage quality and evalu-\nation, and the implications of potential bias due to\nerrors occurring during the linkage process. We draw\non examples from a number of countries to illustrate\napproaches for data linkage in different contexts.\nThe data linkage environment\nA number of models for data linkage studies exist across\ndifferent jurisdictions, with differing degrees of separ-\nation between linkage and analysis processes. The strict-\nest of models involves identifiable data accessed only by a\ntrusted third party (who conduct the linkage), whilst the\nresearch group only access de-identified attribute data\nrequired for analysis. For example, the Data Linkage\nBranch in Western Australia and the Centre for Health\nRecord Linkage (CHeReL) in New South Wales receive\nidentifiable data and use these to create anonymous\n`linkage keys'. These linkage keys are passed to research-\ners, who can then merge together the corresponding attri-\nbute data (e.g. clinical or service records) required for\ntheir analysis (without ever seeing any identifiers). This\nlinkage model creates enduring links that are stored in\nperpetuity within the system, meaning that records do\nnot need to be repeatedly matched for different studies\n(Dibben et al., 2015). Similarly, the SAIL Databank in\nWales does not hold identifiers, but retains an\nAnonymous Linking Field (ALF), which is unique for\neach person and used to link multiple datasets for\nresearch (Jones et al., 2014). The Centre for Data\nLinkage (CDL) in Australia uses a similar model,\nexcept that identifiable data are received and linked on\na project by project basis (Boyd et al., 2012).\nLinkage models can vary within countries. Whilst\nthe Manitoba Centre for Health Policy in Canada fol-\nlows the same model as Australia, a different model\noperates at Institute for Clinical Evaluative Sciences\n(ICES) in Ontario. ICES is legally allowed to receive\nfully identifiable data in order to perform linkage,\nassess data quality and provide coded data to research\nstaff within the organisation. They operate a hierarch-\nical access policy, which means that only a specified\nnumber of people have the highest level of access to\nall data elements, and most researchers can only\naccess de-identified, coded data relevant to their\nstudy. A modification to this system is the `split-file'\napproach, used in Population Data BC, where identi-\nfiers are stripped from attribute data as soon as they are\nreceived, and stored separately, only being accessed by\na certain number of programmers (who do not access\nthe attribute data) (Dibben et al., 2015).\nFull separation of identifiers and attribute data has\nbeen argued to reduce the risk of re-identification, and\nis a valuable tool in reassuring data providers about\nthe security of sharing their data. However, allowing\nlinkage and analysis to take place together provides\nopportunities for both in-depth evaluation of linkage\nquality, and methodological advances in linkage tech-\nexample, this approach can allow alternative linkage\nvariables that are not considered as typical personal\nidentifiers (such as dates or diagnoses) to be incorpo-\nrated into linkage algorithms or validation procedures\nAccessing linked data for research\nEffective data linkage environments protect confidenti-\nality whilst facilitating research use of personal data\n(defined in the UK as data relating to living individuals\nwho can be identified from those data, or from data or\nother information in the possession of the data control-\nler) (Information Commissioner's Office, 2016).\n2 Big Data & Society\nProducing completely anonymous datasets (where it is\nnot possible to identify any individual) would be pro-\ntective of confidentiality (Information Commissioner's\nclear that full anonymization of individual-level data\nis virtually impossible whilst retaining sufficient granu-\nlarity for research (de Montjoye et al., 2015). Instead,\nconfidentially is preserved through a combination of (i)\ncomprehensive data access approvals, (ii) requirements\non the researcher, including training and sanctions and\n(iii) physical or virtual settings that restrict the possibil-\nity of re-identification of individuals or inadvertent\nor deliberate misuse of data. Key points of the three\ncomponents of the data linkage environment are sum-\nmarised in Box 1.\nFirstly, access to linked administrative data is usu-\nally overseen by an approvals panel, who consider a\nnumber of details about the data requested and the\ncredentials of the requesting institution and research-\ner(s), including appropriate security measures and\ngovernance training. Approval panels are concerned\nwith confirming the legal basis for disclosing data,\nand often take into account whether the proposed\nresearch is in the public benefit, and whether this bene-\nfit is outweighed by any potential risks of using the data\n(Dibben et al., 2015). In the UK, approvals ensure that\ndata use meets the principles of Data Protection\nAct 1998, i.e. fair and lawful processing of data\n(Information Commissioner's Office, 2016). In Brazil,\nwhile there is legal support for the use of administrative\ndata for research, clear evidence of advantages of data\nlinkage for health policy is required for ethics commit-\ntee approval (Farinelli et al., 2015). In Australia, record\nlinkage stakeholders are regulated by legislation and\ncontractual obligations relating to privacy and\nconfidentiality.\nApplications may need to be made to a number of\npanels, who consider different and overlapping aspects\nof a study. For example in the UK, a research study\nproposing linkage of identifiable data without consent\nwould require applications to the data provider (e.g. the\nOffice of National Statistics for death registration\ndata), the trusted third party (e.g. NHS Digital, who\nperform linkage with hospital records), a local or\nnational research ethics committee, and the\nConfidentiality Advisory Group (an independent body\nproviding advice on applications to use confidential\npatient data without consent). In Australia, the feder-\nated government system means that various datasets\nare gathered at different tiers of administration, with\ndifferent jurisdictions being responsible for different\ndata collections. Complete population coverage can\nonly be achieved through linkage between jurisdictions.\nHowever, there are significant differences in the access\nand approvals processes between each jurisdiction,\noften requiring researchers to obtain approval from\ncombinations of data custodians, data linkage units\nand ethics committees across each legal jurisdiction.\nThe second component of the safe environment is\nthe researcher. Researchers are expected to undergo\ninformation governance training before accessing\ndata. Once data access is approved, researchers are typ-\nically required to abide by a license or contract, setting\nout the ways in which data may be processed.\nAny breaches of these contracts are subject to strict\nsanctions, often at the institutional level, which provide\na deterrent to intentional or negligent behaviour. For\nexample in the UK, monetary penalty notices of up to\nare publically available online, with implications for the\nreputation of both the associated researcher and their\ninstitution.\nBox 1. Considerations for safe data linkage environments.\nContext Key points\nData access\napprovals\n Comprehensive approvals processes typic-\nally check that:\n There is a legal basis for data access\n There are appropriate security\narrangements\n Data are used only for a specified pur-\npose, are kept only for a specified length\nof time, and are not further disclosed\n The requesting institution has appropri-\nate credentials\n The ethics of the proposed study have\nbeen properly scrutinised\nResearcher\nrequirements\n Researchers have a responsibility, often laid\nout in terms of use, to use data for bona\nfide purposes only\n Researchers should receive regular training\nin information governance\n Legal sanctions are in place where data are\nused inappropriately or without due care\nPhysical or\nvirtual\nsetting\n Secure physical, or virtual, locations estab-\nlished for the processing and linkage of\npersonal or potentially identifiable data,\ncharacterised by:\n Strict access arrangements\n Secure data transfer processes\n Restricted network and/or internet\naccess\n Tight disclosure control procedures\n For example, aggregate data only, sup-\npression of small cell sizes (e.g. < 5),\nk-anonymity\n Help protect against outsider attacks or\ncoercion\n Provide tangible reassurance on data\nsecurity to the public\nHarron et al. 3\nThe final component of the data linkage environ-\nment is the physical or virtual setting within which\ndata processing takes place. A safe setting (or safe\nhaven) is a secure location where data are stored or\naccessed via a secure network link, which is subject to\nstrict access arrangements. An important aspect of the\nsafe setting is how outputs are checked (a process\nknown as statistical disclosure control). In the context\nof linked administrative data, statistical disclosure con-\ntrol attempts to limit the risk of identification (i.e. find-\ning out the identity of someone in a dataset) and\nattribution (i.e. associating information held in a\nrecord with a particular individual). A detailed descrip-\ntion of statistical disclosure control mechanisms can be\nfound elsewhere (Longhurst et al., 2011). A simple\nexample of this process used in many countries is\nwhere outputs are checked to ensure that no small\ncell sizes (e.g. <5) are released outside of the safe set-\nting. More sophisticated approaches include k-anon-\nymity, which ensures that any individual cannot be\ndistinguished from k-1 other individuals (Information\nImplications for research\nSome argue that such extensive governance require-\nments can be a barrier to research, and that the\nharms from not using administrative data are greater\nthan the risks (Jones et al., 2017). Firstly, data access\napplications often require a substantial investment of\nresearcher time, and approvals are subject to long-\ndelays that are difficult to align with project schedules\nand funding timelines (Dattani et al., 2013). Where\napplication processes are not streamlined, the need to\nobtain approval from a number of different bodies can\nresult in the same information being reviewed by differ-\nent panels, each with different remits and perspectives.\nSecondly, physical safe settings are not typically\noptimal for research, as they may require travel and\nbe restricted to set hours, and analyses often need\nto be repeatedly refined and reworked. Virtual safe set-\ntings are more flexible as they allow secure, remote\naccess to data, but may be restricted by strict disclosure\ncontrol procedures that, whilst appropriate for some\nanalyses, would not be sufficient for others that require\nfine-grained individual-level data (e.g. time-to-event\nmodels) (Information Commissioner's Office, 2012).\nIn some countries, organisations that help research-\ners navigate the complex requirements and facilitate\naccess to linked administrative data for research have\nbeen established. For example, the Administrative Data\nResearch Network (ADRN) was established as a UK-\nwide partnership between universities, government\ndepartments, national statistics authorities, and funders\nand researchers. The ADRN includes an approvals\npanel (who examine each research proposal), an accre-\ndited researcher training programme (the Secure Users\nof Research data Environment (SURE) training), and a\nsafe setting within which researchers can access de-iden-\ntified administrative data (with statistical disclosure\nprocedures applied to any data taken outside the safe\nsetting).\nThe linkage process\nData preparation\nAs many administrative datasets contain inconsistent,\ninaccurate or incomplete data that vary in structure,\nformat and content, data pre-processing is a time-con-\nsuming but vital aspect of linkage (Playford et al.,\n2016). For example in Brazil, name is one of the main\nvariables available for linkage of administrative data\n(along with sex, date of birth and municipality).\nAlthough name can be a highly discriminative variable,\nthe number of different ways it can be structured in\nBrazilian datasets can be problematic: a woman with\nfive names might have them all recorded in one dataset,\nbut only her first and last name in another dataset. The\nlevel of data cleaning performed therefore requires\ncareful thought, as there is a need to retain the discrim-\ninative power of individual identifiers whilst standardis-\ning variables across datasets. Heavy data cleaning can\nreduce the variability between identifiers and reduce the\nability to distinguish one record from another (Randall\nMany string comparators and phonetic coding sys-\ntems have been developed in order to overcome differ-\nences in the way names are recorded (Newcombe et al.,\nfour characters, are one of the most commonly used\nphonetic algorithms for indexing names in the English\nlanguage, although other codes exist for different lan-\n\u00b4 and Pola\nstring comparators also exist, which provide a similar-\nity score for two strings, typically based on the number\nof character changes needed to make the two identical\n(e.g. the Jaro-Winkler comparator) (Grannis et al.,\nBlocking\nAs the size of available administrative datasets\nincreases, an important consideration is how to\nreduce the number of comparisons made between rec-\nords. The analysis of large unlinked datasets can\nrequire specialist software and high performance com-\nputing, and linkage compounds the capacity issue: if\nevery record in one dataset is compared with every\n4 Big Data & Society\nrecord in another dataset, the total number of pairwise\ncomparisons is the product of file sizes. Pairwise com-\nparisons quickly become unmanageable in administra-\ntive datasets like the 100 million cohort in Brazil, which\ncomprises detailed socio-economic data on over half of\nthe population (114 million people at baseline) and con-\ntinues to expand as new individuals are added to the\nregister each year (Rasella et al., 2013). The problem is\nexaggerated further with linkage of multiple data\nsources.\nTherefore, blocking strategies are often used, which\nrestrict comparison pairs to those likely to match.\nBlocking strategies determine which records are (and\nare not) considered as matches, which potentially\naffects the overall accuracy of the linkage process.\nFor example, blocking on a particular geographical\nregion or location would only consider pairs of records\nas potential matches if they agreed on that location; any\nerrors in this variable would prevent records from link-\ning. Therefore, careful consideration should be given to\ndeciding on blocking strategies, by assessing quality\nand completeness of each candidate blocking variable.\nLinkage methods\nIn some countries, a unique personal number is\nrequired for access to services and can be readily used\nto obtain information about individuals. For example\nnational legislations in the Scandinavian countries have\ncreated a single unique personal identity number for\neach resident used in all administrative contexts;\nhealth care, judiciary, tax, military and educational sys-\ntems. Such identifiers practically make it possible to\nlink data from many different administrative sources\nwith marginal error (Ludvigsson et al., 2009). Linkage\nwith these unique personal identifiers is so accurate that\ndata can be pooled from different countries to create\nvery large study populations, thereby enabling longitu-\ndinal studies of rare medical conditions with a cohort\nHowever in many other countries, unique identifiers\nfor linkage across sources are not available, because\nunique identifiers that do exist are domain specific\nand have been created by administrative organisations\nfor their own purposes, and may operate at different\nlevels of jurisdiction (Ludvigsson et al., 2009; United\nNational Economic Commission for Europe, 2007).\nFor example in the UK, the National Insurance\nnumber is used by Her Majesty's Revenue & Customs\nand the Department of Work and Pensions for employ-\nment and taxation data; the National Health Service\n(NHS) number is used for health services in England,\nand the Community Health Index (CHI) number is the\nprimary health identifier in Scotland; none of these are\nreliably used in education data. In Ontario and\nManitoba, encoded provincial health card numbers\nthat are used to link health data are not used in other\ngovernment departments such as social care, education\nor immigration (Chiu et al., 2016). Similarly in Brazil\nand Australia, different numbers are used for different\nadministrative purposes (e.g. identification, employ-\nment, taxation, social protection, and health).\nIn the absence of a unique identifier, linkage needs to\nbalance the risk of missed-matches (failing to link\nrecords belonging to the same individual) with false-\nmatches (erroneously linking records belonging to dif-\nferent individuals) (Table 1). There are two broad\napproaches to data linkage: deterministic and probabil-\nistic. Both methods rely on finding agreement on a set\nof common identifiers such as name, date / place of\nbirth, and address. In practice, linkage projects often\nuse a combination of deterministic and probabilistic\nmethods, with algorithms developed in an iterative pro-\ncess of trial and error, involving manual review and\nestimation of linkage error rates (Roos et al., 1986).\nDeterministic linkage. Deterministic linkage uses a set of\npre-determined rules to classify records as belonging to\nthe same or different individuals. For example in the\nUK, hospital admission records for the same individual\nover time are linked together using a three-step deter-\nministic algorithm based on combinations of NHS\nnumber, date of birth, sex and postcode (Hagger-\nJohnson et al., 2015). Deterministic methods are typic-\nally prone to missed-matches, as any recording errors or\nmissing values can prevent a set of identifiers from agree-\ning. Conversely, false-match rates are typically low, as\nrecords belonging to different individuals are unlikely to\nagree on a complete set of identifiers by chance (Grannis\nProbabilistic linkage. Probabilistic methods are arguably\nmore suited to linkage of error-prone administrative\ndata, which can also be subject to changes over time\n(e.g. addresses) (Fellegi and Sunter, 1969; Newcombe\na match weight is assigned to each pair of records, with\nhigher weights indicating a greater likelihood that the\npair is a true match. Where identifiers agree, a positive\nTable 1. Linkage error.\nMatch status\nMatch (pair from\nsame individual)\nNon-match (pair from\ndifferent individuals)\nLink status\nLink Identified match False-match\nNon-link Missed-match Identified non-match\nHarron et al. 5\ncontribution is made to the match weight; disagreement\ncontributes a penalty to the weight. In the simplest case,\neach identifier contributes separately to the match\nweight, taking into account the discriminative value of\neach identifier, so that, for example, agreement on date of\nbirth would contribute more evidence of a match than\nagreement on sex.\nIn the standard Fellegi\u00adSunter probabilistic proced-\nure, match weights are derived from two conditional\nprobabilities: the m-probability (the probability that an\nidentifier agrees given records belong to the same individ-\nual) and the u-probability (the probability that an identi-\nfier agrees given records belong to different individuals).\nThe u-probability represents the frequency of values for\neach identifier, i.e. the probability of chance agreement on\nsex is \u00bd; the probability of chance agreement on month\nof birth is 1/12, and so on. M-probabilities represent the\nerror rate in a particular identifier. For example, if sex\nwere miscoded in 5% of record pairs, the m-probability\nwould be 0.95. These probabilities are typically estimated\nvia a statistical model, and the overall match weight is\ncalculated as a function of these probabilities, usually the\nratio log2\n(m/u) for each identifier, summed across all\nidentifiers (Brown et al., 2017). Adaptations to standard\nmatch weight calculation include frequency-specific\nmatch weights, which assign greater weights to less\ncommon identifier values and thus provide greater dis-\ncrimination between matches and non-matches (Zhu\nRecord pairs are classified as links or non-links\ndepending on whether the corresponding match\nweight reaches a cut-off threshold. Often, two thresh-\nolds are chosen: pairs with weights above the upper\nthreshold are classified as links; pairs with weights\nbelow the lower threshold are classified as non-links;\nthose in the middle are inspected further (e.g. through\nmanual review). Choice of threshold values is import-\nant, as adjusting the thresholds changes the balance\nbetween the number of false-matches and missed-\nmatches (Krewski et al., 2005). However, choosing\noptimal thresholds is not straightforward, and is often\na subjective process based on manual review of record\npairs, guided by plotting the distribution of match\nweights (Blakely and Salmond, 2002; Dusetzina et al.,\n2014). If manual review is not feasible, e.g. due to a lack\nof resources or too large a dataset, a single optimal\nthreshold may be chosen by calculating quality\nmeasures at a number of different threshold values\nand comparing these to levels of acceptable error for\na particular study (Christen and Goiser, 2007).\nMany linkage systems often use a combination\nof deterministic and probabilistic approaches.\nDeterministic methods are computationally inexpensive\nrelative to probabilistic methods and are easier to imple-\nment, but may not achieve sufficient linkage quality.\nPrivacy preserving linkage. There are some situations in\nwhich identifiers cannot be released for linkage. For\nexample, the Office for National Statistics Beyond\n2011 programme involved linkage of information\nfrom different government departments on all individ-\nuals in England and Wales to support the UK Census,\nand a decision was made to handle only non-identifi-\nable data to maintain a high level of data security. The\nprogramme therefore explored privacy preserving\nrecord linkage (known as PPRL) for linking encrypted\nidentifiers (Abbott et al., 2015). Encryption transforms\nidentifiers (such as date of birth or name) into hashed\nvalues in order to avoid re-identification of individuals.\nThe challenge in the adoption of privacy preserving\nmethods is achieving high levels of privacy protection\nwithout negatively impacting on performance and link-\nage quality (accuracy of results). One of the limitations\nof encrypted identifiers is that, by design, similar iden-\ntifiers look very different once encryption has taken\nplace. For example, a hash function may transform\ncharacter differs in the original identifiers, yet the\nhashed values are completely different. This compli-\ncates the process of assessing the similarity between\nidentifiers on different records.\nSuch problems can be overcome through the use of\n`match-keys', which take elements from each identifier\n(e.g. first letter of first name, first letter of second name,\nday of birth and postcode prefix), or Bloom filters,\nwhich decompose a string into bigrams (2-character\nstrings) and map these bigrams to a specific position\nin a binary array. Bloom filters are more complex\ndata structures than standard hashing functions, and\nalthough they preserve anonymity, can be compared\nusing a similarity index such as the Dice coefficient\n(Schnell et al., 2009). In Brazil, software using\nencrypted data via Bloom filters has been developed\nto link the 100 million cohort (using Spark) (Pita\net al., 2015). Australia have also progressed probabilis-\ntic linkage using Bloom Filters to supplement existing\nlinkage systems. A recent project successfully verified\nPPRL using Bloom filters in terms of privacy, scalabil-\nity, error tolerance and security, using real-world data\nfrom New South Wales and Western Australia.\nAlternative linkage methods. Although traditional meth-\nods rely on personal identifiers for linkage, other aux-\niliary variables can provide further evidence about\nlinkage probabilities. For example, a measure of\nheight in one file and a measure of weight in the\nother could potentially provide information about the\nlikelihood of a true match. Indirect identifiers, such as\nclinical information, have also been successfully\n6 Big Data & Society\nincorporated within linkage algorithms and have the\npotential to reduce disclosiveness within linkage\napproach that utilises such auxiliary variables is `prior\ninformed imputation', which treats linkage as a missing\ndata problem, incorporating information on these vari-\nables at the stage of model fitting and performing an\nimputation procedure using the probabilistic weights\nassigned to `candidate' records as Bayesian priors\n(Goldstein et al., 2012). The advantage of this method\nis that it exploits relationships between identifiers and\nnon-identifying variables (Goldstein and Harron, 2015;\nHarron et al., 2014). A number of other Bayesian\nmodels for linkage have been explored, but are not\nyet widely used due to a number of required assump-\ntions about distribution of errors, file structure and\nmodel specification (Tancredi and Liseo, 2011).\nImplications for research\nThe nature of the data to be linked will determine\nwhether a large-scale linkage system is established\n(requiring a dedicated IT infrastructure and support),\nwhere linked datasets are produced in a `one size fits all'\nmanner, or whether ad-hoc linkage can be achieved,\ntailored to a specific research question (Jones et al.,\n2014). In each of these scenarios, choices will need to\nbe made regarding data cleaning procedures, strategies\nfor blocking, and linkage methods. Ideally, these\nchoices are based on contextual knowledge about the\nquality and quantity of identifiers in the underlying\ndatasets, which may come from both the data provider\nand the researcher. However, choices may also be\nrestricted by the availability of identifiers, e.g. if gov-\nernance requires that only encrypted identifiers can be\nreleased. PPRL remains a contentious issue, as any\nerrors in original identifiers are embedded within\nencrypted identifiers, meaning that this approach is\nless flexible and more difficult to evaluate than linkage\nusing unencrypted identifiers. Achieving a balance\nbetween data protection and accuracy and usability of\nthe resulting linked dataset is an ongoing area of\nSharing of information about each step of the link-\nage process between data providers, linkers and ana-\nlysts, can help improve transparency and increase\nunderstanding of the reliability of the linked data\n(Gilbert et al., 2017). For example, Statistics Canada\nhave published a Record Linkage Project Process\nModel, which describes common practices for linkage\nwithin the Agency (Sanmartin et al., 2017). ICES in\nOntario produce a `Linkability Report' for each of\ntheir data holdings, which provides the number and\npercentage of linked records (by type: deterministic or\nprobabilistic) and unlinked records by year.\nEvaluating linkage quality\nLinkage error\nLinkage error arises when pairs of records are incor-\nrectly classified (Table 1). False-matches occur when\nrecords from different individuals link erroneously.\nMissed-matches, where records from the same individ-\nual fail to link, occur in data where identifiers are prone\nto misreporting (e.g. typographical errors), changes\nover time (e.g. married women's surnames; addresses)\nor missing values. Linkage errors in administrative data\nare inevitable due to the imperfect and transient nature\nof identifiers, and even small amounts of linkage error\ncan result in substantially biased results (Neter et al.,\nMissed-matches can result in a loss of generalisabil-\nity, or selection bias, if particular subgroups of records\nare more or less likely to link (non-random or differen-\ntial linkage error) (Bohensky et al., 2010; Ford et al.,\nstudies have found that data quality varies according\nto a number of characteristics including age, sex, eth-\nnicity and health status (Bohensky, 2015). This can lead\nto, for example, lower match rates in more vulnerable\nor deprived populations.\nFalse-matches are a further challenge. When records\nfrom two different individuals are linked together, asso-\nciations between variables can be diluted or spurious\nassociations created. When a record is linked but no\nlink should have been made (e.g. linking a survivor to\na mortality record), this can have implications for\nprevalence estimates (such as overestimating a rate).\nIf false matches depend on individual characteristics\n(e.g. sex, because of maiden/married name inconsisten-\ncies) this may lead to biased estimates of association,\ne.g. if sex is related to both the exposure and outcome\nof interest.\nMeasuring linkage error\nMany linkage studies report the proportion of records\nthat were linked, i.e. the match rate. Other frequently\nreported measures of linkage quality include sensitivity\nand specificity, and positive and negative predictive\nvalues, which are directly related to rates of false- and\nmissed-matches (Christen and Goiser, 2005; Ferrante\nand Boyd, 2012). However, these measures in them-\nselves do not provide information on how results of\nanalyses might be affected in terms of bias, and are\nnot always relevant. For example, match rate is only\nhelpful if you know how many records from a particu-\nlar dataset should be linked.\nBox 2 summarises several methods for evaluating\nlinkage quality, including comparisons with gold-\nHarron et al. 7\nstandard data, post-linkage validation, comparisons of\nlinked and unlinked data, and sensitivity analyses\nImplications for research\nLinkage error can threaten the reliability of results\nbased on analyses of linked administrative data.\nHowever, effective communication between data pro-\nviders, linkers and analysts allows sharing of informa-\ntion that enables the quality of linkage to be evaluated\n(Gilbert et al., 2017). Analysis strategies can then be\nbased on an understanding of the data linkage pro-\ncesses, the context of the data itself and the research\nquestion to be addressed.\nThe type of evaluation conducted will depend on the\ncontext of the data environment (Harron et al., 2017).\nFor example, evaluation of linkage using a gold-\nstandard dataset is usually performed by those\nconducting the linkage, since researchers themselves\nrarely have access to identifiable data. In contrast,\npost-linkage validation, sensitivity analyses and\ncomparison of characteristics of linked and unlinked\nrecords can be performed by the researcher, given the\ndata linker provides certain non-sensitive information\nabout the linkage process. Information that should be\npassed on to researchers to facilitate these evaluations\ninclude meta-data on the quality of each link (such as\nthe decision-rule or match weight), and record-level or\naggregate characteristics of unlinked records (to iden-\ntify potential sources of bias).\nFor example, the body performing most linkage of\nhospital records for the NHS in England (NHS Digital)\nprovide data users with a match rank for each linked\nrecord that indicates which identifiers were used for a\nparticular match. The Institute of Clinical Evaluative\nSciences in Ontario provide researchers with a linkage\nreport, which summarises the linkage strategy and out-\ncomes for each linkage step; linkage weights can be\nadded to each record in the linked data. This informa-\ntion is helpful for researchers to understand exactly\nhow decisions about each record were made, to evalu-\nate the quality of each link, and to take into account\npotential biases.\nStudy designs should be informed by information on\nthe quality of linkage, and can be optimised to account\nfor potential bias due to linkage error, or uncertainty in\nlinkage between data sources. For example, consider an\n`informative' linkage, aiming to ascertain case-status by\nlinking to a registry dataset (such as death notifications\nor infection surveillance). In this scenario, linkages with\nhigh positive predictive value lend themselves to case\u00ad\ncontrol study designs, which require certainty that\nlinked records really do represent true cases, but do\nBox 2. Evaluating linkage quality.\nApproach Key points\n`Gold standard' or reference data  Data where the true match status is known, used to test linkage algorithms and estimate rates\nof linkage error.\n Typically based on a subsample of records that have been manually reviewed, an additional\ndata source with complete identifiers, a representative synthetic dataset, or external refer-\nence rates for the population of interest\n For example, comparison of mortality rates based on linkage of death registrations versus\nnational figures (Schmidlin et al., 2013) or comparison of infection rates within a subset of\nvalidated data (Harron et al., 2013, Paixao et al., in press).\nPost-linkage data validation  Used to estimate minimum false-match rates by identifying implausible scenarios within\nthe data.\n For example, linkage of a hospital admission record following a known date of death could\nindicate a false-match; as could linkage of multiple death records to a single census record\nSensitivity analyses  Used to assess the extent to which results vary according to different linkage criteria.\n Could involve changing the linkage algorithm or changing the threshold within probabilistic\nlinkage, and re-running analyses to evaluate any impact on results (Lariscy, 2011).\n For example, comparing results over a range of match weights could help identify the\ndirection of the effect of linkage errors on outcomes of interest (Moore et al., 2014).\nComparing characteristics of\nlinked and unlinked data\n Used to identify any differences in linkage rates for different subgroups of individuals.\n For example, comparing rates of preterm birth in linked and unlinked maternity records\n Where not all records are expected to match, distributions of variables in the linked data can\nbe compared to external sources (e.g. age and/or ethnic group distributions from national\ncensus data) to explore any evidence of selection bias (Harron et al., 2016).\n8 Big Data & Society\nnot necessarily require all possible matches to be iden-\ntified (Paixao et al., in press). This strategy requires\ndiscussion between researchers and data linkers, so\nthat criteria for defining records as certain links and\ncertain non-links can be agreed upon. On the other\nhand, linkages with high levels of linkage are more\nrelevant to cohort study designs that prioritise high\nsensitivity to provide reliable prevalence estimates. In\nthe latter case, analyses can also incorporate inverse-\nprobability weights (e.g. from survey methodology), to\nprovide values for records that could not be accurately\nlinked. Further methods such as prior informed imput-\nation or multiple imputation can also be used where\nthere is uncertainty about the correct link, provided\ncertain non-sensitive characteristics that predict link-\nages are shared with researchers (Harron et al., 2014).\nRemaining challenges and future\ndirections\nWhile many of the technical challenges of safe data\nlinkage environments have been overcome, there are\nsituations where significant legal and administrative\nchallenges remain (Harron et al., 2015). These, in\nturn, impact on data availability and accessibility for\nresearch and policy development. Although some juris-\ndictions adopt approaches for timely and cost-effective\naccess to linked data (e.g. those in Ontario, Wales and\nAustralia where linkage keys can be held in perpetuity),\nothers are restricted by the `link and destroy' model,\nwhere linked data cannot be reused. A lack of stream-\nlined approval processes also contributes to inefficient\nprocesses for data access.\nThere are a number of areas of ongoing research in\nfacilitating access to data once it has been linked. For\nexample, data perturbation adds noise to data so that\nthe risk of re-identification is reduced to within speci-\nfied limits, i.e. by fixing the probability that a record\ncorresponds to the target individual. This technique\nretains the statistical properties of data for analyses\nand requires that analysts adjust for the added noise\nusing a measurement error model. Alternatively, syn-\nthetic data allow researchers to test out analyses on a\ndataset that mimics the structure of real data but that\ndoes not correspond to real individuals. This allows\nresearchers to explore potential modelling strategies\nprior to analysing the original data, thus reducing the\ntime spent within a safe setting (Dennett et al., 2015).\nHowever, selecting appropriate models for a particular\nanalysis relies on the correct structure being identified\nin the synthetic data, otherwise model estimates may be\nbiased.\nThe need to balance both privacy (for the individual)\nand quality (for research purposes) of linked data is a\npriority for research in data linkage methods. The\ndynamic, error-prone and incomplete nature of admin-\nistrative data makes a certain level of linkage error\ninevitable, and this is compounded when data are\nrequired to be anonymised before linkage. Developing\nmethods to adjust for biases arising for linkage error\nis therefore vital for producing robust evidence to\ninform policy.\nBridging the gap between linkage and analysis is a\nmajor challenge for progress in the area of linkage qual-\nity. Researchers often struggle to obtain the informa-\ntion they need to evaluate linkage and to developing\nmethods to account for any potential bias due to link-\nage error (Jorm, 2015). Recently published guidelines\non the information that should be shared between data\nlinkers and researchers are an important step towards\nincreasing the reliability of research using linked\nadministrative data (Gilbert et al., 2017). Sharing of\nthis information can support transparent reporting of\nstudies using linked administrative data (Benchimol\net al., 2015). As methodologies continue to evolve to\naddress issues of data security and quality, there is an\nongoing need to evaluate the most effective ways of\nsharing this information.\nAuthors' contribution\nAll authors contributed to the drafting of the manuscript.\n"
}