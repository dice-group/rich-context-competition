{
    "abstract": "License (http://creativecommons.org/licenses/by-nc/2.0/uk/) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.",
    "reduced_content": "License (http://creativecommons.org/licenses/by-nc/2.0/uk/) which permits unrestricted non-commercial use,\ndistribution, and reproduction in any medium, provided the original work is properly cited.\nOriginal Contribution\nAre Americans Feeling Less Healthy? The Puzzle of Trends in Self-rated Health\nJoshua A. Salomon, Stella Nordhagen, Shefali Oza, and Christopher J. L. Murray\nAlthough self-rated health is proposed for use in public health monitoring, previous reports on US levels and\ntrends in self-rated health have shown ambiguous results. This study presents a comprehensive comparative\nanalysis of responses to a common self-rated health question in 4 national surveys from 1971 to 2007: the National\nHealth and Nutrition Examination Survey, Behavioral Risk Factor Surveillance System, National Health Interview\nSurvey, and Current Population Survey. In addition to variation in the levels of self-rated health across surveys,\nstriking discrepancies in time trends were observed. Whereas data from the Behavioral Risk Factor Surveillance\nSystem demonstrate that Americans were increasingly likely to report ``fair'' or ``poor'' health over the last decade,\nthose from the Current Population Survey indicate the opposite trend. Subgroup analyses revealed that the great-\nest inconsistencies were among young respondents, Hispanics, and those without a high school education. Trends\nin ``fair'' or ``poor'' ratings were more inconsistent than trends in ``excellent'' ratings. The observed discrepancies\nelude simple explanations but suggest that self-rated health may be unsuitable for monitoring changes in pop-\nulation health over time. Analyses of socioeconomic disparities that use self-rated health may be particularly\nvulnerable to comparability problems, as inconsistencies are most pronounced among the lowest education group.\nMore work is urgently needed on robust and comparable approaches to tracking population health.\nhealth status; health surveys; public health; questionnaires\nAbbreviations: BRFSS, Behavioral Risk Factor Surveillance System; CI, confidence interval; CPS, Current Population Survey;\nNHANES, National Health and Nutrition Examination Survey; NHIS, National Health Interview Survey.\nMeasures of health status are widely used in clinical trials\nand studies on quality of care (1, 2). There is also increasing\ninterest in using health status measures to track changes in\npopulation health and health service needs and to monitor\nprogress toward broad goals for the health of communities\nand nations (3\u00ad5). Interest in tracking population health\nextends to comparisons across countries and measurement\nof disparities within countries (6\u00ad10). Further, population\nhealth measures capturing nonfatal outcomes are essential\nto understanding how well public health and medical care\nGlobal measures of self-rated health, based on responses\nto a single survey question, have been proposed as reliable\nand valid measures of population health (13\u00ad15) and rec-\nommended for use in health monitoring by the US Centers\nfor Disease Control, the World Health Organization, and the\nEuropean Commission (4, 13, 16). The most commonly\nused survey item asks people to characterize their health\nas ``excellent, very good, good, fair, or poor.'' The resulting\ncategorical responses are often dichotomized as ``fair'' or\n``poor'' versus all other categories (7, 17\u00ad19). A recent\nInstitute of Medicine report included the percentage of\nadults reporting ``fair'' or ``poor'' health among the set of\n8 indicators recommended for tracking the progress\nof health in the United States (20).\nAt the individual level, self-rated health based on a single\nitem has been found to be a strong predictor of health-care\nutilization, functional ability, and subsequent mortality,\neven after controlling for other measured indicators of\nhealth status and socioeconomic variables (21\u00ad26). Based\non the strength of these associations, self-rated health has\nbeen used extensively in policy analyses as an overall\nCorrespondence to Dr. Joshua A. Salomon, Harvard University Initiative for Global Health, 104 Mount Auburn Street, Third Floor, Cambridge, MA\nmeasure of health outcomes (27\u00ad30). Despite its appeal as\na simple measure with consistent predictive power in cohort\nstudies, however, existing evidence on trends in self-rated\nhealth in the United States--where time series are available\nfrom multiple survey programs--points to inconsistent pop-\nulation-level patterns across data sources and studies. Zack\net al. (31) analyzed self-rated health responses from the Be-\nhavioral Risk Factor Surveillance System and found worsen-\nNational Health Interview Survey (32), on the other hand,\nindicate that self-rated health has remained relatively stable.\nSuch discrepant findings based on responses to the same item\nin different nationally representative surveys raise questions\nabout thevalidity ofinferences about population health based\non self-rated health.\nTo further understand the potential use of self-rated health\nfor population-level monitoring, we present a comprehen-\nsive analysis of levels and trends in self-rated health re-\nsponses in 4 separate nationally representative US surveys.\nIn particular, we focus on characterizing discrepancies be-\ntween surveys, comparing discrepancies in self-rated health\nwith those in other types of questions, analyzing differences\nin specific subgroups, and considering possible explanations\nfor inconsistencies across surveys.\nData sources\nWe compared responses to a common survey item on\nself-rated health in 4 national US health surveys from\ntion Survey (NHANES), Behavioral Risk Factor Surveil-\nlance System (BRFSS), National Health Interview Survey\n(NHIS), and Current Population Survey (CPS). Table 1\nprovides a summary of the key characteristics of each\nsurvey.\nNHANES comprises a series of cross-sectional surveys of\nthe civilian, noninstitutionalized population aged 2 months\nor older (33). NHANES includes an in-person interview and\na subsequent examination component, with both physical\nand laboratory measurements. The first 3 rounds were con-\nNHANES became a continuous survey with data released\nevery 2 years.\nBRFSS is an annual cross-sectional telephone survey\nhealth departments in all 50 states and the District of\nColumbia by using a random-digit dialing method to obtain\na state-representative sample of the civilian, noninstitution-\nalized population aged 18 years or more. The state samples\ncan be combined to form a nationally representative sample.\nNHIS is an annual cross-sectional household interview\nsurvey of the civilian, noninstitutionalized population,\nupdated approximately every decade, with the last signifi-\ncant revision occurring in 1997. The current survey consists\nof a core questionnaire and supplementary material that may\nchange each year.\nCPS is a monthly nationally representative survey regard-\ning the US labor force, including the noninstitutionalized\npopulation aged 16 years or more (36). The survey is con-\nducted through both personal and telephone interviews,\nindependently in each state. In the survey design, members\nof a household are interviewed for 4 months, left out of the\nsample the next 8 months, and interviewed again for the\nfollowing 4 months. We restrict our analysis to the March\nsupplement, which includes self-rated health.\nAlthough NHIS and CPS elicit information on all house-\nhold members from a single household respondent, we in-\ncluded only self-reports in our analyses. An anomaly in the\n1998 CPS data set--the household respondent indicator is\nblank for 92% of the sample--makes it impossible to dis-\ntinguish self-reports from proxy responses, so we have\nMode of\nData Collection\nYears of\nAnalysis\nSample\nSizes, no.a,b\nResponse\nRates, %a,b,c\nCPS Telephone and/or\nin-person interview,\ndepending on state\nNHANES In-person interview\nand examination\nAbbreviations: BRFSS, Behavioral Risk Factor Surveillance System; CPS, Current Population Survey; NHANES, National Health and Nutrition\nExamination Survey; NHIS, National Health Interview Survey.\na Low and high reported across all years of analysis.\nb The dates in years are provided, respectively, with the first year(s) as the date(s) for the smallest sample size or response rate and the second\nyear(s) the date(s) for the largest.\nc BRFSS: median cooperation rate across states, defined as the ratio of respondents interviewed to eligible units in which a respondent was\nselected and actually contacted; CPS: response rate for the March supplement; NHANES: response rate for the interview component; NHIS:\noverall family response rate for 1997 and onward and overall response rate for the pre-1997 years.\nexcluded these data from our analysis. Self-reports and\nproxy responses in CPS show minimal differences in levels\nand trends in all other years (Web Figure 1). (This is the first\nof 3 supplementary figures; each is referred to as ``Web\nfigure'' in the text and is posted on the Journal's website,\nhttp://aje.oxfordjournals.org/.)\nHealth measures\nIn each survey, analyses were based on responses to the\nquestion, ``Would you say your health in general is excellent,\nvery good, good, fair, or poor?'' (The wording was re-\narranged slightly in BRFSS, as, ``Would you say that in gen-\neral your health is. . ..'') Respondents who answered ``don't\nknow/not sure'' or refused to answer were excluded from the\nanalysis (these respondents constituted less than 1% of the\noverall survey samples in every year and every survey).\nInitial analyses were based on dichotomizing self-rated\nhealth responses as ``fair'' or ``poor'' versus all other cate-\ngories, following common practice (7, 17\u00ad19). In further\nanalyses, we compared this approach with a range of\nalternatives.\nFor comparison, we also examined responses to other\nquestions common to the different surveys, including self-\nreported diabetes and body mass index computed from self-\nreported weight and height.\nAge-standardized measures were computed on the basis\nyears to 70 years or older.\nStatistical methods\nSample weights were applied in each data set to account\nfor unequal probabilities of selection, nonresponse, and non-\ncoverage. The provided weights included ratio adjustments\nto match population distributions by age, sex, and race/\nethnicity in each survey, except in some state samples from\nBRFSS, which matched only on age and sex. Variance\nestimation was undertaken by using Taylor-series lineariza-\ntion methods to account for complex survey designs includ-\ning clustering, stratification, and unequal weights (37). For\nCPS, which does not include variables on stratification and\nclusters in the public-release data set, we developed syn-\nthetic design variables following the approach of Joliffe\n(38), based on resorting the data and assigning consecutive\nobservations to synthetic clusters in a way that approximates\nthe design effects in the actual CPS sample. Following\nJoliffe, we used cluster sizes of 4 housing units and sorted\nby household income to induce intracluster correlation\nin self-rated health, based on the underlying association\nbetween income and health.\nFor each survey year, we computed confidence intervals\naround age-standardized proportions using different\nresponse categories. We examined patterns by sex and by\nor older. We also examined differences by race/ethnicity and\neducational level. Race/ethnicity was categorized as non-\nHispanic white, non-Hispanic black, Hispanic, and other.\nEducation was categorized as less than high school, high\nschool, and more than high school.\nTo assess trends over the last decade overall and by sex,\nage, race, and education, we fit logistic regression models\nrelating the probability of ``fair'' or ``poor'' self-ratings to\nmodels to NHANES, as data are available only for 2-year\n1998 because self-reports could not be distinguished from\nproxy responses in that year, as noted above. Separate mod-\nels were fit for each subgroup within each survey. Analo-\ngous logistic regression models were fit to the probability of\nreporting ``excellent'' health.\nAll statistical analyses were undertaken by using Stata\nRelease 10/SE (StataCorp LP, College Station, Texas).\nRESULTS\nIn 2007, the age-standardized proportion of respondents\nreporting fair or poor health ranged from 12.0% (95% con-\n(the most recent available) were similar to those in BRFSS,\nbut with greater uncertainty.\nTrends in age-standardized probabilities of reporting fair\nor poor health are plotted in Figure 1. BRFSS shows increases\nof 15% among women and 22% among men in reports of fair\nfollowed by slight increases for the next 2\u00ad3 years. Since\n1993, changes in NHIS have been relatively modest, except\nfor a sharp drop in 1997 coinciding with a major redesign of\nthe survey, which preserved the exact wording but relocated\nthe self-rated health question within the survey.\nNHANES shows declines in fair/poor ratings from the\nreductions in fair/poor ratings for males since 1999 and flat\ntrends for females over this period.\nIn order to consider whether differences among the sur-\nveys may apply more generally to other self-reported health-\nrelated items, we compared these results with trends in other\nvariables. For example, Figure 2 presents results from NHIS,\nBRFSS, and NHANES for females on age-standardized\nproportions reporting diabetes, which are much more con-\ncordant than self-ratings of health. Results are similar for\nmen (not shown). Figure 2 also presents a comparison of\nbody mass index computed from self-reported weight and\nheight. Although the levels and trends are similar in NHIS\nand BRFSS, estimates from NHANES are higher, by roughly\nthe same increment in each year of comparison. Thus, in\ncontrast to self-reported diabetes, self-reported body mass\nindex appears subject to some systematic variation across\nsurveys. Unlike self-rated health, however, the trend across\nsurveys appears largely consistent despite variation in esti-\nmated levels.\nTrends in Self-rated Health 345\nAnalyses by age, race, and education\nDisaggregation by age, race/ethnicity, and education\nreveals more subtle patterns (Figure 3). In the youngest\nage group, CPS and NHIS show the lowest fractions of\nrespondents reporting fair or poor health. Conversely, in\nthe oldest age group, the fraction reporting fair or poor\nhealth is highest in CPS. Overall, the sharpest divergence\nin trends across surveys appears in ages 20\u00ad49 years, with\nthe proportion reporting fair/poor health in 2007 around\n50% higher in BRFSS compared with NHIS or CPS, in\ncontrast to relatively modest differences in 1993. In older\nage groups, differences in levels are smaller across surveys,\nin relative terms, but variation in time trends remains.\nDisaggregating by race and ethnicity, we observe the\nsmallest inconsistencies among non-Hispanic African\nAmericans and the largest among Hispanics. For Hispanic\nrespondents, discrepancies among surveys have widened\nover time, with a nearly 2-fold difference in proportions\nreporting fair or poor health in NHIS versus BRFSS in\n2007, compared with roughly equal proportions in the\nearly 1990s. Levels and trends in the 4 surveys among\nnon-Hispanic whites are moderately discrepant.\nDisaggregating by educational level, the greatest discrep-\nancies appear among those respondents without a high\nschool diploma. The magnitudes of cross-survey differences\nin levels and trends between those with a high school\ndiploma and those with at least some college are similar.\nAlthough the poststratification weighting procedures in\nCPS, NHANES, and NHIS accounted for age, sex, and race/\nethnicity, adjustment for race was incorporated in some states\nbut not others in BRFSS (all states adjusted for age and sex).\nEducation was not factored into the weights for any of the\nsurveys. In our sample on self-rated health, we find some\ndifferences across surveys in the sample composition by\nraceand education (WebFigure2). Changesinthesevariables,\nhowever, are modest and gradual over the period of analysis,\nand cross-survey differences remain fairly constant over\ntime, which suggests that discrepancies in self-rated health\ntrends are not explained bydifferences in sample composition.\nAlternative coding schemes for categorical self-ratings\nof health\nAlthough researchers typically dichotomize self-rated\nhealth as ``fair'' or ``poor'' versus all other responses, we\nconsidered whether alternative approaches may yield more\nconsistent results. Figure 4 shows trends in the 4 surveys\nsince 1998 based on 4 different dichotomous coding\nschemes. (Web Figure 3 also presents trends in the average\nFigure 2. Age-adjusted trends in self-reported diabetes (A) and body mass index (BMI) (B) based on self-reported weight and height among\nfemales in 3 nationally representative surveys, United States, 1971\u00ad2007. Open circle, Behavioral Risk Factor Surveillance System; filled square,\nNational Health and Nutrition Examination Survey; open triangle, National Health Interview Survey.\nFigure 1. Age-adjusted trends in self-rated health in males (A) and females (B) in 4 nationally representative surveys, United States, 1971\u00ad2007.\nOpen circle, Behavioral Risk Factor Surveillance System; filled diamond, Current Population Survey; filled square, National Health and Nutrition\nExamination Survey; open triangle, National Health Interview Survey.\nself-rated score, coding ``excellent'' as 5, ``very good'' as 4,\nand so on, which indicate similar discrepancies across sur-\nveys as for ``fair/poor'' ratings.) The ordering of the differ-\nent surveys in terms of the age-standardized responses is\nlargely preserved across the different choices of dichoto-\nmous indicator, with NHIS producing the most favorable\nratings, followed by CPS, BRFSS, and NHANES; the ex-\nception is the indicator of ``poor'' self-ratings, for which\nCPS is least favorable. Figure 4 suggests visually that the\nproportion of respondents rating themselves as ``excellent''\nmay yield more consistent trends across surveys than the\nstandard choice of ``fair/poor.'' This possibility is evaluated\nformally in the statistical models described below.\nFor the 3 surveys with annual reporting (CPS, NHIS,\nlogistic regression of self-rated health (with either ``excel-\nlent'' or ``fair/poor'' ratings as the dependent variable) as\na function of calendar year. Separate models were fit for each\nsurvey, by subgroup. The estimated odds ratios for calendar\nyear in the regressions were translated into average annual\nrates of change in the odds of reporting either ``excellent'' or\n``fair/poor'' health. For example, an odds ratio of 1.02 on year\n100 \u00bc 2%. Figure 5 summarizes the regression results.\nOverall, and in both men and women, the regressions\nconfirm the observation that trends in ``excellent'' ratings\nare more consistent across surveys than trends in ``fair/\npoor'' ratings. In men, CPS shows significant declines in\nthe proportion of fair/poor ratings, in contrast to the signif-\nicant increases seen in BRFSS, whereas declines in excel-\nlent ratings are seen in all surveys, albeit at varying rates.\nAcross age groups, significant differences appear in fair/\npoor ratings from the 2 younger age groups, while excellent\nratings are less discrepant across surveys overall. Consider-\ning differences across race and ethnic groups, using either\ndichotomous measure, we found that the greatest discrep-\nancies in trends appear among Hispanic respondents, espe-\ncially in fair/poor responses. Finally, comparisons across\neducation groups indicate that, for those respondents who\nhave completed at least high school, trends are unambigu-\nously worse: More people report ``fair/poor'' health at the\nsame time that fewer people report ``excellent'' health. On\nthe other hand, trends among those without a high school\ndiploma offer the most ambiguous conclusions in any of\nthe subgroup analyses: In terms of both the fair/poor and\nexcellent responses, CPS points to a strong, significant\nfavorable trend, whereas BRFSS shows a strong, significant\nunfavorable trend in this group.\nDISCUSSION\nIn this study, we undertook a comprehensive comparative\nanalysis of self-rated health in 4 nationally representative\nUS surveys and observed widely discrepant results overall.\nFigure 3. Trends in self-rated health across age, race/ethnicity, and education subgroups, United States, 1971\u00ad2007. Open circle, Behavioral\nRisk Factor Surveillance System; filled diamond, Current Population Survey; filled square, National Health and Nutrition Examination Survey; open\ntriangle, National Health Interview Survey.\nTrends in Self-rated Health 347\nIn addition to variation across surveys in self-rated health\nlevels, we also noted striking inconsistencies in trends.\nWhereas BRFSS finds that Americans were increasingly\nlikely to report ``fair'' or ``poor'' health over the last decade,\nCPS indicates the opposite trend. Unpacking these discrep-\nancies through subgroup analyses reveals the greatest incon-\nsistencies in trends among younger respondents, Hispanics,\nand those without a high school education. Our results also\nchallenge the standard practice of focusing on the percent-\nage of respondents with self-ratings of ``fair'' or ``poor,'' as\nthis indicator appears prone to greater cross-survey discrep-\nancies than other indicators constructed from the same\nsurvey responses, such as the proportion with ``excellent''\nself-ratings.\nWide variations in levels and trends in self-rated health\nmeasured in nationally representative surveys using the\nsame survey item demand an explanation. There are at least\n3 possibilities. First, despite national sample frames and\napplication of sample weights, the aggregated results from\nsome surveys may not adequately reflect the national aver-\nage. For example, concerns have been raised in the past\nabout possible noncoverage and nonresponse bias in tele-\nphone surveys such as the BRFSS. Recent work, however,\nhas indicated that the bias produced by nonresponse in ran-\ndom-digit telephone surveys is probably modest (39, 40).\nAlthough we observed some differences in the demographic\ncomposition of the weighted samples in the 4 surveys, these\ndifferences were stable over time and therefore cannot\nexplain divergent time trends in self-rated health. Moreover,\nthe consistent trends across surveys observed in other mea-\nsures, such as diabetes prevalence, mirror a previous finding\nof consistent cross-sectional estimates in NHIS and BRFSS\nfor 13 of the 14 different health measures examined--with\nself-rated health being the notable exception (41).\nSecond, the differences in results across survey plat-\nforms may signify a survey mode effect particular to\nself-rated health. The potential importance of different\nmodes of administration has been noted previously for\nother specific types of questions, and indeed we observe\nsignificant differences across surveys in reported body\nmass index levels. In order to attribute divergent time\ntrends across the survey platforms to mode effects for\nself-rated health, however, the mode effects need to be\nacting differentially over time. In contrast to the body mass\nindex example of parallel time trends across surveys,\nresponses on self-rated health are evidently growing more\ndiscrepant over time. We are not aware of any existing\nstudies that account for mode-item effects that change over\ntime in such divergent manners.\nA third possibility is that there may be framing and\nordering effects in the different questionnaires that interact\nwith attributes of the respondents, so that biases across plat-\nforms are shifting. It is difficult to construct more precise\nhypotheses regarding the nature of the individual and pop-\nulation attributes that would progressively change framing\nand ordering effects over time. The major shift in NHIS\nresponses in 1997, accompanying a relocation of the self-\nrated health item within the overall structure of the inter-\nview, indicates that ordering effects for the self-rated health\nitem can be large. Cross-survey differences in the steady\nchanges in responses over time would require a more subtle\nform of framing or ordering effect. These effects might\nderive, for example, from some changing cultural or linguis-\ntic attributes of individual respondents. The widening incon-\nsistencies in trends among Hispanic respondents offer some\nevidence in favor of the potential importance of cultural or\nlinguistic factors, but more definitive conclusions await\nfurther qualitative and quantitative investigation.\nFigure 4. Age-adjusted trends in self-rated health, by category of response, United States, 1998\u00ad2007. Open circle, Behavioral Risk Factor\nSurveillance System; filled diamond, Current Population Survey; filled square, National Health and Nutrition Examination Survey; open triangle,\nNational Health Interview Survey.\nComparing trends by educational level, we find that dis-\ncrepancies across surveys are most pronounced among\nrespondents without a high school diploma. This finding\nhas potentially profound implications for analyses of socio-\neconomic disparities in health that rely on self-rated health\nresponses. Trends in CPS show improvements among lower-\neducated respondents at the same time that self-ratings are\nworsening among more educated respondents--which has\nthe net effect overall of reducing disparities across educa-\ntion groups. In contrast, BRFSS shows the sharpest declines\nin health among the least educated group, which implies\na widening gap across socioeconomic strata.\nAlthough our analysis of existing survey programs cannot\nprovide a clear indication of the causes of incomparabilities\nacross surveys and over time, it nevertheless offers an im-\nportant reminder that, at the present time, substantial cau-\ntion is warranted in using self-rated health to monitor trends\nin population health. One concrete suggestion that emerges\nfrom our study is to reconsider the standard approach of\ndichotomizing self-rated health as ``fair/poor'' versus other\nresponses. Although some recent studies have examined the\ncontinuity of self-rated health and found evidence of sym-\nmetry in responses at the positive and negative ends of the\nscale (42, 43), our study indicates that trends in self-reported\nexcellent health appear less prone to inconsistencies across\nsurveys than trends in self-reported fair/poor health. This\nfinding challenges the prevailing approach to using this vari-\nable in empirical studies in public health, epidemiology, and\nmedical sociology.\nGiven the importance of tracking nonfatal health out-\ncomes at the population level, what are the available options\nfor refining these tools for future use? Two main avenues\nhave been pursued to date. First, there has been a steady\nevolution of more detailed instruments that either ask mul-\ntiple questions about general health (44, 45) or ask about\nmore specific domains of health or symptoms (46\u00ad48).\nPopulation-level data for these instruments are not yet avail-\nable for long periods of time or from multiple sources in the\nsame country to test if they suffer from similar problems.\nRecent efforts to understand relations across various\nmultiitem health measurement scales have characterized\ndifferences across instruments in cross-sectional analyses\n(49\u00ad51), but extension of these analyses to compare time\ntrends requires further longitudinal study. Second, strategies\nsuch as anchoring vignettes (52, 53) have been proposed\nrecently to enhance the comparability of self-reported sur-\nvey responses in health and other areas. It is not yet known\nwhether such strategies can successfully remedy the bulk of\ncomparability problems across settings or over time.\nThe epidemiologic transition has advanced far enough\n(54\u00ad56) that, for most countries, critical questions regarding\nthe population's health encompass not only how long people\nlive but also their experience of health while they are alive.\nAlthough self-rated health continues to appeal as a health\nFigure 5. Average annual change in the odds of reporting ``excellent'' or ``fair/poor'' self-rated health, by sex, age, race/ethnicity, and education,\nUnited States, 1998\u00ad2007. Each bar shows the result of a separate logistic regression of self-rated health as a function of calendar year, estimated\nfor a particular survey and population subgroup. Blue, Behavioral Risk Factor Surveillance System; green, National Health Interview Survey;\norange, Current Population Survey.\nTrends in Self-rated Health 349\nmeasure that contributes unique information on individuals'\nperceptions of their own health and has strong predictive\npower for future outcomes, our study suggests that self-rated\nhealth may not be suitable for tracking changes in popula-\ntion health over time. In seeking to identify efficient mea-\nsurement strategies for this latter purpose, more\ndevelopment work on new robust and comparable\napproaches is urgently needed.\n"
}