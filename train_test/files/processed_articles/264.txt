{
    "abstract": "Summary. Analysing the use of marijuana is challenging in part because there is no widely accepted single measure of individual use. Similarly, there is no single response variable that effectively captures attitudes toward its social and moral acceptability. One approach is to view the joint distribution of multiple use and attitude indicators as a mixture of latent classes. Pooling items from the annual `Monitoring the future'surveys of American high school seniors from 1977 to 2001, we find that marijuana use and attitudes are well summarized by a four-class model.",
    "reduced_content": "Latent class logistic regression: application to\nmarijuana use and attitudes among high school\nseniors\n \n \n \nUniversity of Washington, Seattle, USA\nand Joseph L. Schafer\n \nSummary. Analysing the use of marijuana is challenging in part because there is no widely\naccepted single measure of individual use. Similarly, there is no single response variable that\neffectively captures attitudes toward its social and moral acceptability. One approach is to view\nthe joint distribution of multiple use and attitude indicators as a mixture of latent classes. Pooling\nitems from the annual `Monitoring the future'surveys of American high school seniors from 1977\nto 2001, we find that marijuana use and attitudes are well summarized by a four-class model.\nSecular trends in class prevalences over this period reveal major shifts in use and attitudes.\nApplying a multinomial logistic model to the latent response, we investigate how class mem-\nbership relates to demographic and life style factors, political beliefs and religiosity over time.\nInferences about the parameters of the latent class logistic model are obtained by a combination\nof maximum likelihood and Bayesian techniques.\nKeywords: Categorical data; Data augmentation; Finite mixture; Markov chain Monte Carlo\nmethods; Multiple imputation\n1. Introduction\nMany theories of substance use and dependence describe behaviour in terms of population\nclasses or developmental stages. For example, the acquisition of nicotine dependence is often\ndepicted as a behavioural sequence that includes the initial trying of tobacco, experimenta-\ntion and regular smoking before dependence (Leventhal and Cleary, 1980; Flay, 1993; Mayhew\net al., 2000). Additional types of smokers have been identified such as non-dependent irregular\nsmokers (called `chippers') (Shiffman et al., 1994). Stage sequential models have been used to\ndescribe the onset of substance use (Graham et al., 1991; Lanza and Collins, 2002) and to test\nthe gateway hypothesis, which regards marijuana as a potential conduit to more harmful sub-\nstances such as heroin or cocaine (Collins, 2002). A common theme of these theories is that,\nat any moment, individuals are placed into distinct categories or groups rather than along a\ncontinuum.\nAddress for correspondence:   Department of Epidemiology, Michigan State University, B 601\nE-mail: hchung@epi.msu.edu\n724 H. Chung, B. P. Flaherty and J. L. Schafer\nLatent class (LC) analysis (Goodman, 1974; Clogg and Goodman, 1984) is ideally suited to\ntheories of this type. In LC analysis, relationships between categorical variables are explained\nby positing the existence of an unobserved or latent classifier that makes them conditionally\nindependent--i.e. categorical variables are conditionally independent within each latent classi-\nfier. If an LC model fits well, it may provide a parsimonious and intuitively appealing summary\nof the cell frequencies in a high dimensional contingency table and reveal features that are not\napparent from an item-by-item analysis. Another advantage of an LC analysis is that, rather\nthan taking each response at face value, the items are treated as fallible indicators of unseen\nstates. Logical inconsistencies--e.g. a subject claiming use in the last 30 days but no lifetime\nuse--are allowed by the model and do not need to be edited out of the data. In recent years,\nLC modelling has become an increasingly popular strategy for quantifying measurement error\nin substance use self-reports (Flaherty, 2002). Indeed, Biemer and Wiesen (2002) have demon-\nstrated that LC models may yield plausible estimates of the rates of misreporting, comparable\nwith what we would obtain from an expensive process of reinterview. Recent extensions to the\ntraditional LC model allow covariates to predict class membership (Bandeen-Roche et al., 1997).\nThey allow the marginal distribution of class membership to be affected by covariates through\na binary or polytomous logistic regression. In this framework, influences of covariates on items\nare completely mediated by the class membership. The LC logistic regression model allows the\ndistributions of class membership to vary with covariates, but the meaning of the unseen class\nis still determined only by the items. As in classical logistic regression theory, the covariates are\nnon-stochastic, assumed known and fixed.\nIn this paper we apply LC logistic regression to items on self-reported use of marijuana and\nattitudes in representative samples of American high school seniors from 1977 to 2001. The data\nwere drawn from `Monitoring the future' (MTF), an on-going survey that explores changes in\nvalues, behaviours and life style orientations of contemporary American youth (Johnston et al.,\n2001). Analyses of MTF show that rates of use of marijuana among seniors have fluctuated\ndramatically over the last three decades. Prevalence rose during the late 1960s and throughout\nmost of 1970s, declined steadily and substantially throughout the 1980s and began to rise again\nduring the 1990s (Johnston et al., 2002). The use of marijuana is known to be strongly correlated\nwith individuals' attitudes towards its social and moral acceptability (Johnston, 1982, 1985). If\nattitudinal measures are treated as exogenous predictors, interpretation of the estimated rela-\ntionships is clouded by the strong possibility that patterns of use may influence attitudes. Rather\nthan attempting to disentangle use and attitudes, we use LC analysis to examine how they have\njointly co-occurred and changed over time.\nOur work reveals that throughout this period the population has been dominated by four\ngroups: non-users who disapprove of use, non-users who are somewhat approving, experiment-\ners who disapprove of regular use and regular users who approve of regular use. Previous anal-\nyses from MTF revealed significant relationships between the use of marijuana and a variety of\nother factors including demographic characteristics, life style and beliefs (Bachman et al., 1998).\nAccordingly, we use these as covariates to predict jointly the prevalence of group membership.\nWe show how the rates of group membership have historically changed and we examine group\ncomposition in terms of the covariates.\nIn most applications of LC models to date, parameters have been estimated by maximum like-\nlihood (ML). ML may lead to reasonable estimates but often fails to provide useful measures of\nuncertainty. Even with a large sample and well fitting model, ML estimates for some quantities\nmay lie on or near a boundary of the parameter space, rendering the usual Hessian-based stan-\ndard errors ineffective (Chung, 2003). As an alternative to ML, Bayesian analysis by Markov\nchain Monte Carlo (MCMC) sampling has been applied to LC models by Hoijtink (1998),\nLatent Class Logistic Regression 725\nGarrett and Zeger (2000) and Garrett et al. (2002). We extend the work of these researchers by\nshowing how to incorporate covariates and how to account for missing items. Moreover, we\ndemonstrate how the technique of multiple imputation (MI) (Rubin, 1987) can be applied to\nLC indicators to simplify aspects of modelling, inference and diagnosis.\n2. A latent class logistic regression model\n2.1. A traditional latent class model\nLet Yi =.Yi1,. . . , YiM/ be a vector of M survey items for the ith individual, where variable Yim\ntakes possible values 1,2,. . . , rm. The basic idea of the LC model is that associations between\nitems are assumed to arise because the population is composed of different unseen classes. In\nother words, the population is assumed to consist of mutually exclusive and exhaustive groups\n(LCs), and the distributions of the items vary across classes. Let li =1, 2, . . . ,L be the LC mem-\nbership of the ith individual, and let I.y=k/ denote the indicator function which takes the value\n1 if y =k and 0 otherwise.\nIf li were observed, the joint probability that the ith individual belongs to class l and provides\nresponses yi =.yi1,. . . , yiM/ would be\nPr.Yi =yi,li =l/=l\nM\nrm\nI.yim=k/\nmk|l\n,\nwhere l = Pr.li = l/ denotes the marginal rate of lth-class membership in the population, and\nmk|l = Pr.Yim = k|li = l/ represents the probability of response k to the mth item given class\nmembership in l. We refer to the -parameter as the `item response probability'. Therefore,\nthe marginal probability of item responses without regard for the unseen class membership\nis\nPr.Yi =yi/=\nL\nl\nM\nrm\nI.yim=k/\nmk|l\nHere we have assumed that the items Yi1,. . . , YiM are conditionally independent or unrelated\nwithin each class of li. This assumption, called `local independence' by (Lazarsfeld and Henry\n(1968), is the crucial feature of the LC model that allows us to draw inferences about the unseen\nclass variable.\n2.2. A latent class logistic regression model\nA natural way to extend the LC model (1) is to include stratification or grouping variables\nand to investigate whether a common LC structure holds across groups. Clogg and Goodman\n(1984) introduced an observed variable gi =1,2,. . . ,G and allowed the - and/or -parameters\nto vary across groups. This approach, which represents a first attempt to incorporate covari-\nates into LC analysis, is obviously limited to situations where the grouping variable is discrete\nand the number of groups is small. Dayton and Macready (1988) proposed a more general\nway to incorporate subject-specific covariates, allowing them to influence  through a logistic\nlink. They computed ML estimates by a computationally intensive simplex method, whereas\nBandeen-Roche et al. (1997) applied an EM algorithm. Pfeffermann et al. (1998) described a\ngeneralization where not only  but also  is functionally related to covariates. ML routines for\nthese models have been implemented in the software packages Mplus (Muth\u00e9n and Muth\u00e9n,\n1998) and Latent GOLD (Vermunt and Magidson, 2000). Allowing  to depend on covariates\n726 H. Chung, B. P. Flaherty and J. L. Schafer\ncan be problematic, because the covariates may introduce associations between the items within\nan LC, violating local independence. In such a model, the LC structure changes as covariates\nare added or deleted. If  is allowed to covary with predictor variables, then the composition\nof the LCs is no longer constant over the population, and the meaning of  becomes unclear\nWe apply a generalized version of the Dayton and Macready (1988) model in which a grouping\nvariable gi is allowed to affect either the values of  or  or both, but  is not allowed to change\nwith covariates. Let xi = .xi1,xi2,. . . , xip/ denote a vector of covariates for the ith individual.\nImplicitly conditioning on x1,. . . , xn and g1,. . . , gn, our model is\n=y1,. . . , Yn =yn/=\nG\nL\nl|g.xi/\nM\nrm\nI.yim=k/\nmk|lg\nwhere ig denotes the product over the set of individuals in subgroup g. Rates of class mem-\nbership are related to covariates by\nl|g.xi/=Pr.li =l|xi, gi =g/\n=\nexp.xi\nl|g\n/\nexp.xi\nj|g\n/\nfor l = 1,. . . ,L - 1, with L|g.xi/ available as 1 - 1|g.xi/ - . . . - L-1|g.xi/. In equation (3),\nl|g\n=.1l|g, . . . , pl|g/ is a p\u00d71 vector of logistic regression coefficients for subgroup g influ-\nencing the log-odds that an individual falls into class l relative to the base-line class L.\nWe compute ML estimates for the unknown - and -parameters in model (2) by a hybrid pro-\ncedure which combines EM iterations with steps of the Newton\u00adRaphson algorithm (Chung,\n2003). Our algorithm allows missing values to occur among the items in yi, provided that they are\nmissing at random (Rubin, 1976). Asymptotic standard errors for the estimated parameters are\ncomputed in the usual way, which assumes that the log-likelihood is a concave function. Infor-\nmally, we can think of concave functions as functions that `spill water'--i.e. they are shaped like\nan inverted bowl. (More formally, concave functions lie above lines connecting any two points.)\nIf the observed data log-likelihood is concave, the inverse of (-1 times) the Hessian matrix of\nthis log-likelihood consistently estimates the covariance matrix for the ML estimates. In many\ncases, however, this procedure fails because the log-likelihood is not concave. For example, if\nany of the estimated s is close to 0 or 1--which happens when the item in question is a strong\npredictor of class membership--then we cannot obtain standard errors either for the s or for\nthe s. If the sample is not sufficiently large, or if the variation in -parameters across the LCs\nis not sufficiently strong, the log-likelihood can be fairly constant over the regions where it is\nhigh, distorting the contours of the log-likelihood and causing the Hessian matrix to approach\nsingularity. Large fluctuations in curvature are an inherent feature of finite mixtures, so the\nvalue of Hessian-based standard errors is often questionable. This stems from the fact that\nthe log-likelihood function from this finite mixture is invariant with respect to the L! possi-\nble reorderings of the class labels. Confidence regions sometimes extend into portions of the\nparameter space where the class labels have permuted from their order at the current mode,\nmaking the interpretation of the region unclear (Chung, 2003; Chung et al., 2004). Because of\nthese common difficulties with ML, we have also developed Bayesian alternatives, which we\nnow describe.\nLatent Class Logistic Regression 727\n3. Bayesian approaches based on Markov chain Monte Carlo sampling\n3.1. Parameter simulation via Markov chain Monte Carlo sampling\nBayesian methods for LC models have been described by Hoijtink (1998), Garrett and Zeger\n(2000) and Lanza et al. (2005). Without covariates, a simple MCMC algorithm may be imple-\nmented as an iterative two-step procedure which can be regarded as a form of data augmentation\n(Tanner and Wong, 1987) or Gibbs sampling (Gelfand and Smith, 1990). Covariates introduce\na minor complication because there is no simple conjugate prior family for the coefficients of\na multinomial logistic model. We overcome this difficulty by embedding steps of a Metropolis\nalgorithm (Metropolis et al., 1953) for the s into the Gibbs sampler (Robert and Casella, 2004).\nLet zi be an L-dimensional vector of binary variables indicating the latent class to which the\nith individual belongs, i.e., if individual i belongs to class l, then zi contains a 1 in position l and 0\nin every other position. In the first step of our MCMC procedure--the imputation or I-step--we\ngenerate a random draw for each zi given the observed data yi and current parameter guesses.\nIn the second step--the posterior or P-step--we draw new random values for the parameters\nfrom the augmented data posterior distribution which regards the LC membership indicators\nzi as known. Repeating this two-step procedure creates a sequence of iterates converging to the\nstationary observed data posterior distribution. Details of this two-step procedure are given\nbelow.\nIn the I-step, given current simulated parameter values, we calculate the posterior probabili-\nties of class membership by using\nil|g =Pr.li =l|Yi =yi, gi =g/\n=\nl|g.xi/\nM\nrm\nI.yim=k/\nmk|jg\nL\nj|g.xi/\nM\nrm\nI.yim=k/\nmk|jg\nfor l =1,. . . ,L. Then we draw zi from a multinomial.1, i|g/ distribution independently for all\nindividuals in group g, where i|g =.i1|g,. . . , iL|g/.\nOnce class membership has been imputed, the augmented data likelihood factors into inde-\npendent likelihood functions for the - and -parameters. Let B represent coefficients vectors\n,. . . , L-1|G\n/, and let  denote the vectorized item response probability containing all\n-parameters. The augmented data posterior given class membership may be expressed as\nPr.B,|y,z/ Pr.B/\nG\nL\nl|g.xi/zil Pr./\nG\nL\nM\nrm\nnmk|lg\nmk|lg\nwhere y =.y1, . . . , yn/, z =.z1,. . . , zn/, nmk|lg =ig I.yim =k, zil =1/ and Pr.B/ and Pr./ are\nthe priors for B and  respectively.\nIn the P-step, we draw new random values for  and B independently from distribution\n(5). Applying a Jeffreys prior to m|lg\n= .m1|lg,. . . , mrm|lg/, new random values for m|lg are\ndrawn from a Dirichlet.nm1|lg + 1\n,. . . , nmrm|lg + 1\n/ distribution independently for m=1, . . . ,M,\nl = 1,. . . ,L and g = 1,. . . , G. A draw from the Dirichlet distribution can be obtained by nor-\nmalizing a vector of rm independent gamma variates (Kennedy and Gentle, 1980).\nIn Bayesian approaches to regression, coefficients are often treated as exchangeable in their\nprior distributions when attempting to make prior information vague. Goldstein (1976) noted\nthat ridge regression (Hoerl and Kennard, 1970) can be viewed as a Bayesian technique with\nan exchangeable normal prior distribution on the coefficients. The analogue to a ridge prior for\n728 H. Chung, B. P. Flaherty and J. L. Schafer\nour multinomial logit model may be represented by a product of p-dimensional multivariate\nnormal distributions. Another prior distribution, which was suggested by Clogg et al. (1991),\nhas the conjugate form\nPr.g\n/\nig\nL\nl|g.xi/ail\nfor g\n= .1|g,. . . , L-1|g\n/, where the hyperparameters ail could possibly depend on the data.\nail \nig\nn\nI.ig/\nso that the prior distribution smooths g towards an intercept-only model. When the sample\nsize is large relative to the number of parameters, the choice of prior has little effect on the final\ninferences. We use an improper uniform prior (i.e. ail = 0) for our study. This choice may be\nsomewhat arbitrary but, given the large sample size that we have, the difference in inferential\noutput among different sets of prior distributions is inconsequential.\nWe then generate g by the following Metropolis algorithm. At iteration t, a candidate for\nthe next g is sampled from a multivariate Student t proposal distribution t..t/\ng\ndegrees of freedom, where .t/\ng\nis the parameter value at iteration t. Following the advice of\nGelman et al. (2004) for an efficient Metropolis jumping rule, we set c  2:4\n\n{p.L-1/}. For\nour guess of , we invert the g-submatrix of the Hessian evaluated at the ML estimates ^\nB\nand ^\n,\n=-\n@g\n@g\nB= ^\nB,= ^\n\nwhere l is the logarithm of the likelihood function that is defined in model (2). (This inverse\ntypically exists even if ^\n lies on a boundary, because we are ignoring the cross-derivatives with\nrespect to B and .) Expressions for the elements of the Hessian are similar to those which were\ngiven by Bandeen-Roche et al. (1997). The candidate point c\ng\nis then accepted with probability\n..t/\ng\n,c\ng\nig\nL\nl.xi/|c\ng\nl.xi/|\n.t/\ng\nzil\n:\nExtending this procedure to a data set with missing items in yi is straightforward. In the\nI-step, given the current parameter guesses, the posterior probabilities are calculated only from\nthe observed part of yi,\nobs\nil|g\n=Pr.li =l|Yobsi\n=yobsi\n, gi =g/\n=\nl|g.xi/\nmobsi\nrm\nI.yim=k/\nmk|lg\nL\nj|g.xi/\nmobsi\nrm\nI.yim=k/\nmk|jg\n,\nwhere obsi denotes the sets of items responded to by the ith individual. The class membership zi\nis drawn from a multinomial.1,obs\ni|g\n/ distribution independently for all individuals in group g.\nIn the I-step, we also generate the missing part of each yi as follows. Suppose that the mth item\nis missing for individual i who belongs to group g and class l; then yim is randomly drawn from a\nLatent Class Logistic Regression 729\nmultinomial.1,m|lg\n/ distribution, where m|lg is a set of samples from the previous iteration. In\nthe P-step, the updated B and  are simulated in the manner that was described above, treating\nthe imputed values for the missing elements of yi as known.\n3.2. Methods of inference\nIn a typical application of MCMC sampling, the analyst runs the algorithm for a burn-in period\nto eliminate dependence on the starting values. After the burn-in, averaging the output stream of\nsimulated parameters produces estimates for the posterior means and variances (Tierney, 1994).\nVarious methods for choosing the length of the series and the burn-in period have appeared in\ntime series plots and autocorrelation functions to monitor visually the behaviour of output val-\nues from the MCMC algorithm and to confirm our choice for the length of the burn-in period.\nAfter burn-in, we typically use 10000 or more cycles of MCMC sampling to estimate posterior\nmeans and variances.\nAs an alternative to averaging over the simulated parameters, the output from the MCMC\nalgorithm may also be summarized through MI (Rubin, 1987). In MI, we retain a few (say,\n10\u00ad20) simulated draws of the LC variables l1,. . . , ln and missing parts of y1, . . . ,yn from the\nI-steps, spacing them enough cycles apart to ensure that they are essentially independent. Treat-\ning these imputed values as known, we compute point and variance estimates for the s and\ns by standard complete-data methods for proportions and logistic regression coefficients. The\nresults are then combined by using Rubin's (1987) rules for scalar estimands.\nDirect simulation of parameters via MCMC sampling and MI will yield similar inferen-\ntial summaries. Parameter simulation can be more efficient, particularly when based on a long\nsequence of random parameters drawn at P-steps. In contrast, MI retains the drawn values from\njust a few I-steps and is more convenient for analyses that are more exploratory. More discussion\non the relative merits of MI versus direct simulation of parameters by MCMC sampling is given\nA potentially troublesome aspect of MCMC sampling for LC models is label switching. As\nmentioned previously, the likelihood function from an LC model is invariant to permutations\nof the class labels. If the priors are also symmetric with respect to class labels, the posterior\ndistribution will be similarly invariant. This invariance makes the output stream for parameters\ndifficult to interpret if the class labels switch during the MCMC run. Time series plots of the\noutput stream must be examined for evidence of label switching. Label switching did not occur\nin our analyses of data from MTF. It could be argued that non-occurrence of label switching\nis a sign of poor convergence, as the algorithm remains trapped around a local mode (Justel\nand Pe\u00f1a, 1996). For our purposes this is advantageous because, if the algorithm were to switch\nbetween the equivalent modes, the substantive meaning of the parameters would change, and\nsummarizing the posterior would become difficult. A variety of strategies for resolving problems\nthat are related to label switching are reviewed by Chung et al. (2004).\n4. Application to `Monitoring the future'\nis selected from 125\u00ad140 schools to represent a cross-section of high school seniors in the 48\ncontiguous United States. Each participant receives one of five different questionnaire forms\nwith items pertaining to drug use, attitudes towards the Government, social institutions, race\n730 H. Chung, B. P. Flaherty and J. L. Schafer\nrelations, changing roles of women, educational aspirations, occupational aims and marital and\nfamily plans.\nIn MTF, the use of marijuana is retrospectively measured by self-reported frequency of use\nover various periods of time. Subjects report how often they have used marijuana in their life-\ntimes (Life), over the last 12 months (12Mo) and over the last 30 days (30Da). Responses fall\nand 40 or more). Ordinal response items can be viewed as discretized continuous variables. Thus,\nthe LC model can be assumed to have a mixture of multivariate normal distributions using the\nmultivariate probit model (Chib and Greenberg, 1998). This would introduce complication and\nrequire further research. For this study, we reduced each of these items to a binary indicator,\n(0) by 2. A fourth item asks how likely it is that the subject will use marijuana in the next 12\nmonths (Nxt12Mo), with four possible responses ranging from `definitely will' to `definitely will\nnot'; this item was recoded to 1 for `will use' and 2 for `will not use'.\nLike use of marijuana itself, no single item effectively summarizes an individual's attitudes\ntowards use. MTF's form 3 included three items for attitudes. Subjects were asked whether they\ndisapprove of people trying marijuana once or twice (TryMJ), smoking marijuana occasionally\n(OccUse) and smoking marijuana regularly (RegUse). Once again, the possible responses to\nthese items were simplified to binary values of 1, do not disapprove, or 2, disapprove.\nOur logistic LC regression models are based on these seven dichotomized use and attitude\nitems. Our covariates included sex (male or female), race (white or non-white), political beliefs\n(conservative, moderate or liberal), importance of religious beliefs (not important, important\nor very important), number of skipped classes, grades and number of evenings out per week.\nDummy variables were created for sex, race and political and religious beliefs. Including an\nintercept term, the full covariate vector xi for each individual had length 10.\nBecause of differences in questionnaire formats in the first two years of MTF (1975 and 1976),\nspecified as a grouping variable g, and the logistic coefficients l|g were estimated separately for\neach year g =1,. . . ,25. In some cases we allowed the -parameters to vary by year, but in other\ncases we constrained them to be equal across years.\nOur estimation procedures allow for missing values in the use and attitude items but not in\nthe covariates. After combining the samples from 1977 to 2001 and removing individuals with\nmissing covariates, our pooled data set contained 40690 individuals. Deleting subjects may\nintroduce bias if those with missing covariates are systematically different from the complete\ncases (Little and Rubin, 2002). These biases may be reduced by reweighting the complete cases\nby estimated inverse probabilities of response (Robins et al., 1994). In this case, however, a\ndearth of strong predictors for non-response would make the effect of weighting adjustments\ninconsequential.\n4.2. Unconstrained latent class analyses\nThe first and most crucial step in an LC regression analysis is to choose an appropriate class\nstructure. As shown by Bandeen-Roche et al. (1997), model (2) has an appealing marginalization\nproperty: averaging over an arbitrary distribution for the covariates xi produces a conventional\nLC model with the same number of classes and identical values for the s. Therefore, we do not\nneed to consider covariates when selecting the number of LCs or interpreting them.\nChoosing the number of classes in LC analysis and other finite mixture models is an important\nbut difficult statistical problem which has not been completely resolved. Models with different\nnumbers of classes are typically compared by using penalized likelihood criteria such as AIC\nLatent Class Logistic Regression 731\nTable 1. Fit statistics, degrees of freedom and normed fit index\nfor a series of unconstrained LC models without covariates\nNumber of -2 log- G2 Degrees of Normed\nclasses likelihood freedom fit index\nlihood ratio statistic for testing the number of classes in a normal mixture. Rubin and Stern\n(1994) and Garrett and Zeger (2000) assessed the number of classes through Bayesian posterior\npredictive checks. Richardson and Green (1997) treated the number of classes as an unknown\nparameter and used reversible jump MCMC methods to obtain a full joint posterior distribution\nincluding the number of classes.\nIn the absence of strong prior beliefs, the number of classes is usually chosen to strike a bal-\nance between parsimony, fit and interpretability. If the number is too small, the model may give\na poor fit to the joint distribution of observed item responses. If the number is too large, we\nmay find that the -parameters for some classes are too similar to attach substantively different\nmeanings to them, or that some classes have estimated prevalence rates that are nearly 0.\nBecause we have pooled samples over a 25-year period, there is a strong possibility that\nthe number of LCs or their -parameters could vary over time. To allow for that possibility,\nwe fit a sequence of unconstrained LC models without covariates that allow the -parameters\nto vary by year. We started with two classes and increased to three, four and five. Log-like-\nlihood values, deviance statistics (G2) and degrees of freedom for these models are shown in\nTable 1. Deviance statistic G2 must be interpreted carefully when the data contain missing values.\nAs noted by Little and Rubin (2002), chapter 13, fit statistics are aggregated over the cross-\nclassified contingency tables for all missingness patterns appearing in the data set. Models that\nfit well may have large values of G2, because this statistic also detects departures from the (usu-\nally implausible) hypothesis of data missing completely at random. To overcome this difficulty,\nwe adjusted each G2-statistic by removing the portion corresponding to the saturated model.\nDetails of this adjustment are described by Schafer (1997), section 8.5.2.\nEvaluating the significance of these G2-statistics by the usual 2-approximation is not appro-\npriate because, despite the large sample size, estimated expected counts for many of the 25\u00d727 =\n3200 cells are close to 0. Differences in G2 should not be compared with 2-distributions either,\nbecause likelihood ratio statistics for testing the fit of an L-class model against an .L+1/-class\nalternative do not have limiting 2-distributions (Aitkin and Rubin, 1985; Lindsay, 1995). The\nrelative decrements in G2, called the normed fit indices, are reported in Table 1. The normed\nfit index is defined as the proportion of the .L+1/-class model's drop in G2 compared with the\nG2-value of the L-class model. This comparative fit index is a popular descriptive statistic in\nstructural equation modelling (Bentler and Bonett, 1980). Table 1 shows large drops in G2 as\nthe number of classes increases from 2 to 3 (52%) and from 3 to 4 (70%), but a much smaller\ndrop from four classes to 5 (29%).\nAs suggested by Garrett and Zeger (2000), we also compared the estimated probabilities of\nmajor response patterns under the three-, four- and five-class models by a posterior predictive\ncheck distribution. This comparison is based on the following process. Let r represent the\n732 H. Chung, B. P. Flaherty and J. L. Schafer\nmarginal probability of the rth response pattern from model (2). The posterior predictive check\ndistribution is defined as\nPr.r|y/= Pr.r|B,/ Pr.B,|y/d.B, /,\nwhere Pr.B,|y/ is the observed data posterior distribution. By comparing the probability r\nwith an observed response probability obs\nr\n, we can see how well a model reproduces the observed\ndata. We estimated r for the 36 most prevalent patterns under the three-, four- and five-class\nmodels. The three-class model did not fit well because, out of 36 most prevalent patterns, 12\npatterns of obs\nr\nlay outside the estimated intervals of rs. We found that five classes did not\nfit much better than four: the intervals for 32 patterns of r contained their observed response\nprobabilities under four classes, but only 29 intervals did under five classes.\nAnother reason for preferring the four-class model is that its item response probabilities\n(-parameters) are more stable over time. Temporal stability of these parameters is necessary to\nassign a clear interpretation to trends in class prevalence and composition. If they vary strongly\nover time, then the meaning of a statement such as `Membership in class 1 increased from 40%\nmeanings in 1980 and 1992. Plots of the estimated s by year for each use and attitude item are\nshown for the four-class model in Fig. 1 and for the five-class model in Fig. 2. The five-class\nversions show large fluctuations from one year to the next. Even more troubling are the many\nplaces where the plotted curves cross each other, because the interpretation of the classes is\nlargely derived from their ordering with respect to these parameters. In contrast, the plots for\nthe four-class model show less variation and fewer crossings.\nExamining Fig. 1 closely, however, we do see a few troublesome features. Consider the\nresponse probability for the regular use item (RegUse) in class 4. Members of class 4 have\na high probability (almost 80%) of endorsing regular use at the beginning of the study period,\nbut it drops to nearly 40% by 1990 and then rises again to about 60% by the end of the study.\nThe item measuring attitude towards occasional use (OccUse) has two unusual aspects. First,\nthe probability of endorsing occasional use in class 3 drops from about 60% in 1977 to almost\n0 by 1990 before rising again. Second, the rate of endorsement in class 2 is generally high, but\nthere are four years in which it suddenly drops. Aside from these few difficulties, the overall\npicture that emerges from Fig. 1 is that the four-class model is quite well behaved.\n4.3. Four-class model with equality constraints\nTo smooth out the temporal fluctuations, we fit another four-class model in which the -prob-\nabilities are constrained to be equal for all 25 years. G2 for this constrained model is 5981.59\nwith 3072 degrees of freedom. Comparing this with the unconstrained four-class model that\nAlthough this drop appears to be statistically significant--which is not surprising, given the\nlarge sample size--the relative stability of the parameter estimates gives us confidence that this\nconstrained model captures the most essential features of the class structure over the 25-year\nperiod. For example, Fig. 3 displays for one of the items (Nxt12Mo) the point and 95% interval\nestimates for the unconstrained s for all years superimposed over the constrained estimates. For\neach class, the constrained estimate and interval end points appear as horizontal lines, and the\ndots with vertical lines represent the unconstrained estimates and intervals. A large majority of\nthe intervals from the unconstrained model overlap the estimates from the constrained model.\nUsing a constrained model, even if it ignores some of the fine details of the item distributions\nLatent Class Logistic Regression 733\nYear\nYear\nYear\nYear\nYear\nYear\nYear\n(a) (b)\n(c) (d)\n(e)\n(g)\n(f)\nFig. 1. Estimated item response probabilities (-parameters) under the unconstrained four-class model:\n(a) Life; (b) 12Mo; (c) 30Da; (d) Nxt12Mo; (e) TryMJ; (f) OccUse; (g) RegUse\nfor some years, it is a sensible way to strengthen inferences about the other model parameters\nand to facilitate comparisons of prevalence rates and covariate effects across years. Although\nwe acknowledge some decrement in fit, we gain much in terms of interpretability.\nEstimates and 95% intervals for all the -parameters from the constrained four-class model\nare shown in Table 2. These were computed by three methods: ML using a combination of\nthe Newton\u00adRaphson and EM algorithms (ML), our data augmentation MCMC algorithm\ntaking long run averages of the simulated parameters (DA) and MI of the LCs and missing items\n(MI). Point estimates from the three methods are nearly indistinguishable. Standard errors are\n734 H. Chung, B. P. Flaherty and J. L. Schafer\nYear\nYear\nYear\nYear\nYear\nYear\nYear\n(a) (b)\n(c) (d)\n(e)\n(g)\n(f)\nFig. 2. Estimated item response probabilities (-parameters) under the unconstrained five-class model:\n(a) Life; (b) 12Mo; (c) 30Da; (d) Nxt12Mo; (e) TryMJ; (f) OccUse; (g) RegUse\nnot available for the ML method; the Hessian matrix could not be inverted, because some of\nthe estimates lie at or near boundaries. The Bayesian intervals from methods DA and MI are\nnearly identical and very narrow, owing to the large sample size. The value of these intervals\nseems limited, given that there is some fluctuation in the s over time. But the point estimates\nclearly reveal the nature of each of the four classes.\nExamining the estimates from class 1 which we now call `non-users who disapprove of any\nuse', we see that this group is comprised of non-users who strongly disapprove of use of mar-\nLatent Class Logistic Regression 735\nprob.\nprob.\nprob.\nprob.\nYear\nYear\nYear\nYear\n(a)\n(b)\n(c)\n(d)\nFig. 3. Constrained and unconstrained estimates and 95% intervals for item response probabilities\n(-parameters) for Nxt12Mo in (a) class 1, (b) class 2, (c) class 3 and (d) class 4\nijuana. Although a small minority of them have tried marijuana at some point, they have not\ndone so recently, do not intend to do so and do not approve of it. Class 2 (`non-users who\napprove of experimentation') contains those who apparently do not use marijuana themselves\nbut tend to approve of others doing so on an experimental basis. Class 3 (`experimenters who\ndisapprove of occasional use') consists of individuals who use marijuana on occasion but do\nnot approve of occasional use. Members of class 4 (`regular users who approve of any use') are\nregular users who generally approve of use. Speaking broadly, classes 1 and 2 are non-users of\nmarijuana, whereas classes 3 and 4 are users. In terms of attitudes, however, classes 1 and 3 are\nthe most disapproving, and classes 2 and 4 are more approving.\n4.4. Historical trends in class prevalence\nAlthough this four-class model imposes constraints on the -parameters, the class prevalence\nrates freely vary by year. Estimated prevalences for the classes over time are plotted in Fig. 4.\nFig. 4(a) shows the prevalence for each class separately, and Fig. 4(b) shows the combined prev-\nalence for users (classes 3 and 4) and approvers (classes 2 and 4). From these plots, we see that\nthe use of marijuana declined steadily from 1980 to 1992 owing to very strong growth in class\n736 H. Chung, B. P. Flaherty and J. L. Schafer\nTable 2. Estimated item response probabilities (-parameters) and 95% confidence intervals of `1, any use'\nand `1, do not disapprove' from methods ML, DA and MI\nMethod Class Use of marijuana Attitudes towards marijuana\nas seen in the combined membership of classes 3 and 4, declined throughout the 1980s and rose\nthrough the early and mid-1990s. Interestingly, Fig. 4(b) shows that shifting trends in attitudes\nanticipated the trends in use by 2\u00ad3 years. Approval of use of marijuana began to rise after 1990,\n2 years before use itself began to rise; approval then levelled off after 1996, 3 years before use\nstopped rising. The most stable class in terms of rate of membership has been class 2 (non-users\nwho approve of experimentation), whereas the most vigorous fluctuations over time occurred\nin the behaviourally and attitudinally polarized groups (classes 1 and 4).\nThe estimates in Fig. 4 were generated from a model that includes the covariate vector xi\nfor each individual as described in Section 4.1. To obtain prevalence rates from a model with\ncovariates, we can recommend several approaches. One approach is to average the ML estimates\nof the subject-specific class probabilities over the sample,\n\u00af\nl|g =\nn\nn\nexp.xi\n^\nl|g\n/\nexp.xi\n^\nj|g\n/\n.\nIf the sample was obtained from an unequal probability design, then a weighted average over\nthe sample should be taken, with weights proportional to the inverse probabilities of selection.\n(Although MTF has an unequal probability design, its samples are quite representative of the\noverall population of high school seniors in the 48 contiguous states, and taking weighted rather\nthan unweighted averages over the sample had almost no discernible effect in any of our anal-\nyses.) When using MCMC sampling rather than ML, we would average the simulated values\nof l|g.xi/ over the sample at each cycle using the simulated values for l|g, and then average\nthese over the cycles of MCMC sampling. A third approach is to retain MIs of the latent class\nLatent Class Logistic Regression 737\nFig. 4. Estimated class prevalence by year\nvariables l1, . . . , ln for all subjects and to estimate the proportions directly from these. With a\nlarge sample, the differences between these methods tend to be negligible.\nOur four-class model estimates 30 regression coefficients for each of the 25 years. For brevity\nwe shall only summarize these results. Effects of gender on class membership were small, but\nthe effects of race were quite substantial. Across the years, the odds of membership in class 4\n(regular users who approve of any use) relative to class 1 (non-users who disapprove of any use)\nwere 2\u00ad4 times as high for non-whites relative to whites, controlling for the other covariates.\nThis confirms a well-known result that rates of use of marijuana among black youths tend to\nbe lower than among their white counterparts.\nLife style factors tended to be related to class membership in directions that we would expect.\nHigh school seniors who have better grades and less truancy and spend fewer evenings out for fun\neach week were less likely to use marijuana and to approve of use. Interestingly, these covariates\nare more strongly related to actual use than to attitudes. Fig. 5 shows the odds ratios comparing\nclass 1 (non-users who disapprove of any use) with each of the other classes for grades in school\nand number of evenings out. Neither of these covariates has much power to distinguish class 2\n738 H. Chung, B. P. Flaherty and J. L. Schafer\n(a)\n(c)\n(e)\n(b)\n(d)\n(f)\nFig. 5. Estimated odds ratios ( ) and 95% confidence intervals (-------) by year for grades and number\nof evenings out: (a) grades (class 2 versus class 1); (b) evenings out (class 2 versus class 1); (c) grades\n(class 3 versus class 1); (d) evenings out (class 3 versus class 1); (e) grades (class 4 versus class 1);\n(f) evenings out (class 4 versus class 1)\n(non-users who approve of experimentation) from class 1, but they consistently and significantly\ndistinguish class 3 (experimenters who disapprove of occasional use) and class 4 (regular users\nwho approve of any use) from class 1.\nReligiosity, in contrast, seems to correlate more strongly with attitudes than behaviour. Des-\nignating those who regard their religious beliefs as `very important' as the base-line, we created\ndummy indicators for those who responded `not important' and those who responded `impor-\ntant'. The odds ratios that are associated with these dummy indicators are plotted in Fig. 6.\nThose who responded not important or important rather than very important had dramatically\nhigher odds of falling into class 2 rather than into class 1, which are distinguished by attitudes\nLatent Class Logistic Regression 739\n(a)\n(b)\n(c)\n(d)\n(e)\n(f)\nFig. 6. Estimated odds ratios ( ) and 95% confidence intervals (-------) for religious importance (not\nimportant and important versus very important): (a) not important (class 2 versus class 1); (b) important (class\n2 versus class 1); (c) not important (class 3 versus class 1); (d) important (class 3 versus class 1); (e) not\nimportant (class 4 versus class 1); (f) important (class 4 versus class 1)\nbut not behaviour. The less religiously inclined groups also had dramatically higher odds of\nfalling into class 4 versus class 1, which reflects a difference in both attitudes and behaviour. But\nthe odds ratios comparing class 3 (experimenters who disapprove) with class 1 (non-users who\ndisapprove), although significantly different from 1.0, are not as large as the other odds ratios,\nsuggesting that religion has a smaller effect in discouraging the use of marijuana among those\nwho already disapprove of it.\nMany questions still remain about why marijuana use and attitudes have shifted over the\nyears. The -parameters of the LC regression model, which relate the probabilities of class\n740 H. Chung, B. P. Flaherty and J. L. Schafer\nClass 1 total very important\nprob.\nClass 2 total\nClass 3 total\nClass 4 total\nprob.\nprob.\nprob.\n(a)\n(b)\n(c)\n(d)\nimportant\nnot important\nvery important\nimportant\nnot important\nvery important\nimportant\nnot important\nvery important\nimportant\nnot important\nFig. 7. Joint prevalence of class and religious importance by year: (a) class 1; (b) class 2; (c) class 3;\n(d) class 4\nmembership to demographic, life style and belief factors, do not directly reveal how the com-\nposition of the classes themselves may have changed due to the influx or exodus of various\ntypes of individual. With MI, however, we can address these questions in a very straightfor-\nward manner. After imputing the unseen class variables l1, . . . ,ln for the sampled individuals,\nwe can divide each year's sample into classes and examine their composition with respect to any\ncovariate.\nTo illustrate, we imputed the latent variables 20 times. In each imputed data set, we sub-\ndivided each of the four classes by categories of each covariate, and then averaged the resulting\nproportions across the imputed data sets. The composition of each class with respect to the three\ncategories of religious belief is plotted in Fig. 7. In each of the four plots in Fig. 7, the total class\nprevalence (denoted by a full curve) reproduces the total prevalence that is shown in Fig. 4(a).\nEach full curve is also the sum of the three curves below it. These plots show that the prevalences\nof the highly religious (very important) and irreligious (not important) youth in each of the four\nclasses has been remarkably stable over the entire 25 years. The moderately religious (important)\nyouth, however, shows dramatic shifts that closely parallel the national trends, i.e. the national\ntrends have been largely driven by changes in attitude and behaviour among the moderately\nreligious. In one sense, this is not surprising, because the moderately religious are the largest of\nthe three groups. However, the relative intransigence of the not important and very important\nLatent Class Logistic Regression 741\nbelief groups suggests that efforts to influence their attitudes and behaviour towards marijuana\nmay prove to be less effective.\nWe examined plots that were similar to those in Fig. 7 for the other covariates and did not\nsee any dramatically different trends across the response categories. In general, for all other\ncovariates, the prevalences for each category of the covariate tended to rise and fall with the\noverall class prevalence.\n5. Discussion\nLC analysis has long been used by social scientists to summarize the joint distribution of atti-\ntudinal items and to identify population subgroups that might not be apparent in item-by-item\nanalyses (McCutcheon, 1987). Advances in computing power and new computational algo-\nrithms now allow us to fit richer models to larger data sets. Traditional applications of LC\nmodels focused on identifying and validating the latent structure. With LC regression, we can\nnow relate a latent structure to large numbers of covariates at once.\nBecause ML routines for LC regression are available in two software packages (Latent GOLD\nand Mplus), we expect the popularity of these models to grow. Properties of the likelihood have\nalsobeenexploredtoalimitedextent.Forexample,identifiabilityconditionshavebeendescribed\nby Bandeen-Roche et al. (1997). Because we are accustomed to thinking of ML as the default\nmethod, it is tempting to believe that reliable inferences for LC models are simply not possible\nwith the usual way when the shape of the likelihood is abnormal (e.g. when estimates lie on a\nboundary). We have found, however, that Bayesian inference by MCMC sampling is an attrac-\ntive alternative to ML. Simulations by Chung (2003) have shown that Bayesian methods usually\nperform as well as or better than ML by the traditional frequentist criteria of bias, variance,\ninterval coverage and width. MI can be used in tandem with Bayesian methods to perform many\ninnovative analyses that would be difficult if we limited ourselves simply to averaging simulated\nparameters over the MCMC output stream.\nIn our analyses of MTF, we could identify a plausible latent structure from survey items that\nare related to both attitudes and behaviours. Supporting evidence for this latent structure was\nprovided not only by quantitative measures (e.g. fit statistics) but also by its interpretability\nand relative stability over a long period of time. This will not always be so. For example, MTF\nhas several items that measure the perceived risks of use of marijuana. When we applied LC\nanalyses to the perceived risk and use items, we could not identify a plausible latent structure\nthat fitted well over a long period of time.\nReferences\nAitkin, M. and Rubin, D. B. (1985) Estimation and hypothesis testing in finite mixture models. J. R. Statist. Soc.\nBachman, J. G., Johnston, L. D. and O'Malley, P. M. (1998) Explaining recent increases in students' marijuana\nBandeen-Roche, K., Miglioretti, D. L., Zeger, S. L. and Rathouz, P. J. (1997) Latent variable regression for\nBentler, P. M. and Bonett, D. G. (1980) Significance tests and goodness of fit in the analysis of covariance struc-\nBest, N., Cowles, M. and Vines, S. (1995) Coda: convergence diagnostics and output analysis software for gibbs\nsampler output, version 0.3. Technical Report. Medical Research Council Biostatistics Unit, Cambridge.\nBiemer, P. P. and Wiesen, C. (2002) Measurement error evaluation of self-reported drug use: a latent class analysis\nof the US National Household Survey on Drug Abuse. J. R. Statist. Soc. A, 165, 97\u00ad119.\nChung, H. (2003) Latent-class modeling with covariates. PhD Thesis. Pennsylvania State University, University\nPark.\n742 H. Chung, B. P. Flaherty and J. L. Schafer\nChung, H., Loken, E. and Schafer, J. L. (2004) Difficulties in drawing inferences with finite-mixture models:\nClogg, C. C. and Goodman, L. A. (1984) Latent structure analysis of a set of multidimensional contingency tables.\nClogg, C. C., Rubin, D. B., Schenker, N., Schultz, B. and Weidman, L. (1991) Multiple imputation of industry\nand occupation codes in census public-use samples using bayesian logistic regression. J. Am. Statist. Ass., 86,\nCollins, L. M. (2002) Using latent transition analysis to examine the gateway hypothesis. In Stages and Pathways of\nDrug Involvement: Examining the Gateway Hypothesis (ed. D. B. Kandel), pp. 254\u00ad269. Cambridge: Cambridge\nUniversity Press.\nDayton, C. M. and Macready, G. B. (1988) Concomitant-variable latent-class models. J. Am. Statist. Ass., 83,\nFlaherty, B. P. (2002) Assessing the reliability of categorical substance use measures with latent class analysis.\nFlay, B. R. (1993) Youth tobacco use: risks, patterns, and control. In Nicotine Addiction (eds C. Orleans and\nGarrett, E. S., Eaton, W. W. and Zeger, S. L. (2002) Methods for evaluating the performance of diagnostic tests\nGelfand, A. E. and Smith, A. F. M. (1990) Sampling-based approaches to calculating marginal densities. J. Am.\nGelman, A., Carlin, J. B., Stern, H. S. and Rubin, D. B. (2004) Bayesian Data Analysis, 2nd edn. London: Chapman\nand Hall.\nGelman, A. and Rubin, D. B. (1992) Inference from iterative simulation using multiple sequences. Statist. Sci., 7,\nGeweke, J. (1992) Evaluating the accuracy of sampling-based approaches to calculating posterior moments. In\nBayesian Statistics 4 (eds J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith), pp. 169\u00ad193. Oxford:\nOxford University Press.\nGoodman, L. A. (1974) Exploratory latent structure analysis using both identifiable and unidentifiable models.\nGraham, J. W., Collins, L. M., Wugalter, S. E., Chung, N. K. and Hansen, W. B. (1991) Modeling transitions in\nlatent-sequential processes: a substance use prevention example. J. Consltng Clin. Psychol., 59, 48\u00ad57.\nHoerl, A. E. and Kennard, R. W. (1970) Ridge regression: biased estimation for nonorthogonal problems. Techno-\nHoijtink, H. (1998) Constrained latent class analysis using the gibbs sampler and posterior predictive p-values:\nJohnston, L. D. (1982) A Review and Analysis of Recent Changes in Marijuana Use by American Young People,\nMarijuana: the National Impact on Education. New York: American Council on Marijuana.\nJohnston, L. D. (1985) The etiology and prevention of substance use: what can we learn from recent historical\nchanges? In Etiology of Drug Abuse: Implications for Prevention (eds C. L. Johnes and R. J. Battes). Washington\nDC: US Government Printing Office.\nJohnston, L. D., Bachman, J. G. and O'Malley, P. M. (2001) Monitoring the Future: a Continuing Study of American\nYouth (12th-grade Survey) 2000. Ann Arbor: Interuniversity Consortium for Political and Social Research.\nJohnston, L. D., O'Malley, P. M. and Bachman, J. G. (2002) Monitoring the Future National Survey Results on\nDrug Use, 1975\u00ad2001, vol. I, Secondary School Students. Bethesda: National Institute on Drug Abuse.\nJustel, A. and Pe\u00f1a, D. (1996) Gibbs sampling will fail in outlier problems with strong masking. J. Computnl\nKennedy, W. J. and Gentle, J. E. (1980) Statistical Computing. New York: Dekker.\nLanza, S. T. and Collins, L. M. (2002) Pubertal timing and the onset of substance use in females during early\nLanza, S. T., Collins, L. M., Schafer, J. L. and Flaherty, B. P. (2005) Using data augmentation to obtain standard\nerrors and conduct hypothesis tests in latent class and latent transition analysis. Psychol. Meth., 10, 84\u00ad100.\nLazarsfeld, P. F. and Henry, N. W. (1968) Latent Structure Analysis. Boston: Houghton Mifflin.\nLeventhal, H. and Cleary, P. D. (1980) The smoking problem: a review of the research and theory in behavioral\nLindsay, B. G. (1995) Mixture Models: Theory, Geometry and Applications. Hayward: Institute of Mathematical\nStatistics.\nLittle, R. J. A. and Rubin, D. B. (2002) Statistical Analysis with Missing Data, 2nd edn. New York: Wiley.\nLo, Y., Mendell, N. R. and Rubin, D. B. (2001) Testing the number of components in a normal mixture. Biometrika,\nMayhew, K. P., Flay, B. R. and Mott, J. A. (2000) Stages in the development of adolescent smoking. Drug Alc.\nMcCutcheon, A. L. (1987) Sexual morality, pro-life values, and attitudes toward abortion: a simultaneous latent\nLatent Class Logistic Regression 743\nMetropolis, M., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. and Teller, E. (1953) Equations of state\nMuth\u00e9n, L. K. and Muth\u00e9n, B. O. (1998) Mplus User's Guide. Los Angeles: Muth\u00e9n and Muth\u00e9n.\nPfeffermann, D., Skinner, C. and Humphreys, K. (1998) The estimation of gross flows in the presence of mea-\nsurement error using auxiliary variables. J. R. Statist. Soc. A, 161, 13\u00ad32.\nRichardson, S. and Green, P. J. (1997) On Bayesian analysis of mixtures with an unknown number of components\nRobert, C. P. and Casella, G. (2004) Monte Carlo Statistical Methods, 2nd edn. New York: Springer.\nRoberts, G. O. (1992) Convergence diagnostics of the gibbs sampler. In Bayesian Statistics 4 (eds J. M. Bernardo,\nJ. O. Berger, A. P. Dawid and A. F. M. Smith), pp. 775\u00ad782. Oxford: Oxford University Press.\nRobins, J. M., Rotnitzky, A. and Zhao, L. P. (1994) Estimation of regression coefficients when some regressors\nRubin, D. B. (1987) Multiple Imputation for Nonresponse in Surveys. New York: Wiley.\nRubin, D. B. and Stern, H. S. (1994) Testing in latent class models using a posterior predictive check distribu-\ntion. In Latent Variables Analysis: Applications for Developmental Research (eds A. von Eye and C. C. Clogg),\nSchafer, J. L. (1997) Analysis of Incomplete Multivariate Data. London: Chapman and Hall.\nShiffman, S., Kassel, J. D., Paty, J. A. and Gnys, M. (1994) Smoking typology profiles of chippers and regular\nTanner, W. A. and Wong, W. H. (1987) The calculation of posterior distributions by data augmentation. J. Am.\nTierney, L. (1994) Markov chains for exploring posterior distributions (with discussion). Ann. Statist., 22, 1701\u00ad\nVermunt, J. K. and Magidson, J. (2000) Latent GOLD User's Guide. Statistical Innovations."
}