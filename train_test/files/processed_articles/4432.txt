{
    "abstract": "Abstract\nAccording to Recognition-By-Components theory, object recognition relies on a specific subset of\nthree-dimensional shapes called geons. In particular, these configurations constitute a powerful cue\nto three-dimensional object reconstruction because their two-dimensional projection remains\nviewpoint-invariant. While a large body of literature has demonstrated sensitivity to changes in\nthese so-called nonaccidental configurations, it remains unclear what information is used in\nestablishing such sensitivity. In this study, we explored the possibility that nonaccidental\nconfigurations can already be inferred from the basic constituents of objects, namely, their\nedges. We constructed a set of stimuli composed of two lines corresponding to various\nnonaccidental properties and configurations underlying the distinction between geons, including\ncollinearity, alignment, curvature of contours, curvature of configuration axis, expansion,\ncotermination, and junction type. Using a simple visual search paradigm, we demonstrated that\nparticipants were faster at detecting targets that differed from distractors in a nonaccidental\nproperty than in a metric property. We also found that only some but not all of the observed\nsensitivity could have resulted from simple low-level properties of our stimuli. Given that such\nsensitivity emerged from a configuration of only two lines, our results support the view that\nnonaccidental configurations could be encoded throughout the visual processing hierarchy even\nin the absence of object context.\n",
    "reduced_content": "Article\nSensitivity to Nonaccidental\nConfigurations of\nTwo-Line Stimuli\nJonas Kubilius, Charlotte Sleurs and Johan Wagemans\nBrain & Cognition, KU Leuven, Belgium\n Keywords\nPerceptual organization, nonaccidental properties, configural processing, geons\nIntroduction\nWhich principal factors lead to an efficient organization of a visual scene into objects and\nbackgrounds? Since the early days of experimental psychology, Gestalt grouping laws, such\nas proximity, similarity, and good continuation, have offered a powerful means to\nunderstand and predict the structure of our percepts (Wagemans, Elder, et al., 2012;\nWagemans, Feldman, et al., 2012; Wertheimer, 1923). Based on these grouping principles,\nCorresponding author:\nEmail: jonas.kubilius@kuleuven.be\ni-Perception\njournals.sagepub.com/home/ipe\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sage-\npub.com/en-us/nam/open-access-at-sage).\nseparate elements and parts in an image can be grouped together into larger clusters or\ncoherent wholes in the presence of clutter or noise.\nGestalt grouping principles are not the only basis to perceive structure in a scene though.\nFor example, observing that two elements are parallel is important because this relationship\nremains constant from nearly any viewpoint. If the goal is to perceive the three-dimensional\n(3D) structure of an object or to recognize its identity, such viewpoint-independent\nrelations can be very informative. Although it remains true that an image can result\nfrom infinitely many different 3D scenes, to find a particular type of regularity in the\nimage for non-corresponding regularities in the world would be quite accidental. Indeed, it\nusually only happens with one specific viewpoint. Under the assumption of a generic\nviewpoint, therefore, these image regularities usually signal corresponding scene\nregularities. For this reason, these image regularities are called nonaccidental properties\n(Lowe, 1985). Examples of nonaccidental properties (NAPs) include curvilinearity,\ncollinearity, cotermination, parallelism, and skew-symmetry. In contrast, observing that\nthe two parts intersect at a particular angle is much less informative since the projected\nangle on the retina is viewpoint-dependent (e.g., Willems & Wagemans, 2000).\nAccording to the Recognition-By-Components (RBC) theory (Biederman, 1987), these\nNAPs play an essential role in quickly deriving the essential building blocks of objects and\ninterpreting our surroundings in terms of objects. In particular, Biederman proposed that\nobject recognition relies on a small set of 3D geometric primitives called geons that are\nderived from nonaccidental edge configurations. For example, a brick and a pyramid differ\nin the parallelism of the edges and are thus rarely confused in their 2D projection to the eye,\ndespite changes in viewpoint. Conversely, a brick and a cube do not differ in terms of\nnonaccidental features and thus cannot always be distinguished solely based on their 2D\nprojections.\nBiederman and colleagues have accumulated an impressive body of evidence that the\nprimate visual system indeed is sensitive to NAPs. For example, Kayaert, Biederman, and\nVogels (2003) compared neural responses in the monkey inferotemporal cortex by presenting\nstimuli differing from a base stimulus (e.g., a pyramid) either in a NAP (resulting in a brick)\nor a metric property (MP) equally distant from the base stimulus (resulting in a shallower\npyramid). They found that neurons responded more vigorously to objects that differed in\nNAPs than when they differed in MPs. Similarly, by measuring accuracy in a match-\nto-sample task, Amir, Biederman, and Hayworth (2012) found that participants were more\nsensitive behaviorally to both 2D and 3D geons differing in a wide range of NAPs (see also\nTodd et al., 2014). This sensitivity to NAPs appears to be a very general property of the visual\nsystem, observed in infants (Kayaert & Wagemans, 2010), children (Amir, Biederman,\nHerald, Shah, & Mintz, 2014; Ons & Wagemans, 2011), non-urban cultures (Biederman,\nYue, & Davidoff, 2009), and non-mammalian species (Gibson, Lazareva, Gosselin, Schyns,\n& Wasserman, 2007; Lazareva, Wasserman, & Biederman, 2008; Peissig, Young, Wasserman,\n& Biederman, 2000). Neural measurements in monkeys pointed to the inferotemporal cortex as\na possible locus of such sensitivity (Kayaert et al., 2003; Kayaert, Biederman, Op de Beeck, &\nVogels, 2005; Vogels, Biederman, Bar, & Lorincz, 2001) and more recently the shape-selective\nlateral occipital cortex (LOC) in humans has also been shown to respond to changes in NAPs\n(Amir, Biederman, & Hayworth, 2011; Kim & Biederman, 2012). Finally, NAPs have also been\nclaimed to play an important role in scene recognition. Walther and Shen (2014) and Choo and\nWalther (2016) showed that at least some NAPs, namely, junctions and junction angles, might\nalso underlie scene categorization by humans.\nHere we demonstrate that sensitivity to NAPs holds even in the absence of object or shape\ncontext. We constructed a set of stimuli composed of two line segments only, corresponding\n2 i-Perception\nto the nonaccidental configurations in the original geons. Even in these simple displays we\nfound a pronounced sensitivity to NAPs, indicating that the computation of nonaccidental\nproperties is not exclusive to object processing and instead reflects generic image processing\nmechanisms in the visual system.\nMethods\nParticipants\nTen students from KU Leuven participated in the experiment (age: 21\u00ad23; males: 3,\nfemales: 7) and were paid E8 for their participation. Ten additional students from KU\nparticipated in a replication of this experiment and received course credit for their\nparticipation. All participants had normal or corrected-to-normal vision and provided a\nwritten informed consent. The experiments were approved by the ethical committee of the\nFaculty of Psychology and Educational Sciences.\nStimuli\nOur aim was to investigate whether the visual system was sensitive to nonaccidental\nconfigurations even when no object context was provided. We therefore translated geons\nand configurations of geons used in various experiments by Biederman and his colleagues\ninto stimuli composed of two line segments only (Figure 1; Amir et al., 2012; Kim &\n(1) NAPs between objects:\n(a) Alignment: whether objects are aligned or not.\n(b) Collinearity: whether objects are on the same line or not.\n(c) Junction type: the kind of junction that two objects are forming:\n(i) Generic to L\n(ii) Generic to T\nFigure 1. An example how geons were translated into two-line stimuli.\nKubilius et al. 3\n(iii) Generic to X\n(iv) T to L\n(v) X to T\n(2) NAPs within objects:\n(a) Cotermination: whether edges of an object are coterminating or not.\n(b) Expansion vs. constant: whether edges of an object are at a constant distance or\nexpanding\n(c) Collinearity: whether edges of an object are collinear or not\n(d) Curvature:\n(i) Edges: whether edges of an object are straight or curved\n(ii) Axes: whether object's axis is straight or curved\nWe also had an additional condition where the stimulus consisted of a single line segment\nand its curvature was manipulated. This condition served as a control for the two curvature\nconditions where participants could discriminate between the variants not based on the\nnonaccidental configuration but the curvature alone.\nNote that not all NAPs defining geons could be translated to two-line configurations, such\nas a straight versus a curved cross section (Dickinson & Biederman, 2014). Moreover, it is not\nexactly clear whether the junction configurations truly correspond to nonaccidental\nconfigurations. However, we included them for completeness, since occlusion was\nconsidered a nonaccidental property in Kim and Biederman (2012). Furthermore, it is\nFigure 2. Examples of stimuli for each of 13 conditions in the experiment. In each triplet, the middle\nstimulus is the base stimulus, the one on the left is its metric variant (MP), and the one on the right is the\nnonaccidental variant (NAP). Note that in the actual experiment we had many more exemplars for each\ncondition (78 triplets in total), constructed by mirroring the shown stimuli upside-down or left-right.\n4 i-Perception\npossible that observers treat these junction stimuli not as two separate objects but rather as\none, and thus, the nonaccidental relation holds in this two-dimensional context.\nFor each stimulus, which we refer to as the base stimulus, two variants were created. The\nnonaccidental variant featured a very similar configuration that differed from the base in\nterms of a single nonaccidental property. In contrast, the metric variant had the same\nconfiguration as the base but differed to the same extent as the nonaccidental variant but\nin the opposite direction such that there was no change in nonaccidental properties.\nSetup\npsychopy_ext (Kubilius, 2014), pandas, and statsmodels packages (source code available at\nhttps://bitbucket.org/qbilius/twolines).\nA trial was initiated by a key press. The participants saw a central fixation spot for 300 ms,\nfollowed by the onset of four stimuli, presented in the four quadrants of the display (Figure 3),\nmodeled after Pomerantz, Sager, and Stoever (1977). Three of these stimuli were identical,\nwhile the remaining one (the target) was different, and participants were instructed to indicate\nvia a key press as quickly and as accurately as possible which one of the four quadrants\ncontained the target stimulus. The target was either the metric or the nonaccidental variant,\nand the three distractors were then the base stimuli, or the target was the base stimulus and the\ndistractors were either three identical metric or nonaccidental variants. All possible\ncombinations were tested only once, resulting in 1,248 trials in total, 78 (stimuli types) \u00c2 2\n(metric vs. nonaccidental variant) \u00c2 2 (target vs. distractor)\u00c2 4 (target positions).\nThe stimuli subtended 3 in visual angle and were presented 5 away from the central\nfixation spot. The gap between the centers of the two line segments was approximately 1.5.\nFigure 3. Experimental design. At each trial, participants were presented with four stimuli and had to\nindicate which one was different. In half of the trials, the odd stimulus differed from the rest in a nonaccidental\nchange of configuration. In the other half, the odd stimulus was identical to the other stimuli in terms of its\nnonaccidental properties but differed in some metric property (e.g., angle) to the same amount as its\nnonaccidental counterpart. Note that in the actual experiment the stimuli were white and were presented on\na gray background.\nKubilius et al. 5\nTo make the task more challenging and avoid symmetry effects common in Pomerantz et al.\n(1977) displays, in each trial random jitter was added to the position (within \u00c6 .25) and\norientation (within \u00c6 5) of each stimulus independently. Trials were presented in a\nrandom order (conditions were interleaved). The experiment lasted approximately an hour.\nResults\nTo investigate the effects of NAPs, we computed mean reaction time per stimulus condition\n(Figure 4). Note that typically reaction time measures are not distributed normally and thus\ncomputing mean reaction times per participant might lead to a poor estimate of the true\nreaction time. After a graphical inspection that normality was indeed violated, we computed\nthe median reaction time per participant, which was used to compare reaction times to the\nnonaccidental and metric variants across participants. Bonferroni correction was applied to\naccount for multiple testing.\nFigure 4. (a) Average response times per condition (blue) and average error rate (gray). Error bars denote\nthe standard errors of the mean across participants (n \u00bc 10). *denotes p-value significant at a-level .05 for\nreaction times, **denotes p-value significant at a-level .01, ***denotes p-value significant at a-level .001 (after\nthe Bonferroni correction). (b) Cosine similarity of metric and nonaccidental stimuli to the base stimulus as\nmeasured by GaborJet model outputs. Error bars denote the standard errors for the mean across stimuli of\nthe same kind. Significance levels are indicated as in panel (a).\n6 i-Perception\nWe found that in almost all conditions, participants detected nonaccidental variants faster\nthan their metric counterparts (Figure 4(a) and Table 1). The only condition that did not\nexhibit a statistically reliable effect was the expansion versus constant condition (t(9) \u00bc 1.82,\np \u00bc .051). We reasoned that the two line segments might have appeared so close together in\nthe metric variant that participants perceived them as coterminating, which is an undesirable\nnonaccidental change. To test if this was the case, we tested 10 additional participants to\nperform the task again but this time with a slightly larger gap between the two lines (2.25).\nMoreover, to maximize the chances of finding any difference, we presented each condition in\na separate block, so that participants would try just as hard for easy as for hard conditions. In\nthis experiment, we found that all conditions nonaccidental changes were detected reliably\nfaster that metric. (It should be noted however that the generic to T condition resulted in\np \u00bc .005, which does not survive our strict Bonferroni correction criterion.)\nSimilar, albeit weaker, trends were found when accuracy was analyzed (Figure 4(a), gray\nbars). Since accuracy differences were likely influenced by ceiling effects (on average,\nparticipants reached 90% on metric changes and 97% on the nonaccidental ones), we did\nnot analyze these effects any further.\nWe further asked if the observed effects for curvature in conditions curvature edge and\ncurvature axis conditions were due to configural sensitivity per se or resulted solely from\nparticipants' sensitivity to curvature in a single line (curvature control condition). To address\nthis question, we performed a repeated-measures analysis of variance. We found no\nsignificant difference in the effect of distance (NAP vs. MP) between curvature edge and\ncurvature control conditions (F(1,9) \u00bc .124, p \u00bc .727). In contrast, the effect of distance\n(NAP vs. MP) was significantly stronger between curvature axis and curvature control\nconditions (F(1,9) \u00bc 11.66, p \u00bc .002). These observations held in the replicated data as well,\nTherefore, participants could have relied on judging the curvature of single line in the\ncurvature edge condition, but not in the curvature axis condition where the configural\ninformation between the two lines disproportionately influenced participants' decisions.\nFinally, we asked if this pattern of results could be due to some low-level differences\nbetween stimuli that are not related to nonaccidentalness per se? Although we\nparametrically matched the distances of metric and nonaccidental variants from the base,\nTable 1. A Related-Samples One-Tailed t Test Results for Each Condition.\nCondition t(9) p\nKubilius et al. 7\nit is still possible that a difference exists when the actual images of stimuli are processed by\nsimple Gabor filters found in the visual area V1. Thus, if nonaccidental variants are found to\nbe less similar to the base stimulus than the metric variant is to the base stimulus, any\ndifference observed behaviorally could potentially result from the confounding low-level\ndifferences in stimuli. In contrast, if no difference is found, any behavior difference is more\nlikely to stem from features computed later on in the visual system.\nWe therefore quantified the difference between the nonaccidental and metric variants using\nthe GaborJet model (Lades et al., 1993), a common approach used by Biederman and\ncolleagues to equate metric and nonaccidental variants. In a nutshell, this model computes\nV1-like features of each stimulus and a similarity is estimated using the one minus the cosine\ndifference between these feature vectors, as described by Lades et al. (1993).\nFor our stimulus set, we found that all but one stimulus were properly matched or the\nsimilarity between the nonaccidental and the base stimulus was even larger than between the\nmetric and the base one (Figure 4(b)). We also found that the Pearson correlation between\nthis model and human reaction times (using nonaccidental minus metric) across all 78\nstimulus triplets was only about \u00c0.14 (two-tailed p \u00bc .23). Overall, it is unlikely that the\nbehaviorally observed differences resulted from simple low-level differences in stimuli.\nDiscussion\nTaken together, we demonstrated that the participants were sensitive to various\nnonaccidental configurations, even in the absence of object information. Unlike previous\nstudies, here we showed that the visual system is sensitive to even the most basic form of\nnonaccidental configurations, composed of merely two lines. While some of these\nconfigurations might result from confounding changes in nonaccidental configurations\n(curvature edges, between-object collinearity), overall we found that the visual system is\nsensitive to even the most basic form of nonaccidental configurations, composed of merely\ntwo lines. These results are consistent with earlier theoretical, behavioral, and neural studies\nthat reported sensitivity to the regularity in configurations of two-line stimuli (Feldman,\nBased on these findings, it is possible that the encoding of configural information occurs as\na default computation during the visual information processing. More specifically,\nnonaccidental relations between primitive shape features, such as edges, angles, and\ncurves, might already be detected early on and communicated to the next processing stages\neven prior to object-centered visual processing and even in the absence of object recognition\ntasks. Notice that this suggestion reveals a broader range of configural information encoding\nthan proposed by earlier studies where only angles and curved segments have been shown to\nbe encoded (Ito & Komatsu, 2004; Pasupathy & Connor, 1999). It is worth mentioning\nhowever that to some extent our results could also be interpreted as reflecting not just any\nnonaccidental changes but rather changes in symmetry. Consistent with this view, higher\nvisual areas have shown sensitivity to symmetry (Bertamini & Makin, 2014).\nHow early could these configurations be computed? Our GaborJet simulations that try to\ncapture the basic processing in the visual area V1 imply that it is not likely to be the source of\nthis computation. Instead, we suggest that truly configural processing might be required\nwhere the outputs of different kinds of simple cells (e.g., selective for different orientations\nor spatial frequencies) are combined. This idea is consistent recent demonstrations that\nprimate visual area V2 computes summary statistics of edge-based responses (Freeman &\nSimoncelli, 2011; Freeman, Ziemba, Heeger, Simoncelli, & Movshon, 2013). Such summary\nstatistics might be sufficient to reflect differences between metric and nonaccidental property\n8 i-Perception\n(see also Kubilius, Wagemans, & Op de Beeck, 2014b, for a broader discussion of summary\nstatistics computations in the visual cortex). Future studies could explore this possibility\nin depth.\nOn the other hand, in a similar two-line stimuli setup, Kubilius et al. (2014a) only observed\nsensitivity to these configurations in human lateral occipical cortex (LOC) but not earlier.\nGiven that previous studies using three-dimensional geons consistently reported LOC or\nmonkey IT (Kayaert et al., 2003) being sensitive to geon properties, our results indicate a\npossibility that LOC computes configural information between edges in addition to\ncomparing full surface-based representations or matching to geon templates.\nFinally, our findings are consistent with recent computer vision studies that demonstrated\nthat a robust sensitivity to NAPs can emerge even without training explicitly for\nnonaccidental feature processing. Parker, Reichert, and Serre (2015) showed that a\nhierarchical model HMAX enhanced with a temporal continuity rule also develops a\nsensitivity to NAPs by merely observing videos of slowly rotating objects. A similar\nsensitivity is also present in deep convolutional neural networks that are optimized for\nobject recognition and that are currently our best models of visual processing in the\nprimate visual system (Kubilius, Bracci, & Op de Beeck, 2016; Rajalingham et al., 2015;\nYamins et al., 2014). These computational studies indicate that the sensitivity to NAPs\nmight not even rely on any explicit coding of nonaccidental properties but instead emerge\nas a result of the system absorbing statistical regularities from its visual inputs.\n"
}