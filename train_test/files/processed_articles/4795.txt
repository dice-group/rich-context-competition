{
    "abstract": "Abstract\nThe speed and ease with which we recognize the faces of our friends and family members belies\nthe difficulty we have recognizing less familiar individuals. Nonetheless, overconfidence in our\nability to recognize faces has carried over into various aspects of our legal system; for instance,\neyewitness identification serves a critical role in criminal proceedings. For this reason,\nunderstanding the perceptual and psychological processes that underlie false identification is of\nthe utmost importance. Gaze direction is a salient social signal and direct eye contact, in particular,\nis thought to capture attention. Here, we tested the hypothesis that differences in gaze direction\nmay influence difficult decisions in a lineup context. In a series of experiments, we show that when\na group of faces differed in their gaze direction, the faces that were making eye contact with the\nparticipants were more likely to be misidentified. Interestingly, this bias disappeared when the faces\nare presented with their eyes closed. These findings open a critical conversation between social\nneuroscience and forensic psychology, and imply that direct eye contact may (wrongly) increase\nthe perceived familiarity of a face.\n",
    "reduced_content": "Article\nWho is the Usual Suspect?\nEvidence of a Selection Bias\nToward Faces That Make\nDirect Eye Contact in a\nLineup Task\nJessica Taubert\nThe School of Psychology, The University of Sydney, Sydney, Australia;\nThe National Institute of Mental Health (NIMH), MD, USA\nCeline van Golde\nThe School of Psychology, The University of Sydney, Sydney, Australia\nFrans A. J. Verstraten\nThe School of Psychology, The University of Sydney, Sydney, Australia;\nHelmholtz Institute, Utrecht University, Utrecht, The Netherlands\n Keywords\nmisidentification, face perception, legal procedures, eye gaze direction, eyewitness identification,\napplied visual science\nCorresponding author:\nJessica Taubert, The School of Psychology, The University of Sydney, Sydney, New South Wales 2006, Australia.\nEmail: jesstaubert@gmail.com\ni-Perception\njournals.sagepub.com/home/ipe\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sage-\npub.com/en-us/nam/open-access-at-sage).\nIntroduction\nFace perception is the most reliable means of accessing a person's identity without the use of\nautomated technology, such as iris or fingerprint scans. Yet, there are large individual\ndifferences in our ability to recognize faces (Bowles et al., 2009; Russell, Duchaine, &\nNakayama, 2009) and particular difficulties are associated unfamiliar faces (Hancock,\nBruce, & Burton, 2000). For instance, when Bruce et al. (1999) asked participants to select\na target face from an array of 10, in a classic lineup paradigm, they were only able to perform\naccurately in 70% of trials, despite optimal viewing conditions. Moreover, in that particular\nstudy, the photographs and video frames used were taken on the same day, enabling the use\nof identity cues from external features, such as hairstyle (Bruce et al., 1999). More recently,\nMegreya, Sanford, and Burton (2013) reported that, when photographs were taken months\napart, recognition accuracy suffered even more.\nHowever, despite the overwhelming evidence indicating how difficult unfamiliar face\net al., 2013), person-to-ID matching is commonly used to protect citizens against identity\ntheft and to investigate crime. Kemp, Towell, and Pike (1997) investigated fraud detection\namong a group of experienced supermarket cashiers tasked with matching a customer's face\nwith a picture printed on a credit card. The authors reported that in instances where the\nidentities did not match but the photograph resembled the card bearer, cashiers only correctly\nrejected the identities in 36% of trials, leading to an overall error rate of over 60%. Even in\neasier trials, where the card bearer did not resemble the photograph, the error rate remained\nover 30%. This error rate occurred despite the fact that the cashiers were aware of the study's\nobjectives and were presumably motivated to perform well (Kemp et al., 1997). Turning to\nforensic settings such as border control, successfully matching a real person to a photograph\nis often a matter of national security. However, White, Kemp, Jenkins, Matheson, and\nBurton (2014) have showed that even trained passport control officers are not better at\nmatching identities than university students. In summary, evidence suggests that, even\nwhen the stakes are high and people acquire a tremendous amount of practice, unfamiliar\nface recognition is a painfully difficult task.\nPresent Study\nWe are interested in uncovering the signals people might be relying on to select a face in a\nlineup, other than actual recognition. Eye gaze direction is thought to be a major\nsociocommunicative signal among social primates (Langton, Watt, & Bruce, 2000;\nanother person looking directly at you is likely to indicate that their attention is directed\nat you, while averted gaze implies that the other person's attention is directed toward\nsomething else (Kuhn & Benson, 2007; Kuhn & Kingstone, 2009; Ricciardelli, Bricolo,\nAglioti, & Chelazzi, 2002). Allocating visual attention to direct eye gaze seems to be the\nbasis for social interaction (Baron-Cohen, 1995; Tomasello & Carpenter, 2007; Tomasello,\nCarpenter, Call, Behne, & Moll, 2005), and a failure to do so is a symptom of severe social\ndisorders such as Autism (Emery, 2000; Klin, Lin, Gorrindo, Ramsay, & Jones, 2009;\nTanaka & Sung, 2016). In regard to person recognition, the direction of a target's eyes has\nbeen shown to enhance or influence memory for faces in old or new decision-making tasks in\nboth adults and children (Adams, Pauker, & Weisbuch, 2010; Farroni, Massaccesi, Menon,\nVuilleumier, George, Lister, Armony, & Driver, 2005). Interestingly, from a neuroscience\nperspective, changes in eye gaze and direct eye contact are particularly\n2 i-Perception\nprovocative--modulating activity in visual system (Madipakkam, Rothkirch, Guggenmos,\nHeinz, & Sterzer, 2015; Mosher, Zimmerman, & Gothard, 2014; Pelphrey, Morris, Michelich,\nMichel, Henaff, & Decety, 1998). Collectively, these studies indicate that we are sensitive to\ngaze direction, and particularly to direct eye contact, but what information does direct eye\ngaze convey?\nThe idea that direct eye contact might signal more to a receiver than the direction of that\nperson's attention has, so far, only been explored in studies that have examined lie detection,\nwhich have yielded inconsistent results (Vrij, Granhag, & Porter, 2010; Vrij & Semin, 1996).\nIn this article, however, we have married this idea with the emerging evidence that unfamiliar\nface recognition in applied settings is an alarmingly difficult task. Our hypothesis that gaze\ndirection might interfere with face recognition in a lineup task was based on three findings:\n(1) people find it difficult to recognize faces in a lineup (Bruce et al., 1999; Hancock et al.,\nand, thus, might rely on superfluous information to make their judgment such as gaze\ndirection.\n(2) People automatically process gaze direction without awareness and irrespective of the\nand\n(3) direct eye gaze has been shown to enhance recognition memory for faces in old or new\net al., 2006; Vuilleumier et al., 2005); however, it is unknown how this will affect\nrecognition within a lineup setting.\nExperiment 1\nIn Experiment 1, participants were required to watch a brief movie of a person talking\nwithout the benefit of sound and then determine whether that same person was present in\na lineup of four people. For half the trials, the target was present and we manipulated the\ngaze of these targets in four unique conditions (direct gaze, left gaze, right gaze, and upward\ngaze) with the expectation that performance in target present trials would be better in the\ndirect gaze condition. Participants could also make two different kinds of errors, they could\nfalsely reject a target present trial or they could misidentify a distractor. The number of\nmisidentification errors that occurred for each distractor type (direct gaze; left gaze; right\ngaze or upward gaze) was also analyzed to determine whether there was a systematic bias\ntoward faces making direct eye contact.\nMethod\nParticipants. All participants were psychology undergraduate students from The University of\nSydney. In Experiment 1, we recruited 27 participants in total (12 male; aged between 22 and\n34 years of age). The first three participants tested (all female) were given a different set of\ninstructions from the remaining 24 participants, as part of an initial pilot. Instead of testing\ntheir recognition memory, their responses were used to confirm that the direct gaze stimuli\nwere the faces perceived as looking directly at them. A power analysis based on a pilot study\nsuggested 16 participants would be sufficient to find evidence of an effect among four target\ntypes. We collected eight additional participants because the power analysis was based on\nTaubert et al. 3\naccuracy in target present trials and one of our hypotheses referred specifically to an increase\nin the misidentification error rate (i.e., we wanted to measure variance in the false positive\nrate across four distractor types). Participants gave their written consent prior to completing\nthe experiment. All participants reported normal or corrected-to-normal vision and were\nnai\u00a8ve as to the purpose of the study. The research protocol was approved by the Human\nResearch Ethics Committee of the University of Sydney (Project No. 2015/336).\nStimuli and procedure. The stimuli for all three experiments reported here were makeup\ntutorials originally uploaded on to www.youtube.com. We sourced 96 movies depicting 96\ndifferent female tutors, capturing a 5-second period of their monologue at the beginning of\ntheir tutorial (without sound). No further editing was performed. These movie files were\npresented at the beginning of every trial, during the ``learning phase,'' in the center of the\nscreen on gray background (see Figure 1).\nFor each of the 96 movies, we sourced a second makeup tutorial (www.youtube.com) that\nwas delivered by the same tutor. This second tutorial varied as much as possible from the first\nin terms of background, lighting, and clothing. From this second movie file, we took a single\nframe to serve as the target stimulus. These static images of the actors either depicted them\nlooking directly at the camera (24 faces), looking to the left (their right; 24 faces), looking to\nthe right (their left; 24 faces), or looking up above the camera (see Figure 1). Corresponding\ndistractors (and the stimuli used in the target absent trials) were single images captures from\nthe makeup tutorials, and similar interviews, of other female tutors (672 static images in total;\nsee Figure 1). Although some effort was made to capture different gaze directions without\nhead turns, inevitably these stimuli often also differed in viewpoint. However, we tried to\nminimize these differences by ensuring that two eyes were always visible (the majority of the\ndifferences were \u00c6 30 from the front most viewpoint). These static images were cropped, gray\nscaled, and placed on a square canvas 300 \u00c2 300 pixels in size. The luminance and root-mean-\nsquare contrast of each stimulus was adjusted to match the mean luminance and contrast\nvalues of the entire image set (768 stimuli in total).\nAll participants were initially asked if they used the website www.youtube.com to watch\nmovies and whether they had ever watched makeup tutorials on www.youtube.com.\nAlthough all of the participants were www.youtube.com users, only 16 admitted to\nwatching makeup tutorials. Importantly, none of the participants reported seeing a\nfamiliar face during the experiment.\nThe experimental procedure in Experiment 1 is illustrated in Figure 2(a). Each trial began\nwith a 5-second movie, participants were made aware that they needed to pay attention to the\nidentity of the person in the movie because they would be asked to recognize them in the\nsubsequent test phase. After a interstimulus interval of 1.5 seconds (on average), participants\nwere presented with four faces and asked to decide whether the person from the preceding\nmovie was present or not. The four faces were presented in four positions on the screen (top\nleft; top right; bottom left; bottom right), equally distant from the center (see Figure 2(a)). All\nfour faces were presented at the same size (subtending 5 of visual angle in height) on uniform\ngray background. The lineups were constructed so that the targets occurred in each of the\nfour positions an equal number of times. If they were present, the participant was required to\nhit the corresponding key on the keyboard (``7,'' ``9,'' ``1,'' and ``3'' representing the four\nscreen positions) or, alternatively, they could press ``5'' to indicate the person was not\npresent. The lineup was present until a response was recorded, then there was a 2,000 (\u00c6\n200) ms intertrial interval before the next trial began. We recorded their accuracy and their\nresponse speed. Each of the 96 movies were seen twice (serving only once as part of a target\npresent trial) and these 192 trials were presented in a random order.\n4 i-Perception\nFigure 1. The design for Experiment 1. The green squares indicate the target face in target present\nexamples. Otherwise, in target absent examples, the correct answer was ``not present.''\nTaubert et al. 5\nParticipants completed Experiment 1 in a dimly lit curtained booth. The experiment was\nprogrammed in MATLAB version R2010a using the Psychophysics Toolbox 3 (Brainard,\nseated approximately 57 cm in front of a CRT monitor (18-inch viewable screen size) set at a\nrecorded using an Apple wired USB keyboard.\nFigure 2. Procedure and results for Experiment 1. (a) Experimental procedure and illustrative stimuli. The\nexample is taken from the direct gaze condition (target is present in top left corner of lineup array). Each\narray presented participants with four faces (direct gaze; left gaze; right gaze; upward gaze). The location\nwithin was randomized. (b) Response profile across all trials. The proportion of participant responses (direct\ngaze face; left gaze face; right gaze face; up gaze face; target not present) in each of the five target conditions\n(target present-direct gaze face; target present-left gaze face; target present-right gaze face; target present-\nupward gaze face; target absent). The dark diagonal reflects overall accuracy and dark columns reflect a bias\ntoward a particular face type that transcends target condition. (c) Misidentification errors. Average number of\ntimes each participant incorrectly selected each distractor type (direct gaze face; left gaze face; right gaze face;\nup gaze face) as the target (error bars \u00bc \u00c6 SEM). ** indicates a p value that remained less than .01 after\ncorrection. Cohen's d values for repeated factors were calculated for the pairwise contrasts: direct gaze\nversus left gaze face, d \u00bc 1.09; direct gaze versus right gaze, d \u00bc 1.18; direct gaze versus up gaze, d \u00bc 0.48. (d)\nAverage overall accuracy. Average hit rate in target present trials across participants (error bar \u00bc \u00c6 SEM).\nSuperimposed is the average correct reaction time (secondary y-axis) to verify whether participants were\ntrading speed for accuracy. * indicates a p value that was less than .05 after correction and ** indicates a p\nvalue that was less than .01 after correction. Cohen's d values for repeated factors were calculated for the\npairwise contrasts: direct gaze versus left gaze face, d \u00bc 0.68; direct gaze versus right gaze, d \u00bc 0.66; direct\ngaze versus up gaze, d \u00bc 0.75.\n6 i-Perception\nResults\nInitially, we ran three participants who completed the same experiment but were\ninstructed to respond differently from the 24 in the main sample. For the first three\nparticipants, this was not a test of recognition memory, rather they had to simply\nindicate, under the same experimental conditions, which of the four faces was looking\ndirectly at them (including both targets and distractors; a four alternative force-choice\ntask with no option to indicate none). All three were able to choose the faces in the direct\ngaze condition without fail.\nFor the remaining 24 participants, the instructions were to study the face in the learning\nphase and report whether that person was present in the subsequent lineup. The response\nprofile of participants (Figure 2(b)) indicated a tendency to incorrectly reject in target present\ntrials, but also a bias toward direct gaze faces (and to some extent upward gaze faces). After\ncounting the number of misidentification errors participants made (see Table 1), we assessed\nwhich type of distractor was driving the misidentification error rate (Figure 2(c)). A\nsignificant one-way repeated measures analysis of variance (ANOVA) comparing the four\np\n\u00bc 0.3, justified a series of pairwise t-tests,\ncorrected for multiple comparisons with the Bonferroni rule (a/6). These discrete tests\nindicated that participants were more often misidentifying direct gaze and upward gaze\nfaces than other distractor types (for p values see Figure 2(c)).\nAnother one-way ANOVA (for repeated conditions) was used to analyze the target\npresent trials and determine whether the average hit rate differed across the four target\nconditions (target direct gaze; target left gaze; target right gaze; target upward gaze;\np\n\u00bc 0.23). The follow-up contrasts suggested that participants\nwere, on average, more accurate (and a corresponding decrease in correct reaction time;\np\n\u00bc 0.4) when the target was a direct gaze face rather than any\nother target type (Figure 2(d)).\nExperiment 2\nThe results of Experiment 1 suggest that participants recognizing faces in a lineup select\nmore frequently faces making direct eye contact than faces looking elsewhere. One potential\ncaveat in this design was viewpoint differences. Although we tried to capture stimuli that\nvaried only in their gaze direction, it is possible that the earlier result reflects a bias toward\nfront viewpoints, rather than direct gaze per se. One way to examine the contribution of\ngaze direction using the same stimulus set was to repeat Experiment 1 after removing\ngaze cues. Thus, in Experiment 2, we compared performance across two conditions; gaze\ncues present (eyes open condition) and gaze cues absent (eyes closed condition; see\nFigure 3(a)). If the results in Experiment 1 were driven by differences in gaze cues, one\nwould expect no difference across the target conditions when the stimuli had their eyes\nclosed.\nTable 1. Average Error Rate in Main Experiment.\nMean (%) SEM\nTaubert et al. 7\nMethod\nParticipants. In Experiment 2, we collected an independent sample of 16 participants (aged\nbetween 26 and 35; 11 participants were female). The sample size of 16 was determined by a\npower analysis of a previous study, thus, we recruited participants until we reached this\nnumber. All participants reported normal or corrected-to-normal vision. Although these\nparticipants were recruited from the same pool as described in Experiment 1, none of the\nparticipants were testing in Experiment 1.\nStimuli and procedure. We used the same equipment as in Experiment 1. The procedure for\nExperiment 2 was also identical to Experiment 1 except that there were no ``target absent''\ntrials and, thus, the participants were not given the option to reject the faces in the lineup.\nInstead, we forced them to select one of the four faces present (four-alternative forced\nchoice task). The target-present trials were exactly the same; however, they were now\nreferred to as the eyes open trials. Instead of having 96 target absent trials, as in\nExperiment 1, Experiment 2 had 96 eyes closed trials in Experiment 2 (see Figure 3(a)).\nThe test stimuli from the eye closed trials were taken from the same videos that were used\nto collect the eyes open trials. We carefully selected the stimuli with closed eyes from blinks\nthat occurred during those tutorials. Although there was no gaze information in these\nstimuli, we captured these blinks when the head was facing the front or turned to left,\nthe right, or the ceiling (upwards) to mimic the corresponding ``eyes open'' stimuli. Due to\nthe variability in the source material, the extent to which this was achieved differed greatly\nfrom trial to trial.\nFigure 3. The procedure and results of Experiment 2. (a) Illustrative examples of the two lineup conditions\nin Experiment 2; The lineup arrays used in the open eyes condition were identical to those used in target\npresent trials (Experiment 1). The lineup arrays in the closed eyes condition depicted the same target and\ndistractor individuals as the lineups in the open eyes condition, different frames were sourced where all the\ntutors had their eyes closed. (b) Hit rate as a function of target condition (direct gaze face; left gaze face; right\ngaze face; upward gaze face) and lineup condition (open eyes; closed eyes). Error bars represent standard\nerror of the mean.\n8 i-Perception\nResults\nIn the design, there were four levels of the variable ``Target Type'' (direct gaze vs. left gaze vs.\nright gaze vs. upward gaze) crossed with two levels of ``Lineup'' (eyes open vs. eyes closed)\nboth were manipulated within participant. Therefore, we analyzed the average hit rate data\nusing a 2 \u00c2 3 repeated measures ANOVA that yielded a main effect of Target Type,\np\np\np\nFigure 3(b), motivated a set of four pairwise contrasts to compared performance between\nopen eyes and closed eyes within each level of Target Type. These confirmed that closing the\neyes only impacted the direct gaze target trials; participants were more accurate when the\nfaces had their eyes open rather than closed (p \u00bc .001; a/4, cohen's d \u00bc 1.06). This same\ndifference was not significant for any other level of the target type (all p values > .0125; a/4).\nThe number of misidentification errors in the eight unique conditions was also investigated, as\nin Experiment 1. The same series of discrete paired t-tests (two-tailed) were used to determine\nwhether closing the eyes changed the misidentification rate in any of the four gaze conditions\n(Bonferroni corrected for multiple comparisons; a/4). While this was true for the direct gaze\ncondition, the misidentification rate was reduced when the stimuli had their eyes closed,\ncompared with when they had their eyes open (p\u00bc .005, cohen's d\u00bc 0.85), there was no\nevidence that this was true for the right (p\u00bc .07), left (p\u00bc .11), or upward gaze (p\u00bc .03) conditions.\nExperiment 3\nOne question that remained was whether recognition performance in Experiments 1 and 2\nreflected an increase in identity sensitivity when faces were looking at the participants or a\nselection bias toward direct gaze faces. We addressed this question by running a third\nexperiment to measure participant sensitivity to the identity signal without distractors.\nMethod\nParticipants. An independent sample of 20 observers (12 female), all undergraduate\npsychology students at the University of Sydney, served as participants (age ranged\nbetween 22 and 31). A power analysis of a previous pilot investigating sensitivity across\nfour visual conditions implied that a difference should emerge with a sample of size 9. All\nparticipants reported normal or correct-to-normal vision.\nStimuli and procedure. The procedure for the final experiment was the same as Experiment 1,\nexcept there was only one face presented in the test phase and participants simply indicated\nwhether it was the same person they saw in the preceding movie or not (sequential same or\ndifferent task). Target present trials were used as same trials (only the targets were visible in\nthe test phase). Target absent trials were converted into different trials. We were careful to\nhave 24 different trials with a direct gaze distractor, 24 with a left gaze distractor, 24 with a\nright gaze distractor, and 24 with a distractor looking up. Thus, in total, there were 96 same\ntrials and 96 different trials. The timing parameters were the same as in Experiments 1 and 2\n(see Figure 4(a)). The same equipment and testing room were used in all three experiments.\nResults\nOverall accuracy was computed for each participant (% correct across all trials) and analyzed\ninitially using a one-way ANOVA which yielded evidence of variation between the\nTaubert et al. 9\np\n\u00bc 0.35. To further investigate the a priori hypothesis\nregarding better performance in a specific condition (i.e., direct gaze), we ran a series of six\ndiscrete pairwise contrasts (two-tailed). There were three significant differences found in the\naccuracy data, after the correction necessary for multiple comparisons (a/6). The significant\ndifferences all indicated that participants were, on average, less accurate in the direct gaze\ncondition (direct gaze vs. left gaze, p \u00bc .002, cohen's d \u00bc 0.78; direct gaze vs. right gaze,\nInspection of Figure 4(b) suggested that participants were less accurate in the direct gaze\ncondition because of an inflated false positive rate. The number of hits (correct responses in\nsame trials) and false positives (incorrect responses in different trials) that each participant\nmade across each of the four gaze conditions were transformed into a d0 score--these values\nwere then averaged across participants. Sensitivity across gaze conditions was analyzed using\nFigure 4. The sequential Same or Different Experiment. (a) Experimental procedure for Experiment 3. In\nthis particular example, the correct answer would have been ``same'' because these faces all belong to the\nsame person. (b) Average number of ``same'' responses in each trial type (same or different) as a function of\nface condition (direct gaze faces; left gaze faces; right gaze faces; upward gaze faces). Error bars \u00bc \u00c6 1 SEM. (c)\nAverage d0 scores (error bars \u00bc \u00c6 1 SEM).\np\n\u00bc 0.23. A set of six planned t-tests (two-\ntailed) yielded evidence that sensitivity differed between two discrete conditions only\n(direct gaze and right gaze, p \u00bc .008, a/6, cohen's d \u00bc 0.66). None of the other pairwise\ncomparisons were significant (all other p values > .09 after correction; see Figure 4(c)). A\none-way analysis of variance of the corresponding response criterion values (c) indicated that\nthere was a systematic change in the participant's criteria across the four gaze conditions,\np\n\u00bc 0.63. A set of planned t-tests (two-tailed) was used to find the\nsource of the variance in the overall ANOVA. After a Bonferroni correction (a/6), only three\ndiscrete comparisons remained significant, the three that compared direct gaze to another\ngaze direction (direct gaze vs. left gaze, p < .001, cohen's d \u00bc 1.35; direct gaze vs. right gaze,\nthese results indicate that while sensitivity did not greatly differ across gaze conditions, the\nparticipants may have been using different criteria to make decisions in the direct gaze\ncondition compared with the other gaze conditions. Certainly, we found no evidence to\nsupport the idea that performance with direct gaze targets is driven by increased sensitivity\nto the visual signal.\nGeneral Discussion\nThe data across three experiments provide a clear indication that when the direction of gaze\ndiffers among the faces presented in a simultaneous lineup, faces looking directly at the\nparticipant are more likely to be selected. A large body of research has indicated that, for\nprimates, detecting and understanding changes in the gaze direction of other people is a vital\nUntil now, the widely held assumption was that gaze is important to read because it provides\ninformation about social intention. More simply put, the direction of a person's gaze was\nthought to convey the direction of their current behavior or attention (Baron-Cohen, 1995;\nCalder et al., 2002; Tomasello & Carpenter, 2007). However, in studies of lie detection, it has\nbeen argued that gaze direction signals more about a person than the direction of their\nattention (Vrij et al., 2010; Vrij & Semin, 1996). Building on this, we hypothesized that\ngaze direction might interfere with a face recognition task and our results are largely\nconsistent with this prediction. We argue that this might be because people find it difficult\nto recognize faces in a lineup (Bruce et al., 1999; Hancock et al., 2000; Megreya & Burton,\n2006; Megreya et al., 2013) and they automatically process gaze direction information (Kuhn\ninformation about gaze direction is reliably available to participants, even when their\ninstruction is to recognize a target face. Additionally, since gaze direction appears to be\nbeneficial when participants are required to make old or new decisions (Adams et al.,\nit could well be the case they rely on this cue (automatically) in a lineup procedure as well.\nThe purpose of using a highly variable static stimulus set, together with the use of dynamic\nvideos during the learning phase, was to increase the ecological validity of these findings,\nenabling us to draw rough inferences in a forensic context. However, a caveat we would like\nto consider is the nature of the static images we used in these experiments. They were highly\nvariable because no attempt was made to standardize face size, face viewpoint, background\ninformation or principal visual characteristics, over and above luminance, and contrast (such\nas spatial frequency content; see Figure 1). Moreover, while we collected data regarding the\nperceived gaze direction of the faces comprising the ``direct gaze'' condition, the stimuli in\nother gaze direction conditions remain subject to a potential researcher bias. For instance,\nwe have no evidence that the faces in the ``left gaze'' condition are perceived as looking left to\nanyone other than ourselves. For this reason, perhaps it would be better to think of them as\ngaze deviants (i.e., not making direct eye contact) rather than three discrete categories (left\ngaze; right gaze; upward gaze). Certainly, this phenomenon could be confirmed with more a\nstandardized stimulus set, where head position (i.e., viewpoint) and gaze direction could be\nmanipulated independently. Also, we acknowledge that the experience of attending a real life\nlineup is different in nature (one viewing vs. multiple ones) and outcome (legal repercussions)\nto our experimental set up. Therefore, after having established the occurrence of the effect in\na laboratory setting, it is essential to establish if the reliance of eye gaze as a heuristic in the\nface of uncertainty is still present in the same magnitude under a more ecologically valid\nconditions.\nConclusion\nBased on the present literature, it seems that gaze direction has been overlooked as a\npotential problem when asking witnesses to identify a person in a lineup (either live\nviewing or in a photo array). Although the current procedure may encourage people to\nlook forward, the brain is incredibly sensitive to direct eye contact (Baron-Cohen, 1995;\nmade to hold gaze direction, constant small variations can be expected among people in a\nphoto lineup. Importantly, these results suggest that people are biased toward selecting direct\ngaze faces when gaze direction differs among faces, inflating the misidentification rate. It is a\nsimple physical attribute that, with very little effort, can be standardized among a group of\npeople and, thus, neutralized as a contributing factor to misidentification error.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research,\nauthorship, and/or publication of this article.\nFunding\nThe author(s) received no financial support for the research, authorship, and/or publication of this\narticle.\nReferences\nAdams, R. B., Pauker, K., & Weisbuch, M. (2010). Looking the other way: The role of gaze direction in\nBaron-Cohen, S. (1995). Mindblindness: An essay on autism and theory of mind. Cambridge, MA: MIT\npress.\nBowles, D. C., McKone, E., Dawel, A., Duchaine, B., Palermo, R., Schmalzl, L., . . . Yovel, G. (2009).\nDiagnosing prosopagnosia: Effects of ageing, sex, and participant-stimulus ethnic match on the\nCambridge Face Memory Test and Cambridge Face Perception Test. Cognitive Neuropsychology,\nBruce, V., Henderson, Z., Greenwood, K., Hancock, P. J. B., Burton, A. M., & Miller, P. (1999).\nVerification of face identities from images captured on video. Journal of Experimental Psychology:\nCalder, A. J., Lawrence, A. D., Keane, J., Scott, S. K., Owen, A. M., Christoffels, I., . . . Young, A. W.\nEmery, N. J. (2000). The eyes have it: The neuroethology, function and evolution of social gaze.\nFarroni, T., Massaccesi, S., Menon, E., & Johnson, M. H. (2007). Direct gaze modulates face\nHancock, P. J., Bruce, V. V., & Burton, A. M. (2000). Recognition of unfamiliar faces. Trends in\nHood, B. M., Macrae, C. N., Cole-Davies, V., & Dias, M. (2003). Eye remember you: The effects of\ngaze direction on face recognition in children and adults. Developmental Science, 6, 67\u00ad71.\nKemp, R., Towell, N., & Pike, G. (1997). When seeing should not be believing: Photographs, credit\nKlin, A., Lin, D. J., Gorrindo, P., Ramsay, G., & Jones, W. (2009). Two-year-olds with autism orient to\nKuhn, G., & Benson, V. (2007). The influence of eye-gaze and arrow pointing distractor cues on\nKuhn, G., & Kingstone, A. (2009). Look away! Eyes and arrows engage oculomotor responses\nLangton, S. R., Watt, R. J., & Bruce, I. I. (2000). Do the eyes have it? Cues to the direction of social\nattention. Trends in Cognitive Sciences, 4, 50\u00ad59.\nLeonard, T. K., Blumenthal, G., Gothard, K. M., & Hoffman, K. L. (2012). How macaques view\nMadipakkam, A. R., Rothkirch, M., Guggenmos, M., Heinz, A., & Sterzer, P. (2015). Gaze direction\nmodulates the relation between neural responses to faces and visual awareness. Journal of\nMegreya, A. M., & Burton, A. M. (2006). Unfamiliar faces are not faces: Evidence from a matching\nMegreya, A. M., Sandford, A., & Burton, A. M. (2013). Matching face images taken on the same day or\nMosher, C. P., Zimmerman, P. E., & Gothard, K. M. (2014). Neurons in the monkey amygdala detect\nPelli, D. G. (1997). The VideoToolbox software for visual psychophysics: transforming numbers into\nPelphrey, K. A., Morris, J. P., Michelich, C. R., Allison, T., & McCarthy, G. (2005). Functional\nanatomy of biological motion perception in posterior temporal cortex: An FMRI study of eye,\nPelphrey, K. A., Viola, R. J., & McCarthy, G. (2004). When strangers pass: Processing of mutual and\nPerrett, D. I., Smith, P. A., Potter, D. D., Mistlin, A. J., Head, A. S., Milner, A. D., . . . Jeeves, M. A.\n(1985). Visual cells in the temporal cortex sensitive to face view and gaze direction. Proceedings of the\nPozzulo, J. D., & Balfour, J. (2006). Children's and adults' eyewitness identification accuracy when a\nculprit changes his appearance: Comparing simultaneous and elimination lineup procedures. Legal\nRicciardelli, P., Bricolo, E., Aglioti, S. M., & Chelazzi, L. (2002). My eyes want to look where your eyes\nare looking: Exploring the tendency to imitate another individual's gaze. Neuroreport, 13,\nRussell, R., Duchaine, B., & Nakayama, K. (2009). Super-recognizers: People with extraordinary face\nSenju, A., & Johnson, M. H. (2009). The eye contact effect: Mechanisms and development. Trends in\nSmith, A. D., Hood, B. M., & Hector, K. (2006). Eye remember you two: Gaze direction modulates face\nSteblay, N., Dysart, J., Fulero, S., & Lindsay, R. C. L. (2003). Eyewitness accuracy rates in police\nshowup and lineup presentations: A meta-analytic comparison. Law and Human Behavior, 27,\nTanaka, J. W., & Sung, A. (2016). The ``Eye Avoidance'' hypothesis of autism face processing. Journal\nTomasello, M., Carpenter, M., Call, J., Behne, T., & Moll, H. (2005). Understanding and sharing\nintentions: The origins of cultural cognition. Behavioral and Brain Sciences, 28, 675\u00ad691; .\nVrij, A., Granhag, P. A., & Porter, S. (2010). Pitfalls and opportunities in nonverbal and verbal lie\nVrij, A., & Semin, G. R. (1996). Lie experts' beliefs about nonverbal indicators of deception. Journal of\nVuilleumier, P., George, N., Lister, V., Armony, J., & Driver, J. (2005). Effects of perceived mutual gaze\nWells, G. L. (1993). What do we know about eyewitness identification? American Psychologist, 48,\nWhite, D., Kemp, R. I., Jenkins, R., Matheson, M., & Burton, A. M. (2014). Passport officers? Errors in\nWicker, B., Michel, F., Henaff, M. A., & Decety, J. (1998). Brain regions involved in the perception of\nAuthor Biographies\nJessica Taubert is a research fellow currently working in the\nNational Institute of Mental Health (USA). She is also a\nhonorary associate in the School of Psychology (the University\nof Sydney, Australia). Her research interests include the neural\nand psychological mechanisms that support face perception.\nCeline van Golde is an associate lecturer in the School of\nPsychology at the University of Sydney. Her research has\nfocused on fallibility of memory in adults and in children,\nspecifically how interviewing techniques can affect memory\naccuracy, and what drives mistakes in eyewitness identification.\nShe is also the founder and director of Not Guilty; the Sydney\nExoneration project, which assess cases of possible wrongful\nconviction.\nFrans A. J. Verstraten studied Experimental Psychology at the\nRadboud University in Nijmegen and obtained his PhD from\nUtrecht University. After postdoctoral positions in Canada, USA\nand Japan, he became a professor at Utrecht University in 2000,\nwhere he soon after was appointed Department Head and later\nScientific Director of the Helmholtz Institute. He served on the\nboard and as president of the Vision Sciences Society. In 2012,\nhe moved to The University of Sydney. He is the McCaughey\nChair of Psychology and heads the School of Psychology. His\nresearch interests include adaptive aspects of motion perception,\nbinocular vision, and the role of eye-movements."
}