{
    "abstract": "Abstract. In everyday scenes, the illuminant can vary spatially in chromaticity and luminance,\nand change over time (e.g. sunset). Such variation generates dramatic image effects too\ncomplex for any contemporary machine vision system to overcome, yet human observers\nare remarkably successful at inferring object properties separately from lighting, an ability\nlinked with estimation and tracking of light field parameters. Which information does the\nvisual system use to infer light field dynamics? Here, we specifically ask whether color\ncontributes to inferred light source motion. Observers viewed 3D surfaces illuminated by an\nout-of-view moving collimated source (sun) and a diffuse source (sky). In half of the trials,\nthe two sources differed in chromaticity, thereby providing more information about motion\ndirection. Observers discriminated light motion direction above chance, and only the least\nsensitive observer benefited slightly from the added color information, suggesting that color\nplays only a very minor role for inferring light field dynamics.\n",
    "reduced_content": "a Pion publication\nHolly E. Gerhard\nDepartment of Psychology, New York University, 6 Washington Place, New York, NY 10003, USA; Werner Reichardt Centre\nfor Integrative Neuroscience, Otfried-Mueller-Strasse 25, Tuebingen 72076, Germany; e-mail: hgerhard@gmail.com\nLaurence T. Maloney\nDepartment of Psychology and Center for Neural Science, New York University, 6 Washington Place, New York, NY 10003,\nUSA; e-mail: laurence.maloney@nyu.edu\n Keywords: color constancy, material perception, illumination perception, 3D perception, scene understanding,\nmotion perception.\nThe human visual system is remarkably successful at disentangling lighting from object properties in\nthe ambiguous light signal entering our eyes. Several studies show that observers estimate both surface\nproperties and light field parameters from static views of 3D scenes (see Maloney, Gerhard, Boyaci, &\nDoerschner, 2011, for a recent review). We have shown that observers also estimate dynamic light field\nproperties in 3D scenes, an ability linked with improved sensitivity to surface reflectance (Gerhard &\nMaloney, 2010a). Analyses showed that perceiving light field dynamics depends heavily on the 3D\nsurface geometry of the scene's objects, much more so than on the raw luminance patterns in the im-\nages (Gerhard & Maloney, 2010b). However, previous dynamic light stimuli were achromatic. Here,\nwe ask whether color improves sensitivity.\nFollowing previous studies, our subjects viewed rendered 3D scenes stereoscopically. These stim-\nuli simulated a sun setting over a hilly landscape (Figure 1a) viewed from above (Figure 1b). Mo-\nnocularly, peaks and valleys cannot be disambiguated in such scenes so lighting direction is inferred\ncorrectly only up to a 180\u00b0 flip, and disparity must be used to avoid the concave/convex ambiguity.\nTrials were 1,500 ms: the initial 750 ms were static so observers could acquaint themselves with the\ngeometry and initial lighting, in the final 750 ms, the out-of-view collimated light source, the \"sun,\"\nrotated 10\u00b0 overhead in one of the four directions (Figure 1c). The task was 4AFC to indicate the sun\nmotion direction. Feedback was never given, and there was no training.\nThe sun's initial position above the scene was randomized on every trial both in azimuth (angle\nin the image plane) and in elevation, held between 90\u00b0 (perpendicular to the ground plane) and 70\u00b0\n(slightly off-perpendicular). Random initial positions forced observers to track light motion because\nposition in any one frame was uninformative for the task.\nAn additional fixed light source also illuminated the scene: a homogeneous \"sky.\" The sky was al-\nways neutral in hue and a quarter intense as the sun, which had intensity 100 cd/m2. The lights'intensi-\nties were fixed, but we varied their chromaticity coordinates. In half of the trials, both had chromaticity\nShort and Sweet\nInferred motion perception of light sources in 3D scenes is\ncolor-blind\nDynamic light perception in 3D scenes is color-blind 99\ncoordinates corresponding to D65, the standard neutral daylight hue (achromatic condition). In the\nother half, the sun had one of eight hues (chromatic condition) shown in Figure 1(d). Figure 1(e) shows\nhue). Blocks alternated by condition, with first block type counterbalanced over subjects. Hue trial\ntypes were intermixed in chromatic blocks.\nA new random Gaussian landscape was generated for every trial. We ensured that shading was\nthe only cue to light direction by assuming Lambertian reflectance and disallowing combinations of\nsun trajectories and scene geometry causing cast shadows since they are an unambiguous cue to light\ndirection even monocularly. We rendered 16 frames for each trial, in which the sun rotated in incre-\nrun on a stereoscope of two linearized monitors. All details of the equipment, scene generation, and\nstereo rendering process are identical to those described in Gerhard and Maloney (2010b).\nEight subjects participated. All had normal or corrected-to-normal acuity, passed the Ishihara\ncolor plate test, and passed a stereo test emphasizing concavity/convexity judgments from Gerhard\nand Maloney (2010a). All gave informed consent before participation and were remunerated $8/hour.\nExperiments were approved by the New York University Institutional Review Board and were in ac-\ncordance with the Helsinki Declaration.\nResults are shown in Figure 2. Observers performed above chance overall, achieving between\n31% and 77% correct after a correction for guessing; however, color information did not significantly\nimprove sensitivity to light motion direction (Figure 2a) except for the least sensitive observer who\nimproved by 7%. Observers were equally sensitive to all motion directions (Figure 2b) and for all hues\n(Figure 2c).\nAdded color information does not appear to play a large role in sensitivity to light field dynam-\nics. Previous analyses emphasizing the importance of scene geometry provide much more explana-\ntory power for this kind of light field inference in hilly scenes illuminated by a moving sun and sky\nFigure 1. Hilly landscapes and lighting. (a) An example landscape seen from a view never used experimentally\nbut shown for illustrative purposes. (b) Example stereo pairs for crossed and uncrossed fusion. Subjects viewed\nthe scenes stereoscopically from directly overhead as shown. Monocular views do not disambiguate hills from\npeaks; only stereo disparity resolves the concave/convex ambiguity and therefore the direction to the light. (c)\nThe sun rotated 10\u00b0 over the landscape in one of the four directions in the image plane. The task was 4AFC to\nindicate motion direction. (d) In half of the trials, the sun had chromaticity coordinates equal to one of the eight\nhues equally spaced on a circle in CIE La*b* space centered on D65. The hue with * has CIE x, y coordinates\nilluminated by a yellowish sun and neutral sky.\nPublished under a Creative Commons Licence a Pion publication\nHolly E. Gerhard holds a PhD from the Cognition and Perception program of the NYU Psychology\nDepartment and is currently a post-doctoral research scientist at the Computational Vision and Neuro-\nscience Lab in Tuebingen, Germany.\n"
}