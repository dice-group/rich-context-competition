{
    "abstract": "Abstract\nBackground: Trials to identify the minimal effective treatment duration are needed in different therapeutic areas,\nincluding bacterial infections, tuberculosis and hepatitis C. However, standard non-inferiority designs have several limita-\ntions, including arbitrariness of non-inferiority margins, choice of research arms and very large sample sizes.\nMethods: We recast the problem of finding an appropriate non-inferior treatment duration in terms of modelling the\nentire duration\u00adresponse curve within a pre-specified range. We propose a multi-arm randomised trial design, allocating\npatients to different treatment durations. We use fractional polynomials and spline-based methods to flexibly model the\nduration\u00adresponse curve. We call this a `Durations design'. We compare different methods in terms of a scaled version\nof the area between true and estimated prediction curves. We evaluate sensitivity to key design parameters, including\nsample size, number and position of arms.\nResults: A total sample size of ~ 500 patients divided into a moderate number of equidistant arms (5\u00ad7) is sufficient to\nestimate the duration\u00adresponse curve within a 5% error margin in 95% of the simulations. Fractional polynomials pro-\nvide similar or better results than spline-based methods in most scenarios.\nConclusion: Our proposed practical randomised trial `Durations design' shows promising performance in the estima-\ntion of the duration\u00adresponse curve; subject to a pending careful investigation of its inferential properties, it provides a\npotential alternative to standard non-inferiority designs, avoiding many of their limitations, and yet being fairly robust to\ndifferent possible duration\u00adresponse curves. The trial outcome is the whole duration\u00adresponse curve, which may be\nused by clinicians and policymakers to make informed decisions, facilitating a move away from a forced binary hypothesis\ntesting paradigm.\n",
    "reduced_content": "Article\nCLINICAL\nTRIALS\nClinical Trials\nArticle reuse guidelines:\nsagepub.com/journals-permissions\njournals.sagepub.com/home/ctj\nRethinking non-inferiority: a practical\ntrial design for optimising treatment\nduration\nMatteo Quartagno1,2 , A Sarah Walker1, James R Carpenter1,2,\nPatrick PJ Phillips1 and Mahesh KB Parmar1\n Keywords\nAntimicrobial resistance, design, randomised trial, flexible modelling, non-inferiority, duration of therapy\nIntroduction\nWhile much early-phase drug development focusses on\nidentifying the most appropriate dose, for many condi-\ntions, less emphasis is placed on identifying the most\nappropriate treatment duration. Consequently, dura-\ntion is often based as much on precedent as evidence. A\nmotivating example is bacterial infections, where\nconcerns about under-treatment and low costs have his-\ntorically led to long antibiotic courses. However, wide-\nspread antibiotic overuse over the past decades, for\nexample, for non-bacterial infections or for longer than\nnecessary to cure an infection, is now considered the\nmain driver for increasing antimicrobial resistance.1,2\nHow to design trials to optimise treatment duration\n(which will often take the form of finding the shortest\neffective treatment duration) is, however, unclear.\nThe most widely used design is a non-inferiority\ntrial;3,4 two key design choices are the new duration of\ntherapy and the non-inferiority margin, that is, the\nmaximum difference in efficacy of the new versus stan-\ndard treatment duration that investigators will tolerate.\nIf the whole confidence interval (CI) for the difference\nin treatment efficacy lies below this margin, non-\n1MRC Clinical Trials Unit at UCL, London, UK\n2Department of Medical Statistics, London School of Hygiene & Tropical\nMedicine, London, UK\nCorresponding author:\nMatteo Quartagno, Department of Medical Statistics, London School of\nHygiene & Tropical Medicine, Room LG70, LSHTM, Keppel Street,\nLondon WC1E 7HT, UK.\nEmail: m.quartagno@ucl.ac.uk\ninferiority of the shorter duration is demonstrated.\nHowever, non-inferiority trials have been often criti-\ncised;5 key limitations are as follows:\n The non-inferiority margin is somewhat arbitrary,\ntypically being a multiple of 5% on the absolute\ndifference scale. European Medicines Agency gui-\ndance6 recommends that the non-inferiority margin\nfor antibiotic trials should be decided so that equiv-\nalent efficacy versus placebo can be excluded, for\nexample, if cure rates are 80% with control and\n20% without antibiotics, then the non-inferiority\nmargin should ensure that the intervention has\n! 20% cure rate. This is rarely helpful, given low\ncure rates for serious infections without antibiotics\nand high cure rates with antibiotics (also see Food\nand Drug Administration guidance7). Furthermore,\nat the design stage, there is often relatively little a\npriori information on the expected control event\ncan substantially impact the sample size required to\ndemonstrate non-inferiority on an absolute scale.\n Whether the CI should be 95% (two-sided alpha =\ndebated.\n Consequently, sample sizes for non-inferiority trials\nwith reasonably small margins (5%) are usually\nvery large, and they are often unsuccessful.9\n The shorter durations to be tested have to be chosen\nin advance; again, limited prior knowledge makes\nthis choice difficult. A bad choice inevitably leads\nto failure of the trial or an unnecessarily long dura-\ntion being adopted in clinical practice. Comparing\nmultiple durations increases the chance of selecting\nsensible durations to test but requires even bigger\nsample sizes with the traditional design.\n There is no consensus for best analysis methods for\nnon-inferiority trials; both intention-to-treat and\nper-protocol approach can lead to unreliable results.\nInternational recommendations differ;5 at best, lead-\ning to challenges in interpretation and, at worst, to\nmanipulation towards the most favourable results.\nAn alternative approach to non-inferiority trials is\ntherefore attractive but relatively little work has been\ndone in this area. A recent proposal is the Desirability\nof Outcome Ranking/Response Adjusted for Duration\nof Antibiotic Risk (DOOR/RADAR) trial design.10\nRADAR first categorises patients using a composite\nclinical outcome (based on benefits and harms) and\nthen successively ranks them with respect to a DOOR,\nassigning higher ranks to patients with better compo-\nsite outcomes and shorter antibiotic durations. Finally,\nthe probability that a randomly selected patient will\nhave a better DOOR if assigned to the new treatment\nduration is calculated. The main criticisms of DOOR/\nRADAR are that combining clinical outcome and\ntreatment duration into a single composite may hide\nimportant differences in the clinical outcome alone and\nintrinsically assumes (rather than estimates) that\nshorter durations are beneficial, and hence, the clinical\ninterpretation of the treatment effect on the composite\nendpoint is far from clear. Phillips et al.11 showed that\ntwo non-inferiority trials where shorter durations had\nbeen unequivocally demonstrated not to be non-inferior\nwould have instead demonstrated non-inferiority using\nTo identify appropriate treatment durations, another\npossible approach is to model the duration\u00adresponse\ncurve, borrowing information from other durations\nwhen calculating treatment effect at a particular dura-\ntion. This was first proposed, in a limited way, by\nHorsburgh et al.12 where, on the log-odds scale, the\neffect of duration on response rate was assumed to be\nlinear (logistic regression model).\nHowever, in general, and certainly for antibiotic\ntreatment duration, this strong assumption is unlikely\nto hold. Therefore, here, we instead propose using flex-\nible regression modelling strategies to model the\nduration\u00adresponse curve, to provide robustness under\ngeneral forms of the true duration\u00adresponse curve.\nProposals\nSuppose a treatment T has currently recommended\nduration Dmax\nand there is a minimum duration Dmin\n,\nwe are willing to compare with Dmax\n, possibly because\nan even shorter duration is thought unlikely to be suffi-\nciently effective. Our goal is to model the duration\u00ad\nresponse curve for response Y between Dmin\nand Dmax\n.\nIn the equations below, Y can be either a continuous\noutcome or a linear predictor of a binary outcome\n(representing cure). In simulations, we will assume\nDmin\nThe most appropriate design depends on the true\nshape of the duration\u00adresponse curve; we therefore\nhave to ensure robustness against a series of different\nscenarios. For example, allocating patients to only two\narms, at Dmax\nand Dmin\nwould be a very good design if\nthe duration\u00adresponse curve was linear, but a terrible\ndesign for quadratic duration\u00adresponse relationships.\nTherefore, instead of focusing on a single duration\u00ad\nresponse curve, we simulated data from a set of plausi-\nble duration\u00adresponse curves and then evaluated sev-\neral study designs across these scenarios. In particular,\nwe explored the effect of changing: (1) total sample size\nN, (2) number and (3) position of duration arms and (4)\nthe type of flexible regression model used.\nHowever, to select the most accurate procedure for\nestimating the duration\u00adresponse curve, we need to\nchoose a measure of discrepancy between the true and\nestimated curves.\nLack of accuracy is often evaluated through either\nthe integral error or the expected error. For a fixed\nset of chosen durations D = (D1\n, . . . , Dn\n) = (Dmin\n,\n. . . , Dmax\n), the expected error is defined as follows\nEE =\nn\nX\nn\nD(f (Di\n), ^\nf (Di\nwhere D represents a sensible measure of distance, for\nexample, squared difference or absolute difference,\nf (Di\n) represents the true response (typically probability\nof cure) corresponding to treatment duration Di\nand\n^\nf (Di\n) represents the corresponding estimate from the\nfitted model. However, this sum is over the durations\ndefining the support, for example, only over the speci-\nfied durations, while we would like to evaluate the fit of\nthe model across the whole duration range \u00bdDmin\n, Dmax\n.\nTherefore, we instead used a type of integral error, that\nis, a measure of accuracy defined through an integral,\ninstead of a sum, to characterise model accuracy over\nthe entire domain of interest D = \u00bdDmin\n, Dmax\n\nIE =\n\u00f0\nD max\nD min\nD(f (D), ^\nf (D))dD \u00f02\u00de\nWe chose the absolute difference as measure of dis-\ntance D, as it has the most straightforward interpreta-\ntion, namely, the area between the true and estimated\nduration\u00adresponse curve. Henceforth, we refer to this\nmeasure as the Area Between Curves. However, this\nhas as units probability-days which is challenging to\ninterpret. Therefore, we divided it by (Dmax\n\u00c0 Dmin\n) to\nproduce a measure on the probability scale, the scaled\nArea Between Curves. For a particular fitted curve, this\ncan be interpreted as the average absolute error in the\nestimation of probability of cure, with respect to a uni-\nform distribution for duration on (Dmin\n, Dmax\n). In some\nareas of the curve, the model may fit better, and in some\nothers, it may fit worse; however, this measure provides\nan average across the whole duration range. We then\nadditionally considered the maximum absolute error in\n(Dmin\n, Dmax\n) and the coverage level, defined as the pro-\nportion of the true curve included within the point-wise\n95% confidence region around the estimated curve.\nAll these measures can only be calculated when the\ntrue underlying curve is known. They are therefore only\nuseful for simulations to evaluate the behaviour of our\nproposed method.\nTo model the duration\u00adresponse curve as flexibly as pos-\nsible, we compared four different regression strategies:\nDp1 + \u00c1 \u00c1 \u00c1 + bM\nwith powers p1\n, . . . , pM\ntaken from a special set\nis sufficient for a good fit; here, we fix M = 2, pro-\nducing 36 possible combinations.\n2. Linear splines, with the simplest form, under a sin-\ngle knot K\n(D \u00c0 K)+\nwhere (D \u00c0 K)+\n= 0 if D\\K. We investigated lin-\near splines with different numbers of knots; we\npresent results with three or five knots. Knots are\nequidistant, within the duration range considered,\nfor example, for three knots, positioned at\n3. Linear spline with non-equidistant knots: this con-\ncentrates knots for the linear splines in the first half\nof the duration range, where the duration\u00adresponse\nrelationship is most likely to be non-linear. We use\nthree knots that we arbitrarily chose to position at\n4. Multivariate adaptive regression splines,15,16 which\nbuilds models of the form\nY =\nX\nk\nbi\nBi\nwhere each Bi\n(D) can be (1) a constant, (2) a hinge\nfunction, that is, max (0, D \u00c0 K) or max (0, K \u00c0 D) or\n(3) a product of two hinge functions. A forward selec-\ntion step, building on a greedy algorithm, is followed\nby a backward elimination step, to avoid over-fitting.\nCandidate knots K are all durations observed in the\nsample, that is, all selected duration arms.\nWe did not consider restricted cubic splines17\nbecause preliminary work showed similar results to\npiece-wise linear splines; therefore, we focussed on lin-\near splines for simplicity. Other non-linear regression\nmethods include logistic or Gompertz growth models;\nhowever, these lose flexibility.\nOther key design parameters are as follows: How\nmany different duration arms should we allocate\npatients to? How should we space arms across our\nduration range? How many patients should we enrol?\nWe addressed these questions in an extensive simula-\ntion study.\nResults\nThe eight different scenarios considered represented a\nwide range of possible duration\u00adresponse relationships,\nfrom linear to quadratic, sigmoid curves and piecewise\nfunctions (Table 1). We simulated binary responses,\nrepresenting cure of infection, from a binomial\nTable 1. Simulation scenarios: eight different data-generating mechanisms were investigated.\nType Equation Characteristics Plot\n1. Logistic growth curve Psuccess\nIncreases and\nasymptotes early\n2. Gompertz curve A\nPsuccess\nSmall curvature\n3. Gompertz curve B\nPsuccess\n(\u00c0 exp (\u00c0 (D \u00c0 11)))\nLarger curvature,\nasymptotes more clearly\n4. Gompertz curve C\nPsuccess\n(\u00c0 2 exp (\u00c0 (D \u00c0 9)))\nAsymptotes extremely early\nduration\u00adresponse\ncurve on log-odds scale\nlogit(Psuccess\nSituation where simple logistic\nregression is appropriate\n6. Quadratic\nduration\u00adresponse\ncurve, curvature . 0\nPsuccess\nFirst derivative increasing\n7. Quadratic\nduration\u00adresponse\ncurve, curvature \\ 0\nPsuccess\nFirst derivative decreasing\n8. Piece-wise linear\nduration\u00adresponse\ncurve\nPsuccess\nDifferent from linear spline logistic\nregression, here it is linear in\nthe success rate, not\nin the log-odds\nIn plots, x-axis is treatment duration, and y-axis is probability of cure.\ndistribution with duration-specific event rates, with\n1000 simulated trials for each combination of design\nparameters.\nBase-case design\nWe first fixed a sample size of 504 individuals rando-\nmised between seven equidistant duration arms\nWe kept durations unrounded, simulating a situation\nwhere an antibiotic is administered three times a day,\nand therefore 11.6 means three times daily for 11 days\nand then twice on the last day. Simulated data were\nanalysed with a FP logistic regression model, that is, on\nthe log-odds scale.\nIn all eight scenarios, the worst fit still led to a scaled\nArea Between Curves below 5.3% in 95% of simula-\ntions (Table 2); that is, in each scenario, 95% of the\nsimulated trials led to an estimated duration\u00adresponse\ncurve whose error in the estimation of the probability\nof cure was under 5.3%.\nScenarios 1, 2 and 3 had the poorest performance.\nFigure 1 shows the fitted prediction curves for a ran-\ndom sample of 100 simulations (red) against the true\ndata-generating curve (black). In Scenario 1, FP had\ndifficulty in capturing satisfactorily the substantial\nchange in curvature around days 12 and 14, tending to\nunderestimate curvature at these time points.\nBest performances were obtained with Scenario 5,\nwhere the true duration\u00adresponse curve is linear on the\nlog-odds scale, which is exactly an FP model, with a sin-\ngle parameter for the term with power p = 1. Similar\nresults were obtained for Scenario 7.\nThe maximum scaled Area Between Curves was\nsmaller than 10% in all scenarios, meaning that even\nthe simulation leading to the worst fitted prediction\ncurve led to a total bias under 10% in all scenarios.\nThe median of the maximum absolute error was\n5.5% across all simulations, and \\7% except for\nScenario 1, meaning that, irrespective of the real data-\ngenerating mechanism, in half of the simulations even\nthe single design point corresponding to the worse fit\nhad an absolute error below 5.5%. When considering\nthe 95th percentile of the same measure, this was just\nbelow 13% overall. Figure 5 (online supplementary\nmaterial) shows that durations corresponding to the\nworst absolute error tended to be in the first part of the\ncurves, where treatment was less effective.\nMean coverage was 95% only for Scenario 5, where\nthe analysis model was correctly specified; however,\nmost scenarios had coverage greater than 80% and\nFigure 6 (online supplementary material) shows that\neven the 100 simulations leading to the worst coverages\napproximated the true duration\u00adresponse curve quite\nwell for a wide variety of scenarios, similar to the ran-\ndomly selected predictions in Figure 1.\nNext, we investigated the sensitivity of these results\nto the choice of design parameters and analysis\nmethods.\nDifferent flexible regression strategies\nWe re-analysed the same simulated data in Table 2\nusing either FP, linear spline with 3 or 5 equidistant\nknots, linear spline with knots concentrated in the first\nhalf of the curve and multivariate adaptive regression\nsplines. Only Scenario 5 is the true model for both data\ngeneration and analysis.\nTable 2. Scaled Area Between Curves (sABC), maxd\nAE(d) and coverage (%) across the eight different scenarios in the base-case\ndesign (1000 simulations of 504 patients randomised across seven arms, using FP).\nsABC maxd\nAE(d) Coverage (%)\nMin 5th percentile Med. 95th percentile Max Med. 95th percentile Mean\nColumn for the 95th percentile of scaled Area Between Curves is in bold, to show how scaled Area Between Curves is smaller, or close to, 5% in all\nscenarios and overall across all 8000 simulations. Asterisks next to Scenario 5 results indicate that this is the only scenario where the data-\ngenerating mechanism is actually a particular case of fractional polynomial on the log-odds scale and therefore performs optimally. sABC is the scaled\nArea Between Curves as defined in the proposals section, while maxd\nAE(d) indicates the maximum absolute error for a single duration\n, Dmax\n) and coverage (%) is defined as the percentage of the true underlying curve included within the point-wise 95% confidence region\naround the estimated curve.\nFor all methods, scaled areas for the fitted predic-\ntion curves were fairly similar (Figure 2(a) and (b)).\nThe only method with slightly inferior performance\nwas five-knot linear spline. FP had the smallest mean-\nscaled Area Between Curves across the eight scenarios,\nbut marginally higher variability between different sce-\nnarios. FP were best in terms of smallest maximum\nabsolute error, while splines better behaved in terms of\ncoverage (Figure 7, online supplementary material).\nFinally, FP had an advantage in terms of monoto-\nnicity, as shown in Figure 3, comparing prediction\ncurves for the simulated data set with the worst fit\n(largest scaled Area Between Curves), across the eight\nscenarios, with FP (red) or three-knot linear spline\n(blue). Spline-based methods led to undulating func-\ntions, particularly in Scenarios 4, 5, 6 and 8, while FP\nprediction curves were smoother and, at least approx-\nimately, monotonously increasing, the only exception\nbeing the worst fit from Scenario 6. Spline-based\nmethods led to even worse prediction curves in other\nscenarios, particularly with smaller sample sizes (e.g.\n250 patients) and with poor knot positioning relative\nto arms, for example, two adjacent knots with no arm\nin between.\nFigure 1. Prediction curves (red) of a random selection of 100 simulations against the true data-generating curve (black) for all the\neight scenarios under the base-case configuration. The base-case scenario assumes a sample size of 504 patients, randomised to\nseven equidistant arms, and fits a fractional polynomial model to estimate the duration\u00adresponse curve.\nTotal sample size\nOne motivation for this study was large sample sizes\noften required for non-inferiority trials. We therefore\ninvestigated the sensitivity of simulation results to total\narms).\nAs expected, increasing total sample size reduced the\nscaled Area Between Curves (second row of Figure 2).\nWith N ! 350, in more than half the scenarios,\nthe 95th percentile for scaled Area Between Curves was\nunder 5%, and in all scenarios for N ! 750. Therefore,\nabove this threshold, whatever the true data-generating\ncurve, in at least 95% of simulated trials, we estimated\na duration\u00adresponse curve whose error was lower\nFigure 2 and Table 2 suggest that our base-case sce-\nnario sample size of 504 might be a reasonable com-\npromise, guaranteeing good estimation of the\nduration\u00adresponse curve without requiring too many\npatients.\nNumber of duration arms\nFigure 4(a) and (b) compares results from allocating the\nrather than the base case of 7 arms.\nThe three-arm design was clearly inferior and gener-\nally led to worse scaled Area Between Curves. All other\ndesigns had similar performance, and particularly dis-\ntributions from 7, 9 and 20 arms appeared virtually\nidentical, suggesting that, compared to a base-case of 7\nFigure 2. Comparison of results of trial simulations from the eight scenarios varying either (1) the flexible regression method used\n(LS3, LS5, LSNE, MARS, FP), with total sample size of 504 patients (panels (a) and (b)), or (2) the total sample size between 250 and\n1000 patients, using FP (panels (c) and (d)). Patients are divided into seven equidistant duration arms. The red horizontal line\nindicates 5% scaled Area Between Curves (sABC). In the left panels, we show the box plots of the whole simulation results, while in\nthe right panels we compare 95th percentiles from the eight scenarios. LS3-5: Linear Spline with 3\u00ad5 knots; LSNE: linear spline with\nnon-equidistant knots; MARS: multivariable adaptive regression splines; FP: fractional polynomials. (a) Comparison of flexible\nregression methods: 8000 simulations. (b) Comparison of flexible regression methods: 95th percentiles. (c) Sensitivity to sample size:\n8000 simulations. (d) Sensitivity to sample size: 95th percentiles.\nduration arms, there is little gain from adding addi-\ntional arms while keeping sample size fixed.\nPosition of arms\nFinally, we investigated the sensitivity of results to the\nposition, rather than the number, of duration arms, by\ncomparing the following:\n The standard seven equidistant arms design;\n A `not-equidistant' arms design, with five arms con-\ndensed in the first part of the curve, that is,\nAs for the linear spline regression model, the motiva-\ntion for this choice is that the early part of the curve is\nwhere the linearity assumption is least likely to hold.\nWith FP, results were similar with both designs\n(Figure 4(c) and (d)). This is mainly because the eight\nscenarios have at most modest departure from linearity\nin the second half of the curve.\nThe three-knot spline regression performed particu-\nlarly poorly with the `not-equidistant' design, highlight-\ning the issue of knot choice with spline-based methods.\nIf knots are chosen inappropriately, for example, two\nadjacent knots with no arms in between, as here, then\nresults may be highly variable. While obvious in this\ncase, similar issues with inappropriate knot positioning\nmight be less trivial to identify in other situations. In\ncontrast, FP regression is standardised and does not\nrequire users to make additional choices.\nExtensions\nHaving demonstrated promising performance of our\nproposed method, several issues remain. The first is\naccounting for uncertainty. Point-wise confidence\nFigure 3. Prediction curves leading to the largest scaled Area Between Curves for each of the eight scenarios with the base-case\ndesign, analysing data either with three-knot linear spline (blue) or fractional polynomials (red).\nbands around the estimated curve can be calculated\nfrom the FP regression and were used here to estimate\ncoverage levels. These intervals were generally quite\nnarrow, the mean width around the estimated cure rate\nranging between 7% and 10% in the base-case scenar-\nios. However, these do not account for model selection\nuncertainty.18 Broadly, since we use the same set of\ndata that we want to analyse to select the final model\nof interest, the usual standard error estimates from the\nmodel tend to be too small. Therefore, a measure of\nprecision of our estimated duration\u00adresponse curve\nwould require methods, such as bootstrap model aver-\nThe second issue is how the estimated duration\u00ad\nresponse curve might be used. Possible approaches that\ndecision makers could take given the estimated curve\ninclude the following:\n1. Estimating the minimum duration that achieves a\ncertain fixed acceptable cure rate (e.g. .80%) ana-\nlogous to a cost-effectiveness acceptability curve,22\ntogether with a CI. We then would be 95% confi-\ndent that the upper bound would give us a cure rate\ngreater or equal to 80%.\n2. Alternatively, if we did not know the true control\nsuccess rate, estimating the duration leading to a\nFigure 4. Comparison of results of trial simulations from the eight scenarios either varying the number of equidistant arms (panels\n(a) and (b)) between 3 and 20, using fractional polynomials (FP), or using different designs, equidistant (ED) or not equidistant\n(NED), comparing four different regression methods (panels (c) and (d)). The total sample size is always 504 patients. The red\nhorizontal line indicates 5% scaled Area Between Curves. In the left panels, we show the box plots of the whole simulation results,\nwhile in the right panels, we compare 95th percentiles from the eight scenarios. In panel (d), there is only one point for NED-LS3,\nsince only in one scenario the 95th percentile for scaled Area Between Curves was smaller than 0.25. LS3: linear spline with three\nknots; LSNE: linear spline with non-equidistant knots; MARS: multivariable adaptive regression splines; FP: fractional polynomials. (a)\nSensitivity to number of arms: 8000 simulations. (b) Sensitivity to number of arms: 95th percentile. (c) Sensitivity to placement of\narms: 8000 simulations. (d) Sensitivity to placement of arms: 95th percentile.\ncertain acceptable loss in efficiency compared to\nthe maximum duration tested, for example, 10%.\n3. The information gathered from the estimated curve\ncould also be combined with other information\nabout toxicity or cost in a decision analytic frame-\nwork. This could be particularly appealing in the\nexample of hepatitis C, where cost is quantifiable,\nbut would be more complex in the antibiotic exam-\nple, where resistance is more complex.\nDiscussion\nWe have proposed a new design for randomised trials\nto find effective shorter durations of treatment, for\nexample, antibiotics, broadening a previous sugges-\ntion.12 The underpinning concept is, instead of directly\ncomparing a limited and arbitrarily chosen number of\nparticular durations, to model the whole duration\u00ad\nresponse curve across a pre-specified range of dura-\ntions, in order to maximise the information gained\nabout the effect of shorter or longer regimens. The\nresulting estimate of the dose\u00adresponse curve could\nthen be used in a variety of clinically meaningful ways.\nBecause of lack of information on the true shape of\nthis duration\u00adresponse curve, we used flexible model-\nling strategies, to protect against parametric model mis-\nspecification. We compared four different strategies,\nthree based on splines and one on FP, concluding that,\nalthough spline-based methods can potentially better\nestimate locally the duration associated with a particu-\nlar cure rate, FP are better at providing a reasonable\ncurve describing the evolution of the cure rate over\ntreatment duration. Binder et al.23 conducted a vast\nsimulation study comparing FP and spline-based meth-\nods, broadly concluding that with large data sets, the\ntwo methods lead to similar results, while in medium-\nsized data sets FP outperform spline-based methods on\nseveral criteria. They also noted that a major advantage\nof FP is the simplicity of implementation in standard\nsoftware packages, compared to the absence of recom-\nmendations regarding appropriate spline-based meth-\nods, matching our conclusions.\nWhile we could have used FP with more than two\npolynomials, we focussed on two to reduce the number\nof parameters, having only a small number of duration\narms in our setting. Similarly, we focussed on the stan-\ndard set of possible powers, but higher powers could be\nconsidered, if thought likely to improve fit. FP and mul-\ntivariate adaptive regression splines' implementation in\nstandard software packages does not allow restriction\nto monotonously increasing functions; since it is reason-\nable to assume monotonicity of the duration\u00adresponse\ncurve, this could be explored in future.\nRegarding design parameters, a modest number of\nequidistant arms, for example, 7, appeared sufficient to\ngive robust results, that is, the resulting prediction curve\nfrom the fit of the model was reasonably close to the\ntrue underlying duration\u00adresponse curve and can there-\nfore provide sufficient information for clinicians about\nthe effect of duration on treatment response. The `not-\nequidistant' design provided similar results with only\nfive arms (but the same number of patients); however,\nsuch a design might be less robust to other shapes of\nthe duration\u00adresponse curve, for example, if the curve\nwas far from linear even in the second part of the dura-\ntion range investigated.\nWhen multi-arm multi-stage designs were first\nmooted, multiple arms were often raised as a theoreti-\ncal barrier to recruitment, but subsequent practice has\ndemonstrated that, if anything, these trials are more\nacceptable to patients, since they ably demonstrate\nequipoise between a substantial number of treatment\nOne legitimate criticism of non-inferiority trials is\nthe arbitrary nature of the non-inferiority margin; in\nour framework, since Dmax\nrepresents the currently rec-\nommended treatment duration, the only arbitrary\nchoice is that of the minimum duration to be consid-\nered, Dmin\n. This choice certainly has a much smaller\nimpact on the trial results than the choice of a non-\ninferiority margin, but nevertheless it is still extremely\nimportant to choose this carefully. Since we lack any\ninformation about the true shape of the duration\u00ad\nresponse curve below the currently recommended dura-\ntion, Dmax\n, a multi-stage adaptive design could be used\nto change the position of Dmin\nif results after a first\nstage clearly showed this to be too long (i.e. the short-\nest duration still leading to high efficacy) or too short\n(i.e. duration extremely ineffective, which might be con-\nsidered unethical to keep randomising patients to).\nHere, we have considered models where the only\ncovariate was treatment duration; however, it would be\ninteresting to investigate the effect of incorporating\nadditional covariate data, such as age and sex. This\ncould be done as a main effect, for example, to adjust\nthe minimum duration needed to achieve a threshold\ncure rate according to other characteristics affecting\ncure; alternatively, this could be done as an interaction,\nproviding a different duration\u00adresponse curve for speci-\nfied subgroups, for example, males versus females.\nEither would allow stratified or personalised medicine,\nallowing clinicians to prescribe different durations\naccording to key patient characteristics.\nThe underpinning motivation for this article was a\nphase IV trial design to identify minimal effective anti-\nbiotic treatment duration, and the design could be\napplied to other similar situations. However, an evalua-\ntion of the inferential properties of the methodology is\nkey before recommending it in these late-phase settings;\nin particular, preservation of type I error rate is funda-\nmental, as these are treatments that are known to be\neffective, and recommending an insufficiently long\nduration could potentially have serious public health\nconsequences. Once this is done, examples of applica-\ntions may include phase III trials in tuberculosis, where\nshorter treatment durations could improve adherence\ncompared to standard-of-care control duration, or\nphase IV trials in hepatitis C where current treatment\nregimens achieve cure in .95% of patients but are\nextremely costly. Similar approaches could be applied\nto dose-intensity of chemotherapy regimens.\nThe problem addressed here has similarities with\nthat of finding the optimal treatment dose in early-\nphase clinical trials. There is a vast literature on meth-\nods for modelling dose\u00adresponse relationship to find\noptimal treatment doses.25,26 However, there are\nimportant differences making it difficult to use those\nmethods in our situation. The sample sizes required are\nmuch smaller in dose\u00adresponse studies because the\nguiding principle is to start with a low dose and to\nincrease it, avoiding exposing too many patients to\nexcessive, and thus unsafe, doses. This is usually done\nbefore the drug has actually been tested in phase II\u00adIII\ntrials. The power of these methods to identify the cor-\nrect minimum effective dose is therefore often quite\nlow.27 With larger sample sizes, methods like the\nContinual Reassessment Method become infeasible,\nmost of all in the example of tuberculosis where treat-\nment may last several months. Furthermore, in early-\nstage trials, the focus is often on pharmacokinetics, and\nthe specific forms of the dose\u00adresponse curves used\nusually derive from the underlying pharmacokinetic\nmodels for drug absorption into the bloodstream.\nIn conclusion, our proposed new paradigm for clinical\ntrials to optimise treatment duration has the potential to\nrevolutionise the design of trials where reducing treat-\nment duration is our goal, for example in the fight against\nantimicrobial resistance. Our approach moves away from\nmultiple inefficient trials of arbitrary antibiotic durations\nthat may all be suboptimal. We have shown how certain\ndesign parameters may affect the fit of a flexible regres-\nsion strategy to model the duration\u00adresponse curve.\nRandomising approximately 500 patients between a mod-\nerate number of equidistant arms (5\u00ad7) is sufficient under\na range of different possible scenarios to give a good fit\nand describe the duration\u00adresponse curve well. Further\nwork on how to use this estimated curve to draw infer-\nence, controlling power and type I error rate, will follow.\n"
}