{
    "abstract": "Abstract\nGrowth mixture model (GMM) is a flexible statistical technique for analyzing longitudinal data when there are unknown\nheterogeneous subpopulations with different growth trajectories. When individuals are nested within clusters, multilevel\ngrowth mixture model (MGMM) should be used to account for the clustering effect. A review of recent literature shows\nthat a higher level of nesting was described in 43% of articles using GMM, none of which used MGMM to account for the\nclustered data. We conjecture that researchers sometimes ignore the higher level to reduce analytical complexity, but in\nother situations, ignoring the nesting is unavoidable. This Monte Carlo study investigated whether the correct number\nof classes can still be retrieved when a higher level of nesting in MGMM is ignored. We investigated six commonly used\nmodel selection indices: Akaike information criterion (AIC), consistent AIC (CAIC), Bayesian information criterion (BIC),\nsample size\u00adadjusted BIC (SABIC), Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test (VLMR), and adjusted Lo\u00adMendell\u00adRubin\nlikelihood ratio test (ALMR). Results showed that accuracy of class enumeration decreased for all six indices when the\nhigher level is ignored. BIC, CAIC, and SABIC were the most effective model selection indices under the misspecified\nmodel. BIC and CAIC were preferable when sample size was large and/or intraclass correlation (ICC) was small, whereas\nSABIC performed better when sample size was small and/or ICC was large. In addition, SABIC and VLMR/ALMR tended to\noverextract the number of classes when there are more than two subpopulations and the sample size is large.\n",
    "reduced_content": "journals.sagepub.com/home/sgo\nCreative Commons CC BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of\nthe work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages\n(https://us.sagepub.com/en-us/nam/open-access-at-sage).\nArticle\nIntroduction\nMultilevel growth mixture model (MGMM) is a relatively\nnew modeling technique for extracting unknown subpopula-\ntions in multilevel longitudinal data. This technique inte-\ngrates multilevel modeling, finite mixture modeling, and\nstructural equation modeling (Asparouhov & Muth\u00e9n, 2008;\nB. Muth\u00e9n, 2004). The multilevel aspect of MGMM is attrac-\ntive to applied researchers because longitudinal data are\noften collected through cluster sampling, which creates mul-\ntilevel data structure with repeated measures nested within\nindividuals and individuals further nested within organiza-\ntions. Some examples are students nested within classrooms/\nschools/neighborhoods (e.g., Dettmers, Trautwein, L\u00fcdtke,\nKunter, & Baumert, 2010), children/couples nested within\nfamilies (e.g., Jenkins, Dunn, O'Connor, Rasbash, & Behnke,\nindividuals nested within countries (e.g., Matsumoto,\nNezlek, & Koopmann, 2007), clients nested within therapists\n(e.g., Marcus, Kashy, & Baldwin, 2009), and individuals\nnested within organizations (e.g., Vancouver, 1997).With\nmultilevel longitudinal data, unknown subpopulations can be\nextracted at the individual level as well as the organization\nlevel (Palardy & Vermunt, 2010). In addition, researchers\ncan study the associations between organizational character-\nistics and individual growth patterns (note: in this article, the\nterms class and subpopulation are used interchangeably). It\nshould be noted that other methods, such as item response\ntheory (e.g., Bartolucci, Pennoni, & Vittadini, 2011), can be\nused to account for longitudinal data structure in the analysis\n1University of North Texas, Denton, USA\n2Texas A&M University, College Station, USA\n3University of California, Riverside, USA\nCorresponding Author:\nQi Chen, Department of Educational Psychology, University of North\nEmail: qi.chen@unt.edu\nThe Efficacy of Common Fit Indices for\nEnumerating Classes in Growth Mixture\nModels When Nested Data Structure Is\nIgnored: A Monte Carlo Study\nQi Chen1, Wen Luo2, Gregory J. Palardy3, Ryan Glaman1,\nand Amber McEnturff1\n Keywords\ngrowth mixture model, multilevel model, class enumeration, fit index, clustered data\n2 SAGE Open\nof latent traits as well, but the focus of the current article is\non MGMM. Due to space constraints, interested readers may\nfind more detailed technical information on MGMM in\nChen, Kwok, Luo, and Willson (2010). Also note that the\ncurrent article uses many acronyms throughout; therefore,\nfor reference, a list of these acronyms and what they denote\nis provided in the appendix.\nTo investigate the prevalence of the higher level nesting in\ngrowth mixture model (GMM), we reviewed 158 substantive\narticleswith196GMMsfoundinthePsycInfodatabasebetween\n85 GMMs (43%), none of which used MGMM to address it.\nNevertheless, nine articles addressed the clustering by reporting\na low degree of clustering or using adjusted standard errors.\nOur review shows that multilevel longitudinal data are\ncommon, but when applying GMMs, many empirical\nresearchers ignore the highest level of nesting, potentially\nviolating the assumption of independence (e.g., Boscardin,\nMuth\u00e9n, Francis, & Baker, 2008; D'Angiulli, Siegel, &\nMaggi, 2004). Some reasons for ignoring a level of nesting\nare avoidable, such as reducing analytic complexity and\nreducing the difficulty in achieving convergence in model\nestimation, while others are inevitable such as lack of identi-\nfiers (IDs) for higher level units.\nThe literature has demonstrated that if the nonindepen-\ndence is not accounted for, parameter estimates and standard\nerrors in a multilevel regression model could be biased\n(Moerbeek, 2004). In MGMM, ignoring a higher level of\nnesting structure could result in lower classification accu-\nracy, overestimated lower level variance components, and\nbiased standard errors, which affect significance tests for\nIn mixture modeling, one important yet challenging issue\nis extraction of the correct number of latent classes (e.g.,\nrecent years, many researchers have investigated the perfor-\nmance of various model selection indices in identifying the\ncorrect number of classes in different types of mixture mod-\nels with different data structures (i.e., Allua, 2007; Clark &\nmodels used in simulation studies vary and the best perform-\ning indices differ, Bayesian information criterion (BIC;\nSchwartz, 1978), sample size\u00adadjusted BIC (SABIC; Sclove,\n1987), and the Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio\ntest (VLMR; Lo, Mendell, & Rubin, 2001) consistently per-\nformed well for model selection with single-level data.\nHowever, the influence of ignoring a level of nesting on\nclass enumeration for MGMM has not yet been fully investi-\ngated. Because ignoring a higher level may be inevitable in\nsome circumstances as described above, an understanding of\nfit index performance in those situations is warranted. As\nshown in previous studies on multilevel analysis (e.g., Chen\nignoring the highest level data structure results in the redistri-\nbution of variance from the ignored level (i.e., the organiza-\ntion/school level) to the adjacent level (i.e., the individual/\nstudent level). It is unclear if this redistribution of variance\nwill affect model selection index performance. It is important\nto determine whether the recommended model selection indi-\nces can extract the correct number of classes when ignoring a\nhigher level of nesting structure is inevitable and to provide\nresearchers with recommendations on using these indices.\nPurpose of the Study\nThe purpose of this study is to (a) investigate whether the\ncorrect number of classes can be identified using various\ncommonly used model selection indices when the MGMM is\nmisspecified to omit the higher level and (b) identify factors\nthat affect the index performance for class enumeration when\nthe model is misspecified. The current study extends work by\nChen et al. (2010) in several ways. First, whereas Chen et al.\nfocused on the accuracy of classification of individuals and\nthe statistical properties of the parameter estimates (i.e., Type\nI error rate and statistical power) for each subpopulation,\nconditional upon the correct number of classes being identi-\nfied, the current study addresses whether the correct number\nof classes can be enumerated using various model selection\nindices under both true and misspecified models. This is an\nimportant advancement for applying the MGMM given that\nindividual class solutions and corresponding class models\ncan only be further examined and interpreted after the cor-\nrect number of classes is identified. To that end, the current\nstudy examines the efficacy of six commonly used indices\nfor class enumeration in GMM.\nCompared with Chen et al. (2010), the current study has\nbeen expanded to examine one additional design factor by\nincluding a true model with three latent classes. Furthermore,\nwe apply some suggested cutoff values for comparing differ-\nent information criteria between competing models (e.g.,\ndelta-BIC, Raftery, 1996) whereas previous studies examin-\ning the sensitivity of the information criteria did not account\nfor the magnitude of that difference.\nWe begin by reviewing the development and specification\nof MGMM, followed by a brief review of various commonly\nused model selection indices, and a review of recent studies\nexamining the model index performance. In the simulation\nstudy, we first examined a two-subpopulation case (Study 1),\nfollowed by a three-subpopulation case (Study 2), because\nthe number of subpopulations may affect the model selection\nindices' performance. In addition to the number of subpopu-\nlations, we investigated the effect of another type of model\ncomplexity in Study 3.\nBrief Review of MGMMs\nThe development of MGMMs drew upon several lines of\nresearch (Palardy & Vermunt, 2010), namely, latent growth\nChen et al. 3\ncurve modeling (LGCM; Bollen & Curran, 2006), latent\nclass growth analysis (LCGA; Nagin, 1999), and GMM (B.\nMuth\u00e9n, 2004). Combining LGCM and LCGA, GMM is a\nmore general modeling framework capable of examining\nboth the unknown heterogeneous subpopulations and the\nrandom variation of the latent growth factors within classes.\nHowever, GMM does not consider the situation of multi-\nlevel data in which individuals are nested within organiza-\ntions. Hence, GMM cannot handle nonindependence of\nindividuals due to clustering. Existing research has explored\nmethods of accounting for nonindependence of observations\nin mixture modeling and GMM (Asparouhov, & Muth\u00e9n,\nJones, & Ng, 2006). An extension to GMM, MGMM con-\nsiders nonindependence of individuals by specifying a\nmodel for each level of the multilevel data. The model for\nthe individual and organizational levels can be different,\ndepending on whether heterogeneity is assumed and/or ran-\ndom effects at both the individual level and the organiza-\ntional level growth trajectories are modeled. This article\nfocuses on the more common MGMM with classification at\nthe individual level (e.g., students being classified into dif-\nferent subgroups within schools; patients being classified\ninto different subtypes within clinics) and no classification\nat the organizational level.\nBrief Review of Model Selection Indices\nAcombination of substantive knowledge and statistical crite-\nria has been recommended for selecting the optimal number\nof classes in GMM (B. Muth\u00e9n, 2003). Generally, model\nselection statistics can be grouped into four categories: (a)\ninformation-based criteria, (b) nested model likelihood ratio\ntests (LRTs), (c) goodness-of-fit measures, and (d) classifica-\ntion-based statistics (Henson et al., 2007; Tofighi & Enders,\nthe information-based criteria and the nested model LRTs are\nthe most recommended for determining the number of\nEnders, 2008). Hence, the model selection indices from these\ntwo categories are the focus of this study and are briefly\nreviewed below.\nInformation criterion (IC) indices are based on the log-\nlikelihood value of a fitted model and typically penalize\nmodel complexity and/or take sample size into account. IC\nusually takes the form of -2log L plus a penalty and sample\nsize adjustment, where L is the maximized likelihood. The\nmost commonly used indices include Akaike information\ncriterion (AIC; Akaike, 1987), consistent AIC (CAIC;\nBozdogan, 1987), Bayesian information criterion (BIC), and\nsample size\u00adadjusted BIC (SABIC). For a particular sample\nand model, the -2log L is constant. Differences in the pen-\nalty terms distinguish the indices and may result in different\noptimal class enumeration solutions. These fit indices are\ndefined below, respectively:\nAIC = - +\nlog ,\nCAIC = - + ( )+\n( )\nlog log ,\nL p N (1b)\nBIC = - + ( )\n2log log ,\nL p N (1c)\nSABIC = - +\n+\n\n\n\n\n\n\nlog log ,\nL p\nN\nwhere p is the number of free parameters in the model and N\nis the number of subjects. Generally, as a model becomes\nmore complex (i.e., more parameters and larger p), the likeli-\nhood increases and -2log L decreases. IC indices favor\nmodels with a relatively higher likelihood value and rela-\ntively fewer parameters. Thus, lower IC values indicate a\nbetter trade-off between model fit and complexity. For a par-\nticular sample and model, the -2log L is constant. However,\ndifferences in the penalty functions (e.g., penalizing model\ncomplexity) of different model selection indices result in\ninconsistent class solutions (i.e., different indices may favor\ndifferent class solutions). Previous research on mixture\nmodel estimation also suggests sample size plays a role in\npenalty calculations (Leroux, 1992), and that penalties must\nfulfill two criteria for consistent mixture model estimation:\nFirst, as N approaches infinity, penalty / N should become\ncloser to zero. Second, as N approaches infinity, log(N) / pen-\nalty should become closer to zero (Keribin, 2000). Note that\nthe CAIC, BIC, and SABIC fulfill these two conditions.\nThe IC statistics take both model fit and complexity into\nconsideration. Lower values indicate better trade-off between\nmodel fit and complexity. Sometimes, the IC difference\nbetween two models is so small that the evidence to support\none model over the other becomes very weak. Some guide-\nlines for interpreting the absolute IC difference between two\nmodels have been proposed. Petras and Masyn (2010) rec-\nommended the \"elbow criterion\" to determine the optimal\nnumber of classes when using IC indices (i.e., AIC, BIC,\nSABIC). Specifically, they recommended graphing the val-\nues of IC indices against the increasing number of classes,\nand looked for the pronounced angle in the plot where the\ndecrease of IC value dropped. As plotting for all replications\nwas unrealistic, we used cutoff criteria that mimic looking\nfor the \"elbow point.\"\nBesides their statistical differences, the AIC and BIC also\nhave different philosophical contexts (Bauer & Curran,\n2004). AIC aims at finding the model that minimizes the\nKullback\u00adLeibler (K-L) criterion, selecting an approximate\nmodel, and providing better predictions of the population\nparameters. On the contrary, BIC targets the \"true\" underly-\ning model with the highest posterior probability. It depends\non the purpose of model selection and the nature of reality\nwhen deciding which model selection index to use. AIC and\nBIC were designed for different applications, and both appli-\ncations can arise in multilevel (growth) mixture modeling.\n4 SAGE Open\nThe nested model LRTs include the VLMR, the adjusted\nLo\u00adMendell\u00adRubin likelihood ratio test (ALMR; Lo et al.,\n2001), and the bootstrap likelihood ratio test (BLRT;\nMcLachlan & Peel, 2000). All these statistics are developed\nusing LRT and test the null hypothesis that the restricted\nmodel with k - 1 classes fits the data as well as the less\nrestricted model with k classes. The test statistic for a likeli-\nhood ratio (LR) test is defined by\nLR = -\n\n\n\n\n\n\nlog ,\nL\nLu\nwhere L\nand L\nu\nare the maximized likelihood for the more\nand less restricted models, respectively (Agresti, 1996).\nUnder the context of mixture model, the LR for (k - 1)-class\nmodel versus k-class model is not asymptotically distributed\nas a chi-square, so the normal chi-square difference test is\nnot applicable. Therefore, Lo et al. (2001) derived an approx-\nimate reference distribution for the LR in the mixture context\nby extending Vuong's (1989) work called the Vuong\u00adLo\u00ad\nMendell\u00adRubin likelihood ratio test (VLMR). Furthermore,\nLo et al. (2001) proposed an ad hoc adjustment to VLMR\n(i.e., ALMR--adjusted Lo\u00adMendell\u00adRubin likelihood ratio\ntest), which is defined by\nLR\nLR\nadjusted\np q n\n=\n+ -\n( )\n\n \n\n-\nlog\n,\nwhere p k\n= -\nand q k\n= -\n-component normal\nmixture and k1\n-component normal mixture (with k0\nboth to be known constants and k k\n< ). A small p value\n(e.g., p < .05) indicates that the (k - 1)-class model should be\nrejected in favor of the k-class model, while a large p value\n(e.g., p  .05) indicates the k - 1 and k-class solutions fit the\ndata equally well, and the simpler model (with k - 1 classes)\nis preferable. The testing logic of BLRT is similar to that of\nVLMR and ALMR. BLRT was not considered in this article\nbecause it is not available under the MGMM model. Readers\nmay see Nylund et al. (2007) for more details. It should be\nnoted that the conditions for the ALMR theorem are not gen-\nerally satisfied in the context of mixture models (Jeffries,\n2003); nevertheless, the ALMR has been shown to be effec-\ntive in recovering the number of underlying components\nReview of Studies on Performance of Model\nSelection Indices\nRecently, researchers have studied the performance of these\nmodel selection indices in nonclustered data in the context of\nEnders, 2008), latent profile analysis (Morgan, Hodge, &\nBaggett, 2016), latent variable mixture model (Henson et al.,\nlatent Markov model (Bacci, Pandolfi, & Pennoni, 2014). A\nfew studies have searched for the optimal model selection\nindices for clustered/multilevel data in LCA(Clark & Muth\u00e9n,\nTable 1 summarizes these studies, showing the models and\nindices examined, as well as the best performing or recom-\nmended fit indices for class enumeration in each study. As\nshown in the table, although the types of mixture models vary,\nthey seem to agree on the use of SABIC, BIC, and VLMR/\nALMR for model selection in single-level data.\nA few studies have searched for the optimal model selec-\ntion indices for clustered/multilevel data. In LCA, using\nstandard error corrections for clustered data, Clark and\nMuth\u00e9n (2007) found that for simple structure data (i.e.,\nlatent classes with parallel profiles), none of the studied indi-\nces performed well, whereas for complex data structure (i.e.,\nlatent classes with crossing profiles), BIC and SABIC per-\nformed relatively better. For multilevel FMM, which is a\nmultilevel extension of the factor analysis model for cross-\nsectional datasets with a hierarchical structure, Allua (2007)\nfound that BIC, SABIC, and ALMR performed better in situ-\nations when there was only one class in the population; AIC\nand ALMR performed better in situations when there were\ntwo classes. However, Allua (2007) did not identify any con-\nsistently well-performing model selection index for the mul-\ntilevel FMM. Lukociene and Vermunt (2010) compared the\nperformance of alternate fit indices in multilevel mixture\nmodel with focus on determining the true number of mixture\ncomponents at the organization level. They raised the inter-\nesting point that the N for BIC and CAIC computations is\nunambiguous for single-level mixture evaluation but ambig-\nuous for multilevel mixture evaluation. Their results sup-\nported defining N as the number of groups when picking\nclasses that exist at the highest level.\nIn summary, the literature suggests BIC and SABIC per-\nformed best for class enumeration for both single-level and\nmultilevel mixture models. However, no study explicitly exam-\nined which indices perform best when the higher level of nest-\ning is ignored in the context of MGMM. In addition, none of\nthe current widely used fit indices for class enumeration was\ndesigned/developed for testing multilevel models. It would be\ninteresting to see if using the individual level N would be suf-\nficient for the more common MGMM. To address this short-\ncoming in the literature, this study tests the performance of six\ncommonly used model selection indices in MGMM with con-\ntinuous outcomes, includingAIC, CAIC, BIC, SABIC,VLMR,\nand ALMR, all of which except for CAIC are available in\nmances of these indices are compared under the correct model\nspecification, which includes the higher level of the nesting to\naccommodate the clustered data structure, and under the mis-\nspecified model, where the higher level is ignored. This study's\nresults can provide insights into the robustness of the model\nselection indices when a higher level in MGMM is ignored\nunder a variety of design conditions as well as the best practice\nto use when such misspecification is inevitable.\nTable 1. Summary of Recent Studies Examining Performance of Model Selection Fit Indices in Mixture Models.\nReference\nModel(s) studied\nIndices studied Better reforming indices\nName Design Type\nYang (2006) Latent class analysis Cross-sectional Dichotomous AIC, CAIC, BIC, SABIC, DBIC,\nSABIC\nHenson, Reise, and\nLatent variable\nmixture model\nCross-sectional Continuous AIC, CAIC, BIC, SABIC, VLMR, ALMR,\nCLC, ICL-BIC, NEC, entropy, MST,\nMKT\nNylund, Asparouhov,\nLatent class analysis Cross-sectional Dichotomous or\ncontinuous\nBLRT\nFactor mixture model Cross-sectional Categorical\nGrowth mixture\nmodel\nLongitudinal Continuous\nTofighi and Enders\nGrowth mixture\nmodel\nLongitudinal Continuous AIC, CAIC, BIC, SABIC, VLMR, ALMR,\nMorgan, Hodge, and\nLatent profile analysis Cross-sectional Continuous AIC, AICc, CAIC, BIC, SABIC, DIC,\nICL-BIC, entropy, ALMR\nClark and Muth\u00e9n\nLatent class analysis Cross-sectional,\nclustered\nDichotomous AIC, BIC, SABIC None for simple structure data, BIC, SABIC for\ncomplex data structure\nmixture model\nCross-sectional,\nclustered\nContinuous AIC, BIC, SABIC, ALMR BIC, SABIC, ALMR better when only one class in\npopulation; AIC, ALMR better when two classes\nin population.\nLukociene and\nMultilevel mixture\nmodel\nCross-sectional Binary BIC, AIC, AIC3, CAIC, ICOMP,\nvalidation log-likelihood\nBIC, CAIC, ICOMP under large separation, AIC\nunder low separation and small group size\nmodel\nLongitudinal Continuous AIC, CAIC, BIC, DBIC, HQ, HT-AIC,\nNHT-AIC, Entropy, NEC, CLC, ICL-\nFor k = 1, CLC, ICL-BIC, and NICL-BIC. For k =\n3, entropy and HT-AIC for small sample, simpler\nmodel; HT-AIC and entropy for more complex\nmodel with small sample; BLRT for more\ncomplex model with large sample.\nBacci, Pandolfi, and\nLatent Markov model Longitudinal Categorical BIC, AIC, AIC3, AICc, CAIC, NEC,\nNEC1 and NEC2 account for all numbers of time\npoints and latent classes tested.\nNote. Alphabetized fit indices. AIC = Akaike information criterion; AICc = corrected Akaike's information criterion; AIC3 = A variant of AIC that uses 3p as the penalty term; ALMR = adjusted\nLo\u00adMendell\u00adRubin likelihood ratio test; BIC = Bayesian information criterion; BLRT = bootstrap likelihood ratio test; CAIC = consistent AIC; CLC = classification likelihood information criterion; DBIC\n= Draper BIC; DIC = deviance information criterion; HQ-IC = Hannan\u00adQuinn information criterion; HT-AIC = Hurvich\u00adTsai AIC; ICL-BIC = integrated classification likelihood (BIC approximation);\nICOMP = Bozdogan's information complexity criterion; LMR = Lo\u00adMendell\u00adRubin likelihood ratio test; MKT = multivariate kurtosis test; MST = multivariate skewness test; NBIC = sample size\u00adadjusted\nBIC; NC-AIC = sample size\u00adadjusted CAIC (aka SACAIC); NCS = traditional chi-square difference test; ND-BIC = sample size\u00adadjusted DBIC; NEC = normalized entropy criterion; NHQ = sample\nsize\u00adadjusted Hannan\u00adQuinn information criterion; NHT-AIC = sample size\u00adadjusted HT-AIC; NICL-BIC = sample size\u00adadjusted ICL-BIC; SABIC = sample size\u00adadjusted BIC (aka NBIC); SACAIC =\nsample size\u00adadjusted CAIC (aka NC-AIC); VLMR = Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test.\n6 SAGE Open\nStudy 1: Two-Class Case\nMethod\nData generation. Data with two known subpopulations under\na three-level model (e.g., repeated measures nested within\nstudents and students nested within schools) were first gen-\nerated. The three-level model for data generation is shown\nbelow:\nY Time e\ntij ij ij tij tij\n= + ( ) +\n \nwith\ne N\ntij\n~ , .\n\n( )\n\nij j j ij ij\nsubpopulation r\n= + +\n\nij j j ij ij\nsubpopulation r\n= + +\nwith\nr\nr\nMVN\nij\nij\n\n\n\n\n\n =\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n~ , .\n \n \n \n \n  \u00b5\nj j\n= + , (2f)\n \nj\n \nj\n \nj\n= ,\nwith\n\u00b5 \n\nj\nN\n~ , ,\nwhere the time variable ( )\nTime tij\nwas centered and had val-\nij\nwas a dichot-\nomized variable with 0 and 1 representing two different\nsubpopulations. The subscript t represents the measurement\noccasions (t = 1, 2, 3, 4), the subscript i represents the indi-\nviduals (i = 1 . . . n\nj\n), and the subscript j represents the clusters\n(j = 1 . . . J). We used four repeated measures for all simula-\ntion conditions because (a) previous studies found no signifi-\ncant effect of the number of repeated measures on model\nestimation, and (b) four waves of repeated measures were\nmost commonly used in both simulation studies (Enders &\nand empirical studies (Khoo, West, Wu, & Kwok, 2006).\nIn this three-level model, four fixed effect coefficients\n(i.e., \n, \n, \n, and \n) and five variances and covariances\nof the random effects (i.e., 2, \n, \n, \n, \n) needed to\nbe specified. The average growth models for the two sub-\npopulations were specified as follows so that Subpopulation\nA represents a low-start and slow-growing group and\nSubpopulation B represents a high-start and fast-growing\ngroup:\nSubpopulation A:\nY Time\ntij\ntij\n = + \u00d7( )\n. . , (3a)\nSubpopulation B:\nY Time\ntij\ntij\n = + \u00d7( )\n. . . (3b)\nBased on the settings presented in Equations 2a and 2b,\n\n, \n, \n, and \ntively. The residual variance was set to 2 = 1.0.\nDesign factors. Previous simulation studies have identified\nsome important design factors that may affect the perfor-\nmance of the model selection indices. First, the degree of\nclass separation dramatically impacts enumeration of the\ncorrect number of classes; if the generated classes are\nwell-separated, the correct number of classes is more eas-\nily identified (Henson et al., 2007; Tofighi & Enders,\n2008). Second, the latent class mixing proportions have a\nsubstantial impact on class enumeration (Enders & Tofighi,\nunbalanced situations where one latent class has an\nextremely low mixing proportion (e.g., 7% in Tofighi &\nless likely to converge and the class enumeration is less\naccurate. Third, sample size influences model selection\nindex performance in class enumeration, performing better\nwith larger sample sizes (Henson et al., 2007; Tofighi &\nEnders, 2008). Given these findings, we manipulated five\ndesign factors: degree of separation, conditional intraclass\ncorrelation (ICC), number of clusters, cluster size, and\nlatent class mixing proportions.\nDegree of separation.We manipulated the magnitude\nof the T\nmatrix, which includes the within-class vari-\nance parameters (see Equation 2e), to produce different\ndegrees of separation. Although some research has imple-\nmented algorithms that generate mixture distribution data\nusing data characteristics such as pairwise overlap between\nclasses (e.g., Maitra & Melnykov, 2010; Melnykov, Chen,\n& Maitra, 2012), we manipulated the magnitude of the T\nmatrix because other research has shown that it is a suffi-\ncient method for generating data from a mixture distribution\n(e.g., Chen et al., 2010). Holding the mean growth factors\nof the two subpopulations constant, the larger the variation\nof individual growth trajectories within each subpopulation,\nthe more overlapping and less separated the two subpopula-\ntions are. Following Raudenbush and Liu's (2001) criteria,\nChen et al. 7\nwe used T1\n=\n\n\n\n\n\n =\n\n\n\n\n\n\n \n \n \n \n. .\n. .\nas small T\nand\n=\n\n\n\n\n\n =\n\n\n\n\n\n\n \n \n \n \n. .\n. .\nas medium T\n. As illus-\ntrated in Figures 1 and 2, with the small T1\nmatrix, the two\nsubpopulationsonlyoverlapslightlyatthefirsttimepointbutdo\nnot overlap at the subsequent time points1, indicating a medium\nlevel of separation. However, with the medium T2\nmatrix, the\ntwo subpopulations overlap at all four time points, indicating\na low level of separation.\nConditional ICC.We selected two levels of conditional\nICC, .10 and .20, to represent small clustering effect and\nmedium clustering effect (Hox, 2010). Based on the condi-\ntional ICC and \n\nmatrix, the value of \nwas determined\nby conditional ICC = + +\n   \n  \n/ ( ). Hence, \n\nand the T\n\nmatrix was medium, 0.275 when the conditional\nICC was .20 and the T\n\nthe conditional ICC was .20 and the T\n\nmatrix was medium.\nNumber of clusters.We considered three levels for the\nmultilevel modeling from five journals devoted to school\npsychology research and practice. For the 27 studies, the\ncluster number (e.g., number of schools) had a mean of 28\nand a minimum of 17. However, we use 30 as the minimal\nnumber of clusters because the multilevel modeling research\ndesign literature suggests at least 30 clusters are needed to\nprovide unbiased estimates of fixed and random effects that\ncan be expected to replicate in repeated samples from the\nWe included 50 and 80 as medium and high cluster number\nlevels, which enables our simulation study to mimic applied\nstudies with higher cluster numbers and/or in areas other\nthan school psychology, and allows us to examine the impact\nof a broader range of cluster numbers and overall sample size\ncombinations on the estimation of the MGMMs.\nCluster size. We selected two levels for cluster size: 20 and\n40 individuals per cluster. Based on Graves and Frohwerk's\nThe level of 40 individuals per cluster was close to the mean\ncluster size while the level of 20 individuals per cluster was\nTo further justify the sample size conditions, we con-\nducted a literature search in PSYCINFO (from year 2000 to\n2011) for empirical studies applying GMM in different sub-\nstantive areas. We found a total of 171 studies; however, only\none recent study used MGMM (i.e., Tobler & Komro, 2010).\nAfter removing eight studies with extreme sample sizes, the\noverall sample size of the remaining 163 studies ranged from\ncluster size (20, 40), the combined/overall sample size in our\nsimulation study covered a wide range (i.e., from 600 to\n3,200) that is common in applied studies in social sciences.\nMixing proportion. The mixing proportions of the two sub-\npopulations were set to be balanced or unbalanced. In the\nbalanced situation, mixing proportion was set to 50% and\n50% for the two subpopulations. In the unbalanced situation,\nthe mixing proportion was set to 25% for the low-start and\nslow-growing group and 75% for the high-start and fast-\ngrowing group, to mimic a situation in school setting where\nthe majority of students develop their reading skills quickly\n(Nylund et al., 2007). We did not consider a more extreme\nunbalanced situation because previous research found that\nmodels with extreme population mixture proportions (i.e.,\n10% or less) of a subpopulation were less likely to converge\nand the class enumeration was less accurate (Henson et al.,\nIn summary, the simulation used a 2 (degree of separa-\ntorial design to generate the data. A total of 500 replications\nwere generated for each condition using the SAS 9.2 Proc\nY\nTime\nSubpopulaon A\nSubpopulaon B\nFigure 1. Mean growth trajectories with error bars for small\nT\nmatrix (medium separation).\nY\nTime\nSubpopulaon A\nSubpopulaon B\nFigure 2. Mean growth trajectories with error bars for medium\nT\nmatrix (low separation).\n8 SAGE Open\ndatasets \u00d7 48 conditions). For each replication, six different\nmodels--that is, 2 model specifications (true/misspecified)\n\u00d7 3 different class solutions with different numbers of\nclasses (1, 2, and 3) = 6 models--were fitted using the\n2010); analyses were conducted using the MLR (MLR is a\nrobust maximum likelihood estimator that uses a Huber-\nWhite sandwich approach to adjust standard errors for non-\nnormality) estimator. The number of initial stage random\nstart values was initially set to 50 and the number of final\nstage optimizations was set to 10. If there were any conver-\ngence issues during analysis, the number of random starts\nwas increased.\nAnalysis. All 24,000 datasets had converged results for fitted\nmodels and a reasonable number of observations in each\nlatent class (i.e., class size no less than 6% of the total sample\nsize). The performance of a model selection index was mea-\nsured by the proportion of replications in which the index\nretrieved the correct number of classes.\nCriterion for determining success in class enumeration.For\nAIC, differences less than 2 suggest no credible evidence as\nto which model is better, differences between 2 and 4 weak\nevidence, differences between 4 and 7 definite evidence, dif-\nferences between 7 and 10 strong evidence, and differences\nlarger than 10 very strong evidence (Burnham & Anderson,\n2002). We adopted the cutoff value of 4 points; specifically,\nfor AIC to select the correct two-class solution, it had to\nsatisfy two requirements. First, the two-class AIC had to be\nsmaller than the one-class and three-class AIC. Second, the\ntwo-class AIC had to be 4 or more points smaller than the\none-class AIC. Based on the K-L information theory, AIC\ndifferences can be converted to Akaike weight wi\n2 for each\nThe Akaike weight of a model can be interpreted as the prob-\nability associated with the model. Table 2 shows the Akaike\nweights for the one-class, two-class, and three-class solu-\ntions when AIC\nis 4 points less than AIC\n. We can\nsee that using our rule, the two-class solution always has the\nhighest probability, even when the difference between the\ntwo-class and three-class AIC is small.\nFor BIC, differences less than 2 suggest weak evidence,\ndifferences between 2 and 6 positive evidence, differences\nbetween 6 and 10 strong evidence, and differences larger\nthan 10 very strong evidence (Raftery, 1996). The difference\nin BIC can also be converted into relative probability. For\ninstance, if the two-class BIC is 2 points less than the one-\nclass BIC, the Bayes factor for a two-class model against a\n -\nexp(( ) / )\n), and\nthe posterior probability associated with the two-class solu-\nvalue of 2 points for the BIC.\nFor CAIC and SABIC, no guideline has been proposed\nbefore. We used 2 as their cutoff values because they are\nsimilar to BIC in computation.\nAs previously mentioned, different rules were used to select\nbest-fitting models for VLMR and ALMR. Because these two\nindices use a significance test, when testing the k-class model (k\n> 1), there are two possible decisions. When the p value of these\nindices is equal or smaller than .05, the k-class model would be\nselected over the (k - 1)-class model; when the p value is larger\nthan .05, there is a lack of evidence for significant improvement\nand therefore the more parsimonious model--that is, (k -\n1)-class model--is selected (Lo et al., 2001). The procedure for\ndetermining the best model (see Figure 3) begins with the two-\nclass model, and continues until a comparison of the k-class\nmodel, and the (k + 1)-class identify the k-class solution as the\nbetter model. We stopped at the three-class model because our\ninterest was in whether the correct number of classes was identi-\nfied and any decision other than the two-class solution would be\nconsidered a wrong decision.\nDifference between true and misspecified models. We exam-\nined how differently the indices performed under the true\nmodel (i.e., consider the higher level) and the misspecified\nmodel (i.e., ignoring the higher level). The accuracy of each\nindex under the true and misspecified models was compared\nand differences were computed.\nImpact of the design factors.ANOVAs were conducted\nto determine the impact of the five design factors on the\nfit indices' class enumeration accuracy. The percentage\nof correct model identification was the analysis outcome\n(e.g., the outcome value is 90% if two-class model was\nselected for 450 out of 500 replications). Eta-squared (i.e.,\n2 = SS /SS\nEffect Total\n) was computed as the effect size indica-\ntor. With a balanced design, the ANOVA results are expected\nto be robust regardless of the sampling distributions of the\nvarious statistics, some of which can be expected to be non-\nResults\nOverall fit index performance. Figure 4 shows the average per-\ncentages of one-class, two-class, and three-class (or more)\nmodels identified by AIC, CAIC, BIC, SABIC, VLMR, and\nALMR for all 24,000 datasets under both true and misspecified\nTable 2. Example of Relationship Between AIC Difference and\nAkaike Weight.\n\nAW\nAW\nAW\nNote. AIC = Akaike information criterion; AW = Akaike weight;\nsubscripts 1, 2, and 3 refer to one-class, two-class, three-class models,\nrespectively; \nChen et al. 9\nmodels. As shown in the figure, all model selection indices cor-\nrectly identified the two-class solution (i.e., the correct solu-\ntion) in most replications regardless of model specification\n(i.e., correctly specified or misspecified model). For the true\nmodel, BIC had the highest percentage of correct classification\nVLMR (89%), and AIC (76%). For the misspecified model,\nSABIC had the highest percentage of correct classification\nCAIC (78%), and AIC (66%). The difference in classification\naccuracy between true and misspecified models was 6%, 9%,\nBIC, and CAIC, respectively.\nUnder the true model, the proportion of inconclusive clas-\nsification ranged from approximately 20% forAIC, to almost 0\nfor CAIC, BIC, and SABIC. More inconclusive classification\nappeared under the misspecified model, withAIC again having\nthe highest proportion, followed by BIC and CAIC, and then\nSABIC. CAIC and BIC had a tendency to underextract the\nnumber of classes under the misspecified models, whereas\nAIC, VLMR, and ALMR tended to overextract the number of\nclasses under both the true and misspecified models.\nEffect of design factors.ANOVA results indicated that ICC,\ncluster number, and cluster size were the three most impor-\ntant factors. Table 3 shows the performance of the six model\nselection indices under both the true and false models as well\nas the difference between the true and misspecified models\ncollapsed over the three factors.\nICC had a negative impact on all six model selection indi-\nces under the false model. The average accuracy of class\nenumeration decreased as ICC increased from .1 to .2 (2\nIn general, cluster number and cluster size had positive\neffects on the accuracy of the IC indices. As cluster number\nand cluster size increased, the accuracy of class enumera-\ntion increased (\nClusternumber\nClustersize\nranged from .07 to .30), except that cluster size had no sub-\nstantial impact on AIC under the misspecified model.\nHowever, for VLMR and ALMR under the true model,\ncluster number affected classification accuracy negatively\n( \nClusternumber\ntively), and cluster size had no substantial effect.\nSpecifically, the accuracy of VLMR and ALMR did not\nchange substantially when cluster number increased from\nclassification accuracy decreased about 4% on average.\nIn addition, increasing \n\nmatrix decreased the accuracy\nfor CAIC, BIC, VLMR, and ALMR under both the true and\nmisspecified models, and SABIC under the misspecified\nmodel only ( 2 ranged from .06 to .14). As the mixing pro-\nportions changed from balanced to unbalanced for the two\n2-class Model\nYes\ns\nNo\n1-class is the\nbest solution\n3-class Model\nYes\ns\nNo\n2-class is the\nbest solution\n4-class Model\nYes\ns\nNo\n3-class is the\nbest solution\n4-class Model\n...\nFigure 3. VLMR/ALMR decision flowchart.\nNote. VLMR = Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test; ALMR = adjusted Lo\u00adMendell\u00adRubin likelihood ratio test.\nsubpopulations, the accuracy of class enumeration increased\nfor VLMR and ALMR under the true model, and for CAIC,\nBIC, and SABIC under the misspecified model, but\ndecreased for AIC under the true model ( 2 ranged from\nStudy 2: Three-Class Case\nMethod\nIn Study 2, we examined the performance of the previously\nmentioned model selection indices in a three-subpopula-\ntion MGMM. According to Tofighi and Enders's (2008)\nreview, three-class models are also common in published\nstudies using GMM. In addition, increased number of sub-\npopulations might increase the difficulty of separating\nlatent classes. Therefore, Study 2 can help determine\nwhether fit index performance remains consistent in more\ncomplicated situations. The design conditions and analysis\nprocedure remained mostly similar as those in Study 1\nwith a few modifications, which are described in the fol-\nlowing sections.\nData generation. In Study 2, data with three known subpopu-\nlations under a three-level model were first generated. The\nLevel 1 model was the same as in Study 1. The Level 2 and\nLevel 3 models were as follows:\n   \nij j j ij j ij ij\nD D r\n= + + + , (4a)\n   \nij j j ij j ij ij\nD D r\n= + + + ,\nwith\nr\nr\nMVN\nij\nij\n\n\n\n\n\n [ ] =\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n~ , .\n\n \n \n \n \n  \u00b5\nj j\n= + , (4d)\n \nj\n= ,\n \nj\n \nj\n\nj\n=  ,\n\nj\nwith\n\u00b5\nj\nN\n~ ( , ),\n\nAIC True\nBIC True\nPercent\nInconclusive\n3 Class (or more)\nFigure 4. Percentage of one-, two-, three-class (or more) models and inconclusive classification identified by AIC, CAIC, BIC, SABIC,\nVLMR, and ALMR under true and misspecified models.\nNote. Three-class (or more): three-class for AIC/CAIC/BIC/SABIC, three-class or more for VLMR/ALMR. AIC = Akaike information criterion; CAIC =\nconsistent AIC; BIC = Bayesian information criterion; SABIC = sample size\u00adadjusted BIC; VLMR = Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test; ALMR\n= adjusted Lo\u00adMendell\u00adRubin likelihood ratio test.\nTable 3. Study 1, Study 2, and Study 3 Results Collapsed Over ICC, Cluster Number, and Cluster Size.\nDesign conditions Performance of fit indices Difference between models\nCluster\nnumber\nCluster\nNote. ICC = intraclass correlation; AIC = Akaike information criterion; CAIC = consistent AIC; BIC = Bayesian information criterion; SABIC = sample size\u00adadjusted BIC; VLMR = Vuong\u00adLo\u00adMendell\u00ad\nRubin likelihood ratio test; ALMR = adjusted Lo\u00adMendell\u00adRubin likelihood ratio test. The \"t\" represents true model and \"f\" represents misspecified model. Numbers for performance and difference are\nin percentage numbers. Difference between models = true model accuracy - misspecified model accuracy.\nij\nij\nwere dummy variables to represent\nthe three different subpopulations (i.e., D1\nij\nij\nfor Subpopulation A; D1\nij\nij\n= 1 for Subpopulation\nij\nij\n= 0 for Subpopulation C).\nThe average growth models for the three subpopulations\nwere specified so that the two subpopulations in Study 1\nremained the same as in Equations 2a and 2b, and a third\nsubpopulation with a high start but a decelerating mean\ngrowth trajectory (i.e., Equation 3k) was added:\nSubpopulation C:\nY Time\ntij\ntij\n = - \u00d7( )\n. . . (4i)\nWe chose the growth pattern for Subpopulation C based on a\nreview by Tofighi and Enders (2008). The shape of estimated\ngrowth trajectories usually includes three classes: (a) a \"zero\nclass\" of individuals with low and stable levels of some problem\nbehaviors (i.e., Subpopulation A), (b) an \"accelerating class\"\nwith low start but increasing number of problems (i.e.,\nSubpopulation B), and (c) a \"decelerating class\" with higher\nstart but decreasing number of problems (i.e., Subpopulation C).\nBased on the settings presented in Equations 2a, 2b, and\n3k and the coding of the dummy variables, \n, \n, \n,\n\n, \n, and \nrespectively. Hence, the intercepts for each subpopulation\nThe three subpopulations' mixing proportions were fixed\nto be balanced, with 33.33% for each subpopulation, because\nthe effect of mixing proportions was not substantial accord-\ning to Study 1's findings. The cluster size was set to be 21\nand 42 for the ease of assigning equal number of individuals\ninto three subpopulations during data generation through\nthe impact of cluster number has been clearly shown in Study\n1, we only adopted the low and high levels for this design\nfactor (i.e., 30 and 80) and omitted the intermediate level\n(i.e., 50) to reduce the total number conditions. The vari-\nances and covariance of the random effects as well as the\nnumber of repeated measures were the same as in Study 1.\nThe mean growth trajectories of the three subpopulations\nand the level of separation under the small and medium T\nmatrix are illustrated in Figures 5 and 6.\nIn summary, the simulation used a 2 (magnitude of the T\nmatrix: small or medium) \u00d7 2 (number of participants per\nclusters) \u00d7 2 (ICC: .10 or .20) factorial design to generate the\ndata. Similar to Study 1, 500 replications were generated for\neach condition yielding a total of (500 datasets \u00d7 16 condi-\nAnalyses and Results\nThe analysis procedures and observed outcomes were the\nsame as those for Study 1. The performance of the six fit\nindices had several similarities with those in Study 1.\nTherefore, we only highlighted patterns that are different.\nOverall fit index performance. Results including the percent-\nages of correct and incorrect classifications by the six model\nselection indices for both the true and misspecified models\nare presented in Figure 7. Because Study 2 contained fewer\ndesign conditions than Study 1, only results from design con-\nditions similar across two studies were used for comparison.\nAIC had a much lower class enumeration accuracy (below\n40%) compared with that in Study 1 (above 65%) for both\ntrue and misspecified models. CAIC and BIC still performed\nwell in true models; furthermore, their enumeration accuracy\nunder the misspecified models improved by 13% and 11%,\nrespectively, compared with that in Study 1. Compared with\nresults from Study 1, SABIC's accuracy decreased by 16%\nunder the true model and 7% under the misspecified model,\nwith the overextraction rate increasing by 6% and 4%,\nrespectively. The accuracy of VLMR and ALMR dropped by\n7% under the true model and 10% under the misspecified\nmodel compared with that in Study 1.\nIn summary, under the misspecified model, BIC and\nCAIC had higher percentages of correct class enumeration\nY\nTime\nSubpopulaon A\nSubpopulaon B\nSubpopulaon C\nFigure 5. Mean growth trajectories with error bars for small\nT\nmatrix (medium separation).\nY\nTime\nSubpopulaon A\nSubpopulaon B\nSubpopulaon C\nFigure 6. Mean growth trajectories with error bars for medium\nT\nmatrix (low separation).\nand ALMR (69% and 71%). The difference in classification\naccuracy between true and misspecified models was -2%,\nALMR, and VLMR, respectively.\nEffect of design factors.The effects of the design factors\nremained mostly similar as what was found in Study 1; there-\nfore, only a few different patterns are highlighted here. For\nAIC, cluster number and cluster size affected the classifica-\ntion accuracy negatively (\nClusternumber\nClustersize\n= .24 and .26 for true and misspecified models, respectively).\nAs cluster size and number increased, the class enumeration\naccuracy for all AIC decreased. The accuracy of SABIC also\ndecreased significantly (i.e., overall 13% for true model and\n5% for misspecified model) when sample size was at the\nhighest level. In addition, ICC did not affect the accuracy of\nSABIC, VLMR, and ALMR under the false model.\nStudy 3: Complex Model in Two-Class\nCase\nIn the first two simulation studies, the within-class covari-\nance structure (i.e., the T\nmatrix) was identical across latent\nclasses. In reality, however, this might not be true. In this\nsimulation, we examined the effect of having different T\nmatrices across classes on model selection index performance.\nWe generated two-class multilevel data with a small T\nmatrix\n(\n.\n.\n)\nT\n \n \n \n \n=\n\n\n\n\n\n =\n\n\n\n\n\n\nfor Population A and a\nAIC True\nBIC True\nPercent\nInconclusive\n4 Class (or more)\nFigure 7. Percentage of one-, two-, three-, four-class (or more) models and inconclusive classification identified by AIC, CAIC, BIC,\nSABIC, VLMR, and ALMR under true and misspecified models.\nNote. Four-class (or more): four-class for AIC/CAIC/BIC/SABIC, four-class or more for VLMR/ALMR. AIC = Akaike information criterion; CAIC = consistent\nAIC; BIC = Bayesian information criterion; SABIC = sample size\u00adadjusted BIC; VLMR = Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test; ALMR = adjusted\nLo\u00adMendell\u00adRubin likelihood ratio test.\nmedium T\nmatrix (\n.\n.\n)\nT\n \n \n \n \n=\n\n\n\n\n\n =\n\n\n\n\n\n\nfor\nPopulation B. The analysis procedure was similar as that of\nStudy 1. Note that now class-specific variances were esti-\nmated for each model fitted.\nAs expected, there were more convergence issues as the\nmodel became more complex. A total of 33 replications were\nexcluded from further analysis due to nonconvergence or\nlocal solutions for the three-class MGMM or GMM models.\nWe highlighted the results that are different from Study 1 in\nthe following section (see Table 3).AIC's accuracy decreased\nsubstantially, whereas CAIC, BIC, VLMR, and ALMR\nbecame more accurate as the model became more complex.\nSABIC performed similarly as in Study 1, except its accu-\nracy decreased under the small sample size condition under\nthe true model.\nDiscussion and Conclusion\nThe current study examined model selection index perfor-\nmance in class enumeration for MGMMs when the top level\nof nesting was ignored. As expected, under the correctly\nspecified MGMM, the indices'performance was mostly con-\nsistent with the findings in previous studies. BIC and CAIC\nhad the highest class enumeration accuracy, followed by\nSABIC, ALMR, and VLMR, with ALMR and VLMR per-\nforming similarly. AIC had the lowest enumeration accuracy.\nSABIC, ALMR, VLRM, and AIC tended to overextract the\nnumber of classes when there were three subpopulations and\nless clear-cut class separation. When the highest data level\nwas ignored and a single-level GMM was fitted to the data,\nthe classification accuracy of all model selection indices\ndecreased compared with the accuracy under the true model.\nWe discuss the impact of design factors, Bonferroni correc-\ntion with VLMR/ALMR, and the implications for research-\ners in the following section.\nImpact of Design Factors\nThe impact of ICC.The ICC had the biggest impact on the\ndifference between the true and misspecified models. An\nimportant advantage of using multilevel models is that by\nmodeling the higher level nesting structure (e.g., schools),\nvariation in the individual growth trajectories can be decom-\nposed into within- and between-organization components\n(Raudenbush & Bryk, 2002). As shown in some previous\nstudies on multilevel analysis (e.g., Meyers & Beretvas,\nture results in the redistribution of the variance from the\nignored level (or the organization/school level) to the adja-\ncent level (i.e., the individual/student level). A similar vari-\nance redistribution mechanism has been found in MGMM\n(e.g., the overestimation of \nreduction in class enumeration accuracy is therefore likely\nthe result of the redistributed higher level variance, which\ncan increase the variation of the individual growth trajecto-\nries, potentially increasing overlap between different latent\nclasses.\nThe impact of degree of separation. The magnitude of the T\nmatrix is related to the variation within each latent class and\nthereby the degree of separation of different latent classes. It\nis not surprising that as the magnitude of T\nmatrix increased\n(i.e., latent classes became less separated), the class enumer-\nation accuracy under both the true and the misspecified mod-\nels decreased. Furthermore, model selection index\nperformance deteriorated more under the misspecified model\nthan under the true model when the magnitude of T\nincreased. This indicates that model selection indices are\nmore sensitive to class separation when the nesting structure\nis ignored and thus even less likely to identify the correct\nnumber of classes when class separation is less clear.\nThe impact of sample size. Sample sizes affected the indices\nin different ways. Our finding is consistent with previous\nfindings that CAIC and BIC tend to select the correct class\nsolution more frequently as sample size increases under the\ntrue model (Nylund et al., 2007). However, the impact of\nsmall sample size on CAIC and BIC under the misspecified\nGMM is much more serious than its impact under the true\nmodel. Previous research on two-level GMM found that BIC\nand CAIC tended to underextract the number of classes\nunder small sample sizes even when the model was correctly\nspecified. It is possible that the N adjustment is too strong\nwhen N is small or Ln is not the optimal function. However,\nthe performances of SABIC (with smaller penalty on N),\nVLMR, and ALMR were less affected by small sample size\nconditions. The performance gaps between the true and the\nmisspecified model for SABIC, VLMR, and ALMR were\nmuch smaller than those for CAIC and BIC. Therefore, when\nsample size was small, SABIC, VLMR, and ALMR were\ngenerally more accurate than CAIC and BIC under the mis-\nspecified model.\nAs shown in Equations 1a to 1d, different sample size (N)\nfunctions are used in the penalty term for different IC indi-\nces. Figure 8 illustrates how class enumeration decisions\nmade by different IC change with sample size based on the\nlog-likelihood values from an empirical data analysis.\nSuppose we are comparing the three-class solution and the\nfour-class solution. The difference between IC4class\nand\nis\nIC Penalty Penalty\nPen\n= - +\n( )- - +\n( )\n=\nlog log\na\nalty -Penalty\n( )- -\n( )\nlog log .\nLet Penalty Penalty Penalty\n= -\nand 2log L =\nlog log\n- . Figure 8 plotted Penalty and 2log L\nagainst sample size ( 1  N  104). The 2log L was different\nunder the MGMM and the GMM models (see Figure 8 for\nthe two curved lines). We can see that 2log L was positive\nand increased as the sample size increased. The Penalty\nwas different depending on the particular IC index (see\nFigure 8 for the four straight lines); however, it was the same\nunder MGMM and GMM models because the difference in\nthe number of parameters (i.e., p) between the four- and\nthree-class solutions was the same under MGMM and GMM.\nWe can see that Penalty increased as sample size increased\nfor CAIC, BIC, and SABIC whereas the Penalty for AIC\nwas a constant despite the sample size increase. When a\nPenalty line intersects a 2log L line, it means that\nIC class class\n-\nis zero and the four-class solution is as good as\nthe three-class solution (the corresponding sample size is the\ncutoff sample size). When the Penalty line is above the\n2log L line, it means that IC class class\n-\nis greater than zero\nand the three-class solution is better. Conversely, if the\nPenalty line is below the 2log L line, it means that\nIC class class\n-\nis smaller than zero and the four-class solution\nis better. Apparently, the cutoff sample size is dependent\nupon the likelihood values of the tested models and the cor-\nresponding number of estimated parameters (i.e., model\ncomplexity).\nFigure 8 shows that when sample size is large enough, all\nindices will favor the four-class solution. Note that SABIC\nwill also favor the four-class solution when sample size is\nvery small because it has two crossing points. The range of\nsample size in which the IC indices will select the three-class\nsolution (i.e., when the Penalty line is above the 2log L\nline) is the largest for CAIC, followed by BIC, SABIC, and\nAIC. In other words, the range of sample size in which the IC\nindices will favor the four-class solution is the largest for\nAIC, followed by SABIC, BIC, and CAIC. This can explain\nseveral findings of our simulation studies. First, AIC tended\nto overextract classes most and SABIC had some overextrac-\ntion but much less than AIC, whereas BIC and CAIC were\nmore conservative and had less overextraction. This caused\nthe accuracy of AIC and SABIC to decrease with the sample\nsize increase in both studies. Second, SABIC could also over-\nextract when sample size was small because it had two cross-\ning points. This caused the accuracy of SABIC to be lower\ncompared with BIC and CAIC under the smaller sample size\ncondition in Study 2. Third, the range of sample size for an IC\nindex to choose the four-class solution is larger under GMM\nthan under MGMM. This explained why overextraction of\nclasses was more likely to occur under GMM than MGMM.\nThe MGMM examined in this study was strategically\nspecified to have only one Level 3 random effect, which cap-\ntures the intercept variance between cluster/organization\nmeans. Under specifications where the number of parameters\nat Level 3 increases (e.g., by including a slope residual vari-\nance, latent classes, or fixed effects at the organization level),\nPenalty would remain the same for true and misspecified\nMGMM; however, these additions may change the amount\nand shape of the Level 2 variance distribution, which could\nimpact the number of within-cluster classes. Regarding the\ncurrent study, these Level 3 additions can also impact the\naccuracy of class enumeration (Chen et al., 2010).\nBonferroni Corrections With VLMR/ALMR\nOne reason for VLMR/ALMR's overextracting the number\nof classes might be increased Type I error rate resulting from\nmultiple testing for the same dataset. In previous research, no\ncorrection for  was used and the effect of using corrected \nis unknown (B. Muth\u00e9n, personal communication, March 8,\n2011). Therefore, we have examined the accuracy of VLMR\nand ALMR after applying Bonferroni correction to  in both\nstudies. Based on the number of VLMR/ALMR from each\n= .167 for Study 2. We found that the overall accuracy of\nVLMR and ALMR improved under both the true and mis-\nspecified models (improvement ranged from 1% to 10%).\nFurthermore, the difference between the nonadjusted and\nadjusted VLMR/ALMR increased as the cluster number and\ncluster size increased. By using the Bonferroni correction to\n, VLMR/ALMR is less likely to overextract the number of\nclasses, an improvement especially noticeable in large sam-\nple size conditions, in misspecified models, and when there\nwere more than two subpopulations in data generation. There\nwas no appreciable difference between the nonadjusted and\nadjusted VLMR/ALMR under the small sample size condi-\ntion (i.e., N = 600 or 630) and for the true model. Therefore,\nBonferroni correction seems more appropriate for data with\nlarge sample sizes (N  1,000) only; besides, when the higher\nlevel nesting structure is ignored, the Bonferroni correction\nwould be especially useful to achieve higher accuracy for\nImplications for Researchers\nTechniques such as GMM and MGMM that are rooted in\nstructural equation modeling can be viewed as model-building\ntechniques in which researchers start with a simpler model\nFigure 8. Example of the effect of sample size on class enumeration decisions by IC indices.\nNote. IC = information criterion; AIC = Akaike information criterion; CAIC = consistent AIC; BIC = Bayesian information criterion; SABIC = sample\nsize\u00adadjusted BIC; MGMM = multilevel growth mixture model; GMM = growth mixture model.\nand build up to a more complex one (Kline, 2010). The\nresults of the current study can aid researchers in this model-\nbuilding process because they demonstrate the importance of\naccounting for nested data structure and provide information\non which fit indices can most accurately identify the appro-\npriate model when using MGMM. Based on our findings, we\nstrongly recommend that researchers accommodate multi-\nlevel structure by using MGMMs, especially when the sam-\nple size is relatively small, the ICC is relatively large, or\nboth. Table 4 summarizes the top performing indices under\ndifferent conditions.\nIn general, when the sample size is small, SABIC is pre-\nferred, whereas when the sample size is large, BIC and CAIC\nare preferred. Note that the sample size is relative to ICC. For\nexample, 1,200 may be considered as a large sample size\nwhen ICC is .1, but small when ICC is .2.\nThe cutoff value of 2 is a reasonable value to use for BIC,\nCAIC, and SABIC. In the process of finding the best fit\nmodel, when the decrease in the indices' values (especially\nSABIC) becomes less than 2, researchers can stop fitting\nmore complicated models (i.e., models with more classes)\nand select the model with the second lowest IC index.\nVLMR and ALMR can be used as references when sam-\nple size is small (i.e., N  630), but should be used with cau-\ntion when sample size is large due to their tendency to\noverextract classes. Bonferroni correction can help improve\nVLMR/ALMR's accuracy for data with large sample size (N\nUnder more complex models, we recommend using\nCAIC, BIC, VLMR, and ALMR for MGMM; SABIC is only\nsuitable for large sample size conditions. For misspecified\nmodels, CAIC and BIC are best, SABIC is appropriate for\nlarge sample size conditions, and VLMR and ALMR can\nalso be used, but tend to overextract classes.\nIt is important to note that these fit index recommenda-\ntions are based on the simulation conditions used in this\nstudy. Readers should be cautious when applying our find-\nings to models and conditions that are very different from\nthose studied in this article.\nLimitations and Future Directions\nAccurate class enumeration is perhaps the greatest challenge\nin mixture modeling and much is still unknown about highly\ncomplex mixture models such as the MGMM. That said,\nthere are some limitations to the current study that raise cau-\ntion regarding generalizing the results. First, the residual\nvariance of the slope at the organization level was con-\nstrained to zero. While this specification will be common for\nempirical studies because organization level slope variation\ntends to be small, which may result in convergence problems\n(Palardy & Vermunt, 2010), including the organization level\nslope random effect and other Level 3 parameters may\nimpact class enumeration.\nSecond, while this study focuses on the particular model\nmisspecification of ignoring the highest level of the hierar-\nchical data, there are other types of model misspecifications\nand assumption violations that may affect class enumeration.\nFor instance, misspecifying the shape of the growth trajec-\ntory or violating the multivariate normality assumption for\nthe repeated measures can effect class enumeration (Bauer &\nthese issues.\nThird, the current study was conducted under frequentist\nestimation using the maximum likelihood estimator. Recently,\nBayesian estimation for multilevel models has been gaining\nattention due to its advantages over the classical approach\n(Hamaker & Klugkist, 2011). The deviance information crite-\nrion (DIC; Spiegelhalter, Best, Carlin, & Van der Linde,\n2002) is available under the Bayesian estimation, and it can\nbe used in similar fashion as the AIC and BIC to select the\noptimal model (i.e., models with small DIC values are\nfavored). In the most recent version of Mplus 6.1 (L. K.\navailable but not yet implemented for MGMM (B. Muth\u00e9n,\nBayesian analysis with a specific prior distribution allows\nmodel selection using posterior model probabilities or the\nBayes factor (Hamaker & Klugkist, 2011). We expect the\nmodel selection by DIC to be similar to AIC according to\nTable 4. Better Performing Indices Under Small and Large N by Type of Model.\nType of model Small N Large N\nMGMM\n Three class, same variance BIC, CAIC, VLMR/ALMR, SABIC BIC, CAIC\n Two class, different variance BIC, CAIC, VLMR/ALMR BIC, CAIC, SABIC, VLMR/ALMR\nGMM\n Two class, same variance SABIC, VLMR/ALMR SABIC, BIC, CAIC, VLMR/ALMR\n Three class, same variance SABIC, VLMR/ALMR BIC, CAIC, SABIC\n Two class, different variance BIC/CAIC, VLMR/ALMR BIC/CAIC, SABIC, VLMR/ALMR\nNote. MGMM = multilevel growth mixture model; SABIC = sample size\u00adadjusted BIC; BIC = Bayesian information criterion; CAIC = consistent AIC;\nVLMR = Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test; ALMR = adjusted Lo\u00adMendell\u00adRubin likelihood ratio test; GMM = growth mixture model; AIC =\nAkaike information criterion.\nSpiegelhalter et al. (2002), whereas Bayes factor and poste-\nrior probabilities under full Bayesian analysis to be similar to\nthe BIC, as they belong to Bayesian model selection approach.\nAdditional research on the performance of DIC, posterior\nmodel probabilities, and Bayes factor for MGMM and GMM\nunder the Bayesian estimation framework is needed to see\nhow they compare with the classical/frequentist approach.\nAppendix\nBelow is a list of all acronyms used in the current article as\nwell as what they denote, in alphabetical order.\nAIC--Akaike information criterion\nALMR--adjusted Lo\u00adMendell\u00adRubin likelihood ratio test\nANOVA--analysis of variance\nBIC--Bayesian information criterion\nBLRT--bootstrap likelihood ratio test\nCAIC--consistent Akaike information criterion\nFMM--factor mixture model\nGMM--growth mixture model\nIC--information criterion\nICC--intraclass correlation\nID--identifier\nIRT--item response theory\nLCA--latent class analysis\nLCGA--latent class growth model\nLGCM--latent growth curve model\nLR--likelihood ratio\nLRT--likelihood ratio test\nK-L--Kullback\u00adLeibler\nMGMM--multilevel growth mixture model\nSABIC--sample size\u00adadjusted BIC\nVLMR--Vuong\u00adLo\u00adMendell\u00adRubin likelihood ratio test\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect\nto the research, authorship, and/or publication of this article.\nFunding\nThe author(s) received no financial support for the research, author-\nship, and/or publication of this article.\nNotes\n1. Error bars computed as 1.96 standard deviations.\ni\ni\ni\nm\n=\n-\n-\n=\n\nexp[ ( / ) ]\nexp[ ( / ) ]\n\n\n, m = number of models fitted,\ni i\n= -\nmin .\nReferences\nAgresti, A. (1996). An introduction to categorical data analysis.\nNew York, NY: John Wiley.\nAkaike, H. (1987). Factor analysis and AIC. Psychometrika, 52,\nAllua, S. S. (2007). Evaluation of single- and multilevel factor\nhttps://libproxy.library.unt.edu/login?url=http://search.pro-\nAsparouhov, T., & Muth\u00e9n, B. (2008). Multilevel mixture mod-\nels. In G. R. Hancock & K. M. Samuelsen (Eds.), Advances\nin latent variable mixture models (pp. 27-51). Greenwich, CT:\nInformation Age.\nBacci, S., Pandolfi, S., & Pennoni, F. (2014). A comparison of some\ncriteria for states selection in the latent Markov model for lon-\ngitudinal data. Advances in Data Analysis and Classification,\nBartolucci, F., & Murphy, T. B. (2015). A finite mixture latent tra-\njectory model for modeling ultrarunners' behavior in a 24-hour\nBartolucci, F., Pennoni, F., & Vittadini, G. (2011). Assessment of\nschool performance through a multilevel latent Markov Rasch\nmodel. Journal of Educational and Behavioral Statistics, 36,\nBauer, D. J., & Curran, P. J. (2003). Distributional assumptions\nof growth mixture models: Implications for overextraction of\nBauer, D. J., & Curran, P. J. (2004). The integration of continu-\nous and discrete latent variable models: Potential problems and\npromising opportunities. Psychological Methods, 9, 3-29.\nBollen, K. A., & Curran, P. J. (2006). Latent curve models: A struc-\ntural equation approach. Hoboken, NJ: John Wiley.\nBoscardin, C. K., Muth\u00e9n, B., Francis, D. J., & Baker, E. L.\n(2008). Early identification of reading difficulties using het-\nerogeneous developmental trajectories. Journal of Educational\nBozdogan, H. (1987). Model selection and Akaike's information\ncriterion (AIC): The general theory and its analytic extensions.\nBurnham, K. P., & Anderson, D. R. (2002). Model selection and\nmultimodel inference: A practical information-theoretic\napproach (2nd ed.). New York, NY: Springer-Verlag.\nBurnham, K. P., & Anderson, D. R. (2004). Multimodel\ninference: Understanding AIC and BIC in model selec-\nChen, Q., Kwok, O., Luo, W., & Willson, V. L. (2010). The impact\nof ignoring a level of nesting structure in multilevel growth\nmixture models: A Monte Carlo study. Structural Equation\nClark, S., & Muth\u00e9n, B. O. (2007, April). How to handle clustered\ndata when deciding on the number of classes in a latent class\nanalysis: A Monte Carlo simulation study. Paper presented\nat the annual meeting of American Educational Research\nAssociation. Chicago, IL.\nD'Angiulli, A., Siegel, L. S., & Maggi, S. (2004). Literacy instruc-\ntion, SES, and word-reading achievement in English-language\nlearners and children with English as a first language: A longi-\ntudinal study. Learning Disabilities Research & Practice, 19,\nDettmers, S., Trautwein, U., L\u00fcdtke, O., Kunter, M., & Baumert, J.\n(2010). Homework works if homework quality is high: Using\nmultilevel modeling to predict the development of achievement\nin mathematics. Journal of Educational Psychology, 102, 467-\nEnders, C. K., & Tofighi, D. (2008). The impact of misspecify-\ning class-specific residual variances in growth mixture models.\nGlass, G. V., & Hopkins, K. D. (1996). Statistical methods in psy-\nchology and education (3rd ed.). Needham Heights, MA: Allyn\n& Bacon.\nGraves, S., & Frohwerk, A. (2009). Multilevel modeling and\nschool psychology: A review and practical example. School\nHamaker, E. L., & Klugkist, I. (2011). Bayesian estimation of mul-\ntilevel models. In J. J. Hox & J. K. Roberts (Eds.), Handbook\nNY: Routledge.\nHenson, J. M., Reise, S. P., & Kim, K. H. (2007). Detecting mix-\ntures from structural model differences using latent variable\nmixture modeling: A comparison of relative model fit statis-\nHox, J. (2010). Multilevel analysis techniques and applications,\nsecond edition. Mahwah, NJ: Lawrence Erlbaum.\nJeffries, N. O. (2003). A note on \"testing the number of mixture\nJenkins, J. M., Dunn, J., O'Connor, T. G., Rasbash, J., & Behnke,\nP. (2005). Change in maternal perception of sibling negativ-\nity: Within- and between-family influences. Journal of Family\nKeribin, C. (2000). Consistent estimation of the order of mix-\nture models. Sanky: The Indian Journal of Statistics, 62,\nKhoo, S., West, S. G., Wu, W., & Kwok, O. (2006). Longitudinal\nmethods. In M. Eid & E. Diener (Eds.), Handbook of psy-\nchological measurement: A multimethod perspective (pp.\nAssociation.\nKline, R. B. (2010). Principles and practice of structural equation\nmodeling (3rd ed.). New York, NY: Guilford Press.\nKreft, I., & De Leeuw, J. (1998). Introducing multilevel modeling.\nThousand Oaks, CA: SAGE.\nKuha, J. (2004). AIC and BIC: Comparisons of assumptions and\nLeroux, B. G. (1992). Consistent estimation of a mixing distribu-\nLo, Y., Mendell, N. R., & Rubin, D. B. (2001). Testing the number\nLukociene, O., & Vermunt, J. K. (2010). Determining the number\nof components in mixture models for hierarchical data. In A.\nFink, B. Lausen, W. Seidel, & A. Ultsch (Eds.), Advances in\ndata analysis, data handling and business intelligence (pp.\nMaitra, R., & Melnykov, V. (2010). Simulating data to study per-\nformance of finite mixture modeling and clustering algorithms.\nJournal of Computational and Graphical Statistics, 19, 354-\nMarcus, D. K., Kashy, D. A., & Baldwin, S. A. (2009). Studying\npsychotherapy using the one-with-many design: The therapeu-\ntic alliance as an exemplar. Journal of Counseling Psychology,\nMatsumoto, D., Nezlek, J. B., & Koopmann, B. (2007). Evidence\nfor universality in phenomenological emotion response system\nMcLachlan, G., & Peel, D. (2000). Finite mixture models. New\nYork, NY: John Wiley.\nMelnykov, V., Chen, W., & Maitra, R. (2012). MixSim: An R\npackage for simulating data to study performance of cluster-\nMeyers, J. L., & Beretvas, S. N. (2006). The impact of inappropri-\nate modeling of cross-classified data structures. Multivariate\nMoerbeek, M. (2004). The consequence of ignoring a level of nest-\ning in multilevel analysis. Multivariate Behavioral Research,\nMorgan, G. B., Hodge, K. J., & Baggett, A. R. (2016). Latent profile\nanalysis with nonnormal mixtures: A Monte Carlo examination\nof model selection using fit indices. Computational Statistics\nMuth\u00e9n, B. (2003). Statistical and substantive checking in growth\nmixture modeling: Comment on Bauer and Curran (2003).\nMuth\u00e9n, B. (2004). Latent variable analysis: Growth mixture mod-\neling and related techniques for longitudinal data. In D. Kaplan\n(Ed.), Handbook of quantitative methodology for the social sci-\n(6th ed.). Los Angeles, CA: Author.\nNagin, D. S. (1999). Analyzing developmental trajectories: A semi-\nparametric, group-based approach. Psychological Methods, 4,\nNg, S. K., & McLachlan, G. J. (2014). Mixture models for clus-\ntering multilevel growth trajectories. Computational Statistics\nNg, S. K., McLachlan, G. J., Wang, K., Jones, L. B., & Ng, S. W.\n(2006). A mixture model with random-effects components for\nclustering correlated gene-expression profiles. Bioinformatics,\nNylund, K. L., Asparouhov, T., & Muth\u00e9n, B. O. (2007). Deciding\non the number of classes in latent class analysis and growth\nmixture modeling: A Monte Carlo simulation study. Structural\nPalardy, G., & Vermunt, J. K. (2010). Multilevel growth mixture\nmodels for classifying groups. Journal of Educational and\nPetras, H., & Masyn, K. (2010). General growth mixture analysis\nwith antecedents and consequences of change. In A. R. Piquero\n& D. Weisburd (Eds.), Handbook of quantitative criminology\nPeugh, J., & Fan, X. (2012). How well does growth mixture mod-\neling identify heterogeneous growth trajectories? A simula-\ntion study examining GMM's performance characteristics.\nPruchno, R., Wilson-Genderson, M., & Cartwright, F. P. (2009).\nDepressive symptoms and marital satisfaction in the context\nof chronic disease: A longitudinal dyadic analysis. Journal of\nRaftery, A. E. (1996). Bayesian model selection in social research.\nIn P. V. Marsden (Ed.), Sociological methodology (pp. 111-\n163). Oxford, UK: Basil Blackwell.\nRaudenbush, S. W., & Bryk, A. S. (2002). Hierarchical linear mod-\nels: Applications and data analysis methods. Thousand Oaks,\nRaudenbush, S. W., & Liu, X. (2001). Effects of study duration,\nfrequency of observation, and sample size on power in stud-\nies of group differences in polynomial change. Psychological\ngram]. Cary, NC: Author.\nSchwartz, G. (1978). Estimating the dimension of a model. The\nSclove, L. S. (1987). Application of model-selection criteria to\nsome problems in multivariate analysis. Psychometrika, 52,\nSpiegelhalter, D. J., Best, N. G., Carlin, B. P., & Van der Linde, A.\n(2002). Bayesian measures of model complexity and fit (with\ndiscussion). Journal of the Royal Statistical Society, Series B,\nTobler, A. L., & Komro, K. A. (2010). Trajectories or parental\nmonitoring and communication and effects on drug use among\nurban young adolescents. Journal of Adolescent Health, 46,\nTofighi, D., & Enders, C. K. (2008). Identifying the correct number\nof classes in a growth mixture models. In G. R. Hancock, &\nK. M. Samuelsen (Eds.), Advances in latent variable mixture\nVancouver, J. B. (1997). The application of HLM to the\nanalysis of the dynamic interaction of environment, per-\nVermunt, J. K., & Magidson, J. (2002). Latent class cluster analysis.\nIn J. Hagenaars & A. McCutcheon (Eds.), Applied latent class\nanalysis (pp. 89-106). New York, NY: Cambridge University\nPress.\nVuong, Q. H. (1989). Likelihood ratio tests for model selection and\nWeakliem, D. L. (2004). Introduction to the special issue on model\nYang, C. (2006). Evaluating latent class analyses in qualitative\nphenotype identification. Computational Statistics & Data\nAuthor Biographies\nQi Chen is an associate professor of Research, Measurement and\nStatistics within the Educational Psychology Department at UNT.\nHer research expertise includes growth mixture modeling, multi-\nlevel modeling, structural equation modeling, longitudinal data\nanalysis, mediation and moderation analysis, parenting and child\nachievement subject matter, and school-based prevention work.\nWen Luo is an associate professor in the Department of Educational\nPsychology. She specializes in quantitative research methodology.\nHer research interests include statistical modeling of data with com-\nplex multilevel structures and longitudinal data analyses.\nGregory J. Palardy's research focuses on school and teacher\neffectiveness and applications of quantitative methods in educa-\ntional research. Recent studies have addressed: the consequences of\nsocioeconomic segregation in schools on cognitive outcomes, non-\ncognitive outcomes, and educational attainment; the impact of\naccess to qualified and effective teachers on achievement gaps; and\nthe impact of including summer on value-added models of teacher\nand school effectiveness.\nRyan Glaman is a PhD candidate in Educational Psychology with a\nconcentration in Research, Measurement, and Statistics at the\nUniversity of North Texas. His methodological research interests are\nin the areas of multilevel modeling and structural equation modeling\nAmber McEnturff is a PhD candidate in Educational Psychology\nat the University of North Texas. She specializes in multilevel mod-\nels, as well as data analysis and program evaluation in school and\nnonprofit settings."
}