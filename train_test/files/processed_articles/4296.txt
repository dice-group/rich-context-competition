{
    "abstract": "Abstract\nSudden, broad-scale shifts in public opinion about social problems are relatively rare. Until recently, social scientists were\nforced to conduct post-hoc case studies of such unusual events that ignore the broader universe of possible shifts in public\nopinion that do not materialize. The vast amount of data that has recently become available via social media sites such as\nFacebook and Twitter--as well as the mass-digitization of qualitative archives provide an unprecedented opportunity for\nscholars to avoid such selection on the dependent variable. Yet the sheer scale of these new data creates a new set of\nmethodological challenges. Conventional linear models, for example, minimize the influence of rare events as\n``outliers''--especially within analyses of large samples. While more advanced regression models exist to analyze outliers,\nthey suffer from an even more daunting challenge: equifinality, or the likelihood that rare events mayoccur via different causal\npathways. I discuss a variety of possible solutions to these problems--including recent advances in fuzzy set theory and\nmachine learning--but ultimately advocate an ecumenical approach that combines multiple techniques in iterative fashion.\n",
    "reduced_content": "Commentary\nLost in a random forest: Using Big Data to\nstudy rare events\nChristopher A Bail\n Keywords\nSocial media, rare events, causal complexity, automated text analysis, machine learning, cultural sociology\nAmong the most intriguing aspects of the recent explo-\nsion in digital text-based data is that it offers the poten-\ntial for social scientists to analyze rare events with\nunprecedented precision. Consider, for example, a\nlongstanding puzzle within the literature on collective\nbehavior and cultural sociology: how do social move-\nments, advocacy groups, or other civil society organ-\nizations create sweeping shifts in the way the public\nthinks about complex social problems such as racism,\nincome inequality, or gender discrimination?\nFew social scientists are prescient enough to antici-\npate such rare events before they occur. As a result,\nmost studies of collective behavior and cultural\nchange employ post-hoc case studies that trace the his-\ntory of organizations only after they successfully trans-\nform the status quo. Yet the overwhelming majority of\ncivil society organizations fail to create any public\nimpact--let alone major shifts in public worldviews\n2010). As a result, extent studies are routinely criticized\nfor using circular reasoning that confuses the charac-\nteristics of successful civil society organizations with the\nThe recent explosion of text-based data enables scho-\nlars interested in the relationship between collective\nbehavior and cultural change to escape the cardinal sin\nof selection on the dependent variable. Over the past five\nyears, I developed new app-based technologies that track\nthe influence of hundreds of civil society organizations\nupon the more than one billion people who use Facebook\non a routine basis (Bail, 2015). This new research method\nnot only situates organizations that succeed in shaping\npublic opinion amidst the vast sea negative cases that fail\nto create broad-scale cultural change, but also collects\nhundreds of variables that describe these organizations,\ntheir audiences, and the broader social context in which\nthey interact. Though important questions about the\nDuke University, Durham, NC, USA\nCorresponding author:\nChristopher A Bail, Duke University, 254 Soc/Psych Building, 417 Chapel\nEmail: christopher.bail@duke.edu\nBig Data & Society\nReprints and permissions:\nsagepub.com/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons Attribution\n3.0 License (http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work\nwithout further permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/\nnam/open-access-at-sage).\nrelationship between on and offline behavior remain\nunanswered, these new data enable fine-grained analysis\nof the spread of ideas across vast social networks with\nunprecedented qualitative and longitudinal detail.\nYet the study of rare events with Big Data also pre-\nsents daunting new challenges. Now that we can see the\nhaystack, we still need to find the needle. Even the most\nbasic forms of descriptive analyses necessary to identify\nrare events within large datasets require new computing\ntechnologies designed to process massive datasets. Once\nsuch events are found, it is impossible to compare them\nto the vast population of negative cases with the naked\neye because of their sheer scale. Preliminary analyses\nsuch as histograms, cross-tabulations, or scatterplots\nare of limited utility because the distribution of rare\nevents within such datasets is so heavily skewed.\nIt is therefore rather tempting to forego basic descrip-\ntive analyses of Big Data and proceed with multivariate\nanalyses that might better differentiate rare events from\nthe negative cases that surround them. Yet analysis of\nvariance and multivariate regression are designed to min-\nimize the influence of rare events as ``outliers.'' Indeed,\nmuch enthusiasm around Big Data surrounds the\nimprovement of regression estimators because of the\nCentral Limit Theorem, or the tendency for normal dis-\ntributions to emerge as sample sizes grow.\nThere are, of course, a number of more nuanced\nregression models for analysis of rare events (e.g.\nKing and Zeng, 2001), but these techniques suffer\nfrom a separate--perhaps more vexing--problem: equi-\nfinality, or the likelihood that rare events occur via mul-\ntiple causal pathways. Consider, again, the study of\nwhy certain civil society organizations produce social\nmedia messages that reach millions of people, while\nothers go mostly unnoticed. There are not only many\ndifferent types of organizations with different messages\nand strategies to publicize them, but also diverse audi-\nences who might receive and distribute them in a var-\niety of different manners. Moreover, there are a variety\nof broader social conditions that may shape whether\nand how a message goes viral. Though one campaign\nmay spread organically across dense networks of\nfriends over months--or even years--others may suc-\nceed because they are dispatched within the context of a\nmajor news story about a social problem.\nEven methods that are explicitly designed to capture\ncausal complexity do not yet work well for analyzing\nfuzzy-set qualitative comparative analysis (fsQCA), for\ninstance, arrays cases into ``truth tables'' that describe\nthe frequency of different configurations of necessary or\nsufficient conditions that produce an outcome of inter-\nest. While fsQCA was originally designed to study\ncausal complexity in ``small N'' studies, it holds consid-\nerable promise for studying larger datasets as well\n(Ragin, 2008). Though state-of-the art algorithms for\nreducing truth tables can identify multiple sufficient\nconditions for an outcome, most rare events include\nmultiple necessary conditions. A social media message\nabout climate change, for example, is unlikely to go\nviral in the aftermath of a major terrorist attack or at\n3 am on the fourth of July.1\nAnother approach to modeling causal complexity\nwithin large datasets is the burgeoning field of machine\nlearning. Random forest techniques, for example, com-\nbine conventional regression tree methods with iterative\nbootstrapping techniques to classify large amounts of\ndata into different branches--or configurations of vari-\nables--with sufficiently large samples (Breiman, 2001).\nThese new techniques--which are gradually attracting\nthe interest of social scientists (e.g. Grimmer and\nStewart, 2013)--hold great promise for the study of\nrare events. This is not only because they recognize\ncausal complexity but also because they permit identi-\nfication of patterns within data that could not be recog-\nnized by the naked eye.\nYet machine-learning techniques also introduce an\nentirely new genre of methodological problems. From\nthe perspective of a computer or other machine, many\nof the proverbial needles within haystacks look like\nhay.2 Therefore, even the most sophisticated machine-\nlearning techniques will produce nonsensical results if\nhumans do not carefully validate them. This is already\nobvious within the exciting new field of natural lan-\nguage processing. Topic models and other automated\nforms of content analysis can easily categorize vast cor-\npora with impressive precision--and, some argue,\ngreater efficiency and reliability than human coders\n(Hopkins and King, 2010). Not unlike cluster analysis,\nhowever, topic models require social scientists to spe-\ncify an expected number of latent topics a priori.\nBecause one cannot possibly read vast corpora, how-\never, many people utilize topic models in an inductive\nmanner that resembles reading tea leaves (Chang et al.,\n2009). Though such ``grounded theory'' approaches can\nbe a powerful tool for classifying large corpora when\nused properly, arbitrary or under-validated topic\nmodels become nonsensical if they are combined with\nthe random forest techniques that do not discriminate\nbetween variables that were carefully created by a\nmasterful qualitative researcher and those that resulted\nfrom the topic model validity measure du jour.\nThe burgeoning field of Big Data visualization pro-\nvides another exciting opportunity for the analysis of\nrare events in Big Data. While social scientists typically\nemploy visualization techniques to represent data, this\nnew field provides a suite of new visual methods for\nanalyzing data as well. These include interactive com-\nputer-based tools that enable one to change certain\nparameters while holding others constant--for\n2 Big Data & Society\nexample, ``CorrPlots'' that spatially encode observa-\ntions as points on geometric structures that underlay\nPearson's correlation (McKenna et al., 2015), or\nvideo-based network analysis that may enable identifi-\ncation of sudden shifts in social relationships that\ncreate the conditions for rare events (Moody et al.,\n2005). The major downside of these new methods is\nthat standards do not yet exist for what counts as evi-\ndence (Healy and Moody, 2014), and the boundary\nbetween aesthetics and empirical evidence currently\nrests in the eye of the beholder.\nAttheriskofcliche\n\u00b4 ,thisbriefreviewhintsatthevalueof\nan ecumenical approach to studying rare events with Big\nData. Though each of the methods described above has\nconsiderable limitations, the rapid diversification of the\ncomputational social scientist's tool kit has produced a\nsuite of methods that complement each other rather nat-\nurally. For example, random forests or fsQCA might be\nused to identify interaction terms for negative binomial\nregression models--or qualitative coding can be used to\ncalibratelarge-scalequantitativecontent analysesasMohr\net al. (2013) have shown. The challenge for studying rare\neventswithBigData,then,willbetoavoidgetting``lost''in\nrandom forests--or staring too long at any single tree.\n"
}