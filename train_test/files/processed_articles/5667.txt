{
    "abstract": "Abstract\nThis paper discusses the empirical, Application Programming Interface (API)-based analysis of very large Facebook Pages.\nLooking in detail at the technical characteristics, conventions, and peculiarities of Facebook's architecture and data\ninterface, we argue that such technical fieldwork is essential to data-driven research, both as a crucial form of data\ncritique and as a way to identify analytical opportunities. Using the ``We are all Khaled Said'' Facebook Page, which\nhosted the activities of nearly 1.9 million users during the Egyptian Revolution and beyond, as empirical example, we\nshow how Facebook's API raises important questions about data detail, completeness, consistency over time, and\narchitectural complexity. We then outline an exploratory approach and a number of analytical techniques that take\nthe API and its idiosyncrasies as a starting point for the concrete investigation of a large dataset. Our goal is to close the\ngap between Big Data research and research about Big Data by showing that the critical investigation of technicity is\nessential for empirical research and that attention to the particularities of empirical work can provide a deeper under-\nstanding of the various issues Big Data research is entangled with.\n",
    "reduced_content": "Original Research Article\nData critique and analytical opportunities\nfor very large Facebook Pages:\nLessons learned from exploring\n``We are all Khaled Said''\nBernhard Rieder1, Rasha Abdulla2, Thomas Poell3,\nRobbert Woltering4 and Liesbeth Zack5\n Keywords\nFacebook Pages, Application Programming Interface-based research, data critique, exploratory data analysis\nIntroduction\nSince social media services such as Facebook, Twitter,\nor Instagram have emerged as prominent online venues\nattracting very large numbers of users and intense activ-\nity, researchers from a range of disciplines have set out\nto study these platforms and the social phenomena they\nare entangled with through software-supported data\ncapture and analysis. Drawing on approaches set in\ncomputational social science (Lazer et al., 2009), digital\nmethods (Rogers, 2013), or computational variants of\nmore traditional techniques, for instance content ana-\nlysis (Lewis et al., 2013), these researchers have empir-\nically explored three general directions: first and most\nfrequently, studies have investigated particular cases set\nin genres such as political activism (Poell and Borra,\n2012), public debates (Maireder and Schlo\ndisaster communication (Shaw et al., 2013); second,\nthere have been studies trying to profile overall plat-\nform characteristics, often working with complete data-\n1Department of Media Studies, University of Amsterdam, the\nNetherlands\n2Department of Journalism and Mass Communication, The American\nUniversity in Cairo, Egypt\n3Department of Media Studies, University of Amsterdam, the\nNetherlands\n4Amsterdam Centre for Middle Eastern Studies, University of\nAmsterdam, the Netherlands\n5Center for Language and Communication, University of Amsterdam, the\nNetherlands\nCorresponding author:\nBernhard Rieder, Amsterdam University, Turfdraagsterpad 9, Amsterdam\nEmail: rieder@uva.nl\nBig Data & Society\nbds.sagepub.com\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License (http://\nwww.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without further\npermission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-\nat-sage).\nrepresentative samples (e.g. Gerlitz and Rieder, 2013);\nthird, a considerable number of researchers, often\ncoming from computer science or related disciplines,\nhave used social media data to develop and test formal-\nizations of concepts coming out of communication stu-\ndies or social exchange theory, for example the notion\nof ``influence'' (Watts and Dodds, 2007). Despite con-\nsiderable differences in research direction and epistemo-\nlogical outlook, these approaches and fields share an\ninterest in gathering large datasets from social media\nplatforms and analyzing these data with the help of\ncomputational techniques. Official Application\nProgramming Interfaces (APIs), provided by the plat-\nforms themselves, are typically used for collection,\nhighlighting these technical passage points as a crucial\nmatter of concern.\nAPIs are a means for programs to interact with each\nother and social media companies provide such interfaces\nto third party developers to foster the growth of an appli-\ncation ecosystem, thereby enhancing the value of the plat-\nform through added functionality and public exposure.\nAs a side effect, APIs provide seemingly robust and con-\nvenient access to vast data pools for research purposes.\nBut they are not designed to accommodate the needs of\nresearchers and thus pose a series of specific problems,\nranging from opacity to rate limiting or legal uncertainty.\nWhile not all of these problems are new, APIs introduce a\ndegree of technicity--``technology considered in its effi-\ncacy or operative functioning'' (Hoel and van der Tuin,\nonly mastery in purely technical terms, but also an appre-\nciation of technical forms and functions on the level of\nmethodology. Moreover, behind every social media API\nlurks another technical contraption, the platform itself,\nwith its specific feature sets, interfaces, database architec-\ntures, and so forth. This raises the thorny question\nwhether we should ``understand these devices and plat-\nforms as part of our `methodology''' or rather as ``part of\nthe `object' of our analysis'' (Marres and Weltevrede,\noperational principles and forms espoused by a platform\nlike Facebook, demands that we treat them as both sim-\nultaneously, and suggests a ``commitment to research-as-\nthis tension a central concern.\nIndeed, before becoming research into a particular\ncase or question, data-driven social media analysis\nengages--not always in full awareness--in a curious\nkind of fieldwork that has to deal with technical char-\nacteristics, conventions, and peculiarities. This work is\nrarely considered to be a central part of research design.\nSince no one really enjoys dealing with subjects as\ninfuriating and time-consuming as character set coher-\nence or connection timeouts,1 we gladly delegate these\nmatters to the black box of a specialized tool or the\nhands of a research technician, hoping that they will be\nable to smooth out the jagged edges of technicity, to\nmake it disappear both practically and epistemologically,\nleaving us with unadulterated access to social reality. But\nare the logistics behind computational techniques not as\nmuch part of the knowledge production process as the\ndesign and distribution of a questionnaire?\nThe recent debate around Big Data (cf. Ekbia et al.,\n2015) has begun to address the concerns raised by the\ntechnicity of data-driven research by critically discuss-\ning issues ranging from sampling to inequality in access,\ndisparity in technological competence, and fundamen-\ntal ethical dilemmas. But there remains a large gap\nbetween research about Big Data and actual Big Data\nresearch. On the one side, empirical research projects\nrarely address these critical questions as central topics,\neven if they are increasingly acknowledged; on the\nother side, critical discussion too often remains\nabstract, overly generalizing, and set in the rhetorical\nmodes of unmasking and admonition. In both cases,\nthe concrete technological fieldwork going into the con-\nstruction of the data collection and analysis infrastruc-\nture remains uninvestigated.\nThis paper turns to the allied fields of software and\nmore in spirit than in letter, in order to inquire how the\ntechnicity of an API intervenes in the practice of an\nactual empirical research project based on data gleaned\nfrom Facebook. While software and platform studies\ngenerally consider more far-reaching social and polit-\nical matters, they have indeed called attention to the\nspecific architectures and logics embedded in digital\nartifacts. One of the goals, here, is to show that this\nattention is indispensable for data-driven research, not\nonly to avoid skewed results, but also as a valuable\nresource when it comes to developing analytical strate-\ngies and interpreting findings. How much confidence in\na variable should we have and, consequentially, how\nmuch explanatory weight can we burden it with? Is a\nparticular variable an indicator for an aspect of the\nphenomenon under scrutiny or an artifact of the plat-\nform's functional design? And, framed more positively,\nwhich methodological opportunities does an API pro-\nvide in the first place and how can we make them serve\nour analytical objectives? If ``raw data'' is indeed an\nbeen precooked? How to process them even further? In\nshort, how does an appreciation of the technicity of a\nplatform help us make sense of the data captured from\nand through it?\nTo approach these questions in concrete terms, we\nstay mostly clear of a general discussion of the role of\nAPIs in research and focus instead on the trials and\ntribulations of a particular social media research tool,\nNetvizz, which has enabled scholars to export data from\n2 Big Data & Society\nwe discuss a research project that investigated the role\nthe ``We are all Khaled Said''2 Facebook Page3 played in\nthe Egyptian revolution of 2011 and beyond. This Page,\nfounded by the Egyptian Google executive Wael\nGhonim in June 2010 after the brutal death of a young\nman in police custody, has been consistently singled out\nby scholars as a major driver of the political events that\nled to the resignation and incarceration of president\nand Wilson, 2012). Our research project brought\ntogether media scholars, political scientists, linguists,\nand Arabic scholars, who cooperated around a large-\nscale dataset retrieved from Facebook through its API.\nWhile the main findings of this project are reported else-\nwhere (Poell et al., 2015), we consider the issues we\nencountered and the methodological strategies we\nemployed to be substantial enough to warrant a separate\ndiscussion of these methodological aspects. This decision\nis further justified by the relative lack of attention paid to\ndata-driven Facebook research, in particular when com-\npared with the much smaller Twitter platform. There are\na number of reasons for this imbalance, but the ``gener-\nally public nature of tweets and replies'' (Bruns and\nFacebook's much more restrictive and complicated\narchitecture, already pulling the technical dimension\ninto the foreground. By addressing both limitations\nand opportunities for data-driven Facebook research,\nthis paper will hopefully prove useful to other projects\nand, at the same time, contribute productively to a\ndeepening of the critical debate around API-based\nsocial media research.\nIn order to achieve these goals, our argument pro-\nceeds in three main steps: we first discuss the Facebook\nplatform with an emphasis on Pages and briefly sum-\nmarize previous empirical work; we then examine\nFacebook's API from the angle of empirical research;\na final section outlines the exploratory approach we\nadopted in our project and proposes a number of con-\ncrete techniques to analyze activity on (very) large\nFacebook Pages. We conclude by advocating for\nincreased critical attention to technicity in social\nmedia research, as a means for both data critique and\nrecognition of analytical opportunities.\nFacebook and Facebook Pages\nWhen scrutinizing the technicity of APIs in relation to\nempirical research, we cannot ignore the technical\ninfrastructures data collection interfaces provide\naccess to. This section therefore outlines the larger\nresearch setting we are confronted with, discusses the\nspecific role of Facebook Pages, and summarizes previ-\nous efforts to analyze them.\nFacebook as infrastructure and research setting\nstructure occurs when local practices are afforded by a\nlarger-scale technology, which can then be used in a nat-\nural, ready-to-hand fashion'', and this applies perfectly\nwell to Facebook. Having expanded rapidly beyond its\ninitial domain as a service designed for college campuses,\nit now counts 1.39 billion monthly active users,4 and can\nbe considered a general-purpose communication plat-\nform that hosts a vast collection of variegated practices.\nAll of these practices are enabled and structured by the\nsame grammars of action (Agre, 1994), the same set of\naction possibilities and interface features, even if local\nappropriations can vary significantly.\nFrom a methodological perspective, these infrastruc-\ntural qualities draw a parallel between social media plat-\nforms and social experiments in the sense that interfaces\nand functionalities establish a controlled environment\nthat users act in, but have little power to change. There\nis neither a ``dislike'' button in Facebook's vocabulary of\naction possibilities, nor one labeled ``interesting'', ``sad'',\nor ``strange''. The artificial conditions social experiments\nsubmit their subjects to normally serve to isolate a par-\nticular aspect of behavior or cognition, with the goal of\nmaking it measurable. But the goals of social media ser-\nvices have little to do with academic research and, even if\nwe consider obvious commercial interests, these plat-\nforms are significantly more open-ended than research\nexperiments. Nonetheless, the controversy over a recent\nstudy (Kramer et al., 2014), where researchers affiliated\nwith Facebook manipulated users' News Feed to show\nhappier or sadder messages, should not distract from the\nobservation that the whole contraption is a designed\nenvironment and the News Feed is already painstakingly\noptimized to produce more engagement, longer time on\nsite, and, at the end of the day, higher advertisement\nrevenue. When working with data collected from APIs,\nwe engage with a technical infrastructure that reflects the\noperational goals of a company and is merely inhabited\nby users.\nAPI-based social media research does not rely on data\nproduced by methodological devices conceived by\nresearchers, such as questionnaires or observational\nprotocols, but on ``already formatted'' (Marres and\ntechnical interfaces containing standardized information\nfields specified by the platform provider. These fields do\nnot simply represent an arbitrary observational grid of\ncategories or variables that captures an otherwise unruly\nand overflowing external reality into a formalized set of\ndata points. The shape of the data retrieved from APIs\nclosely mirrors the technical infrastructure. A post\nappearing in a user's News Feed--the filtered stream\nof ``stories'' appearing in the middle of a user's home\npage--corresponds to the API entity ``/post,''5 and the\nRieder et al. 3\nvarious data fields reflect different properties of that\nitem, for example its author, the publishing date, some\ncontent, a like count, and so forth. When considering\nthese variables, we are confronted with a semantic bifur-\ncation: on the one side, we can read them as markers of\nusers' intentional behavior; but on the other side, these\nproperties have meaning as part of a technical system. A\npost's like count can be interpreted as a measure of\nattention, engagement, or resonance--even if such attri-\nbutions are rarely straightforward--but, at the same\ntime, it functions as a means for the system to decide\nwhether to show a post in certain users' News Feeds or\nnot. The purely technical meaning of a like, the way it\nbecomes part of chains of technical causation, has con-\nsequences for concrete outcomes, such as the contents\nactually seen by users. And these consequences are inde-\npendent from any ``social'' meaning we may want to\nattribute to a variable. We should therefore recognize\nthat what we are studying when using data collected\nfrom APIs is not only a sociotechnical phenomenon,\nbecause human practice is channeled through interfaces\nand data structures, but also because the system itself\ninterprets these practices and responds to them on the\nlevel of the interface. Although we cannot easily attri-\nbute outcomes to either technical functioning or user\nagency, we should attempt to describe and delineate\nthe contributions of the technical system as a particular\nand pervasive actor. This is the first level of technicity we\nneed to take into account when working with data col-\nlected from social media platforms.\nFrom campus to public space\nThe technical characteristics of a platform take shape\nduring a design process where forms and functions are\nrelated to use case scenarios embedded in what is gener-\nally called a domain. In the case of Facebook, one could\nsay that the initial domain was ``life on campus'' and\ndesigning a system that both fits the domain and adds\nsomething appealing to it required both analysis or\ndescription (``what are the important aspects of college\nlife?'') and synthesis or prescription (``these functional-\nities will allow users to have a better college life'').\nOver the years, Facebook's domain has widened to\ninclude basically any area of human interaction. This\nbroader focus became evident in 2006 when Facebook\nstopped requiring a university email address to sign up.\nNowadays, according to the company, ``[p]eople use\nFacebook to stay connected with friends and family, to\ndiscover what's going on in the world, and to share and\nexpress what matters to them''.6 The aspiration to target\na wider set of practices was further realized in November\n2007 with the introduction of Facebook Pages, which\n``are for businesses, brands and organizations to share\ntheir stories and connect with people''.7\nPages thus occupy a distinct place in the larger plat-\nform, which mediates expression, exchange, and coord-\nination in a number of different ways. In terms of\nschematic constellations, Facebook combines symmet-\nric point-to-point networks, group communication\n(Facebook Groups), and forms of mass media like\none-to-many communication (Facebook Pages). These\nelements are largely arranged around two types of enti-\nties: profile entities such as user profiles, Groups, and\nPages have basic descriptions attached to them and,\nmost importantly, function as organizing structures\nfor content items such as posts, which are always pro-\nduced by and attached to a profile entity. Pages are thus\nessentially streams of content items posted by the Page\nadministrators, who can choose to allow user posts as\nwell. In both cases, users can comment on posts, like or\nindividual comments. As we lay out in more detail\nbelow, these features are prone to evolve, affecting\nboth actual use practices and the analytical possibilities\navailable to researchers.\nPages constitute the most public parts of Facebook:\n``Facebook Pages [. . .] are public spaces''.8 They can be\naccessed without signing into an account and are most\noften used by organizations for presentation, outreach,\nmarketing, and so forth. In contrast to Groups, where\nvisibility and access can be modulated in various ways,\nPages provide few means to limit their audience and\nthose that exist target individual users only: an admin-\nistrator can ban users, unsubscribe them by removing\ntheir like, and delete their posts or comments. Everyone\ncan view posts on the Page itself, but an integral part of\nFacebook's architecture is dedicated to enabling and\nmanaging the flow of content items from profile entities\nto users' home pages, where they appear in the News\nFeed. Since this feed is by default filtered via an opaque\ncombination of metrics and machine learning, aca-\ndemics have critically interrogated this ``technical struc-\nmost virulent debates have been occurring in marketing\ncircles around the apparently shrinking reach of posts.\nCompared to other social media platforms, Facebook's\ncontent distribution architecture is quite complex. By\nfriending people, joining Groups, or liking Pages, a user\ncan subscribe to the output of these profile entities, which\nmeans that their content items will start appearing in\nthe user's News Feed. Engaging with content items\nfrom a particular profile entity through liking, sharing,\nor commenting leads to a higher probability that items\nfrom that entity will move through the filter in the\nfuture. But engaging with a post also grows the probability\nthat it will appear in other people's News Feed.9 Once\nit does appear, users can decide to share the item with\ntheir friends, thereby distributing the content beyond\nthose subscribed to the author of the post in question.\n4 Big Data & Society\nThe significance of these architectural complexities for\nresearchers is considerable. For example, since content\nitems percolate through the network, gauging the actual\naudience of a post without access to a Page's administra-\ntor interface is very difficult and metrics such as like or\nshare count, while certainly not without merit, are imper-\nfect stand-ins. For lack of a better alternative, most of the\nexisting work on Pages has built on these metrics.\nPrevious work on Facebook Pages\nDespite the strong uptake of Pages by companies and\npublic figures, the research literature on Facebook has\nbeen dominated by more ``private'' aspects and uses. A\nreview article from 2012 surveyed existing literature on\nFacebook and identified ``412 relevant articles, which\nwere sorted into 5 categories: descriptive analysis of\nusers, motivations for using Facebook, identity presen-\ntation, the role of Facebook in social interactions, and\ninteresting division in research focus: while those parts\nof the social sciences that are mainly preoccupied with\npublic communication concentrate on Twitter, psych-\nology--and, in particular, social psychology--has\nshown a deep interest in the research opportunities\nafforded by Facebook, a platform that is seen as\nmore conductive to the expression of an authentic\nself. This bifurcation, in conjunction with Facebook's\nmore challenging setting for API-based research, is\nprobably the main reason why empirical and computa-\ntional studies focusing on the public side of Facebook\nare still rare.\nWhen it comes to investigating the practices develop-\ning around Pages, most existing studies examine the\nactivities of political or commercial actors in relation\nto user engagement, in line with the basic communica-\ntive constellation Pages suggest: a rather clear separ-\nation between administrators who write posts and\nusers who read and possibly react. A first group of\nscholars analyzed Pages maintained by government\n(Alam and Walker, 2011) or political candidates\nduring election campaigns (Gulati and Williams,\non collections of company Pages (Bonso\n\u00b4 n and Ratkai,\n2013) or possible metrics for the analysis of such Pages\n(Sabate et al., 2014). Finally, a recent paper (van Es\net al., 2014) investigated two Pages representing oppos-\ning views in a public debate in the Netherlands. In most\nof these studies, scholars relied on relatively simple fre-\nquency counts for posts and engagement metrics based\non liking, commenting, and sharing, which are often\ncombined with content classification of posts and/or\ncomments. Only one paper (van Es et al., 2014) ana-\nlyzed the temporal distribution of user comments. The\nstudies working with data captured from Facebook's\nAPI used ready-made tools and did not reflect further\non the status and validity of these data.\nWhile computer scientists have written on the tech-\nnical design and use possibilities of the Facebook API\n(Mu\n\u00a8 ller and Thiesing, 2011), there has been little critical\nassessment. Bodle (2011) is one of the few authors\nhaving investigated the API critically, but his focus is\non the larger commercial logic rather than the issues\nencountered by empirical research. The rest of this\npaper is therefore dedicated to an analysis of the API\nin relation to the data-driven study of Facebook Pages.\nFacebook's API and empirical research\nThe appealing possibility to easily collect large amounts\nof potentially interesting data from social media ser-\nvices without the need to ``scrape'' them from the inter-\nface is contrasted by the observation that practical\naccess is governed by APIs that are not only ``far\nfrom neutral tools'' (Bucher, 2013: n.p.), but subject\nto a company's fluctuating view of how sharing data\nand functionality with third-party developers can bene-\nfit their platform. Facebook's API is no exception. In\nthis section, we will thus engage in technical fieldwork\nand propose a critique of the API based on the numer-\nous issues we encountered during the development and\nmaintenance of the Netvizz application and the Khaled\nSaid research project.\nFacebook's API\nAPIs are constructed for different purposes, but mainly\nto make platforms or services more appealing to users by\nadding functionality, public presence, and so forth.\nFacebook, in particular, has close relationships with\nthird-party developers, especially with social gaming\ncompanies or dating apps like Tinder that require a\nFacebook account and provide incentives to groom\none's profile. Academic research is certainly not con-\nsidered a central part of the intended audience for APIs\nand this shows both in the way these interfaces work and\nevolve and in the reluctance to provide any special pro-\nvisions to (external) scholars. But instead of entering fur-\nther into the debate about the more general questions\nattached to working with APIs (cf. Lomborg and\nBechmann, 2014), we want to focus on the specific case\nof Facebook and, in particular, Facebook Pages. In this,\nwe follow the call by Lazer et al. (2014) to ``study the\nalgorithm'', which we consider the API to be a part of:\nTwitter, Facebook, Google, and the Internet more gen-\nerally are constantly changing because of the actions of\nmillions of engineers and consumers. Researchers need\na better understanding of how these changes occur over\nRieder et al. 5\nIn the case of Facebook's API, there have been numer-\nous and far-reaching changes over the years, including\nthe introduction and deprecation of a considerable\nnumber of access paths. The company's first interface,\nand received several significant updates over the follow-\ning years. The first version introduced the general setup\nof Facebook's data access regime: to receive the neces-\nsary access credentials, one needs to create an app and\nregister it. In addition, all calls to the API have to be\nsigned with tokens identifying the Facebook account of\nthe current user of the app. Data access is thus always\nframed from the perspective of a particular user and\nthat user's place in the larger system determines\nwhich elements can be retrieved. While some elements,\nin particular those collected from Pages and public\nGroups, are visible to everyone, the access to personal\ninformation depends on the particular friendship con-\nnections and group memberships of the app user. For\nexample, apps are able to acquire considerable amounts\nof data from the signed-in user and her friends, but\nmuch less from people beyond her immediate network.\nDuring installation, apps have to explicitly ask permis-\nsion to access certain data and users' privacy settings\nfurther affect what can be collected. Since apps are\noften used by a large number of people and datasets\nretrieved from different user scopes can be easily\nmerged, successful apps can collect enormous amounts\nof information. However, Facebook's push towards\nstronger privacy has already begun to curtail data gath-\nering possibilities.\nBack in February 2007, however, Facebook added a\nsecond point of access to complement the REST API,\nfacilitating more complex interactions with the data\npool. The Facebook Query Language (FQL), a subset\nof the Structured Query Language (SQL) used by the\nhighly optimized MySQL servers Facebook runs its\nbackend on, allowed for powerful filtering and concat-\nenation, quite uncommon in the web-API space.\nRetrieving complex compound data such as large\nfriendship networks became considerably easier and\nmuch faster. In October 2009, the company finally\nintroduced the so-called Graph API, a redesign of the\nREST API, which facilitated app development by\nmoving the API interface closer to the entities and rela-\ntionships Facebook's architecture and interfaces are\nler changes or additions were made, but the general\nsetup remained by and large the same. The year 2014,\nhowever, marked a turning point. Over the span of\nGraph API were introduced and older access methods\nhave since been progressively deprecated and shut\ndown. These new interfaces represent a considerable\nchange in philosophy and mark a multilayered move\ntoward much stronger protection of user privacy vis-\na\n` -vis third-party apps. This includes the adoption of\napp-scoped identifiers, making it impossible to combine\ndatasets retrieved through different apps; the removal\nof FQL in v2.2; the progressive disappearance of\nfriendship relations and News Feed access from all\nAPIs; an obligatory review procedure for all apps that\nask for more than the most basic access permissions.\nSince we are still in the middle of these changes, it is\nhard to fully assess their significance for researchers,\nbut it is already clear that they will be far-reaching.\nDuring the writing of this paper Netvizz, the app we\nused to retrieve our Egyptian dataset, was blocked by\nFacebook and could only be reinstated after all features\nfor personal data export were removed. Although some\nof these elements are still available through the API, the\ncapacity to export them--crucial for research--is pro-\nhibited by the company's platform policy. Facebook's\ndifferentiation between public (open) and private\n(closed) has become the structuring element for API\naccess control.\nFor the moment, Facebook Pages have not been\naffected by these limitations. Facebook's decision to\nrender them public to the largest possible degree--one\nneed not even sign into Facebook to access a Page--\ncontinues on the level of data capture via the API.\nAlthough we will nuance this statement further down,\nFacebook grants access to all of the content entities on\nthe Page since its inception, to all comments on posts,\nand to all users that liked or commented on a post. This\nmakes these Pages eminently accessible to computational\nresearch. For our project, we were able to retrieve 14,072\nprofiles are generally well protected, users' names were\navailable in full. Considering Facebook's real name\npolicy, the sheer mass of retrievable information through\nPages should give us pause.\nAPI fieldwork and data critique\nWorking with an API is not only bounded by the con-\ntinuously evolving technical interfaces and the policies\nthat accompany them; to fully investigate the technical\nfieldwork going into the data collection process one\nwould have to include many different elements. APIs\nare idiosyncratic objects that vary, for example, in how\nconnections are managed (Twitter allows for persistent\nnear-realtime connections, Facebook only allows for\nconventional call-response access), how errors are\nhandled (Facebook's API used to often fail without\ngiving reasons), how call frequency is governed\n(Facebook has a complicated three level system for\nrate limiting11), or how far back in time data is made\naccessible (Facebook has few time limitations, Twitter\n6 Big Data & Society\nseverely restricts free access to historical data). All of\nthese aspects need to be attended to when working with\nan API and the chance that any kind of research soft-\nware can fully deal with a constantly changing set of\nissues is small. This does not mean that these things\ncannot be done well; but the blackboxing of an import-\nant part of the research chain is a real issue when it\ncomes to assessing the merit of findings.\nTo compensate for some of these difficulties, compa-\nnies usually provide different tools to assist developers\nin their work. These not only include testing or sandbox\nenvironments such as the Facebook API Explorer\nshown in Figure 1, but also Software Development\nKits (SDKs) that wrap actual HTTP calls behind lan-\nguage-specific functions or classes, thereby providing a\nhigher level API that sits on top of the actual API. This\nmakes development faster and more convenient, but\nadds yet another link to the chain. A wider approach\nto API fieldwork would have to include these tools, as\nwell as sites like Stack Overflow12 that host commu-\nnities of practice engaged in mutual assistance and,\nbecause questions and answers are visible to everyone,\nin the accumulation of deep knowledge about the pecu-\nliarities of popular APIs. Although such a wider exam-\nination is beyond the scope of this paper, a more\ndetailed account of our encounter with Facebook's\nAPI is crucial for our argument.\nWith the help of a modified version of the Netvizz appli-\ncation--the public version is unable to deal with Pages the\nsize of ``We are all Khaled Said''--we collected our data in\nJanuary 2014, covering the full period of posting activity\nretrieved all of the posts from the Page, as well as the\ncomments, likes, and shares these posts received.\nResearchers usually use counts of these elements as indica-\ntors for resonance or engagement, and one can rightfully\nwonder whether ascribing ``a single meaning to any of\nthese behaviors masks the complexities of users' actual\nintentions and experiences'' (Driscoll and Walker, 2014:\n1747). But before we can even begin to connect with this\nlevel of interpretation, the mere technical meaning of these\nvariables poses a number of challenges.\nFigure 1. Facebook's API Explorer, a helpful tool for developers to test API calls. The image shows the result (in JSON format) of a\nbasic Graph API v2.2 call for the ``We are all Khaled Said'' Page.\nRieder et al. 7\nA first concern is data detail. As Table 1 summarizes,\nthe API does not provide the same facets for the three\nmain user actions on posts and thus delimits analytical\npossibilities. Comments are both time-stamped and\nattributed to individual users, likes are missing the tem-\nporal component, and the data concerning shares is a\nsimple counter without any user information. As we\nwill show in section four, fine-grained temporal analysis\nis possible for comments, but not for the other two\nactions. The differential availability of detail also\nposes problem when it comes to dealing with continu-\nous activity on ``historic'' content items. The Khaled\nSaid Page, for example, is no longer active in the\nsense that administrators have stopped adding new\nposts; but users continue to like and comment on exist-\ning posts. Should we consider a comment or like on a\npost weeks or months after it was published differently\nfrom more immediate reactions? Independently of our\nanswer, the API already intervenes in this matter since\nonly comments are delivered with a timestamp. We\ncould thus exclude all comments made after a certain\npoint in time from our calculations, but the same oper-\nation would not be possible for likes and shares. For\nour project, we opted to leave the issue aside, since tests\ndid not reveal a fundamentally different picture when\ndiscounting newer comments, but this may be a bigger\nproblem in other cases.\nA second issue is completeness. While Facebook\nseems to provide complete access to data, the question\nis more complex than it appears at first glance. For each\npost on a Page, the API indeed provides a list of likes\nand comments containing user names and identifiers. If\nexplicitly requested, Facebook also provides a simple\ncount for both elements. When comparing this count to\nthe number of elements actually retrieved, we noticed a\nsystematic discrepancy between the two: the number of\nretrieved likes on posts was on average 7.1% lower than\nFacebook's count (a mean of 2,276 likes retrieved vs.\n657). While we cannot be sure about the exact reasons\nbehind these discrepancies without confirmation from\nFacebook, they can be explained in a number of ways:\nboth likes and comments can be retracted, accounts can\nbe deleted, and privacy settings can reduce the elements\nretrievable through the API.13 But what explains the\ndisparity in missing elements between likes and com-\nments? These are governed by the same privacy settings.\nPossible explanations could be that administrators\nactively deleted an important number of comments or\nthat some heavy commenters deleted their accounts. But\nthis is largely speculation. For our project, we selected\nFacebook's counts for quantitative analysis, but textual\nanalysis could obviously only be applied to the retrieved\ncomments. When it comes to share counts, however, an\nadditional caveat applies. Until early 2015, the API only\nprovided a value for public posts if they were shared\nmore than ten times--below that number, the field\nremained empty.14 Any descriptive statistic based on\nFacebook shares should thus be taken with an extra\ngrain of salt, in particular when it comes to comparing\nresults from different studies.\nPlatform changes constitute a third problem. During\nthe lifetime of the Khaled Said Page, Facebook imple-\nmented a number of important new features, for exam-\nple the introduction of a multiple-choice polling widget\nin late March 2011 or the possibility to like and reply to\ncomments in March 2013. For our study, the first\nchange in particular is highly relevant. Before and\nduring the ``hot'' phase of the revolution in January\nand February 2011, the Page administrators had fre-\nquently made use of proto-polling by asking users to\nwrite their preference in a comment and counting votes\nmanually. The move to a structured polling fea-\nture--which was removed again in June 2013--did\nthus not only affect the practices on the Page, but\nupsets the way we have to look at comment counts\nbefore and after its introduction. Since there is no\nsimple quantitative solution to this problem, constant\nawareness when interpreting results is necessary.\nA fourth issue is Facebook's complex architecture.\nSince certain functionalities cannot be directly embedded\ninto a post, user activity may happen elsewhere. For\nexample, when a Page administrator creates a new\nFacebook Event--another platform-specific feature--an\nannouncement post is created, but commenting, liking,\nand sharing mostly happen on the page of the event\nrather than the main Page, keeping the counts for the\npost low. Since these event pages provide different func-\ntionalities and interaction possibilities, even if there was\nan easy way to automatically find and include them,\ncould we simply fuse the metrics into the main dataset?\nWe may be tempted to dismiss these concerns as\n``noise'' or as something that can be ``corrected for'',\nbut we would like to advocate prudence and critical\nattentiveness when it comes to using these seemingly\nrobust data. While none of these issues preclude\nmaking interesting and deep findings, when taken\ntogether, they force us to fully engage in a form of qual-\nculative assessment (Cochoy, 2002) of the quantities we\nare presented with, even before we engage in any\nTable 1. The data facets available for the three actions on\nposts: commenting, liking, and sharing.\nComment Like Share\nCount Yes Yes Yes\nIndividual user list Yes Yes No\nTime-stamp Yes No No\n8 Big Data & Society\ninterpretation concerning user activities. What we\nencounter when dealing with Facebook's API is not\nsimply that variables and their values are ``constructed'',\nbut that this construction has particular characteristics\nthat need to be interpreted and accounted for.\nSomewhere in Facebook's backend lurk a couple of\nshort lines of code that construct the values behind the\n``total_count'' API field for likes and comments, and these\nlines determine how retracted reactions, removed com-\nments, and deleted accounts are to be counted.\nSomewhere else a few lines of code are missing that\ncould transfer the like count from an event to the post\nannouncing that event. And these lines could change at\nany minute. Before we can even begin to interpret a vari-\nable in relation to its meaning in the context of human\npractice, we need to consider its production in the bowels\nof a server farm. While we usually cannot access the\ndetails of these procedures, this section has hopefully\nshown that we are not completely devoid of means to\ninvestigate and understand the peculiarities of the data\nwe receive. API fieldwork cannot make the mentioned\nproblems disappear, but it can contextualize and clarify\nthe status of the data, preparing its use as a set of indi-\ncators. The following section further explores Facebook's\nAPI, but moves from technical concerns to the many\nanalytical possibilities it affords.\nAnalytical possibilities\nDespite the various caveats, the data retrieved from\nFacebook Pages is rich in detail and allows for a variety\nof analytical techniques to be applied. In this section,\nwe use the Egyptian ``We are all Khaled Said'' Page as\nan example to discuss four methodological directions\nthat build on the data structures provided by\nFacebook's API in relation to a concrete and complex\ncase. These four directions take an explorative perspec-\ntive, which we first need to introduce.\nExploration and description\nResearch on the basis of data gleaned from APIs unfolds\nin a peculiar analytical setting. There are indeed large\namounts of well-structured data to be collected, but\nresearchers have little to no influence on the actual elem-\nents made available. As argued above, not only are the\nparameters of the social experiment defined by\nFacebook, but the analytical grid of variables is as\nwell. For many projects studying online activity, in par-\nticular those following a classic waterfall-type research\nprotocol where the inquiry starts with a precise research\nquestion and methods are designed in accordance, data\ncollection through APIs will thus not be a workable\noption, or at least not without additional data gathered\nthrough other means such as questionnaires.\nThis is one of the reasons why social media data\nanalysis at this stage often deviates from what statisti-\ncian John Tukey called ``confirmatory data analysis'',\nor basically hypothesis testing, to engage in ``explora-\ntory data analysis''. While increasing stabilization of\nthe field has led to a rise in hypothetico-deductive\nresearch, the variety and complexity of social media\ndata often calls for more open-ended analysis or\n``detective work--numerical detective work--or count-\ning detective work--or graphical detective work''\n(Tukey, 1977: 1). Sharing inductive affinities with meth-\nodologies such as grounded theory, ``the discovery of\nexploratory data analysis begins with a broader\nresearch interest and refrains from applying a hardened\ntheoretical frame that would allow for the formulation\nof a testable hypothesis. Concepts are certainly brought\nin at various stages, but mainly through active theoriz-\ning in conversation with the data. Exploration, how-\never, does not simply mean plunging into the data or\nthat the data ``speak for themselves''; it means iterative\nprobing and systematic construction on both the empir-\nical and the conceptual level. The scope of the inquiry\nbecomes progressively narrower and more refined as\nunderstanding increases. But, according to Tukey,\n``[d]ata analysis must progress by approximate answers,\nat best, since its knowledge of what the problem really\nExploration recognizes that local social realities are\nrich and diverse enough to challenge preconceived\nassumptions and emphasizes learning and flexibility\nover artificial precision.\nSince exploratory data analysis operates mainly\nthrough descriptive statistics, often relying on charts\nand summaries,15 one can establish a connection with\nother proponents of the recent ``descriptive turn''\n(Savage, 2009), such as actor-network theory, where\nattributions of causality are bracketed in favor of\nmeticulous description. Transposed to the issue at\nhand, Latour's call to ``follow the actors themselves''\nthrough the data, following ``a process of assemblage,\nwhere processes of creativity, conceptual innovation,\nand observation can be used to mobilize novel insights''\nsocial science and humanities disciplines, descriptive\napproaches challenge traditional demarcations such as\nqualitative/quantitative. In the context of data-driven\nsocial media research, this is practically facilitated when\nthe sample is complete, i.e. when all of the members of\na population, for example all posts on a Facebook\nPage, are included. Researchers can then move with\nrelative ease between micro and macro levels and com-\nbine intensive and extensive perspectives. Instead of the\nusual demarcations, we are then faced with the\nRieder et al. 9\nqualculative dilemmas evoked in previous sections of\nthis paper:\nThe traditional tension between `qualitative' and `quan-\ntitative,' therefore, is rendered obsolete with the intro-\nduction of Big Data techniques. In its place, we see a\ntension between the empirics of raw numbers, the algo-\nrithmics of mechanical filtering, and the dictates of sub-\njective judgment, playing itself out in the question that\nCameron raised more than 50 years ago: what counts\nWhile a critical interrogation of this renaissance of\ndescription is certainly necessary in its own right, the\nindeterminate character of much social media activity\ncalls for iterative and flexible approaches that can com-\nbine different perspectives and levels of analysis.\nDespite the channeling qualities of defined interfaces\nand functionalities, very different forms of exchange\ncan emerge around identical technical structures. The\ncharacteristics of the ``channel'' are far from irrelevant,\nbut even a Facebook Page is designed in ways that\nallow for the emergence of a wide array of different\npractices and dynamics.\nIn our analysis of the Khaled Said Page, we started out\nfrom a specific research interest that mainly concerned\nthe ways the Page served as a means for expression,\nexchange, debate, coordination, and mobilization in\nthe complex and fast-moving context of a revolution.\nWhile the main findings of our project are reported else-\nwhere (Poell et al., 2015), the following sections outline\nthe four principal methodological perspectives we\napplied to a remarkable dataset.Since the technical infra-\nstructure is the same, these techniques can be applied to\nany Facebook Page, regardless of its size. But scale is\nrelevant in other ways: the techniques we describe over\nthe following pages are relying heavily on statistical sum-\nmaries and data smoothing, both of which become prob-\nlematic when the number of elements drops. Exploratory\ndata analysisthus needs to maintain its ``research-as-pro-\ncess'' outlook when it comes to formal techniques,\naccepting that ``relations between subjects, objects,\nmethods and techniques'' (Marres and Weltevrede,\nOverview and user analysis\nAlthough the Khaled Said Page is only one Facebook\nPage among millions, the amount of activity it hosted\n2013, when the administrators were making posts\nnearly every day, is staggering.\nRelying on API counters, the 14,072 posts the Page\nadministrators published over three years received, on\ngoing regularly much higher, in particular during the\nInterestingly, the most commented on post is one of\nthe proto-polls mentioned above, asking users how\nthe protests should continue on the morning of what\nwould become the ``Friday of Departure'', 11 February\n2011, the day Hosni Mubarak resigned. The extreme\ntenacity of the administrators merits particular atten-\npassed without a post. This already points towards one\nof our key findings, worked out in more detail in Poell\net al. (2015), namely the important role the administra-\ntors played as ``connective leaders'' (Della Ratta and\nValeriani, 2012) that distributed information, coordi-\nnated decision-making, and kept up the momentum.\nUsers can like a Facebook Page, which practically\nmeans that they subscribe to its content feed. In early\n2015, the Khaled Said Page had received over four mil-\nlion likes, but the API provides no additional detail for\nthis metric. We can neither collect a list of users, nor\ninvestigate the count's evolution over time. What we\ncan say about the audience of a Page thus only con-\ncerns the population active on a Page: since no user list\nis provided for sharing and our Page does not allow\nuser posts, this means active through liking or com-\nfrom the lists of likes and comments of all posts. The\nAPI provides full names and identifiers, which Netvizz\nanonymizes using the SHA-1 hashing algorithm.16\nBecause Facebook did not allow users to block infor-\nmation of gender and the user-chosen interface lan-\nguage without opting out of app use altogether, these\ntwo variables were available for nearly all users.\nWhile the dominance of English shown in Figure 2\nmay indicate a large presence of foreign or even western\naudiences of the Page, there are good reasons to believe\nthat this is not the case. First, Facebook's Arabic inter-\nface only launched in 2009 and many users may simply\nnot have switched over. Second, virtually all content on\nthe Page is written in Arabic. And third, when\nMubarak ordered the Internet in Egypt shut off in\nJanuary 2011, numbers for both comments and likes\nTable 2. A statistical summary of user reactions around posts.\n10 Big Data & Society\ndropped dramatically. It is safe to say that this Page\nreally was an Egyptian phenomenon.\nSince the API provides lists of users liking or com-\nmenting on a post and each user has a unique identifier,\nwe are able to examine the population of users in rela-\ntion to their activity on their Page. On the most general\nusers liked at least one post, whereas 42.9% engaged\nin commenting. Interestingly, 8.9% commented with-\nout liking. Since we can consider commenting to be a\nmore involved gesture than liking, the relatively high\nprevalence of commenting is a good indicator for users'\nstrong involvement.\nTable 3 documents the often-observed contrast\nbetween a large group of less involved users and a\nsmaller group of heavily involved participants. The dis-\ncrepancy may seem striking, but we must not forget\nthat due to the sheer size of the (active) audience, the\n1% most involved users represent a still large group of\n18,921 individuals. And these ``elite'' users were indeed\nvery active: the 1% most active likers made a third of\nall likes and the 1% most active commenters wrote\n40% of all comments.\nFigure 3 shows size\u00adrank distributions for the two\nsubpopulations of likers and commenters, and while we\ndo find the typical long-tail distributions, neither fol-\nlows a power law.17 The distribution for liking is cer-\ntainly somewhat bounded by the fact that users cannot\nlike a post more than once, but commenting follows a\nsimilar pattern. As we move up in rank, the number for\nboth comments and likes falls off more slowly than a\npower law would predict, which indicates that in par-\nticular the group of most active users is more ``egalitar-\nian'' than the many cases found online where power\nlaws do apply. This reinforces the assessment that the\nKhaled Said Page was dominated by a comparably\nlarge group of very active users. An analysis of the\nactivity periods of users could add interesting nuances\nto this assessment, but is beyond the scope of this\npaper.\nWhen looking at the relationship between liking and\ncommenting we find a correlation coefficient of 0.391,\nwhich is clearly significant, yet indicates that certain\nusers are more disposed to like and others are more\nactive commenters. Figure 4 shows the relationship\ngraphically. Interestingly, the separation becomes\nslightly more pronounced (0.378) when looking at the\ncommenting.\nFinally, we should not forget that the administrators\nthemselves are part of the Page's population. And,\nindeed, because comment users are uniquely identifi-\nable, we found that in addition to the already very\nhigh number of posts the Page's account also contrib-\nuted 3,421 comments. Since we do not know the iden-\ntity of all the administrators and our data is\nanonymized, we cannot say whether they also partici-\npated in the discussions with their own user accounts.\nFigure 2. Overview of gender and interface language.\nTable 3. A statistical summary of user activity.\nThe role of post types\nA more detailed examination of the administrators'\nposts and users' reactions to them is made possible by\nFacebook's built-in classification of post types. When\ncomparing the six types used on the Khalid Said Page,\nwe find a number of significant differences, pointing\ntowards the idea that they indeed played different\nroles on the Page (see Table 4).\nAlthough share counts need to be considered with\nprudence, we can observe a clear tendency: photos, a\nterm Facebook uses for any image, have by far the\nhighest share count, which points to the idea that\nvisual content is emotionally rousing and thus particu-\nlarly ``spreadable'' (Jenkins et al., 2013). Looking at the\nactual images, however, suggests a more nuanced inter-\npretation, since the material has clearly been selected\nfor impact. In the earliest period, images showing\nregime brutality and photos or drawings of Khaled\nSaid dominate. The young man's face, both before\nand after his violent death, became a symbol for both\nthe repressive regime and the innocence or innocuous-\nness of its victims. Wael Ghonim, a marketing execu-\ntive, understood this dynamic very well and, according\nto his own account, worked strategically to build the\na key element.\nFigure 4. Users (n \u00bc 1,892,118) and how much they liked and commented; the smoother line is based on a Generalized Additive\nModel (GAM), provided by R, which shows a slightly more nuanced summary of the relationship between the two variables than the\nusual least squares method.\n12 Big Data & Society\nFigure 5 shows posting activity and use of different\npost types over time. We can clearly see the heavy use\nof images in the early months, and again in the ``hot''\nphase of the revolution in January 2011, where the\nadministrators post photos not only showing the\nlarge-scale street protests, police brutality, and patriotic\nsymbols, but also ``average'' Egyptians holding up signs\nin support of the protests.\nStatus messages, on the other hand, which are often\nshort comments or propositions inviting users to react,\nhave the highest like and comment counts and a much\nlower share count. The administrators use this post type\nto ``dialogue'' with the audience of the Page, either by\nasking for suggestions and feedback or calling to action.\nIn the revolutionary phase, status items dominate, high-\nlighting the coordination role the Page plays during this\ntime. Interestingly, the phase around the constitutional\nreferendum in March 2011, which is characterized by a\nmore ``deliberative'' atmosphere, sees a relatively high\namount of links, which often point to official documents\nor contributions to the debate.\nWhile the technical part of our methodology can be\neasily transposed to other Pages, we caution against\nfixed interpretations of content types. This is one of\nthe many occasions where quantitative analysis needs\nto be accompanied by constant qualitative assessment\nof data items in order to make situated interpretations\nthat consider the particularities of the case.\nTemporal analysis of user activity\nAnother set of techniques allows us to study user activity\nover time. Here, we investigate the ups and downs of\nbasic elements such as post, like, and comment count,\nand develop a set of derived metrics that rely on the spe-\ncifics of Facebook's API, in particular the ability to dis-\ntinguish unique users and the timestamps on comments.\nLooking at Figure 6, we see that there is a strong\nconnection between posts made by the Page and daily\nuser activity, in particular in the pre-revolutionary phase\nthat lasts roughly until late December 2010. During this\nperiod, user activity is almost directly correlated with the\nFigure 5. Both absolute and relative distribution of post types per month.\nTable 4. An overview of the different post types in relation to the likes, comments, and shares they received. Since Facebook's API\nonly provided a share count for public posts shared more often than ten times, we have greyed out the column to signal the more\nprecarious status of this metric.\nCount Mean likes (SD) Mean comments (SD) Mean shares (SD)\nFigure 6. Line graph per day of the number of posts made by the Page, the comments and likes they received as well as the number\nof new users (users that were not active on the Page before) and unique active users. Because of the large variation between numbers,\nwe use a logarithmic scale. For increased legibility, we use a rolling mean calculation to smooth short-term fluctuation by plotting the\nmoving averages for a 28-day window.\nFigure 7. Line graph with the same variables as Figure 6, but for a much shorter timespan and without smoothing.\n14 Big Data & Society\nPage's posts frequency. In early January 2011, however,\nthe situation changes dramatically: while post frequency\ngoes down, all other metrics grow very rapidly.\nFacebook's architecture suggests an interesting interpret-\nation. When liking a Page, users subscribe to its feed of\nposts; posting is thus a means for administrators to\n(potentially) engage users through their News Feed in\naddition to the Page's own interface. Posts function as\nreminders or invitations to participate and increased post\nfrequency heightens the chance that the Page's contents\nand concerns will reach users. When user activation on\nthe Khaled Said Page was still low, the administrators\nserved as campaigners, agitators, or even ``animators'',\nlike the employees at a holiday resort who appear at your\ndoorstep to invite you to the collective morning run.\nJanuary 2011, however, marks the beginning of a revolu-\ntionary dynamic where the administrators' role as anima-\ntors takes a backseat as users reach a level of involvement\nthat no longer requires constant reminding. The admin-\nistrators continue to fuel the movement, but increasingly\nserve as ``moderators'' (van Es et al., 2014) trying to keep\nthe Page inclusive and non-partisan. While we do not\nhave empirical evidence, we can speculate that user\nengagement moves from the News Feed to the Page\nitself, as protest planning and coordination become a\ncentral issue and users follow the events more directly.\nSome nuances become visible when focusing on the\n2011, shown in Figure 7. We first notice two dips on\ndays when no single post was made. We do not know\nwhy the administrators decided to refrain from posting\nplunge in activity that clearly appears in Figure 6\nand separates the flaring-up of protests in Tunisia\nfrom the revolutionary period in Egypt. Does this\nshow the administrators hesitating at a moment where\nthe self-immolation of Mohamed Bouazizi in Tunisia\n(17 December) marks a stark moment of radicalization?\nThe second day without a post, however, can be clearly\nconnected to the arrest of Wael Ghonim (27 January\n2011) and the government orchestrated shutdown of\nvarious Internet services (25 January\u00ad2 February).\nAfter that point, the lower post frequency does little\nto reduce the intense activity on the Page.\nIn addition to these basic frequencies, the ``new users''\nmetric, which counts first time active users, points\ntoward two interesting points in time. The spike on 14\nPage in a single day, coincides with the flight of\nTunisian President Ben Ali, giving further credence to\nthe idea that the Egyptian revolution was inspired or\nemboldened by the events in Tunisia. But the highest\nnumber of new users comes on 11 February, when\n25,941 new users join the celebrations of the ``Friday\nof Departure'', when President Mubarak resigns.\nWhile these metrics already provide an interesting\nview into the dynamics of the Page, the presence of\ntime-stamps on comments allows for an even deeper\nview. To investigate variations in the speed of com-\nmenting, we decided to plot the percentage of com-\nments that were made in the first hour and day after\na post was published.\nOne could argue that the comment speed variations\nshown in Figure 8 indicate a changing sense of urgency.\nFigure 8. Line graph showing the percentage of comments that were made in either the first hour or first day (24 hours) after the\npost was made. Lines are smoothed using a 28-day rolling mean.\nThe highest peak indeed appears during the ``hot'' phase\nof the revolution when 60% of comments are made in\nthe first hour. But we can also observe a close relation-\nship with the Page's post frequency. Users tend to com-\nment on the latest post and more time between posts\ngenerally leads to slower reaction times, for example at\nend of 2012 when the administrators significantly reduce\ntheir output. Outside of the revolutionary phase, some\nusers will continue to comment on older posts, while\nmany others cease their activity as Figure 6 shows. In\ngeneral, however, commenting is very fast. Considering\nthat the administrators posted, on average, 12.5 posts\nper day and sometimes over a hundred, it is not surpris-\ning that the active life of a post is quite short.\nSince the API makes comments available in full-text,\nlooking at text length is an interesting way to begin dis-\ntinguishing between different communicative settings,\ne.g. between more ``agitated'' or ``deliberative'' periods.\nLooking at the average comment length, shown in\nFigure 9, we can clearly see a peak around the consti-\nperiod is characterized by deliberation and debate con-\ncerning Egypt's political and institutional makeup, with\naverage comment length almost doubling compared to\nautumn 2010. Comment length is, of course, a very\ncrude variable, but by providing different measures\nthat express different aspects of the length distribution\nat a given time, the assessment can become more\nnuanced. Standard deviation, for example, gives us an\nidea about the dispersion around the mean: a low value\nindicates that comments are mostly grouped close to\nthe mean, while a high value indicates a combination\nof shorter and longer messages. However, to truly make\nsense of comments, additional techniques are required.\nAnalyzing comments\nWith the exception of the disparities mentioned above,\nFacebook's API makes all comments on Page posts\navailable and, in contrast to Twitter, without limiting\nhistorical access. Whereas one would traditionally\ncreate a sample of cases to account for the full popula-\ntion, a situation where n \u00bc all not only alleviates certain\nmethodological inconveniences (no confidence inter-\nvals!), but also makes it possible to move much more\nfreely between aggregates and individual data points.\nInstead of inferring the whole from well-chosen parts,\nwe can use views of the whole to select specific cases for\nmore detailed or qualitative forms of analysis. Indeed,\nfor the manual content analysis reported in Poell et al.\n(2015), we used quantitative indicators to make a selec-\ntion of posts and comments to translate and analyze.\nFebruary 2011, we selected the three most commented\non posts per day and then the ten most liked comments\nfor a subset of these posts.\nIn addition to qualitative analysis, we built three\nsimple ``distant reading'' (Moretti, 2013) tools that\nallowed us to investigate comments more schematically\nfrom different perspectives. The main findings are\nreported in forthcoming publications, but the three\napproaches are worth mentioning. In order to facilitate\nFigure 9. Line graph showing the average, standard deviation, median, and 90th percentile for the length of comments on posts; the\ngraph is smoothed with a 28-day rolling mean.\n16 Big Data & Society\nfast and interactive exploration of the nearly seven mil-\nlion comments, we developed a tool, shown in Figure\n10, that plots the absolute and relative frequencies of\nthe occurrence of specified terms over time. To paint a\nmore accurate picture of how present actors or issues\nwere, we counted the number of comments they\nappeared in rather than absolute word frequencies.\nPlotting several queries on a single chart made it easy\nto compare; and the ``widening'' of queries through the\nOR operator (e.g. revolution OR uprising) helped us in\ndealing with synonyms and language issues.\nFigure 10 demonstrates that such a simple approach\ncan yield interesting results. One of the questions we\nbrought to the Page was which grievances were\naddressed and how they changed over time. The screen-\nshot shows that in the initial phase after Khaled Said's\ndeath, torture was the main concern--but as time\npassed and critique widened, the question of corruption\ncame to dominate. In the revolutionary phase in\nparticular, when protesters demanded President\nMubarak's resignation, and in the months following\nit, when the country was faced with having to organize\nFigure 10. The interface of our simple text analysis tool, which plots the occurrence of terms over time. The upper line chart shows\nthe absolute number of comments the terms appear in. The area chart below indicates the relative frequency as percentage of\ncomments. Legend: blue, hereditary transmission (of the presidency); red, despotism; orange, corruption; green, torture; purple,\nunemployment. The tool can show the actual comments for the various terms, providing an easy way to move from the aggregate to\nindividual data points.\nthe political aftermath, between 2% and 5% of all com-\nments mentioned corruption.\nA second tool was built to facilitate the exploration of\nthe comment sections of individual posts. This simple\ntool produced word clouds, as shown in Figure 11,\nand was intended as a means to get a quick overview\nof the issues mentioned, in order to help guide further\nanalytical steps. Outputs were not used as findings in\nany of the publications coming out of this project,\nbut the tool played a role in mediating our relationship\nwith the dataset, and merits mention as part of the meth-\nodological and epistemological infrastructure we were\nworking with.\nA third issue we wanted to investigate more\nthoroughly was comment dynamics. Since Facebook's\ncomment system did not allow for threaded communi-\ncation at the time and users rarely mentioned each\nother, we developed a very basic method to visualize\na comment section.\nThe visualization in Figure 12 follows a simple prin-\nciple: there are two rows and in both, every one-pixel\ncolumn represents a comment, starting on the left,\nmoving to the right. In the top row, a black bar signals\na comment from a user who is participating for the first\ntime in the thread, a red bar stands for a user that has\nalready commented, and a yellow bar indicates a com-\nment from the Page administrator. While these elem-\nents could be easily quantified, the visual inspection\nallows for the identification of more ``dialogical''\nmoments in the conversation, in the absence of a\nthread structure. The lower bar adds a means to iden-\ntify repetition, a very common phenomenon on the\nKhaled Said Page. A bar is red if a near identical\ncomment--calculated via Levenshtein's (1966) string\ndistance metric18--has already been posted. This\nallows us to identify repetition.\nFigure 13 clearly shows packets of repeated com-\nments, a common occurrence in our dataset. These\nFigure 11. Word cloud for the over 40,000 messages users wrote on the most commented on post in our dataset.\nFigure 12. Two-row visualization of user dynamics in the comment section of a post.\nFigure 13. A comment section showing packets of comment repetition.\n18 Big Data & Society\ncan be considered as particular forms of ``shouting''\nand, in some cases, can take the form of hundreds of\nidentical comments in a row. Again, one could simply\ncount repeated comments in a single metric, but closely\nspaced repetition is an indicator of a different conver-\nsational dynamic than more stretched out repetition.\nVisual representation makes this difference discernible.\nIt is highly doubtful, however, that we can establish\nstrict correspondence between particular patterns and\nclear types of behavior. The most important function of\nvisualization, here, is the capacity to easily find ``abnor-\nmal'' patterns that can then be examined manually in\nmore detail.\nConclusions\nIn this paper, we examined Facebook's API as a central\nlink in the methodological chain of data-driven empir-\nical research, mediating between a technical platform\nand our desire to understand. Instead of subscribing to\nthe habitual separation between critical conceptual and\napplied empirical work, we combined data critique and\ndata analysis to demonstrate that computational social\nmedia analysis--and Big Data research in general--can\nprofit from such a more integrated perspective. Since\nwe now base findings on data gleaned from opaque\nservices via complicated technical interfaces, what we\nhave called technical fieldwork needs to take a more\nimportant role in empirical research. Without an\ninvolved assessment of data in relation to the platform\nthey pertain to and the means by which they were\nretrieved, results can be highly problematic. But such\nan assessment of the technical rules, rituals, idioms, and\ntaboos that characterize platforms and their APIs is\nimpractical without the grounding of a concrete case.\nWe were able to detect and document most of the issues\nwith Facebook's API because we ran into them. It is\nhighly doubtful that a study of the documentation or\neven technical probing could have led to comparable\nfindings.\nBut this investigation should not stop at the level of\nproblems and limitations. What makes APIs important\nfor empirical work is not just the way they jeopardize\nresearch, but also how they enable or suggest different\ndirections and methods of analysis. In our analysis of\nthe Khaled Said Page, API data allowed us to highlight\nand nuance the role of the administrators as connective\nleaders, to measure the size and composition of the\nparticipating audience, to engage in various types of\nperiodization, and to investigate the issues that were\nraised in the comment sections. These approaches\nwere developed by an iterative articulation between\nour research interest and the possibilities afforded by\nthe API. This again highlights the benefits of an\nexploratory approach. Here, the oppositions between\nmicro/macro, qualitative/quantitative, and manual/\nautomated fade, but instead of disappearing altogether,\nthey give way to a back-and-forth between different\nlevels: the macro perspective helps in deciding where\nto dig deeper and provides context; the micro perspec-\ntive delivers clues and rich resources for the interpret-\nation of larger trends or deviations. But the cycles of\niteration also facilitate the coordination between the\ntechnicity of platform and API on the one side and\nthe empirical case on the other. We are still far away\nfrom a stable and standardized relationship between\nthe two that would allow us to easily ignore the\nformer when analyzing the latter. This is indeed the\nmain reason why we presented and discussed analytical\nopportunities in close relationship with an empirical\ncase and not as a set of abstract techniques. While the\ntechnical part of the analysis can be easily transferred,\ninterpretation is deeply caught up in the particularities\nof local settings and the massive amounts of data avail-\nable do not change this in any way.\nLooking back at the various difficulties, changes,\nand obscurities we had to deal with leads us to an\nambivalent assessment of social media analysis\nthrough APIs, since researchers are put into a position\nwhere the promise of high-volume and high-quality\ndata is contradicted by a strongly asymmetric relation-\nship with the platform provider, who shapes informa-\ntional structures, defines policy, and imposes ever\nevolving logistics. For this to remain a viable avenue\nfor research, we need more than continuous technical\nfieldwork. A sustainable setting that keeps our under-\nstanding of social media practices from slipping into\nthe obscurity of in-house research will have to include\nlegal expressions of the public's legitimate interest to\nknow what goes on in these huge sociotechnical struc-\ntures. Without an equivalent of fair use principles or\nsimilar provisions, social media analysis risks becom-\ning impossible for researchers that operate independ-\nently from commercial interests, because the work we\nhave outlined in this paper may simply become too\nburdensome. Only a system of research rights vis-a\n` -\nvis online platforms can assure that the production\nand dissemination of knowledge concerning the activ-\nities of billions of users does not become privatized\nentirely.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with\nrespect to the research, authorship, and/or publication of this\narticle.\nFunding\nThe author(s) received no financial support for the research,\nauthorship, and/or publication of this article.\nNotes\n1. As an illustration, when working on research software for\nTwitter (Borra and Rieder, 2014), the connection between\none of our servers and Twitter's API would systematically\ndrop without giving any indication of the underlying\nreason. After hours of searching, we found out that our\nserver's system clock had been running late and that the\nAPI would not allow a time mismatch of more than five\nminutes.\n2. https://www.facebook.com/ElShaheeed\n3. ``Facebook Pages'' is the official name of the particular\nfeature or section of Facebook this paper focuses on (cf.\nfollow the company's naming convention and use the\nterm in uppercase letters.\n4. http://investor.fb.com/\n5. https://developers.facebook.com/docs/graph-api/reference/\n6. https://www.facebook.com/facebook/info?tab\u00bcPage_info\n10. REST stands for Representational State Transfer and\ndenotes a set of principles for the design of lightweight\nAPIs that are more suited to the demands of the Web\nthan the more robust techniques that previously domi-\nnated exchange between systems.\n11. https://developers.facebook.com/docs/marketing-api/api-\nrate-limiting\n12. http://stackoverflow.com\n13. The options for blocking apps are buried deeply in\nFacebook's interface: the checkbox for ``activities, interests,\nthings I like'', located in the ``apps others use'' section in the\n``apps'' part of the settings menu, needs to be explicitly\nunchecked.\nopers.facebook.com/docs/graph-api/reference/v2.2/post)\nstated: ``For public posts, it is only shown after the post has\nbeen shared more than 10 times.'' This has since dis-\nappeared. Despite our best efforts, we have not been able\nto discern during which timeframe this limitation applied.\n15. Tukey's famous five-number summary, for example,\ndescribes a distribution through the minimum value\nobserved, the lower quartile (p25), the median (p50),\nthe upper quartile (p75), and the maximum value.\n16. Although considerations concerning research ethics are\nnot an explicit subject of this paper, it is clear that this\nproject raises important implications that are not easy to\ndeal with. Privacy is one of them, in particular in a con-\ntext of sectarian violence, where actual physical danger to\npeople is a very real possibility. Inspired by the ethics\nguidelines of the AoIR (Markham and Buchanan,\n2012), we based our decisions on the concept of harm.\nWe therefore decided to not pursue any further research\ninto the most active users of the Page and made sure that\nno names were used in any public presentation of our\nwork. While Netvizz anonymizes users, software that per-\nforms similar data gathering functions without\nanonymization is widely available. Despite Facebook's\npush towards more privacy, the API remains largely\nopen when it comes to Pages.\nand likes, respectively.\n18. This metric simply states how many single characters\nneed to be changed to transform one string into another.\nThe distance between ``this'' and ``that'' is two. We con-\nsider two comments to be identical when their distance is\ntwo or less.\nReferences\nAbdulla R (2014) Egypt's Media in the Midst of Revolution.\nReport, Carnegie Endowment for International Peace,\nUSA, July.\nAgre PE (1994) Surveillance and capture: Two models of\nprivacy. The Information Society: An International\nAlam SL and Walker D (2011) The public Facebook: A case\nof Australian Government Facebook Pages and participa-\nNovember\u00ad2 December. Paper 3. AIS Electronic Library\n(AISeL).\nBodle R (2011) Regimes of sharing. Open APIs, interoper-\nability, and Facebook. Information, Communication &\nBonso\n\u00b4 n E and Ratkai M (2013) A set of metrics to assess\nstakeholder engagement and social legitimacy on a corpor-\nate Facebook page. Online Information Review 37(5):\nBorra EK and Rieder B (2014) Programmed method:\nDeveloping a toolset for capturing and analyzing Tweets.\nBowker GC (2005) Memory Practices in the Sciences.\nCambridge, MA: The MIT Press.\nBruns A and Highfield T (2013) Political networks on\nTwitter: Tweeting the Queensland State Election.\nBucher T (2012) Want to be on the top? Algorithmic power\nand the threat of invisibility on Facebook. New Media &\nBucher T (2013) Objects of intense feeling: The case of the\nTwitter API. Computational Culture 3. Available at: http://\ncomputationalculture.net/article/objects-of-intense-feel-\nCha M, Haddadi H, Benevenuto F, et al. (2010) Measuring\nuser influence in Twitter: The million follower fallacy. In:\nProceedings of the fourth international AAAI conference on\nweblogs and social media, Washington, DC, 23\u00ad26 May,\nCochoy F (2002) Une sociologie du packaging ou L'a^ne de\nBuridan face au marche\u00b4. Paris: Presses universitaires de\nFrance.\nDella Ratta D and Valeriani A (2012) Remixing the Spring!\nconnective leadership and read-write practices in the 2011\nArab Uprisings. CyberOrient \u00ad Online Journal of the\nVirtual Middle East 6(1). Available at: http://\n20 Big Data & Society\nwww.cyberorient.net/article.do?articleId\u00bc7763 (accessed\nDriscoll K and Walker S (2014) Working within a black box:\nTransparency in the collection and production of big\nTwitter data. International Journal of Communication 8:\nEkbia H, Mattioli M, Kouper I, et al. (2014) Big data, bigger\ndilemmas: A critical review. Journal of the Association for\nFuller M (ed) (2008) Software Studies: A Lexicon.\nCambridge, MA: The MIT Press.\nGerlitz C and Rieder B (2013) Mining one percent of Twitter:\nCollections, baselines, sampling. M/C Journal 16(2).\nAvailable at: http://journal.media-culture.org.au/\nindex.php/mcjournal/article/view/620 (accessed 18 April\ngreater than the people in power: A memoir. New York:\nHoughton Mifflin Harcourt.\nGillespie CS (2014) Fitting heavy tailed distributions: The\nGillespie T (2010) The politics of `platforms'. New Media &\nGlaser BG and Strauss AL (1967) The Discovery of Grounded\nTheory: Strategies for Qualitative Research. Chicago:\nAldine de Gruyter.\nGulati G and Williams CB (2013) Social media and campaign\n2012: Developments and trends for Facebook adoption.\nHoel AS and van der Tuin I (2012) The ontological force of\ntechnicity: Reading Cassirer and Simondon diffractively.\nJenkins H, Ford S and Green J (2013) Spreadable Media.\nCreating Value and Meaning and a Networked Culture.\nNew York: New York University Press.\nKramer ADI, Guillory JE and Hancock JT (2014)\nExperimental evidence of massive-scale emotional conta-\ngion through social networks. Proceedings of the National\nLarsson AO (2014) Online, all the time? A quantitative assess-\nment of the permanent campaign on Facebook. New\nLarsson AO (2015) Pandering, protesting, engaging:\nNorwegian party leaders on Facebook during the 2013\n`Short campaign'. Information, Communication & Society\nLatour B (2005) Reassembling the Social: An Introduction to\nActor-Network-Theory. Oxford: Oxford University Press.\nLazer D, Kennedy R, King G, et al. (2014) The parable of\nLazer D, Pentland A, Adamic L, et al. (2009) Computational\nLevenshtein VI (1966) Binary codes capable of correcting\ndeletions, insertions, and reversals. Soviet Physics-\nLewis SC, Zamith R and Hermida A (2013) Content analysis\nin an era of Big Data: A hybrid approach to computa-\ntional and manual methods. Journal of Broadcasting &\nLomborg S and Bechmann A (2014) Using APIs for data\ncollection on social media. The Information Society\nMaireder A and Schlo\nnetworked publics of a socio-political debate. European\nMarkham A and Buchanan E (2012) Ethical Decision-Making\nand Internet Research. Recommendations from the AoIR\nEthics Working Committee (Version 2.0). Available at:\nhttp://aoir.org/reports/ethics2.pdf (accessed 18 April\nMarres N and Weltevrede E (2013) Scraping the social? Issues\nin live social research. Journal of Cultural Economy 6(3):\nMoretti F (2013) Distant Reading. London: Verso Books.\nMu\n\u00a8 ller F and Thiesing F (2011) Social networking APIs for\ncompanies: An example of using the Facebook API for\ncompanies. In: 2011 international conference on computa-\ntional aspects of social networks (CASoN 2011),\nPoell T and Borra EK (2012) Twitter, YouTube, and Flickr as\nplatforms of alternative journalism: The social media\nPoell T, Abdulla R, Rieder B, et al. (2015) Protest leadership\nin the age of social media. Information, Communication &\nPrieur C, Cardon D, Beuscart JS, et al. (2008) The Strength of\nWeak Cooperation: A Case Study on Flickr.\nRieder B (2013) Studying Facebook via data extraction: the\nNetvizz application. In: Proceedings of the 5th Annual\nACM Web Science Conference, Paris, France, 2\u00ad4 May,\nRogers RA (2013) Digital Methods. Cambridge, MA: The\nMIT Press.\nSabate F, Berbegal-Mirabent J, Can\nFactors influencing popularity of branded content in\nFacebook fan pages. European Management Journal\nSavage M (2009) Contemporary sociology and the challenge\nof descriptive assemblage. European Journal of Social\nShaw F, Burgess J, Crawford K, et al. (2013) Sharing news,\nmaking sense, saying thanks: Patterns of talk on Twitter\nduring the Queensland floods. Australian Journal of\nCommunication, Australia and New Zealand Communication\nStar SL and Ruhleder K (1996) Steps toward an ecology of\ninfrastructure: Design and access for large information\nTufekci Z and Wilson C (2012) Social media and the decision\nto participate in political protest: Observations from\nTukey JW (1962) The future of data analysis. The Annals of\nTukey JW (1977) Exploratory Data Analysis. Reading, MA:\nAddison-Wesley.\nvan Es K, van Geenen D and Boeschoten T (2014) Mediating\nthe Black Pete discussion on Facebook: Slacktivism, flam-\ning wars, and deliberation. First Monday 19(12). DOI:\nWatts DJ and Dodds PS (2007) Influentials, networks, and\npublic opinion formation. Journal of Consumer Research\nWilson RE, Gosling SD and Graham LT (2012) A review of\nFacebook research in the social sciences. Perspectives on\n22 Big Data & Society"
}