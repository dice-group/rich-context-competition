{
    "abstract": "Abstract\nWe studied whether human observers can estimate the illumination direction from 3D textures of\nrandom Brownian surfaces, containing undulations over a range of scales. The locally Lambertian\nsurfaces were illuminated with a collimated beam from random directions. The surfaces had a\nuniform albedo and thus texture appeared only through shading and shadowing. The data confirm\nearlier results with Gaussian surfaces, containing undulations of a single scale. Observers were able\nto accurately estimate the source azimuth. If shading dominated the images, the observers\ncommitted 180 errors. If cast shadows were present, they resolved this convex-concave-\nambiguity almost completely. Thus, observers relied on second-order statistics in the shading\nregime and used an unidentified first-order cue in the shadow regime. The source elevations\ncould also be estimated, which can be explained by the observers' exploitation of the statistical\nhomogeneity of the stimulus set. The fraction of the surface that is in shadow and the median\nintensity are likely cues for these elevation estimates.\n",
    "reduced_content": "Article\nEstimating the Illumination\nDirection From Three-\nDimensional Texture of\nBrownian Surfaces\nSylvia C. Pont\nPerceptual Intelligence (p-)lab, Department of Industrial Design\nEngineering, Delft University of Technology, The Netherlands\nAndrea J. van Doorn and Jan J. Koenderink\nLaboratory of Experimental Psychology, University of Leuven, Belgium;\nLaboratory of Experimental Psychology, Faculty of Social Sciences,\nUtrecht University, The Netherlands\n Keywords\nBrownian surface, illumination direction, illuminance flow, light field, shading, shadowing, texture\nIntroduction\nWe will consider texture due to the illumination of rough surfaces. The appearance of such\nthree-dimensional (3D) textures is dependent on the illumination and on the viewing\ndirection and can be characterized by bidirectional texture functions or BTFs (Curet, 1997;\nCorresponding author:\nSylvia C. Pont, Perceptual Intelligence (p-)lab, Department of Industrial Design Engineering, Delft University of Technology,\nEmail: s.c.pont@tudelft.nl\ni-Perception\njournals.sagepub.com/home/ipe\nCreative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License\n(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of the work without\nfurther permission provided the original work is attributed as specified on the SAGE and Open Access pages (https://us.sage-\npub.com/en-us/nam/open-access-at-sage).\nDana, van Ginneken, Nayar, & Koenderink, 1997, 1999). Conversely, the texture appearance\nmight provide us with cues about the illumination and viewing directions. Luminance\ndistribution or histogram-based cues are, for instance, the width, average, and skewness\nof the luminance distribution (Ho, Landy, & Maloney, 2008; Kim & Anderson,\nWijntjes & Pont, 2010). In addition to such relatively easy derivable cues, the spatial\nproperties of 3D textures also provide cues about the illumination, material, and shape\n(Chantler, Schmidt, Petrou, & McGunnigle, 2002; Gerhard & Maloney, 2010; Karlsson,\nZisserman, 2004). The second-order statistics of shaded 3D textures provides us with\nestimates of the azimuth of the average illumination orientation, that is, the direction\nmodulo 180 (Koenderink & Pont, 2003; Koenderink, van Doorn, Kappers, te Pas, &\nthe convex-concave-ambiguity. Furthermore, for arbitrary textures (i.e., statistically\ninhomogeneous sets of textures), the elevation cannot be estimated due to the bas-relief\nambiguity (Belhumeur, Kriegman, & Yuille, 1997).\nIllumination direction estimation is an important prerequisite for estimates of the light\nfield, shape from shading, and material judgments. In this article, we investigate how well\nhuman observers are able to estimate the illumination direction from 3D textures,\nin connection to our interest in light field perception. The light field (Gershun, 1939), or\nplenoptic function (Adelson & Bergen, 1991), is defined as the irradiance as a function of\nposition and direction and might serve as a radiometric framework for perception. Texture\nprovides us with cues which are additional to shading. Note that Lambertian shading (Horn\n& Brooks, 1989) is dependent on the normal component of the local light vector, while\ntexture due to surface roughness is also dependent on the tangential component of the\nlocal light vector. The ensembles of local illumination orientation estimates over rough 3D\nobjects form patterns, the illuminance flow (Pont & Koenderink, 2003, 2004). The\nilluminance flow depends systematically on the light field and on the shape of the object\nWijntjes, & Koenderink, 2015) and provides cues about the light field and object shape\nIn a previous study, we derived how second-order statistics based on the squared gradient\nand on the Hessian relate to the illumination direction (Koenderink & Pont, 2003). This\nrelation suggests that the illumination orientation can be derived from 3D textures via\nresponses of so-called edge and line detectors. In another study (Koenderink et al., 2003),\nwe tested whether human observers were actually able to carry out this task for frontally\nviewed real 3D textures from the Curet database, see, for examples, Figure 1 left, and we\nfound that the experimental results were surprisingly similar to the theoretical predictions.\nThe similarity was especially surprising because real textures do not comply with the strict\nassumptions of the theory at all namely, that the geometry is Gaussian, that the material is\nlocally perfectly matte (Lambertian shading), and that the relief is shallow such that no\nshadows and no interreflections occur.\nIn still another study (Koenderink et al., 2004), we carried out a similar experiment for\nfrontally viewed computer-generated Gaussian surfaces, see, for examples, Figure 1 bottom,\nand again found that human observers' estimates were close to the fiducial orientation values\n(interquartile intervals of the deviations of the azimuthal estimates were below 14).\nHowever, for the Gaussian textures in the shadowing regime, we found that observers\nwere able to resolve the convex-concave-ambiguity. The main difference between the\n2 i-Perception\nFigure 1. Textures of real materials from the CURET database at the top and rendered textures of\nGaussian surfaces at the bottom. All textures were viewed frontally. The Gaussian textures were rendered\nfor a single scale of the roughness, for illumination polar angles of about 0, 30, 50, and 70 (from left to\nright), varying azimuth (depicted by the red arrows), and for three reliefs, increasing from above to below.\nPont et al. 3\ntextures in the shadowing and shading regimes was the presence of cast shadows. This\nsuggests that observers make use of the difference between the boundaries of the cast\nshadows and the body shadows, the latter being much more gradual than the former.\nNext, we tested illumination direction estimation for textures of frontally viewed Gaussian\nanisotropic rough surfaces (Koenderink, van Doorn, & Pont, 2007). For such textures, one\nexpects systematic errors of the settings as a function of the anisotropy (Karlsson et al., 2008,\n2009). Our expectations were fully borne out, in that the observers committed the predicted\nsystematic errors. The results were precise enough to allow the inference that illumination\ndirection detection is based on second-order statistics, that is, of edge detector (rather than\nline detector) activity.\nFigure 1 shows examples of real materials and of rendered Gaussian surfaces. The\nGaussian textures look somewhat artificial and as if photographed out-of-focus. The main\nreason might be that the surface roughness of these textures is restricted to a single scale,\nwhile in natural materials one typically finds undulations over a range of scales\n(Green, Padilla, Drbohlav, & Chantler, 2007; Kube & Pentland, 1988; Padilla, Drbohlav,\nGreen, Spence, & Chantler, 2008; Wainwright & Simoncelli, 2000). Therefore, in this\narticle, we tested whether a deviation from the theoretical assumption of Gaussian\ngeometry (while the theoretical assumptions of Lambertian reflectance and uniform albedo\nwere fulfilled) will systematically affect the estimates of human observers. We rendered\nimages of height profiles resulting from linear superpositions of a range of Gaussian\nsurfaces of different scales. Due to the effect that larger bumps might put smaller ones in\ncast shadow, such a ``Brownian image texture'' is not simply a linear superposition of the\nimage textures of the composing Gaussian surfaces. Can human observers estimate the\nillumination orientation for these, more realistic surface profiles, containing roughness at a\nrange of scales?\nMethods\nStimuli\nWe generated 250 images of frontally viewed Brownian surfaces, see Figure 2 for examples.\nTo create these images, we first constructed statistically independent random surfaces\n(i.e., surface height profiles) for each of them. The surfaces were generated by linear\nsuperposition of seven random Gaussian reliefs of different scales. Each Gaussian relief\ncomponent was generated with normally distributed heights and an isotropic Gaussian\ncorrelation function (Longuet-Higgins, 1957). Hereafter, we set scale as the half-width of\nthe autocorrelation function. The scales of the seven Gaussian relief components were\nsquare spreads in the heights were taken proportional to the scales. After superposition of\nthe seven Gaussian random relief components, we subtracted the linear trends of the generated\nheight profiles in order to avoid global slants of the surfaces with respect to the fronto-parallel\nsurface. Finally, the variance of the surfaces was normalized, and the height scaled with a\nconstant of 128. Thus the surface structures had a fractal like character, see the powerspectrum\nin Figure 3. Because of this fractal like character we called them Brownian surfaces.\nThe stimuli were prepared through a Mathematica program and saved as grayscale TIFF-\nformatted image files of 512 \u00c2 512 pixels, 8 bit per pixel, linearly mapping the luminance\nvalues. The stimuli were rendered assuming locally Lambertian or perfectly diffuse scattering\n(Lambert, 1760), a collimated beam (similar to direct sunlight), with pixels in body and cast\nshadows being set to black (no ambient term). These stimuli represent physically realistic\n4 i-Perception\nrenderings, except for the fact that multiple scattering is not present. Note that, although the\nsurface structure or height profile is simply a linear superposition of the surface structures of\nthe composing Gaussian surfaces, the resulting image structure or 3D texture is not a simple\ncombination. This is because the shadows of larger bumps might overcast smaller bumps and\nin effect make smaller bumps invisible.\nThe illumination directions of the 250 images were distributed randomly over the\nhemisphere of potential illumination directions (see the polar plot in Figure 4). All stimuli\nwere presented in randomized order. The rendered images were shown in a circular mask in\norder to avoid a possible bias due to the square shape of the images. The test was conducted\nFigure 2. Examples of the stimuli, with arrows depicting the true illumination direction. The cut-out was\ncircular in order to prevent biased responses due to oriented contours.\nLog(frequency) [cycles/image]\nLog(power spectral density)\nFigure 3. A depiction of the powerspectrum of the surface height profiles of our stimuli (log power spectrum\ndensity as a function of frequency).\nPont et al. 5\nusing a linearized monitor (unit gamma; implemented via software and checked with a gray\nscale and Koninca Minolta luminance meter).\nObservers\nSix observers, the authors and three naive observers, participated in the experiment. Authors\nS. P. and A. D. were naive with respect to the stimulus parameters. All six observers had\nnormal or corrected-to-normal vision. The experiment was done in accordance with local\nethical guidelines, Dutch Law, and with the Declaration of Helsinki.\nExperimental Setup\nThe setup consisted of an Apple Macintosh G4 and a luminance linearized, 2200 LaCie Blue\nheads in a chinrest, 83 cm from the screen. Vision was binocular, and the head was fixed\nthrough the chin rest. The stimulus and probe (see next subsection) images extended visual\nangles of 8.6 \u00c2 8.6 each. The room was dark during the course of the experiment.\nDesign and Procedure\nWe defined a ``natural'' interface in the form of a monochrome rendering of an illuminated\nhemispherical boss on a plane (see Figure 5). The boss and plane were rendered using\n(Lambertian) shading, with body and cast shadows, without reflexes. The observer could\nuse the mouse in order to adjust the direction of the (simulated) source. The task was to let\nFigure 4. The parameters of the 250 stimuli. The grid specifies 15 increments in azimuth and elevation,\nusing equal-area projection. The convention for the specification of the azimuth (zero direction toward the\nright, increase in counter-clockwise direction) is used throughout the article. Elevation is measured by the\npolar angle, that is, the distance to the direction of normal incidence (at the center of the graph). The\nelevation and azimuth specify the direction toward the light source.\n6 i-Perception\nthe illumination of the hemispherical boss appears the same as the illumination of the texture.\nThis proved indeed to be an intuitive interface to all observers in our former and present\nstudies. The median time for a judgment was less than 8 seconds.\nResults\nFigure 6 shows the settings (dots) of the azimuthal angles against the stimulus azimuths, per\nobserver. The drawn lines represent the veridical values modulo 180. Surprisingly, most\nsettings seem to lie close to the true values, while one would expect about half of them to\nbe 180 off due to the convex-concave-ambiguity. Figure 7 shows the polar histograms of the\ndeviations of the azimuthal settings from the actual illumination azimuths, for all six subjects.\nObviously, the number of deviations near 0 is different from the number of deviations that\nare 180 off, and clearly outnumbers it, confirming that most responses were clustered around\nthe fiducial illumination orientation. Since this result contradicts naive expectations, we did\nsome further analysis on these data. Figure 8 splits the data in three groups for three separate\nelevation ranges: with a polar angle of 0 to 30 (in which range shading dominates) in the left\nplot, 30 to 60 (in which range neither shading nor shadowing dominates) in the middle plot,\nand 60 to 90 (in which range shadowing dominates) in the right plot. It is clear from this\nfigure that in the shading regime indeed (following our expectations), about half of the data is\n180 off. However, in the intermediate and in the shadowing regimes, almost all settings are\nclose to the veridical illumination orientations. We calculated the ratios of the numbers of\ndatapoints in the first plus fourth quadrant with respect to the stimulus values to those in the\nsecond plus third quadrant. We found that the ratios in the shading, mixed, and shadow\nshadows in the image seems to resolve the convex-concave-ambiguity.\nFigure 5. The interface with a stimulus (left) and interaction panel (right). The observers could adjust the\ndirection of the virtual light source that determined the rendering in the response panel. This rendering\nserved to indicate both the elevation and the azimuth of the illumination.\nPont et al. 7\nFigure 9 shows the settings (dots) of the polar angles against the stimulus values, per\nobserver. Theoretically, the elevation cannot be estimated due to the bas-relief ambiguity\n(Belhumeur et al., 1997), so here we expected no clear relation of the settings with the\nveridical values. Because the data seem to show some correlation with the stimulus values\nwe did a regression on the data. The lines represent linear fits to the veridical polar angle y,\nfor which we found:\nTo understand this slight but significant correlation, we looked at the correlation between\nthe data and a few possible effective cues that the observers might have used. Since the\nstimulus set is homogeneous in terms of statistics, observers might have used cues such as\nthe average gray level, contrast, shadowed fraction of the total area. Figure 10 shows the\naverage polar angle settings (horizontal axis) of the observers against the shadow fraction,\nmedian intensity, and Michelson contrast (from 5% to 95% percentiles instead of the\nabsolute minimum and maximum). It is clear that the settings correlate nicely with the\nshadow fraction. The median intensity also acts as a cue in the shading regime, not just in\nthe shadow regime. For the contrast, we find a distinct picture. The contrast explodes at\nabout 60 due to the dominance of cast shadows of big bumps, which put very large parts of\nFigure 6. Scatter plots of the azimuth settings (vertical axes) against the ground truth (horizontal axes) for\neach observer. The drawn lines depict the lines of expectation (ground truth modulo 180).\n8 i-Perception\nthe image in shadow (including small bumps). Even in this large-scale shadow dominated\nregime, observers were able to conduct our task well.\nIn addition to the former analysis, we studied (straight) correlations between the\nobservers' azimuthal data (O) and illumination orientation estimates (E) that were\ncalculated from second-order statistics on the basis of the squared gradient--that is,\nFigure 8. Polar histograms of the azimuthal errors committed by all observers, split into three regimes:\npolar angles smaller than 30 (the shading regime, left plot, and based on 402 settings), between 30 and 60\n(both shading and shadowing happen, middle plot, and based on 750 settings), and larger than 60 (shadowing\ndominates, right plot, and based on 348 settings).\nFigure 7. Polar histograms of the azimuthal errors per observer (thus each plot totals 250 trials). Notice\nthat the veridical direction is toward the right.\nPont et al. 9\nof edge detector (rather than line detector) activity. Our former studies suggested that such a\nmechanism might underly illumination orientation detection (Koenderink & Pont, 2003;\ndifferentiating scales of our algorithm (1, 8, and 64 pixels) and averaged over the inner\nFigure 9. Scatter plots of the polar angle settings (vertical axis) against the ground truth (horizontal axis)\nfor each observer. We fitted the data linearly (drawn lines).\nFigure 10. Scatterplots of the average polar angle settings of all observers and the percentage of\nshadow-filled area (left), the average intensity (center), and the root mean square contrast (right). Notice\nthat shadowing sets in at a polar angle of about 30, and that the settings correlate nicely with the shadow\nfraction. The median intensity also acts as cue in the shading regime, not just in the shadow regime.\nTable 1. Correlation Coefficients for Comparison Between the Illumination Orientation Estimates (E) and\nthe True Azimuths (T), Between the Illumination Orientation Estimates and the Observers' Azimuthal\nSettings (E\u00adO), and Between the Observers' Azimuthal Settings and the True Azimuths (O\u00adT). The\nillumination orientation estimates were computed at three different scales (second column). These\ncorrelations were computed separately for the shading, intermediate, and shadowing regimes (Columns 3\u00ad5).\nComparison Scale (pixels)\nCorrelation in\nshading regime\nCorrelation in\nintermediate regime\nCorrelation in\nshadowing regime\nFigure 11. Surface profiles with arrows representing illumination directions (the first row for each set). The\nsecond row for each set shows the images which correspond with the illumination directions represented\nabove them. The first set shows images of a bump and the second set of a trough in the shading (left),\nintermediate (middle), and shadowing (right) regimes.\nsquare of the stimuli of 344 pixels squared in which there was no coverage by the circular\nmask. Correlations were computed for the orientations, rather than directions, in other\nwords, we corrected for 180 flips. We also computed the correlations between these\nillumination orientation estimates (E) and the true azimuths (T), for comparison with the\ncorrelations between the illumination orientation estimates and the observers' azimuthal\nsettings (E\u00adO). Finally, as a sort of baseline correlation, we computed the observers'\nazimuthal settings against the true azimuths (O\u00adT). These correlations were computed\nseparately for the shading, intermediate, and shadowing regimes. The results are\nrepresented in Table 1.\nThese numbers confirm that observers could estimate the illumination orientations rather\nwell (O\u00adT correlations are quite high). The correlations of the observers' settings and of the\nillumination orientation estimates with the true estimates were consistently higher for the\nintermediate regime than for the shading or shadowing regimes. Moreover, the correlations\nfor the intermediate regime were most robust under variation of the differentiating scale. The\ncorrelations for the shading regime show the largest decrease with increasing scale. The\ncorrelations of the estimated illumination orientations at the largest scale (E\u00adO and E\u00adT)\nwere clearly lower than those of the observers (O\u00adT). Summarizing, we find that the\nFigure 12. Surface profiles with arrows representing illumination directions (the first row for each set). The\nsecond row for each set shows the images which correspond with the illumination directions represented\nabove them. The first set shows images of a bumpy bump and the second set of a bumpy trough in the shading\n(left), intermediate (middle), and shadowing (right) regimes.\nsecond-order statistics correlated well with the observers' settings, especially at lower scales,\nand especially in the intermediate regime.\nConclusions and Discussion\nThe main conclusion from this study is that a deviation from the theoretical assumption of\nGaussian geometry does not affect the estimates of human observers systematically. Human\nobservers can estimate the illumination orientation for our more realistic surface profiles\ncontaining roughness at a range of scales. Moreover, the presence of a range of scales,\ninstead of a single scale of the undulations, prevented complaints by the observers. In our\nprevious work on random Gaussian surfaces, we found that observers ``did not `like' the\nsamples because they appear somewhat ambiguous'' (Koenderink et al., 2004). The stimuli in\nthe current study are probably more pleasant to view because they do look sharp and they do\noffer a ``hold'' to the eye (as distinct from the Gaussian surfaces). The results from the current\nstudy confirm earlier results using texture images from the CURET database (Curet, 1997).\nMoreover, as in the case of our study using rendered random Gaussian surfaces (Koenderink\net al., 2004), we found that observers were quite capable at elevation and azimuthal direction\n(instead of orientation) estimation.\nThe observers' sensitivity to light source elevation cannot be interpreted as an absolute\nsensitivity to the height of the light source. Such sensitivity is impossible in view of the bas-\nrelief ambiguity (Belhumeur et al., 1997), which is a basic image ambiguity concerning light\nsource elevation and relief height. The reason must be the statistical homogeneity of the\nFigure 13. Surface illuminance flow estimates for a flat plaster surface, a mountainous area viewed from\nabove, and a mountain viewed from the side. The ellipsoids' semimajor axes represent the estimated\nilluminance flow orientations. The eccentricity represents the confidence level.\nstimulus set. Observers might have used, for instance, the average brightness and shadow\nfraction to grade the samples and relate them to some equivalent elevation scale for the\nexperiment. In contradistinction to our study on Gaussian textures, we did not find a\nmonotonic relation of the settings with contrast, so the contrast cannot serve as a direct\ncue in the current study.\nThe azimuthal settings in the intermediate and shadowing regimes did not show a 180\nmodulus. Thus, observers were able to estimate the illumination direction, not just the\norientation, if cast shadows were present. Probably the difference between cast and body\nshadows was used as a cue to the illumination direction, resolving the convexity-concavity-\nillumination-direction-ambiguity, see Figure 11. Cast shadows have a sharp boundary, while\nbody shadow boundaries are generally more gradual. Noncollimated lighting might thus\ninfluence how well the convexity-concavity-illumination-direction-ambiguity direction\nambiguity can be resolved because the difference in sharpness of the cast and body\nshadows might become less clear. The transitions of light-to-dark and dark-to-light in the\ndirection of the tangential component of the light vector are cast shadow edges and body\nshadow edges. The asymmetric shapes of the shadow and light patches might be another cue\nfor this resolution. In the case of our more natural Brownian surfaces, these differences\nbetween cast and body shadows can be much less salient due to the nonlinear combination\nof such image effects on a range of scales. Figure 12 shows a visualization of how small-scale\nshadows may mask the large-scale cast-body shadow differences in sharpness of the gradients\n(sharp vs. more gradual boundaries) and the asymmetric shapes of the shadow patches. This\nmasking effect is striking in the intermediate regime of the center images in Figure 12. In\naddition, in our stimuli, very large-scale cast shadows may put smaller ones in shadow and\ndecrease this masking effect; this effect is very clear in the right images of Figure 12. However,\ndespite these complicating factors--that are omnipresent in most natural\nmaterials--observers showed to be quite capable of using the shadowing cues to resolve\nthe 180 ambiguity. It remains to be answered whether the same resolution due to cast\nshadows occurs in scenes with generic content, that is, objects instead of 3D texture.\nIn all regimes, we found that the observers' estimates were accurate in terms of orientation,\nwhich suggests that they used shading as well as shadowing cues. The second-order statistics\ncorrelated well with the observers' settings for stimuli in all three regimes, especially at lower\nscales. The decrease of the correlations for increasing scale suggests that shading and\nshadowing cues at smaller scales are needed to arrive at the observed accuracy of the\nobservers' settings and may be combined with large-scale cues--especially in the\nintermediate and shadowing regimes. It would be interesting to study this point in more\ndetail in combination with eye tracking, to see whether observers look at specific locations\nin the image. A mechanism combining shading and shadowing cues at a range of scales is of\ncourse very convenient with regard to light field estimates in natural scenes.\nOur results show that it is very plausible that ensembles of illuminance flow estimates are\nan important cue to the light field in natural scenes. Figure 13 shows the computational\ngradient-based illuminance flow estimates (for the algorithm, see Koenderink et al., 2003) for\nthree photographs: a flat piece of plaster, a mountain area seen from above, and a mountain\nseen from the ground. The flow estimates are represented by ellipses, with the orientation of\nthe major axis representing the estimated irradiation direction and the eccentricity\nrepresenting the confidence. On the basis of our findings, we hypothesize that weighted\ncombinations of such flow estimate ensembles at multiple scales are probably an important\ncue for the visual light field (Koenderink et al., 2007). Recent findings show that the visual\nlight field is simplified in comparison to the physical light field and that observers are sensitive\nto converging, diverging, and uniform fields (Kartashova, Sekulovski, de Ridder, te Pas, &\nPont, 2016; van Doorn, Koenderink, Todd, & Wagemans, 2012), which suggests that such\nrelatively simple topologies might represent templates for (often more complicated) natural\nlight fields. Also, it was shown that scene layout and object properties can influence\nillumination estimates (Schutt, Baier, & Fleming, 2016; Xia, Pont, & Heynderickx, 2016),\nwhich is to be expected if the visual light field is inferred from shading and shadowing\npatterns. In future studies, we will further study the extrapolation from textures to\n(perception of) illuminance flow over 3D objects and natural scenes, which is far from\ntrivial due to, for instance, foreshortening and local occlusion effects.\nFinally, these observations are of course related to material and shape perception, and not\njust light. Since we simultaneously infer higher dimensional material, shape, and illumination\nproperties from two-dimensional images, it is to be expected that such inferences interact.\nMany studies have shown that it is indeed the case that material, shape, and illumination\nKucukoglu, & Pont, 2012). Looking at our stimuli in the current study, see, for examples,\nFigure 2, we saw that many of our stimuli did not look as being made of matte material.\nMany of them tend to look quite glossy or shiny. We studied this illusory gloss in depth in\nanother article (Wijntjes & Pont, 2010), in which we tested gloss perception for Brownian\nsurfaces as a function of the depth range and illumination direction. We found that an\ninterpretation in the context of the bas-relief ambiguity (Belhumeur et al., 1997) could\nexplain our gloss perception data; on average perceived gloss increased with increasing\nrelief and decreased with decreasing source elevation.\nInterreflections were ignored in that experiment, as well as in the current experiment. We\nexpect that the addition of interreflections (or an ambient term) will not influence our data.\nWe do expect, however, that interreflections rendering will influence the perception of relief; a\nfamous observation in this area of study concerns the perceptual overestimation of relief of\nthe moon surface by astronauts (Philips, 2006). Unfortunately, we are still lacking\nexperimental methods to probe surface shape. We belief this is currently one of the biggest\nchallenges to arrive at a more holistic approach in natural material perception. Simultaneous\ntesting of surface relief height, material reflectance, and illumination perception may well be\nthe only manner to fully understand its underlying processes.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or\npublication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or\npublication of this article: This work is supported by Delft University of Technology.\nReferences\nAdelson, E. H., & Bergen, J. R. (1991). The plenoptic function and the elements of early vision.\nIn M. Landy, & J. A. Movshon (Eds.), Computational models of visual processing (pp. 3\u00ad20).\nCambridge, MA: MIT Press.\nBelhumeur, P., Kriegman, D. J., & Yuille, A. L. (1997). The bas-relief ambiguity. Proceedings of IEEE\nConference on Computer Vision and Pattern Recognition (pp. 1060\u00ad1066). New York, NY: Institute\nof Electrical and Electronics Engineers.\nChantler, M., Schmidt, M., Petrou, M., & McGunnigle, G. (2002). The effect of illuminant rotation on\ntexture filters: Lissajous's ellipses. In A. Heyden, G. Sparr, M. Nielsen, & P. Johansen (Eds.), ECCV\nCuret (1997). Columbia-Utrecht reflectance and texture database. Retrieved from http://www.cs.\ncolumbia.edu/CAVE/Curet\nDana, K. J., van Ginneken, B., Nayar, S. K., & Koenderink, J. J. (1997). Reflectance and texture of\nreal-world surfaces. Proceedings of IEEE Conference on Computer Vision and Pattern Recognition\n(pp. 151\u00ad157). New York, NY: Institute of Electrical and Electronics Engineering.\nDana, K. J., van Ginneken, B., Nayar, S. K., & Koenderink, J. J. (1999). Reflectance and texture of\nreal-world surfaces. ACM Transactions on Graphics, 18, 1\u00ad34.\nGerhard, H. E., & Maloney, L. T. (2010). Estimating changes in lighting direction in binocularly viewed\nthree-dimensional scenes. Journal of Vision, 10, 14.\nGershun, A. (1939). The light field (P. Moon & G. Timoshenko, Trans.). Journal of Mathematical\nGreen, P. R., Padilla, S., Drbohlav, O., & Chantler, M. (2007). Perceived roughness of textured\nHo, Y. X., Landy, M. S., & Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture.\nHorn, B. K. P., & Brooks, M. J. (1989). Shape from shading. Cambridge, MA: MIT Press.\nKarlsson, S., Pont, S. C., & Koenderink, J. J. (2008). Illuminance flow over anisotropic surfaces.\nKarlsson, S., Pont, S. C., & Koenderink, J. J. (2009). Illuminance flow over anisotropic surfaces with\nKartashova, T., de Ridder, H., te Pas, S. F., Schoemaker, M., & Pont, S. C. (2015). The visual light field\nin paintings of museum Prinsenhof: Comparing settings in empty space and on objects. In Bernice E.\nRogowitz, Thrasyvoulos N. Pappas, & Huib de Ridder (Eds.), Human vision and electronic imaging\nKartashova, T., Sekulovski, D., de Ridder, H., te Pas, S. F., & Pont, S. C. (2016). Global structure of\nthe visual light field and its relation to the physical light field. Journal of Vision, 16, 9.\nKim, J., & Anderson, B. L. (2010). Image statistics and the perception of surface gloss and lightness.\nKim, J., Marlow, P. J., & Anderson, B. L. (2014). Texture-shading flow interactions and perceived\nKnill, D. C. (1990). Estimating illuminant direction and degree of surface relief. Journal of the Optical\nKoenderink, J. J. (2012). Shadows of shape. In Utrecht: De Clootcrans Press. Retrieved from http://\nwww.gestaltrevision.be/en/resources/clootcrans-press\nKoenderink, J. J., van Doorn, A. J., Kappers, A. M. L., te Pas, S. F., & Pont, S. C. (2003). Illumination\ndirection from texture shading. Journal of the Optical Society of America A, 20, 987\u00ad995.\nKoenderink, J. J., & Pont, S. C. (2003). Irradiation direction from texture. Journal of the Optical Society\nKoenderink, J. J., Pont, S. C., van Doorn, A. J., Kappers, A. M. L., & Todd, J. (2007). The visual light\nKoenderink, J. J., van Doorn, A. J., & Pont, S. C. (2004). Light direction from shad(ow)ed random\nKoenderink, J. J., van Doorn, A. J., & Pont, S. C. (2007). Perception of illuminance flow in the case of\nKube, P., & Pentland, A. (1998). On the imaging of fractal surfaces. IEEE Transactions on Pattern\nLambert, J. H. (1760). Photometria, sive de Mensura et gradibus luminis, colorum et umbrA\n\u00b0. Augsburg,\nGermany: Eberhard Klett.\nLonguet-Higgins, M. S. (1957). The statistical analysis of a random moving surface. Philosophical\nMotoyoshi, I., Nishida, S., Sharan, L., & Adelson, E. (2007). Image statistics and the perception of\nPadilla, S., Drbohlav, O., Green, P. R., Spence, A., & Chantler, M. (2008). Perceived roughness of 1/f\nPhilips, T. (2006). Apollo chronicles: Dark shadows. Retrieved from http://science.nasa.gov/science-\nPont, S. C., & Koenderink, J. J. (2003). Illumination flow. In N. Petkov & M. A. Westenberg (Eds.),\nComputer analysis of images and patterns, proceedings lecture notes in computer Science (Vol. 2756,\npp. 90\u00ad97). Berlin, Heidelberg/Germany: Springer.\nPont, S. C., & Koenderink, J. J. (2004, September). Surface illuminance flow. In Y. Aloimonos & G.\nTaubin (Eds.), Second international symposium on 3D data processing, visualization and transmission.\nSymposium conducted at the meeting of Thessaloniki, Greece.\nPont, S. C., & Koenderink, J. J. (2005). Bidirectional texture contrast function. International Journal of\nPont, S. C., & Koenderink, J. J. (2008). Shape, surface roughness, and human perception. In M.\nMirmehdi, X. Xie, & J. Suri (Eds.), Handbook of texture analysis (pp. 197\u00ad222). London,\nEngland: Imperial College Press.\nPont, S. C., & te Pas, S. F. (2006). Material-illumination ambiguities and the perception of solid objects.\nPont, S. C., van Doorn, A. J., Wijntjes, M. W. A., & Koenderink, J. J. (2015). Texture, illumination,\nand material perception. In B. E. Rogowitz, T. N. Pappas, & H. de Ridder (Eds.), Human vision and\nelectronic imaging XX, proceedings of SPIE (Vol. 9394, p.). Bellingham, WA: SPIE.\nSchutt, H. H., Baier, F., & Fleming, R. W. (2016). Perception of light source distance from shading\npatterns. Journal of Vision, 16, 9.\nShepard, M. K., & Campbell, B. A. (1998). Shadows on a planetary surface and implications for\nte Pas, S. F., & Pont, S. C. (2005). Comparison of material and illumination discrimination\nperformance for real rough, real smooth and computer generated smooth spheres. Proceedings of\nthe 2nd Symposium on Applied Perception in Graphics and Visualization, A Corun\nvan Doorn, A. J., Koenderink, J. J., Todd, J. T., & Wagemans, J. (2012). Awareness of the light field:\nVarma, M., & Zisserman, A. (2004). Estimating illumination direction from textured images. CVPR, 1,\nWainwright, M. J., & Simoncelli, E. P. (2000). Scale mixtures of Gaussians and the statistics of natural\nimages. In S. A. Solla, T. K. Leen, & K.-H. Mu\n\u00a8 ller (Eds.), Advances of neural information processing\nWijntjes, M. W. A., Doerschner, K., Kucukoglu, G., & Pont, S. C. (2012). Relative flattening between\nvelvet and matte 3D shapes: Evidence for similar shape-from-shading computations. Journal of\nWijntjes, M. W. A., & Pont, S. C. (2010). Illusory gloss on Lambertian surfaces. Journal of Vision, 10,\nXia, L., Pont, S. C., & Heynderickx, I. (2016). Effects of scene content and layout on the perceived light\ndirection in 3D spaces. Journal of Vision, 16, 14.\nAuthor Biographies\nSylvia Pont graduated in Experimental Physics in 1993 at\nAmsterdam University. She did her PhD in 1997 at Utrecht\nan institute for visually disabled people. Next, she returned to\nUtrecht University to investigate ecological optics. In 2008, she\ntransferred her group and equipment to Delft University of\nTechnology. Here she coordinates the perceptual intelligence\nlab (p-lab), Department of Industrial Design Engineering of\nDelft University of Technology and was appointed Anthonie\nvan Leeuwenhoek Professor in 2016. Her group's research\nincludes studies into design, perception, and optics of light and\nmaterials, considering the physical and perceptual interactions\nbetween objects' shapes, materials, and light.\nAndrea van Doorn (1948) studied physics, mathematics, and\nchemistry at Utrecht University, where she did her master's in\nUtrecht University and Delft University of Technology,\nDepartment of Industrial Design, until her retirement in 2013.\nShe presently is a guest researcher at Utrecht University, the\nUniversity of Leuven. Current research interests are various\ntopics in vision, communication by gestures, and soundscapes.\nJan Koenderink (1943) studied physics, mathematics, and\nastronomy at Utrecht University, where he did his PhD in\nMan'' at Utrecht University till his retirement in 2008. He\npresently is a guest professor at Utrecht University, the\nUniversity of Leuven. He is a member of the Dutch Royal\nSociety of Arts and Sciences and received honorific doctorate\nin medicine from Leuven University. Current interests include\nthe mathematics and psychophysics of space and form in vision,\nincluding applications in art and design."
}