{
    "abstract": "Abstract\nResearch on group creativity has concentrated on explaining how the group\ncontext influences idea generation and has conceptualized the evaluation of\ncreative ideas as a process of convergent decision making that takes place\nafter ideas are generated to improve the quality of the group's creative output.\nWe challenge this view by exploring the situated nature of evaluations that\noccur throughout the creative process. We present an inductive qualitative pro-\ncess analysis of four U.S. healthcare policy groups tasked with producing crea-\ntive output in the form of policy recommendations to a federal agency. Results\nshow four modes of group interaction, each with a distinct form of evaluation:\nbrainstorming without evaluation, sequential interactions in which one idea was\ngenerated and evaluated, parallel interactions in which several ideas were gen-\nerated and evaluated, and iterative interactions in which the group evaluated\nseveral ideas in reference to the group's goals. Two of the groups in our study\nfollowed an evaluation-centered sequence that began with evaluating a small\nset of ideas. Surprisingly, doing so did not impede the groups' creativity. To\nexplain this, we develop an alternative conceptualization of evaluation as a gen-\nerative process that shapes and guides collective creativity.\n",
    "reduced_content": "Administrative Science Quarterly\nReprints and permissions:\nsagepub.com/\njournalsPermissions.nav\nasq.sagepub.com\nCollective Engagement\nin Creative Tasks: The\nRole of Evaluation in\nthe Creative Process in\nGroups\nSarah Harvey1 and Chia-Yu Kou1\n Keywords: group creative process, collective creativity, creative idea evalua-\ntion, group decision making, idea generation, brainstorming, healthcare policy\nCollectively developing the creative products that are at the heart of organiza-\ntional innovation requires that small, diverse groups are able to both draw on\nmembers' perspectives and expertise to generate novel and potentially useful\n(i.e., creative) ideas and evaluate their most creative ideas as worthy of pursuit\ngroups struggle with both of these tasks. In general, groups generate fewer\nand less creative ideas than do individuals working alone (McGrath, 1984; Diehl\n1 University College London\nideas to be the most creative (Rietzschel, Nijstad, and Stroebe, 2006). How can\ngroups collectively engage in the creative process to overcome these\nchallenges?\nUntil now, research has concentrated on ways to improve idea generation in\ngroups to answer this question. This approach assumes that the collective\ncreative process mirrors that of individual creativity: recursive stages of idea\ngeneration followed by evaluation (Drazin, Glynn, and Kazanjian, 1999; Jackson\nwhen group members stimulate one another's divergent thinking and their indi-\nvidual ideas are aggregated into the group's creative output (Nemeth, 1986;\nIdea evaluation is a later-stage convergent decision-making process that filters\na useful dichotomy between idea generation and evaluation that has allowed\nresearchers to isolate and examine each stage individually, holding the process\nconstant. Explanations for collective creativity are then based on how the\nments (e.g., Taggar, 2002) affect the creative process.\nThe problem is that this approach neglects the evaluative processes that are\nsituated in the on-going interactions of creative groups. Studies of collectives\nengaged in creative tasks are replete with examples of such evaluations.\nMembers of creative collectives choose consciously or subconsciously to\nignore ideas, advocate for their own ideas, show enthusiasm for others' ideas,\nand provide interpersonal rewards for good ideas (Murnighan and Conlon,\nThose processes reflect the iterative and integrated nature of idea evaluation\ninto group creativity research, however, because it focuses on the set of ideas\na group selects during the final stage of convergent decision making, rather\nthan the process through which those decisions evolve. Given the importance\nof flexibility and adaptability for creativity (Amabile, 1996; Pentland, 2003), the\nconclusion that it is facilitated by a single, structured process of generation fol-\nlowed by evaluation is counterintuitive. The idea-generation perspective may\ntherefore be an idealization that overlooks the variety of situated evaluations\nthat are integral to how collective creativity occurs.\nExamining situated evaluations of creative ideas can provide a deeper theo-\nretical understanding of how creativity functions at the group level because the\nprocess of evaluating ideas interacts with cognitions about ideas and the\nbroader context to produce judgments (Collins, 2005; Elsbach, Barr, and\nHargadon, 2005). A group's ability to select a final set of creative ideas there-\nfore cannot be isolated from the process of forming their evaluations. We sug-\ngest that examining evaluations situated within the creative process can\nprovide three insights into group creativity. First, situated evaluations are likely\nto influence a group's problem framework because the process of evaluating\nideas shapes the evaluation criteria that people attend to (Hsee, 1996). At the\nindividual level, the process of forming criteria into a problem framework tends\nto improve creativity (Getzels and Csikszentmihalyi, 1976); however, part of the\nvalue of group work is the diversity of perspectives members bring to the prob-\nated evaluations through which a group's problem framework develops is\nimportant for understanding how groups navigate this tension.\nSecond, articulating the differences between forms of situated evaluations\ncan help to explain why a group's decision-making skills do not appear to\nextend to creative tasks. Recent research suggests that although groups can\nbe effective decision makers (Laughlin, 1988), they tend not to recognize their\nPaulus, 2009). These are different kinds of decisions, but by equating creative\nidea evaluation with other kinds of group decision making, previous research\nfocuses on how groups identify high-quality ideas at the expense of other out-\ncomes, such as how groups identify their most novel ideas. Group members\nare likely to respond negatively initially to novel ideas (Mueller, Melwani, and\nGoncalo, 2012), so that creative ideas may first be ignored but may move back\ninto the consideration set over time. Examining situated evaluations throughout\nthe process is necessary to explain how novel ideas are evaluated and retained\nby the group in its final creative output.\nThird, in order for groups to build on and integrate ideas, members must\nconverge around some ideas as worthy of further pursuit during idea genera-\nless is known about these forms of idea generation (Kutzberg and Amabile,\n2000), however, because the processes recommended for improving divergent\ngeneration limit the opportunity for members to decide which ideas to build on\nand integrate by minimizing group interactions. For example, mediating group\ndiscussions with technology or interspersing them with independent work\nreduce the cognitive and social challenges of generating ideas in a group set-\nting to improve divergent idea generation (Osborn, 1953; Gallupe, Bastianuttti,\nlikely to promote the kinds of unexpected connections we hope for groups to\nmake, because without interaction, how can members decide which ideas to\nbuild on or integrate? Examining evaluations that occur within the creative pro-\ncess can provide insight into those processes.\nTo address these issues, we explored the role of evaluations situated\nthroughout the collective creative process by conducting an inductive process\nanalysis of four public healthcare policy groups over a five-month period. Our\nstudy builds on individual and organizational creativity research to offer an alter-\nnative conceptualization of evaluation as a process that enriches idea genera-\ntion by guiding and shaping collective creativity.\nCreative idea evaluation in groups has been defined as a convergent decision-\nmaking process through which groups select ideas. In contrast, idea generation\nis a divergent process in which a variety of ideas are generated, then explored\nunexpected ideas or perspectives stimulate new associations in group mem-\nproduce novel ideas, whereas idea evaluation is expected to improve the qual-\nStudies of individuals and larger creative collectives suggest that evaluation\nmay fulfil a more varied role in the creative process than this characterization\nportrays. Precisely how different roles of evaluation unfold to influence group\ncreativity is unclear, however, because different literatures predict different\neffects. We consider the evidence on how evaluation functions as a group deci-\nsion making activity, a source of feedback, and a problem framework to lay the\nfoundation for our exploration of evaluations situated in the creative process of\nthe group.\nEvaluation as Convergent Decision Making\nFor groups to select ideas, their generated ideas must be winnowed down until\na smaller set of the best ideas remain (Larey and Paulus, 1999; Rietzschel,\nSchunn, 2010). This process entails validating ideas against task criteria\n(Amabile, 1996) to choose options that may be implemented. Convergent think-\ning underlies this process because it involves narrowing alternatives toward a\nimproves the usefulness, appropriateness, or quality of a group's creative ideas\nBecause evaluation involves winnowing down the idea set, it may entail neg-\native feedback about some ideas that can create anxiety (Mullen, Johnson, and\nSalas, 1991) and limit cognitive flexibility (Isen, 1999) and willingness to share\nGroups are therefore advised not to evaluate ideas during idea generation\nideas down or inputting them into an electronic system facilitate this separation\nCooper et al., 1998). Evaluation therefore occurs at the end of the creative pro-\ncess, once a large set of ideas is available to choose from (Staw, 2009), and\nproceeds by comparing a set of generated ideas with one another.\nGroups are expected to have an advantage in convergent decision making\nbecause they have a large quantity of information and diverse resources for\ntherefore be effective at evaluating creative ideas (Singh and Fleming, 2010).\nDecision-making research further suggests that comparing ideas with one\nanother can improve the quality of decisions (Hsee et al., 1999) by making it\neasier to judge attributes that are otherwise difficult assess (Hsee, 1996).\nThe limited research that directly examines the evaluation of creative ideas\nin groups, however, suggests that despite following this process, interacting\ngroups do not outperform nominal groups at selecting ideas (Faure, 2004), and\nthey generally fail to identify the most creative of the ideas that they generate\nInstead, some evidence indicates that evaluating creative ideas improves when\ngroups move away from this decision-making process. For example, when a\ngroup is asked to select a set of ideas, so that each member's preferred idea\ncan be included in the set, the selected ideas are more original (Putman and\nmembers to act individualistically, so that they advocate strongly for their own\nideas, improves the selection of creative ideas (Goncalo and Staw, 2006).\nAlternatively, novel ideas may be more positively valued when groups evaluate\nthem throughout the creative process. Doing so provides opportunities to draw\non others' expertise to develop ideas and is more likely to generate commit-\nSingh and Fleming, 2010). What the best process is for evaluating creative\nideas is therefore an open question.\nEvaluation as Feedback\nThough apprehension over how others will evaluate one's ideas may impair\nidea generation, evaluation is also a source of disagreement and debate that\nResearch therefore has shown that developmental feedback can improve crea-\nand Buyens, 2011). Evaluation provides the information necessary to build on,\nelaborate, or refine ideas (Runco, 1994).\nIndirectly, receiving feedback can also facilitate attention to and engagement\ning feedback can help to engage with others' ideas (Langer, 1989). For exam-\nple, the process of evaluating writers' pitches has been shown to increase\nHollywood producers' interest in ideas (Elsbach and Kramer, 2003). Similarly,\nUzzi and Spiro (2005) emphasized that difficult editing choices were central to\npicking the right material for the development of Broadway musicals. These\nexamples highlight that evaluation also entails positively valuing ideas (Runco,\n1994). Feedback therefore need not create a negative interpersonal environ-\nment. For example, Long-Lingo and O'Mahony (2010) found that feedback\nhelped country music writers and producers to maintain positive interpersonal\nrelationships. It was how that feedback was delivered that mattered. Research\ntherefore needs to consider how groups draw on developmental feedback\nwithout interfering with idea generation.\nEvaluation as Problem Framework\nThe problem framework contains the assumptions, values, and rules underlying\nin the problem framework, therefore, are the criteria for evaluating ideas\n(Mumford, Whetzel, and Reiter-Palmon, 1997). Exposure to different problem\nframeworks stimulates new ways of thinking (Paulus and Yang, 2000; Milliken,\nAt the same time, however, a shared problem framework gives structure\nand meaning to a collective's otherwise dispersed knowledge (Weick, Sutcliffe,\nenables members to use one another's information and ideas for collective idea\ngeneration (Reiter-Palmon, Herman, and Yammarino, 2008). It therefore guides\nthe search for solutions (Getzels and Csikszentmihalyi, 1976; Mumford,\na novel and appropriate problem framework, it can improve the group's creativ-\nFor example, having similar evaluations of the art of the day led the Batignolle\ngroup of French impressionist artists in the mid-nineteenth century to make\nriskier, more creative artistic choices (Farrell, 1982). Shared knowledge of\nunderlying content allows members of improvisation groups to recognize the\nLeavitt (1996) noted that common professional standards were the foundation\nfor interaction in academic ``hot groups.'' How groups draw on their diverse\nperspectives while communicating effectively within the creative process is\ntherefore a further unresolved issue.\nThe literature thus suggests that evaluations that occur throughout the crea-\ntive process may affect both idea generation and the identification and reten-\ntion of creative ideas, yet how these processes develop and interact within a\ngroup is unclear. The present paper aims to systematically explore idea evalua-\ntion in the creative processes of organizational groups to shed light on this\nissue. In particular, we ask what is the role of evaluation in the group's creative\nprocess and how does it influence the nature of collective creativity?\nMETHODS\nWe used an inductive, qualitative process analysis to develop an explanation of\ncreative idea evaluation grounded in organizational groups (Glaser and Strauss,\nhealthcare information technology policy in four cross-functional and cross-\norganizational groups from each group's first meeting to its first deliverable.\nThroughout the process, we identified when ideas were generated, the point\nat which idea evaluation occurred, and the nature of decisions about ideas that\nresulted.\nResearch Setting\nThis study takes place in the context of the American Health Information\nCommunity (AHIC), a federal advisory committee that established four groups\ncharged with developing policy on the use of electronic information technology\n(IT) in healthcare. These groups held monthly public meetings to develop rec-\nommendations for the U.S. Department of Health and Human Services on four\ninterrelated issues: enabling the use of IT in the treatment of chronic diseases;\nfacilitating the use of patient data in emergency situations; establishing a sys-\ntem for patients to access and manage their own personal health records; and\nconsolidating patient data across points of healthcare delivery. We label the\ngroups CD, ES, HR, and PD, respectively.\nAn overview of the groups is provided in table 1. Experts from public health-\ncare (e.g., doctors, nurses, academics), private healthcare (e.g., insurance com-\npanies, medical services start-ups), information technology (e.g., executives\nfrom IT companies), and government agencies (e.g., the Veteran's Association,\nthe Treasury) were appointed to the groups. For example, members included a\nrecognized telemedicine expert who had worked as a doctor for over 25 years,\na hospital president, and the chairman of the board of an international technol-\nogy company. Some members had prior professional relationships. The groups\nhad formal co-chairs who primarily acted as facilitators and liaisons with the\nsecretary of the department, to whom the groups reported. The secretary occa-\nsionally joined meetings to thank the groups or discuss their goals. Otherwise,\nthe groups were largely self-managing.\nWe examined the first five meetings of each group over a five-month\nperiod, after which the groups' first deliverables were due. The secretary to\nwhom the groups reported described the first deliverable as an ``important\ntransition'' from ``the thinking phase . . . to the very specific action phase.''\nThus the need for creativity was concentrated in the period of our study.\nMeetings lasted from one to over four hours (two hours and 32 minutes, on\naverage). As part of the AHIC, the groups were based in Washington, DC,\nbut meetings typically involved some members who were co-located and\ninteracting face to face, communicating with others in different locations in a\nteleconference and web conference. Like an increasing number of groups,\nthose in the present study therefore often operated virtually (e.g., Gibson\nThe tasks facing the groups required a significant amount of creativity\nbecause they required developing policy in response to emerging technologies.\nProblems such as who should be able to access genomic testing information\nor how to generate data that are standardized and anonymous yet useful are\nnovel, ambiguous, and open-ended, and therefore require creativity (Dillon,\n1982). Group members had to engage in creative behaviors such as generating\nnovel ideas (Amabile, 1988) about how technology could be used to deliver\nTable 1. Overview of Healthcare Policy Groups\nPolicy objective Develop online\nrecord for patients\nto access and\nmanage own health\nDevelop online record\nfor use by professionals\nacross healthcare\nsystem\nEnable use of IT in\nmanagement of\nchronic disease\nDevelop real-time,\nnationwide public\nhealth event-\nmonitoring\ncapability\nAverage team\nmembers per\nmeeting\nFunctional\ndiversity*\nOther group\nfeatures\nMeetings run by 2\nco-chairs\n5 external presenters\nRelatively structured\ndiscussions with\naction items\ncompleted in each\nmeeting\nMeetings run by 2\nco-chairs\n3 external presenters\nRelatively unstructured\ndiscussions with action\nitems completed in\neach meeting\nMeetings run by 2\nco-chairs\n1 external presenter\nRelatively\nunstructured\ndiscussions\nMeetings run by 2\nco-chairs\n3 external\npresenters\nRelatively\nstructured\ndiscussions with\naction items\ncompleted in each\nmeeting\n* Functional diversity was calculated using Blau's (1977) index, (1- pi\n2), where pi\nis the proportion of group\nmembers with attribute i. Attributes were functional affiliations based on our categorizations of group members as\nmedical professionals, IT professionals, lawyers, business/finance backgrounds, or military. Includes only members\nwho attended 3 or more meetings.\nhealthcare and how it would evolve over time, reframing the group task around\nkey issues (Getzels and Csikszentmihalyi, 1976), and solving problems in\nresponse to unexpected or ambiguous regulatory constraints (Weisberg, 1988).\nMoreover, group members were likely to search for novel responses because\nthey framed the task as one requiring creativity (Gilson and Shalley, 2004). For\nexample, the facilitator at one meeting of CD emphasized the need for\ncreativity:\nOne of the things that I'm taking away from this conversation is that we need to find\nways to push the envelope a little bit . . . we need to really think through as creatively\nas possible, and I do mean creatively, any idea is a good idea on this one in terms of\nbrainstorming, how we might be able to push that envelope.\nThe setting provides several other advantages that make it ideal for studying\ngroups' creative processes. First, the full transcripts of all group meetings were\navailable, and group members interacted within the scope of the group's task\nprimarily in these meetings. This is because, as federal advisory committees,\nall groups' meetings had to be public and transparent, making it difficult to coor-\ndinate additional meetings. Second, the issues were personally and profession-\nally important to group members, who demonstrated strong motivation to\nachieve the group's goals. Perhaps because of this high level of commitment,\nas well as the fact that individuals only met once per month, often virtually, we\ndetected relatively little interpersonal conflict in the groups. The setting is\ntherefore somewhat unique, but it is this uniqueness that enables us to trace\nhow ideas evolved over time by bringing to the surface the group interactions\nthrough which creative output developed (Bamberger and Pratt, 2010).\nData Collection and Sources\nThe primary data for the study were collected from verbatim transcripts, sup-\nported by audio recordings, of 20 group meetings that were publicly available\nfrom the AHIC. These comprise over 50 hours of group interaction. Meeting\ndata were supplemented by archival material such as agendas, presentation\ndocuments, and the formal recommendations that were submitted to the\nAnalytic Strategy\nTo address our question about the role of evaluation in the groups' creative pro-\ncess, we began by focusing on group interactions over a single idea, then\nplaced these interactions in the context of meetings, and finally the group pro-\ncess over time. We tracked ideas and their evaluation within group discussions\nand groups' immediate responses.\nStage I: Identifying group interactions during the creative process. Our\ninitial approach was grounded in the data to develop a coding scheme to\ndescribe the activities that made up group interactions over creative ideas. We\nused ideas as focal events (Abbott, 1990) and attempted to track the activities\nrelated to ideas in each meeting. One aggregate dimension that emerged from\nthe data and its development is illustrated in figure 1.\nBoth authors initially read through the entire set of transcripts for one group\nto become familiar with the content and flow of group discussion. The first\nauthor then open-coded statements with process codes (Strauss and Corbin,\n1990) to describe activities occurring in the groups. For example, the statement\n``I just have to say that I disagree with this decision vehemently'' (ES group\nmember) was coded as disagree with and refine idea. Next, we shifted from\ncomprehensively describing the data to formulating more meaningful interpre-\ntations from which to develop our theory (Glaser and Strauss, 1967; Van\nMaanen, 1979). To do this, we used constant comparison techniques (Miles\nand Huberman, 1984) to assemble the first-order codes into more abstract,\nsecond-order themes through axial coding (Van Maanen, 1979). For example,\ndisagree with and refine idea was similar to integrate multiple ideas in that both\nrelated to the discussion of ideas. Finally, the themes were gathered into\naggregate dimensions (see figure 1).\nThroughout the process, we iterated between the data and frameworks\nand Poole, 2003). Because our focus was on the creative process, our final\nframework differs somewhat from previous research, but it is also consistent\nFigure 1. Illustration of the data structure.\nIdea\u00adrelated\nDiscussion\nIdea\nIntroduced\nIdea\nDiscussed\nInformation Exchange Related to Idea:\n\"We did a market analysis . . . 72% of those in that survey said they\nwould probably or definitely use a personal health record (PHR).\"\nAgree & Elaborate:\n\"I think you're right about the word `messaging,' and maybe it's just\nan agreement among us what messaging really means.\"\nDisagree with & Refine Idea:\n\"The models [that have been discussed] are interesting. I don't think\nany one really jumps out at me as being `the' model [that we should go\nwith].\"\nIntegrate Multiple Ideas:\n\"I think we need to look at it obviously not as an either/or type of\nsituation. It could be either done through a text message, or it could be\ndone through a data stream. We need to make sure that the standards\nwe adopt are both capable of dealing with the specific types of\nbandwidth that we have available as well as the type of electronic\ninformation we want to transmit.\"\nIdea\nDecided\nAccept Idea:\n\"We've built out a very robust recommendation here.\" Member 1: \"I\nagree.\" Member 2: \"I agree also.\" Member 3: \"Let's consider that\ndone.\"\nReject Idea:\nMember 1: \"I don't think race is needed as part of the minimum\ndataset. . . .\" Member 2: \"Okay, let's move on.\"\nPresent New Idea:\n\"I'll speak for the next few minutes about a model of health care,\nwhich the college refers to as the advanced medical home. . . .\"\nDevelop New Idea:\n\"I would like to suggest that we don't define intangible and don't use\nthe term. . . .\n1st Order Process Codes 2nd Order\nThemes\nAggregate\nDimensions\nwith that research. In particular, we identified one aggregate dimension related\nto the progress of ideas in the group (illustrated in figure 1) and a separate\ndimension related to interpersonal and process issues.\nTo ensure that the framework was trustworthy (Lincoln and Guba, 1985),\nthe second author, who had not been involved in coding at that point, was\ntrained in using the coding scheme and performed two reliability checks. First,\na randomly selected set of 70 statements from the meeting transcripts were\ncoded according to the two aggregate dimensions. The Cohen's kappa\nbetween the two sets of coding was 0.77, indicating a high level of reliability.\nDiscrepancies were discussed and resolved by the authors to update the\nframework. Second, the authors compared their coding of two full meeting\ntranscripts according to the complete data structure. This revealed that the\ncategories captured the group interactions over time.\nStage II: Developing meeting maps. Once we were satisfied with the\nreliability of our framework for describing the activities of the group, we used\nthe coding from Stage I to develop a visual map (Langley, 1999) of group inter-\nactions over the course of a meeting. Our assumption at this stage was that\nexamining the sequence of events would be insightful for understanding group\nevaluative processes, we focused on identifying when and how ideas were\nintroduced, discussed, and decided upon within a meeting. These were the\nsecond-order themes related to ideas described in figure 1.\nSpecifically, we defined introducing an idea as the first mention or presenta-\ntion of a task-related idea during group discussion. Ideas could be solicited\n(e.g., when a group member asked for suggestions about an issue), formally\npresented (e.g., when a group member gave a presentation that outlined a par-\nticular idea or model for the group to consider), or spontaneously introduced to\nthe group (e.g., when a group member offered a new task-relevant idea\nunprompted). Ideas were new if they were entirely novel, extended a previous\nidea with novel content, or provided an alternative to a suggested idea.\nDiscussion of an idea occurred when group members' comments explicitly\naddressed the idea. We defined decisions as explicit consensus of agreement\nor disagreement with an idea or an expressed decision by one or more group\nmembers that was not challenged. When no explicit expression of value was\nmade or one or more group members challenged an idea without resolving the\ndisagreement, it was deemed that no decision had been made. Appendix A\nprovides a map illustrating how the themes were arranged over a meeting. As\ndemonstrated in this map, more than one idea could be discussed at a time.\nWe also included breaks in the maps for non-idea-related group activities identi-\nfied in the other aggregate dimension in Stage I, such as the process discus-\nsions at the beginning of the map in Appendix A.\nAt this point, we looked for commonalities across and differences between\nmeeting maps. We closely examined each map to identify ways of interacting\nover ideas. For example, in the map in Appendix A, we observed that ideas 3\nand 5 were introduced separately and each became the single focus of discus-\nsion, whereas ideas 16 and 17 were introduced and discussed together. We\ndeveloped hypotheses about alternative modes of interaction based on this and\ncompared the emerging modes with newly examined data as we went through\niterative process resulted in a stable set of four modes of group interaction,\nwhich we discuss more fully below: brainstorming mode, sequential mode, par-\nallel mode, and iterative mode. The two authors developed maps separately for\nthree meetings to compare the overall patterns for reliability and identified the\nsame patterns in each of the three meetings.\nOne observation that emerged during this stage of the analysis was that\ngroups engaged in more than one mode of interaction in 11 out of 20 meetings.\nThat is, the mode of interaction changed part of the way through the meeting,\nso that two or more modes each took up a substantial portion of the meeting.\nThis is illustrated in Appendix A: up to idea 9, ideas were primarily discussed\none after the other, while from idea 10, two or more ideas were usually dis-\ncussed together. Each group had at least one meeting with multiple modes of\ninteraction; for HR, this occurred in only one meeting, for PD and ES, it\noccurred in three meetings, and for CD it occurred in four meetings. In addition,\ntransitions out of each mode of interaction occurred across the groups; these\nswitches were not limited to one type of interaction. We therefore segmented\nthe meetings based on these differences. This resulted in 33 meeting seg-\nments from the 20 meetings; meeting segments became the primary unit of\nanalysis at this point. We provide details of each segment of each group in\nAppendix B. This is the underlying data on which the comparisons of modes\nand sequences we present in the paper are based.\nStage III: Examining the creative process over time. Finally, we\ncreated visual maps of the order in which the modes occurred across meet-\nings for each group. Our unit of analysis at this point shifted from meeting\nsegments to the entire group process across the five meetings. We ordered\neach of the meeting segments identified in stage II of the analysis (see\nAppendix B) across each group's meetings, retaining information about the\nacceptance or rejection of ideas at each point. As in the previous stage of\nanalysis, we searched for commonalities across and differences between\nthe groups.\nFINDINGS\nFour Modes of Creative Interactions in Groups\nExamining the 33 meeting segments revealed four different modes of interac-\ntion over creative ideas. In brainstorming mode, ideas were generated without\nevaluation; in sequential interactions, one idea was generated, elaborated, and\nevaluated; in parallel interactions, several ideas were generated and then evalu-\nated simultaneously; and in iterative interactions, the group evaluated multiple\nideas with reference to group goals. We summarize the primary features of the\nmodes in table 2. All of the groups engaged in each of the four modes we had\nidentified. Each mode involved different ways of evaluating and generating\nideas.\nBrainstorming mode. In some cases, groups interacted in a way that\nclosely resembled the traditional conception of idea generation. Brainstorming\nmode was characterized by group members generating ideas with little if any\nevaluation, relying on their own interpretation of the problem framework to do\nso. Decisions rarely occurred in this mode.\nGroups exchanged a great deal of information either before or during brain-\nstorming, but information was rarely used to elaborate or evaluate ideas. The\nfollowing brief excerpt from group CD's second meeting illustrates brainstorm-\ning interactions.1 In this discussion, the group brainstormed barriers that could\nprevent medical professionals or consumers from using technology to help\nmanage their healthcare.\nRaj: ``. . . the way you reimburse physicians drives, in a lot of ways, how physicians\nperform. I would also ask us to consider the whole idea of personal health records\nand who owns the data. We have constant conversations about physicians owning\nthat information. . . .''\nJohn: ``I would echo the reimbursement issue. I also think one of the biggest barriers\n. . . is workflow in the physician or caregiver's office. If you don't get 20 to 30 percent\nuse rate for secure messaging systems, it creates a new workflow that doesn't ever\ntake over the existing workflow. . . .''\nTable 2. Summary of Characteristics of Four Creative Modes of Interaction\nBrainstorming\nmode Sequential Mode Parallel mode Iterative mode\nDescription Ideas generated with\nlittle evaluation\nOne idea generated,\nelaborated, and\nevaluated at a time\nSmall set of ideas\ngenerated and\nevaluated in parallel\nGroup moves back\nand forth between\nideas and group\ngoals\nNature of idea\ngeneration\nDiverse set of ideas\ngenerated relatively\nindependently\nMembers tend to\nelaborate on ideas\nMembers tend to\nchallenge and refine\nideas\nMembers tend to\nintegrate multiple\nideas\nTotal number of\nideas generated\nIdeas generated per\nminute of\ninteraction\nNature of idea\nevaluation\nDecision making Few decisions made Members tend to\nagree\nMembers tend to\ndisagree\nDecisions made\nabout criteria\nFeedback Little feedback Positive Tends to be negative Focuses on criteria\nProblem framework No explicit\nconsideration\nBuilds consensus\nabout problem\nframework\nExposes problem Revise problem\nframework\nPercentage of ideas\ndecided on\nPercentage of ideas\naccepted / rejected\n1 Due to space constraints, all excerpts from meetings presented in the paper have been edited for\nreadability and confidentiality (including names being changed) and to eliminate redundant or irrele-\nvant exchanges, except when this would alter the substance of the conversation. We have made\nevery effort to retain the intent and substance of the excerpts.\n[The co-chair then directs the group to discuss legal issues, followed by an informa-\ntion exchange about legal issues. Several other group members introduce barriers.]\nJosh (co-chair): ``I know we've talked about barriers and have defined a number of\nthem, but one of the questions you had asked early on was which of the definitions\nof secure messaging we feel as a group should be recommended. I would like to see\nif we can get the group to focus on which of these would make the most sense.''\nIn this interaction, group members identified several barriers: reimbursement,\nownership of data, physician workflow, and legal restrictions. In some cases,\nmembers attended to others' ideas; for example, John ``echoed'' his support\nfor the reimbursement issue raised by Raj. But the issues were not discussed\nfurther. Although an idea may have been influenced by others' comments, the\nconnection was rarely obvious. For example, raising the issue of reimburse-\nment may have stimulated John to think about what to reimburse, leading to\nhis comments about workflow; however, no member of the group, including\nJohn, made this connection explicit. As a result, ideas in this mode tended to\nhave little relation to one another. Despite the focus on idea generation in this\nmode, groups generated only 92 ideas in brainstorming; fewer than in parallel\nmode (which produced 133 ideas) and in sequential mode (which produced\n112 ideas). When the amount of time spent brainstorming is accounted for, it\nwas the least productive mode, with only 0.11 ideas generated per minute of\ninteraction time, as shown in table 2.\nGroups also very rarely made decisions about ideas in brainstorming mode\n(only 18 percent of ideas generated were decided on in this mode). The group\neither failed to recognize and attend to ideas or failed to obtain consensus on\nthem. This can be observed in the above excerpt, in that members did not pick\nup on one another's ideas, and following the discussion, it was not clear\nwhether the group agreed that any of the ideas were real barriers to imple-\nmenting technology. The quotation from Josh, above, also illustrates that mem-\nbers tended to rely on their own problem framework during brainstorming\ninteractions. At the beginning of the interaction, group members raised the\nquestion of how to define ``secure messaging,'' a term that was presented to\nthem in the group's goals. Josh's attempt to refocus the group on this term\nindicates that members did not resolve or even address its meaning as they\ngenerated ideas.\nSequential mode. A second pattern was the sequential generation, discus-\nsion, and evaluation of one idea at a time. In this mode, groups elaborated on\nideas and built consensus about the problem framework by considering the\nadvantages and disadvantages of each idea.\nThe following excerpt from a sequential discussion by the PD group during\ntheir third meeting illustrates this process. This excerpt follows one member,\nSam, describing an electronic health record (EHR) system in one state and pro-\nposing it as a model for wider roll out:\nCharlton: ``I think, obviously, this is the model all others should probably follow. I\nthink they had a lot of success. But something that is not mentioned here that I think\ndrove adoption . . . was incentivizing laboratories and creating some type of an add-\non payment so that they do transmit their results [to other providers].''\nDaniel: ``I wonder if maybe [you are referring to] the DFD messaging system, which\nreplaces their existing delivery processes. That has been a very powerful influence in\nengaging laboratories and radiology centers.''\nSam: ``. . . I appreciate the discussion between you and Charlton that there is a value\nproposition for this system based on the ability to not have to ship out paper. You\nestimate the cost of doing that is about $ 0.81, correct?''\nDaniel: ``Correct, although I will say the $ 0.81 is for hospital results. We find a lot of\nthe commercial laboratories are more efficient. . . .''\nWes: ``I'm curious; do you have any experience with the physician office lab?''\nDaniel: ``We do, and there's two flavors of those. One is the larger practice, the 10-\nphysician internal medicine practice, and they work just like everybody else. The\nother one, which is trickier, is physician offices.''\nBrad: ``I wanted to complete the thought that beyond the value proposition, though,\nit is not absolutely necessary for it to be a centralized database. In fact other models\ncould sustain this as well. The value proposition would remain intact.''\nDuring this exchange, group members focused on one idea: adopting the fed-\nerated model for capturing patient data that was in use in one state. They\nexchanged information about the model, asked questions, and proposed ways\nto change it.\nSequential mode was the most productive, with 0.20 ideas generated per\nminute of interaction, resulting in 112 ideas. Ideas generated in this mode\ntended to be elaborations of existing ideas, because members generally agreed\nwith and built on a focal idea. This can be seen in the above discussion, when\nBrad noted that to achieve the value proposition of the model, the data did not\nneed to be centralized. As another example, the same group later discussed\nhow to build a system to provide information to first responders in emergency\nsituations. One group member suggested using a web-based system. Simon,\nwho had experience in these situations, responded by proposing that this was\nnot a complete solution:\n. . . [a] transmission path for the Internet is really a challenge in those situations. But I\nwould echo the comments that it's exceedingly important to deliver Internet to your\nhospitals. What becomes really difficult, particularly in a combat zone, is delivering\nInternet to the point of injury. So you rely heavily on your voice networks.\nSequential discussion of new ideas therefore appeared to be a mechanism\nthrough which groups attended to and built on a single idea, rather than diver-\nging in different directions.\nSequential interactions also built consensus about the problem framework.\nDuring the first exchange quoted in this section, Daniel's comment identified\nengagement with laboratories and radiology centers as one dimension on\nwhich to evaluate solutions. Sam then implied that the value proposition of the\nsolution was an important criterion for judging solutions. Although the group\ndid not explicitly choose between these criteria, their subsequent discussion\nbuilt consensus about the importance of the value proposition. For example,\nwhen Brad built on the idea of using a database, he confirmed that ``the value\nproposition would remain intact.'' Thus evaluating an idea as it was discussed\ninvolved elaborating evaluation criteria, which directed subsequent discussions\nand built consensus about the problem framework.\nUltimately, groups decided on 58 percent of ideas discussed in sequential\nmode. Only 15 percent of ideas were rejected, even though group members\nwere not always in full agreement. In the discussion about using the Internet\nfor first responders, it was clear that Simon disagreed that an Internet solution\nwas entirely correct, and in the discussion of the federated model, Brad did not\nthink that a centralized model was necessary. But members expressed their\nviews by agreeing with and then broadening the idea. For example, Simon\nagreed with the value of providing Internet access to hospitals and added a\nsuggestion for dealing with situations in which that would not work. Similarly,\nBrad agreed with the model being discussed and noted that ``other models''\nwould allow the group to achieve the same benefits. Evaluation was not a neg-\native experience in this context, nor did it interfere with subsequent idea-\ngenerating efforts. In fact, idea evaluation promoted idea generation and helped\nthe group to build consensus about the problem framework in sequential\nmode.\nParallel mode. A third mode that emerged from the data was the parallel\ndiscussion of multiple ideas at the same time. In parallel mode, groups gener-\nated then compared and contrasted a small number of ideas, clarifying the\nproblem framework and making decisions.\nIdeas generated in parallel mode tended to be alternatives to one another.\nFor example, during their second meeting, the CD workgroup discussed the\nappropriate population for a pilot test. Two options were suggested: focusing\non all of the patients with a particular disease, or focusing on a geographic\nregion:\nRaj: ``I would recommend segmenting out a specific population. I believe that you\nhave to isolate the customers you are serving. If you were to take it in a diffuse man-\nner, you really haven't segmented your market enough to win with some[thing]\nmeasurable.''\nTim: ``. . . you could segment it within that group. Let's just focus on diabetics. Let's\njust focus on congestive heart failure . . . prove that one community shows savings,\nand then expand it. . . . Or would you say that the geographic provider-based\napproach is better?''\nRaj: ``That is a very, very challenging question for me. I believe that the disease set\nin chronic illnesses is really connected. It's really hard to isolate one particular disease\nlike that and say, `That's the one we can work with.' So I believe you have to take a\ngeographically specific environment . . . and take a set of diseases that are\ncorrelated.''\nNina: ``Could I just clarify that? As an example, one of the things we had talked about\nwas [a model of engaging] primary care physicians and/or cardiologists and/or endo-\ncrinologists and/or nephrologists. It would encompass a number of . . . illnesses.''\nRaj: ``Yes, that would be an example.''\nJohn: ``If you don't have a critical mass of physicians adopting this type of technol-\nogy and actually using it . . . it doesn't matter how you structure it. . . . So I would\nargue strongly that we define our charter around a geographic pilot first and then find\nthe disease-specific opportunities within that.''\nBecause ideas were compared with one another, the nature of idea genera-\ntion was often to disagree and therefore to refine rather than build on ideas.\nThis is evident in the preceding exchange, when Raj argued that it was not\npossible to isolate specific diseases. These disagreements were task-based\nconflicts between group members. Their effect was to narrow the scope of\nideas. For example, during one conversation about the minimum data needed\nby emergency first responders in the ES group, members proposed a list of\ndata elements. One member argued that many of the elements were not\nneeded and proposed an edited list:\nA broader . . . system really keeps it much simpler than this proposal. . . . When I've\nheard [our manager] talk about what he sees as the need, you really want to keep it\nextremely simple . . . how many people are in your ICUs, how many people are in\nyour hospitals, and what's your excess capacity? So I have a lot of concerns about\nthis minimum dataset.\nThis conflict did not prevent idea generation, however. As shown in table 2,\nthe most ideas (133) were generated in parallel mode.\nEvaluation during parallel discussions provided direct feedback about ideas.\nFor example, during their second meeting, the HR group discussed four ways\nto implement personal health records (PHRs), including leveraging regional sys-\ntems (option 1) and expanding an existing emergency information system\n(option 2). One group member, Kyle, commented:\nIn looking at the options, my concern [with option 1] is: are we engaged with every\none of these providers and exchanging information with them. . . . I think this would\nbe a huge distraction for them. Option two, being involved with this system, I think\nwhatever we do should be scalable. And whatever we demonstrate to do should be\nscalable. As much as we enjoy doing this and helping out, this is not a scalable\nsolution.\nKyle directly criticized option 1 as a ``huge distraction.'' This illustrates that par-\nallel discussions focused on eliminating ideas from consideration. In this mode,\ndecisions were made about 62 percent of ideas, and rejection was the most\nlikely, with 19 percent of ideas rejected, as shown in table 2.\nDirectly comparing ideas also made the problem framework explicit. For\nexample, Kyle, above, was adamant that ``. . . whatever we . . . do should be\nscalable.'' Whereas identifying assumptions led the group to build consensus\nabout the problem framework in sequential mode, making the problem frame-\nwork explicit by comparing ideas allowed the group to clarify and choose which\ncriteria to base decisions on. For example, in the exchange at the beginning of\nthis section, Raj described his understanding that chronic diseases were con-\nnected to one another and should be treated as a whole. Nina clarified her\nunderstanding of his point, and John directly suggested that another criterion,\nphysician participation, should take priority. Therefore, in parallel mode, evalua-\ntion stimulated refinements of ideas and helped the group to develop the prob-\nlem framework.\nIterative mode. The final mode through which ideas developed was an\niterative interaction in which groups introduced and discussed one idea, then\nintroduced a new idea without directly comparing it with the previous idea,\nthen returned to the original idea. Ideas from earlier in the group discussion\nmay have been re-introduced in this mode. This mode involved integrating\nideas and shaping the problem framework in the process of making decisions,\nas summarized in table 2.\nIn iterative mode, group interactions also built on and elaborated ideas, simi-\nlar to sequential interactions, but by moving back and forth between ideas,\ngroups also identified ways to integrate multiple ideas. This seemed to occur\nnaturally, in response to additional information or others' ideas, rather than\nbecause the group was focused on a particular idea. For example, during one\nof the CD workgroup meetings, members attempted to identify ways to mea-\nsure the success of a secure messaging system:\nTim: ``The bottom line is: how many hospital stays or visits do you avoid?''\nRaj: ``Exactly, exactly.''\nTim: ``How much cost do you take out of the system while providing better care?''\nRaj: ``Exactly. So the assumption is that it will reduce patient-physician office visits\nwhile increasing the care outcomes. That's what I think we are trying to go for,\nright?''\nJosh: ``I agree with you completely, and exactly that was the point I was making in\nmy initial remarks, that it cannot just be based on technology enabling, but also\nneeds to be based on some specific outcomes.''\nJohn: ``In our experience in a prospective trial . . . we actually did see a reduction in\nper-member-per-month costs in the treatment group versus control. So this is a case\nfor cost reduction or cost avoidance. I think another way to think about it, too, is\ncompliance.''\nMartin: ``I want to go back to the question relating to the specific charge of the work-\ngroup and the issue of secure messaging versus secure e-mail. I would hope that we\nwould keep the broader definition so that we could access all of these outcomes.''\nIn this excerpt, Raj, Tim and John built on Tim's initial suggestions about how\nto measure success. Then, Martin referred back to the group's previous ideas\nabout how to define secure messaging, connecting it to outcomes, and stimu-\nlating a discussion that iterated between these topics and the connections\nbetween them. The group concluded by framing the problem in a way that\nallowed them to integrate ideas so that they could achieve ``all of these\noutcomes.''\nDisagreements during this type of interaction tended to focus on a single\nidea, rather than the trade-offs between ideas. For example, one member of\nthe ES group suggested including data from animal communities in the mini-\nmum dataset for emergency situations. Another member disagreed without\ncomparing the idea with others:\nThere are . . . when you start to delve into this, an increasingly broad realm of data. . . .\nOne is the animal realm, one could go to the environmental realm, etc. While lots of\nthat may be important, it is critically important that we consider the very specific\ncharge that the group has been given in terms of a deliverable inside of a year. And\nthat, I think, may be something that has to scope us in terms of some of the activities\nwe pursue.\nThis contrasts with parallel discussions, in which group members argued that\nothers' ideas, such as focusing on a specific disease category, were not\npossible.\nAs in parallel and sequential interactions, ideas were likely to be decided on in\niterative mode. Decisions were made on 73 percent of ideas in this mode, in con-\ntrast to 62 percent in parallel mode and 58 percent in sequential mode, as shown\nin table 2. In this mode, members frequently referred back to the group's goals\nand often refined both the problem framework and ideas in light of the frame-\nwork. Evaluation therefore tended to occur in response to the problem frame-\nwork. For example, in the quotation above about the value of animal data, the\ngroup member disagreed by referring to the scope of the task and what was\nachievable within the timeframe. The group was not bound by the problem\nframework in iterative discussions, however; members often challenged the\nframework when they were concerned that it would lead the group to support a\npoor idea. For example, after trying to gain consensus on privacy issues related\nto their group task, members of the HR group fundamentally challenged whether\nthey could provide good recommendations given the constraints of time and\ninformation:\nLewis: ``I would hope that our workgroup would advocate to the community as a\nwhole that there be a more rigorous public process. . . . I haven't seen a time or pro-\ncess set aside yet where the issues will be fully discussed, and my concern honestly\nis, [we are] not the right set of players to discuss these basic values and privacy\nissues.''\nHarrison: ``. . . I've been a little concerned about the time--this is all being done\nunder a number of constraints that are challenging at best and daunting. We're trying\nto do many, many things at once. And I am concerned that we have to slide those\ndown to the ones that are essential for our narrow charge.''\nThe group went on to navigate a consensus about how to refine the framework\nbased on their ideas, identifying where the task goals were too broad. In this\nway, evaluation in iterative processing contained judgments about the problem\nframework used to assess ideas.\nSequences of Creative Interactions over Time\nFigure 2 displays the results of our analysis of group interactions over time. It\nillustrates that groups did not engage in the four modes of interaction in the same\nsequence over time. Instead, we observed two broad ways that the modes of\ninteractions were ordered. We describe the process followed by groups HR and\nPD as a generation-centered sequence. In the generation-centered sequence,\ngroups engaged in divergent idea generation through brainstorming and then nar-\nrowed down the set of ideas selected. Given the resemblance of the generation-\ncentered sequence to the creative process described in research to date, it was\nsomewhat surprising to discover that groups CD and ES followed a sequence\nthat was essentially the mirror image of this pattern. We describe this process as\nan evaluation-centered sequence. In the evaluation-centered sequence, groups\nevaluated a small number of ideas early in parallel mode then developed a shared\nproblem framework and elaborated on and integrated their ideas.\nThe differences between modes in the nature of idea generation and evalua-\ntion that we described above corresponded to some differences in outcomes.\nFor example, ideas were more likely to be decided on in sequential, parallel,\nand iterative mode than in brainstorming, as table 2 showed. Comparing the\ntwo sequences revealed that the order in which a mode occurred also\nFigure 2. Sequences of creative modes of interaction over time.*\nGeneration-centered Sequences\nEvaluation-centered Sequences\nGroup\nCD\nGroup\nES\nGroup\nHR\nGroup\nPD\nCumulative percentage of group meetings\nParallel (P) Iterative (I/S) Brainstorming (B)\nBrainstorming Mode\nIterative Mode\nSequential Mode\nParallel Mode\nParallel (P)\nBrainstorming (B) Iterative (I/S)\nParallel (P)\nBrainstorming (B) Iterative & Sequential (I/S)\nParallel (P) Iterative & Sequential (I/S) Brainstorming (B)\nMODE\n-------- 7 --------\n-------- 5 ---------\n-------- 5.5 -------\nIdeas generated\n% Decided\n% Accepted\n% Rejected\nAvg. proposed\nrecommendations\nAvg. Accepted\nRecommendations\nAvg. switches between\nmodes\nMODE\n------- 8.5 --------\n------- 8 --------\n-------- 8 ---------\nIdeas generated\n% Decided\n% Accepted\n% Rejected\nAvg. proposed\nrecommendations\nAvg. accepted\nrecommendations\nAvg. switches between\nmodes\n* Summary data for ideas generated, decided, accepted, and rejected are based on only those portions of the process highlighted as consistent across\nthe two groups (i.e., those portions contained in the dashed boxes).\ninfluenced the periods during which groups generated versus decided on ideas,\nas shown in figure 2. We explore these differences in more detail below.\nDescribing the sequences this way inevitably obscures some of their complex-\nity. Our goal was to explore key commonalities and differences rather than to\ncomprehensively account for the sequences in each of the four groups.\nGeneration-centered sequences. We pool the data from groups HR and\nPD in figure 2 to describe generation-centered sequences. Brainstorming domi-\nnated the first meeting of the generation-centered sequence. Facilitators of the\ntwo groups in this category encouraged members to generate ideas individually\nearly on, either implicitly or explicitly. For example, the facilitator of PD solicited\ncomments from group members who hadn't spoken, shifting the conversation\nto a new topic, whereas the facilitator of HR encouraged members ``. . . to be\ndeveloping [a] list of issues individually. . . .'' Figure 2 shows that in the\ngeneration-centered sequence, 42 ideas occurred in early brainstorming inter-\nactions, more than were generated in the evaluation-centered sequence early\non or during brainstorming. This supports the view that evaluation stunts idea\ngeneration. When following this sequence, groups also spent more time brain-\nstorming than in the evaluation-centered sequence. Yet evaluation was not\nentirely absent from this mode: the group made decisions on over 30 percent\nof ideas while brainstorming in the generation-centered sequence.\nNext, groups built on and integrated ideas through sequential and iterative\ninteractions. Their productivity dropped to 34 ideas at this point, while they\nmade decisions on over 60 percent of ideas. The generation-centered\nsequence concluded with parallel interactions. Despite continuing to evaluate\nideas, this was the most productive part of the sequence, as shown in figure 2,\ngenerating 89 ideas. These groups also spent longer in parallel mode than\nevaluation-centered groups. In addition, once these groups entered parallel\nmode, they only exited it at the end of a meeting. For HR, there was relatively\nlittle movement out of any mode within a meeting; a switch only occurred in\ntheir second meeting. The movement from brainstorming to iterative / sequen-\ntial to parallel interactions occurred over the first four meetings.\nOverall, group members diverged early in the generation-centered sequence\nand then refined ideas through parallel interactions late in the sequence. Mid-\nstage sequential and iterative interactions focused on evaluating ideas, rather\nthan elaborating and integrating ideas.\nEvaluation-centered sequences. Pooling data from groups CD and ES\nreveals that evaluation through parallel mode occurred early in this sequence.\nFigure 2 illustrates that early interactions produced only 20 ideas, fewer than\nthe generation-centered sequence, but groups decided on 75 percent of those\nideas and spent relatively little time in this mode.\nLike the generation-centered sequence, the evaluation-centered sequence\nnext transitioned into iterative and sequential interactions. In contrast to the\ngeneration-centered sequence, however, these interactions were the most pro-\nductive, with 39 ideas generated in these modes, while ideas decided on\ndecreased to 46 percent, as shown in figure 2. The sequence concluded with\nbrainstorming. Both idea generation and decision making decreased during\nthis mode. Decisions continued to be made about ideas after these three\nmodes, primarily through sequential interactions late in the group process.\nThose later-stage interactions were more important in the evaluation-centered\nsequence, which was also more varied than the generation-centered sequence:\ngroups transitioned between modes eight times in this sequence, while the\ngeneration-centered sequence involved less than six transitions. As a result,\ngroups following this sequence engaged in parallel mode for short periods late\nin the process. In addition, there were multiple modes of interaction in at least\nthree meetings for both CD and ES. Unlike generation-centered groups, they\ntransitioned back and forth between parallel and other modes within a meeting.\nOverall, the evaluation-centered sequence began with a short period in\nwhich a small number of ideas were evaluated in parallel mode. Most ideas\nwere decided on during that time. Idea generation followed and involved ela-\nborating on and integrating ideas in sequential and iterative modes. This\nsequence also involved more frequent transitions between modes within and\nacross meetings than the generation-centered sequence.\nGroup Creative Sequences and Performance\nIt is apparent that some groups engaged in the creative task by essentially\nreversing the traditional creative process. Even more intriguing is that these\ngroups did not appear to suffer as a result of ordering the process this way. As\ntable 3 shows, all four groups generated many ideas, and each group put for-\nward several formal recommendations in their first deliverable, most of which\nwere accepted. Recommendations were collated by a group's facilitator based\non group discussions and may have included several elaborated or integrated\nideas that emerged during group discussion. We cannot be definitive about the\nway that evaluations throughout the process resulted in these recommenda-\ntions, nor do we know the ultimate novelty or quality of the recommendations.\nIt is not our intention to make strong claims about performance differences\nbetween the groups. There is ample evidence to conclude that both sequences\nenabled groups to develop some creative solutions.\nTable 3 does offer some support, however, for the two sequences of crea-\ntivity we observed across the groups. Generation-centered groups generated\nmore ideas (207) than evaluation-centered groups (175), supporting the focus\nwe observed on divergent generation in this sequence. The HR group may be\nTable 3. Summary of Policy Groups' Process and Outcomes\nNumber of recommendations accepted 3 7 8 8\nPercentage of group meetings in each mode of interaction\nCreative sequence Generation-\ncentered\nGeneration-\ncentered\nEvaluation-\ncentered\nEvaluation-\ncentered\ndescribed as sticking most closely to the brainstorming process, because it\ntransitioned between modes infrequently and usually only between meetings;\nit also generated the most ideas but decided on less than half and rejected few\n(less than 10 percent). Interestingly, however, members spent almost 60 per-\ncent of their time in parallel mode; this emphasizes the importance of the\nsequence in which the modes occurred. Evaluation-centered groups agreed on\nmore recommendations (17, versus generation-centered groups' 14) and had\nmore recommendations accepted (16 versus 10). This is consistent with mid-\nstage iterative and sequential interactions enabling the group to establish a\nproblem framework through which to evaluate ideas. These differences cannot\nbe explained by the degree of structure present in the group meetings, as both\nthe generation-centered and evaluation-centered sequences occurred in rela-\ntively more and relatively less structured environments. We take these out-\ncome data as support for our contention that the generation-centered process\nstimulates divergent idea generation, while the evaluation-centered process\nenhances creativity by establishing a problem framework that enables group\nmembers to elaborate and integrate ideas.\nGroups are often responsible for creative output in organizations because\nmembers can stimulate one another's divergent thinking (Nemeth, 1986;\nout poor ideas (Laughlin, 1988; Paletz and Shunn, 2010). This is consistent with\nan idea-generation-centered creative process. By focusing on idea generation\nas the core creative activity of the group process, however, existing theoretical\nconceptions provide less insight into how groups develop a problem frame-\nwork, retain novel ideas, and build on and elaborate ideas.\nFigure 3 contrasts this model with an alternative in which idea evaluation is\ncentral to the group creative process. In the evaluation-centered model, evalua-\ntion directs collective attention to ideas and therefore shapes idea generation.\nAn evaluation-centered process that begins with comparing a small number of\nideas and moves toward divergent idea generation later in the process provides\nan alternative way for groups to engage with creative tasks. The core creative\nactivities of the evaluation-centered process are the construction of a problem\nframework, the retention of novel ideas, and the elaboration and integration of\nthose ideas.\nCreative idea evaluation. In our model, evaluation is not a stage of the\ncreative process; it is embedded within a mode of interaction. Consistent with\na long-standing body of research that demonstrates that the process of\ndecision making affects the evaluation criteria used and therefore the resulting\nHargadon, 2005), we suggest that the process of evaluating creative ideas in\ngroups influences the problem framework, the type of feedback provided, and\ntherefore decisions.\nSpecifically, comparing ideas exposes and clarifies the categories for com-\nFigure 3. Alternative models of the group creative processes.\nGeneration-centered group creative process\nEvaluation-centered group creative process\nGenerate novel ideas in divergent\ndirections\nNegotiate problem framework Filter out low-quality ideas through\ncollective decision making\nNovel ideas\nrelative to a\npresented &\nnegotiated\nproblem\nframework;\nhigh\u00adquality\nideas selected\nNature of Idea Generation\nNature of Idea Evaluation\n- Decision making\n- Feedback\n- Problem framework\nGenerate novel ideas in collective\ndirection; retain novel ideas\nDiscover & construct problem framework;\nelaborate and integrate ideas based on\nfeedback\nExpose & clarify problem framework\nthrough idea generation\nNature of idea generation\nNature of idea evaluation\n- Decision making\n- Feedback\n- Problem framework\nElaborated and\nintegrated ideas\nin response to\njointly developed\nproblem\nframework; novel\nideas selected\nBrainstorming\nDivergent idea generation\nNo explicit decisions\nImplicit feedback\nIndividual interpretation of\nframework\nSequential / Iterative\nElaborate & integrate ideas\nAcceptance of ideas\nPositive feedback Construct &\nbuild consensus about\nframework\nParallel\nRefine & narrow ideas\nRejection of ideas\nCritical feedback\nExpose & clarify\nframework\nBrainstorming\nNo explicit decisions\nImplicit feedback\nIndividual interpretation of\nframework\nDivergent idea generation\nSequential / Iterative\nAcceptance of ideas\nPositive feedback Construct &\nbuild consensus about\nframework\nElaborate & integrate ideas\nParallel\nRejection of ideas\nCritical feedback\nExpose & clarify\nframework\nRefine & narrow ideas\nParallel and iterative modes rely more on direct comparisons than the other\nmodes. The parallel mode helps to illuminate the problem framework, while\nthe iterative mode helps to refine that problem framework. Although this\nmakes ideas easier to critically evaluate (Hsee et al., 1999), it also calls atten-\ntion to the lack of information about ambiguous, novel alternatives (Knight,\nindividual and group judgments tend to be more negative (Ellsberg, 1961; Fox\nand Goncalo, 2012). We propose that these negative evaluations are likely to\nresult in refining and improving focal ideas (cf. De Stobbeleir, Ashford, and\nBuyens, 2011). In sequential mode, in contrast, group members do not focus\non the ambiguity of novel ideas and are therefore more likely to positively value\nthem, so that those ideas may become a starting point for elaboration (Runco,\nimplied problem framework. In iterative mode, the group is explicit in deciding\nwhich elements of the problem framework to focus on, providing indirect feed-\nback about ideas in the process. Even in brainstorming, when there is no\nshared problem framework, members rely on their own view of the problem so\nthat there is little explicit feedback or decision making. Implicitly, no ideas are\nselected into the group's discussion. This may highlight the group's need for\nbetter ideas, directing members to individually generate ideas that are worthy\nof the group's attention.\nThis integrated view of creative idea evaluation provides three insights into\nits role in the creative process. First, rather than fulfilling a single role at one\nstage, evaluation fills three roles: providing feedback, constructing the problem\nframework, and decision making. These roles are linked through the mode of\ninteraction in which they are enacted (Collins, 2005; Elsbach, Barr, and\nHargadon, 2005). Second, we propose that what integrates these roles is that\nevaluation directs collective attention to ideas. Evaluative processes like distin-\nguishing between ideas or concepts promote attention and understanding\nEvaluation may therefore be necessary to stimulate other group members'\ninterest in an idea. In addition, the more group members who focus on an idea,\nthe more psychologically meaningful it becomes to each member (Shteynberg,\n2010), making the group more likely to invest time and effort to develop the\nidea. Evaluative processes therefore facilitate interaction over and engagement\nwith ideas. Third, whether group members diverge, elaborate, integrate, or\nrefine ideas depends on how ideas are evaluated. Idea evaluation therefore\nshapes the nature of idea generation in groups (Elsbach and Kramer, 2003;\nThese three insights into the role of idea evaluation within the creative pro-\ncess reveal that idea generation and evaluation are embedded within a mode\nof interaction. The activities of the group therefore cannot be understood with-\nout reference to the process that produces them (Poole, McPhee, and Seibold,\nThe evaluation-centered creative process. We further propose that the\ncombination of idea generation and evaluation within a mode of interaction\nshapes subsequent engagement with the creative task and the nature of\ncreativity. Just as individuals can engage in a search for tried and tested solu-\ntions or for novel ideas (Ford, 1996; Gilson and Shalley, 2004; Zhang and Bartol,\n2010), groups can engage in the collective creative process in alternative ways.\nFigure 3 reveals that when idea generation is the focal activity of a group, the\ngeneration-centered sequence--individual divergence, building on and integrat-\ning ideas, refining ideas--makes intuitive sense. Consistent with existing litera-\nture, this sequence stimulates divergent thinking early in the process (Nemeth,\nIn our model, however, idea generation is not the only activity occurring dur-\ning this sequence. Moving from divergent generation to idea elaboration and\nintegration also means moving from individually interpreting the problem frame-\nwork to decision making. This provides little opportunity for the group to collec-\ntively construct the problem framework. Members are likely to rely on their\nown preexisting frameworks to make sense of ideas (Gioia, 1986; Weick,\ncan become a battle over whose perspective should dominate the group's\nlarly likely when members have already committed to their own ideas in brain-\nstorming mode. Although the conflict may improve the rigorous selection of\nhigh-quality ideas (Singh and Fleming, 2010), it also limits the group's ability to\nconstruct a problem framework by integrating perspectives.\nIn contrast, in the evaluation-centered process, moving from parallel to itera-\ntive/sequential interactions means that members expose and clarify the prob-\nlem framework early on, providing an opportunity for members to construct the\nproblem framework together. Ideas generated during the early stages of this\nprocess can act as boundary objects (Carlile, 2002), like prototypes or experi-\nments, helping to uncover otherwise hidden problems and making assump-\ntions explicit (Schrage, 2000). They therefore provide a mechanism for\nexposing and manipulating the problem framework. Without such a mechan-\nism, underlying assumptions would likely remain hidden (Cronin and Weingart,\n2007). Identifying gaps between members' problem frameworks may then\nenable the group to reframe the problem in creative ways (Langer, 1989;\nonly be known by mentally experimenting with and exploring ideas (Bechky,\npositioned to construct the problem framework. Research suggests that\nactively developing the problem framework can result in novel ways of viewing\ning a clear and shared problem framework facilitates deeper engagement in\nA second advantage of the evaluation-centered process is revealed by con-\nsidering the placement of parallel interactions. Although relatively more novel\nideas may be rejected during early parallel interactions in the evaluation-\ncentered sequence due to members' aversion to their ambiguity (Fox and\nTversky, 1995), such ideas are unlikely to be the group's most creative. The\nmost easily accessible and therefore common solutions to a problem tend to\nbe identified first; novel ideas emerge with time and effort (Basadur and\nThompson, 1986). Eliminating relatively more novel early ideas is likely to\npose a minimal risk to group creativity. In contrast, prolonged parallel\ninteractions later in the process are likely to result in rejecting the most novel\nwell-developed ideas. Again, this may reduce the risk of selecting a poor idea,\nbut it may also eliminate the group's most novel ideas, even when they are\nhigh in quality.\nFinally, moving from mid- to late-stage interactions reveals that a third advan-\ntage of the evaluation-centered sequence is the opportunity to use develop-\nmental feedback for idea generation. In the generation-centered sequence,\nevaluation becomes increasingly salient as it moves from problem framework\nto ideas and increasingly negative as it moves from accepting to rejecting\nideas. This is reinforced by the negotiation of the problem framework. This is\nan unlikely ground for further elaboration or integration of others' ideas\ndiscussing a small number of ideas in parallel early in the sequence may lead to\na more positive evaluation environment. By exposing group members to direct\nevaluation early in the process, parallel interactions may set a group norm in\nwhich members are comfortable providing and receiving feedback\n(Edmondson, 1999). Group members may also be less committed to ideas and\ntherefore more open to evaluation early on, particularly because feedback at\nthat stage provides the opportunity to develop ideas (Shalley, 1995; Shalley,\nZhou, and Oldham, 2004). The evaluation-centered sequence provides an\nopportunity for groups to use feedback to elaborate and integrate ideas.\nAlthough decisions were not explicitly made at the end of the sequence, we\nsuggest that ideas are more likely to be noticed and remembered because they\nare better developed and understood within a problem framework (Walsh,\nAn evaluation-centered sequence offers an alternative path to creativity. We\ndo not suggest that it will necessarily be more effective than the generation-\ncentered creative process. Instead, our model proposes that the core creative\nactivities of the sequence are collectively constructing the problem framework,\nretaining novel ideas, and elaborating and integrating ideas based on feedback.\nWe propose that this can result in more novel final output. In contrast, the core\ncreative activity of the generation-centered creative process is the generation\nof novel alternatives stimulated by others' ideas. This should lead to more ideas\nand a more diverse set of ideas. But it may also cause groups to undervalue\nnovel ideas, because members do not share a problem framework, may nega-\ntively evaluate novel ideas in comparison to less ambiguous, high-quality ideas,\nand have less opportunity to elaborate and integrate ideas. We describe these\nas alternative ways of engaging with creative tasks. In the early stages of the\ngeneration-centered sequence, individuals generate ideas in a group context,\nfollowed by collective decision making; in the evaluation-centered sequence,\ngroups collectively generate ideas.\nBoundary Conditions\nThe context that allowed us to uncover the nature of creative idea evaluation\nalso has unique features. It therefore provided an extreme case that is ideal for\ntheory building (Bamberger and Pratt, 2010), but that may limit the generaliz-\nability of our results. The groups we studied were cross-functional and cross-\norganizational, so they brought diverse perspectives to the task. In addition, the\ngroup's tasks were highly ambiguous and complex, providing the opportunity\nfor interpretation. In a context with less underlying variability, or in which oppor-\ntunities for interpretation do not exist, an evaluation-centered process may inhi-\nbit creativity.\nWe also found few interpersonal problems in the groups, and those that did\noccur were quickly diffused with minimal impact. It is unusual for long discus-\nsions with a high degree of task conflict to remain so interpersonally neutral.\nThis may have been aided by members' deep personal commitment to the\ngroup's goals. In addition, groups were not ultimately responsible for imple-\nmenting their ideas, so members' may have been less politically motivated to\npropose particular solutions than in other contexts. In groups with negative\ninterpersonal environments or in which power and status are predominant,\nearly-stage evaluation of ideas could have become more contentious, and the\nprocess may have been driven by dialectic conflicts between partisan actors\nevaluation-centered process may be bounded by members' commitment to\ncommon goals.\nFinally, the groups in our study interacted in a relatively minimal way, with\nmuch of their discussion occurring virtually and little contact between monthly\nmeetings. This is similar to a growing number of organizational groups in which\nmembers divide their time and affiliation between many groups with whom\nthey interact virtually (e.g., Gibson and Gibbs, 2006; Wageman, Gardner, and\nMortensen, 2012). But this context does not lend itself to examining the role of\ninformal dyadic and subgroup interactions that often occur outside of group\nmeetings. These informal interactions are also likely to be characterized by a\nhost of power and status dynamics that we did not uncover. In addition, the\ncontext provided less opportunity for group members to influence one another\nthrough nonverbal cues than in more traditional groups, which may have helped\nto shift the group between modes of interaction. We expect that informal inter-\nactions would replicate the patterns we found, in effect replicating outside of\nformal meetings the same modes of group interaction we observed. For exam-\nple, when presented with an idea in an informal interaction, a group member\nmay discuss that idea in detail (sequential mode) or generate an alternative\n(parallel mode). At the same time, informal interactions may alter the likelihood\nof different modes occurring and may produce additional patterns that we did\nnot observe.\nDISCUSSION\nCollectives evaluate ideas throughout the creative process as they ignore or\nbuild on one another's ideas, provide interpersonal rewards and punishments\nfor ideas, or follow particular idea paths (Sutton and Hargadon, 1996; Elsbach\nWe built on research into these situated evaluations to reconceptualize evalua-\ntion as a process that guides how groups combine members' inputs into crea-\ntive collective products. Rather than viewing idea evaluation in groups as a\nstage of convergent decision making (Paletz and Schunn, 2010), we view it as\na different aspect of the same mode of interaction through which ideas are\ngenerated. When one group member shifts a discussion toward an idea sug-\nmoment of idea generation for the originator and evaluation for the other. For\nthe collective, it is both. The actions and reactions of the group reveal and\nOvercoming the challenges of collective creativity. A central contribution\nof our research is to provide new insights into how groups can use evaluation\nto engage in the creative process in a way that overcomes the challenges of\ncollective creativity identified in previous research. One way is to prompt the\nprocess of problem construction. Previous research emphasizes that diversity\nenhances a group's divergent cognitive and dynamic processes (e.g., Watson,\nmore difficult for groups to identify and select creative ideas (Milliken, Bartel,\nsuggesting that evaluation enables groups to synthesize members' diverse\nperspectives into a shared problem framework. This casts a new light on\ndiversity research, which has emphasized the value of diversity to divergent\nthinking. In contrast, our study suggests that diverse perspectives are also\nvaluable when they converge, to the extent that they provide a novel problem\nframework for the group. Our study further implies that problem construction\nrequires engaging with the content of ideas, and that, as others have also\nobserved, it does not occur at the beginning of the creative process (e.g.,\nconstruction as a key element of the collective creative process that unites\nidea generation and evaluation and calls for further research on the facilitators\nof this process and the conditions under which it is more or less valuable to\ncollective creativity.\nOur research also differentiates the contexts that allow groups to retain\nnovel ideas from those that promote convergent decision making. We highlight\nthat evaluating the novelty of an idea differs from evaluating its quality because\njudgments of novelty entail selecting ideas into the group discussion rather\nthan eliminating them from consideration and require retaining rather than\nresolving ambiguity about ideas (Long-Lingo and O'Mahony, 2010). Our\nresearch therefore implies that to improve their ability to select novel ideas,\ngroups need to manage their interactions to make ambiguity less salient.\nAdditional research may consider other ways that the group context amplifies\nor dampens perceptions of an idea's ambiguity. For example, ideas may be per-\nceived as less ambiguous when members trust one another's expertise (Fox\nand Tversky, 1995) or creative ability (Elsbach and Kramer, 2003). More broadly,\nour research emphasizes that groups may need to trade off different outcomes\nat different points in time. For example, reducing group members' perceptions\nof the ambiguity of novel ideas may also lead to the selection of lower-quality\nideas. We provide a framework for linking evaluative processes to alternative\noutcomes.\nFinally, our study reveals that evaluation promotes two underexplored forms\nof collective idea generation--elaboration and integration (Litchfield, 2008;\nKohn, Paulus, and Choi, 2011)--because it helps to illuminate relationships\nbetween ideas. This offers a novel explanation for why groups struggle to gen-\nerate creative ideas. Whereas previous research indicates that group interac-\ntion interferes with the cognitive processes of idea generation (Diehl and\nindividual cognitive processes can interfere with interaction, hindering idea ela-\nboration and integration because members pay too little attention to one\nanother's ideas. Our study therefore calls for a shift in research attention from\nexamining the ways that groups stimulate divergent thinking to ways that\ngroup members become more deeply engaged with one another's ideas. For\nexample, relational cognitive processes through which members identify con-\nnections between ideas, such as counterfactual (e.g., Kray, Galinksy, and\nbe critical for these forms of idea generation. Alternatively, research may con-\nsider how the group environment can promote the help-giving behaviors\ninvolved in working on others' ideas, given that doing so may also harm one's\nown creativity (Mueller and Kamdar, 2011).\nThe situated cognition of group creativity. Our study advances theory by\nexpanding the social psychological view of creativity (e.g., Amabile, 1996;\nHennessey, 2003) to introduce the immediate group interaction as a variable\nthat affects group creativity. Those interactions are the point at which group\nmembers' cognitions (e.g., Paulus and Yang, 2000), dynamics (e.g., Hirst, van\nintersect to produce a momentary collective consensus about the value of an\n2006). This emphasizes that evaluations are temporary and evolve as ideas\ndevelop, rather than one-time decisions. We therefore focus on the process of\nevaluations rather than only the final set of ideas a group selects.\nOur approach also has implications for the collective creative process.\nPerhaps the most surprising of these is that group creativity is not always best\nserved by separating evaluation from idea generation (e.g., Osborn, 1953).\nAttempting to separate these activities limits the opportunity for groups to con-\nstruct the problem framework, retain novel ideas, and elaborate and integrate\nideas, while integrating them enables evaluation to enhance generation. This\nnovel view of the group's creative process integrates insights from individual\n2002) creativity. It implies greater variety in the process than has been explicitly\nidentified in group creativity research to date. Modes of interaction provide the\nbuilding blocks for this variety (e.g., Pentland, 1994). In our model, evaluations\nare influenced by both the immediate group interaction and its situation in the\nbroader process. Therefore changing the sequence of modes also produces dif-\nferent momentary experiences and judgments of ideas. Future research may\nconsider the performance of the creative process as a source of variety.\nTransitions between modes may be critical because they shape this perfor-\nmance. For example, the transition from comparing ideas to reconsidering eva-\nluation criteria may be a critical juncture at which the group members begin to\nintegrate their perspectives (e.g., Okhuysen and Eisenhardt, 2002).\nAlternatively, shifting frequently between modes may help groups remain open\nto novel ideas by delaying final decisions, while still engaging in evaluation.\nFuture research may also ask how shifts between modes occur. Our findings\nsuggest that meetings may be transition points. Alternatively, leaders may\ndirect shifts, or shifts may follow exceptionally positive or negative interactions.\nVarying meeting length or frequency or rotating leadership may produce novel\noutcomes by changing the creative performance.\nResearch should also explore the contingencies under which those alterna-\ntive processes facilitate or inhibit creativity. For example, because an advantage\nof the evaluation-centered process is the opportunity to construct a problem\nframework based on members' diverse perspectives, groups may be most\nlikely to benefit from it when they face complex, open problems (e.g.,\nUnsworth, 2001) and when members of the group have diverse perspectives\nto integrate. Processes may therefore be differently suited to particular creative\ntasks or contexts.\nThe collective nature of creativity. Taken together, our insights reveal a\nfundamentally new way to understand the collective nature of creativity.\nWhereas previous research has considered the group as a context for individual\ncreativity that results in collective output when individual contributions are\naggregated (Sacramento, Dawson, and West, 2008), we argue that evaluation\nis the point at which the process becomes collective (Collins, 2005). Evaluation\nis therefore central to collective engagement in the creative process.\nEvaluating ideas early and throughout the process is not only an alternative path\nto creativity, but a different kind of collective process through which individual\nideas are transformed into collective products.\nWe began this research with the question of how groups overcome the chal-\nlenges of transforming members' inputs into collective creative products. Our\nsurprising answer is that evaluation can facilitate rather than hinder this pro-\ncess. Creative groups like the jazz ensembles, music producers, and product\ndesigners studied by organizational scholars may be creative not because their\nmembers stimulate divergent new ideas, but because they excel at allowing\nevaluation to guide the creative process.\n"
}