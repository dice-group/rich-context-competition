{
    "abstract": "School of Public Health and Institute of Gerontology, University of Michigan,Ann Arbor.",
    "reduced_content": "School of Public Health and Institute of Gerontology, University of Michigan,Ann Arbor.\nObjective. The purpose of this study is to describe the development and implementation of a nine-step strategy for\ndevising closed-ended survey questions that assess religion in late life. The intent was to illustrate one way in which\nqualitative and quantitative methods could be combined in the same study.\nMethods. The following methods and procedures were developed to create closed-ended questions: Focus groups,\nin-depth interviews, input from ongoing quantitative studies, input from an expert panel, cognitive interviews, a quantitative\npretest, a nationwide random probability sample of elderly people, and rigorous empirical psychometric testing. Three hun-\ndred ninety-nine older people took part in the first seven steps, and 1,500 elders participated in the nationwide survey.\nResults. Approximately 175 closed-ended survey items were developed assessing 14 different major dimensions\nof religion. In the process, practical solutions to a number of problems encountered in implementing the nine-step\nstrategy are discussed.\nDiscussion. The item development strategy may serve as a template that can be used to improve the quality of\nclosed-ended survey items that assess a wide range of topics in social gerontology.\ngrowing number of investigators are calling for studies\nthat combine qualitative and quantitative research meth-\nods (Morgan, 1998). This promising strategy is consistent with\nthe principle of triangulation, in which the combined strengths\nof two or more methods are used to produce more valid re-\nsults than would be obtained by using the same methods in\nout, there are a number of ways to combine qualitative and\nquantitative methods in the same study. In fact, he proposes\nfour broad approaches for configuring the interface between\nthese methodologies. One is especially important for the\npurposes of the present study. In particular, Morgan (1998)\nargues that the insights provided by qualitative methods,\nsuch as focus groups, may be useful for crafting high-quality,\nclosed-ended survey questions.\nUnfortunately, researchers often encounter two problems\nwhen they try to use both qualitative and quantitative meth-\nods for this purpose. First, even though many investigators\ncall for the use of qualitative methods to develop quantita-\ntive survey items, relatively few show precisely how this\nmay be accomplished. Instead, most researchers merely\nstate they have used some qualitative procedure, such as fo-\ncus groups, to draft closed-ended survey items, but they do\nnot fully describe the steps that were followed (see Fultz &\nHerzog, 1993, for a notable exception). Second, a number of\ndifferent qualitative methods are available, including focus\ngroups, in-depth interviews, and participant observation studies.\nEach of these procedures has its own unique strengths and\nweaknesses. Consistent with the principle of triangulation,\nit would, therefore, appear that a well-developed item devel-\nopment strategy should include more than one qualitative\nmethod. However, no one in social gerontology has discussed\nhow this should be done.\nThe purpose of the present study is to address these gaps\nin the literature by providing a comprehensive strategy for\ncombining multiple qualitative methods to develop closed-\nended survey items. This strategy begins with focus groups\nand culminates in the quantitative analysis of closed-ended\nsurvey items that were administered to a nationwide sample\nof older people. Throughout, an emphasis is placed on pro-\nviding practical, hands-on advice for bridging the two meth-\nodological approaches.\nThree points should be kept in mind as this item develop-\nment strategy is reviewed. First, qualitative methods are used\nin this study to enhance the effectiveness of quantitative sur-\nvey questions. This may create the mistaken impression that\nqualitative methods occupy a secondary position in the re-\nsearch enterprise, and that their sole purpose is to provide raw\ngrist for quantitative work. Nothing could be further from the\ntruth. Instead, it should be emphasized that qualitative meth-\nods are important in their own right. In fact, Morgan (1998)\ndiscusses how quantitative methods can be used to enrich\nfindings from studies that have a primary qualitative focus.\nSecond, the research described later was designed to develop\nsurvey items to assess religion in late life. Even so, these\nprocedures can be readily adapted to virtually any substan-\ntive domain. Finally, a number of the methodologies that\nfollow have already appeared in the literature (e.g., focus groups\nand in-depth interviews). However, no one has pulled them\ntogether to form a single comprehensive strategy for devel-\noping better closed-ended survey items.\nThe discussion that follows is divided into four main\nA\nsections. First, the benefits of combining qualitative and\nquantitative methods to develop closed-ended survey items\nare explored in greater detail. Second, as noted previously,\nthe substantive goal of the present study was to develop a\ncomprehensive battery of items to measure religion in late\nlife. To provide a better context for understanding how these\nmeasures were devised, problems and issues in the assess-\nment of religion are discussed briefly. Methodological issues\nthat cut across all nine steps in the proposed item development\nstrategy are discussed at this juncture as well. Third, the\nnine-step item development strategy is presented in detail.\nFourth, limitations and unresolved issues in the implemen-\ntation of the proposed strategy are discussed.\nBenefits of Combining Qualitative and\nQuantitative Methods\nThe advantages of using qualitative and quantitative meth-\nods in the same study are best presented by briefly reviewing\nhow researchers typically select or develop closed-ended\nsurvey items. One frequently used approach is to simply take\nscales or items that are available in the literature. Although\nthis is certainly a reasonable strategy, it is often done with-\nout checking to see if the items were developed specifically\nfor older people. Research on social desirability provides a\ngood example of what may happen under these circumstances.\nSurvey researchers often ask questions about sensitive is-\nsues, such as the excessive use of alcohol or sexual difficulties.\nSome investigators are concerned that instead of answering\nthese questions honestly, study participants may respond in\na socially appropriate manner (DeMaio, 1984). In an effort to\ndeal with this problem, scales have been devised to identify\nthose who are likely to give socially desirable responses.\nPerhaps the most widely used measure is the Marlowe-Crowne\nSocial Desirability Scale (Crowne & Marlowe, 1964). This\nmeasure has been used in a number of studies with older\nadults (see, e.g., Kozma & Stones, 1987), yet a careful review\nof the history of this scale reveals that it was developed pri-\nmarily with undergraduate students. As a result, this mea-\nsure contains a number of items that do not seem appropri-\nate for elderly populations (e.g., \"If I could get into a movie\nwithout paying and be sure I was not seen, I would probably\nAnother common strategy for developing quantitative ques-\ntionnaires involves writing survey items from scratch with\ninput from colleagues working in the field. A more sophisti-\ncated variant of this approach involves convening a panel of\nexperts (Fetzer Institute & the National Institute on Aging,\n1999). Here, the group of experts is charged with identify-\ning the key dimensions of a conceptual domain and devising\ngood survey measures of them. Unfortunately, researchers\nwho rely on expert panels rarely take steps to verify that all\nkey dimensions of a conceptual domain have been identi-\nfied, or that the dimensions that have been specified by the\nexperts are valid. Instead, the basis of this strategy rests largely\non consensus. The problem with relying on consensus is cap-\ntured succinctly in Faust and Minor's (1986) critique of the\nDSM-III (Diagnostic and Statistical Manual of Mental Dis-\norders, ed. III; American Psychiatric Association, 1980). The\npurpose of the DSM-III was to devise a comprehensive\nscheme to identify, categorize, and describe the different types\nof clinical mental disorder. This was accomplished, in part, by\nturning to panels of experts. But as Faust and Minor (1986)\npoint out, expert consensus is not necessarily valid: there was a\ntime in history when most experts believed the world was flat.\nDespite the criticisms of Faust and Minor (1986), care\nmust be taken not to disparage the use of expert panels. In\nfact, this valuable procedure is incorporated in the item\ndevelopment strategy discussed later in this article. In-\nstead, the key issue is that problems may arise when expert\npanels become the sole means of developing closed-ended\nsurvey items.\nProponents of the two item development strategies dis-\ncussed previously might argue that problems in their work\nmay be detected and resolved through careful pretesting. This\nmay be true, but pilot tests are typically not conducted in a\nrigorous way. Instead, a draft of the closed-ended question-\nnaire is typically administered to between 25 and 75 respon-\ndents (Oksenberg, Cannell, & Kalton, 1991). The questionnaire\nis administered by interviewers who are instructed to look\nout for two types of problems. First, they are told to flag any\ndifficulties study participants have in answering the questions.\nSecond, the interviewers are instructed to report any prob-\nlems they encounter in administering the interview schedule\n(e.g., problems following skip-patterns). Once the pilot inter-\nviews have been conducted, a debriefing session is held by a\nfield manager, who systematically works through each question\nin an effort to see if any of the survey items are not working\nwell. Unfortunately, as Oksenberg and her colleagues point\nout, this strategy is not entirely satisfactory because it relies\non a respondent's ability to express a problem and the inter-\nviewer's ability to detect that one is present (Oksenberg et\nal., 1991). Moreover, it is not clear what to do when inter-\nviewers disagree in debriefing sessions about the presence\nor the nature of a problem. Finally, standard pretesting pro-\ncedures may flag items that are in need of revision, but this\nstrategy often provides little information about how to fix\nthese problems.\nIt is precisely for these reasons that qualitative studies\nmay be especially useful for developing closed-ended sur-\nvey items. By allowing people to talk freely without impos-\ning a researcher's prior assumptions on the study, qualitative\nmethods provide an excellent opportunity for getting direct\naccess to a substantive domain, such as religion. Listening\nwhile older adults share their experiences and feelings about\nreligion gives researchers an improved understanding of this\nconstruct from the participants' perspective. As a result, in-\nvestigators are in a better position to uncover broad themes\nand content areas that more accurately reflect the ways that\nelders themselves think about and practice religion in\ndaily life, thereby making it possible to identify key di-\nmensions of a phenomenon that have not appeared previously\nin the literature.\nAnother major advantage of qualitative methods is that\nthey allow investigators to capture the words and phrases\nthat older adults use when talking about things like religion.\nThese words and phrases provide excellent raw grist for writ-\ning closed-ended question stems. As a result, researchers\nmay enhance the relevance and comprehension of the quan-\ntitative survey measures they devise, thereby improving the\nvalidity of study findings.\nIssues in the Measurement of Religion in Late Life\nA compelling number of studies indicate that older adults\nwho are religious may enjoy greater health and well-being\nthan elderly people who are less involved in religion (see\nKoenig, McCullough, & Larson, 2001, for a comprehensive\nreview of this literature). Unfortunately, there are at least\ntwo problems with this research. First, as Ellison and Levin\n(1998) point out, many investigators use relatively crude\nmeasures to assess religion. In particular, religious prefer-\nence or the frequency of church attendance are often used\nas the sole indicators of religion. Although some investiga-\ntors have examined other facets of religion, such as religious\nsupport (Krause, Ellison, & Wulff, 1998) or religious coping\n(Pargament, 1997), relatively few efforts have been made to\nsystematically stake out the entire content domain of this\nelusive construct (for a notable exception, see the work of the\nFetzer Institute & the National Institute on Aging, 1999).\nThe second problem with research on religion and health\nin late life arises from the fact that the wide majority of religion\nmeasures have been developed solely with younger people.\nThis is problematic because a number of researchers argue\nthat the nature and meaning of religion may change as\npeople grow older (Koenig, 1994). But even when measures\nhave been developed specifically for older adults, they may\nnot be appropriate for all elderly people. More specifically,\nthere is growing evidence of significant differences in the\nway that older White persons and elderly Black persons\nview and practice religion (Chatters, 2000).Yet, there do not\nappear to be any studies that have systematically developed\nmeasures of religion that are appropriate for older people in\nboth racial or ethnic groups.\nThe present study was designed to meet these problems\nhead-on by developing a comprehensive battery of items to\nmeasure religion in late life that would be appropriate for\nuse with both Black and White respondents. In the process\nof conducting this research, a number of critical decisions\nhad to be made to make the scope of this task more manage-\nable and to ensure that the data adequately capture the views\nof the typically older person. This was accomplished by\ncarefully specifying the exclusion criteria and developing a\nsound plan for sampling study participants.\nThree exclusion criteria were used in this research. First,\nthe study was restricted to individuals who were currently\npracticing Christians, were Christians in the past but no longer\npractice any religion, or people who were not involved with\nany faith at any point in their lifetime. However, since 90%\nof older adults in the United States currently affiliate with\nthe Christian faith, the measures should be useful for study-\ning the wide majority of elderly people (Princeton Religion\nResearch Center, 1994). Second, potential study participants\nwere screened to see if they were either members of the\nclergy or if they resided with someone who was a member\nof the clergy. Those who were ministers or people who lived\nwith a member of the clergy were excluded from the study\nfor the following reasons. Views on the meaning, nature,\nand practice of religion among clergy are likely to differ\nfrom those of the average lay person because of the exten-\nsive formal training pastors receive in seminary school. In\naddition, individuals who live with a member of the clergy\nwere excluded because they often play a role in the church\nthat differs significantly from that of the typical rank-and-\nfile church member (e.g., the minister's wife). Finally, the third\nexclusion criterion had to do with religious involvement. In\nparticular, potential study subjects were asked the following\nquestion: \"How important is religious faith in your life?\nWould you say it is very important, somewhat important, a\nlittle important, or not at all important?\" Individuals were\nexcluded from the initial steps of the study if they indicated\nthat religion was not at all important to them. This was done\nbecause it did not make sense to ask people who are not at\nall religious to discuss how they practice religion in their\ndaily lives. Excluding those who are not religious is not\nlikely to be a major problem because research indicates that\nonly about 8% of older adults say that religion is not very\nimportant to them (Gallup, 1999). Even so, it should be em-\nphasized that once a preliminary set of closed-ended items\nwas developed, all study measures were carefully tested with\nall older subjects, regardless of how religious they may be.\nOnce the exclusion criteria were specified, a decision had\nto be made about how to select eligible participants for the\nqualitative components of the study. There is a fairly large\nliterature on qualitative sampling methods (see, e.g., Lubor-\nsky & Rubinstein, 1995), but this is not the place to discuss\nthe relative strengths of qualitative and quantitative sam-\npling procedures. Instead, it makes more sense at this point\nto review the reasons why quantitative, random-probability\nsampling procedures were used in this study. Even though\nthis study was restricted to older Christians, there is tremen-\ndous diversity within the Christian faith. In addition to the\nobvious differences between Protestants and Catholics, there\nis considerable variation in the way that Protestants practice\ntheir faith. The fact that the General Social Survey codes re-\nligious preference into more than 20 different Protestant\nchurches or denominations provides ample evidence of this\n(see the following website for a detailed overview of the Gen-\neral Social Survey: http://www.icpsr.umich.edu/gss/). Initially,\nit might appear that selecting potential respondents from\ndifferent Protestant churches would be a good sampling\nstrategy. However, this is not a viable option because find-\nings from the nationwide survey conducted for the present\nstudy reveal that approximately 24% of eligible study par-\nticipants either do not go to church at all, or attend church\nonly once or twice a year. Subsequent analyses revealed that\nsome were unable to do so because they were either too ill\nto go to church, or because they were caring for someone\nwho was sick.\nGiven these constraints, a decision was made to use\nrandom-probability sampling procedures. The study popula-\ntion was defined as all individuals who are noninstitutional-\nized, English-speaking, and at least 65 years of age and older.\nGeographically, the study population was restricted to all eli-\ngible persons who reside in Washtenaw County, MI. The\nsampling frame consisted of all eligible individuals who\nwere contained in the Health Care Financing Administration\n(HCFA) Medicare Beneficiary Eligibility List (HCFA is\nnow called the Centers for Medicare and Medicaid Ser-\nvices). This list contains the name, address, sex, and race of\nvirtually every older person in Washtenaw County. It should\nbe emphasized that people are included in this list even though\nthey are not currently receiving Social Security benefits.\nHowever, some older adults are not covered in this database\nbecause they do not have a Social Security number (this\nmay be caused by factors such as illegal immigration).\nThe names of potential study participants were selected\nfrom the HCFA list with a simple random sampling proce-\ndure. Then, sampled individuals were sent a letter informing\nthem about the nature of the study, and indicating that a\nmember of the research team would be calling them shortly.\nThe purpose of the telephone call was to briefly screen sam-\npled individuals to see if they met the eligibility criteria\ndiscussed previously. In general, phone numbers for study\nparticipants were found by checking the local telephone di-\nrectories. However, some telephone numbers were more dif-\nficult to locate. Although precise counts were not kept, it\nseemed that telephone numbers were more difficult to obtain\nfor older Black persons than older White persons. This prob-\nlem was handled by turning to the recent addition of the R. L.\nPolk City Directory for the catchment area covered by our\nstudy. This book contains the results of a survey conducted\nby the Polk Corporation to obtain information (including\nphone numbers) for every individual residing in a given\ngeographical area.\nMETHODS\nThe nine-step strategy for developing closed-ended sur-\nvey items that was developed for this study is presented in\nTable 1. The steps in this table are presented in the order\nin which they were executed. In the discussion provided, the\nprocedures that were followed in implementing each step\nare described in detail. In addition, where it is appropriate,\nsubstantive findings are presented to illustrate precisely how\nthe procedures were implemented.\nFocus Groups\nAll together, 8 focus groups were conducted with a total\nof 63 older adults. Thirty-one were older African Americans\nand 32 were elderly White adults. The groups were run in\nfour pairs--one consisting solely of older White adults and\none made up entirely of elderly Blacks adults. New subjects\nwere recruited for each round of focus groups. Focus group\nmoderators were matched to the race of the study partici-\npants. All subjects were paid $25 for participating in this\nstudy (subject remuneration was used in all phases of data\ncollection in this study). David Morgan, an expert on focus\ngroups (Morgan & Krueger, 1998), came to Ann Arbor to train\nthe moderators and to help run the first round of focus groups.\nThe focus groups were conducted in a local hotel. All fo-\ncus groups were tape recorded and transcribed. In reviewing\nfocus group transcripts, it is often useful to know the iden-\ntity of the speaker because this information enables re-\nsearchers to get a better sense of important issues like how\nwidely opinions are shared in the group. Unfortunately, when\nlistening to tapes of a focus group that consists of six or\neight people, it is often difficult to know who is speaking. To\nattribute responses to specific people, a court stenographer\nwas hired to transcribe all focus group sessions. Because\ncourt stenographers are trained to produce virtually flawless\ntranscripts, the risk of encountering transcription errors was\nreduced significantly. Initially, it may appear that study sub-\njects would be bothered or inhibited by the presence of a\nstenographer in the focus group sessions. There are two rea-\nsons why this was not a problem in the present study. First,\nfield notes taken during the course of the focus groups re-\nvealed that study participants paid little attention to the ste-\nnographer and rarely even looked at this individual during\nthe sessions. Second, at the end of the focus groups, study\nparticipants were asked if they were bothered in any way by\nthe presence of the court recorder. Without exception, they\nindicated this was not the case, and some even made jokes\nabout it.\nTwo key concepts guided the flow of focus group discus-\nsions: The funnel approach (Morgan, 1988) and the satura-\ntion point (Glaser & Strauss, 1967). Because the focus groups\nwere conducted sequentially over time, a funnel approach\nwas used to devise the moderator's guide. For those unfamil-\niar with focus groups, the moderator's guide contains a list\nof topics or questions that are used to stimulate focus group\ndiscussions. The first round of focus groups began with very\ngeneral questions that were designed to throw as broad a net\nas possible, thereby ensuring that the views of the research\nteam were not imposed on the group discussions (e.g.,\n\"What is the most important part of living a religious life?\").\nInitially, the members of the research team read the tran-\nscripts from the first round of focus groups on their own. Then,\nthe team met as a group to reach a consensus about what had\nbeen said. This information was subsequently used to draft a\nseries of more specific questions for the next round of focus\ngroups. So, for example, more targeted questions were\nasked about church-based social support (\"Some people say\nthat the help and guidance they get from people at church is\nimportant. What do you think? What are some of the ways\npeople in your church may help each other?\").\nTwo important points must be made about the funnel ap-\nproach. First, consistent with the basic tenets of qualitative\ninterviewing (Madill, Jordan, & Shirley, 2000), this strategy\nhelps ensure that the substantive content of the focus group\nquestions, and the way they are phrased, are determined by\nthe subjects. Second, because data from earlier rounds of fo-\ncus groups were used to devise questions for later rounds of\nfocus groups, the content of the moderator's guide changed\nseveral times during this phase of the study (see May\n1991, for a more detailed discussion of this data collec-\ntion strategy).\nConcerns may arise over the use of the funnel approach\nbecause it may seem as though the use of more focused ques-\ntions would prohibit those who participate in later rounds of\nfocus groups from expressing their own views. This poten-\ntial problem was addressed in the following manner. Even in\nTable 1. Steps for Developing Closed-Ended Survey Questions\n1. Focus groups\n2. In-depth interviews\n3. Input from quantitative studies\n4. Developing preliminary quantitative measures\n5. Review by expert panel\n6. Cognitive interviews\n7. Pilot study\n8. Nationwide survey\n9. Psychometric testing\nlater rounds of focus groups, the moderator always began\nwith general questions about religion, and only asked more\nfocused questions after study participants had sufficient\ntime to respond to the more general questions. In this way,\nthe general questions provided a way to continually bring\nnew information on religion to the foreground.\nIn the process of conducting qualitative research, investi-\ngators often reach the point where respondents in later rounds\nof focus groups begin to discuss the same issues that emerged\nin earlier rounds of focus groups. This is called the satura-\ntion point (Glaser & Strauss, 1967). If the goal of a study is\nto flush out the content domain of a construct, gathering re-\ndundant information is not useful. Therefore, once the satu-\nration point is reached, the moderator's guide is changed so\nthat time spent with study subjects can be devoted to uncov-\nering new information.\nThe focus group data were evaluated using a two-level\nqualitative data inventory. The first level, which is part of the\nfunnel approach discussed previously, consisted of a more\ngeneral assessment of the findings. Here, the intent was to\nsort the data into relatively crude large-level categories that\ncould be used to identify themes to pursue in later rounds of\nfocus groups (Brenner, 1985). Consequently, this first-level\nassessment of the data was an ongoing process that unfolded\nover the course of all eight focus groups. The second level\nof analysis began once the focus groups were complete.\nHere, members of the research team reviewed the transcripts\nand independently developed a more detailed coding scheme\n(Mishler, 1986). Following this, team members met as a\ngroup, discussed their coding schemes, and arrived at a con-\nsensus on how best to present the data.\nThe focus groups provided a wealth of information about\nreligion in late life. Two papers were written to explore se-\nlect areas in detail: One examined negative interaction in the\nchurch (Krause, Morgan, Chatters, & Meltzer, 2000a), whereas\nthe other dealt with prayer (Krause, Morgan, Chatters, &\nMeltzer, 2000b). The findings on prayer will be reviewed\nbriefly to highlight the rich insights that emerged from this\nphase of the item development strategy.\nMost research on prayer focuses on how often people\npray and the types of prayers they offer (e.g., prayers of thanks-\ngiving or petitionary prayers requesting specific outcomes;\nPoloma & Gallup, 1991). However, it became apparent over\nthe course of the focus groups that study participants had a\ngood deal to say about whether prayers are answered, and if\nthey are, how answers are provided. So, for example, some\nfelt that prayers are answered right away, whereas others be-\nlieve that God answers prayers whenever He is ready. More-\nover, some felt they got exactly what they asked for in a\nprayer. In contrast, others indicated they did not always get\nwhat they asked for. However, when these individuals took\nthe time to think about it, they found the answer they got\nwas precisely what they needed most.\nThis information provides a host of new ways to think\nabout the relationship between prayer and health in late life.\nFor example, older people who expect immediate answers\nto prayers may become disillusioned, and lose hope, if the\nanticipated answer is not forthcoming. As research indi-\ncates, the loss of hope may be an important risk factor for\nsome health problems (Nunn, 1996). To empirically evalu-\nate this issue, closed-ended questions were crafted in later\nphases of this study to assess beliefs about the timing of an-\nswers to prayers.\nA major advantage of using focus groups arises from the\nfact that it is possible to observe and record how older\npeople talk to each other when they discuss important topics\nlike religion. The words and phrases they use provide excel-\nlent raw grist for writing closed-ended question stems.\nThere are, however, several disadvantages in using focus\ngroups. First, respondent burden is heavy because subjects\nmust leave their homes and come to a common location,\nsuch as a meeting room in a local hotel. Unfortunately, this\nmakes it difficult for elderly people to attend focus groups if\nthey do not have adequate transportation, or if they are physi-\ncally challenged. Transportation problems may be dealt with\nby providing cab rides for those who need them, but little\ncan be done to improve attendance rates among older adults\nwith physical health problems.\nThe second disadvantage in using focus groups is dis-\ncussed by Knodel (1995). He argues that the presence of\nothers in the focus group may make it difficult to disclose\ninformation of a personal nature. Because some older people\nmay consider their religious beliefs and practices to be a pri-\nvate matter, they may feel uncomfortable expressing their\nviews and feelings in a focus group setting. In view of these\nlimitations, and consistent with the principle of triangula-\ntion, the next step in the item development strategy involved\nconducting a series of one-on-one, in-depth interviews.\nIn-Depth Interviews\nThe individual in-depth interviews were conducted face-\nto-face with study participants in their homes. All interview-\ners were race-matched with respondents. A new set of subjects\nwas recruited for the in-depth interviews from the HCFA list.\nOnce again, the names of potential respondents were se-\nlected using simple random sampling procedures. A total of\n131 in-depth interviews were completed successfully. Approx-\nimately 61% of these individuals were older White adults,\nand 39% were elderly African American adults. All inter-\nviews were tape-recorded. The interviews typically lasted\nThe number of in-depth interviews conducted for this\nstudy is unusually large (N  131). In fact, some investiga-\ntors suggest that as few as eight are sufficient to cover a new\ndomain (McCracken, 1988). However, the members of the\nresearch team believed it was important to interview a large\nnumber of older people because the content domain of reli-\ngion is so vast. This decision was ultimately supported by\nthe wealth of data that was obtained during this phase of\nthe study.\nThroughout, the funnel approach and the saturation point\nconcepts guided the flow of the in-depth interviews. As a re-\nsult, the content of the questionnaire changed a number of\ntimes as the in-depth interviews were being conducted. It is\nimportant to emphasize two points about the way in which\nthe funnel approach was implemented. First, following the\nprocedures used in the focus groups, all in-depth interviews\nbegan with general, open-ended questions about religion\nand concluded with questions about more focused aspects of\nreligion. Second, in-depth interview questions about more\nspecific aspects of religion were written with input from the\nfocus group data. This means that the use of the funnel tech-\nnique was extended in this study by carrying insights across\ntwo different qualitative methodologies.\nDuring the course of developing the in-depth interview\nquestionnaires, a procedure was implemented that departs\nsignificantly from the traditional qualitative approach. As\nnoted earlier when discussing the funnel approach, focused\nprobe questions are typically developed based solely on the\ninput provided by study subjects. However, in the process of\nwriting the in-depth interview questionnaire, information\nfrom other sources was taken into consideration. Shortly be-\nfore the in-depth interviews began, the John Templeton Foun-\ndation issued a request for proposals on forgiveness. This\ninitiative was developed in response to a burgeoning litera-\nture, which suggests that forgiveness may be an important\nfactor in promoting health and well-being (McCullough,\nPargament, & Thoresen, 2000). However, the focus group\nparticipants in the present study had very little to say about\nforgiveness. Even so, the research team decided that since\nthe goal of the project was to develop a comprehensive set\nof religion measures, it would not be advisable to overlook\nthis potentially important construct. This decision raises a\nbroader question about how to obtain complete coverage of\na conceptual domain that has been the subject of empirical\nand theoretical investigation for some time. For more than\n100 years, scholars have been studying religion in an effort\nliterature contains many valuable theoretical insights and\nimportant empirical findings (Koenig et al., 2001). We felt it\ndid not make sense to completely disregard this work. Instead,\na more profitable approach to designing in-depth interviews\ninvolves finding a way to exploit existing material without\ncompromising the inherent advantages associated with this\nimportant qualitative methodology.\nWith this objective in mind, a series of open-ended probe\nquestions on forgiveness were placed at the end of the in-depth\ninterviews. This ensures that the questions on forgiveness\ndid not unduly influence or bias responses to the earlier, more\ntraditional, qualitative probe questions because respondents\nwere given ample time to express their own views before they\nwere presented with questions based on external material.\nViewed more generally, this strategy provides a unique way\nto more tightly integrate qualitative methods and quantita-\ntive research findings in the interests of developing the best\nclosed-ended survey items.\nAs the in-depth interviews progressed, it quickly became\nevident that the questions on forgiveness evoked the most\nemotionally charged response that was encountered during\nthe entire study. This was especially true of questions about\nself-forgiveness. Although data are not available to explain\nwhy forgiveness did not arise spontaneously in the focus\ngroups, perhaps the highly personal nature of this topic ini-\ntially inhibited discussion.\nBecause so many in-depth interviews were conducted (N \n131), the author was the only person to listen to all the tapes.\nDifferent members of the research team reviewed segments\nof the taped interviews dealing with specific topics, such as\nforgiveness. After these individuals independently coded the\nthemes that emerged from the data, they met with the author\nto discuss their findings and arrive at a consensus on the best\nway to code the data.\nThe in-depth interviews provided rich insights into how\nolder adults practice religion in their daily lives. The quality\nof these data may be illustrated by briefly reviewing some of\nthe results on forgiveness. More detailed findings on for-\ngiveness appear in a paper that was written with these data\n(Krause & Ingersoll-Dayton, 2001). As the in-depth inter-\nviews progressed, it quickly became evident that respondents\nheld quite different views about forgiving other people. Al-\nthough some felt it was their duty as Christians to forgive\nothers automatically, and not require transgressors to do\nanything first, other study participants believed that trans-\ngressors must earn their forgiveness. In particular, this latter\ngroup of subjects felt that transgressors must take one or\nmore of the following steps to be forgiven: (1) transgressors\nmust be aware of what they have done; (2) explicitly ask for\nforgiveness; (3) offer an explanation for the hurtful act; (4)\nmake a resolution not to repeat the offense again; (5) follow-\nup on this resolution by changing their behavior; and (6) make\namends (i.e., provide restitution). These insights set up a se-\nries of intriguing questions about the nature of the relation-\nship between forgiveness and health. First, regardless of how\nit is attained, is forgiveness related to health? Second, does\nforgiving others without requiring them to do anything first\nprovide the greatest health benefits, or is requiring trans-\ngressors to earn forgiveness more beneficial in this respect?\nFinally, if forgiveness must be earned, do potential health-\nrelated benefits increase as transgressors perform progres-\nsively more of the steps outlined previously?\nIn retrospect, it appears as though more valuable data\nwere obtained from the in-depth interviews than from the\nfocus groups. Although it is difficult to support this impres-\nsion with hard data, study subjects may have provided better\ninformation because they felt more comfortable discussing\nsensitive religious issues in the privacy of the individual in-\ndepth interview (Knodel, 1995). Also, as noted previously,\nbecause the in-depth interviews were conducted in the homes\nof study participants, this methodology made it possible to\nreach a wider group of older people, including those who\nwere homebound.\nInput from Quantitative Studies\nThe next step in the item development strategy also de-\nparts from traditional qualitative procedures. This phase of\nthe study emerged serendipitously. As the focus group and\nin-depth interviews were being conducted, an opportunity\narose to insert closed-ended quantitative questions on religion\nin a nationwide survey of people affiliated with the Presby-\nterian Church (USA). Data from the focus groups and in-\ndepth interviews revealed that many older study participants\nvalued church-based social support highly. Although rela-\ntively little space was available in the questionnaire for the\nPresbyterian study, seven closed-ended items were crafted\nfrom the qualitative data to assess three aspects of church-\nbased support: Emotional support from rank-and-file church\nmembers, emotional support from the pastor, and spiritual sup-\nport from church members. Spiritual support involves things\nlike sharing religious experiences and helping others live ac-\ncording to their religious beliefs. Data from the nationwide\nPresbyterian survey provided an excellent opportunity to\ngain a preliminary sense of the quality of the newly devel-\noped items. In particular, a series of analyses were per-\nformed ranging from an examination of simple frequency\ndistributions to the estimation of a sophisticated second-\norder confirmatory factor model. The results of these analyses\nappear in a paper by Krause, Ellison, Shaw, Marcum, and\nThe Presbyterian survey was useful for several reasons.\nFirst, the confirmatory factor model revealed that the newly\ndeveloped measures had good psychometric properties (i.e.,\ngood item and scale reliability).\nSecond, the Presbyterian study provided an opportunity\nto conduct a preliminary assessment of the construct valid-\nity of the newly devised, church-based support items. Con-\nstruct validity is assessed by seeing whether a new set of\nitems is related to an established outcome measure in a the-\noretically meaningful way. The Presbyterian survey also\ncontained a set of widely used indicators on religious cop-\ning responses that were developed by Pargament (1997).\nThese items assess specific ways that people use religion\nwhen they are confronted by stressful events. Based on the\npremise that the selection of religious coping responses are\nsocially determined, Krause and colleagues (2001) examined\nwhether the three dimensions of the church-based support\ndiscussed previously are related to religious coping. Data\nindicate that people are especially likely to use religious\ncoping responses when they receive spiritual support from\nchurch members. Even though emotional support from the\npastor was also associated with greater use of religious cop-\ning methods, the relationship was not as strong. In contrast,\nemotional support from church members had no effect on\nreligious coping.\nThird, findings from the empirical work with the Presby-\nterian data also provided valuable information on how to\nimplement the funnel approach in the in-depth interviews.\nAs discussed earlier, the funnel technique involves using\ndata from earlier rounds of in-depth interviews to develop\nmore focused questions for later rounds of in-depth inter-\nviews. The decision to devote scarce interview time to probe\nspecific areas in detail is based on the nature of the themes\nthat emerge from the initial in-depth interviews. However, if\nthe goal of a study is to ultimately develop closed-ended\nquantitative survey measures, then relatively unique criteria\nmust be used for identifying themes that should be probed\nmore deeply. In particular, an investigator must determine\nwhether different themes that emerge from the qualitative data\nwill lead to the development of different quantitative scales,\nor whether the themes assess content areas that are so\nclosely related that they can be more economically assessed\nwith a single scale. It is sometimes difficult to make this de-\ncision based on the qualitative data alone. This was true\nwith respect to the church-based social support measures\nidentified previously. In particular, it was hard to imagine\nhow rank-and-file church members could provide spiritual\nsupport to respondents without also giving them emotional\nsupport at the same time. However, the empirical analysis of\nthe Presbyterian data suggests that even though the two di-\nmensions of church-based support are correlated, spiritual\nsupport is related to religious coping, whereas emotional\nsupport from church members is not. This differential im-\npact suggests that the two dimensions of church-based sup-\nport are conceptually distinct and that it would be useful to\ncontinue to invest in-depth interview time in exploring them\nboth. Viewed from this perspective, the analysis of the Pres-\nbyterian data provides a relatively unique way of showing\nhow both qualitative and quantitative methods can be used\nsimultaneously to develop closed-ended survey items.\nDeveloping Preliminary Quantitative Measures\nOnce the in-depth interviews were complete, a set of\nclosed-ended survey questions was developed. These ques-\ntions came from three sources. First, some questions were\ntaken from existing scales (e.g., measures of religious com-\nmitment, as well as some religious coping items). Second,\nmeasures devised by other investigators were modified on\nthe basis of information gleaned from the focus groups and\nin-depth interviews (e.g., some indicators of emotional sup-\nport from church members). Finally, because good measures\ncould rarely be found in the literature, the bulk of the items\nwere developed from scratch.\nIt is important to provide more detail on how new survey\nitems were written when good indicators could not be found\nelsewhere. Two issues figured prominently in this process.\nThe first involved creating a list of all facets of religion that\nemerged from the focus groups and in-depth interviews. The\ntwo-level qualitative inventory discussed earlier was invalu-\nable in this respect.\nThe second key issue involved confronting the problem of\ndepth versus breadth. Data obtained in the focus groups and\nin-depth interviews were incredibly rich, and the number of\nquestions that could be written from this material seemed\nalmost limitless. However, because the final step in the item\ndevelopment strategy consisted of a nationwide survey last-\ning 70 minutes, crucial decisions had to be made about how\nmany dimensions of religion to cover, and how many items\nto devise for each dimension. There does not appear to be\nmuch guidance in the literature on how to make these deci-\nsions. The following approach was used in this study.\nFirst, the members of the research team estimated the\ntotal number of questions that could be administered in a\n70-min interview. Second, in estimating the likely number of\nitems, team members had to take into account the fact that\nquestions would also be asked about health, psychological\nwell-being, and a number of factual matters, such as age,\neducation, and marital status. Once the amount of question-\nnaire space that could be used to measure all areas of reli-\ngion was established, the number of specific dimensions\nthat could be covered was estimated by turning to the work\nof Andrews (1984). His sophisticated latent variable model-\ning analyses reveal that the ideal length of a scale should be\nbetween two and four items. The upper limit of four items\nwas used in the present study. Although departures from the\ntarget of four indicators ultimately arose, this general guide-\nline was, nevertheless, useful. Finally, once an estimate was\nderived of the number of dimensions of religion that could\nbe covered, difficult decisions had to be made about what to\ninclude. This was clearly the most challenging part of this\nstudy phase. Because the ultimate goal of this study was to ex-\namine the relationship between religion and health, decisions\nwere based, in part, on whether a particular dimension of re-\nligion is likely to affect the health of older people. Dimen-\nsions of religion that might be related to health were identi-\nfied by turning to the literature, as well as insights gleaned\nfrom the focus groups and in-depth interviews.\nPanel of Experts\nSeven scholars with outstanding reputations in the area of\nreligion graciously agreed to review the items that were de-\nveloped for this study. The following researchers were\nmembers of this group: Linda Chatters, Christopher G. Ellison,\nEllen Idler, Harold G. Koenig, Jeffrey S. Levin, Kenneth I.\nPargament, and Robert Taylor. It should be emphasized at\nthe outset that even though these individuals provided in-\nvaluable input, the author is solely responsible for any prob-\nlems with the closed-ended survey items that were devel-\noped in this study. Although expert panels have been used to\ndevelop items in other studies, a protocol for fully exploit-\ning the expertise of these individuals is difficult to find in\nthe literature. The following procedures were developed\nespecially for this study.\nFirst, a complete draft of all the religion items was sent to\neach of the experts. They were instructed to rate each indi-\ncator on a scale that ranged from 1 to 5, where 5 meant the\nquestion stem and the item response categories were of high\nquality, and a score of 1 denoted items that were most in\nneed of revision. These data were mailed back to the study\nfield office where frequency distributions of the ratings for\neach question were tabulated.\nFollowing this, the experts were all flown to Ann Arbor\nfor an intensive 2-day review of the study measures. The rat-\nings provided before the meeting were used to structure the\ndiscussions. In particular, the meeting began by focusing on\nitems with the least favorable ratings. The problems with\neach measure were identified, discussed, and potential solu-\ntions were proposed. The 2-day session with the experts was\ntape-recorded and transcribed.\nAn example may help illustrate how the expertise of the\npanel members was put to good use. Recent research suggests\nthat, as people grow older, they turn control over specific\ndomains in their lives to trusted others (Schulz & Heck-\nhausen, 1996). For example, some older people turn over the\nmanagement of their financial affairs to a grown offspring.\nDuring the course of the focus groups and in-depth inter-\nviews, the subjects in our study indicated they turn control\nover to God as well. A series of preliminary items were de-\nvised to capture this domain. Initially, these items focused\non turning things over completely to God, but the group of\nexperts recommended that a second approach should also be\nconsidered. In particular, they argued that people may only\npartially rely on God while continuing to exercise control\nthemselves. Items were, therefore, developed to capture this\nform of collaborative control with God. Following this two-\npart strategy makes it possible to see if complete control by\nGod, or collaborative control with God, is most likely to\nenhance the health and well-being of older people.\nIn addition to reviewing question stems and response for-\nmats, the expertise of the group was also used to help deter-\nmine the order of the closed-ended questions in the interview\nschedule. Toward the end of the 2-day meeting, the experts\nwere each given a stack of index cards. The name of one di-\nmension of religion was written on each card. The experts\nwere asked to sort the cards according to where the ques-\ntions should appear in the final closed-ended questionnaire.\nA consensus was determined by tabulating the rankings pro-\nvided by the group.\nBased on the input from the group of experts, a number of\nchanges were made to the newly devised religion questions.\nThe tapes and transcripts of the meeting with the experts\nproved to be quite valuable in this respect. In the process,\nproblems and revisions suggested by these experts were\nchecked against the focus group and in-depth interview data.\nCognitive Interviews\nOnce a good set of preliminary closed-ended questions\nwas in place, a series of cognitive interviews were conducted.\nCognitive interviews involve presenting study subjects with\na closed-ended question followed by a series of open-ended\nprobes. The purpose of the open-ended probe questions is to\nsee if study subjects understand the closed-ended question\nin the intended manner, to see if respondents can provide a\nbetter way of phrasing question stems, and to see if subjects\nfeel comfortable with the closed-ended response options.\nEighty-five cognitive interviews were conducted with a\nnew sample of subjects. Once again, these study participants\nwere selected from the HCFA list, using simple random\nsampling procedures. Up to this point, older adults were ex-\ncluded from the study if they indicated that religion was not\nat all important to them. However, this exclusion criteria was\nrelaxed at this point, and all elderly people were included in\nthe remaining steps of this study regardless of how impor-\ntant religion may be to them. Forty-five of the participants in\nthe cognitive interviews were older White adults, and 40\nwere elderly African American adults. All cognitive inter-\nviews were conducted face-to-face in the homes of the\nstudy participants.\nThe closed-ended religion items were broken down into\nfour blocks. Cognitive interviews were conducted using ap-\nproximately 20 subjects for each of the four blocks of ques-\ntions. It was not necessary to probe some closed-ended\nquestions because a good deal is already known about them\n(e.g., \"At the present time, what is your religious prefer-\nence?\"). The cognitive interviews lasted between 60 and 90\nmin. All cognitive interviews were tape-recorded.\nInitially, members of the research team were concerned\nthat study participants would quickly tire when they found\nthat each closed-ended question would be followed by a se-\nries of open-ended probes. This did not prove to be the case.\nInstead, the older people in this study worked hard to help\nthe research team improve the closed-ended questions. This\nhigh level of motivation was due in part to the way the cog-\nnitive interviews were introduced. Subjects were told that a\ngreat deal of time had been spent speaking with older people\nabout religion in an unstructured manner. They were also\ntold that a series of questions had been written about religion\nbased on these conversations, but to know if these items are\nany good, their critical input was essential. Subjects were\nasked to work hard to help the research team uncover prob-\nlems and find new ways to improve the questions. This ap-\nproach represents a modified version of Cannell's strategy for\nincreasing respondent motivation and commitment (Cannell,\nTwo broad approaches may be followed in developing\nprobe questions for cognitive interviews. The first is to ask\nvery general follow-up questions, as in the think-aloud strat-\negy (see Foddy, 1998, for a recent discussion of this tech-\nnique). An example will help clarify the nature of these gen-\neral probe questions. Using religion to derive a sense of\nmeaning in life emerged as an important theme in this study.\nConsequently, a series of closed-ended questions were de-\nvised to assess this domain. One item from this battery\nasked subjects if they felt that, \"God has a specific plan for\nmy life.\" This indicator was followed with a broad probe:\n\"Can you tell me a little more about what you were thinking\nabout when you answered this question?\"\nThese general probe questions did not appear to be espe-\ncially useful. Instead, a second approach involving more fo-\ncused probe questions was more helpful. This strategy can\nbe illustrated by turning to forgiveness. Some subjects in the\nqualitative studies indicated that when they were hurt by\nsomeone, they were usually able to \"forgive and forget.\" A\nclosed-ended question was written to assess this topic. After\nadministering the closed-ended question, subjects were asked\nthe following focused probe questions: \"What does the phrase\n`forgive and forget' mean to you? If you were to ask a friend\nabout this, how would you do it--what words would you\nuse to see if they can forgive and forget?\" The observation\nthat focused probe questions tend to produce better feed-\nback than general probe questions is consistent with recent\nresearch on cognitive interviewing by Foddy (1998).\nAn example may help clarify how the focused cognitive\ninterview probes were used to revise the religion measures.\nIn his outstanding work on the measurement of religious\ncoping, Pargament (1997) devised an item that asks respon-\ndents how often they look to God for strength and guidance\nin a crisis. The respondents in our focus groups and in-depth\ninterviews indicated they turned to God for this purpose, but\nthe members of the research team were concerned that the\nitem devised by Pargament (1997) was double-barreled be-\ncause \"strength\" and \"guidance\" may not mean the same thing\nto study participants. To evaluate this possibility, partici-\npants in the cognitive interviews were presented with the\noriginal item developed by Pargament (1997). Focused probe\nquestions were subsequently asked to see if they felt that\nturning to God for strength was the same as turning to God\nfor guidance. The wide majority of study subjects indicated\nthey were different and recommended that separate ques-\ntions be asked about these issues. Based on their input, two\nseparate items were developed: \"I look to God for strength\nin a crisis,\" and \"I look to God for guidance when difficult\ntimes arise.\"\nThe cognitive interviews were also used to evaluate the\nclosed-ended responses for the religion items. For example,\nsubjects were asked whether they felt it is easier to answer a\nquestion using a standard five-point Likert scale, or whether\nselecting a response from a Cantril ladder (scored 1\u00ad10)\nmade more sense to them. An effort was also made to learn\nmore about how older people calibrate closed-ended re-\nsponses. For example, subjects were asked whether they\nused a particular religious coping response a great deal,\nsome, only a little, or not at all. Cognitive interview probe\nquestions were subsequently asked to determine how much\ndifference (if any) there was between a response of \"some\"\nand a response of \"only a little.\"\nThe newly developed religion items were revised again\nafter members of the research team listened to the tapes of\nthe cognitive interviews. These revisions were made by con-\nsulting the data gathered from the focus groups and in-depth\ninterviews, and by turning to the feedback provided by re-\nspondents during the cognitive interviews.\nPilot Study\nThe closed-ended religion items were administered to a\nnew sample of 98 older subjects. Half the respondents were\nolder White adults (n  49), and half were elderly African\nAmericans (n  49). These subjects were, once again, selected\nfrom the HCFA list. All pilot test interviews were conducted\nface-to-face in the homes of the study participants. Only\nclosed-ended quantitative questions were administered in\nthis phase of the study. As a result, this step in the item de-\nvelopment strategy more closely approximates a traditional\npilot test.\nThe goal of the pilot study was to check the length of the\nsurvey, to examine frequency distributions to make sure the in-\ndicators had sufficient variance, and to perform exploratory\nfactor analyses to examine the structure and psychometric\nproperties of the newly developed scales. This information\nwas supplemented with feedback from the interviewers about\nany problems they encountered with the questionnaire. Some\nminor revisions were made in some of the questions at this\npoint. In addition, the exploratory factor analyses helped\nidentify a few items that could be eliminated from some\nscales, thereby holding down the overall length of the inter-\nview schedule.\nAfter this phase of the item development strategy was\ncomplete, a total of 175 closed-ended questions were in hand\nthat assessed 14 major dimensions of religion. Copies of the\nreligion items are available on request from the author.\nNationwide Survey\nThe next step in the item development strategy involved\nadministering the closed-ended questionnaire to a nation-\nwide sample of 1,500 older people. Data were collected by\nHarris Interactive (formerly Louis Harris and Associates).\nInterviewing was completed in August 2001. The sample\ncan Americans. The sampling frame for the study was again\nprovided by HCFA. Greater detail on the sampling proce-\ndures is available from the author.\nBefore the nationwide survey went into the field, the ques-\ntionnaire was reviewed closely by staff members at Harris\nInteractive who have considerable experience in writing\nclosed-ended survey questions. A few very minor revisions\nwere made to the religion items. Then the entire interview\nschedule was evaluated in two brief pilot tests, consisting of\nPsychometric Testing\nThe final step in the item development strategy is cur-\nrently in progress. A series of substantive papers are being\nwritten to explore the relationships between select dimen-\nsions of religion, health, and well-being (copies of these pa-\npers are available from the author). Detailed psychometric\ntesting is being performed on the religion measures that are\nused in each paper. Four issues involving these tests are dis-\ncussed briefly below.\nFirst, all multiple item scales are examined with both ex-\nploratory and confirmatory factor analyses. The goal is to\nsee whether items that were designed to capture a specific\ndimension of religion cluster together, and whether the indi-\ncators measure each factor well (i.e., whether the factor\nloadings are equal to or greater than .400).\nSecond, the findings from the confirmatory factor analy-\nses are being used to compute internal consistency reliabil-\nity estimates for each scale. More specifically, based on a\nformula provided by Rock, Werts, Linn, and J\u00f6reskog\n(1977), the factor loadings and measurement error terms as-\nsociated with each item are used to derive reliability esti-\nmates. So far, the reliability estimates for the newly devised\nscales are generally in excess of .800.\nThird, in the process of performing the confirmatory fac-\ntor analyses, tests are being performed for measurement in-\nvariance (Bollen, 1989). As noted earlier, older White subjects\nmake up half the sample obtained in the nationwide survey,\nwhereas the other half consists of older Black subjects. Con-\nsequently, it is important to see whether the factor loadings\nand measurement error terms are equivalent in both racial\ngroups. If these parameter estimates are the same, it is rea-\nsonable to conclude that the survey items mean the same\nthing to older White respondents and older Black respon-\ndents. One goal in conducting the focus groups, in-depth in-\nterviews, and cognitive interviews for this study was to de-\nvelop survey items that mean the same thing to older White\nand older Black people. However, the assessment of mea-\nsurement equivalence in this context is largely based on sub-\njective evaluations of feedback provided by the focus group,\nin-depth interview, and cognitive interview participants. The\nempirical tests of measurement equivalence that are now\nbeing performed with the nationwide data are a nice com-\nplement to these qualitative strategies, and provide yet\nanother way of more tightly merging qualitative and quan-\ntitative methods in studies designed to develop closed-\nended survey measures.\nFinally, in addition to assessing issues in measurement in-\nvariance and scale reliability, it is also important to evaluate\nthe validity of the newly devised measures. Unfortunately, it\nis difficult to estimate some types of validity (i.e., predictive\nvalidity) with data that have been gathered at one point in time\nonly (see Carmines & Zeller, 1979, for an insightful discus-\nsion of scale validity). However, it is possible to evaluate\nconstruct validity with the data on hand. As noted earlier, con-\nstruct validity is evaluated by embedding new measures in\nsubstantive conceptual models to see whether the new indi-\ncators are related to select outcomes in theoretically mean-\ningful ways. Although the establishment of construct valid-\nity is an ongoing task that requires replication across a series\nof studies, the results that have emerged from the analyses\nthat have been done so far are very encouraging. For exam-\nple, as one might anticipate, older people who receive spiri-\ntual support from their fellow parishioners indicate they\nhave a closer relationship with God, and people who feel\ncloser to God report they are more hopeful about the future\n(further detail on this is available from the author).\n\"Measurement is a sine qua non of any science.\" This makes\nsense because the relationship between two or more mea-\nsures cannot be evaluated properly until good indicators of\neach construct are firmly in place. Unfortunately, it seems\nthat researchers spend far more time discussing how data are\nanalyzed, whereas far less attention is devoted to how study\nmeasures were devised. This problem arises, in part, because\nsound protocols for developing closed-ended survey items\nhave rarely appeared in the literature. A basic premise in the\npresent study is that merging qualitative and quantitative\nmethods represents a promising way to approach this prob-\nlem. Some time ago, Lazarsfeld (1944) recommended that\nqualitative and quantitative methods be used for this pur-\npose, but there is relatively little concrete guidance on how\nto implement this strategy in practice. The purpose of this\nstudy was to provide a practical, yet comprehensive, strategy\nfor developing closed-ended survey items. Beginning with\nfocus groups, and culminating in the psychometric testing of\ndata obtained in a nationwide probability sample of older\npeople, the intent was to highlight problems and provide\nhelpful solutions for those wishing to study the content do-\nmain of a wide range of constructs. Although these proce-\ndures have all been examined previously in the literature,\nthere do not appear to be any studies that pull them together\nin one place.\nA tremendous amount of work was needed to execute all\nnine steps in this study. In fact, it took three full years to\ncomplete this task. Not counting the nationwide survey, the\nresearch team spoke with 399 older adults. In addition to pro-\nviding vitally important information on how to develop\nclosed-ended survey questions, the qualitative interviews\ntriggered a flood of new ideas about theoretical or substan-\ntive issues in the field of religion and aging. As discussed\nearlier, a great deal was learned about the steps that may be\nfollowed in the process of forgiveness, as well as beliefs\nabout how prayers are answered.\nThose wishing to use the item development strategy out-\nlined above should pay attention to the shortcomings in this\napproach. Three limitations are discussed briefly below.\nFirst, because merging qualitative and quantitative methods is\ncostly and labor-intensive, it is incumbent upon those who\nadvocate this approach to demonstrate that this strategy pro-\nduces results that are superior to findings obtained with\nmore traditional approaches to survey item development\n(e.g., relying on a panel of experts alone). Moreover, we need\nto devise ways of seeing whether each step in the item devel-\nopment strategy outlined earlier has an equal payoff, or\nwhether one step (e.g., focus groups) is less effective than\nanother (e.g., in-depth interviews). Unfortunately, protocols\ndo not appear to exist for tackling these difficult tasks. De-\nveloping a feasible evaluation component should be a top\npriority for investigators wishing to merge qualitative and\nquantitative research methods in the same study.\nSecond, with the exception of the nationwide survey, data\nfor all steps in the item development strategy were gathered\nin Washtenaw County, MI. This was done because practical,\nas well as economic, considerations made it difficult to con-\nduct focus groups and in-depth interviews in a wider geo-\ngraphical area. Nevertheless, research indicates that there\nare regional differences in the way Christianity is practiced\n(Hunt & Hunt, 2001). Consequently, the items developed in\nthe present study may not fully capture how older people\nin other regions of the nation, such as the rural southeast,\nview their faith.\nThird, as noted earlier, many interesting dimensions of\nreligion emerged from the qualitative interviews, but ques-\ntions were not written for all of them. So, for example, a good\ndeal of discussion in the in-depth interviews involved changes\nthat older adults experienced in the way they practiced reli-\ngion over the course of their lives. In fact, a separate paper\nwas written on this issue (Ingersoll-Dayton, Krause, &\nMorgan, in press). Even so, questions on change in religion\nover the life course were not included in the final nationwide\nsurvey. As noted earlier, there are no firm guidelines for figur-\ning out which domains should be pursued and which should\nbe eliminated. In the end, this decision was based on a\nsubject judgment concerning which domains are most\nlikely to affect health in late life. However, researchers\nwho are interested in relating religion to other outcomes,\nand investigators who treat religion as a dependent vari-\nable, may find that the dimensions of religion that were\nexcluded from the present study are vitally important for\ntheir purposes.\nBoth qualitative and quantitative researchers may ques-\ntion some of the procedures that were used in the item de-\nvelopment strategy. For example, qualitative investigators\nmay not feel comfortable with feeding empirical findings\nfrom ongoing quantitative studies into the in-depth inter-\nviews (see step 3 in Table 1). Similarly, as discussed previ-\nously, quantitative researchers may feel uneasy about re-\ncruiting subjects for focus groups and in-depth interviews\nfrom a local geographical area. Consequently, the greatest\ncontribution of the present study may arise from the fact that\nit provides a concrete forum for opening a more focused di-\nalogue on how to best develop closed-ended survey items\nfor studies of older adults.\n"
}