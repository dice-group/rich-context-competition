{
    "abstract": "Abstract\nOpenness and transparency are becoming hallmarks of responsible data practice in science and governance. Concerns\nabout data falsification, erroneous analysis, and misleading presentation of research results have recently strengthened\nthe call for new procedures that ensure public accountability for data-driven decisions. Though we generally count\nourselves in favor of increased transparency in data practice, this Commentary highlights a caveat. We suggest that\nlegislative efforts that invoke the language of data transparency can sometimes function as ``Trojan Horses'' through\nwhich other political goals are pursued. Framing these maneuvers in the language of transparency can be strategic,\nbecause approaches that emphasize open access to data carry tremendous appeal, particularly in current political and\ntechnological contexts. We illustrate our argument through two examples of pro-transparency policy efforts, one\nhistorical and one current: industry-backed ``sound science'' initiatives in the 1990s, and contemporary legislative efforts\nto open environmental data to public inspection. Rules that exist mainly to impede science-based policy processes\nweaponize the concept of data transparency. The discussion illustrates that, much as Big Data itself requires critical\nassessment, the processes and principles that attend it--like transparency--also carry political valence, and, as such,\nwarrant careful analysis.\n",
    "reduced_content": "Commentary\nWhen open data is a Trojan Horse:\nThe weaponization of transparency in\nscience and governance\nKaren EC Levy1 and David Merritt Johns2\n Keywords\nTransparency, openness, data, policy, governance, science\nOpenness, transparency, and reproducibility have\nbecome the new watchwords of responsible data prac-\ntice in science. A series of recent high-profile scandals\nhas brought to light the problems of erroneous analysis,\nfalsified data, problematic methodology, and cherry-\npicked presentation of research results (Carey and\n2011). Some evidence suggests these problems, whether\nintentional or accidental, are more widespread than has\nbeen previously recognized, and that existing norms\nand processes of academic publishing and peer-review\nare poorly configured to detect or deter them (Gelman,\nscale reanalysis of 100 published psychology studies,\nonly about one-third of the results could be replicated\n(Open Science Collaboration, 2015); in another recent\nanalysis of 60 published economics papers, less than\nhalf of the main results could be replicated\n(Chang and Li, 2015). In response, a number of stan-\ndard-bearers in the scientific process have recently\ncalled for or instituted pro-transparency policies--from\nrequiring researchers to make their data publicly\navailable, to insisting that study results be independ-\nently replicated prior to publication (Ablin, 2014;\nSimilar pro-transparency principles have also gained\ntraction in government. The ethos of open government,\n1Data & Society Research Institute and Cornell University, New York, NY,\nUSA\n2Data & Society Research Institute and Columbia University, New York,\nCorresponding author:\nKaren Levy, Data & Society Research Institute, New York, NY, USA.\nEmail: karen@datasociety.net\nBig Data & Society\nReprints and permissions:\nsagepub.com/journalsPermissions.nav\nbds.sagepub.com\nCreative Commons NonCommercial-NoDerivs CC-BY-NC-ND: This article is distributed under the terms of the Creative Com-\nmons Attribution-NonCommercial-NoDerivs 3.0 License (http://www.creativecommons.org/licenses/by-nc-nd/3.0/) which permits\nnon-commercial use, reproduction and distribution of the work as published without adaptation or alteration, without further permission provided the\noriginal work is attributed as specified on the SAGE and Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).\nadvocated in recent years by the Obama administration\n(Ellman and Suh, 2013), posits that accessible datasets\nand transparent decision-making processes are neces-\nsary precursors to government accountability, respon-\nsible governance, public trust, and, ultimately, improved\npolicy outcomes. Providing open access to information\nproduced in federally funded research is said to be a core\nfunction of democracy, an effective means of accelerat-\ning job growth and innovation, and an essential strategy\nfor promoting an engaged and informed public\nAs social scientists, we count ourselves in support of\nthe (often overlapping) agendas of the open science and\nopen governance movements. In numerous cases, acces-\nsibility and replication have strengthened the integrity\nof data-driven decisions and increase the accountability\nof decision-makers. Indeed, it is difficult to imagine\nmany principled arguments against transparency\n(except to the extent necessary to protect personal priv-\nacy or otherwise sensitive information)--especially\nwhen data are analyzed as part of public governance\nprocesses, or when public money has been used to pro-\nduce them.\nHowever, in this Commentary, we highlight a critical\nchallenge to the growing movement toward increased\ndata transparency in science and public policy. We note\nthat legislative efforts that invoke the language of data\ntransparency can sometimes function as ``Trojan\nHorses'' designed to advance goals that have little to\ndo with good science or good governance. Framing\nthese maneuvers in the language of transparency can\nbe politically strategic, because approaches that empha-\nsize open access carry tremendous appeal, particularly\nin current political, technological, and institutional\ncontexts. We illustrate our argument through two\nexamples of pro-transparency policy efforts, one histor-\nical and one current: industry-backed ``sound science''\nlobbying in the 1990s, and contemporary legislative\nefforts to open environmental data to public inspection.\n``Sound science,'' data quality, and the\ninstitutionalization of uncertainty\nIn the 1990s, the tobacco company Philip Morris\nlaunched a ``sound science'' initiative aimed at casting\ndoubt on the link between secondhand tobacco smoke\nand lung cancer by challenging prevailing interpret-\nations of key studies (Baba et al., 2005). Among the\ncampaign's first objectives was to ``legislate public\naccess to epidemiological data used in support of fed-\neral laws and regulations'' (SRIC Innovation, 1997).\nRecognizing that frustration in the oil and coal indus-\ntries over proposed clean air regulations represented a\n``hook'' that could provide an opportunity for political\ncoalition-building, the sound science team presented\ndata access legislation to Capitol Hill allies (Philip\nadded a rider called the Data Access Act (DAA) to an\nappropriations bill that mandated public access to all\ndata produced by federally funded scientists employed\nby nonprofit institutions (Michaels, 2008). The law,\ncommonly known as the Shelby Amendment and\npassed in September 1998, did not apply to privately\nfunded studies.\nIn 2000, the sound science team achieved an even\nbigger victory when a tobacco industry lobbyist con-\nvinced Rep. Jo Ann Emerson (R-Mo.) to slip a two-\nsentence rider into a 712-page appropriations bill\nrequiring all federal agencies to issue guidelines\n``ensuring and maximizing the quality, objectivity, util-\nity, and integrity of information (including statistical\ninformation) disseminated by the agency.'' The Data\nQuality Act (DQA)--also known as the Information\nQuality Act--required agencies to establish a mechan-\nism through which ``affected persons'' could ``seek and\nobtain correction of information'' promulgated by the\ngovernment. No hearings were held on the DQA, and it\nis not clear that most members were aware it was being\nMany scientists have denounced the DAA and DQA\nas attempts to magnify and institutionalize the uncer-\ntainty inherent in the science policy enterprise\nSchick et al., 2007). David Michaels, current chief of\nthe Occupational Safety and Health Administration,\nhas referred to the DAA as an invitation to ``dredge\nand manipulate'' government data in an effort to\nMichaels has written that the DQA has ``successfully\nslowed agency activities'' by consuming scarce\ntions have become a favored tactic for delaying agency\nactions that run counter to industry interests. An ana-\nlysis by the Washington Post found that DQA petitions\nhad been filed predominantly by regulated industries,\nlobbyists, and trade organizations (32 of 39 petitions\nanalyzed) (Weiss, 2004). Public health scholars have\nwarned that the DQA may prompt agencies to ``self-\ncensor'' important information that is likely to come\nunder challenge (Rosenstock, 2006). Because these pur-\nportedly pro-transparency laws do not apply to indus-\ntry-funded science and are invoked only in the face of\nagency action, they are like ``a knife that cuts only one\nway''--against federal intervention (Houck, 2003).\n``Secret science'' in environmental\nregulation\nSimilar legislative efforts are unfolding today. The\nSecret Science Reform Act (SSRA) is currently pending\n2 Big Data & Society\nin Congress. (It was passed in the House of\nRepresentatives in March 2015, and is currently await-\ning Senate action.) The bill would prohibit the\nEnvironmental Protection Agency (EPA) from propos-\ning or implementing regulations ``based on science that\nis not transparent or reproducible,'' and requires the\npublic release of all data used in the EPA's assessments\nin a manner that allows for independent analysis and\nreproduction of results. Advocacy for the SSRA has\nbeen couched firmly in the language of data transpar-\nency: as its sponsor Lamar Smith (R-Tex.) put it,\n``[c]ostly regulations should not be created behind\nclosed doors and out of public view'' (US Congress\npress release 2015). Notably, the notion of using the\ncatchphrase ``secret science'' to advocate for data dis-\nclosure was discussed in private meetings of consultants\nto the tobacco industry as early as 1998 (Gianelli,\nThe SSRA hits squarely at the intersection of open\nscience and open government. For the science commu-\nnity, the SSRA appears to respond to calls for increased\nreplicability, open access, and data sharing. On the gov-\nernance side, many informed advocates on the left have\npushed to open up government datasets to fight corrup-\ntion and cast ``sunlight'' on policy processes.\nBut upon closer inspection, the SSRA appears to use\ndata transparency as a Trojan Horse through which to\nadvance a different goal: namely, to hamstring the pro-\ncesses of the EPA. The EPA relies upon approximately\n50,000 scientific studies annually to make environmen-\ntal policy. The Congressional Budget Office forecasts\nthat the SSRA would severely restrict the EPA's ability\nto enact new regulations, due to both the costs of\nmaking so much data publicly available, and the fact\nthat certain classes of data (for example, industry-held\nor medical data) would be impossible to release (and\nthus to rely upon) according to the terms of the pro-\nposed law (Congressional Budget Office, 2014)--creat-\n2014). These effects do not appear to have been unfore-\nseen: Congressional votes on the SSRA have divided\nalong party lines, and some of its chief advocates are\nactive in the climate-change denial movement. On the\nother side, more than 50 scientific societies and univer-\nsities have signed statements in opposition to the bill\n(American Association for the Advancement of\nData dredging and the risks of ``scientific\ncacophony''\nBeyond these legislative actions, the open data move-\nment has provoked a complex debate among scientists\nwho wish to ensure that vested interests do not take\nadvantage of open-access policies to advance their\ngoals to the detriment of public health. For example,\nsome clinical and public health researchers, informed\nby prior scientific battles with the tobacco industry\nand other powerful interests, have expressed concern\nthat biased actors may ``dredge'' existing data sets to\ngenerate new analyses that contradict established scien-\ntific and public health positions (Christakis and\nOpen access to research data is said to be a ``double-\nedged sword'' (Spertus, 2012). To prevent the ``scientific\ncacophony'' that might ensue from truly open access,\nsome have proposed that data sharing may not be\nuseful when those requesting data have strong vested\ninterests (Christakis and Zimmerman, 2013).\nScientific proponents of data sharing, in contrast,\nassert that de-identified raw data ``should eventually\nbe put into the public domain for unconditional, uni-\nversal access'' (Strom et al., 2014). For such advocates\nof unrestricted access, status quo arrangements in\nwhich data are tightly held and the original investiga-\ntors' interpretation prevails ``may be just as or more\nharmful'' than a situation in which diverse private\nactors are empowered to challenge the accepted\nwisdom with their own assessments of the evidence\nThese competing perspectives invoke different\nassumptions about the institutional processes of\nscience-based governance. Regulatory open-data advo-\ncates propose essentially a democratic, free-market\napproach to the evaluation of scientific findings: release\nthe data, they suggest, and the ``best'' findings will rise\nto the top, while promoting accountability for decision-\nmakers. Other researchers fear that open-data policies\nmight, paradoxically, increase industry ``capture'' of\nregulatory processes, as resource-rich special interests\nexploit scientific uncertainty to impose undue adminis-\ntrative delay.\nThe limits of transparency in science\nand governance\nIn an era of increased skepticism toward science, any-\nthing less than unqualified openness on the part of\nregulatory agencies may be taken as an indication\nthat something is being hidden. In this Commentary,\nwe emphasize that the principle of data transparency is\nsubject to limits (Jasanoff, 2006). Data processes in sci-\nence and governance face at least three sources of con-\nstraint, which calls for increased data transparency may\nstrategically play against. First, institutional resource\nlimitations are unavoidable--open processes require\nsubstantial outlays of time and money, which can ham-\nstring the workings of agencies to the extent that they\ncannot accomplish their aims. Second, countervailing\ninterests, such as privacy protection, may make it\nLevy and Johns 3\nimpossible to fully release data; while techniques like\nanonymization can provide a middle ground, initiatives\nlike the SSRA do not make allowances for them.\nIn time, technological and methodological advance-\nments may ameliorate these two concerns somewhat, as\ninfrastructures for data sharing become standardized\nand institutional norms shift. But a final constraint\nremains: the fact that epistemological limitations con-\nstrain data-driven political decision-making. Agencies\ncharged with protecting public health and the environ-\nment must make decisions in the face of scientific uncer-\ntainty, because science by its nature is incomplete and\nonly rarely provides precise answers to the complex\nquestions policymakers pose. Sarewitz (2000) compares\nthe goals of science and politics:\nThe goal of politics is the achievement . . . of an oper-\national consensus that enables action. This is a very\ndifferent goal from that of science, which seeks to\nexpand insight and knowledge about nature through\nan ongoing process of questioning, hypothesizing, val-\nidation, and refutation . . . . When a scientific problem is\ncontentious and the object of a vibrant research effort,\nconsensus is extremely difficult to achieve--the process\nof scientific investigation intrinsically militates against,\nis designed to inhibit, premature consensus.\nData transparency, even with its many virtues, cannot\nalter this fundamental aspect of scientific inquiry.\nCacophony and contention are core elements of the\nscientific enterprise. By invoking a ``narrow, idealized\nportrayal of science'' in which research reliably pro-\nduces clear and reproducible facts, the special interests\nbehind the DAA, DQA, and SSRA mischaracterize sci-\nence's ``inevitably incomplete, uncertain, contested,\nand . . . often unreliable'' nature in their efforts to\nstymie regulatory activities with which they disagree\n(Sarewitz, 2015). Technical experts at regulatory agen-\ncies frequently commit this same mistake by failing to\ndelineate the extent to which their science policy deci-\nsions inevitably are informed by value judgments that\ngo well beyond the available science (Wagner, 2003).\nRegulators and their opponents thus co-produce a\nfalse impression of the contribution of science to\npublic policy development.\nRules that invoke the specter of ``secret science'' or\nthat exist mainly to impede policy processes weaponize\nthe concept of data transparency. They also, ironically,\nmay themselves violate principles of transparency: the\nDAA and DQA were covertly inserted into large\nappropriations bills--a strikingly opaque approach.\nThe SSRA proposes that evidence that has not been\nreleased publicly should be excluded from EPA ana-\nlyses even if it might improve agency decision-\nmaking. Transparency requires that relevant research\nnot be dismissed from policy processes even if it is\nincomplete or less than definitive (Wagner and\nSteinzor, 2006). There are other recent examples of\nlegislative efforts that invoke the language of transpar-\nency and scientific quality control in the name of demo-\ncratic values but that appear to be camouflaged efforts\nto improve the lot of special interests (Marcos, 2015;\nThe political valence of data transparency is a critical\nreminder of the inherently sociopolitical nature of all\ntechnologies, including institutional data practices.\nThough transparency is often framed as an unalloyed\ngood (provided that privacy interests can be adequately\nprotected), in practice it provides a means through which\ndiverse stakeholders attempt to achieve diverse political\ngoals. Politically motivated proponents of transparency,\nin some cases, may exploit the epistemological and insti-\ntutional realities that accompany the production of sci-\nence and science-based policy. Policies that allow for\nopen sharing of data may improve perceptions that\nscience-based decisions are credible, but data access\napproaches must be carefully designed to ensure they\nmake science and governance better, not worse. Just as\nBig Data itself creates phenomenological and epistemo-\nlogical challenges that must be critically assessed, its\nattendant processes also warrant careful analysis.\nDeclaration of conflicting interests\nThe author(s) declared no potential conflicts of interest with\nrespect to the research, authorship, and/or publication of this\narticle.\nFunding\nThe author(s) received no financial support for the research,\nauthorship, and/or publication of this article.\nReferences\nAblin RJ (2014) The problem with prostate screening.\nThe New York Times, 25 November. Available at:\nwith-prostate-screening.html (accessed 9 October 2015).\nAlberts B, Cicerone RJ, Fienberg SE, et al. (2015) Self-correc-\nAmerican Association for the Advancement of Science (2014)\nLetter to house majority whip Kevin McCarthy, 31 July.\nAvailable at: http://democrats.science.house.gov/sites/\ndemocrats.science.house.gov/files/documents/Coalition-\nsecret_science_house.pdf (accessed 9 October 2015).\nBaba A, Cook DM, McGarity TO, et al. (2005) Legislating\n`sound science': The role of the tobacco industry.\nCarey B and Belluck P (2015) Doubts about study of gay\ncanvassers rattle the field. The New York Times, 25 May.\nmaligned-study-on-gay-marriage-is-shaking-trust.html\n4 Big Data & Society\nChang AC and Li P (2015) Is economics research replicable?\nSixty published papers from thirteen journals say ``usually\nWashington, DC: Board of Governors of the Federal\nReserve System. Available at: http://www.federalreserve.-\nChristakis DA and Zimmerman FJ (2013) Rethinking\nreanalysis. Journal of the American Medical Association\nSecret Science Reform Act of 2014, 3 October. Available\nCoy P (2013) Reinhart, Rogoff, and the Excel error that\nchanged history. Bloomberg Business 18 April. Available\nfaq-reinhart-rogoff-and-the-excel-error-that-changed-history\nEconomist (2013) Trouble at the lab: Scientists like to think\nof science as self-correcting. To an alarming degree, it is\nnot, 19 October. Available at: http://www.economist.com/\nalarming-degree-it-not-trouble (accessed 9 October 2015).\nEllman L and Suh R (2013) Sunshine week: In celebration of\ntransparency. In: White House Open Government Initiative\nblog. Available at: https://www.whitehouse.gov/blog/2013/\n03/14/sunshine-week-celebration-transparency (accessed 9\nGelman A (2013) Ethics and statistics: It's too hard to publish\ncriticisms and obtain data for replication. Chance 26(3):\nGianelli L (1998) Memorandum to ``Secret Science'' Work\nGroup, Philip Morris, 10 April. Available at: http://\nindustrydocuments.library.ucsf.edu/tobacco/docs/klyc0069\nHoldren JP (2013) Memorandum for the Heads of Executive\nDepartments and Agencies: Increasing Access to the Results\nof Federally Funded Scientific Research. Available at:\nhttps://www.whitehouse.gov/sites/default/files/microsites/\nHorton R (2015) Offline: What is medicine's 5 sigma? The\nHouck O (2003) Tales from a troubled marriage: Science and\nInstitute of Medicine (2015) Sharing Clinical Trial Data:\nMaximizing Benefits, Minimizing Risk. Washington, DC:\nThe National Academies Press.\nJacoby W (2015) The AJPS replication policy: Innovations\nand revisions. In: American Journal of Political Science\najps-replication-policy-innovations-and-revisions/ (accessed\nJaffe S (2015) Republicans' bills target science at US envir-\nonment agency: Proposed legislation would change how\nthe US Environmental Protection Agency uses science to\nJasanoff S (2006) Transparency in public science: Purposes,\nreasons, limits. Law and Contemporary Problems 69(3):\nKaiser J (2003) Industry groups petition for data on salt and\nKolata G (2011) How bright promise in cancer testing fell apart.\nThe New York Times, 7 July. Available at: http://www.nyti\nKrumholz HM and Peterson ED (2014) Open access to clin-\nical trials data. Journal of the American Medical\nMarcos C (2015) House passes bill to overhaul EPA Scientific\nAdvisory Board. The Hill, 17 March. Available at: http://\nbill-to-overhaul-epa-advisory-board (accessed 9 October\nMichaels D (2008) Doubt is Their Product. New York, NY:\nMichaels D and Monforton CA (2005) Manufacturing uncer-\ntainty: Contested science and the protection of the public's\nhealth and environment. American Journal of Public\nOpen Science Collaboration (2015). Estimating the reproduci-\nPhilip Morris (1997) Sound Science Project Plan, December.\nAvailable at: http://industrydocuments.library.ucsf.edu/\nRosenberg AA (2014) Congress must block these attacks on\nindependent science. Roll Call, 17 November. Available at:\nhttp://www.rollcall.com/news/congress_must_block_these_\nRosenstock L (2006) Protecting special interests in the name\nof `good science'. Journal of the American Medical\nSacks FM, Appel LJ, Bray GA, et al. (2003) Sodium and\nblood pressure: No data dredging, please! American\nSarewitz D (2000) Science and environmental policy: An\nexcess of objectivity. In: Frodeman R (ed.) Earth\nMatters: The Earth Sciences, Philosophy, and the Claims\nof Community. Upper Saddle River, NJ: Prentice Hall,\nSarewitz D (2015) Reproducibility will not cure what ails sci-\nSchick SF, Bero LA and Cook DM (2007) The tobacco industry\nSeife C and Thacker P (2015) Why it's OK for taxpayers to\n`snoop' on scientists. Los Angeles Times, 21 August.\nAvailable at: http://www.latimes.com/opinion/op-ed/la-\nSpertus JA (2012) The double-edged sword of open access to\nresearch data. Circulation: Cardiovascular Quality and\nSRIC Innovation (1997) Sound Science Project. Philip\nMorris, May. Available at: http://industrydocuments.\nlibrary.ucsf.edu/tobacco/docs/snyc0069 (accessed 9\nLevy and Johns 5\nStrom BL, Buyse M, Hughes J, et al. (2014) Data sharing,\nyear 1--Access to data from industry-sponsored clinical\nUrology Times (2013) AUA throws its support behind\nUSPSTF reform bill, 3 June. Available at: http://urology-\ntimes.modernmedicine.com/urology-times/content/tags/\naua/aua-throws-its-support-behind-uspstf-reform-bill?\nUS Congress (2015) House Committee on Science, Space, and\nTechnology press release. House, Senate Introduce Bill to\nEnsure Open EPA Science, 24 February. Available at:\nhttp://science.house.gov/press-release/house-senate-intro-\nduce-bill-ensure-open-epa-science (accessed 9 October\nWagner WE (2003) The `bad science' fiction: Reclaiming the\ndebate over the role of science in public health and envir-\nonmental regulation. Law and Contemporary Problems\nWagner W and Steinzor R (2006) Transparency and honesty.\nIn: Wagner W and Steinzor R (eds) Rescuing Science from\nPolitics: Regulation and the Distortion of Scientific\nResearch. New York, NY: Cambridge University Press,\nWeiss R (2004) A policy puts science on trial: ``Data quality''\nlaw is nemesis of regulation. Washington Post, 16 August.\nAvailable at: http://www.washingtonpost.com/wp-dyn/\nThis article is a part of Special theme on Critical Data Studies. To see a full list of all articles in this special\ntheme, please click here: http://bds.sagepub.com/content/critical-data-studies.\n6 Big Data & Society"
}