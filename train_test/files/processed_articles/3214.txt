{
    "abstract": "Abstract\nWe analyze Granger causality testing in a mixed-frequency VAR, where the differ-\nence in sampling frequencies of the variables is large. Given a realistic sample size,\nthe number of high-frequency observations per low-frequency period leads to param-\neter proliferation problems in case we attempt to estimate the model unrestrictedly.\nWe propose several tests based on reduced rank restrictions, and implement boot-\nstrap versions to account for the uncertainty when estimating factors and to improve\nthe finite sample properties of these tests. We also consider a Bayesian VAR that we\ncarefully extend to the presence of mixed frequencies. We compare these methods to\nan aggregated model, the max-test approach introduced by Ghysels et al. (2015a) as\nwell as to the unrestricted VAR using Monte Carlo simulations. The techniques are\nillustrated in an empirical application involving daily realized volatility and monthly\nbusiness cycle fluctuations.\n",
    "reduced_content": "Discussion Paper\nDeutsche Bundesbank\nDiscussion Papers represent the authors` personal opinions and do not\nnecessarily reflect the views of the Deutsche Bundesbank or its staff.\nTesting for Granger causality in large\nmixed-frequency VARs\nThomas B. G\u00f6tz\n(Deutsche Bundesbank)\nAlain Hecq\n(Maastricht University)\nStephan Smeekes\n(Maastricht University)\nEditorial Board: Daniel Foos\nThomas Kick\nJochen Mankart\nChristoph Memmel\nPanagiota Tzamourani\nDeutsche Bundesbank, Wilhelm-Epstein-Stra\u00dfe 14, 60431 Frankfurt am Main,\nPlease address all orders in writing to: Deutsche Bundesbank,\nInternet http://www.bundesbank.de\nReproduction permitted only if source is stated.\nNon-technical summary\nResearch Question\nWhen dealing with time series sampled at various frequencies it has become common\npractice to directly incorporate high-frequency information into the econom(etr)ic model\nat hand. These specifications were first restricted to the single regression case; with the\ndevelopment of the (stacked) mixed-frequency vector autoregressive (MF-VAR) system\n(Ghysels, 2015) it is now possible to treat all series similarly and investigate causal effects\nbetween them. However, if the difference in frequencies between the series involved is large\n(as, e.g., in a month/working day scenario), estimation accuracy of the system coefficients\nis exacerbated, implying the detection of causal effects to be potentially inaccurate. To\novercome this issue various parameter reduction techniques are introduced and analyzed.\nThese methods are then evaluated in terms of their ability to detect causality patterns\nbetween the series under consideration in the resulting restricted model.\nContribution\nTwo parameter reduction techniques are discussed in detail: three reduced rank regression\n(RRR) model variants and a Bayesian MF-VAR. Using a Monte Carlo experiment both\napproaches are compared in terms of their Granger causality testing behavior with an\nunrestricted VAR, a (time-aggregated) low-frequency VAR and the max-test (Ghysels,\nMotegi, and Hill, 2015a). To further enhance their finite sample properties we develop and\nevaluate (whenever possible) two bootstrap variants of these tests. Finally, the methods\nare applied to U.S. data by investigating channels of causality between the monthly growth\nrate of the industrial production index (IPI) and daily bipower variation (BV) of the\nResults\nWe find that, depending on the direction of causality under consideration, a different set\nof tests results in the best Granger non-causality testing behavior. For the direction from\nthe high- to the low-frequency series, standard testing within the Bayesian MF-VAR,\nthe max-test and the restricted bootstrap version of the Wald test in two RRR model\nversions performs best. For the reverse direction, the unrestricted bootstrap variants of\nthe Bonferroni-corrected Wald tests within the unrestricted VAR and the RRR models\ndominate. As far as our application is concerned, Granger causality from BV to IPI-\ngrowth is clearly supported by the data; evidence for causality in the reverse direction,\nhowever, only comes from a subset of tests.\nNichttechnische Zusammenfassung\nFragestellung\nBei der Handhabe unterschiedlich frequenter Zeitreihen ist es nunmehr \u00a8\nublich hochfre-\nquente Informationen direkt in das \u00a8\nokonom(etr)ische Modell enflie\u00dfen zu lassen. Waren\ndiese Spezifikationen zun\u00a8\nachst auf univariate Regressionen beschr\u00a8\nankt, so ist es durch die\nEntwicklung des (\"gestapelten\") gemischtfrequenten vektor-autoregressiven (MF-VAR)\noglich alle Variablen gleicherma\u00dfen zu behandeln und\nKausalzusammenh\u00a8\nange zwischen ihnen zu untersuchen. Sollte der Frequenzunterschied\njedoch gro\u00df sein (wie z.B. in einem Monat/Arbeitstage Szenario), verschlechtert sich die\nSch\u00a8\natzgenauigkeit der System-Koeffizienten, wodurch die Erfassung kausaler Effekte un-\ngenau werden k\u00a8\nonnte. Um dieses Problem zu umgehen werden Techniken zur Parameter-\nReduzierung vorgestellt und analysiert. Diese Methoden werden dann anhand ihrer F\u00e4higkeit,\nKausalzusammenh\u00a8\nange zwischen den entsprechenden Variablen zu erfassen, beurteilt.\nBeitrag\nZwei Techniken zur Parameter-Reduzierung werden detailliert diskutiert: Drei Varian-\nten einer Reduzierter-Rang-Regression (RRR) und ein Bayesianisches MF-VAR. Mit-\ntels einer Monte Carlo Analyse werden beide Ans\u00a8\natze anhand ihres Granger Kausa-\nlit\u00a8\natstestverhalten mit einem unrestriktierten VAR, einem (zeit-aggregierten) niedrig-\nfrequenten VAR und dem max-Test (Ghysels et al., 2015a) verglichen. Um ihre Ei-\ngenschaften weiter zu verbessern, entwickeln und bewerten wir (wann immer m\u00a8\noglich)\nzwei Bootstrap-Varianten dieser Tests. Als Anwendung untersuchen wir die Kausalzusam-\nmenh\u00a8\nange zwischen der Monatswachstumsrate des U.S.-Industrieproduktionsindex (IPI)\nund der t\u00a8\naglichen \"bipower\" Variation (BV) des S&500 Aktienindex.\nErgebnisse\nWir stellen fest, dass, je nach betrachteter Kausalit\u00a8\nats-Richtung, eine unterschiedliche\nGruppe von Tests zum jeweils besten Verhalten f\u00a8\nuhrt. F\u00a8\nur einen kausalen Effekt von der\nhoch- zur niedrigfrequenten Reihe erweisen sich Standard-Tests innerhalb des Bayesiani-\nschen MF-VARs, der max-Test und die restriktierte Bootstrap-Version des Wald Tests in\nzwei RRR-Varianten als am besten. F\u00a8\nur die entgegensetzte Richtung dominieren die un-\nrestriktierten Bootstrap-Varianten der Bonferroni-korrigierten Wald Tests innerhalb des\nunrestriktierten VARs und der RRR Modelle. In unserer Anwendung wird Granger Kau-\nsalit\u00a8\nat von BV zu IPI-Wachstum klar von den Daten unterst\u00a8\nutzt; Beweise f\u00a8\nur Kausalit\u00a8\nat\nin die entgegengesetzte Richtung kommen allerdings nur von einer Teilmenge der Tests.\nTesting for Granger Causality in Large\nMixed-Frequency VARs\nThomas B. G\u00a8\notz\nDeutsche Bundesbank\nAlain Hecq Stephan Smeekes\nMaastricht University\n Keywords: Granger Causality, Mixed Frequency VAR, Bayesian VAR, Reduced\nRank Model, Bootstrap Test\nContact address: Thomas B. G\u00a8\notz, Deutsche Bundesbank, Macroeconomic Analysis and Projection\nDivision, Wilhelm-Epstein-Strasse 14, 60431 Frankfurt am Main. Email: thomas.goetz@bundesbank.de.\nThe authors particularly thank Eric Ghysels for many fruitful discussions, comments and suggestions.\nMoreover, we thank two anonymous referees, Daniela Osterrieder, Lenard Lieb, J\u00a8\norg Breitung, Roman\nLiesenfeld, Jan-Oliver Menz, Klemens Hauzenberger, Martin Mandler and participants of the various\nconferences and workshops the paper was presented at. This paper supersedes both the mimeo Chauvet,\nG\u00a8\notz and Hecq (2014), \"Realized volatility and business cycle fluctuations: a mixed-frequency VAR\napproach\" and the discussion paper G\u00a8\notz and Hecq (2014), \"Testing for Granger causality in large\nmixed-frequency VARs\", Maastricht University, GSBE discussion paper. Discussion Papers represent the\nauthors' personal opinions and do not necessarily reflect the views of the Deutsche Bundesbank or its\nstaff.\n1 Introduction\nEconomic time series are published at various frequencies. While higher frequency vari-\nables used to be aggregated (e.g., Silvestrini and Veredas, 2008), it has become more and\nmore popular to consider models that take into account the difference in frequencies of the\nprocesses under consideration. As argued extensively in the mixed-frequency literature\n(e.g., Ghysels, Sinko, and Valkanov, 2007), working in a mixed-frequency setup instead\nof a common low-frequency one is advantageous due to the potential loss of information\nin the latter scenario and feasibility of the former through MI(xed) DA(ta) S(ampling)\nregressions (Ghysels, Santa-Clara, and Valkanov, 2004), even in the presence of many\nhigh-frequency variables compared to the number of observations.\nUntil recently, the MIDAS literature was limited to the single-equation framework, in\nwhich one of the low-frequency variables is chosen as the dependent variable and the high-\nfrequency ones are in the regressors. Since the work of Ghysels (2015) for stationary series\nand the extension of G\u00a8\nthe non-stationary and possibly cointegrated case, we can analyze the link between high-\nand low-frequency series in a VAR system treating all variables as endogenous. Ghysels,\nMotegi, and Hill (2015b) define causality in such a mixed-frequency VAR and develop\na corresponding test statistic. Decent size and power properties of their test, however,\nare dependent on a relatively small difference in sampling frequencies of the variables\ninvolved. Indeed, if the number of high-frequency observations within a low-frequency\nperiod is large, size distortions and losses of power may be expected.\nIn this paper we analyze the finite sample behavior of Granger non-causality tests\nwhen the number of high-frequency observations per low-frequency period is large as, e.g.,\nin a month/working day-example. To avoid the proliferation of parameters we consider\ntwo parameter reduction techniques: reduced rank restrictions and a Bayesian mixed-\nfrequency VAR. Both approaches are then compared to (i) temporally aggregating the\nhigh-frequency variable (Breitung and Swanson, 2002), (ii) the max-test, independently\nand simultaneously developed by Ghysels et al. (2015a), and (iii) the unrestricted ap-\nproach.\nWith respect to reduced rank regressions, the factors are typically not observable and\nmust be estimated. This will obviously affect the distribution of the Wald tests to detect\ndirections of Granger causalities. Consequently, one important contribution of this paper\nis the introduction of bootstrap versions of these tests (also for the unrestricted VAR),\nwhich have correct size even for large VARs and a small sample size.\nAs far as the Bayesian VAR is concerned, we show how to adapt the analysis to the\npresence of mixed frequencies. We do so by extending the dummy observation approach\nof Banbura, Giannone, and Reichlin (2010) to a mixed-frequency setting.1 Importantly,\ndue to stacking the high-frequency variables in the mixed-frequency VAR (Ghysels, 2015),\ntheir approach cannot be applied directly such that a properly adapted choice of auxil-\niary dummy variables corresponding to the prior moments is required. As these insights\ntransfer beyond Granger causality testing, the adaption of Bayesian methods to mixed-\nfrequency time series marks a significant contribution to the literature by itself.\n1Banbura et al. (2010) refer to these variables as dummy observations. To avoid confusion between\nhigh- and low-frequency observations and auxiliary variables, we use the term 'auxiliary dummy variables'\nhenceforth.\nThe rest of the paper is organized as follows. In Section 2 notations are introduced,\nthe mixed-frequency VAR (MF-VAR hereafter) for our specific case at hand is presented\nand Granger (non-)causality is defined. Section 3 discusses the approaches to reduce the\nnumber of parameters to be estimated, whereby reduced rank restrictions (Section 3.1)\nas well as Bayesian MF-VARs (Section 3.2) are presented in detail. The finite sample\nperformances of these tests are analyzed via a Monte Carlo experiment in Section 4. An\nempirical example with U.S. data on the monthly industrial production index and daily\nvolatility in Section 5 illustrates the results. Section 6 concludes.\n2 Causality in a Mixed-frequency VAR\nLet us start from a two variable mixed-frequency system, where yt\n, t = 1, . . . , T, is the\nlow-frequency variable and x(m)\nt-i/m\nare the high-frequency variables with m high-frequency\nobservations per low-frequency period t. Throughout this paper we assume m to be\nrather large as in a year/month- or month/working day-example. We also assume m\nto be constant rather than varying with t.2 The value of i indicates the specific high-\nfrequency observation under consideration, ranging from the beginning of each t-period\n(x(m)\n) until the end (x(m)\nt\nwith i = 0). These notational conventions have become\nstandard in the mixed-frequency literature and are similar to the ones in G\u00a8\notz, Hecq, and\nFurthermore, let Wt\n, . . ., Wt-p\n) denote the last p low-frequency lags\nof any process W stacked. Finally, 0i\u00d7j\n) denotes an (i \u00d7 j)-matrix of zeros (ones),\nIi\nis an identity matrix of dimension i,  represents the Kronecker product and vec\ncorresponds to the operator stacking the columns of a matrix.\nRemark 1. Extensions towards representations of higher dimensional multivariate systems\nas in Ghysels et al. (2015b) can be considered, but are left for further research here.\nAnalyzing Granger causality among more than two variables inherently leads to multi-\nhorizon causality (see L\u00a8\nutkepohl, 1993 among others). The latter implies the potential\npresence of a causal chain: for example, in a trivariate system, X may cause Y through\nan auxiliary variable Z. To abstract from that scenario, Ghysels et al. (2015b) often\nconsider cases, in which high- and low-frequency variables are grouped and causality\npatterns between these groups, viewed as a bivariate system, are analyzed. They study\nthe presence of a causal chain and multi-horizon causality in a Monte Carlo analysis\nthough.\nConsidering each high-frequency variable such that\nX(m)\nt\n= (x(m)\nt\n, x(m)\n, . . . , x(m)\n2As long as m is deterministic, even time-varying frequency discrepancies do not pose a problem on a\ntheoretical level. However, the assumption of constant m simplifies the notation greatly (Ghysels, 2015).\na dynamic structural equations model for the stationary multivariate process Zt\n= (yt\n, X(m)\nt\n)\nis given by\nAc\nZt\n+ . . . + Ap\nZt-p\n+ t\nNote that the parameters in Ac\nare related to the ones in A1\ndue to stacking the high-\nfrequency observations X(m)\nt\nin Zt\nthe model reads as:\n\n\n\n\n\n\n\n. . . m\n. . . -m-1\n.\n.\n.\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\nm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyt\nx(m)\nt\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n=\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n+\n\n\n\n\n\n\n\ny\n. . . m\nm\n. . . . . . 0\nm\n.\n.\n.\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\n. . . m\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx(m)\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n+\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n.\nIn general, we assume the high-frequency process to follow an AR(q) process with\nq < m (we set q = m in the equation above; if q < m, one should set q+1\n= . . . = m\nFor non-zero values of j\nor j\nthe matrix Ac\nlinks contemporaneous values of y and x, a\nfeature referred to as nowcasting causality (G\u00a8\nPre-multiplying (3) by A-1\nc\nwe get to the mixed-frequency reduced-form VAR(p)\nmodel:\nZt\n+ . . . + p\nZt-p\n+ ut\n= \u00b5 + B Zt\n+ ut\n.\nConsequently, \u00b5 = A-1\nc\nc, i\nc\nAi\nand ut\nc\nt\n. Let B = (1\n, . . . , p\n) and\nB(z) = 1 - p\nj\nzj. We then make the following assumptions on the MF-VAR:\nAssumption 1. Zt\nis generated by the MF-VAR(p) in (4), for which it holds that (i) the\nroots of the matrix polynomial B(z) all lie outside the unit circle; (ii) ut\nis independent\nand identically distributed (i.i.d.) with E(ut\n) = 0, E(ut\nut\n) = u\n, with u\npositive definite,\nand E(||ut\n||4) < , where || \u00b7 || is the Frobenius norm.\nAssumption 1(i) ensures that the MF-VAR is I(0), while (ii) is a standard assumption\nto ensure validity of the bootstrap for VAR models, see, e.g., Paparoditis (1996), Kilian\n(1998) or Cavaliere, Rahbek, and Taylor (2012). For the derivation of the limit distribution\nof the test statistics (ii) could be weakened (e.g., Ghysels et al., 2015b), but as we rely on\n3Compared to Ghysels (2015) we simply reverse the mixed-frequency vector Zt\nand put the low-\nfrequency variable first.\n= 0 implies that yt\nis affected by incoming observations of X(m)\nt\n, whereas j\n= 0 implies that\nthe high-frequency observations are influenced by yt\n(see G\u00a8\ninteresting for studying policy analysis, where the high-frequency policy variable(s) may react to current\nlow-frequency conditions (see Ghysels, 2015 for details). Note that G\u00a8\na noncausal MF-VAR in which one allows for non-zero elements in the lead coefficients of the Ac\nmatrix.\nthe aforementioned literature to establish the asymptotic validity of our bootstrap tests\nproposed in Section 3.1.4, we assume i.i.d. error terms here.\nRemark 2. Assumption 1 implies that the data are truly generated at mixed frequencies.\nHence, similar to Ghysels et al. (2015a) but unlike Ghysels et al. (2015b), we do not start\nwith a common high-frequency data generating process (DGP hereafter).5 The latter\nwould imply causality patterns to arise at the high frequency. Consequently, we do not\ninvestigate which causal relationships at high frequency get preserved when moving to\nthe mixed- or low-frequency case. Indeed, an extension of our methods along these lines\nwould demand a careful analysis of the mixed- and low-frequency systems corresponding\nto their latent high-frequency counterpart (see Ghysels et al., 2015b for the unrestricted\nVAR case).\nEquation (4) is easy to estimate for small m, yet becomes a rather large system as the\nlatter grows. For example, in a MF-VAR(1),\n\n\n\n\n\n\n\n\nyt\nx(m)\nt\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n=\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n+\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\n\n\n\n\n\n\u00d7\n\n\n\n\n\n\n\n\nx(m)\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n+\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n,\nut\ni.i.d.\n, u\n), u\n=\n\n\n\n\n\n. . .\n.\n.\n.\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\n\n\n\n\n\nthere are (m+1)2 parameters to estimate in the matrix 1\n. Additional lags would further\ncomplicate the issue.\n5Given such a situation it would seem natural to cast the model in state space form and estimate\nthe parameters using the Kalman filter. However, this amounts to a 'parameter-driven' model (Cox,\nGudmundsson, Lindgren, Bondesson, Harsaae, Laake, Juselius, and Lauritzen, 1981), which contains\nlatent processes, i.e., the high-frequency observations of y. The latter is a feature we try to avoid in our\nMF-VAR: say we are interested in the impact of shocks to one or several variables on the whole system.\nUsing a high-frequency DGP with missing observations implies that shocks to these latent processes are\nalso latent and unobservable. This is undesirable given that, e.g., policy shocks are, of course, observable\n2.3 Granger Causality in MF-VARs\nLet t\nrepresent the information set available at moment t and let W\nt\ndenote the cor-\nresponding set excluding information about the stochastic process W. With P[X(m)\nt+h\n|]\nbeing the best linear forecast of X(m)\nt+h\nbased on , Granger non-causality is defined as\nDefinition 1. y does not Granger cause X(m) if\nP[X(m)\n|y\nt\n] = P[X(m)\n|t\nSimilarly, X(m) does not Granger cause y if\n|X(m)\nt\n] = P[yt+1\n|t\nIn other words, y does not Granger cause X(m) if past information of the low-frequency\nvariable do not help in predicting current (or future) values of the high-frequency variables\nand vice versa (Granger, 1969). In terms of (5), testing for Granger non-causality implies\nthe following null (and alternative) hypotheses:\n\u00b7 y does not Granger cause X(m)\nHA\n= 0 for at least one i = 2, . . . , m + 1.\n\u00b7 X(m) does not Granger cause y\nHA\n= 0 for at least one i = 2, . . . , m + 1.\n3 Parameter Reduction\nThis section presents techniques that we have considered, and evaluated through a Monte\nCarlo exercise, with the aim to reduce the amount of parameters to be estimated in the\nMF-VAR model. Two approaches are discussed in detail, reduced rank restrictions and a\nBayesian MF-VAR.\nThere are many alternative approaches to reduce the number of parameters among\nwhich are principal components, Lasso (Tibshirani, 1996) or ridge regressions (Hoerl and\nKennard, 1970, among others). However, using principal components does not necessarily\npreserve the dynamics of the VAR under the null: nothing prevents, e.g., the first and\nonly principal component to be loading exclusively on y implying that the remaining\ndynamics enter the error term. In other words, the autoregressive matrices in (4) may\nand will most likely not be preserved, which naturally affects the block of parameters we\ntest on for Granger non-causality. As for Lasso and ridge regressions, it is well known\nthat they may be interpreted in a Bayesian context. In particular, the latter is equivalent\nto imposing a normally distributed prior with mean zero on the parameter vector (Vogel,\n2002, among others), while the former may be replicated using a zero-mean Laplace prior\ndistribution (Park and Casella, 2008). Given that our set of models contains a Bayesian\nVAR for mixed-frequency data, we abstract from its connection to regularized versions of\nleast squares at this stage. Developing a system version of Marsilli (2014) and justifying\nit from a Bayesian point of view, however, constitutes an interesting avenue for future\nresearch.\n3.1 Reduced Rank Restrictions\n3.1.1 Reduced Rank Regression Model\nIn order to reduce the number of parameters to estimate in the MF-VAR, we propose the\nfollowing reduce rank regression model, for which we make the following assumption:\nAssumption 2. Let BX(m)\nbe the matrix obtained from B in (4) by excluding the first\ncolumns of 1\n, . . ., p\n. The rank of this matrix is smaller than the number of high-\nfrequency observation within Zt\n, i.e.,\nrk(B\nX(m)\n) = r < m.\nThe model then reads as follows:\nZt\ny\nt\n+  p\n (m)\ni t-i\n+ t\ny\nt\n+  X(m)\nt\n+ t\n,\nis the (m + 1) \u00d7 p matrix containing the first columns of 1\n, . . . , p\n, and \n, . . . , p\n) are (m + 1) \u00d7 r and pm \u00d7 r matrices, respectively. Note that (11)\ncan also be written in terms of Zt\n. Let us define i\n ((i)\n, i\n), where (i)\n, i = 1, . . . , p,\ncorresponds to the ith column of \u00b7,1\n. Then, (11) is equivalent to\nZt\n= \u00b5 + B Zt\n+ t\nwhere B = (1\n, . . . , p\n) . For p = 1 the models becomes\n\n\n\n\n\n\n\n\nyt\nx(m)\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n= \u00b5 +\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n+\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n\n\n\n\n\n\nx(m)\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n+ t\n= \u00b5 +\n\n\n\n\n\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n,\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n\n\n\n\n\n\u00d7\n\n\n\n\n\n\n\n\nx(m)\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n+ t\n,\nwhere each i\n, i = 1, . . . , m + 1, is of dimension 1 \u00d7 r and where 1\nis an m \u00d7 r matrix.\nHence, we could call  X(m)\nt\na vector of r high-frequency factors. Note that r = m - s,\nwhere s represents the rank reduction we are able to achieve within X(m)\nt\n. In terms of\nparameter reduction, the unrestricted VAR in (4) requires p(m + 1)2 coefficients to be\nestimated in the autoregressive matrices, whereas the VAR under reduced rank restrictions\nin (11) or (12) needs p(m + 1) + r(m + 1) + prm parameter estimates. As an example,\ncoefficients to be estimated in 1\nin. Note that we do not require\nto be included in the same transmission mechanism as the x variables.\nRemark 3. There are several ways to justify the reduced rank feature of the autoregressive\nmatrix BX(m)\n. First, at the model representation level we may assume that, in the struc-\ntural model (3), x follows an AR(q) process with q < m and that the last m - q elements\nof each X(m)\nt-i\n, i = 1, . . . , p, have a zero coefficient in the equation for yt\n. Plugging these\nrestrictions into (4) results in a reduced rank of B\nX(m)\nbecause matrices i\nc\nAi\nhave\nthe rank of Ai\n. Second, at the empirical level one can interpret the MF-VAR as an ap-\nproximation of the VARMA obtained after the block marginalization of a high-frequency\nVAR for each variable. In this situation, reduced rank matrices may empirically not be\nrejected by the data because of the combinations of many elements. Thus, a small number\nof dynamic factors can approximate more complicated (possibly nonlinear) dynamics. Fi-\nnally, the way one typically restricts the MF-VAR in (4), i.e., assuming the high-frequency\nseries to follow an ARX-process (Ghysels, 2015), actually implies a reduced rank repre-\nsentation. Looking slightly ahead, consider Equation (25) or the matrix in (29), which\nwe will use in our Monte Carlo section, for the special case p = 1. It is obvious that for\nfirst order MF-VAR, Zt\n+ ut\n, with\n=\n\n\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\n\n\n\n\n\n\n\n\nwe have, due to the block of zeros, a reduced rank matrix BX(m)\nwith two (restricted\ncoefficient) factors:\nrk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n= rk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhere A is a 2\u00d72 full rank rotation matrix, the identity in this particular example. Hence,\nunder HA\n, e.g., two factors (although unrestricted in our setting) will capture the reduced\nrank feature. Note that we could impose (overidentifying) restrictions to retain the large\nblock of zeros in 1\n. In that sense, the model with r = 2 would not be misspecified but\n\"suboptimal\". On the other hand, with merely one factor we would not be able to impose\nthe block of zeros implying the model to be misspecified. Under the null hypothesis the\nmodel is not misspecified with either one or two factors, because the test tries to capture\nsome dynamics that is not there.\nNote that our focus is to compare the performance of different approaches including\ntheir bootstrap versions (whenever applicable) and that in this light we view reduced\nrank regressions as just one particular specification. In particular, next to the Bayesian\nMF-VAR and the max-test, our bootstrap implementation has also made the unrestricted\nMF-VAR (which is not subject to rank misspecification) a viable option to compare the\nreduced rank regressions with.\n3.1.2 Testing for Granger Non-Causality\nGiven r and Assumption 2, under the condition that the high-frequency factors  X(m)\nt\nare\nobservable, we can estimate (11) by OLS. Letting  = (^\n\u00b5, ^\n, ^\n) denote the corresponding\nOLS estimates, we can test for Granger non-causality by defining R as the matrix that\npicks the set of coefficients we want to do inference on, i.e., Rvec(). For a general\nconstruction of the matrix R in the presence of several low- and high-frequency variables,6\nwe refer the reader to Ghysels et al. (2015b). The Wald test is constructed as\nW\n= Rvec() (R^\nwith\n^\n = (W W)-1  ^\nu\nwhere ^\nu\nT\n^\nu ^\nu is the empirical covariance matrix of the disturbance terms and W =\n, . . . , WT\n) is the regressor set consisting of Wt\nt\n,  X(m)\nt\n) .7 As illustrated in\nis asymptotically 2\nrank(R)\n. A robust version of (14) is also\nimplemented in the empirical section.\nOf course, the factors are typically not observable and must be estimated (unless we\nimpose specific factors). Using estimated rather than observed factors in the regression\n(11) will obviously affect the distribution of W\n, certainly in small samples. For this reason\nwe consider bootstrap versions of the tests. Before going into the details on the bootstrap\nwe describe how we estimate or impose the factors.\nWe use three ways to estimate the factors, canonical correlation analysis (CCA hereafter),\npartial least squares (PLS hereafter) and heterogeneous autoregressive (HAR hereafter)\ntype restrictions. We briefly present the algorithms that are used to extract those factors.\nCCA is based on analyzing the eigenvalues and corresponding eigenvectors of\n^\n~\nX(m) ~\nX(m)\n^\n~\nX(m) ~\nZ\n^\n~\nZ ~\nZ\n^\n~\nZ ~\nX(m)\nor, similarly, of the symmetric matrix\n^\n~\nX(m) ~\nX(m)\n^\n~\nX(m) ~\nZ\n^\n~\nZ ~\nZ\n^\n~\nZ ~\nX(m)\n^\n~\nX(m) ~\nX(m)\n6Within the unrestricted MF-VAR in (4), though.\n7A sample size correction, i.e., using ^\nu\n^\nu ^\nu, where KW\nis the amount of elements in W,\nmay alleviate size distortions in finite samples.\nFor a detailed discussion we refer the reader to Anderson (1951) or, for the application\nto common dynamics, to Vahid and Engle (1993). Note that ^\nij\nrepresents the empirical\ncovariance matrix of processes i and j. Furthermore, ~\nZ and ~\nX(m)\nindicate Zt\nand X(m)\nt\n,\nrespectively, to be concentrated out by the variables that do not enter in the reduced rank\nregression, i.e., the intercept and yt-1\n. Denoting by ^\n, . . . , vr\n), with vi\nvj\ni = j and 0 otherwise, the eigenvectors corresponding to the r largest eigenvalues of the\nmatrix in (17), we obtain the estimators of  and  as:\n^\n = ^\n~\nZ ~\nZ\n^\n~\nZ ~\nX(m)\n^\n~\nX(m) ~\nX(m)\n^\nV\n^\n = ^\n~\nX(m) ~\nX(m)\n^\nV .\nNote that the estimation of the eigenvectors obtained from the canonical correlation\nanalysis in (16) or (17) may, however, perform poorly with high-dimensional systems,\nbecause inversions of the large variance matrices ^\n~\nZ ~\nZ\nand ^\n~\nX(m) ~\nX(m)\nare required. As\nan alternative to CCA we use a PLS algorithm similar to the one used in Cubadda and\nHecq (2011) or Cubadda and Guardabascio (2012). In order to make the solution of\nthis eigenvalue problem invariant to scale changes of individual elements, we compute the\neigenvectors associated with the largest eigenvalues of the matrix\n^\n~\nX(m) ~\nX(m)\n^\n~\nX(m) ~\nZ\n^\n~\nZ ~\nZ\n^\n~\nZ ~\nX(m)\n^\n~\nX(m) ~\nX(m)\nwith ^\nD~\nX(m) ~\nX(m)\nand ^\nD~\nZ ~\nZ\nbeing diagonal matrices having the diagonal elements of, respec-\ntively, ^\n~\nX(m) ~\nX(m)\nand ^\n~\nZ ~\nZ\nas their entries. The computation of ^\n and ^\n works in a similar\nfashion as with CCA-based factors.\nFinally, we may impose the presence of r = 3p factors,8 inspired by the Corsi HAR-\ni\n=\n\n\n\n\n\n\nm)\nm)\n\n\n\n\n\n\n  X(m)\nt\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx(m)\nx(m)\nx(m)\n.\n.\n.\nx(m)\nt-p\nx(m)\nt-p-i/m\nx(m)\nt-p-i/m\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor p = 1 and m = 20 this corresponds to\n X(m)\nt\n=\n\n\n\n\n\n\n\n\n\nxD\nxW\nxM\n\n8To ensure that r < m we assume that p < 1\nm at this stage.\nwith xD\nt\n, xW\nt\nand xM\nt\ndenoting daily, weekly and monthly measures, respectively.\ntype restrictions are a special case of MIDAS with step functions introduced in Forsberg\nand Ghysels (2007). Considering partial sums of regressors x as Xt\n(K, m) = K\nx(m)\nt-i/m\n,\na MIDAS regression with M steps reads as yt\n= \u00b5 + M\nj\nXt\n(Kj\n, m) + t\n, where K1\n<\n. . . < KM\n. Alternatively, we could use MIDAS restrictions as introduced in Ghysels et al.\n(2004), for the difference between the latter and HAR-type restrictions has been shown to\nbe small (Ghysels and Valkanov, 2012). However, step functions have the advantage of not\nrequiring non-linear estimation methods, since the distributed lag pattern is approximated\nby a number of discrete steps, thereby simplifying the analysis. Furthermore, and more\ncrucially in the context of this paper, implementing MIDAS restrictions and testing for\nGranger non-causality implies the well-known Davies (1987) problem, i.e., the parameters\ndetermining the MIDAS weights (see Ghysels et al., 2004 for details) are not identified\nunder the null hypothesis.9\nDespite the dimensionality reduction achieved by imposing the factor structure, a consid-\nerable number of parameters remains to be estimated for conducting the Wald tests such\nthat the tests may still be subject to considerable small sample size distortions. Moreover,\nthe estimation of the factors will have a major effect on the distribution of the Wald test\nstatistic. We therefore also consider a bootstrap implementation of these tests to improve\nthe properties of the tests in finite samples.\nLet B =  denote the estimates of B obtained by one of the reduced rank methods,\nand assume that  is normalized such that its upper r \u00d7 r block is equal to the identity\nmatrix.10 The first bootstrap method we consider is a standard \"unrestricted\" bootstrap,\nthat may have superior power properties in certain cases (cf. Paparoditis and Politis,\n1. Obtain the residuals from the MF-VAR(p)\n~\nt\n= Zt\n- ^\n\u00b5 + B Zt\n2. Draw the bootstrap errors \n, . . . , \nT\nwith replacement from ~\n, . . . , ~\ny,T\n.\n3. Letting Z\nt\n= (Z\n, . . . , Z\nt-p\n) , construct the bootstrap sample Z\nt\nrecursively as\nZ\nt\n= ^\n\u00b5 + B Z\nt\n+ \nt\n, t = 1, . . . , T, Z\n9To properly test for Granger non-causality in this case, a grid for the weight specifying parameter\nvector has to be considered and the corresponding Wald tests for each candidate have to be computed.\nSubsequently, one can calculate the supremum of these tests (Davies, 1987) and obtain an 'asymptotic\np-value' using bootstrap techniques (see Hansen, 1996 or Ghysels et al., 2007 for details). While this\napproach is feasible, it is computationally more demanding. Admittedly, HAR-type restrictions provide\nless flexibility than the MIDAS approach, yet their simplicity makes them very appealing from an applied\nperspective.\n10This ensures that the rotation of the factors is the same for the original sample and the bootstrap\nsample, which ensures for the first bootstrap method that the correct bootstrap null hypothesis is imposed.\nIn the simulations we experimented with different normalizations which didn't change any results.\nNote that the null hypothesis in the bootstrap is not imposed which has conse-\nquences for the next step.\n4. Estimate the bootstrap equivalent of (11), where the factors are estimated using\nthe same method as for the original sample, and obtain the bootstrap Wald test\nstatistic \nW\n. As the \"true\" bootstrap parameters governing the Granger causality\nare different from zero, we need to adapt the bootstrap Wald test such that it tests\nthe correct null hypothesis. Observing that those parameters form a subset of the\nestimates in  used in (22), the appropriate Wald test statistic is\n\nW\n= Rvec(\n) - Rvec() (R^\nR )-1 Rvec(\nwhere all quantities with a superscript `*' are calculated analogously to their sample\ncounterparts but then using the bootstrap sample.\n5. Repeat steps 2 to 4 B times, and calculate the bootstrap p-value as the proportion\nof bootstrap samples for which \nW\n> W\n.\nWhile this bootstrap method has the advantage that it can be used for testing Granger\ncausality in both directions (as only the matrix R needs to change), it also has some\ndrawbacks. In particular, even with the dimensionality reduction provided by the reduced\nrank estimation, it still relies on the generation of a bootstrap sample based on an (m+1)-\ndimensional MF-VAR(p) that requires p(m+1)+r(m+1)+prm parameters to estimate.\nThis may make the bootstrap unstable and prone to generate outlying samples, with\npotential size distortions or a loss of power as a result.\nTherefore we consider a second bootstrap method that imposes the null hypothesis of\nno Granger causality and in doing so achieves a further significant reduction of dimen-\nsionality. A downside of this method is that it requires separate bootstrap algorithms\nfor testing in the two opposite directions. We describe the procedure here for the null\nhypothesis that X(m) does not Granger cause y; we comment on the test in the opposite\ndirection below.\n1. Estimate an AR(p) model for y and obtain the residuals\n~\nuy,t\n= yt\n- ^\n\u00b5 -\np\n^\ny,j\nyt-j\n, t = p + 1, . . . , T.\n2. Draw the bootstrap errors u\n, . . . , u\nT\nwith replacement from ~\n, . . . , ~\nuy,T\n.\n3. Construct the bootstrap sample y\nt\nrecursively as\ny\nt\n=\np\n^\ny,j\ny\n+ u\nt\n, t = 1, . . . , T, y\nthus imposing the null of no Granger causality from X(m) to y.\n4. Letting X(m)\nt\n= X(m)\nt\n, use the bootstrap sample to estimate the MF-VAR using the\nsame estimation method as for the original estimator, and obtain the corresponding\nWald test statistic \nW\n. As the null hypothesis of no Granger causality has been\nimposed in the bootstrap, \nW\nnow has the same form as W\nNote that only p parameters need to be estimated in order to generate the bootstrap\nsample, most likely making the procedure more stable than the unrestricted bootstrap\nabove. A similar bootstrap procedure can be implemented for the reverse direction of\ncausality by only resampling X(m)\nt\nwhile keeping yt\nfixed. As one can resample X(m)\nt\nindependently of yt\n, it can be done in the original high-frequency as a univariate process.\nSaid differently, it only requires fitting an AR(q) process to x(m)\nt\n, again achieving a large\nreduction of dimensionality.\nIt is also possible in step 2 of both algorithms to use the wild bootstrap to be\nrobust against heteroskedasticity. In this case the bootstrap errors are generated as\nu\nt\n= \nt\n~\nut\nwhere we generate \n, . . . , \nT\nas independent standard normal random variables.\nThis would constitute the so-called \"recursive wild bootstrap\" scheme that Br\u00a8\nuggemann,\nJentsch, and Trenkler (2014) prove to be asymptotically valid under conditionally het-\neroskedastic errors. In particular, employing the wild bootstrap then allows us to replace\nthe i.i.d. assumption in Assumption 1 with the martingale difference sequence assumption\nin Assumption 2.1 of Br\u00a8\nuggemann et al. (2014). We implement the wild bootstrap version\nin the empirical application in Section 5.\nunrestricted VAR bootstrap under Assumption 1. The validity of the restricted bootstrap\ncan be derived from the results for AR(p) processes in Bose (1988), and the observation\nthat conditioning is a valid approach in the absence of Granger causality. Van Giersbergen\nand Kiviet (1996) provide a detailed examination of the two different types of bootstraps\nin the context of ADL models and demonstrate that the restricted bootstrap even works\nwell in the absence of strong exogeneity.11\nRemark 6. Gon\u00b8\ncalves and Perron (2014) consider factor-augmented regression models,\nwith the factors estimated by principal components. In this setting the asymptotic im-\npact of factor estimation depends on which asymptotic framework is assumed. Under\nthe asymptotic framework, in which factor estimation has a non-negligible effect on the\nlimit distribution of the regression estimators, the bootstrap correctly mimics this ef-\nfect and is therefore asymptotically valid. Consequently, the bootstrap provides a much\nmore accurate approximation to the finite sample distribution of the regression estimators\nthan the asymptotic approximation, that assumes a negligible effect of factor estimation.\nWe expect the bootstrap to have similar properties in our setting where the factors are\nestimated using CCA or PLS.\n3.2 Bayesian MF-VARs\nGhysels (2015) discusses the issue of parsimony in MF-VAR models by specifying the high-\n11If the test statistic (14) is asymptotically pivotal, we may expect the bootstrap to provide asymptotic\nrefinements as well and, hence, reduce small sample size distortions (cf. Bose, 1988; Horowitz, 2001).\nfrequency process in such a way as to allow a number of parameters that is independent\nfrom m. Indeed, while it seems reasonable to leave the equation for yt\nis less clear for the remaining ones. Hence, let us make the following assumption (see\nAssumption 3. The high-frequency process x(m)\nt\nfollows an AR(1) model with one lag\nof the low-frequency variable in the regressor set\nx(m)\nt-i/m\n+ x(m)\nfor i = 0, . . . , m - 1.\nCompleting the system with the equation for yt\nleads to the following restricted MF-\n\n\n\n\n\n\n\n\nyt\nx(m)\nt\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n=\n\n\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n\n\n+\n\n\n\n\n\n\n\ni m\n.\n.\n.\n.\n.\n.\n \n\n\n\n\n\n\n\n\u00d7\n\n\n\n\n\n\n\n\nx(m)\nx(m)\n.\n.\n.\nx(m)\n\n\n\n\n\n\n\n\n+ p\n(k)\n(k)\n. . . (k)\n\u00d7\n\n\n\n\n\nyt-k\nx(m)\nt-k\n.\n.\n.\nx(m)\nt-k-(m-1)/m\n\n\n\n\n\n+\n\n\n\n\n\n\n\n.\n.\n.\n\n\n\n\n\n\n\n\nt\n,\nwhere (k)\ni,j\ncorresponds to the (i, j)-element of matrix k\nin (4). As for the error terms\nit\n, i = 1, . . . , m + 1, we set E(it\nit\n) = HH\nit\n) = HL\nfor i = 2, . . . , m + 1, and\n) = LL\n. Furthermore, each error term is assumed to possess a zero mean and\nto be normally distributed. Consequently, \nt\n, \n), whereby we refer the\nreader to Ghysels (2015) for the exact composition of \n.\n12In fact, viewed as single equation, it boils down to an unrestricted MIDAS model (Foroni, Marcellino,\nand Schumacher, 2015) without contemporaneous observations of the high-frequency variable. MIDAS\nrestrictions (Ghysels et al., 2004) can be imposed here as an alternative. However, doing so implies leaving\nthe linear framework, which is needed to apply the auxiliary dummy variable approach presented below.\nFurthermore, even after having drawn the MIDAS hyperparameters, one still faces the aforementioned\nDavies (1987) problem when attempting to test for Granger non-causality from X(m) to y.\n3.2.2 The Auxiliary Dummy Variable Approach for Mixed-Frequency Data\nAs pointed out by Carriero, Kapetanios, and Marcellino (2011), Bayesian methods allow\nthe imposition of restrictions such as the ones in Assumption 3, while also admitting\ninfluence of the data. Consequently, Bayesian shrinkage has become a standard tool\nwhen being faced with large-dimensional estimation problems such as large VARs (e.g.,\ndescribes a way to sample the MIDAS hyperparameters and subsequently formulates\nprior beliefs for the remaining parameters.13 Once these hyperparameters are taken care\nof, the Bayesian analyses of mixed- and common-frequency VAR models are quite similar\nand, hence, traditional Bayesian VAR techniques (e.g., Kadiyala and Karlsson, 1997,\nWe follow the approach of Banbura et al. (2010), which in turn is built on the work\nof Sims and Zha (1998), showing that adding a set of auxiliary dummy variables to the\nsystem is equivalent to imposing a normal inverted Wishart prior. The specification of\nprior beliefs is derived from the Minnesota prior in Litterman (1986), whereby we center\nthe prior distributions of the coefficients in B around the restricted MF-VAR in (25):\nE[(k)\ni,j\n] =\n\n\n\nm if i = j = k = 1\n,\nV ar[(k)\ni,j\n] =\n\n\n\nSLH\nSHL\nelse\n,\nwhere all (k)\ni,j\nare assumed to be a priori independent and normally distributed. The\ncovariance matrix of the residuals is for now assumed diagonal and fixed, i.e., u\n=\n = d\nwith d\nL\nH\n, . . . , 2\nH\n) of dimension m + 1. The tightness of the prior\ndistributions around the AR(1) specification in (24) is determined by ,14 the influence of\nlow- on high-frequency data and vice versa is controlled by  and, finally, Sij\ni\nj\n, i, j =\nL, H, governs the difference in scaling between y and the x-variables. For \u00b5 we take a\ndiffuse prior.\nRemark 7. As for the common-frequency case, the expressions for V ar[(k)\ni,j\nthat more recent (low-frequency) lags provide more reliable information than more dis-\ntant ones. However, due to the stacked nature of X(m)\nt\n, the coefficients could be shrunk\naccording to their high-frequency time difference instead. This implies specifying the\nlag associated with each coefficient in fractions of the low-frequency time index: yt\nand\nx(m)\n, e.g., are 1 + i/m low-frequency time periods apart such that the denominator\nin the corresponding coefficient's prior variance would equal (1 + i/m)2.\n13McCracken, Owyang, and Sekhposyan (2015) use a Sims-Zha shrinkage prior and the algorithm\nin Waggoner and Zha (2003) to solve the parameter proliferation problem with Bayesian estimation\ntechniques. Bayesian methods within mixed-frequency VARs were also considered by Schorfheide and\nSong (2015). However, they use a latent high-frequency VAR instead of the mixed-frequency system `\na la\n14  0 results in the posterior coinciding with the prior, whereas  =  causes the posterior mean to\ncoincide with the OLS estimate of the unrestricted VAR in (4).\nHowever, in the context of Granger causality testing such a specification is problematic\nas the coefficients to test on are shrunk in \"opposite directions\": yt\nand x(m)\nare\n1.5 t-periods apart, whereas x(m)\nare separated by only 0.5 low-frequency\nperiods. Consequently, for a given , the coefficients are shrunk much more when testing\nfor Granger causality from X(m) to y, especially for large m. This makes it difficult to\ncontrol the size of the respective tests in one or the other direction. The common-frequency\nhandling of the prior variances in (26) mitigates this issue, although some losses in power\nhave to be assumed.\nNote that a treatment of the mixed-frequency nature of the variables along the lines\noutlined above may well be advantageous in other circumstances (e.g., forecasting) such\nthat we present this approach in detail in Appendix A.15\nGiven the prior beliefs specified before, the analysis is very similar to the one in\nBanbura et al. (2010). In short, let us write the MF-VAR as\nZ = ZB + E,\nwhere Z = (Z\u00b5\n, . . . , Z\u00b5\nT\n) with Z\u00b5\nt\n= (Zt\n, . . . , ZT\n) , E = (u1\n, . . . , uT\n) and\nB = (B , \u00b5) . Then, one can show that augmenting the model by two dummy variables,\nYd\nand Xd\n, is equivalent to imposing a normal inverted Wishart prior that satisfies the\nmoments in (26). Finally, estimating the augmented model by ordinary least squares gives\nus the posterior mean of the coefficients, on which we can do inference as outlined in the\nnext subsection.\nNote that Xd\nis, in fact, identical to the matrix for the common-frequency VAR (Ban-\n, however, is slightly different due to the prior means being centered\naround the restricted VAR in (25):\nYd\n=\n\n\n\n\n\n\nmL\n/ . . . H\n/\ndiag(L\n, H\n, . . . , H\n)\n\n\n\n\n\n\n,\nAugmenting the model is then achieved by setting Z\n= (Z , Yd\n) and Z\n= (Z , Xd\n) .\n3.2.3 Testing for Granger Non-Causality\nIn terms of analyzing the Granger non-causality testing behavior within the Bayesian\nMF-VAR, the auxiliary dummy variable approach is quite appealing, as it provides a\nclosed-form solution for the posterior mean of the coefficients. It is thus straightforward\nto compare the testing behavior with the ones from alternative approaches using the Wald\n15When extending the approach we stick to the standard structure of the Minnesota prior in Litterman\n(1986). It is, however, also feasible to address the aforementioned issue by introducing, say, three hyper-\nparameters: 1\ngoverning the prior tightness for the coefficients determining Granger causality from y to\nX(m)\nt\nfor parameters controlling causality in the reverse direction and 3\ntaking care of the remain-\ning coefficients. This strategy is, however, a rather straightforward extension of the theory presented in\nAppendix A such that we do not present it here.\ntest.16 The latter is derived analogously to the one in (14), and is, given Assumption 3,\nalso asymptotically 2\nrank(R)\n-distributed.\nRemark 8. Because the parameter vector vec(B) is not assumed fixed but random, con-\nstruction of the test statistic, and especially its interpretation, need to be treated with\nspecial care. We consider Bayesian confidence intervals, in particular highest posterior\ndensity (HPD) confidence intervals (Bauwens, Lubrano, and Richard, 2000), the tightness\nof which is expressed by , not coincidentally the same letter that denotes the significance\nlevel in the frequentist's framework. Here, it is interpreted such that (1-)% of the prob-\nability mass falls within the respective interval. In other words, the probability that a\nmodel parameter falls within the bounds of the interval is equal to (1-)%. The interval\ncentered at the modal value for unimodal symmetric posterior densities is then called the\nHPD (Zellner, 1996 or Bauwens et al., 2000). The connection to Wald tests is now im-\nmediate using the equivalence between confidence intervals and respective test statistics,\nwhereby similar care is demanded when interpreting results.\n3.3 Benchmark Models\nBefore the introduction of MIDAS regression models, high-frequency variables were usu-\nally aggregated to the low frequency in order to obtain a common frequency for all\nvariables appearing in a regression (Silvestrini and Veredas, 2008 or Marcellino, 1999).\nLikewise for systems, a monthly variable, for example, was usually aggregated to, say,\nthe quarterly frequency such that a VAR could be estimated in the resulting common\nlow frequency. Formally, xt\n= W(L1/m)x(m)\nt\n, where W(L1/m) denotes a high-frequency\nlag polynomial of order A, i.e., W(L1/m)x(m)\nt\n= A\nwi\nx(m)\nt-i/m\n(Silvestrini and Veredas,\n2008).17 As far as testing for Granger non-causality is concerned, we can rely on the Wald\nstatistic in (14), where the set of regressors, the matrix R and the coefficient matrix are\nsuitably adjusted.\nRemark 9. Naturally, such temporal aggregation leads to a great reduction in parame-\nters. After all, each set of m high-frequency variables per t-period is aggregated into one\nlow-frequency observation. Of course, this decrease in parameters comes at the cost of\ndisregarding information embedded in the high-frequency process. As argued in Miller\n(2011), if the aggregation scheme employed is different from the true one underlying the\nDGP, potentially crucial high-frequency information will be forfeited. Additionally, ag-\ngregating a high-frequency variable may lead to 'spurious' (non-)causality in the common\nlow-frequency setup (Breitung and Swanson, 2002), since causality is a property which is\n16There is a large sample correspondence between classical Wald and Bayesian posterior odds tests\n(Andrews, 1994). For certain choices of the prior distribution, the posterior odds ratio is approximately\nequal to the Wald statistic. Andrews (1994) shows that for any significance level  there exist priors such\nthat the aforementioned correspondence holds, and vice versa.\n17This generic specification nests the two dominating aggregation schemes in the literature, Point-in-\n= 1) and Average sampling (A = m - 1, wi\n= 1/m i), where the former is usually\napplied to stock and the latter to flow variables. In view of the high-frequency variable we consider in\nour empirical application, the natural logarithm of bipower variation, we focus on Average sampling in\nthis paper.\nIndependently and simultaneously to this work, Ghysels et al. (2015a) have developed\na new Granger non-causality testing framework, whose parsimonious structure makes it\nvery appealing in a situation, where m is large relative to the sample size. In short,\nthe idea is to focus on the first line of the MF-VAR in (4), but rather than estimating\nthat (U)-MIDAS equation (Foroni et al., 2015) and test for Granger non-causality in the\ndirection from X(m) to y, the authors propose to compute the OLS estimates of j\nin the\nfollowing h separate regression models:\nyt\n= \u00b5 +\nq\nk,j\nyt-k\nx(m)\n+ vj\n, j = 0, . . . , h - 1,\nwhereby h needs to be set \"sufficiently large\" (to achieve h > pm). The corresponding\nmax-test statistic is then the properly scaled and weighted maximum of {^\n, . . . , ^\nh\n}.\nAlthough it has a non-standard limit distribution under H0\n, an asymptotic p-value may\nbe obtained in a similar way as when overcoming the Davies (1987) problem (see Remark\n4). Testing for Granger non-causality in the reverse direction works analogously in the\nfollowing regression model:\nyt\n= \u00b5 +\nq\nk,j\nyt-k\n+\nh\nk,j\nx(m)\n+ j\nx(m)\nt+j/m\n+ vj\n, j = 1, . . . , l.\nAgain, the corresponding max-test statistic is the maximum of {^\n, . . . , ^\nl\n} scaled and\nweighted properly.18\nFinally, we can attempt to estimate the full MF-VAR in (4) ignoring the possibility that\nthe amount of parameters may be too large to perform accurate estimations or adequate\nGranger non-causality tests. To this end we estimate the MF-VAR using ordinary least\nsquares disregarding the potential parameter proliferation problem. In this sense the\ncomparison is related to the one of U-MIDAS (Foroni et al., 2015) and MIDAS regression\nmodels for large m. We can test for Granger non-causality using the Wald statistic in\n(14). Again, W, R and B have to be adjusted adequately. We also consider a bootstrap\nversion of the unrestricted MF-VAR, which we expect to alleviate size distortions, but\nwhich cannot solve power issues due to the parameter proliferation.\nk,j\nx(m)\nmay be imposed to increase\nparsimony. Note that the aforementioned Davies problem does not occur due to testing for Granger\nnon-causality by looking at the OLS estimates of j\n. Furthermore, Ghysels et al. (2015a) argue that m\ncontemporaneous high-frequency observations of x should be included as instruments in order to handle\nsimultaneity between y and x.\n4 Monte Carlo Simulations\nIn order to assess the finite sample performance of our different parameter reduction\ntechniques, we conduct a Monte Carlo experiment. In light of our empirical investigation\nwe set m = 20, i.e., as in a month/ working day-example.19 Furthermore, we start by\ninvestigating the case where p = 1 and keep the analysis of higher lag orders for future\nresearch.\nAs far as investigating the size of our Granger non-causality tests is concerned, we\nassume that the data are generated as a mixed-frequency white noise process, i.e.,\nZt\n= ut\nRemark 10. Additionally, we have considered three alternative DGPs for size, all based\non the restricted VAR in (25): (i) 1,i\n= \n= 0 ('diagonal'), (ii) 1,i\n('only Granger non-causality from X(m) to y') or (iii) \n= 0 ('only Granger\nnon-causality from y to X(m)') i = 2, . . . , 21, where the parameters 1,i\nand \nrefer to\n(29). However, with the respect to the respective testing direction, the outcomes do not\ndiffer qualitatively and quantitative differences are very small. Results are available upon\nrequest.\nTo analyze power we generate two different DGPs that are closely related to the\nrestricted VAR in (25):\nZt\n= P\n+ ut\nwith\nP\n=\n\n\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n...\n.\n.\n.\n\n\n\n\n\n\n\n\n= w\n() =\ncorresponds to the two-dimensional exponential Almon lag polynomial with\nthe first parameter set to zero (Ghysels et al., 2007). Now, for the first power DGP we\nsimply set w\ni\n() = wi\n(), whereas in the second power DGP w\ni\n() = wi\n()-w() with\nthe horizontal bar symbolizing the arithmetic mean. As far as \nis concerned we take\n\n(first power DGP) and \n(second power DGP) for j = 2, . . . , 21,\nwhereby j,1\nand\n\n19See Section 5 for a justification of the time-invariance of m within this setup.\n20The parameter values have been chosen to mimic part of the structure of the restricted VAR in (25)\nand to ensure stability of the system. In the first DGP late xt-1\n-observations have a larger impact on yt\n,\nand positive values of yt-1\nincrease x towards the end of the current period, but hardly have an impact\nat the beginning. In the second power DGP a zero-mean feature is imposed on the coefficients w\n()\nand \nwithout changing the general pattern of their evolvement.\nFigure 1: Parameter values for 2w\nRemark 11. Due to the zero-mean feature of w\n() and \n, j = 2, . . . , 21, in the second\npower DGP, we expect the presence of Granger causality to be 'hidden' when Average\nsampling the high-frequency variable (see Section 3.3.1). It is thus a situation, in which\nclassical temporal aggregation is expected not to preserve the causality patterns in the\ndata (Marcellino, 1999). The first power DGP serves as a benchmark in the sense that\nwe do not a priori expect one approach to be better or worse than the others.\ncorresponding to roughly 4, 21 and 42 years of monthly data. Note that an additional\n100 monthly observations are used to initialize the process. As far as the error term\nis concerned, we assume ut\n, u\n), where u\nhas the same structure as the\ncovariance matrix of the restricted VAR in (25) with LL\nFor CCA and PLS we consider r = 1, 2 and leave the analysis of higher factor di-\nmensions for further research. Recall from Remark 3 that under H0\nthe model is not\nmisspecified with either amount of factors. Under HA\n, however, the model is misspecified\nfor r = 1, but not for r = 2. In that sense, we implicitly analyze the impact of mis-\nspecification, stemming from choosing r too small, on the behavior of the respective test\nstatistics. As far as the Bayesian approach is concerned, we experimented with various\nvalues for the hyperparameter and found  = 0.175 to be a good choice. Furthermore,\nwe approximate  by running a corresponding univariate regression. For the max-test we\ntake q = 1 and h = l = m = 20.\nWe consider different variants of our size and power DGPs by varying the values\nof HL\nand . To be more precise, we choose HL\nproperties of our tests in both directions. A value of zero implies the absence of nowcasting\ncausality, whereas the other two values imply some degree of correlation between the low-\n21These values resemble the data in the empirical section, where ^\nLL\nHH\nand high-frequency series. For both power DGPs we fix HL\ninvestigating Granger causality testing from X(m) to y in the first power DGP we consider\n = 0.5, 0.8, 2; in the second power DGP we only take the  = 0.5. For causality in the\nreverse direction we take 2,1\n= 0.2 in both power DGPs, because the results do not seem\nsensitive in this respect.\nThe figures in the tables below represent the percentage amount of rejections at  =\nthe bootstrap versions we use B = 499.\nTables 1 and 2 contain the size results for Granger non-causality tests within the following\napproaches: the low-frequeny VAR (LF), the unrestricted VAR (UNR), reduced rank\nrestrictions using canonical correlations analysis (CCA) or partial least squares (PLS),\nand with three imposed factors using the HAR model (HAR), the max-test (max) and\nthe Bayesian mixed-frequency VAR (BMF). With respect to CCA and PLS, the outcomes\nfor r = 2 turn out to be qualitatively very similar to the r = 1 case, showing that the\nmethods are apparently not affected by the presence of misspecification. Consequently, we\nonly show the outcomes for r = 1 to save on space. Furthermore, aside from the results of\nthe standard Wald tests, we only display the outcomes for the best performing bootstrap\nvariant, which are denoted with a superscript `' (e.g., CCA is the bootstrap CCA-\nbased Wald test). In the case of testing causality in the direction from the high- to the\nlow-frequency series this turns out to be the bootstrap that imposes the null hypothesis,\nwhereas the unrestricted variant dominates for the reverse direction.23 For both methods\nwe set the lag length within the bootstrap equal to p = 1.\nWhen testing causality from y to X(m) size distortions may occur due to computing a\njoint test on mp parameters from m different equations in the system. In order to address\nthis issue, we take the maximum of the Wald statistics computed equation by equation.\nWe denote these tests by adding a subscript 'b', e.g., CCAb\n. For the tests with asymptotic\ncritical values we apply a Bonferroni correction to control the size under multiple testing\n(Dunn, 1961). In similar spirit as in White (2000), the bootstrap implementations of these\ntests automatically provide an implicit Bonferroni-type correction for multiple testing, as\nwe calculate the corresponding maximum of the single-equation Wald tests within each\nbootstrap iteration and compare that to the maximum of the original tests. We will refer\nto all these tests as `Bonferroni-type' tests to avoid confusion with the max-test, and\npresent the corresponding outcomes in Table 3.\nLet us start by analyzing the testing behavior from X(m) to y. First, LF has size\nclose to the nominal one, which is not surprising given that the flat aggregation scheme\nis correct in this white noise DGP (no matter the value of HL\n). The unrestricted VAR,\nhowever, incurs some size distortions for small T due to parameter proliferation. Reduced\nrank restrictions based on CCA and PLS yield considerable size distortions, whereby the\nimposed HAR-type factor structure delivers good results (despite being slightly oversized\n22Outcomes for  = 10% and  = 1% are available upon request.\n23The unrestricted bootstrap is seriously oversized testing causality from X(m) to y, while the other\nway around the bootstrap under the null is mildly oversized for small samples. All outcomes not shown\nhere are available upon request.\nTable 1: Size of Granger Non-Causality Tests from X(m) to y\nHL\nHL\nHL\nNote: For testing Granger non-causality from X(m) to y the figures represent percentages of rejections of the asymptotic Wald test statistics and the\nrestricted bootstrap variants (indicated with a superscript '*') of the following approaches: The low-frequeny VAR (LF), the unrestricted approach (UNR),\nreduced rank restrictions with one factor using canonical correlations analysis (CCA) or partial least squares (PLS), and with three imposed factors using\nthe HAR model (HAR), the max-test (max) and the Bayesian mixed-frequency approach (BMF). The lag length of the estimated VARs is equal to one.\nThe underlying DGP is found in (27), where the variance-covariance matrix of the error term is equal to u\nwith HL\nfor T = 50). Finally, max and BMF show almost perfect size, whereby the former is\nmarginally under- and the latter marginally oversized.\nTurning to the outcomes of the bootstrap versions we observe that, independent of the\nvalue of HL\n, even for T = 50 the actual size of the Wald tests within the unrestricted VAR\nand reduced rank restriction models with CCA- or HAR-type factors is very close to the\nnominal one, such that the bootstrap tests clearly dominate their asymptotic counterparts.\nFor PLS-based factors this conclusion only holds in the absence of nowcasting causality,\nand size distortions arise quickly as we increase the contemporaneous correlation between\nX(m) and y.\nMany of the aforementioned statements carry over to testing causality in the reverse\ndirection: LF delivering nearly perfect size (as it is the correct model under the null), max\nperforming very well (being only marginally oversized for small T) and BMF being a bit\noversized (by a slightly larger degree than in Table 1).24 The size distortions incurred by\nUNR, CCA, PLS and HAR are, however, amplified. The use of the Bonferroni-corrected\n, CCAb\n, PLSb\nand HARb\ncan only mitigate this effect, yet not fully eradicate it.\nThe bootstrap version does eliminate the size distrotions, though: actual size of UNR,\nPLS and HAR becomes oftentimes very close to 5%; only CCA remains a bit oversized\nfor T = 50. The Bonferroni-type tests UNR\nb\nb\nb\nand HAR\nb\nall have size very\nclose to the nominal one for all sample sizes.\nTo sum up, the Granger non-causality tests with size close to the nominal one are\nLF, max and BMF to some degree. Furthermore, these are UNR, CCA, PLS (with\nat most \"mild\" nowcasting causality) and HAR when testing the direction from X(m)\nto y, and UNR, CCA, PLS and HAR as well as their Bonferroni-type counterparts\nwhen testing the reverse direction. Consequently, these are the cases we focus on when\nanalyzing power (and when dealing with real data in Section 5).\nTables 4 and 5 contain the corresponding outcomes under the alternative hypothesis.\nRecall that for the direction from X(m) to y we consider three different values of  within\nthe first power DGP,  = 0.5, 0.8 and 2. For the second power DGP we fix  = 0.5. For\nthe reverse direction we always keep 2,1\nLet us again start with the direction from the high- to the low-frequency variable and\nfirst focus on the outcomes for the first power DGP, i.e., the top three blocks of Table 4.\nObserve (i) how power reaches one asymptotically for all approaches, and (ii) how larger\nvalues of  imply an increase in the rejection frequencies for a given T. Naturally, for a\nlarge enough  all tests have power equal to one, irrespective of the sample size (as nearly\nhappens for  = 2). So, in order to compare our different tests let us focus on  = 0.5.\nThe asymptotic Wald test within the low-frequency VAR still performs very well, with\nthe highest rejection frequency for T = 50. Note, however, that the Granger causality\nfeature in the data does not get averaged out by temporal aggregation in the first power\nDGP. The bootstrapped version of the Wald test after HAR-type restrictions have been\nimposed in a reduced rank regression perform almost as well as LF. max, BMF and\nPLS appear to fall a bit short, but catch up quickly as either T or  grows. A similar\n24Strangely, BMF seems to be rejected less and less for growing HL\n, with the effect being strongest\nfor small T.\nTable 2: Size of Granger Non-Causality Tests from y to X(m)\nHL\nHL\nHL\nNote: For testing Granger non-causality from y to X(m) the figures represent percentages of rejections of the asymptotic Wald test statistics and the\nunrestricted bootstrap variants (indicated with a superscript '*') of the following approaches: The low-frequency VAR (LF), the unrestricted approach\n(UNR), reduced rank restrictions with one factor using canonical correlations analysis (CCA) or partial least squares (PLS), and with three imposed\nfactors using the HAR model (HAR), the max-test (max) and the Bayesian mixed-frequency approach (BMF). The lag length of the estimated VARs is\nequal to one. The underlying DGP is found in (27), where the variance-covariance matrix of the error term is equal to u\nwith HL\nTable 3: Size of Granger Non-Causality Tests from y to X(m) (Bonferroni)\ny to X(m) T UNRb\nUNR\nb\nCCA\nb\nPLS\nb\nHAR\nb\nHL\nHL\nHL\nNote: For testing Granger non-causality from y to X(m) the figures represent percentages of rejections of the Bonferroni-type tests (indicated with a\nsubscript 'b') for both the asymptotic Wald test statistics and the unrestricted bootstrap variants (indicated with a superscript '*') of the following\napproaches: The unrestricted approach (UNR), reduced rank restrictions with one factor using canonical correlations analysis (CCA) or partial least\nsquares (PLS), and with three imposed factors using the HAR model (HAR) and the Bayesian mixed-frequency approach (BMF). For the low-frequency\nVAR (LF) and the max-test (max) the Bonferroni-type test is not applicable. The lag length of the estimated VARs is equal to one. The underlying\nDGP is found in (27), where the variance-covariance matrix of the error term is equal to u\nwith HL\nTable 4: Power of Granger Non-Causality Tests from X(m) to y\nX(m) to y T LF max BMF UNR CCA PLS HAR\nPower-DGP\nPower-DGP\nPower-DGP\nPower-DGP\nNote: For testing Granger non-causality from X(m) to y the figures represent percentages of rejections of the asymptotic Wald test statistics of the\nlow-frequeny VAR (LF), the max-test (max) and the Bayesian mixed-frequency approach (BMF). Furthermore, it contains percentages of rejections of\nthe restricted bootstrap variants (indicated with a superscript '*') of the unrestricted approach (UNR), reduced rank restrictions with one factor using\ncanonical correlations analysis (CCA) or partial least squares (PLS), and with three imposed factors using the HAR model (HAR). The lag length of the\nestimated VARs is equal to one. The underlying DGP is found in (28) or (29), where the variance-covariance matrix of the error term is equal to u\nwith\nHL\n= -0.05. In power-DGP 1 the Granger causality determining coefficients do not sum up to zero, whereas they do so in power-DGP 2. See Section 4\nobservation holds for UNR and CCA, whereby they seem to be markedly less powerful\nfor small T.\nThese conclusions generally carry over to the second power DGP, with two exceptions:\nFirst and foremost, the outcomes of LF show that Average sampling of X(m) annihilates\nthe causality feature between the series for all sample sizes (power actually almost coin-\ncides with the nominal size of 5%). Second, the rejection frequencies are lower than they\nwere in the corresponding setting of the first power DGP.\nTurning to the direction from y to X(m), it becomes obvious that the outcomes for\nthe first and second power DGP are, once again, similar, with the same two exceptions\nmentioned before. This being said and leaving aside the ones for LF due Granger causality\nnot being invariant to temporal aggregation (Marcellino, 1999), it suffices to analyze the\nresults of the first power DGP.\nBoth max and BMF have higher power than the bootstrapped Wald tests correspond-\ning to the reduced rank restrictions approaches. However, recall that BMF and max were\nsomewhat oversized, especially for small T, which may inflate their power. However, so\nfar we did not consider the Bonferroni-type tests based on the maximum of the individual\nWald tests. Given the way in which max is constructed though, it seems more natural\nto compare it to the Bonferroni-type counterparts of the bootstrap tests. Indeed, both\napproaches rely on a statistic that is computed as the maximum of a set of test statis-\ntics.25 Here it turns out that, for a given T, almost all approaches are more powerful\nthan max. The fact that UNR\nb\nb\nand HAR\nb\nare all slightly undersized for small T,\nwhile max is marginally oversized, even strengthens the aforementioned conclusions. Also\nnote that the bootstrap tests based on the reduced rank restrictions seem to be slightly\nmore powerful than UNR\nb\n, confirming again (though less pronounced than in the other\ndirection) that while the bootstrap can correct size of the unrestricted MF-VAR approach\nwell, the parameter proliferation problem continues to have a negative effect on power.\nCombining the power and size outcomes, it seems that BMF, HAR, max (for large\nenough  when T is small) and PLS (in the absence of nowcasting causality) are the\ndominant Granger non-causality testing approaches as far as the direction from X(m) to\ny is concerned. For the reverse direction of causality, CCA\nb\nb\nand HAR\nb\nas well as\nUNR\nb\nand max (though both to a lesser degree) appear superior.\n5 Application\nWe apply the approaches described in Section 3 to a MF-VAR consisting of the monthly\ngrowth rate of the U.S. industrial production index (ipi hereafter), a measure of busi-\nness cycle fluctuations, and the logarithm of daily bipower variation (bv hereafter) of the\nS&P500 stock index, a realized volatility measure more robust to jumps than the realized\nvariance. While the degree to which macroeconomic variables can help to predict volatility\nmovements has been investigated widely in the literature (see Schwert, 1989b, Hamilton\nand Gang, 1996, or Engle and Rangel, 2008, among others), the reverse, i.e., whether\nthe future path of the economy can be predicted using return volatility, has been granted\n25There is a difference in terms of the underlying regression to obtain the various test statistics, of\ncourse. Ghysels et al. (2015a) consider univariate MIDAS regressions with leads, whereas the Bonferroni-\ntype tests are based on estimated coefficients from different equations, i.e., the ones for X(m), of the\ncorresponding system regression.\nTable 5: Power of Granger Non-Causality Tests from y to X(m)\nb\nCCA\nb\nPLS\nb\nHAR\nb\nPower-DGP 1\nPower-DGP 2\nNote: For testing Granger non-causality from y to X(m) the figures represent percentages of rejections of the asymptotic Wald test statistics of the\nlow-frequeny VAR (LF), the max-test (max) and the Bayesian mixed-frequency approach (BMF). Furthermore, it contains percentages of rejections of\nthe unrestricted bootstrap variants (indicated with a superscript '*') of the unrestricted approach (UNR), reduced rank restrictions with one factor using\ncanonical correlations analysis (CCA) or partial least squares (PLS), and with three imposed factors using the HAR model (HAR). For the latter set of\napproaches, it also shows the outcomes for the Bonferroni-type tests (indicated with a subscript 'b'). The lag length of the estimated VARs is equal to one.\nThe underlying DGP is found in (28) or (29), where the variance-covariance matrix of the error term is equal to u\nwith HL\nthe Granger causality determining coefficients do not sum up to zero, whereas they do so in power-DGP 2. See Section 4 for details. 2,1\npower-DGPs.\ncomparably few attention (examples are Schwert, 1989a, Mele, 2007, and Andreou, Os-\nborn, and Sensier, 2000). Instead of using an aggregate measure of volatility such as, e.g.,\nmonthly realized volatilities (Chauvet, Senyuz, and Yoldas, 2015) or monthly GARCH es-\ntimated variances, we use daily bipower variation computed on 5-minute returns obtained\nfrom the database in Heber, Lunde, Shephard, and Sheppard (2009). With the bv-series\nbeing available at a higher frequency than most indicators of business cycle fluctuations,\nwe obtain the mixed-frequency framework analyzed in this paper.\nThe sample covers the period from January 2000 to June 2012 yielding a sample size\nof T = 150. We take m = 20 as it is the maximum amount of working days that is\navailable in every month throughout the sample we deal with.26 Consequently, we have\nt\nt\n) . Figure 2 plots the data.\nFigure 2: Growth Rate of Industrial Production Index and the logarithm of Bipower\nVariation\nNote: This figure shows the monthly growth rate of the U.S. industrial production index (lower line),\ni.e., ipi, and the logarithm of daily bipower variation of the S&P500 stock index (top lines), i.e., BV (20),\nfor the time period from January 2000 to June 2012. The graph for the former is shifted downwards to\nenable a visual separation of ipi from the bv-lines.\nTable 6 contains the outcomes of Granger non-causality tests for all approaches dis-\ncussed in Section 3. As mentioned before, we disregard the cases that showed considerable\n26Whenever a month contains more than 20 working days we disregard the corresponding amount of\ndays at the beginning of the month. In June 2012, e.g., there are 21 working days such that we do not\nconsider June 1. For May 2012 we disregard the first three days. An alternative (balanced) strategy would\nhave been to take the maximum number of days in a particular month (i.e., 23, usually in July, August\nor October) and to create additional values for non-existing days in other months whenever necessary.\nAs far as the treatment of daily data is concerned we have also taken bv(20)\nt\nwhen there are\nno quotations for bv(20)\nt\n.\nsize distortions in the Monte Carlo analysis. Note that a lag length of p = 1 and 2 is\nconsidered (the same for the bootstrap) and that the numbers represent p-values (in per-\ncentages). For reduced rank restrictions using CCA and PLS we consider one up to three\nfactors, whereby we only show the outcomes for r = 1 and r = 2 for representational ease;\nr = 3 gives similar results. For the non-bootstrap tests, except the max-test and the\nWald-test within the Bayesian mixed-frequency VAR,27 we also consider a heteroscedas-\nticity consistent variant of (14) by computing a robust estimator of  (see Ravikumar,\nRay, and Savin, 2000) to account for the potential presence of a time varying multivariate\nprocess:\n^\nR\n) ^\nwhere\n^\n=\nT\nT\n(Wt\n ^\nut\n) (Wt\n ^\nut\nFor the bootstrap tests we achieve the robustness to heteroskedasticity by implement-\ning the wild bootstrap version as described in Section 3.1.4.\nIf we consider the test statistics that perform best in our Monte Carlo experiment,\nthe outcomes above clearly point towards Granger-causality from BV (20) to ipi. This\nresult supports Andreou et al. (2000) concluding that \"[...] volatilities may also be useful\n[...] indicators for both the growth and volatility of industrial production\" (p. 15).\nThe situation is less clear cut when looking at Granger-causality from the low-frequency\nvariable to the high-frequency volatility measures. Indeed, max and most Bonferroni-\ntype tests seem to reject the null of no Granger-causality, whereas the joint tests do\nnot. However, the higher power obtained on the maximum of the individual Wald-type\ntests would favor the presence of Granger-causality in the direction from business cycle\nmovements to financial uncertainties as well. A more careful investigation, out of the\nscope of this paper, could be done on different subsamples in order to analyze whether,\ne.g., periods before, during or after the financial crises lead to similar conclusions.\n6 Conclusion\nWe investigate Granger non-causality testing in a mixed-frequency VAR, where the mis-\nmatch between the sampling frequencies of the variables under consideration is large,\ncausing estimation and inference to be potentially problematic. To avoid this issue we\ndiscuss two parameter reduction techniques in detail, reduced rank restrictions and a\nBayesian MF-VAR approach, and compare them to (i) a common low-frequency VAR,\n(ii) the max-test approach and (iii) the unrestricted VAR in terms of their Granger non-\ncausality testing behavior. To further improve their finite sample test properties we also\nconsider two bootstrap variants for the reduced rank regression approaches (and the un-\nrestricted VAR).\n27Note that, as discussed in Section 3.2.2, there is a one-to-one correspondence between the OLS\nestimator of the augmented model and the prior setting we consider in our Bayesian framework. As we\ndid not discuss setting that corresponds to a robust version of the Wald test we disregard from that test\nvariant here.\nTable 6: Testing for Granger Causality between BV (20) and ipi\nWald Robust Wald Robust\nWald Robust Wald Robust\nUNR\nb\nb\nb\nb\nb\nHAR\nb\nNote: For testing Granger non-causality between BV (20) and ipi the figures represent p-values (in per-\ncentages) of the asymptotic Wald test statistics, the restricted bootstrap variants for the direction from\nBV (20) to ipi and the unrestricted bootstrap variants for the direction from ipi to BV (20) (bootstrap\nvariants are indicated with a superscript '*', the Bonferroni-type tests with a subscript 'b'). For all\napproaches but the max-test (max) and the Bayesian MF-VAR (BMF) a robustified version is computed\nas well. The lag length of the estimated VARs is equal to one or two. For CCA and PLS the results for\none and two factors are displayed.\nFor both directions of causality we find a different set of tests to result in the best\nGranger non-causality testing behavior. For the direction from the high- to the low-\nfrequency series, standard testing within the Bayesian mixed-frequency VAR, the max-\ntest of Ghysels et al. (2015a), and the restricted bootstrap version of the Wald test in a\nreduced rank regression after HAR-type factors have been imposed or PLS-type factors\nhave been computed, the latter of which being restricted to nowcasting non-causality\n(G\u00a8\notz and Hecq, 2014), perform best. For the reverse direction, the unrestricted bootstrap\nvariants of the Bonferroni-corrected Wald tests within the following models dominate: the\nunrestricted VAR and reduced rank regressions with CCA-, PLS- or HAR-based factors.\nAn application investigating the presence of a causal link between business cycle fluc-\ntuations and uncertainty in financial markets illustrates the practical usefulness of these\napproaches. While Granger causality from uncertainty in financial markets to business\ncycle fluctuations was clearly supported by the data, evidence for causality in the reverse\ndirection only comes from a subset of the tests, yet the more powerful ones according to\nour simulation results.\nA Bayesian VAR estimation with mixed-frequency prior variances\nProperly accounting for the high-frequency time difference between the variables involved\nimplies the following prior variances:\nV ar[(k)\ni,j\n] =\n\n\n\n\n\nSLH\nSHL\n(k+(j-i)/m)2\nelse\nNow, define Z = (Z\u00b5\n, . . . , Z\u00b5\nT\n) , where Z\u00b5\nt\n= (Zt\n, 1) , and let us re-write the MF-VAR\nin (4) in the following way:\nvec(Z)\n= Z\nvec(B)\n+ vec(E)\nwhere Z = (Z1\n, . . . , ZT\n) , Z = Im+1\n Z, E = (u1\n, . . . , uT\n) , B = (B , \u00b5) and n =\n(m + 1)p + 1. In order to drop the undesirable feature of a fixed and diagonal covariance\nmatrix , we impose a normal inverted Wishart prior (at the cost of having to set  = 1)\nwith the following form (Kadiyala and Karlsson, 1997):\nvec(B)|  N(vec(B\n), [Z\n)Z\nwhere Z\nbeing a (T \u00d7 n)-matrix. B\nhave to be chosen\nas to let expectations and variances of the elements in B coincide with the moments in\nneed to be set such that E[] = d\n.\nSimilar to Banbura et al. (2010), we can show that adding auxiliary dummy variables\nYd\nand Xd\n, the precise composition of which is given in Appendix B, to (33) is equivalent\nto imposing the normal inverted Wishart prior in (34). To this end, let\nBaux\n= (Xd\nXd\nYd\n,\nZaux\n= Xd\n= (Yd\n- Xd\nBaux\n) (Yd\n- Xd\nBaux\n) and\n= m + 3 = Td\n- naux + 2,\nwhere naux = m(2p + 1) and Td\n= naux + (m + 1), and subsequently set\nvec(B\n) = S vec(Baux\n) and\nV ar[vec(B)] = S [Zaux\n)Zaux\nwith Zaux\nZaux\nand where S is an [(m+1)naux \u00d7(m+1)n]-dimensional selection\nmatrix, the precise construction of which is given in Appendix C.\nRemark 12. Intuitively speaking, Zaux\nis an auxiliary matrix constructed as the 'union'\nmatrices corresponding to the different columns of B. The non-random matrix\nS selects, for each column of B, the corresponding elements of Zaux\nin order to let the\nvariance of each element in B match the corresponding prior variance. Likewise, Baux\nis an auxiliary matrix from which we derive B\n.\nIn order to augment the model in (33), let us define Zd\nj\n= (Z , (Xd\nSj\n) ) , where Sj\nis\nthe jth block of the selection matrix S (see Appendix C for details), j = 1, . . . , m + 1.28\nThen, the augmented system becomes\nvec(Z\n)\n= Z\n\nvec(B)\n+ vec(E\n)\nwhere Z\n= (Z , Yd\n) , E\n= (E , Ed\n) and Z\n\nis block diagonal with Z\n\n= diag{Zd\n, Zd\n, . . . , Zd\n}.\nThe posterior then has the form\nvec(B)|, Z  N(vec( ^\nB), [Z\n\n(-1  IT+Td\n)Z\n\n]-1) and |Z  iW(^\nwhere ^\nV = ^\nE\n^\nE\nwith vec( ^\nE\n) = vec(Z\n) - Z\n\nvec( ^\nB).29 Note that the posterior mean\nof the coefficients boils down to\nvec( ^\nB) = [Z\n\n(-1  IT+Td\n)Z\n\n\n(-1  IT+Td\n)vec(Z\ni.e., the GLS estimate of a SUR regression of vec(Z\n) on Z\n\n. As for the common-frequency\ncase, it can be checked that it also coincides with the posterior mean for the prior setup\nin (26). An example with p = 1 and m = 2 illustrates the auxiliary dummy variables\napproach and is provided in Appendix D.\nB The auxiliary dummy variables with mixed-frequency prior variances\nThe auxiliary dummy variables that imply a matching of the prior moments turn out to\nbe\nYd\n=\n\n\n\n\n\n\n\n\nD\n/)\nL\nm/\ndiag(L\n, H\n, . . . , H\n)\n\n\n\n\n\n\n\n\nXd\nTd\u00d7naux\n=\n\n\n\n\np\n diag(L\n, H\np\nH\n\n\n\n\nwhere D\n= diaga(m, m-1\nm\nm\nm\n), with diaga(\u00b7) denoting an anti-diagonal\nmatrix. Furthermore,\np\nm\nm\nm\n, . . . , 2, . . . , . . . , p),\np\n= diag(p + 1\nm\nm\n, . . . , p + m-1\nm\n).\npicks the elements of Zaux\n= Xd\ncorresponding to column j of B.\n29In practice, we estimate  in the standard way, i.e., ^\nT +Td\n^\nEols\n\n^\nEols\n\n, where ^\nEols\n\ndenotes the OLS\nresiduals of the system in (37). Again, a sample size correction alleviates potential size distortions (see\nSection 3.1.2). The ith column of ^\nEols\n\n, i = 1, . . . , m + 1, corresponds to the residuals of a regression of\n(Z\u00b7,i\n, Yd,i\n) on Zd\ni\n, where Z\u00b7,i\nand Yd,i\ndenote the ith columns of Z and Yd\n, respectively.\nThe last line of both, Yd\nand Xd\n, corresponds to the diffuse prior for the intercept ( is a\nvery small number), the block above imposes the prior for  and the remaining blocks set\nthe priors for the coefficients (k)\ni,j\ni\ni\n, i = L, H,\ni\nis the variance of a residual from an AR(p), respectively an AR(mp), model for\nyt\n, respectively for x(m)\nt\n.\nC Construction of the selection matrix S\nLet us investigate the variance of vec(B)| more closely. Noting that we have to choose\n, or Z\nin (34), in such a way as to let the variances of the corresponding coefficients\ncoincide with the prior variances in (26), it turns out that we need to set\nV ar[vec(B)|] =\n\n\n\n\n\n\n\n\nL\n. . . . . . 0n\u00d7n\nH\n. . . 0n\u00d7n\n.\n.\nH\n. . .\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n. . . 0n\u00d7n\nH\n\n\n\n\n\n\n\n\nwhere\n(i)\nL\nH\nH\n, . . . , 2\nH\n, . . . ,\nL\nH\n, . . . , 2\nH\n)\nfor i = 2, . . . , m + 1.\nHence, unlike in the common-frequency case, where (i)\ni (Banbura et al.,\n2010), the set of variances changes due to the stacked nature of the vector Zt\nand the\nspecific lag structure for each coefficient (see the variances in (26)). Let us form an\nauxiliary matrix aux\n, which contains the union of all elements in (2)\n, . . . , (m+1)\n. Each\nmatrix (i)\ncontains p + 1 new elements compared to (i-1)\nfor i > 2. As there are n\nelements in (2)\n, we end up with a dimension of m(2p + 1) = naux for the square matrix\naux\n:\naux\nL\nH\n, . . . , 2\nL\nH\nL\nH\n, . . . , 2\nH\n,\n. . . , . . . , 2\nL\nH\nH\n, . . . , 2\nH\n).\nAll that remains is to define a [(m + 1)naux \u00d7 (m + 1)n]-dimensional selection matrix S\nsuch that S (d\n aux\n)S = V ar[vec(B)|] . Note that from aux\nwe can then derive\nZaux\n= Xd\nby using aux\n= (Zaux\nZaux\nLet us denote by 1i\nan naux-dimensional column vector with a one in row i and zeros\nelsewhere. It turns out that S is a block-diagonal matrix, i.e., S = diag{S1\n, . . . , Sm+1\n},\nwhere each off-diagonal block is 0naux\u00d7n\n. Each Sj\n, j = 1, . . . , m + 1, can be described as\nfollows:\nSj\nj\nj\nwhere\nj\n, . . . ,\n),\nj\n=\n for j = m + 1\n) else\nand\nEach of the indices in Sj\nreveals which row element of the jth column of Baux\ngets selected\nby S. Put differently, the indices that are missing in Sj\ncorrespond to elements of Baux\n(in\ncolumn j) that will not get chosen by S. This implies that the values of these elements do\nnot play a role for the computation of vec(B\n). Consequently, when constructing Baux\n,\nand subsequently also Yd\n, we assign these elements a value of zero for simplicity.\nD Example of the auxiliary dummy variables approach with mixed-frequency\nprior variances\nLet p = 1 and m = 2. The prior beliefs in (26) corresponding to this setup, and written\nin terms of vec(B) = vec((B , \u00b5) ), are given by\nE(vec(B)) = vec\n\n\n\n\n\n\n\n\nand\nV ar(vec(B)) =\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLH\nL\nH\nSHL\nH\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\nWith Td\n= 9 and naux = 6 the auxiliary dummy variables look as follows:\nYd\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH\n\n\n\nL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n, Xd\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL\n\nH\n\n\n\nH\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\nLet us demonstrate that these auxiliary dummy variables truly imply a matching of\nthe prior moments in (34) and the prior beliefs given above. Simple algebra gives us\nZaux\n= Xd\n= 5 as well as\nBaux\n= (Xd\nXd\nYd\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n,\n= (Yd\n- Xd\nBaux\n) (Yd\n- Xd\nBaux\n) =\n\n\nL\nH\nH\n\n .\nTo obtain vec(B\n) we require the selection matrix S. Following the guidelines in Appendix\nC yields S = diag{S1\n}, where the off-diagonal blocks are of dimension 6 \u00d7 4 and\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\nNow it is easy to show that, indeed,\nvec(B\n) = S vec(Baux\n) = vec\n\n\n\n\n\n\n\n\n= E(vec(B))\nand S [  (Zaux\nZaux\n)-1]S = V ar(vec(B)) as in equation (50).\nHaving shown that Yd\nand Xd\ncapture the prior moments, we need to augment the\nMF-VAR. Let us start by re-writing it into the format presented in equation (33):\nvec\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\nyT\nT\n\n\n\n=\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n\n\n\n\n\nvec\n\n\n\n\n\n\n\n\nvec(B)\n+vec(E).\nFollowing the steps outlined at the end of Section 3.2.2 gives us the augmented system:\nvec\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\nyT\nT\nH\n\n\n\nL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n= Z\n\nvec(B) + vec(E\n).\nwith\nZ\n\n=\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nL\n\n\nH\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nL\n\n\nH\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\nL\n\nH\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.\nThe GLS estimate of vec(B) in the regression above is then a closed-form solution\nfor the posterior mean of the coefficients.\nReferences\nAnderson, T. W. (1951). Estimating linear restrictions on regression coefficients for mul-\nAndreou, E., D. R. Osborn, and M. Sensier (2000). A comparison of the statistical\nproperties of financial variables in the usa, uk and germany over the business cycle.\nAndrews, D. W. K. (1994). The large sample correspondence between classical hypothesis\nBanbura, M., D. Giannone, and L. Reichlin (2010). Large bayesian vector auto regressions.\nBauwens, L., M. Lubrano, and J.-F. Richard (2000). Bayesian inference in dynamic\neconometric models. Oxford University Press.\nBose, A. (1988). Edgeworth correction by bootstrap in autoregressions. Annals of Statis-\nBreitung, J. and N. R. Swanson (2002). Temporal aggregation and spurious instantaneous\ncausality in multiple time series models. Journal of Time Series Analysis 23, 651\u00ad666.\nBr\u00a8\nuggemann, R., C. Jentsch, and C. Trenkler (2014). Inference in VARs with conditional\nheteroskedasticity of unknown form. Technical report, Department of Economics, Uni-\nversity of Konstanz.\nCarriero, A., G. Kapetanios, and M. Marcellino (2011). Forecasting large datasets with\nbayesian reduced rank multivariate models. Journal of Applied Econometrics 26(5),\nCavaliere, G., A. Rahbek, and A. M. R. Taylor (2012). Bootstrap determination of the\nChauvet, M., Z. Senyuz, and E. Yoldas (2015). What does financial volatility tell us about\nmacroeconomic fluctuations? Journal of Economic Dynamics and Control 52(C), 340\u00ad\nClements, M. and A. B. Galv~\nao (2008). Macroeconomic forecasting with mixed-frequency\nClements, M. and A. B. Galv~\nao (2009). Forecasting u.s. output growth using leading\nindicators: An appraisal using midas models. Journal of Applied Econometrics 24(7),\nCorsi, F. (2009). A simple approximate long-memory model of realized volatility. Journal\nCox, D. R., G. Gudmundsson, G. Lindgren, L. Bondesson, E. Harsaae, P. Laake,\nK. Juselius, and S. L. Lauritzen (1981). Statistical analysis of time series: Some re-\ncent developments [with discussion and reply]. Scandinavian Journal of Statistics 8(2),\nCubadda, G. and B. Guardabascio (2012). A medium-n approach to macroeconomic\nCubadda, G. and A. Hecq (2011). Testing for common autocorrelation in data rich\nDavies, R. B. (1987). Hypothesis testing when a nuisance parameter is present only under\nDunn, O. J. (1961). Multiple comparisons among means. Journal of the American Sta-\nEichler, M. and V. Didelez (2009). On Granger-causality and the effect of interventions\nin time series. Technical report.\nEngle, R. F. and J. G. Rangel (2008). The spline-garch model for low-frequency volatility\nForoni, C. and M. Marcellino (2014, November). Mixed Frequency Structural Mod-\nels: Identification, Estimation, And Policy Analysis. Journal of Applied Economet-\nForoni, C., M. Marcellino, and C. Schumacher (2015, 01). Unrestricted mixed data sam-\npling (MIDAS): MIDAS regressions with unrestricted lag polynomials. Journal of the\nForsberg, L. and E. Ghysels (2007). Why do absolute returns predict volatility so well?\nGhysels, E. (2015). Macroeconomics and the reality of mixed frequency data. Technical\nreport.\nGhysels, E. and J. I. Miller (2013, June). Testing for Cointegration with Temporally\nAggregated and Mixed-frequency Time Series. Working Papers 1307, Department of\nEconomics, University of Missouri.\nGhysels, E., K. Motegi, and J. Hill (2015a). Simple granger causality tests for mixed\nfrequency data. Discussion Paper.\nGhysels, E., K. Motegi, and J. Hill (2015b). Testing for granger causality with mixed\nfrequency data. Discussion Paper.\nGhysels, E., P. Santa-Clara, and R. Valkanov (2004). The midas touch: Mixed data\nsampling regression models. CIRANO Working Papers 2004s-20, CIRANO.\nGhysels, E., A. Sinko, and R. Valkanov (2007). Midas regressions: Further results and\nGhysels, E. and R. Valkanov (2012). Forecasting volatility with MIDAS, Chapter 16, pp.\n383\u00ad401. Handbook of Volatility Models and Their Applications. John Wiley & Sons,\nInc., Hoboken, NJ, USA.\nGon\u00b8\ncalves, S. and B. Perron (2014). Bootstrapping factor-augmented regression models.\nG\u00a8\notz, T. B. and A. Hecq (2014). Nowcasting causality in mixed frequency vector autore-\nG\u00a8\notz, T. B., A. Hecq, and L. Lieb (2015). Real-time mixed-frequency vars: Nowcasting,\nbackcasting and granger causality. Discussion Paper.\nG\u00a8\notz, T. B., A. Hecq, and J.-P. Urbain (2013). Testing for common cycles in non-\nstationary VARs with varied frecquency data, Volume 32 of Advances in Econometrics,\nG\u00a8\notz, T. B., A. Hecq, and J.-P. Urbain (2014). Forecasting mixed frequency time series\nGranger, C. W. J. (1969). Investigating causal relations by econometric models and\nHamilton, J. D. and L. Gang (1996). Stock market volatility and the business cycle.\nHansen, B. E. (1996). Inference when a nuisance parameter is not identified under the\nHeber, G., A. Lunde, N. Shephard, and K. Sheppard (2009). Oxford-man institute's\nrealized library (version 0.2). Oxford-Man Institute, University of Oxford.\nHoerl, A. E. and R. W. Kennard (1970). Ridge regression: Biased estimation for\nHorowitz, J. L. (2001). The bootstrap. In J. J. Heckman and E. E. Leamer (Eds.),\nHolland Publishing.\nKadiyala, K. R. and S. Karlsson (1997). Numerical methods for estimation and inference\nKilian, L. (1998). Small-sample confidence intervals for impulse response functions. Review\nLitterman, R. B. (1986). Forecasting with bayesian vector autoregressions - five years of\nexperience. Journal of Business & Economic Statistics 4(1), 25\u00ad38.\nL\u00a8\nutkepohl, H. (1993). Testing for causation between two variables in higher dimensional\nVAR models, pp. 75\u00ad91. Studies in Applied Econometrics. Springer-Verlag, Heidelberg.\nMarcellino, M. (1999). Some consequences of temporal aggregation in empirical analysis.\nMarsilli, C. (2014). Variable selection in predictive midas models. Working papers 520,\nBanque du France.\nMcCracken, M. W., M. T. Owyang, and T. Sekhposyan (2015, October). Real-Time\nForecasting with a Large, Mixed Frequency, Bayesian VAR. Working Papers 2015-30,\nFederal Reserve Bank of St. Louis.\nMele, A. (2007). Asymmetric stock market volatility and the cyclical behavior of expected\nMiller, J. I. (2011). Conditionally efficient estimation of long-run relationships using\nmixed-frequency time series. Working Papers 1103, Department of Economics, Univer-\nsity of Missouri.\nMiller, J. I. (2012, August). Mixed-frequency Cointegrating Regressions with Parsimo-\nnious Distributed Lag Structures. Working Papers 1211, Department of Economics,\nUniversity of Missouri.\nPaparoditis, E. (1996). Bootstrapping autoregressive and moving average parameter es-\ntimates of infinite order vector autoregressive processes. Journal of Multivariate Anal-\nPaparoditis, E. and D. N. Politis (2005). Bootstrap hypothesis testing in regression\nPark, T. and G. Casella (2008). The Bayesian Lasso. Journal of American Statistical\nRavikumar, B., S. Ray, and N. E. Savin (2000). Robust wald tests in sur systems with\nSchorfheide, F. and D. Song (2015). Real-time forecasting with a mixed-frequency var.\nJournal of Business and Economic Statistics 33, 366\u00ad380. \u00a1p\u00bfSecond version: December\navailable as FRB Minneapolis Working Paper 701\u00a1/p\u00bf.\nSchwert, G. W. (1989a). Business cycles, financial crises, and stock volatility. Carnegie-\nSchwert, G. W. (1989b). Why does stock market volatility change over time? Journal of\nSilvestrini, A. and D. Veredas (2008). Temporal aggregation of univariate and multivariate\nSims, C. A. (1971). Discrete approximations to continuous time distributed lags in econo-\nSims, C. A. and T. Zha (1998, November). Bayesian Methods for Dynamic Multivariate\nTibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the\nVahid, F. and R. F. Engle (1993). Common trends and common cycles. Journal of Applied\nVan Giersbergen, N. P. A. and J. F. Kiviet (1996). Bootstrapping a stable AD model:\nweak vs strong exogeneity. Oxford Bulletin of Economics and Statistics 58, 631\u00ad656.\nPhiladelphia: Society for Industrial and Applied Mathematics.\nWaggoner, D. F. and T. Zha (2003, November). A Gibbs sampler for structural vector\nWhite, H. (2000). A reality check for data snooping. Econometrica 68.\nZellner, A. (1996). An introduction to bayesian inference in econometrics. John Wiley\nand Sons, Inc."
}